filename,title,authors,doi,arxiv_id,keywords,summary,tps,total_time,tokens,mode,model,platform
2601.07192v1_Relink Constructing Query-Driven Evidence Graph On.pdf,Constructing Query-Driven Evidence Graph On-the-Fly for GraphRAG,"Manzong Huang, Chenyang Bu, Yi He, Xingrui Zhuo, Xindong Wu",,,"Graph-based Retrieval-Augmented Generation, Knowledge Graph, Large Language Models, Open-Domain Question Answering, Evidence Graph, Latent Relations","Graph-based Retrieval-Augmented Generation (GraphRAG) mitigates hallucinations in Large Language Models (LLMs) by grounding them in structured knowledge. However, current GraphRAG methods are constrained by a build-then-reason paradigm, relying on a static, pre-constructed Knowledge Graph (KG). This paradigm faces challenges such as KG incompleteness and low signal-to-noise ratio, introducing distractor facts. To address these, the paper proposes Relink, a framework that dynamically builds a query-specific evidence graph. Relink instantiates required facts from a latent relation pool derived from the original text corpus, repairing broken paths on the fly. It employs a unified, query-aware evaluation strategy to select the most useful candidates for answering the query, actively discarding distractor facts. Extensive experiments show that Relink achieves significant improvements over leading GraphRAG baselines, demonstrating the superiority of the proposed framework.",7.79,40.429,315,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07197v1_Beyond Variance Knowledge-Aware LLM Compression vi.pdf,Beyond Variance: Knowledge-Aware LLM Compression via Fisher-Aligned Subspace Diagnostics,"Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma",,,"Large Language Models, activation compression, Singular Value Decomposition, Fisher Information Matrix, knowledge-intensive benchmarks, MMLU, LAMA","Post-training activation compression is essential for deploying Large Language Models (LLMs) on resource-constrained hardware. Standard methods like Singular Value Decomposition (SVD) are gradient-blind and preserve high-variance dimensions regardless of their impact on factual knowledge preservation. This paper introduces Fisher-Aligned Subspace Compression (FASC), a knowledge-aware compression framework that selects subspaces by directly modeling activation-gradient coupling, minimizing a second-order surrogate of the loss function. FASC leverages the Fisher Information Matrix to identify dimensions critical for factual knowledge, which often reside in low-variance but high-gradient-sensitivity subspaces. The Dependence Violation Score (ρ) is proposed as a diagnostic metric that quantifies activation-gradient coupling, revealing where factual knowledge is stored within transformer architectures. Experiments on Mistral-7B and Llama-3-8B demonstrate that FASC preserves 6-8% more accuracy on knowledge-intensive benchmarks compared to variance-based methods at 50% rank reduction, effectively enabling a 7B model to match the factual recall of a 13B uncompressed model. The analysis reveals that ρ serves as a fundamental signal of stored knowledge, with high-ρ layers emerging only when models internalize factual associations during training.",18.47,20.146,372,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07199v1_Forward versus Backward Comparing Reasoning Object.pdf,Forward versus Backward: Comparing Reasoning Objectives in Direct Preference Optimization,"Murtaza Nikazad, Raghuram Ramanujan",,,"Direct Preference Optimization, reasoning capabilities, hallucination, GSM8K, Low-Rank Adaptation","This paper investigates the effect of training objective composition on reasoning reliability through Direct Preference Optimization. It examines two training signals: forward chain-of-thought generation and backward verification. Experiments on GSM8K reveal a trade-off between these objectives. Forward-only training improves accuracy, while backward-only training reduces false positives but with minimal accuracy gains. Both training variants reduce the acknowledgement rate, indicating increased model confidence. Forward training enhances problem-solving, and backward training improves verification calibration. The study uses Low-Rank Adaptation for efficient implementation.",16.79,12.567,211,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07200v1_Safeguarding LLM Fine-tuning via Push-Pull Distrib.pdf,Safeguarding LLM Fine-tuning via Push-Pull Distributional Alignment,"Haozhong Wang, Zhuo Li, Yibo Yang, He Zhao, Hongyuan Zha, Dandan Guo",,,"LLM Fine-tuning, Safety Alignment, Optimal Transport, Data Distribution, Model Safety","The inherent safety alignment of Large Language Models (LLMs) is prone to erosion during fine-tuning, even with seemingly innocuous datasets. Existing defenses often rely on heuristic, instance-level assessments that neglect the global geometry of data distribution and fail to explicitly repel harmful patterns. This paper introduces Safety Optimal Transport (SOT), a novel framework that reframes safe fine-tuning from an instance-level filtering challenge to a distribution-level alignment task grounded in Optimal Transport (OT). SOT employs a dual-reference 'push-pull' weight-learning mechanism, optimizing sample importance by pulling the downstream distribution towards a trusted safe anchor while pushing it away from a general harmful reference. This establishes a robust geometric safety boundary that effectively purifies the training data. Extensive experiments demonstrate that SOT significantly enhances model safety while maintaining competitive downstream performance, achieving a superior safety-utility trade-off compared to baselines.",17.24,17.629,304,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07201v1_CalPro Prior-Aware Evidential--Conformal Predictio.pdf,CalPro: Prior-Aware Evidential–Conformal Prediction with Structure-Aware Guarantees for Protein Structures,"Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma",,,"protein structure prediction, uncertainty quantification, conformal prediction, evidential learning, distribution shift, calibration, deep learning, structure-aware guarantees","Deep protein structure predictors like AlphaFold provide confidence estimates that are not calibrated and degrade under distribution shifts. CalPro introduces a prior-aware evidential–conformal framework for robust uncertainty quantification. It combines a geometric evidential head, a differentiable conformal layer, and domain priors to maintain near-nominal coverage and achieve tighter intervals. Empirically, CalPro shows ≤5% coverage degradation across modalities, reduces calibration error by 30–50%, and improves ligand-docking success by 25%. It is applicable to structured regression tasks with local reliability priors.",16.4,15.551,255,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07206v1_LLMRouterBench A Massive Benchmark and Unified Fra.pdf,LLMRouterBench: A Massive Benchmark and Unified Framework for LLM Routing,"Hao Li, Yiqun Zhang, Zhaoyan Guo, Chenxu Wang, Shengji Tang, Qiaosheng Zhang, Yang Chen, Biqing Qi, Peng Ye, Lei Bai, Zhen Wang, Shuyue Hu",,,"Large Language Models, LLM Routing, Benchmark, Performance-Cost Trade-off, Model Ensemble, Routing Methods","LLMRouterBench is a large-scale benchmark and unified framework for LLM routing, comprising over 400K instances from 21 datasets and 33 models. It provides comprehensive metrics for performance-oriented and performance-cost trade-off routing, integrating 10 representative routing baselines. The benchmark reveals strong model complementarity, similar performance among many routing methods, and a substantial gap to the Oracle due to model-recall failures. It also shows limited impact of backbone embedding models, diminishing returns from larger ensembles, and enables latency-aware analysis. All code and data are available at https://github.com/ynulihao/LLMRouterBench.",16.96,17.749,301,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07209v1_SIRR-LMM Single-image Reflection Removal via Large.pdf,SIRR-LMM: Single-image Reflection Removal via Large Multimodal Model,"Yu Guo, Zhiqiang Lao, Xiyun Song, Yubin Zhou, Heather Yu",,,"Single-image Reflection Removal, Large Multimodal Model, Synthetic Dataset, Path-tracing, LoRA","Glass surfaces create complex interactions of reflected and transmitted light, making single-image reflection removal (SIRR) challenging. Existing datasets suffer from limited physical realism in synthetic data or insufficient scale in real captures. This paper introduces a synthetic dataset generation framework that path-traces 3D glass models over real background imagery to create physically accurate reflection scenarios with varied glass properties, camera settings, and post-processing effects. By leveraging the capabilities of Large Multimodal Model (LMM), the approach concatenates image layers into a single composite input, applies joint captioning, and fine-tunes the model using task-specific LoRA rather than full-parameter training. This enables improved reflection removal and separation performance compared to state-of-the-art methods. The paper addresses the gap in high-quality training data by using a path-traced synthetic dataset with physically accurate 3D glass models combined with real background imagery, fine-tuning an LMM with task-specific Low-Rank Adaptation (LoRA) for strong performance with relatively small datasets.",18.06,16.554,299,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07214v1_BlindU Blind Machine Unlearning without Revealing .pdf,BlindU: Blind Machine Unlearning without Revealing Erasing Data,"Weiqi Wang, Zhiyi Tian, Chenhan Zhang, Shui Yu",,,"Machine Unlearning, Federated Learning, Privacy Leakage, Privacy Preserving, Information Bottleneck","Machine unlearning enables data holders to remove the contribution of their specified samples from trained models to protect their privacy. However, most unlearning methods require the unlearning requesters to upload their data to the server, which is infeasible in privacy-preserving scenarios like federated learning. This paper proposes Blind Unlearning (BlindU), which uses compressed representations instead of original inputs for unlearning. BlindU involves the server and the unlearning user, where the user generates privacy-preserving representations locally, and the server performs unlearning on these representations and their labels. The paper employs the information bottleneck mechanism for FL model training and introduces a noise-free differential privacy masking method to enhance privacy protection. Theoretical analysis and experimental results demonstrate the superiority of BlindU in privacy protection and unlearning effectiveness compared to existing benchmarks.",17.48,15.618,273,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07224v1_Consolidation or Adaptation PRISM Disentangling SF.pdf,Consolidation or Adaptation? PRISM: Disentangling SFT and RL Data via Gradient Concentration,"Yang Zhao, Yangou Ouyang, Xiao Ding, Hepeng Wang, Bibo Cai, Kai Xiong, Jinglong Gao, Zhouhao Sun, Li Du, Bing Qin, Ting Liu",,,"Hybrid Supervised Fine-Tuning, Reinforcement Learning, LLM agents, data arbitration, Schema Theory, gradient concentration, structural adaptation, pattern consolidation, optimization interference, cognitive conflict","The paper discusses the standard paradigm of using Hybrid Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) for training Large Language Model (LLM) agents. It highlights the lack of effective data allocation mechanisms between these stages and proposes PRISM, a framework that arbitrates data based on cognitive conflict with the model's existing knowledge. PRISM identifies high-conflict data requiring RL for structural adaptation and low-conflict data for SFT consolidation. Experiments show PRISM's superiority in performance and computational efficiency.",17.3,17.399,301,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07226v1_Lost in the Noise How Reasoning Models Fail with C.pdf,Lost in the Noise: How Reasoning Models Fail with Contextual Distractors,"Seongyun Lee, Yongrae Jo, Minju Seo, Moontae Lee, Minjoon Seo",,,"reasoning models, contextual distractors, NoisyBench, robustness, RAG, tool-use tasks, Rationale-Aware Reward (RARE)","Recent advances in reasoning models and agentic AI systems have led to an increased reliance on diverse external information. However, this shift introduces input contexts that are inherently noisy, a reality that current sanitized benchmarks fail to capture. The paper introduces NoisyBench, a comprehensive benchmark that evaluates model robustness across 11 datasets in RAG, reasoning, alignment, and tool-use tasks against diverse noise types. The evaluation reveals a significant performance drop in state-of-the-art models when faced with contextual distractors. The study finds that agentic workflows often amplify these errors by over-trusting noisy tool outputs, and distractors can trigger emergent misalignment even without adversarial intent. The paper proposes Rationale-Aware Reward (RARE) to strengthen resilience by incentivizing the identification of helpful information within noise. It also uncovers an inverse scaling trend where increased test-time computation leads to worse performance in noisy settings and demonstrates via attention visualization that models disproportionately focus on distractor tokens.",18.57,17.989,334,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07229v2_DiSCo Making Absence Visible in Intelligent Summar.pdf,DiSCo: Making Absence Visible in Intelligent Summarization Interfaces,"ERAN FAINMAN, HAGIT BEN SHOSHAN, ADIR SOLOMON, OSNAT MOKRYN",,,"Review Summarization, Absence, Expectations, Learning via surprisability, Missing commonalities, Human-centered computing, User studies, Information systems, Expert systems, Computing methodologies, Artificial intelligence","Intelligent interfaces increasingly use large language models to summarize user-generated content, yet these summaries emphasize what is mentioned while overlooking what is missing. This presence bias can mislead users who rely on summaries to make decisions. The paper presents Domain Informed Summarization through Contrast (DiSCo), an expectation-based computational approach that makes absences visible by comparing each entity’s content with domain topical expectations captured in reference distributions of aspects typically discussed in comparable accommodations. This comparison identifies aspects that are either unusually emphasized or missing relative to domain norms and integrates them into the generated text. In a user study across three accommodation domains, namely ski, beach, and city center, DiSCo summaries were rated as more detailed and useful for decision making than baseline large language model summaries, although slightly harder to read. The findings show that modeling expectations reduces presence bias and improves both transparency and decision support in intelligent summarization interfaces.",18.25,16.766,306,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07232v1_Yes FLoReNce I Will Do Better Next Time Agentic Fe.pdf,"Y es FLoReNce, I Will Do Better Next Time! Agentic Feedback Reasoning for Humorous Meme Detection","Olivia Shanhong Liu, Pai Chet Ng, De Wen Soh, Konstantinos N. Plataniotis",,,"humorous meme detection, agentic feedback reasoning, multimodal models, AI systems, humor interpretation, closed-loop learning, open-loop inference","Humorous memes blend visual and textual cues to convey irony, satire, or social commentary, posing unique challenges for AI systems that must interpret intent rather than surface correlations. Existing multimodal or prompting-based models generate explanations for humor but operate in an open loop, lacking the ability to critique or refine their reasoning once a prediction is made. We propose FLoReNce, an agentic feedback reasoning framework that treats meme understanding as a closed-loop process during learning and an open-loop process during inference. In the closed loop, a reasoning agent is critiqued by a judge; the error and semantic feedback are converted into control signals and stored in a feedback-informed, non-parametric knowledge base. At inference, the model retrieves similar judged experiences from this KB and uses them to modulate its prompt, enabling better, self-aligned reasoning without finetuning. On the PrideMM dataset, FLoReNce improves both predictive performance and explanation quality over static multimodal baselines, showing that feedback-regulated prompting is a viable path to adaptive meme humor understanding.",18.22,19.592,357,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07233v1_From Thinking to Justifying Aligning High-Stakes E.pdf,From “Thinking” to “Justifying”: Aligning High-Stakes Explainability with Professional Communication Standards,"Chen Qian, Yimeng Wang, Yu Chen, Lingfei Wu, Andreas Stathopoulos",,,"Explainable AI, Chain-of-Thought, Structured Explainability Framework, SEF, CREAC, BLUF, high-stakes domains","Explainable AI (XAI) in high-stakes domains should help stakeholders trust and verify system outputs. Chain-of-Thought methods reason before concluding, but logical gaps or hallucinations can lead to unreliable conclusions. The paper proposes a 'Result → Justify' approach, using the Structured Explainability Framework (SEF) to align explanations with professional communication standards like CREAC and BLUF. Experiments show that SEF improves verifiability and reliability, with metrics correlating with correctness and achieving higher accuracy than CoT.",15.48,14.147,219,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07238v1_Group Pattern Selection Optimization Let LRMs Pick.pdf,Group Pattern Selection Optimization: Let LRMs Pick the Right Pattern for Reasoning,"Hanbin Wang, Jingwei Song, Jinpeng Li, Fei Mi, Lifeng Shang",,,"Large reasoning models, reinforcement learning, pattern selection, mathematics benchmarks, science benchmarks, Chain-of-Thought, Proximal Policy Optimization, GRPO","Large reasoning models (LRMs) exhibit diverse high-level reasoning patterns, yet prevailing training methods often bias them towards a limited set of dominant patterns. This paper introduces Group Pattern Selection Optimization (GPSO), a reinforcement learning framework that enhances pattern selection by incorporating multi-pattern rollouts, verifier-guided optimal pattern selection per problem, and attention masking to prevent pattern leakage. GPSO enables models to map problem characteristics to optimal reasoning patterns, resulting in consistent performance gains across various models and benchmarks. The approach mitigates pattern sub-optimality and fosters more robust, adaptable reasoning.",16.61,15.114,251,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07239v1_Stochastic CHAOS Why Deterministic Inference Kills.pdf,"Stochastic CHAOS: Why Deterministic Inference Kills, and Distributional Variability Is the Heartbeat of Artificial Cognition","Tanmay Joshi, Shourya Aggarwal, Anusa Saha, Aadi Pandey, Shreyash Dhoot, Vighnesh Rai, Raxit Goswami, Aman Chadha, Vinija Jain, Amitava Das",,,"large language models, deterministic inference, stochasticity, distributional variability, artificial cognition, LLM inference, reproducibility, uncertainty modeling, emergent abilities, reasoning paths, safety alignment","The paper argues against deterministic inference in large language models (LLMs), claiming it undermines the ability to model uncertainty, disrupts emergent abilities, and makes reasoning brittle. It advocates for stochastic inference, emphasizing that distributional variability is crucial for artificial cognition. The authors distinguish between algorithmic stochasticity and numerical/systems nondeterminism, proposing three stability goals for LLM inference: bitwise determinism, distributional reproducibility, and semantic stability. They demonstrate that deterministic inference can be misleading in instruction-following, emergent abilities, and reasoning, advocating for a stochastic approach to better capture the underlying distribution.",18.4,17.992,331,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07245v1_Learning to Trust the Crowd A Multi-Model Consensu.pdf,Learning to Trust the Crowd: A Multi-Model Consensus Reasoning Engine for Large Language Models,Pranav Kallem,,,"Large Language Models, Multi-Model Consensus, Reliability, Semantic Embeddings, Graph Neural Networks, Gradient-Boosted Trees, Listwise Ranking, LLM Diversity, Model Calibration","Large language models (LLMs) achieve strong average performance but remain unreliable at the instance level, with frequent hallucinations, brittle failures, and poorly calibrated confidence. This study explores reliability through multi-model consensus, using responses from several heterogeneous LLMs to determine the most likely correct answer for a given query. A Multi-Model Consensus Reasoning Engine is introduced, which uses a supervised meta-learner to map natural language responses into structured features. These features include semantic embeddings, pairwise similarity, clustering statistics, lexical and structural cues, reasoning-quality scores, confidence estimates, and model-specific priors. The system applies gradient-boosted trees, listwise ranking, and graph neural networks over similarity graphs of answers. Evaluations on subsets of GSM8K, ARC-Challenge, HellaSwag, and TruthfulQA show that the best graph-attention-based consensus model improves macro-average accuracy by 4.6 percentage points over the strongest single LLM and by 8.1 points over majority vote, while also yielding lower Brier scores and fewer TruthfulQA hallucinations. Ablation and feature-importance analyses indicate that semantic agreement and clustering features are most influential, with reasoning-quality and model-prior features providing complementary gains. This suggests that supervised multi-model consensus is a practical route toward more reliable LLM behavior, even in a modest single-machine setup.",18.96,20.889,396,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07250v1_DDT A Dual-Masking Dual-Expert Transformer for Ene.pdf,DDT: A Dual-Masking Dual-Expert Transformer for Energy Time-Series Forecasting,"Mingnan Zhu, Qixuan Zhang, Yixuan Cheng, Fangzhou Gu, Shiming Lin",,,"Time-Series Forecasting, Multivariate Temporal Modeling, Dynamic-Causal Masking, Adaptive Feature Fusion","Accurate energy time-series forecasting is crucial for ensuring grid stability and promoting the integration of renewable energy, yet it faces significant challenges from complex temporal dependencies and the heterogeneity of multi-source data. To address these issues, we propose DDT, a novel and robust deep learning framework for high-precision time-series forecasting. At its core, DDT introduces two key innovations. First, we design a dual-masking mechanism that synergistically combines a strict causal mask with a data-driven dynamic mask. This novel design ensures theoretical causal consistency while adaptively focusing on the most salient historical information, overcoming the rigidity of traditional masking techniques. Second, our architecture features a dual-expert system that decouples the modeling of temporal dynamics and cross-variable correlations into parallel, specialized pathways, which are then intelligently integrated through a dynamic gated fusion module. We conducted extensive experiments on 7 challenging energy benchmark datasets, including ETTh, Electricity, and Solar. The results demonstrate that DDT consistently outperforms strong state-of-the-art baselines across all prediction horizons, establishing a new benchmark for the task.",18.44,18.384,339,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07261v1_Pseudodata-guided Invariant Representation Learnin.pdf,Pseudodata-guided Invariant Representation Learning Boosts the Out-of-Distribution Generalization in Enzymatic Kinetic Parameter Prediction,"Haomin Wu, Zhiwei Nie, Hongyu Zhang, Zhixiang Ren",,2601.07261v1,"enzyme kinetic parameters, deep learning, enzyme-substrate interaction, out-of-distribution generalization, invariant representation learning","Accurate prediction of enzyme kinetic parameters is essential for understanding catalytic mechanisms and guiding enzyme engineering. Existing deep learning-based enzyme-substrate interaction (ESI) predictors often exhibit performance degradation on sequence-divergent, out-of-distribution (OOD) cases, limiting robustness under biologically relevant perturbations. This work proposes O2DENet, a lightweight, plug-and-play module that enhances OOD generalization via biologically and chemically informed perturbation augmentation and invariant representation learning. O2DENet introduces enzyme-substrate perturbations and enforces consistency between original and augmented enzyme-substrate-pair representations to encourage invariance to distributional shifts. When integrated with representative ESI models, O2DENet consistently improves predictive performance for both kcat and Km across stringent sequence-identity-based OOD benchmarks, achieving state-of-the-art results among the evaluated methods in terms of accuracy and robustness metrics. Overall, O2DENet provides a general and effective strategy to enhance the stability and deployability of data-driven enzyme kinetics predictors for real-world enzyme engineering applications.",20.36,17.142,349,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07263v1_When Bots Take the Bait Exposing and Mitigating th.pdf,When Bots Take the Bait: Exposing and Mitigating the Emerging Social Engineering Attack in Web Automation Agent,"Xinyi Wu, Geng Hong, Yueyue Chen, MingXuan Liu, Feier Jin, Xudong Pan, Jiarun Dai, Baojun Liu",,,"Web agents, social engineering attacks, web automation, large language models, security, runtime mitigation","Web agents, powered by large language models (LLMs), are increasingly deployed to automate complex web interactions. The rise of open-source frameworks has accelerated adoption but also broadened the attack surface. This study introduces the AGENTBAIT paradigm, exploiting intrinsic weaknesses in agent execution to induce malicious objectives. The SUPERVISOR module is proposed as a defense, enforcing environment and intention consistency to mitigate unsafe operations. Empirical results show mainstream frameworks are highly vulnerable to AGENTBAIT, with an average attack success rate of 67.5%. The SUPERVISOR module reduces attack success rates by up to 78.1% with minimal runtime overhead, advancing the security of web agents.",17.32,16.453,285,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07291v1_A Visual Semantic Adaptive Watermark grounded by P.pdf,A Visual Semantic Adaptive Watermark grounded by Prefix-Tuning for Large Vision-Language Model,"Qi Zheng, Shuliang Liu, Yu Huang, Sihang Jia, Jungang Li, Lyuhao Chen, Junhao Chen, Hanqian Li, Aiwei Liu, Yibo Yan, Xuming Hu",,,"watermarking, vision-language models, prefix-tuning, visual fidelity, semantic-aware methods, inference efficiency","Watermarking has emerged as a pivotal solution for content traceability and intellectual property protection in Large Vision-Language Models (LVLMs). However, vision-agnostic watermarks introduce visually irrelevant tokens and disrupt visual grounding by enforcing indiscriminate pseudo-random biases, while some semantic-aware methods incur prohibitive inference latency due to rejection sampling. In this paper, we propose the VIsualSemantic Adaptive Watermark (VISA-Mark), a novel framework that embeds detectable signals while strictly preserving visual fidelity. Our approach employs a lightweight, efficiently trained prefix-tuner to extract dynamic Visual Evidence Weights, which quantify the evidentiary support for candidate tokens based on the visual input. These weights guide an adaptive vocabulary partitioning and logits perturbation mechanism, concentrating watermark strength specifically on visually-supported tokens. By actively aligning the watermark with visual evidence, VISA-Mark effectively maintains visual fidelity. Empirical results confirm that VISA-Mark outperforms conventional methods with a 7.8% improvement in visual consistency (Chair-I) and superior semantic fidelity. The framework maintains highly competitive detection accuracy (96.88% AUC) and robust attack resilience (99.3%) without sacrificing inference efficiency, effectively establishing a new standard for reliability-preserving multimodal watermarking.",18.63,22.272,415,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07292v1_Photometric Redshift Estimation Using Scaled Ensem.pdf,Photometric Redshift Estimation Using Scaled Ensemble Learning,"Swagata Biswas, Shubhrangshu Ghosh, Avyarthana Ghosh, Yogesh Wadadekar, Abhishek Roy Choudhury, Arijit Mukherjee, Shailesh Deshpande, Arpan Pal",,,"Galaxies, High-redshift galaxies, Redshift surveys, Neural networks","The study introduces a new ensemble-based machine learning framework for predicting photometric redshifts (Pz) for faint galaxies and higher redshift ranges using optical photometric data. The framework integrates multiple learning algorithms within a scaled ensemble structure, demonstrating improved predictive performance and accuracy up to z ∼ 4. The model is validated using data from the Hyper Suprime-Cam Strategic Survey Program and meets or exceeds benchmarks specified in the LSST Science Requirements Document. Evaluation metrics include catastrophic outlier, bias, and rms.",16.6,15.063,250,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07296v1_LRAS Advanced Legal Reasoning with Agentic Search.pdf,LRAS: Advanced Legal Reasoning with Agentic Search,"Yujin Zhou, Chuxue Cao, Jinluan Yang, Lijun Wu, Conghui He, Sirui Han, Yike Guo",,,"Legal Reasoning, Agentic Search, Large Reasoning Models, Introspective Imitation Learning, Reinforcement Learning, Legal Logic, Procedural Rigor","While Large Reasoning Models (LRMs) have demonstrated exceptional logical capabilities in mathematical domains, their application to the legal field remains hindered by the strict requirements for procedural rigor and adherence to legal logic. Existing legal LLMs, which rely on 'closed-loop reasoning' derived solely from internal parametric knowledge, frequently suffer from a lack of self-awareness regarding their knowledge boundaries, leading to confident yet incorrect conclusions. To address this challenge, we present Legal Reasoning with Agentic Search (LRAS), the first framework designed to transition legal LLMs from static and parametric 'closed-loop thinking' to dynamic and interactive 'Active Inquiry'. By integrating Introspective Imitation Learning and Difficulty-aware Reinforcement Learning, LRAS enables LRMs to identify knowledge boundaries and handle legal reasoning complexity. Empirical results demonstrate that LRAS outperforms state-of-the-art baselines by 8.2-32%, with the most substantial gains observed in tasks requiring deep reasoning with reliable knowledge. We will release our data and models for further exploration soon.",18.27,19.707,360,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07304v1_Heterogeneous Multi-Expert Reinforcement Learning .pdf,Heterogeneous Multi-Expert Reinforcement Learning for Long-Horizon Multi-Goal Tasks in Autonomous Forklifts,"Yun Chen, Bowei Huang, Fan Guo, Kang Song",,,"Autonomous Forklift, Hierarchical Reinforcement Learning, Mobile Manipulation, Hybrid Training, Modality Decoupling","Autonomous mobile manipulation in unstructured warehouses requires balancing efficient large-scale navigation and high-precision object interaction. Traditional end-to-end learning approaches often struggle with these conflicting demands. This paper proposes a Heterogeneous Multi-Expert Reinforcement Learning (HMER) framework for autonomous forklifts, decomposing long-horizon tasks into specialized sub-policies controlled by a Semantic Task Planner. This structure separates macro-level navigation from micro-level manipulation, allowing each expert to focus on its specific action space without interference. The planner coordinates the sequential execution of these experts, bridging the gap between task planning and continuous control. A Hybrid Imitation-Reinforcement Training Strategy is introduced to address sparse exploration, using expert demonstrations to initialize the policy and Reinforcement Learning for fine-tuning. Experiments in Gazebo simulations show that HMER significantly outperforms sequential and end-to-end baselines, achieving a task success rate of 94.2%, reducing operation time by 21.4%, and maintaining placement error within 1.5 cm.",17.72,17.441,309,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07309v1_ARM Role-Conditioned Neuron Transplantation for Tr.pdf,ARM: Role-Conditioned Neuron Transplantation for Training-Free Generalist LLM Agent Merging,"Zhuoka Feng, Kang Chen, Sihan Zhao, Kai Xiong, Yaoning Wang, Minshen Yu, Junjie Nian, Changyi Xiao, Yixin Cao, Yugang Jiang",,arXiv:2601.07309v1,"large language models, model merging, neuron transplantation, generalization, interactive environments","Interactive large language model agents have advanced rapidly, but most remain specialized to a single environment and fail to adapt robustly to other environments. Model merging offers a training-free alternative by integrating multiple experts into a single model. In this paper, we propose Agent-Role Merging (ARM), an activation-guided, role-conditioned neuron transplantation method for model merging in LLM agents. ARM improves existing merging methods from static natural language tasks to multi-turn agent scenarios, and over the generalization ability across various interactive environments. This is achieved with a well-designed 3-step framework: 1) constructing merged backbones, 2) selection based on its role-conditioned activation analysis, and 3) neuron transplantation for fine-grained refinements. Without gradient-based optimization, ARM improves cross-benchmark generalization while enjoying efficiency. Across diverse domains, the model obtained via ARM merging outperforms prior model merging methods and domain-specific expert models, while demonstrating strong out-of-domain generalization.",19.51,18.653,364,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07313v1_Explaining Machine Learning Predictive Models thro.pdf,Explaining Machine Learning Predictive Models through Conditional Expectation Methods,"Silvia Ruiz-España, Laura Arnal, François Signol, Juan-Carlos Pérez-Cortes, Joaquim Arlandis",,,"machine learning, XAI, explainable models, local explainability, model-agnostic, uncertainty, stability","The rapid adoption of complex AI and ML models has led to their characterization as black boxes due to the difficulty of explaining their internal decision-making processes. This lack of transparency hinders users’ ability to understand, validate, and trust model behavior, particularly in high-risk applications. This work introduces Multivariate Conditional Expectation (MUCE), a model-agnostic method for local explainability designed to capture prediction changes from feature interactions. MUCE extends Individual Conditional Expectation (ICE) by exploring a multivariate grid of values in the neighborhood of a given observation at inference time, providing graphical explanations that illustrate the local evolution of model predictions. In addition, two quantitative indices, stability and uncertainty, summarize local behavior and assess model reliability. Uncertainty is further decomposed into uncertainty + and uncertainty − to capture asymmetric effects that global measures may overlook. The proposed method is validated using XGBoost models trained on three datasets: two synthetic (2D and 3D) to evaluate behavior near decision boundaries, and one transformed real-world dataset to test adaptability to heterogeneous feature types. Results show that MUCE effectively captures complex local model behavior, while the stability and uncertainty indices provide meaningful insight into prediction confidence. MUCE, together with the ICE modification and the proposed indices, offers a practical contribution to local explainability, enabling both graphical and quantitative insights that enhance the interpretability of predictive models and support more trustworthy and transparent decision-making.",19.69,21.129,416,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07315v1_VLM-CAD VLM-Optimized Collaborative Agent Design W.pdf,VLM-CAD: VLM-Optimized Collaborative Agent Design Workflow for Analog Circuit Sizing,"Guanyuan Pan, Yugui Lin, Tiansheng Zhou, Pietro Li, Shuai Wang, Yaqi Wang*",,,"Analog Circuit Sizing, Agentic AI, Vision Language Model, Explainability, Electronic Design Automation","Analog mixed-signal circuit sizing involves complex trade-offs within high-dimensional design spaces. Existing automatic approaches often underutilize circuit schematics and lack the explainability required for industry adoption. This paper proposes a Vision Language Model-optimized collaborative agent design workflow (VLM-CAD), which analyzes circuits, optimizes DC operating points, performs inference-based sizing, and executes external sizing optimization. The integration of Image2Net annotates circuit schematics and generates a structured JSON description for precise interpretation by Vision Language Models. An Explainable Trust Region Bayesian Optimization method (ExTuRBO) is proposed, employing collaborative warm-starting from agent-generated seeds and offering dual-granularity sensitivity analysis for external sizing optimization, supporting a comprehensive final design report. Experiments on amplifier sizing tasks using 180nm, 90nm, and 45nm Predictive Technology Models demonstrate that VLM-CAD effectively balances power and performance, achieving a 100% success rate in optimizing an amplifier with a complementary input and a class-AB output stage, while maintaining total runtime under 43 minutes across all experiments.",18.88,18.648,352,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07316v1_BEAT-Net Injecting Biomimetic Spatio-Temporal Prio.pdf,BEAT-Net: Injecting Biomimetic Spatio-Temporal Priors for Interpretable ECG Classification,"Ma Runze, Liao Caizhi",,2601.07316v1,"ECG classification, deep learning, biomimetic spatio-temporal priors, QRS tokenization, interpretable AI, self-supervised learning","Although deep learning has advanced automated electrocardiogram (ECG) diagnosis, prevalent supervised methods typically treat recordings as undifferentiated one-dimensional (1D) signals or two-dimensional (2D) images. This formulation compels models to learn physiological structures implicitly, resulting in data inefficiency and opacity that diverge from medical reasoning. To address these limitations, we propose BEAT-Net, a Biomimetic ECG Analysis with Tokenization framework that reformulates the problem as a language modeling task. Utilizing a QRS tokenization strategy to transform continuous signals into biologically aligned heartbeat sequences, the architecture explicitly decomposes cardiac physiology through specialized encoders that extract local beat morphology while normalizing spatial lead perspectives and modeling temporal rhythm dependencies. Evaluations across three large-scale benchmarks demonstrate that BEAT-Net matches the diagnostic accuracy of dominant convolutional neural network (CNN) architectures while substantially improving robustness. The framework exhibits exceptional data efficiency, recovering fully supervised performance using only 30 to 35 percent of annotated data. Moreover, learned attention mechanisms provide inherent interpretability by spontaneously reproducing clinical heuristics, such as Lead II prioritization for rhythm analysis, without explicit supervision. These findings indicate that integrating biological priors offers a computationally efficient and interpretable alternative to data-intensive large-scale pre-training.",19.51,19.941,389,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07320v1_Segmental Advantage Estimation Enhancing PPO for L.pdf,Segmental Advantage Estimation: Enhancing PPO for Long-Context LLM,"Xue Gong, Qi Yi, Ziyuan Nan, Guanhua Huang, Kejiao Li, Yuhao Jiang, Ruibin Xiong, Zenan Xu, Jiaming Guo, Shaohui Peng, Bo Zhou",,,"Large Language Models, Reinforcement Learning, Verifiable Rewards, Proximal Policy Optimization, Advantage Estimation, Sparse Rewards, Generalized Advantage Estimation, Segmental Advantage Estimation","Training Large Language Models (LLMs) for reasoning tasks is increasingly driven by Reinforcement Learning with Verifiable Rewards (RLVR), where Proximal Policy Optimization (PPO) provides a principled framework for stable policy updates. However, the practical application of PPO is hindered by unreliable advantage estimation in the sparse-reward RLVR regime. This issue arises because the sparse rewards in RLVR lead to inaccurate intermediate value predictions, which in turn introduce significant bias when aggregated at every token by Generalized Advantage Estimation (GAE). To address this, we introduce Segmental Advantage Estimation (SAE), which mitigates the bias that GAE can incur in RLVR. Our key insight is that aggregating n-step advantages at every token (as in GAE) is unnecessary and often introduces excessive bias, since individual tokens carry minimal information. Instead, SAE first partitions the generated sequence into coherent sub-segments using low-probability tokens as heuristic boundaries. It then selectively computes variance-reduced advantage estimates only from these information-rich segment transitions, effectively filtering out noise from intermediate tokens. Our experiments demonstrate that SAE achieves superior performance, with marked improvements in final scores, training stability, and sample efficiency. These gains are shown to be consistent across multiple model sizes, and a correlation analysis confirms that our proposed advantage estimator achieves a higher correlation with an approximate ground-truth advantage, justifying its superior performance.",19.72,23.734,468,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07342v1_Agentic Diagnostic Reasoning over Telecom and Data.pdf,Agentic Diagnostic Reasoning over Telecom and Datacenter Infrastructure: Foundation for Autonomous Incident Resolution and Change Impact Mitigation,Nicolas Tacheny,,2601.07342v1,"telecom, datacenter, root cause analysis, impact analysis, large language model, diagnostic reasoning, incident resolution, change impact mitigation","Large-scale telecom and datacenter infrastructures rely on multi-layered service and resource models, where failures propagate across physical and logical components and affect multiple customers. Traditional approaches to root cause analysis (RCA) rely on hard-coded graph traversal algorithms or rule-based correlation engines, which are costly to maintain and tightly coupled to the infrastructure model. This work introduces an agentic diagnostic framework where a Large Language Model (LLM) performs step-wise investigation using a constrained tool-space exposed through the Model Context Protocol (MCP). Instead of embedding causal logic or traversal algorithms into the application, the agent autonomously navigates the infrastructure model by invoking tools for service lookup, dependency retrieval, structured and unstructured data, and event analysis, and impact discovery. This lays the foundation for autonomous incident resolution and change impact mitigation, enabling future systems to diagnose and remediate infrastructure failures and predict the impact of planned changes on services and customers.",19.0,15.998,304,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07344v1_PulseMind A Multi-Modal Medical Model for Real-Wor.pdf,PulseMind: A Multi-Modal Medical Model for Real-World Clinical Diagnosis,"Jiao Xu, Junwei Liu, Jiangwei Lao, Qi Zhu, Yunpeng Zhao, Congyun Jin, Shinan Liu, Zhihong Lu, Lihe Zhang, Xin Chen, Jian Wang, Ping Wang",,,"multi-modal models, clinical diagnosis, medical images, diagnostic dataset, evaluation benchmark, training framework, Comparison-based Reinforcement Policy Optimization (CRPO)","Recent advances in medical multi-modal models focus on specialized image analysis like dermatology, pathology, or radiology. However, they do not fully capture the complexity of real-world clinical diagnostics, which involve heterogeneous inputs and require ongoing contextual understanding during patient-physician interactions. To bridge this gap, we introduce PulseMind, a new family of multi-modal diagnostic models that integrates a systematically curated dataset, a comprehensive evaluation benchmark, and a tailored training framework. Specifically, we first construct a diagnostic dataset, MediScope, which comprises 98,000 real-world multi-turn consultations and 601,500 medical images, spanning over 10 major clinical departments and more than 200 sub-specialties. Then, to better reflect the requirements of real-world clinical diagnosis, we develop the PulseMind Benchmark, a multi-turn diagnostic consultation benchmark with a four-dimensional evaluation protocol comprising proactiveness, accuracy, usefulness, and language quality. Finally, we design a training framework tailored for multi-modal clinical diagnostics, centered around a core component named Comparison-based Reinforcement Policy Optimization (CRPO). Compared to absolute score rewards, CRPO uses relative preference signals from multi-dimensional comparisons to provide stable and human-aligned training guidance. Extensive experiments demonstrate that PulseMind achieves competitive performance on both the diagnostic consultation benchmark and public medical benchmarks.",19.12,22.548,431,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07348v4_Controlled Self-Evolution for Algorithmic Code Opt.pdf,Controlled Self-Evolution for Algorithmic Code Optimization,"Tu Hu, Ronghao Chen, Shuo Zhang, Jianghao Yin, Mou Xiao Feng, Jingping Liu, Shaolei Zhang, Wenqi Jiang, Yuqi Fang, Sen Hu, Huacan Wang, Yi Xu",,arXiv:2601.07348v4,"self-evolution, code optimization, algorithmic strategies, genetic evolution, hierarchical memory, exploration efficiency","Self-evolution methods enhance code generation through iterative 'generate-verify-refine' cycles, yet existing approaches suffer from low exploration efficiency, failing to discover solutions with superior complexity within limited budgets. This inefficiency stems from initialization bias trapping evolution in poor solution regions, uncontrolled stochastic operations lacking feedback guidance, and insufficient experience utilization across tasks. To address these bottlenecks, we propose Controlled Self-Evolution (CSE), which consists of three key components: Diversified Planning Initialization, Genetic Evolution, and Hierarchical Evolution Memory. Experiments on EffiBench-X demonstrate that CSE consistently outperforms all baselines across various LLM backbones, achieving higher efficiency from early generations and maintaining continuous improvement throughout evolution.",19.27,16.609,320,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07351v2_Beyond Hard Masks Progressive Token Evolution for .pdf,Beyond Hard Masks: Progressive Token Evolution for Diffusion Language Models,"Linhao Zhong, Linyu Wu, Bozhen Fang, Tianjian Feng, Chenchen Jing, Wen Wang, Jiaheng Zhang, Hao Chen, Chunhua Shen",,,"Diffusion Language Models, EvoToken-DLM, masked diffusion, probabilistic representations, iterative refinement, parallel decoding","Diffusion Language Models (DLMs) enable parallel decoding through iterative refinement, contrasting with autoregressive models. Most DLMs use hard binary masking and discrete token assignments, limiting early decision revisions and underutilizing intermediate probabilistic representations. This paper introduces EvoToken-DLM, which replaces hard binary masks with evolving soft token distributions, allowing a progressive transition from masked states to discrete outputs and supporting revisable decoding. Continuous trajectory supervision aligns training objectives with iterative probabilistic updates. Experiments show EvoToken-DLM outperforms diffusion-based and masked DLM baselines.",15.8,16.894,267,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07356v1_Efficient Convolutional Forward Model for Passive .pdf,Efficient Convolutional Forward Model for Passive Acoustic Mapping and Temporal Monitoring,"Tatiana Gelvez-Barrera, Barbara Nicolas, Bruno Gilles, Adrian Basarab, Denis Kouam ´e",,,"Passive Acoustic Mapping, Model-based beamforming, Convolutional forward model, Temporal monitoring","Passive acoustic mapping (PAM) is a key imaging technique for characterizing cavitation activity in therapeutic ultrasound applications. Recent model-based beamforming algorithms offer high reconstruction quality and strong physical interpretability. However, their computational burden and limited temporal resolution restrict their use in applications with time-evolving cavitation. To address these challenges, we introduce a PAM beamforming framework based on a novel convolutional formulation in the time domain, which enables efficient computation. In this framework, PAM is formulated as an inverse problem in which the forward operator maps spatiotemporal cavitation activity to recorded radio-frequency signals accounting for time-of-flight delays defined by the acquisition geometry. We then formulate a regularized inversion algorithm that incorporates prior knowledge on cavitation activity. Experimental results demonstrate that our framework outperforms classical beamforming methods, providing higher temporal resolution than frequency-domain techniques while substantially reducing computational burden compared with iterative time-domain formulations.",17.37,17.729,308,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07359v1_Seeing Right but Saying Wrong Inter- and Intra-Lay.pdf,Seeing Right but Saying Wrong: Inter- and Intra-Layer Refinement in MLLMs without Training,"Shezheng Song, Shasha Li, Jie Yu",,,"Multimodal Large Language Models, MLLMs, vision-language tasks, attention, DualPD, decoding refinement, accuracy, generalizability","Multimodal Large Language Models (MLLMs) show strong capabilities in vision-language tasks but often exhibit a critical inconsistency: deeper layers may focus on correct visual regions, yet final predictions are misled by noisy attention from earlier layers. This results in a disconnect between the model's internal understanding and its output, described as 'seeing it right but saying it wrong.' To address this, the authors propose DualPD, a dual-perspective decoding refinement strategy that enhances visual understanding without additional training. DualPD includes a layer-wise attention-guided contrastive logits module and a head-wise information filtering module. Experiments on LLaVA and Qwen-VL models across multiple benchmarks show that DualPD consistently improves accuracy without training, confirming its effectiveness and generalizability.",17.17,15.082,259,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07364v1_On the universal definition of intelligence.pdf,On the universal definition of intelligence: A definition for Human - AI Comparison,Joseph Chen,,,"intelligence, AI, human comparison, R. Carnap, conceptual clarification, predictive ability, Extended Predictive Hypothesis (EPH)","This paper proposes a universal definition of intelligence to enable fair and consistent comparison between human and artificial intelligence (AI). It introduces four criteria for evaluating intelligence definitions based on R. Carnap's methodology: similarity to explicandum, exactness, fruitfulness, and simplicity. The paper examines six representative definitions, including IQ testing, complex problem-solving ability, reward optimization, environmental adaptation, learning efficiency, and predictive ability, highlighting their strengths and limitations. The paper proposes the Extended Predictive Hypothesis (EPH), which combines the ability to predict the future accurately and benefit from those predictions, offering a unified framework for explaining various aspects of intelligence such as creativity, learning, and future planning. The EPH is argued to be the most satisfactory and universal definition for comparing human and AI intelligence.",18.72,12.765,239,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07372v1_Conditional Memory via Scalable Lookup A New Axis .pdf,Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models,"Xin Cheng, Wangding Zeng, Damai Dai, Qinyu Chen, Bingxuan Wang, Zhenda Xie, Kezhao Huang, Xingkai Yu, Zhewen Hao, Yukun Li, Han Zhang, Huishuai Zhang, Dongyan Zhao, Wenfeng Liang",,2601.07372v1,"Mixture-of-Experts, Transformers, knowledge lookup, conditional memory, Engram, N-gram embedding, Sparsity Allocation, scaling law, neural computation, static memory, knowledge retrieval, general reasoning, code/math domains, mechanistic analyses, long-context retrieval, runtime prefetching, sparse models","The paper introduces conditional memory as a new sparsity axis for large language models, addressing the lack of native primitives for knowledge lookup in Transformers. The proposed Engram module modernizes classic N-gram embedding for efficient O(1) lookup. By solving the Sparsity Allocation problem, a U-shaped scaling law is discovered, optimizing the trade-off between neural computation and static memory. Scaling Engram to 27B parameters results in superior performance over MoE baselines, with significant gains in knowledge retrieval, general reasoning, and code/math domains. Engram also enhances long-context retrieval and establishes infrastructure-aware efficiency through deterministic addressing and runtime prefetching. The paper envisions conditional memory as a crucial modeling primitive for future sparse models.",19.29,20.949,404,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07376v1_OpenTinker Separating Concerns in Agentic Reinforc.pdf,OpenTinker: Separating Concerns in Agentic Reinforcement Learning,"Siqi Zhu, Jiaxuan You",,arXiv:2601.07376v1,"Reinforcement Learning, Large Language Models, OpenTinker, Agent-Environment Interaction, Decomposition, Scalability, Systems Challenges","We introduce OpenTinker, an infrastructure for reinforcement learning (RL) of large language model (LLM) agents built around a separation of concerns across algorithm design, execution, and agent–environment interaction. Rather than relying on monolithic, end-to-end RL pipelines, OpenTinker decomposes agentic learning systems into lightweight, composable components with clearly defined abstraction boundaries. Users specify agents, environments, and interaction protocols, while inference and training are delegated to a managed execution runtime. OpenTinker introduces a centralized scheduler for managing training and inference workloads, including LoRA-based and full-parameter RL, supervised fine-tuning, and inference, over shared resources. We further discuss design principles for extending OpenTinker to multi-agent training. Finally, we present a set of RL use cases that demonstrate the effectiveness of the framework in practical agentic learning scenarios.",17.84,15.636,279,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07377v1_Learning Dynamic Collaborative Network for Semi-su.pdf,Learning Dynamic Collaborative Network for Semi-supervised 3D Vessel Segmentation,"Jiao Xu, Xin Chen, Lihe Zhang",,,"3D vessel segmentation, semi-supervised learning, dynamic collaborative network, mean teacher, multi-view integration, adversarial supervision","This paper introduces a dynamic collaborative network, DiCo, for semi-supervised 3D vessel segmentation. Unlike conventional mean teacher methods that use a static approach, DiCo allows dynamic switching of teacher-student roles to address cognitive biases and improve performance. The method incorporates a multi-view integration module and adversarial supervision to enhance segmentation accuracy. Experiments show that DiCo achieves state-of-the-art performance on three 3D vessel segmentation benchmarks.",15.25,13.051,199,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07389v1_On the Non-decoupling of Supervised Fine-tuning an.pdf,On the Non-decoupling of Supervised Fine-tuning and Reinforcement Learning in Post-training,"Xueyan Niu, Bo Bai, Wei Han, Wei Xi Zhang",,arXiv:2601.07389v1,"Supervised Fine-tuning, Reinforcement Learning, Post-training, Large Language Models, Decoupling, Cross-entropy loss, Reward signals, Human preferences, Rule-based verifiers, Reasoning models","Post-training of large language models often involves interleaving supervised fine-tuning (SFT) and reinforcement learning (RL). SFT minimizes the cross-entropy loss between model outputs and expert responses, while RL maximizes reward signals derived from human preferences or rule-based verifiers. This study proves that decoupling SFT and RL is impossible in either order: RL increases SFT loss under SFT optimality, and SFT lowers the reward achieved by RL. Experiments on Qwen3-0.6B confirm the predicted degradation, verifying that SFT and RL cannot be separated without loss of prior performance in the post-training pipeline.",17.99,15.896,286,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07392v1_OceanSAR-2 A Universal Feature Extractor for SAR O.pdf,OceanSAR-2: A Universal Feature Extractor for SAR Ocean Observation,"Alexandre Tuela, Thomas Kerdreux, Quentin Febvre, Alexis Mouche, Antoine Grouazel, Jean-Renaud Miadana, Antoine Audras, Chen Wang, Bertrand Chapron",,,"SAR, ocean observation, self-supervised learning, Sentinel-1 Wave Mode, feature extraction, geophysical pattern classification, ocean surface wind vector, significant wave height estimation, iceberg detection","We present OceanSAR-2, the second generation of our foundation model for SAR-based ocean observation. Building on our earlier release, which pioneered self-supervised learning on Sentinel-1 Wave Mode data, OceanSAR-2 relies on improved SSL training and dynamic data curation strategies, which enhances performance while reducing training cost. OceanSAR-2 demonstrates strong transfer performance across downstream tasks, including geophysical pattern classification, ocean surface wind vector and significant wave height estimation, and iceberg detection. We release standardized benchmark datasets, providing a foundation for systematic evaluation and advancement of SAR models for ocean applications.",17.54,17.159,301,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07393v1_Software-Hardware Co-optimization for Modular E2E .pdf,"A Unified Framework of Optimization Approaches, Simulation Environment and Evaluation Metrics for Modular End-to-End Autonomous Driving","Chengzhi Ji, Xingfeng Li, Zhaodong Lv, Hao Sun, Pan Liu, Hao Frank Yang, Ziyuan Pu",,2601.07393v1,"Modular end-to-end, Closed-Loop Evaluation, Software–Hardware co-optimization, Energy Consumption","Modular end-to-end (ME2E) autonomous driving paradigms combine interpretability with global optimization capability and have achieved state-of-the-art performance. However, extant research has primarily emphasized improvements in accuracy metrics, while neglecting to address critical system-level considerations such as energy consumption and inference latency. Consequently, model designs have evolved to become increasingly intricate. To improve deployability, previous studies have investigated model compression and acceleration, yet these approaches are often pursued independently on either the software or hardware side. Software-only optimization cannot fundamentally eliminate intermediate tensor access and operator scheduling overheads. Hardware-only optimization is constrained by model structure and bit-width. Consequently, the benefits of such optimizations are often substantially diminished in real-world deployment. To address these limitations, this paper proposes a reusable software–hardware co-optimization and closed-loop evaluation framework for ME2E autonomous driving inference. The framework integrates software-level model optimizations with hardware-level computation optimizations under a unified system-level objective. Furthermore, a multidimensional evaluation metric, EERA V, is introduced. This metric evaluates the ME2E autonomous driving system performance by jointly considering safety, comfort, efficiency, latency, and energy, enabling quantitative assessment of the true system-level impact of different optimization strategies. The proposed framework is evaluated across multiple ME2E autonomous driving stacks. It preserves baseline-level accuracy while reducing inference latency by over 6× and per-frame energy to around one-fifth of the baseline. Furthermore, a 22.35% improvement in the EERA V metric is achieved. These results validate that the proposed framework provides actionable optimization guidance from both software and hardware perspectives.",20.39,23.101,471,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07395v1_MCP-ITP An Automated Framework for Implicit Tool P.pdf,MCP-ITP: An Automated Framework for Implicit Tool Poisoning in MCP,"Ruiqi Li, Zhiqiang Wang, Yunhao Yao, Xiang-Yang Li",,,"Model Context Protocol, LLM-based agents, tool poisoning, implicit tool poisoning, security, attack surface, malicious instructions, attack success rate, malicious tool detection rate","The paper introduces MCP-ITP, an automated framework for implicit tool poisoning within the Model Context Protocol (MCP) ecosystem. Unlike explicit tool poisoning, which involves direct invocation of poisoned tools, implicit tool poisoning embeds malicious instructions in tool metadata, causing agents to invoke legitimate but high-privilege tools for malicious operations. MCP-ITP formulates poisoned tool generation as a black-box optimization problem, using feedback from evaluation and detection language models to maximize attack success rate while evading detection. Experimental results show that MCP-ITP outperforms manually crafted baselines, achieving high attack success rates with low detection rates.",16.61,15.893,264,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07397v1_Layerwise goal-oriented adaptivity for neural ODEs.pdf,Layerwise goal-oriented adaptivity for neural ODEs: an optimal control perspective,"Michael Hintermüller, Michael Hinze, Denis Korolev",,2601.07397v1,"Resnet, neural ODEs, parameter identification/learning, adaptive neural network","This work proposes a novel layerwise adaptive construction method for neural network architectures based on a goal-oriented dual-weighted residual technique for the optimal control of neural differential equations. This approach leads to an ordinary differential equation constrained optimization problem with controls acting as coefficients and a specific loss function. The method is implemented using a DG(0) Galerkin discretization of the neural ODE, resulting in an explicit Euler time marching scheme. Optimization is performed using steepest descent. The method is applied to construct neural networks for classifying datasets, with results presented for well-known examples from the literature.",16.7,13.776,230,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07411v1_SCALPEL Selective Capability Ablation via Low-rank.pdf,SCALPEL: Selective Capability Ablation via Low-rank Parameter Editing for Large Language Model Interpretability Analysis,"Zihao Fu, Xufeng Duan, Zhenguang G. Cai",,,"large language models, interpretability, capability ablation, low-rank parameter editing, LoRA adapters","Large language models have achieved remarkable success across diverse domains, yet their deployment in many applications such as healthcare, legal systems, and autonomous decision-making remains limited by our incomplete understanding of their internal mechanisms. Traditional approaches identify important modules through gradient attribution or activation analysis, assuming that specific capabilities are controlled by specific components. However, this assumption oversimplifies neural computation: individual modules may contribute to multiple capabilities simultaneously, and conversely, a single capability may be implemented in a distributed manner across multiple modules. SCALPEL (Selective Capability Ablation via Low-rank Parameter Editing for Large Language Models) represents capabilities as low-rank parameter subspaces rather than discrete modules. By training LoRA adapters to reduce the model’s ability to distinguish correct from incorrect answers while preserving general language modeling quality, SCALPEL identifies the low-rank representation responsible for a particular capability while remaining disentangled from other capabilities. Experiments demonstrate that SCALPEL successfully removes target capabilities while preserving other general capabilities, providing fine-grained insights into how capabilities are distributed across the model’s parameter space. The results reveal that capabilities exhibit low-rank structure and can be selectively ablated through targeted parameter-space interventions, offering a more nuanced understanding of capability encoding in large language models.",19.25,18.127,349,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07422v1_Two Pathways to Truthfulness On the Intrinsic Enco.pdf,Two Pathways to Truthfulness: On the Intrinsic Encoding of LLM Hallucinations,"Wen Luo, Guangyue Peng, Wei Li, Shaohang Wei, Feifan Song, Liang Wang, Nan Yang, Xingxing Zhang, Jing Jin, Furu Wei, Houfeng Wang",,,"LLMs, hallucinations, truthfulness, Question-Anchored pathway, Answer-Anchored pathway, attention knockout, token patching, knowledge boundaries, hallucination detection","Despite their impressive capabilities, large language models (LLMs) frequently generate hallucinations. This paper demonstrates that truthfulness cues in LLMs arise from two distinct information pathways: a Question-Anchored pathway dependent on question-answer information flow, and an Answer-Anchored pathway deriving self-contained evidence from the generated answer itself. The study validates these pathways through attention knockout and token patching, revealing their association with LLM knowledge boundaries and internal representation awareness. The findings propose applications to enhance hallucination detection performance, offering new insights into how LLMs encode truthfulness.",16.94,17.594,298,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07430v1_KALE Enhancing Knowledge Manipulation in Large Lan.pdf,KALE: Enhancing Knowledge Manipulation in Large Language Models via Knowledge-aware Learning,"Qitan Lv, Tianyu Liu, Qiaosheng Zhang, Xingcheng Xu, Chaochao Lu",,,"large language models, knowledge manipulation, supervised fine-tuning, knowledge graphs, multi-hop reasoning, rationale-guided reasoning, KL divergence","Despite the impressive performance of large language models (LLMs) pretrained on vast knowledge corpora, advancing their knowledge manipulation—the ability to effectively recall, reason, and transfer relevant knowledge—remains challenging. Existing methods mainly leverage Supervised Fine-Tuning (SFT) on labeled datasets to enhance LLMs’ knowledge manipulation ability. However, SFT models still exhibit the known&incorrect phenomenon, where they explicitly possess relevant knowledge for a given question but fail to leverage it for correct answers. To address this challenge, we propose KALE (Knowledge-Aware Learning)—a post-training framework that leverages knowledge graphs (KGs) to generate high-quality rationales and enhance LLMs’ knowledge manipulation ability. Specifically, KALE introduces a Knowledge-Induced (KI) data synthesis method that efficiently extracts multi-hop reasoning paths from KGs to generate high-quality rationales for question-answer pairs. Then, KALE employs a Knowledge-Aware (KA) fine-tuning paradigm that enhances knowledge manipulation by internalizing rationale-guided reasoning through minimizing the KL divergence between predictions with and without rationales. Extensive experiments on eight popular benchmarks across six different LLMs demonstrate the effectiveness of KALE, achieving accuracy improvements of up to 11.72% and an average of 4.18%.",18.55,21.243,394,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07449v1_RLPO Residual Listwise Preference Optimization for.pdf,RLPO: Residual Listwise Preference Optimization for Long-Context Review Ranking,"Hao Jiang, Zhi Yang, Annan Wang, Yichi Zhang, Weisi Lin*",,,"review ranking, e-commerce, large language models, listwise optimization, pointwise scoring, NDCG@k, long-context","Review ranking is pivotal in e-commerce for prioritizing diagnostic and authentic feedback from the deluge of user-generated content. While large language models have improved semantic assessment, existing ranking paradigms face a persistent trade-off in long-context settings. Pointwise scoring is efficient but often fails to account for list-level interactions, leading to miscalibrated top-k rankings. Listwise approaches can leverage global context, yet they are computationally expensive and become unstable as candidate lists grow. To address this, we propose Residual Listwise Preference Optimization (RLPO), which formulates ranking as listwise representation-level residual correction over a strong pointwise LLM scorer. RLPO first produces calibrated pointwise scores and item representations, then applies a lightweight encoder over the representations to predict listwise score residuals, avoiding full token-level listwise processing. We also introduce a large-scale benchmark for long-context review ranking with human verification. Experiments show RLPO improves NDCG@k over strong pointwise and listwise baselines and remains robust as list length increases.",17.61,17.545,309,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07463v1_Puzzle it Out Local-to-Global World Model for Offl.pdf,Puzzle it Out: Local-to-Global World Model for Offline Multi-Agent Reinforcement Learning,"Sijia Li, Xinran Li, Shibo Chen, Jun Zhang",,,"Offline multi-agent reinforcement learning, Multi-agent model-based reinforcement learning","Offline multi-agent reinforcement learning (MARL) aims to solve cooperative decision-making problems in multi-agent systems using pre-collected datasets. Existing offline MARL methods primarily constrain training within the dataset distribution, resulting in overly conservative policies that struggle to generalize beyond the support of the data. While model-based approaches offer a promising solution by expanding the original dataset with synthetic data generated from a learned world model, the high dimensionality, non-stationarity, and complexity of multi-agent systems make it challenging to accurately estimate the transitions and reward functions in offline MARL. Given the difficulty of directly modeling joint dynamics, we propose a local-to-global (LOGO) world model, a novel framework that leverages local predictions—which are easier to estimate—to infer global state dynamics, thus improving prediction accuracy while implicitly capturing agent-wise dependencies. Using the trained world model, we generate synthetic data to augment the original dataset, expanding the effective state-action space. To ensure reliable policy learning, we further introduce an uncertainty-aware sampling mechanism that adaptively weights synthetic data by prediction uncertainty, reducing approximation error propagation to policies. In contrast to conventional ensemble-based methods, our approach requires only an additional encoder for uncertainty estimation, significantly reducing computational overhead while maintaining accuracy. Extensive experiments across 8 scenarios against 8 baselines demonstrate that our method surpasses state-of-the-art baselines on standard offline MARL benchmarks, establishing a new model-based baseline for generalizable offline multi-agent learning.",18.77,20.614,387,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07464v1_IFDNS An Iterative Feedback-Driven Neuro-Symbolic .pdf,IFDNS: An Iterative Feedback-Driven Neuro-Symbolic Method for Faithful Logical Reasoning,"Xiaoheng Wang, Tongxuan Liu, Zi Gong, Xianzhe Dong, Yuting Zeng, Minhan Hu, Weizhe Huang, Jing Li",,,"Logical Reasoning, Large Language Model, Reasoning","Large language models (LLMs) have demonstrated impressive capabilities across a wide range of reasoning tasks, including logical and mathematical problem-solving. While prompt-based methods like Chain-of-Thought (CoT) can enhance LLM reasoning abilities to some extent, they often suffer from a lack of faithfulness, where the derived conclusions may not align with the generated reasoning chain. To address this issue, researchers have explored neuro-symbolic approaches to bolster LLM logical reasoning capabilities. However, existing neuro-symbolic methods still face challenges with information loss during the process. To overcome these limitations, we introduce Iterative Feedback-Driven Neuro-Symbolic (IFDNS), a novel prompt-based method that employs a multi-round feedback mechanism to address LLM limitations in handling complex logical relationships. IFDNS utilizes iterative feedback during the logic extraction phase to accurately extract causal relationship statements and translate them into propositional and logical implication expressions, effectively mitigating information loss issues. Furthermore, IFDNS is orthogonal to existing prompt methods, allowing for seamless integration with various prompting approaches. Empirical evaluations across six datasets demonstrate the effectiveness of IFDNS in significantly improving the performance of CoT and Chain-of-Thought with Self-Consistency (CoT-SC). Specifically, IFDNS achieves a +9.40% accuracy boost for CoT on the LogiQA dataset and a +11.70% improvement for CoT-SC on the PrOntoQA dataset.",18.83,22.148,417,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07468v1_Beyond Dialogue Time Temporal Semantic Memory for .pdf,Beyond Dialogue Time: Temporal Semantic Memory for Personalized LLM Agents,"Miao Su, Yucan Guo, Zhongni Hou, Long Bai, Zixuan Li, Yufei Zhang, Guojun Yin, Wei Lin, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng",,2601.07468v1,"Large Language Model, memory, temporal semantic memory, personalization, dialogue agents","Memory enables Large Language Model (LLM) agents to perceive, store, and use information from past dialogues, which is essential for personalization. Existing methods fail to properly model the temporal dimension of memory in two aspects: temporal inaccuracy and temporal fragmentation. This paper proposes Temporal Semantic Memory (TSM), a framework that models semantic time for point-wise memory and supports the construction and utilization of durative memory. TSM builds a semantic timeline and consolidates temporally continuous and semantically related information into durative memory. Experiments show that TSM outperforms existing methods, achieving up to 12.2% absolute improvement in accuracy.",16.9,17.514,296,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07469v1_Knowledge Distillation for LLM-Based Human Activit.pdf,KNOWLEDGE DISTILLATION FOR LLM-BASED HUMAN ACTIVITY RECOGNITION IN HOMES,"Julien Cumin, Oussama Er-Rahmany, Xi Chen",,2601.07469v1,"Human activity recognition, large language models, knowledge distillation, ambient intelligence, smart homes","Human Activity Recognition (HAR) is crucial for context-aware applications in smart homes and assisted living. Recent studies have demonstrated that Large Language Models (LLMs) can be effectively used for HAR, achieving high performance and addressing key challenges. This paper presents new experimental results on the use of LLMs for HAR using two state-of-the-art datasets. It explores how recognition performance varies with the size of the LLM and investigates the application of knowledge distillation techniques to fine-tune smaller LLMs using HAR reasoning examples generated by larger LLMs. The results show that fine-tuned models can nearly match the performance of the largest LLMs while having 50 times fewer parameters.",16.93,15.359,260,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07470v1_Learning How to Remember A Meta-Cognitive Manageme.pdf,Learning How to Remember: A Meta-Cognitive Management Method for Structured and Transferable Agent Memory,"Sirui Liang, Pengfei Cao, Jian Zhao, Wenhao Teng, Xiangwen Liao, Jun Zhao, Kang Liu",,,"Large language model, memory management, meta-cognitive, memory abstraction, transfer learning, long-horizon decision-making, procedural memory","This paper introduces the Meta-Cognitive Memory Abstraction method (MCMA) for enhancing memory management in large language model (LLM) agents. MCMA treats memory abstraction as a learnable cognitive skill, decoupling task execution from memory management. It employs a learned memory copilot, trained using direct preference optimization, to structure, abstract, and reuse memories. The method organizes memories into a hierarchy of abstraction levels, allowing selective reuse based on task similarity. MCMA demonstrates significant improvements in performance, out-of-distribution generalization, and cross-task transfer in experiments on ALFWorld, ScienceWorld, and BabyAI.",16.86,16.37,276,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07474v1_Task Prototype-Based Knowledge Retrieval for Multi.pdf,Task Prototype-Based Knowledge Retrieval for Multi-Task Learning from Partially Annotated Data,"Youngmin Oh, Hyung-Il Kim, Jung Uk Kim",,,"Multi-task learning, Partially annotated data, Prototype-based knowledge retrieval, Task-specific characteristics, Knowledge retrieval transformer, Association knowledge generating loss","Multi-task learning (MTL) is essential for applications like autonomous driving and robotics, which require handling multiple tasks simultaneously. However, fully annotating data for all tasks is impractical due to high labeling costs. Existing methods for partially labeled MTL often rely on predictions from unlabeled tasks, leading to unreliable task associations and potential negative transfer. This paper proposes a prototype-based knowledge retrieval framework to address these issues. The framework includes task prototype embedding to capture task-specific characteristics and a knowledge retrieval transformer to refine feature representations based on task associations. An association knowledge generating (AKG) loss ensures consistent capture of task-specific characteristics. Extensive experiments demonstrate the framework's effectiveness, showing its potential for robust MTL even with partially annotated data.",16.97,15.442,262,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07475v1_ARCQuant Boosting NVFP4 Quantization with Augmente.pdf,ARCQuant: Boosting NVFP4 Quantization with Augmented Residual Channels for LLMs,"Haoqian Meng, Yilun Luo, Yafei Zhao, Wenyuan Liu, Peng Zhang, Xindian Ma",,,"NVFP4, Post-Training Quantization, LLMs, Augmented Residual Channels, GEMM kernels, hardware constraints, quantization error, NVIDIA Blackwell architecture, Microscaling formats","The emergence of fine-grained numerical formats like NVFP4 offers new opportunities for efficient Large Language Model (LLM) inference. However, adapting existing Post-Training Quantization (PTQ) strategies to these formats is challenging due to issues with block isolation, quantization errors, and hardware constraints. ARCQuant is proposed to address these challenges by maintaining a unified NVFP4 format and augmenting the activation matrix with quantized residual channels. This approach integrates error compensation into the matrix reduction dimension, allowing the use of optimized GEMM kernels with minimal overhead. Theoretical analysis shows that ARCQuant's error bound is comparable to standard 8-bit formats. Experiments on LLaMA and Qwen models demonstrate state-of-the-art accuracy, and deployment on RTX GPUs shows up to 3× speedup over FP16.",17.73,18.39,326,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07477v1_JudgeFlow Agentic Workflow Optimization via Block .pdf,JUDGEFLOW: AGENTICWORKFLOWOPTIMIZATION VIA BLOCK JUDGE,"Zihan Ma, Zhikai Zhao, Chuanbo Hua, Federico Berto, Jinkyoo Park",,,"LLM-based agentic workflows, workflow optimization, evaluation-judge-optimization-update pipeline, block-level diagnostics, mathematical reasoning, code generation","Optimizing LLM-based agentic workflows is challenging due to reliance on coarse evaluation signals, leading to inefficient modifications. JUDGEFLOW introduces an Evaluation-Judge-Optimization-Update pipeline, incorporating reusable logic blocks and a Judge module to assign responsibility scores to problematic blocks. This approach enhances sample efficiency, interpretability, and scalability, outperforming existing methods in mathematical reasoning and code generation benchmarks. The source code is available at https://github.com/ma-zihan/JudgeFlow.",16.13,14.324,231,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07496v1_Graph Inference Towards ICD Coding.pdf,Graph Inference Towards ICD Coding,Xiaoxiao Deng,,,"transfer learning, graph convolutional network, lightweight attention, ICD code prediction, adversarial domain adaptation","Automated ICD coding involves assigning standardized diagnostic codes to clinical narratives. The vast label space and extreme class imbalance continue to challenge precise prediction. To address these issues, LabGraph is introduced—a unified framework that reformulates ICD coding as a graph generation task. By combining adversarial domain adaptation, graph-based reinforcement learning, and perturbation regularization, LabGraph effectively enhances model robustness and generalization. In addition, a label graph discriminator dynamically evaluates each generated code, providing adaptive reward feedback during training. Experiments on benchmark datasets demonstrate that LabGraph consistently outperforms previous approaches on micro-F1, micro-AUC, and P@K.",15.77,13.695,216,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07514v1_Data-Driven Stochastic VRP Integration of Forecast.pdf,Data-Driven Stochastic VRP: Integration of Forecast Duration into Optimization for Utility Workforce Management,Matteo Garbellia,,2601.07514v1,"Stochastic VRP, Machine Learning, XGBoost, Sub-Gaussian Concentration, Multi-Objective Optimization, Evolutionary Algorithms","This paper investigates the integration of machine learning forecasts of intervention durations into a stochastic variant of the Capacitated Vehicle Routing Problem with Time Windows (CVRPTW). It utilizes tree-based gradient boosting (XGBoost) trained on eight years of gas meter maintenance data to produce point predictions and uncertainty estimates, which then drive a multi-objective evolutionary optimization routine. The methodology addresses uncertainty through sub-Gaussian concentration bounds for route-level risk buffers and explicitly accounts for competing operational KPIs through a multi-objective formulation. Empirical analysis of prediction residuals validates the sub-Gaussian assumption underlying the risk model. The results report improvements around 20-25% in operator utilization and completion rates compared with plans computed using default durations. The integration of uncertainty quantification and risk-aware optimization provides a practical framework for handling stochastic service durations in real-world routing applications.",19.85,14.255,283,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07516v1_Controlling Multimodal Conversational Agents with .pdf,Controlling Multimodal Conversational Agents with Coverage-Enhanced Latent Actions,"Yongqi Li, Hao Lang, Tieyun Qian, Yongbin Li",,,"multimodal conversational agents, reinforcement learning, latent action space, vision-language models, cross-modal projector, cycle consistency loss","Vision-language models are increasingly used as multimodal conversational agents (MCAs) for various tasks. Reinforcement learning (RL) has been explored to adapt MCAs to diverse human-AI interaction scenarios, enhancing generalization performance. However, fine-tuning MCAs via RL faces challenges due to the large text token space. This work proposes learning a compact latent action space for RL fine-tuning, using a learning from observation mechanism to construct a codebook for the latent action space. The method leverages both paired image-text data and text-only data, using a cross-modal projector and a novel cycle consistency loss to enhance robustness. The proposed method outperforms baselines on conversation tasks across various RL algorithms.",16.65,15.973,266,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07518v1_Mon3tr Monocular 3D Telepresence with Pre-built Ga.pdf,Mon3tr: Monocular 3D Telepresence with Pre-built Gaussian Avatars as Amortization,"Fangyu Lin, Yingdong Hu, Zhening Liu, Yufan Zhuang, Zehong Lin, Member, IEEE, Jun Zhang, Fellow, IEEE",,,"Monocular 3D telepresence, 3D Gaussian splatting, animatable avatars, real-time neural rendering","Immersive telepresence aims to transform human interaction in AR/VR applications by enabling lifelike full-body holographic representations for enhanced remote collaboration. Existing systems rely on hardware-intensive multi-camera setups and demand high bandwidth for volumetric streaming, limiting their real-time performance on mobile devices. This paper proposes Mon3tr, a novel Monocular 3D telepresence framework that integrates 3D Gaussian splatting (3DGS) based parametric human modeling into telepresence. Mon3tr adopts an amortized computation strategy, dividing the process into a one-time offline multi-view reconstruction phase to build a user-specific avatar and a monocular online inference phase during live telepresence sessions. A single monocular RGB camera captures body motions and facial expressions in real time to drive the 3DGS-based parametric human model, significantly reducing system complexity and cost. The extracted motion and appearance features are transmitted at <0.2 Mbps over WebRTC’s data channel, allowing robust adaptation to network fluctuations. On the receiver side, a lightweight 3DGS attribute deformation network dynamically generates corrective 3DGS attribute adjustments on the pre-built avatar, synthesizing photorealistic motion and appearance at ~60 FPS. Extensive experiments demonstrate state-of-the-art performance, achieving a PSNR of >28 dB for novel poses, an end-to-end latency of ~80 ms, and >1000× bandwidth reduction compared to point-cloud streaming, while supporting real-time operation from monocular inputs across diverse scenarios.",19.57,22.581,442,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07525v1_Thinking Before Constraining A Unified Decoding Fr.pdf,Thinking Before Constraining: A Unified Decoding Framework for Large Language Models,"Ngoc Trinh Hung Nguyen, Alonso Silva, Laith Zumot, Liubov Tupikina, Armen Aghasaryan, Mehwish Alam",,,"Large Language Models, natural generation, structured generation, constrained decoding, structured output, reasoning tasks, classification tasks","This paper introduces a unified decoding framework that combines natural and structured generation for Large Language Models (LLMs). The proposed method, called In-Writing, allows LLMs to reason freely until specific trigger tokens are generated, at which point it switches to structured generation. This approach maintains the expressive power of natural language reasoning while ensuring the reliability of structured outputs. The method is evaluated on various datasets, demonstrating a significant improvement in accuracy over natural generation, with minimal overhead. The code and results are available online.",16.39,14.642,240,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07528v1_From RAG to Agentic RAG for Faithful Islamic Quest.pdf,From RAG to Agentic RAG for Faithful Islamic Question Answering,"Gagan Bhatia, Hamdy Mubarak, Mustafa Jarrar, George Mikros, Fadi Zaraket, Mahmoud Alhirthani, Mutaz Al-Khatib, Logan Cochrane, Kareem Darwish, Rashid Yahiaoui, Firoj Alam",,,"Islamic question answering, LLMs, hallucinations, abstention, benchmark, agentic RAG, Quran grounding, retrieval, multilingual LLMs","The paper discusses the use of Large Language Models (LLMs) for Islamic question answering, highlighting the risks of ungrounded responses in this sensitive domain. It introduces ISLAMIC FAITH QA, a bilingual benchmark for evaluating hallucination and abstention in responses. The authors developed an agentic Quran-grounding framework (agentic RAG) that improves answer correctness and robustness, particularly in Arabic-English contexts. The framework uses structured tool calls for iterative evidence seeking and answer revision, showing significant performance gains over standard RAG. The experimental resources and datasets are made publicly available for community use.",17.88,17.79,318,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07553v1_VirtualEnv A Platform for Embodied AI Research.pdf,VirtualEnv: A Platform for Embodied AI Research,"Kabir Swain, Sijie Han, Ayush Raina, Jin Zhang, Shuang Li, Michael Stopa, Antonio Torralba",,,"Large Language Models, Simulation Platform, Unreal Engine, Embodied AI, Interactive Environments, Agent-Environment Interactions, Procedural Generation, AI and Gaming, Reinforcement Learning, Computer Vision","As large language models (LLMs) continue to improve in reasoning and decision-making, there is a growing need for realistic and interactive environments where their abilities can be rigorously evaluated. We present VirtualEnv, a next-generation simulation platform built on Unreal Engine 5 that enables fine-grained benchmarking of LLMs in embodied and interactive scenarios. VirtualEnv supports rich agent-environment interactions, including object manipulation, navigation, and adaptive multi-agent collaboration, as well as game-inspired mechanics like escape rooms and procedurally generated environments. We provide a user-friendly API built on top of Unreal Engine, allowing researchers to deploy and control LLM-driven agents using natural language instructions. We integrate large-scale LLMs and vision-language models (VLMs), such as GPT-based models, to generate novel environments and structured tasks from multimodal inputs. Our experiments benchmark the performance of several popular LLMs across tasks of increasing complexity, analyzing differences in adaptability, planning, and multi-agent coordination. We also describe our methodology for procedural task generation, task validation, and real-time environment control. VirtualEnv is released as an open-source platform, aiming to advance research at the intersection of AI and gaming, enable standardized evaluation of LLMs in embodied AI settings, and pave the way for future developments in immersive simulations and interactive entertainment.",18.93,22.395,424,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07556v1_Backpropagation-Free Test-Time Adaptation for Ligh.pdf,Backpropagation-Free Test-Time Adaptation for Lightweight EEG-Based Brain-Computer Interfaces,"Siyang Li, Jiayi Ouyang, Zhenyao Cui, Ziwei Wang, Tianwang Jia, Feng Wan, Dongrui Wu",,,"Brain-computer interface, domain adaptation, electroencephalogram, test-time adaptation, transfer learning","Electroencephalogram (EEG)-based brain-computer interfaces (BCIs) face significant deployment challenges due to inter-subject variability, signal non-stationarity, and computational constraints. This paper proposes Backpropagation-Free Transformations (BFT), a test-time adaptation approach for EEG decoding that eliminates issues related to backpropagation, such as computational overhead, privacy risks, and sensitivity to noisy data streams. BFT applies multiple sample-wise transformations to each test trial, generating multiple prediction scores for a single test sample. A learning-to-rank module enhances the weighting of these predictions, enabling robust aggregation for uncertainty suppression during inference. Extensive experiments on five EEG datasets demonstrate the effectiveness, versatility, robustness, and efficiency of BFT, enabling lightweight plug-and-play BCIs on resource-constrained devices.",17.45,17.536,306,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07565v1_A Unified Framework for Emotion Recognition and Se.pdf,A Unified Framework for Emotion Recognition and Sentiment Analysis via Expert-Guided Multimodal Fusion with Large Language Models,"Jiaqi Qiao, Xiujuan Xu, Xinran Li, Yu Liu",,,"emotion recognition, large language models, multimodal sentiment analysis, affective computing, multimodal fusion","This paper presents EGMF, a unified framework for multimodal emotion understanding that integrates text, audio, and visual modalities for both discrete emotion recognition and continuous sentiment analysis. The framework combines expert-guided multimodal fusion with large language models (LLMs), featuring three specialized expert networks: a fine-grained local expert, a semantic correlation expert, and a global context expert. These experts are adaptively integrated through hierarchical dynamic gating for context-aware feature selection. Enhanced multimodal representations are integrated with LLMs via pseudo token injection and prompt-based conditioning, enabling a single generative framework to handle both classification and regression tasks through natural language generation. The approach employs LoRA fine-tuning for computational efficiency. Experiments on bilingual benchmarks (MELD, CHERMA, MOSEI, SIMS-V2) demonstrate consistent improvements over state-of-the-art methods, with superior cross-lingual robustness, revealing universal patterns in multimodal emotional expressions across English and Chinese. The source code will be publicly released.",17.95,16.937,304,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07568v1_d3LLM Ultra-Fast Diffusion LLM using Pseudo-Trajec.pdf,d3LLM: Ultra-Fast dLLM using Pseudo-Trajectory Distillation,"Yu-Yang Qian, Junda Su, Lanxiang Hu, Peiyuan Zhang, Zhijie Deng, Peng Zhao, Hao Zhang",,,"Diffusion large language models, parallel decoding, random-order generation, pseudo-trajectory distillation, entropy-based multi-block decoding, KV-cache refresh mechanism, Accuracy Under Parallelism (AUP)","Diffusion large language models (dLLMs) offer capabilities beyond autoregressive (AR) LLMs, such as parallel decoding and random-order generation. However, they face an accuracy-parallelism trade-off. The proposed d3LLM (Pseudo-Distilled Diffusion Large Language Model) balances accuracy and parallelism by introducing pseudo-trajectory distillation during training and entropy-based multi-block decoding with a KV-cache refresh mechanism during inference. A new metric, Accuracy Under Parallelism (AUP), is introduced to evaluate dLLMs. Experiments show that d3LLM achieves up to 10× speedup over vanilla LLaDA/Dream and 5× speedup over AR models without significant accuracy loss.",17.45,17.539,306,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07573v1_A Model of Artificial Jagged Intelligence.pdf,A Model of Artificial Jagged Intelligence,Joshua S. Gans,,2601.07573v1,"generative AI, adoption, calibration, learning, knowledge density, scaling","Generative AI systems often display highly uneven performance across tasks that appear 'nearby': they can be excellent on one prompt and confidently wrong on another with only small changes in wording or context. This phenomenon is termed Artificial Jagged Intelligence (AJI). The paper develops an economic model of AJI, treating adoption as an information problem where users care about local reliability but typically observe only coarse, global quality signals. The model uses a one-dimensional landscape where truth is a rough Brownian process, and knowledge is scattered points drawn from a Poisson process. The model interpolates optimally, and local error is measured by posterior variance. The paper derives an adoption threshold for a blind user, shows that experienced errors are amplified by the inspection paradox, and interprets scaling laws as denser coverage that improves average quality without eliminating jaggedness. It also studies mastery and calibration, showing that a calibrated user who can condition on local uncertainty enjoys positive expected value even in domains that fail the blind adoption test. Mastery is modeled as learning a reliability map via Gaussian process regression, yielding a learning-rate bound driven by information gain. The paper concludes by studying how scaling interacts with discoverability, exploring when calibrated signals and user mastery accelerate the harvesting of scale improvements and when opacity can make gains from scaling effectively invisible.",20.06,16.453,330,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07577v1_Beyond Entangled Planning Task-Decoupled Planning .pdf,Beyond Entangled Planning: Task-Decoupled Planning for Long-Horizon Agents,"Yunfan Li, Bingbing Xu, Xueyun Tian, Xiucheng Xu, Huawei Shen",,,"large language models, planning, task execution, long-horizon tasks, task decoupling, directed acyclic graph, sub-goals, error propagation, replanning, robustness, efficiency","Recent advances in large language models (LLMs) have enabled agents to autonomously execute complex, long-horizon tasks, yet planning remains a primary bottleneck for reliable task execution. Existing methods typically fall into two paradigms: step-wise planning, which is reactive but often short-sighted; and one-shot planning, which generates a complete plan upfront yet is brittle to execution errors. Both paradigms suffer from entangled contexts, where the agent must reason over a monolithic history spanning multiple sub-tasks, increasing cognitive load and allowing local errors to propagate across otherwise independent decisions. To address this, the authors propose Task-Decoupled Planning (TDP), a training-free framework that replaces entangled reasoning with task decoupling. TDP decomposes tasks into a directed acyclic graph (DAG) of sub-goals via a Supervisor. Using a Planner and Executor with scoped contexts, TDP confines reasoning and replanning to the active sub-task, preventing error propagation and correcting deviations locally without disrupting the workflow. Results on TravelPlanner, ScienceWorld, and HotpotQA show that TDP outperforms strong baselines while reducing token consumption by up to 82%, demonstrating that sub-task decoupling improves both robustness and efficiency for long-horizon agents.",19.26,21.492,414,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07580v1_Large Language Models for Physics Instrument Desig.pdf,Large Language Models for Physics Instrument Design,"Sara Zoccheddu, Shah Rukh Qasim, Patrick Owen, Nicola Serra",,,"large language models, physics instrument design, reinforcement learning, detector configurations, machine learning, optimization, trust region optimizer, meta-planners, closed-loop instrument design","This study explores the application of large language models (LLMs) in physics instrument design, comparing their performance to reinforcement learning (RL). LLMs, using only prompting, propose detector configurations based on task constraints and prior high-scoring designs. These configurations are evaluated using simulators and reward functions similar to those in RL-based optimization. While RL produces stronger final designs, LLMs generate valid, resource-aware, and physically meaningful configurations leveraging broad pretrained knowledge. The study suggests pairing LLMs with a trust region optimizer to create hybrid design workflows, where LLMs propose and structure design hypotheses and RL performs reward-driven optimization. LLMs are identified as suitable meta-planners, capable of designing and orchestrating RL-based optimization studies, defining search strategies, and coordinating multiple components within a unified workflow. This approach points toward automated, closed-loop instrument design, reducing the human effort required to structure and supervise optimization.",18.46,17.014,314,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07582v2_ES-Mem Event Segmentation-Based Memory for Long-Te.pdf,ES-Mem: Event Segmentation-Based Memory for Long-Term Dialogue Agents,"Huhai Zou, Tianhao Sun, Chuanjiang He, Yu Tian, Zhenyang Li, Li Jin, Nayu Liu, Jiang Zhong, Kaiwen Wei",,,"memory mechanisms, dialogue agents, Event Segmentation Theory, semantic coherence, hierarchical memory architecture, dynamic event segmentation, episodic memory, context localization","Memory is critical for dialogue agents to maintain coherence and enable continuous adaptation in long-term interactions. Existing memory mechanisms offer basic storage and retrieval capabilities but are hindered by rigid memory granularity and flat retrieval paradigms. To address these limitations, the ES-Mem framework is proposed, incorporating a dynamic event segmentation module and a hierarchical memory architecture. This framework partitions long-term interactions into semantically coherent events and constructs multi-layered memories, leveraging boundary semantics for precise context localization. Evaluations demonstrate consistent performance gains over baseline methods, and the event segmentation module shows robust applicability on dialogue segmentation datasets.",17.23,16.252,280,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07597v1_Pheromone-Focused Ant Colony Optimization algorith.pdf,Pheromone-Focused Ant Colony Optimization algorithm for path planning,"Yi Liu, Hongda Zhang, Zhongxue Gan, Yuning Chen, Ziqing Zhou, Chunlei Meng, Chun Ouyang",,,"Ant Colony Optimization, path planning, pheromone, convergence, optimization","Ant Colony Optimization (ACO) is a prominent swarm intelligence algorithm extensively applied to path planning. However, traditional ACO methods often exhibit shortcomings, such as blind search behavior and slow convergence within complex environments. To address these challenges, this paper proposes the Pheromone-Focused Ant Colony Optimization (PFACO) algorithm, which introduces three key strategies to enhance the problem-solving ability of the ant colony. First, the initial pheromone distribution is concentrated in more promising regions based on the Euclidean distances of nodes to the start and end points, balancing the trade-off between exploration and exploitation. Second, promising solutions are reinforced during colony iterations to intensify pheromone deposition along high-quality paths, accelerating convergence while maintaining solution diversity. Third, a forward-looking mechanism is implemented to penalize redundant path turns, promoting smoother and more efficient solutions. These strategies collectively produce the focused pheromones to guide the ant colony’s search, which enhances the global optimization capabilities of the PFACO algorithm, significantly improving convergence speed and solution quality across diverse optimization problems. The experimental results demonstrate that PFACO consistently outperforms comparative ACO algorithms in terms of convergence speed and solution quality.",18.58,18.41,342,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07606v1_Proof of Time A Benchmark for Evaluating Scientifi.pdf,Proof of Time: A Benchmark for Evaluating Scientific Idea Judgments,"Bingyang Ye, Shan Chen, Jingxuan Tu, Chen Liu, Zidi Xiong, Samuel Schmidgall, Danielle S. Bitterman",,,"large language models, scientific idea judgments, benchmarking framework, citations, research agendas, peer-review awards, agent-based research, tool use, forecasting, AI for Science","The paper introduces Proof of Time (PoT), a semi-verifiable benchmarking framework that evaluates the quality of models' judgments about scientific ideas by linking these judgments to observable downstream signals such as citations and shifts in research agendas. PoT uses a pre-cutoff snapshot of evidence in an offline sandbox to forecast post-cutoff outcomes, allowing for verifiable evaluation when ground truth arrives. It supports scalable benchmarking without exhaustive expert annotation and analyzes human-model misalignment against signals like peer-review awards. The framework also provides a controlled testbed for agent-based research judgments, comparing tool-using agents to non-agent baselines. Across 30,000+ instances in four benchmark domains, the study finds that higher interaction budgets generally improve agentic performance, while the benefit of tool use is task-dependent. PoT enables scalable evaluation of agents on future-facing scientific idea judgment tasks.",18.08,18.469,334,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07611v1_DIAGPaper Diagnosing Valid and Specific Weaknesses.pdf,DIAGPaper: Diagnosing Valid and Specific Weaknesses in Scientific Papers via Multi-Agent Reasoning,"Zhuoyang Zou, Abolfazl Ansari, Delvin Ce Zhang, Dongwon Lee, Wenpeng Yin",,,"paper weakness identification, multi-agent systems, review criteria, author rebuttals, prioritization, AI-assisted reviewing","This paper introduces DIAGPaper, a novel multi-agent framework designed to identify valid and specific weaknesses in scientific papers. Existing approaches often simulate human roles superficially and assume identified weaknesses are inherently correct, overlooking reviewer bias and the importance of author rebuttals. DIAGPaper addresses these issues through three integrated modules: Customizer, Rebuttal, and Prioritizer. The Customizer module simulates human-defined review criteria, the Rebuttal module engages author agents in structured debates with reviewer agents, and the Prioritizer module assesses the severity of validated weaknesses. Experiments demonstrate that DIAGPaper outperforms existing methods by producing more valid, paper-specific weaknesses in a prioritized manner.",17.36,15.61,271,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07618v1_Neural Architecture for Fast and Reliable Coagulat.pdf,Neural Architecture for Fast and Reliable Coagulation Assessment in Clinical Settings: Leveraging Thromboelastography,"Yulu Wang, Ziqian Zeng, Jianjun Wu, Zhifeng Tang",,,"Thromboelastography, coagulation assessment, medical AI, deep learning, Physiological State Reconstruction, multi-domain learning, temporal signals, data scarcity","This paper addresses the challenge of real-time coagulation monitoring in clinical settings using Thromboelastography (TEG), which traditionally takes nearly an hour to provide outputs. The authors introduce a new algorithm, Physiological State Reconstruction (PSR), designed to make reliable predictions from small datasets and account for variations between patient populations. PSR integrates varied temporal signals using multi-domain learning and learns high-level temporal interactions with attention mechanisms. The algorithm demonstrates superior performance with R2 > 0.98 for coagulation traits and significantly reduces error and inferencing time compared to state-of-the-art methods. The approach suggests potential applications in medical AI beyond thrombophilia discovery, particularly in scenarios with data scarcity.",17.59,16.036,282,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07632v2_GeoMotionGPT Geometry-Aligned Motion Understanding.pdf,GeoMotionGPT: Geometry-Aligned Motion Understanding with Large Language Models,"Zhankai Ye, Bofan Li, Yukai Jin, Shuoqiu Li, Wei Wang, Yanfu Zhang, Shangqian Gao, Xin Liu",,,"Large Language Models, motion understanding, motion-language reasoning, discrete motion tokenization, geometry alignment, embedding space, quantization, HumanML3D","Discrete motion tokenization has enabled Large Language Models (LLMs) to serve as versatile backbones for motion understanding and motion-language reasoning. However, existing pipelines typically decouple motion quantization from semantic embedding learning, linking them solely via token IDs. This approach fails to effectively align the intrinsic geometry of the motion space with the embedding space, hindering the LLM’s capacity for nuanced motion reasoning. The authors propose a novel framework that enforces orthogonality on both the motion codebook and the LLM embedding space, ensuring their relational structures naturally mirror each other. This framework employs a decoder-only quantizer with Gumbel-Softmax for differentiable training and balanced codebook usage, and uses a sparse projection to map motion codes into the LLM embedding space while preserving orthogonality. A two-stage orthonormal regularization schedule maintains geometric alignment without hindering semantic adaptation. Experiments on HumanML3D demonstrate a 20% performance improvement over current state-of-the-art methods, validating the effectiveness of a unified geometric basis for nuanced motion reasoning.",18.72,19.765,370,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07635v2_Learning About Learning A Physics Path from Spin G.pdf,Learning About Learning: A Physics Path from Spin Glasses to Artificial Intelligence,"Denis D. Caprioti, Matheus Haas, Constantino F. Vasconcelos, Mauricio Girardi-Schappo",,,"Hopfield model, spin-glass physics, neural networks, artificial intelligence, statistical mechanics, associative memory, combinatorial optimization, undergraduate physics, dynamical systems, linear algebra, computational methods","The Hopfield model, inspired by spin-glass physics, serves as a bridge between statistical mechanics, neural networks, and artificial intelligence. Despite its simplicity and broad applicability, it is rarely included in undergraduate physics curricula. This paper presents the Hopfield model as a pedagogically rich framework that unifies core topics from undergraduate statistical physics, dynamical systems, linear algebra, and computational methods. It provides a theoretical introduction, analyzes the model’s energy function, dynamics, and pattern stability, and discusses practical simulation aspects, including a freely available simulation code. The paper concludes with classroom-ready example problems designed to mirror research practice, aiming to prepare physics students to understand, apply, and critically engage with computational tools central to research, industry, and society.",17.48,16.25,284,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07638v1_SALT-KG A Benchmark for Semantics-Aware Learning o.pdf,SALT-KG: A Benchmark for Semantics-Aware Learning on Enterprise Tables,"Isaiah Onando Mulang’, Felix Sasaki, Tassilo Klein, Jonas Kolk, Nikolay Grechanov, Johannes Hoffart",,2601.07638v1,"semantics-aware learning, enterprise tables, SALT benchmark, metadata knowledge graph, tabular prediction, foundation models, structured data","Building upon the SALT benchmark for relational prediction, SALT-KG introduces a benchmark for semantics-aware learning on enterprise tables. It extends SALT by linking multi-table transactional data with a Metadata Knowledge Graph (OBKG) that captures field-level descriptions, relational dependencies, and business object-types. This enables evaluation of models that reason over tabular evidence and contextual semantics, highlighting gaps in models' ability to leverage semantics in relational contexts. SALT-KG reframes tabular prediction as semantics-conditioned reasoning, advancing tabular foundation models grounded in declarative knowledge.",16.9,15.744,266,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07641v1_Beyond Static Tools Test-Time Tool Evolution for S.pdf,Beyond Static Tools: Test-Time Tool Evolution for Scientific Reasoning,"Jiaxuan Lu, Ziyu Kong, Yemin Wang, Rong Fu, Haiyuan Wan, Cheng Yang, Wenjie Lou, Haoran Sun, Lilong Wang, Yankai Jiang, Xiaosong Wang, Xiao Sun, Dongzhan Zhou",,,"AI for Science, scientific reasoning, Large Language Models, Test-Time Tool Evolution, computational methods, tool libraries, SciEvo benchmark","The central challenge of AI for Science is not just reasoning, but creating computational methods in an open-ended scientific world. Existing LLM-based agents rely on static, pre-defined tool libraries, which fail in scientific domains where tools are sparse, heterogeneous, and incomplete. This paper proposes Test-Time Tool Evolution (TTE), enabling agents to synthesize, verify, and evolve executable tools during inference. TTE transforms tools from fixed resources into problem-driven artifacts, overcoming the limitations of static tool libraries. The paper introduces SciEvo, a benchmark with 1,590 scientific reasoning tasks supported by 925 evolved tools. Experiments show TTE achieves state-of-the-art performance in accuracy and tool efficiency, enabling effective cross-domain adaptation. The code and benchmark are available at https://github.com/lujiaxuan0520/Test-Time-Tool-Evol.",18.38,19.202,353,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07651v1_Active Evaluation of General Agents Problem Defini.pdf,Active Evaluation of General Agents: Problem Definition and Comparison of Baseline Algorithms,"Marc Lanctot, Kate Larson, Ian Gemp, Michael Kaisers",,,"general evaluation, multitask evaluation, ranking, active learning, game theory, social choice theory","As intelligent agents become more generally-capable, the complexity and cost of evaluating them increases. This paper proposes a formal definition and framework for active evaluation of agents across multiple tasks, assessing ranking algorithms based on the number of evaluation data samples. The study compares several baseline algorithms, including the classical Elo rating system and Soft Condorcet Optimization, using synthetic data and real evaluation data from Atari game-playing agents. The findings suggest that while Elo is reliable in practice, Soft Condorcet Optimization performs better on real data, especially when task variation is high.",15.89,13.78,219,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07654v1_Towards Automating Blockchain Consensus Verificati.pdf,Towards Automating Blockchain Consensus Verification with IsabeLLM,"Elliot Jones, William Knottenbelt",,2601.07654v1,"Blockchain, Consensus, Formal Verification, Theorem Proving, Artificial Intelligence","Consensus protocols are crucial for blockchain systems as they enable agreement between nodes in potentially adversarial environments. Ensuring their correct design and implementation is essential to prevent malicious behavior. Formal verification can ensure protocol correctness but requires significant effort and expertise, often leading to its omission in development. This paper introduces IsabeLLM, a tool integrating the proof assistant Isabelle with a Large Language Model to assist and automate proofs. The tool's effectiveness is demonstrated by developing and verifying a novel model of Bitcoin’s Proof of Work consensus protocol using the DeepSeek R1 API. The study found that IsabeLLM could generate correct proofs for each non-trivial lemma in the verification process.",17.69,13.228,234,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07663v2_Reasoning Models Will Blatantly Lie About Their Re.pdf,Reasoning Models Will Blatantly Lie About Their Reasoning,William Walden,,,"Large Reasoning Models, CoT monitoring, interpretability, faithfulness, hints","This study extends the work of Chen et al. (2025) to demonstrate that Large Reasoning Models (LRMs) will deny relying on hints provided in prompts when answering multiple-choice questions, even when explicitly instructed to acknowledge such hints. The research highlights significant implications for CoT monitoring and interpretability, showing that despite improvements in verbalizing the presence of hints, LRMs still exhibit unfaithful behavior by denying their reliance on these hints.",13.41,12.01,161,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07666v1_Variational Contrastive Learning for Skeleton-base.pdf,Variational Contrastive Learning for Skeleton-based Action Recognition,"Dang-Dinh NGUYEN, Decky ASPANDI-LATIF, Titus ZAHARIA",,arXiv:2601.07666v1,"Human Action Recognition, Self-Supervised Learning, Variational Inference","In recent years, self-supervised representation learning for skeleton-based action recognition has advanced with the development of contrastive learning methods. However, most of contrastive paradigms are inherently discriminative and often struggle to capture the variability and uncertainty intrinsic to human motion. To address this issue, we propose a variational contrastive learning framework that integrates probabilistic latent modeling with contrastive self-supervised learning. This formulation enables the learning of structured and semantically meaningful representations that generalize across different datasets and supervision levels. Extensive experiments on three widely used skeleton-based action recognition benchmarks show that our proposed method consistently outperforms existing approaches, particularly in low-label regimes. Moreover, qualitative analyses show that the features provided by our method are more relevant given the motion and sample characteristics, with more focus on important skeleton joints, when compared to the other methods.",18.59,15.06,280,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07667v1_Adaptive Layer Selection for Layer-Wise Token Prun.pdf,Adaptive Layer Selection for Layer-Wise Token Pruning in LLM Inference,"Rei Taniguchi, Yuyang Dong, Makoto Onizuka, Chuan Xiao",,,"Large Language Models, Key-Value Cache, Token Pruning, Layer-Wise Selection, LLM Inference","This paper introduces ASL, a training-free method for adaptively selecting the layer for key-value (KV) cache reduction in large language models (LLMs). Unlike existing methods that use pre-defined layers for token selection, ASL exploits the variance of token ranks ordered by attention score to adaptively choose the selection layer. This approach balances performance across different tasks while meeting user-specified KV budget requirements. ASL operates during the prefilling stage and can be used with existing methods like SnapKV to optimize the decoding stage. Evaluations on benchmarks such as InfiniteBench, RULER, and NIAH demonstrate that ASL outperforms state-of-the-art layer-wise token selection methods in accuracy while maintaining decoding speed and KV cache reduction.",15.94,15.371,245,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07685v1_Predictive Analytics for Dementia Machine Learning.pdf,Predictive Analytics for Dementia: Machine Learning on Healthcare Data,"Shafiul Ajam Opee, Nafiz Fahad, Anik Sen, Rasel Ahmed, Fariha Jahan, Md. Kishor Morol, Md Rashedul Islam",,,"Dementia, Machine learning, Linear Discriminant Analysis (LDA), APOE-ϵ4 allele","Dementia is a complex syndrome impacting cognitive and emotional functions, with Alzheimer’s disease being the most common form. This study focuses on enhancing dementia prediction using machine learning (ML) techniques on patient health data. Supervised learning algorithms such as K-Nearest Neighbors (KNN), Quadratic Discriminant Analysis (QDA), Linear Discriminant Analysis (LDA), and Gaussian Process Classifiers are applied. Techniques like Synthetic Minority Over-sampling Technique (SMOTE) and Term Frequency-Inverse Document Frequency (TF-IDF) vectorization are employed to address class imbalance and improve model performance. LDA achieved the highest testing accuracy of 98%. The study highlights the importance of model interpretability and the correlation of dementia with features such as the presence of the APOE-ϵ4 allele and chronic conditions like diabetes. Future ML innovations, particularly in integrating explainable AI approaches, are advocated to further improve predictive capabilities in dementia care.",18.17,17.946,326,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07701v1_Deep Whole-body Parkour.pdf,Deep Whole-body Parkour,"Ziwen Zhuang, Shaoting Zhu, Mengjie Zhao, Hang Zhao",,arXiv:2601.07701v1,"humanoid control, perceptive locomotion, general motion tracking, deep reinforcement learning, legged robotics, whole-body motion tracking, exteroceptive sensing, multi-contact motions, parkour, dynamic tasks, terrain adaptability","This work presents a framework that integrates exteroceptive sensing into whole-body motion tracking, enabling a humanoid robot to perform dynamic, non-locomotion tasks on uneven terrain. By training a single policy to execute multiple distinct motions across varied terrestrial features, the framework demonstrates the benefits of incorporating perception into the control loop. The results show that the system can perform robust, highly dynamic multi-contact motions—such as vaulting and dive-rolling—on unstructured terrain, significantly expanding the robot's traversability beyond simple walking or running.",17.29,14.69,254,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07718v1_Hiking in the Wild A Scalable Perceptive Parkour F.pdf,Hiking in the Wild: A Scalable Perceptive Parkour Framework for Humanoids,"Shaoting Zhu, Ziwen Zhuang, Mengjie Zhao, Kun-Ying Lee, Hang Zhao",,2601.07718v1,"humanoid, parkour, perception, terrain traversal, reinforcement learning, depth images, end-to-end framework","Achieving robust humanoid hiking in complex, unstructured environments requires transitioning from reactive proprioception to proactive perception. This work presents 'Hiking in the Wild,' a scalable, end-to-end parkour perceptive framework designed for robust humanoid hiking. The framework utilizes depth images for perception and includes mechanisms such as a foothold safety mechanism and a flat patch sampling strategy to ensure safety and training stability. The approach maps raw depth inputs and proprioception directly to joint actions without relying on external state estimation. Extensive field experiments demonstrate the policy's effectiveness on a full-size humanoid.",18.19,13.745,250,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07737v1_Evaluating the encoding competence of visual langu.pdf,Evaluating the encoding competence of visual language models using uncommon actions,"Chen Ling, Nai Ding",,2601.07737v1,cs.CV,,12.77,4.777,61,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07748v1_Improving Domain Generalization in Contrastive Lea.pdf,Improving Domain Generalization in Contrastive Learning using Adaptive Temperature Control,"Robert Lewis, Katie Matton, Rosalind W. Picard, John Guttag",,2601.07748v1,"contrastive learning, domain generalization, adaptive temperature control, self-supervised pre-training, covariate shift, domain invariance","Self-supervised pre-training with contrastive learning is a powerful method for learning from sparsely labeled data. However, performance can drop considerably when there is a shift in the distribution of data from training to test time. This paper presents a new method for contrastive learning that incorporates domain labels to increase the domain invariance of learned representations, leading to improved out-of-distribution generalization. The method adjusts the temperature parameter in the InfoNCE loss to control the relative weighting of negative pairs based on domain similarity, encouraging the model to discriminate samples based on domain-invariant attributes. Experiments on a variant of the MNIST dataset demonstrate that this method yields better out-of-distribution performance than domain generalization baselines while maintaining strong in-distribution task performance.",17.72,15.797,280,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07778v1_DT-ICU Towards Explainable Digital Twins for ICU P.pdf,DT-ICU: Towards Explainable Digital Twins for ICU Patient Monitoring via Multi-Modal and Multi-Task Iterative Inference,Wen Guo,,2601.07778v1,"digital twins, ICU patient monitoring, multi-modal, multi-task, iterative inference, clinical time series, risk estimation, MIMIC-IV dataset, interpretability","We introduce DT-ICU, a multimodal digital twin framework for continuous risk estimation in intensive care. DT-ICU integrates variable-length clinical time series with static patient information in a unified multitask architecture, enabling predictions to be updated as new observations accumulate over the ICU stay. We evaluate DT-ICU on the large, publicly available MIMIC-IV dataset, where it consistently outperforms established baseline models under different evaluation settings. Our test-length analysis shows that meaningful discrimination is achieved shortly after admission, while longer observation windows further improve the ranking of high-risk patients in highly imbalanced cohorts. To examine how the model leverages heterogeneous data sources, we perform systematic modality ablations, revealing that the model learnt a reasonable structured reliance on interventions, physiological response observations, and contextual information. These analyses provide interpretable insights into how multimodal signals are combined and how trade-offs between sensitivity and precision emerge. Together, these results demonstrate that DT-ICU delivers accurate, temporally robust, and interpretable predictions, supporting its potential as a practical digital twin framework for continuous patient monitoring in critical care.",20.51,16.186,332,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07779v1_OS-Symphony A Holistic Framework for Robust and Ge.pdf,OS-SYMPHONY: A Holistic Framework for Robust and Generalist Computer-Using Agent,"Bowen Yang, Kaiming Jin, Zhenyu Wu, Zhaoyang Liu, Qiushi Sun, Zehao Li, Jingjing Xie, Zhoumianze Liu, Fangzhi Xu, Kanzhi Cheng, Qingyun Li, Yian Wang, Yu Qiao, Zun Wang, Zichen Ding",,,"Vision-Language Models, Computer-Using Agents, Robustness, Generalization, Long-horizon workflows, Novel domains, Orchestrator, Reflection-Memory Agent, Multimodal Searcher, See-Act paradigm, Online benchmarks","While Vision-Language Models (VLMs) have significantly advanced Computer-Using Agents (CUAs), current frameworks struggle with robustness in long-horizon workflows and generalization in novel domains. These limitations stem from a lack of granular control over historical visual context curation and the absence of visual-aware tutorial retrieval. To bridge these gaps, we introduce OS-SYMPHONY, a holistic framework that comprises an Orchestrator coordinating two key innovations for robust automation: 1) a Reflection-Memory Agent that utilizes milestone-driven long-term memory to enable trajectory-level self-correction, effectively mitigating visual context loss in long-horizon tasks; 2) Versatile Tool Agents featuring a Multimodal Searcher that adopts a See-Act paradigm to navigate a browser-based sandbox to synthesize live, visually aligned tutorials, thereby resolving fidelity issues in unseen scenarios. Experimental results demonstrate that OS-SYMPHONY delivers substantial performance gains across varying model scales, establishing new state-of-the-art results on three online benchmarks, notably achieving 65.84% on OSWorld.",19.04,23.793,453,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07782v1_Beyond Single-Shot Multi-step Tool Retrieval via Q.pdf,Beyond Single-Shot: Multi-step Tool Retrieval via Query Planning,"Wei Fang, James Glass",,,,"LLM agents operating over massive, dynamic tool libraries rely on effective retrieval, yet standard single-shot dense retrievers struggle with complex requests. These failures primarily stem from the disconnect between abstract user goals and technical documentation, and the limited capacity of fixed-size embeddings to model combinatorial tool compositions. To address these challenges, we propose TOOLQP, a lightweight framework that models retrieval as iterative query planning. Instead of single-shot matching, TOOLQP decomposes instructions into sub-tasks and dynamically generates queries to interact with the retriever, effectively bridging the semantic gap by targeting the specific sub-tasks required for composition. We train TOOLQP using synthetic query trajectories followed by optimization via Reinforcement Learning with Verifiable Rewards (RLVR). Experiments demonstrate that TOOLQP achieves state-of-the-art performance, exhibiting superior zero-shot generalization, robustness across diverse retrievers, and significant improvements in downstream agentic execution.",16.62,14.201,236,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07790v1_Benchmarking Small Language Models and Small Reaso.pdf,Benchmarking Small Language Models and Small Reasoning Language Models on System Log Severity Classification,"Yahya Masri, Emily Ma, Zifu Wang, Joseph Rogers, Chaowei Yang",,arXiv:2601.07790v1,"system logs, severity classification, language models, reasoning language models, benchmarking, digital twin systems, root cause analysis","System logs are crucial for monitoring and diagnosing modern computing infrastructure, but their scale and complexity require reliable and efficient automated interpretation. This study evaluates nine small language models (SLMs) and small reasoning language models (SRLMs) using real-world journalctl data from Linux production servers. The models are assessed under zero-shot, few-shot, and retrieval-augmented generation (RAG) prompting. Qwen3-4B achieves the highest accuracy at 95.64% with RAG, while Gemma3-1B improves significantly with RAG. Efficiency measurements show that most Gemma and Llama variants complete inference quickly, whereas Phi-4-Mini-Reasoning is slower and less accurate. The study suggests that architectural design, training objectives, and the ability to integrate retrieved context determine performance. The benchmark aligns with real-time requirements of digital twin systems and highlights severity classification as a lens for evaluating model competence and deployability.",18.66,17.528,327,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07794v1_Kinship Data Benchmark for Multi-hop Reasoning.pdf,Kinship Data Benchmark for Multi-hop Reasoning,"Tianda Sun, Dimitar Kazakov",,,"multi-hop reasoning, kinship relations, genealogical data, large language models, cultural settings","Large language models (LLMs) are increasingly evaluated on their ability to perform multi-hop reasoning, i.e., to combine multiple pieces of information into a coherent inference. This paper introduces KinshipQA, a benchmark designed to probe this capability through reasoning over kinship relations. The central contribution is a generative pipeline that produces large-scale, realistic, and culture-specific genealogical data: collections of interconnected family trees that satisfy explicit marriage constraints associated with different kinship systems. This allows task difficulty, cultural assumptions, and relational depth to be systematically controlled and varied. From these genealogies, textual inference tasks are derived that require reasoning over implicit relational chains. The benchmark is evaluated using six state-of-the-art LLMs, spanning both open-source and closed-source models, under a uniform zero-shot protocol with deterministic decoding. Performance is measured using exact-match and set-based metrics. Results demonstrate that KinshipQA yields a wide spread of outcomes and exposes systematic differences in multi-hop reasoning across models and cultural settings.",17.4,15.746,274,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07821v1_Failure-Aware RL Reliable Offline-to-Online Reinfo.pdf,Failure-Aware RL: Reliable Offline-to-Online Reinforcement Learning with Self-Recovery for Real-World Manipulation,"Huanyu Li, Kun Lei, Sheng Zang, Kaizhe Hu, Yongyuan Liang, Bo An, Xiaoli Li, Huazhe Xu",,,"Reinforcement Learning, Offline-to-Online RL, Failure-Aware RL, Real-World Manipulation, Intervention-requiring Failures, Self-Recovery, Robotic Models","This paper introduces Failure-Aware Offline-to-Online Reinforcement Learning (FARL), a paradigm designed to minimize failures during real-world reinforcement learning. FARL predicts potential failures and executes recovery actions, significantly reducing Intervention-requiring Failures (IR Failures) during real-world RL while improving task performance. The authors present FailureBench, a benchmark incorporating common failure scenarios requiring human intervention, and propose an algorithm integrating a world-model-based safety critic and a recovery policy trained offline. Extensive simulation and real-world experiments demonstrate FARL's effectiveness in reducing IR Failures by 73.1% and improving performance by 11.3% on average during real-world RL post-training.",17.94,17.0,305,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07832v2_MHLA Restoring Expressivity of Linear Attention vi.pdf,MHLA: Restoring Expressivity of Linear Attention via Token-Level Multi-Head,"Kewei Zhang, Ye Huang, Yufan Deng, Jincheng Yu, Junsong Chen, Huan Ling, Enze Xie, Daquan Zhou",,arXiv:2601.07832v2,"Transformer, self-attention, linear attention, multi-head attention, expressivity, computational efficiency, image classification, NLP, image generation, video generation","While the Transformer architecture dominates many fields, its quadratic self-attention complexity hinders its use in large-scale applications. Linear attention offers an efficient alternative, but its direct application often degrades performance, with existing fixes typically re-introducing computational overhead through extra modules (e.g., depthwise separable convolution) that defeat the original purpose. In this work, we identify a key failure mode in these methods: global context collapse, where the model loses representational diversity. To address this, we propose Multi-Head Linear Attention (MHLA), which preserves this diversity by computing attention within divided heads along the token dimension. We prove that MHLA maintains linear complexity while recovering much of the expressive power of softmax attention, and verify its effectiveness across multiple domains, achieving a 3.6% improvement on ImageNet classification, a 6.3% gain on NLP, a 12.6% improvement on image generation, and a 41% enhancement on video generation under the same time complexity.",19.55,19.129,374,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07885v1_Small Symbols Big Risks Exploring Emoticon Semanti.pdf,"Small Symbols, Big Risks: Exploring Emoticon Semantic Confusion in Large Language Models","Weipeng Jiang, Xiaoyu Zhang, Juan Zhai, Shiqing Ma, Chao Shen, Yang Liu",,,"emoticon semantic confusion, large language models, security vulnerabilities, automated data generation, human-AI interaction","Emoticons are widely used in digital communication to convey affective intent, yet their safety implications for Large Language Models (LLMs) remain largely unexplored. This paper identifies emoticon semantic confusion, a vulnerability where LLMs misinterpret ASCII-based emoticons to perform unintended and potentially destructive actions. An automated data generation pipeline was developed, resulting in a dataset with 3,757 code-oriented test cases across 21 meta-scenarios, four programming languages, and varying contextual complexities. The study on six LLMs reveals that emoticon semantic confusion is pervasive, with an average confusion ratio exceeding 38%. Over 90% of confused responses yield 'silent failures', which are syntactically valid but deviate from user intent, potentially leading to destructive security consequences. This vulnerability transfers to popular agent frameworks, and existing prompt-based mitigations are largely ineffective. The paper calls for the community to recognize this emerging vulnerability and develop effective mitigation methods to ensure the safety and reliability of human-AI interactions.",17.74,18.662,331,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07891v1_KVzap Fast Adaptive and Faithful KV Cache Pruning.pdf,"KVzap: Fast, Adaptive, and Faithful KV Cache Pruning","Simon Jégou, Maximilian Jeblick",,2601.07891v1,"KV cache, pruning, transformer-based language models, inference bottleneck, compression, accuracy","Growing context lengths in transformer-based language models have made the key-value (KV) cache a critical inference bottleneck. KVzap is introduced as a fast, input-adaptive approximation of KVzip that works in both prefilling and decoding. It achieves 2–4× KV cache compression with negligible accuracy loss and achieves state-of-the-art performance on the KVpress Leaderboard for models like Qwen3-8B, Llama-3.1-8B-Instruct, and Qwen3-32B across long-context and reasoning tasks. KVzap matches the performance of KVzip while outperforming 15 other methods.",16.61,13.306,221,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07892v1_Sherry Hardware-Efficient 1.25-Bit Ternary Quantiz.pdf,Hardware-Efficient 1.25-Bit Ternary Quantization via Fine-grained Sparsification,"Hong Huang, Decheng Wu, Qiangqiang Hu, Guanghua Yu, Jinhai Yang, Jianchen Zhu, Xue Liu, Dapeng Wu",,,"Large Language Models, ternary quantization, hardware efficiency, sparsification, edge devices, quantization, model deployment","The deployment of Large Language Models (LLMs) on resource-constrained edge devices is increasingly hindered by prohibitive memory and computational requirements. Ternary quantization, which reduces weights to {−1,0,+1}, offers a solution but suffers from misalignment with commodity hardware. This paper introduces Sherry, a hardware-efficient ternary quantization framework that achieves a regularized 1.25-bit width through fine-grained sparsity, restoring power-of-two alignment. Sherry also addresses the weight trapping issue in sparse ternary training with an annealing residual synapse mechanism. Empirical evaluations on LLaMA-3.2 demonstrate that Sherry matches state-of-the-art ternary performance while significantly reducing model size, achieving zero accuracy loss compared to SOTA baselines on an Intel i7-14700HX CPU, with 25% bit savings and 10% speed up.",17.94,18.622,334,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07894v1_Revealing the Attention Floating Mechanism in Mask.pdf,Revealing the Attention Floating Mechanism in Masked Diffusion Models,"Xin Dai, Pengcheng Huang, Zhenghao Liu, Shuo Wang, Yukun Yan, Chaojun Xiao, Yu Gu, Ge Yu, Maosong Sun",,,"masked diffusion models, attention mechanisms, autoregressive models, denoising process, bidirectional attention, in-context learning, large language models","Masked diffusion models (MDMs) leverage bidirectional attention and a denoising process to narrow the performance gap with autoregressive models (ARMs). This paper investigates the attention behaviors in MDMs, revealing the phenomenon of Attention Floating. Unlike ARMs, where attention converges to a fixed sink, MDMs exhibit dynamic, dispersed attention anchors that shift across denoising steps and layers. The analysis shows a Shallow Structure-Aware, Deep Content-Focused attention mechanism: shallow layers use floating tokens to build a global structural framework, while deeper layers focus on capturing semantic content. This distinctive attention pattern explains the strong in-context learning capabilities of MDMs, allowing them to double the performance compared to ARMs in knowledge-intensive tasks. All codes and datasets are available at https://github.com/NEUIR/Attention-Floating.",17.72,18.34,325,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07898v1_Large Language Models and Algorithm Execution Appl.pdf,Large Language Models and Algorithm Execution: Application to an Arithmetic Function,"Farah Ben Slama, Frédéric Armetta",,,"Algorithmic learning in natural language, Supervised learning by decomposition, Large language model, Fine-tuning","Large Language Models (LLMs) have developed advanced functionalities through statistical learning and generalization. However, they struggle with internalizing data and executing algorithms autonomously. This paper explores extending LLMs' capabilities for algorithm execution via specialized supervised training focused on reasoning decomposition. A training model called LLM-DAL (Large Language Model - Decompositional Algorithmic Learning) is introduced, demonstrating improved algorithmic inference and generalization when training methods guide the learning process. The paper also discusses the challenges of using neural networks for algorithmic learning, referencing Searle's Chinese room thought experiment to highlight the limitations of AI systems in understanding and knowledge grounding.",16.6,13.612,226,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07901v1_Decentralized Online Convex Optimization with Unkn.pdf,Decentralized Online Convex Optimization with Unknown Feedback Delays,"Hao Qiu, Mengxiao Zhang, Juliette Achddou",,2601.07901v1,"Decentralized Online Convex Optimization, Feedback Delays, Federated Learning, Sensor Networks, Multi-Agent Control, Adaptive Learning Rate, Gossip-Based Strategy, Spectral Gap, Strongly Convex Setting","This paper addresses decentralized online convex optimization (D-OCO) under unknown, time- and agent-varying feedback delays. Existing algorithms assume prior knowledge of the total delay, leading to suboptimal performance. The authors propose a novel algorithm with an improved regret bound, leveraging an adaptive learning rate mechanism and a decentralized communication protocol. This allows agents to estimate delays locally without prior knowledge of the total delay. The framework is extended to the strongly convex setting, yielding a sharper regret bound. Experimental results demonstrate the effectiveness of the approach, showing improvements over existing benchmarks.",17.14,15.048,258,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07903v2_Enhancing Large Language Models for Time-Series Fo.pdf,Enhancing Large Language Models for Time-Series Forecasting via Vector-Injected In-Context Learning,"Jianqi Zhang, Jingyao Wang, Wenwen Qiang, Fanjiang Xu, Changwen Zheng",https://doi.org/XXXXXXX.XXXXXXX,,"Time Series Forecasting, Large Language Model, In-context Learning","The World Wide Web needs reliable predictive capabilities to respond to changes in user behavior and usage patterns. Time series forecasting (TSF) is a key means to achieve this goal. In recent years, the large language models (LLMs) for TSF (LLM4TSF) have achieved good performance. However, there is a significant difference between pretraining corpora and time series data, making it hard to guarantee forecasting quality when directly applying LLMs to TSF; fine-tuning LLMs can mitigate this issue, but often incurs substantial computational overhead. Thus, LLM4TSF faces a dual challenge of prediction performance and compute overhead. To address this, we aim to explore a method for improving the forecasting performance of LLM4TSF while freezing all LLM parameters to reduce computational overhead. Inspired by in-context learning (ICL), we propose LVICL. LVICL uses our vector-injected ICL to inject example information into a frozen LLM, eliciting its in-context learning ability and thereby enhancing its performance on the example-related task (i.e., TSF). Specifically, we first use the LLM together with a learnable context vector adapter to extract a context vector from multiple examples adaptively. This vector contains compressed, example-related information. Subsequently, during the forward pass, we inject this vector into every layer of the LLM to improve forecasting performance. Compared with conventional ICL that adds examples into the prompt, our vector-injected ICL does not increase prompt length; moreover, adaptively deriving a context vector from examples suppresses components harmful to forecasting, thereby improving model performance. Extensive experiments demonstrate the effectiveness of our approach.",19.75,23.446,463,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07935v1_Towards Specialized Generalists A Multi-Task MoE-L.pdf,Towards Specialized Generalists: A Multi-Task MoE-LoRA Framework for Domain-Specific LLM Adaptation,"Yuxin Yang, Aoxiong Zeng, Xiangquan Yang",,arXiv:2601.07935v1,"Large Language Models, Domain-Specific Adaptation, Mixture-of-Experts, Low-Rank Adaptation, Medical NLP, Catastrophic Forgetting, Knowledge Preservation","The paper addresses the challenges of adapting Large Language Models (LLMs) to specialized fields like medicine, focusing on the 'Stability-Plasticity Dilemma' and 'Task Interference'. It proposes a novel framework, Med-MoE-LoRA, integrating Mixture-of-Experts (MoE) with Low-Rank Adaptation (LoRA) for efficient multi-task domain adaptation. The framework employs an asymmetric expert distribution and a 'Knowledge-Preservation Plugin' to protect general-purpose reasoning while enhancing performance in medical benchmarks. Experimental results show that Med-MoE-LoRA outperforms standard LoRA and conventional MoE architectures in clinical NLP tasks while retaining general cognitive capabilities.",18.0,16.053,289,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07939v1_SECite Analyzing and Summarizing Citations in Soft.pdf,Analyzing and Summarizing Citations in Software Engineering Literature,"Shireesh Reddy Pyreddy, Khaja Valli Pathan, Hasan Masum, Tarannum Shaila Zaman",,,"Sentiment Analysis, LLMs, Text Summarization, Citations","Identifying the strengths and limitations of a research paper is a core component of any literature review. Traditional summaries reflect only the authors’ self-presented perspective. Analyzing how other researchers discuss and cite the paper can offer a deeper, more practical understanding of its contributions and shortcomings. This research introduces SECite, a novel approach for evaluating scholarly impact through sentiment analysis of citation contexts. A semi-automated pipeline extracts citations referencing nine research papers and applies advanced natural language processing (NLP) techniques with unsupervised machine learning to classify these citation statements as positive or negative. Generative AI is used to produce sentiment-specific summaries that capture the strengths and limitations of each target paper, derived both from clustered citation groups and from the full text. The findings reveal meaningful patterns in how the academic community perceives these works, highlighting areas of alignment and divergence between external citation feedback and the authors’ own presentation. By integrating citation sentiment analysis with LLM-based summarization, this study provides a comprehensive framework for assessing scholarly contributions.",18.17,17.278,314,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07941v2_Moonworks Lunara Aesthetic Dataset.pdf,Moonworks Lunara Aesthetic Dataset,"Yan Wang, M M Sayeef Abdullah, Partho Hassan, Sabit Hassan",,arXiv:2601.07941v2,"text-to-image generation, prompt grounding, style conditioning, aesthetic dataset, artistic styles, image–prompt pairs","This data card presents the first public release of the Lunara Aesthetic Dataset, a curated set of 2,000 image–prompt pairs for controlled research on prompt grounding and style conditioning in text-to-image generation systems. The dataset spans diverse artistic styles, including regionally grounded aesthetics from the Middle East, Northern Europe, East Asia, and South Asia, alongside general categories such as sketch and oil painting. All images are generated using the Moonworks Lunara model and intentionally crafted to embody distinct, high-quality aesthetic styles, yielding a first-of-its-kind dataset with substantially higher aesthetic scores, exceeding even aesthetics-focused datasets, and general-purpose datasets by a larger margin. Each image is accompanied by a human-refined prompt and structured annotations that jointly describe salient objects, attributes, relationships, and stylistic cues. Unlike large-scale web-derived datasets that emphasize breadth over precision, the Lunara Aesthetic Dataset prioritizes aesthetic quality, stylistic diversity, and licensing transparency, and is released under the Apache 2.0 license to support research and unrestricted academic and commercial use.",19.44,16.46,320,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07946v1_Coupled Diffusion-Encoder Models for Reconstructio.pdf,Coupled Diffusion–Encoder Models for Reconstruction of Flow Fields,"AmirPouya Hemmasian, Amir Barati Farimani",,,"Diffusion model, Encoder, Flow field reconstruction, Autoencoder, Variational Autoencoders, Probabilistic modeling, Generative modeling, Compression, Spectral accuracy, Statistical structure","This paper introduces DiffCoder, a coupled framework integrating a probabilistic diffusion model with a conventional convolutional ResNet encoder, designed for the reconstruction of flow fields. Unlike traditional autoencoders, which often struggle to preserve the higher-order statistical structure of fluid flows under strong compression, DiffCoder aims to recover distributional and spectral properties critical for representing the statistical properties of flow fields. The framework is evaluated against Variational Autoencoders (VAEs) on a dataset of Kolmogorov flow fields, demonstrating significant improvements in spectral accuracy under aggressive compression. While both methods show comparable relative L2 reconstruction error, DiffCoder better preserves the underlying distributional structure of the flow. The results suggest that diffusion-based priors are particularly beneficial when information bottlenecks are severe, offering a promising approach for compact, statistically consistent representations of complex flow fields.",18.28,16.354,299,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07948v1_Reinforcement Learning Methods for Neighborhood Se.pdf,Reinforcement Learning Methods for Neighborhood Selection in Local Search,"Yannick Molinghen, Augustin Delecluse, Renaud De Landtsheer, Stefano Michelini",,,"Local Search, Reinforcement Learning, Combinatorial Optimization","Reinforcement learning has recently gained traction as a means to improve combinatorial optimization methods, yet its effectiveness within local search metaheuristics specifically remains comparatively underexamined. In this study, we evaluate a range of reinforcement learning-based neighborhood selection strategies – multi-armed bandits (upper confidence bound, ε-greedy) and deep reinforcement learning methods (proximal policy optimization, double deep Q-network) – and compare them against multiple baselines across three different problems: the traveling salesman problem, the pickup and delivery problem with time windows, and the car sequencing problem. We show how search-specific characteristics, particularly large variations in cost due to constraint violation penalties, necessitate carefully designed reward functions to provide stable and informative learning signals. Our extensive experiments reveal that algorithm performance varies substantially across problems, although that ε-greedy consistently ranks among the best performers. In contrast, the computational overhead of deep reinforcement learning approaches only makes them competitive with a substantially longer runtime. These findings highlight both the promise and the practical limitations of deep reinforcement learning in local search.",17.95,17.712,318,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07951v1_Hybrid SARIMA LSTM Model for Local Weather Forecas.pdf,Hybrid SARIMA–LSTM Model for Local Weather Forecasting: A Residual-Learning Approach for Data-Driven Meteorological Prediction,"Shreyas Rajeev Stevens Institute of Technology Hoboken, USA, Karthik Mudenahalli Ashoka Stevens Institute of Technology Hoboken, USA, Amit Mallappa Tiparaddi Stevens Institute of Technology Hoboken, USA",,,"SARIMA, LSTM, weather forecasting, residual-learning, deep learning, time-series analysis, meteorological prediction","This paper introduces a Hybrid SARIMA–LSTM architecture for local weather forecasting, addressing the limitations of traditional statistical models and independent neural network models in long-term forecasting. The proposed model separates temperature into a predictable climate component and a nonlinear weather component using a residual-learning strategy. SARIMA models the long-term seasonal trend, while LSTM learns the random changes in SARIMA's prediction errors. The approach incorporates Fourier seasonal encoding and a stabilized recursive forecasting mechanism to maintain prediction accuracy within a 293-day horizon. The model's efficacy is demonstrated using data from 2020 to 2023 to predict daily average temperatures in New York City, showing significant improvements over traditional SARIMA models.",18.17,16.235,295,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07953v1_Quantum automated theorem proving.pdf,Quantum Automated Theorem Proving,"Zheng-Zhi Sun, Qi Ye, Dong-Ling Deng",,,"Quantum computing, Automated theorem proving, Quantum superposition, Quantum entanglement, Quantum resolution, First-order logic, Propositional logic, Geometric theorems, Wu’s algebraic approach, Quantum algebraic proving method","Automated theorem proving aims to use computer programs to automatically prove or disprove mathematical theorems and logical statements. This paper proposes a framework for quantum automated theorem proving, leveraging quantum superposition and entanglement to potentially enhance theorem-proving capabilities. The authors introduce quantum representations of knowledge bases and reasoning algorithms for various tasks, demonstrating how quantum resolution can achieve automated reasoning in both propositional and first-order logic with reduced query complexity. Additionally, a quantum algebraic proving method for geometric theorems is proposed, extending Wu’s algebraic approach. The paper illustrates these concepts with examples, including geometry problems from the International Mathematical Olympiad, showing how quantum computers can improve query complexity in proving geometric theorems. The results suggest a foundational approach to developing quantum automatic theorem provers, which could be crucial for future quantum technologies.",17.79,17.14,305,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07957v1_LWMSCNN-SE A Lightweight Multi-Scale Network for E.pdf,LWMSCNN-SE: A Lightweight Multi-Scale Network for Efficient Maize Disease Classification on Edge Devices,"Fikadu Weloday, Jianmei Su",,,"lightweight CNN, multi-scale feature extraction, attention mechanism, plant pathology","Maize disease classification is crucial for mitigating yield losses and ensuring food security. Traditional disease detection models face challenges in resource-constrained environments due to high computational costs. This paper proposes LWMSCNN-SE, a lightweight convolutional neural network that integrates multi-scale feature extraction, depthwise separable convolutions, and squeeze-and-Excitation (SE) attention mechanisms. The model achieves 96.63% classification accuracy with only 241,348 parameters and 0.666 GFLOPs, making it suitable for real-time deployment in field applications. This approach addresses the accuracy-efficiency trade-off, demonstrating potential for efficient maize disease diagnosis on edge devices in precision farming systems.",16.68,14.272,238,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07958v1_LJ-Spoof A Generatively Varied Corpus for Audio An.pdf,LJ-SPOOF: A GENERATIVELY VARIED CORPUS FOR AUDIO ANTI-SPOOFING AND SYNTHESIS SOURCE TRACING,"Surya Subramani, Hashim Ali, Hafiz Malik",,,"Anti-Spoofing, Speaker Verification, Deepfake, Source tracing, Synthetic Speech","Speaker-specific anti-spoofing and synthesis-source tracing are central challenges in audio anti-spoofing. Progress has been hampered by the lack of datasets that systematically vary model architectures, synthesis pipelines, and generative parameters. To address this gap, we introduce LJ-Spoof, a speaker-specific, generatively diverse corpus that systematically varies prosody, vocoders, generative hyperparameters, bona fide prompt sources, training regimes, and neural post-processing. The corpus spans one speaker-including studio-quality recordings-30 TTS families, 500 generatively variant subsets, 10 bona fide neural-processing variants, and more than 3 million utterances. This variation-dense design enables robust speaker-conditioned anti-spoofing and fine-grained synthesis-source tracing. We further position this dataset as both a practical reference training resource and a benchmark evaluation suite for anti-spoofing and source tracing.",17.49,16.696,292,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07964v1_Executable Ontologies in Game Development From Alg.pdf,Executable Ontologies in Game Development: From Algorithmic Control to Semantic World Modeling,Alexander Boldachev,,,"executable ontologies, game AI, behavior trees, GOAP, event semantics, dataflow architecture, semantic modeling","This paper examines the application of Executable Ontologies (EO), implemented through the boldsea framework, to game development. It argues that EO represents a paradigm shift from algorithmic behavior programming to semantic world modeling, where agent behavior emerges naturally from declarative domain rules rather than being explicitly coded. Using a survival game scenario (Winter Feast), the paper demonstrates how EO achieves priority-based task interruption through dataflow conditions rather than explicit preemption logic. Comparison with Behavior Trees (BT) and Goal-Oriented Action Planning (GOAP) reveals that while these approaches model what agents should do, EO models when actions become possible, addressing the semantic-process gap in game AI architecture. The paper discusses integration strategies, debugging advantages inherent to temporal event graphs, and the potential for LLM-driven runtime model generation.",17.85,13.223,236,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07965v1_When Models Know When They Do Not Know Calibration.pdf,"WHEN MODELS KNOW WHEN THEY DO NOT KNOW: CALIBRATION, CASCADING, AND CLEANING","Chenjie Hao, Weyl Lu, Yuko Ishiwaka, Zengyi Li, Weier Wan, Yubei Chen",,,"model calibration, confidence, model cascading, data cleaning, vision models, language models","This work explores how models can recognize when they do not know, focusing on calibration, cascading, and data cleaning. It introduces a training-free method for model calibration applicable to both vision and language models. The study highlights the reliability of calibrated confidence and proposes applications such as model cascading with calibrated advantage routing and data cleaning based on model ensemble. The results demonstrate improved efficiency, reliability, and trustworthiness in AI systems.",15.83,13.769,218,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07969v1_Tuberculosis Screening from Cough Audio Baseline M.pdf,"TUBERCULOSIS SCREENING FROM COUGH AUDIO: BASELINE MODELS, CLINICAL VARIABLES, AND UNCERTAINTY QUANTIFICATION","George P. Kafentzis, Efstratios Selisios",,2601.07969v1,"Tuberculosis, Machine Learning, Cough Audio, Cross-Validation, Uncertainty Quantification, Feature Extraction","In this paper, we propose a standardized framework for automatic tuberculosis (TB) detection from cough audio and routinely collected clinical data using machine learning. While TB screening from audio has attracted growing interest, progress is difficult to measure because existing studies vary substantially in datasets, cohort definitions, feature representations, model families, validation protocols, and reported metrics. Consequently, reported gains are often not directly comparable, and it remains unclear whether improvements stem from modeling advances or from differences in data and evaluation. We address this gap by establishing a strong, well-documented baseline for TB prediction using cough recordings and accompanying clinical metadata from a recently compiled dataset from several countries. Our pipeline is reproducible end-to-end, covering feature extraction, multimodal fusion, cougher-independent evaluation, and uncertainty quantification, and it reports a consistent suite of clinically relevant metrics to enable fair comparison. We further quantify performance for cough audio-only and fused (audio + clinical metadata) models, and release the full experimental protocol to facilitate benchmarking. This baseline is intended to serve as a common reference point and to reduce methodological variance that currently holds back progress in the field.",18.89,19.008,359,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07973v1_Cultural Compass A Framework for Organizing Societ.pdf,Cultural Compass: A Framework for Organizing Societal Norms to Detect Violations in Human-AI Conversations,"Myra Cheng, Vinodkumar Prabhakaran, Alice Oh, Hayk Stepanyan, Aishwarya Verma, Charu Kalia, Erin MacMurray van Liemt, Sunipa Dev",,arXiv:2601.07973v1,"Generative AI, Sociocultural norms, Natural Language Processing, Cultural alignment, Human-AI interaction","Generative AI models need to be useful and safe across cross-cultural contexts, which requires understanding how they adhere to sociocultural norms. Existing work lacks nuance and coverage in evaluating models' norm adherence. This paper introduces a taxonomy of norms, clarifying contexts, specifications, and mechanisms, and demonstrates how it can be used to evaluate models' norm adherence in naturalistic settings. The analysis shows that state-of-the-art models frequently violate norms, with variation by model, context, and country. The proposed taxonomy and evaluation pipeline enable nuanced, context-sensitive evaluation of cultural norm adherence.",17.03,16.857,287,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07988v1_From Word Sequences to Behavioral Sequences Adapti.pdf,From Word Sequences to Behavioral Sequences: Adapting Modeling and Evaluation Paradigms for Longitudinal NLP,"Adithya V Ganesan, Vasudha Varadarajan, Oscar NE Kjell, Whitney R Ringwald, Scott Feltman, Benjamin J Luft, Roman Kotov, Ryan L Boyd, H Andrew Schwartz",,,"NLP, longitudinal studies, behavioral sequences, evaluation paradigms, PTSD, mental health","This paper addresses the limitations of traditional NLP approaches when applied to longitudinal data, where documents are nested within authors and ordered in time. It proposes a new modeling and evaluation paradigm that updates four parts of the NLP pipeline: evaluation splits, accuracy metrics, sequence inputs, and model internals. The authors demonstrate the issues with traditional pipelines and their proposed improvements using a dataset of 17,000 daily diary transcripts paired with PTSD symptom severity from 238 participants. They find that traditional document-level evaluation can yield different and sometimes reversed conclusions compared to their ecologically valid modeling and evaluation. The paper advocates for a shift from word-sequence evaluation to behavior-sequence paradigms in NLP.",17.64,17.291,305,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.07994v2_DYCP Dynamic Context Pruning for Long-Form Dialogu.pdf,DYCP: Dynamic Context Pruning for Long-Form Dialogue with LLMs,"Nayoung Choi, Jonathan Zhang, Jinho D. Choi",,,"Large Language Models, context management, dialogue systems, context pruning, long-form dialogue, response latency, answer quality","Large Language Models (LLMs) often exhibit increased response latency and degraded answer quality as dialogue length grows, making effective context management essential. Existing methods rely on extra LLM calls to build memory or perform offline memory construction without considering the current user utterance, which can introduce inefficiencies or disrupt conversational continuity. This paper introduces DYCP, a lightweight context management method that dynamically segments and retrieves relevant memory at query time. It preserves the sequential structure of dialogue without predefined topic boundaries and supports efficient, adaptive context retrieval. Across three long-form dialogue benchmarks—LoCoMo, MT-Bench+, and SCM4LLMs—and multiple LLMs, DyCP consistently improves answer quality while reducing response latency. The paper also examines the gap between modern LLMs’ expanded context windows and their actual long-context processing capacity, highlighting the continued importance of effective context management.",17.28,16.548,286,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08000v1_Reasoning over Precedents Alongside Statutes Case-.pdf,Reasoning over Precedents Alongside Statutes: Case-Augmented Deliberative Alignment for LLM Safety,"Can Jin, Rui Wu, Tong Che, Qixin Zhang, Hongwu Peng, Jiahui Zhao, Zhenting Wang, Wenqi Wei, Ligong Han, Zhao Zhang, Yuan Cao, Ruixiang Tang, Dimitris N. Metaxas",,,"Large Language Models, safety, deliberative alignment, case-augmented reasoning, reinforcement learning, LLM safety","Ensuring that Large Language Models (LLMs) adhere to safety principles without refusing benign requests remains a significant challenge. This work evaluates the impact of specifying extensive safety codes versus demonstrating them through illustrative cases. It finds that case-augmented simple codes yield more robust and generalized safety behaviors. The proposed CADA method enhances harmlessness, improves robustness against attacks, and reduces over-refusal while preserving utility across diverse benchmarks, offering a practical alternative to rule-only deliberative alignment for improving safety while maintaining helpfulness.",16.84,17.217,290,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08003v1_LLM Review Enhancing Creative Writing via Blind Pe.pdf,LLM Review: Enhancing Creative Writing via Blind Peer Review Feedback,"Weiyue Li, Mingxiao Song, Zhenda Shen, Dachuan Zhao, Yunfan Long, Yi Li, Yongce Li, Ruyi Yang, Mengyu Wang",,,"Large Language Models, creative writing, peer review, multi-agent frameworks, creativity, content homogenization, SciFi-100 dataset, LLM-as-a-judge scoring, human annotation, rule-based novelty metrics","Large Language Models (LLMs) often struggle with creative generation, and multi-agent frameworks that improve reasoning through interaction can paradoxically hinder creativity by inducing content homogenization. This paper introduces LLM Review, a peer-review-inspired framework implementing Blind Peer Review, where agents exchange targeted feedback while revising independently, preserving divergent creative trajectories. The framework is evaluated using the SciFi-100 dataset, which combines LLM-as-a-judge scoring, human annotation, and rule-based novelty metrics. Experiments demonstrate that LLM Review consistently outperforms multi-agent baselines, and smaller models with this framework can surpass larger single-agent models, suggesting that interaction structure may substitute for model scale.",17.6,17.895,315,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08005v1_Internal Deployment Gaps in AI Regulation.pdf,Internal Deployment Gaps in AI Regulation,"JOE KWON, STEPHEN CASPER",,,"AI regulation, internal deployment, AI Act, General-Purpose AI Code of Practice, regulatory gaps","This paper examines how frontier AI regulations in the United States and European Union in 2025 handle internal deployment. It identifies three gaps that could cause internally-deployed systems to evade intended oversight: scope ambiguity, point-in-time compliance assessments, and information asymmetries. The paper analyzes why these gaps persist, examining tensions around measurability, incentives, and information access. It maps potential approaches to address these gaps and their associated tradeoffs, aiming to inform deliberate policy choices around internally deployed AI systems.",14.82,11.61,172,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08011v1_TP-Blend Textual-Prompt Attention Pairing for Prec.pdf,TP-Blend: Textual-Prompt Attention Pairing for Precise Object-Style Blending in Diffusion Models,"Xin Jin, Yichuan Zhong, Yapeng Tian",,arXiv:2601.08011v1,"text-conditioned diffusion editors, object replacement, style introduction, attention processors, optimal transport problem, self-attention, image editing, diffusion models, object blending","Current text-conditioned diffusion editors handle single object replacement well but struggle when a new object and a new style must be introduced simultaneously. We present Twin-PromptAttention Blend(TP-Blend), a lightweight, training-free framework that receives two separate textual prompts, one specifying a blend object and the other defining a target style, and injects both into a single denoising trajectory. TP-Blend is driven by two complementary attention processors. Cross-Attention Object Fusion (CAOF) first averages head-wise attention to locate spatial tokens that respond strongly to either prompt, then solves an entropy-regularised optimal transport problem that reassigns complete multi-head feature vectors to those positions. CAOF updates feature vectors at the full combined dimensionality of all heads (e.g., 640 dimensions in SD-XL), preserving rich cross-head correlations while keeping memory low. Self-Attention Style Fusion (SASF) injects style at every self-attention layer through Detail-Sensitive Instance Normalization. A lightweight one-dimensional Gaussian filter separates low- and high-frequency components; only the high-frequency residual is blended back, imprinting brush-stroke-level texture without disrupting global geometry. SASF further swaps the Key and Value matrices with those derived from the style prompt, enforcing context-aware texture modulation that remains independent of object fusion. Extensive experiments show that TP-Blend produces high-resolution, photo-realistic edits with precise control over both content and appearance, surpassing recent baselines in quantitative fidelity, perceptual quality, and inference speed.",19.57,22.991,450,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08017v1_Representations of Text and Images Align From Laye.pdf,Representations of Text and Images Align From Layer One,"Evˇzen Wybitul, Javier Rando, Florian Tram`er, Stanislav Fort",,arXiv:2601.08017v1,"vision-language models, adapter-based models, image-text alignment, DeepDream, model interpretability","This paper demonstrates that in adapter-based vision-language models, the representations of images and their text descriptions are aligned from the very first layer, contrary to the belief that such alignment only occurs in later layers. Using a synthesis-based method inspired by DeepDream, the authors extract concept vectors for textual concepts and synthesize images whose representations align with these vectors. This approach is applied to hundreds of concepts across seven layers in Gemma 3, revealing that even at layer 1, a significant portion of synthesized images depict recognizable features of the targeted textual concepts. The method provides direct evidence of image-text alignment on a concept-by-concept and layer-by-layer basis, offering a new path towards model interpretability without requiring auxiliary models or datasets.",17.97,14.914,268,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08026v2_FigEx2 Visual-Conditioned Panel Detection and Capt.pdf,FigEx2: Visual-Conditioned Panel Detection and Captioning for Scientific Compound Figures,"Jifeng Song, Arun Das, Pan Wang, Hui Ji, Kun Zhao, Yufei Huang",,,"compound figures, panel detection, captioning, multimodal consistency, zero-shot transferability, scientific literature","Scientific compound figures combine multiple labeled panels into a single image, but captions in real pipelines are often missing or only provide figure-level summaries, making panel-level understanding difficult. This paper proposes FigEx2, a visual-conditioned framework that localizes panels and generates panel-wise captions directly from the compound figure. To address diverse phrasing in open-ended captioning, a noise-aware gated fusion module is introduced to filter token-level features and stabilize the detection query space. A staged optimization strategy combining supervised learning with reinforcement learning (RL) is employed, utilizing CLIP-based alignment and BERTScore-based semantic rewards to enforce strict multimodal consistency. A refined benchmark, BioSci-Fig-Cap, is curated for panel-level grounding, alongside cross-disciplinary test suites in physics and chemistry. Experimental results show that FigEx2 achieves a superior 0.726 mAP@0.5:0.95 for detection and significantly outperforms Qwen3-VL-8B by 0.51 in METEOR and 0.24 in BERTScore. Notably, FigEx2 exhibits remarkable zero-shot transferability to out-of-distribution scientific domains without any fine-tuning.",18.68,19.592,366,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08043v1_The Role of Noisy Data in Improving CNN Robustness.pdf,The Role of Noisy Data in Improving CNN Robustness for Image Classification,"Oscar H. Ramírez-Agudelo, Nicoleta Gorea, Aliza Reif, Lorenzo Bonasera, Michael Karl",,,"deep learning, CNNs, data quality, CIFAR-10, noise injection, image classification, model robustness","Data quality is crucial for the performance and robustness of convolutional neural networks (CNNs) in image classification. This paper explores the impact of introducing controlled noise into training data to enhance model robustness. Using the CIFAR-10 dataset, the study evaluates the effects of Gaussian noise, Salt-and-Pepper noise, and Gaussian blur at various intensities and training set pollution levels. Experiments with a Resnet-18 model show that incorporating 10% noisy data during training significantly reduces test loss and improves accuracy under fully corrupted test conditions, with minimal impact on clean-data performance. These findings suggest that strategic noise exposure can serve as an effective regularizer, balancing traditional data cleanliness with real-world resilience.",17.22,14.812,255,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08049v1_Integrating Attendance Tracking and Emotion Detect.pdf,Integrating Attendance Tracking and Emotion Detection for Enhanced Student Engagement in Smart Classrooms,"Keith Ainebyona, Ann Move Oguti, Joseph Walusimbi, Ritah Kobusingye",,,"Affective computing, Attendance automation, Emotion detection, IoT, Smart classroom","The increasing adoption of smart classroom technologies in higher education has mainly focused on automating attendance, with limited attention given to students' emotional and cognitive engagement during lectures. This paper presents SCASED (Smart Classroom Attendance System with Emotion Detection), an IoT-based system that integrates automated attendance tracking with facial emotion recognition to support classroom engagement monitoring. The system uses a Raspberry Pi camera and OpenCV for face detection, and a fine-tuned MobileNetV2 model to classify four learning-related emotional states: engagement, boredom, confusion, and frustration. A session-based mechanism is implemented to manage attendance and emotion monitoring by recording attendance once per session and performing continuous emotion analysis thereafter. Attendance and emotion data are visualized through a cloud-based dashboard to provide instructors with insights into classroom dynamics. Experimental evaluation using the DAiSEE dataset achieved an emotion classification accuracy of 89.5%. The results show that integrating attendance data with emotion analytics can provide instructors with additional insight into classroom dynamics and support more responsive teaching practices.",19.48,14.989,292,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08052v1_Forecast Aware Deep Reinforcement Learning for Eff.pdf,Forecast Aware Deep Reinforcement Learning for Efficient Electricity Load Scheduling in Dairy Farms,"Nawazish Ali, Rachael Shaw, Karl Mason",,2601.08052v1,cs.AI,"Dairy farming is an energy intensive sector that relies heavily on grid electricity. With increasing renewable energy integration, sustainable energy management has become essential for reducing grid dependence and supporting the United Nations Sustainable Development Goal 7 on affordable and clean energy. However, the intermittent nature of renewables poses challenges in balancing supply and demand in real time. Intelligent load scheduling is therefore crucial to minimize operational costs while maintaining reliability. Reinforcement Learning has shown promise in improving energy efficiency and reducing costs; however, most RL-based scheduling methods assume complete knowledge of future prices or generation, which is unrealistic in dynamic environments. Moreover, standard PPO variants rely on fixed clipping or KL-divergence thresholds, often leading to unstable training under variable tariffs. To address these challenges, this study proposes a Deep Reinforcement Learning framework for efficient load scheduling in dairy farms, focusing on battery storage and water heating under realistic operational constraints. The proposed Forecast-Aware PPO incorporates short-term forecasts of demand and renewable generation using hour-of-day and month-based residual calibration, while the PID-KL PPO variant employs a proportional–integral–derivative controller to regulate KL-divergence for stable policy updates adaptively. Trained on real-world dairy farm data, the method achieves up to 1% lower electricity cost than PPO, 4.8% than DQN, and 1.5% than SAC. For battery scheduling, PPO reduces grid imports by 13.1%, demonstrating scalability and effectiveness for sustainable energy management in modern dairy farming.",20.5,19.023,390,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08058v1_Reasoning Beyond Chain-of-Thought A Latent Computa.pdf,Reasoning Beyond Chain-of-Thought: A Latent Computational Mode in Large Language Models,"Zhenghao He, Guangzhi Xiong, Bohan Liu, Sanchit Sinha, Aidong Zhang",,,"Chain-of-Thought, Large Language Models, Sparse Autoencoders, Latent Features, Reasoning, Latent Steering","Chain-of-Thought (CoT) prompting has improved the reasoning performance of large language models (LLMs), but it remains unclear why it works and whether it is the unique mechanism for triggering reasoning in LLMs. This study analyzes and intervenes on the internal representations of LLMs with Sparse Autoencoders (SAEs), identifying a small set of latent features causally associated with LLM reasoning behavior. Across multiple model families and reasoning benchmarks, steering a single reasoning-related latent feature can substantially improve accuracy without explicit CoT prompting. For large models, latent steering achieves performance comparable to standard CoT prompting while producing more efficient outputs. The reasoning-oriented internal state is triggered early in generation and can override prompt-level instructions that discourage explicit reasoning. The results suggest that multi-step reasoning in LLMs is supported by latent internal activations that can be externally activated, while CoT prompting is one effective, but not unique, way of activating this mechanism.",17.41,17.119,298,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08065v1_A New Strategy for Verifying Reach-Avoid Specifica.pdf,A New Strategy for Verifying Reach-Avoid Specifications in Neural Feedback Systems,"Samuel I. Akinwande, Sydney M. Katz, Mykel J. Kochenderfer, Clark Barrett",,2601.08065v1,"neural feedback systems, reachability analysis, forward reachability, backward reachability, verification framework","Forward reachability analysis is the predominant approach for verifying reach-avoid properties in neural feedback systems—dynamical systems controlled by neural networks. This dominance stems from the limited scalability of existing backward reachability methods. In this work, we introduce new algorithms that compute both over- and under-approximations of backward reachable sets for such systems. We further integrate these backward algorithms with established forward analysis techniques to yield a unified verification framework for neural feedback systems. Neural feedback systems are increasingly prevalent in applications such as robotics, autonomous driving, and aerospace autonomy. Ensuring compliance with safety and design specifications is critical. Common approaches for verifying specification satisfaction include sampling, invariance analysis, and reachability analysis. Sampling is scalable but cannot provide formal guarantees. Invariance analysis offers formal guarantees but is difficult to implement. Reachability analysis provides formal guarantees but suffers from a trade-off between precision and scalability. Most existing methods for reachability analysis of neural feedback systems rely on forward analysis, which propagates the system dynamics forward to compute all possible states. This reliance arises because computing a backward pass through a neural network is particularly challenging. However, the exclusive use of forward analysis often amplifies the inherent limitations of reachability analysis.",19.88,18.464,367,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08070v1_Semantic Gravity Wells Why Negative Constraints Ba.pdf,Semantic Gravity Wells: Why Negative Constraints Backfire,Shailesh Rana,,,"negative constraints, language models, instruction-following, semantic pressure, mechanistic analysis","Negative constraints (instructions of the form 'do not use word X') are a fundamental test of instruction-following capability in large language models. Despite their simplicity, these constraints often fail. This paper presents a comprehensive investigation into the failure of negative instructions, introducing 'semantic pressure' as a measure of the model's intrinsic probability of generating the forbidden token. The study reveals a logistic relationship between violation probability and pressure, and identifies two distinct failure modes: priming failure and override failure. The findings highlight a fundamental tension in negative constraint design, where mentioning a forbidden word paradoxically primes the model to produce it.",15.34,12.583,193,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08079v1_MemoBrain Executive Memory as an Agentic Brain for.pdf,MemoBrain: Executive Memory as an Agentic Brain for Reasoning,"Hongjin Qian, Zhao Cao, Zheng Liu",,,"executive memory, tool-augmented agents, large language models, long-horizon reasoning, cognitive control, memory mechanisms","Complex reasoning in tool-augmented agent frameworks is inherently long-horizon, causing reasoning traces and transient tool artifacts to accumulate and strain the bounded working context of large language models. Without explicit memory mechanisms, such accumulation disrupts logical continuity and undermines task alignment. This positions memory as a core component for sustaining coherent, goal-directed reasoning over long horizons. The paper proposes MemoBrain, an executive memory model for tool-augmented agents that constructs a dependency-aware memory over reasoning steps, capturing salient intermediate states and their logical relations. Operating as a co-pilot alongside the reasoning agent, MemoBrain organizes reasoning progress without blocking execution and actively manages the working context. Specifically, it prunes invalid steps, folds completed sub-trajectories, and preserves a compact, high-salience reasoning backbone under a fixed context budget. These mechanisms enable explicit cognitive control over reasoning trajectories rather than passive context accumulation. The model is evaluated on challenging long-horizon benchmarks, demonstrating consistent improvements over strong baselines.",17.36,16.644,289,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08089v1_Q-realign Piggybacking Realignment on Quantization.pdf,Q-realign: Piggybacking Realignment on Quantization for Safe and Efficient LLM Deployment,"Qitao Tan, Xiaoying Song, Ningxi Cheng, Ninghao Liu, Xiaoming Zhai, Lingzi Hong, Yanzhi Wang, Zhen Xiang, Geng Yuan",,,"Large Language Models, Safety Alignment, Fine-tuning, Quantization, Post-hoc Defense, Deployment","Public large language models (LLMs) are typically safety-aligned during pretraining, but task-specific fine-tuning often erodes this alignment, introducing safety risks. Existing defenses either embed safety recovery into fine-tuning or rely on fine-tuning-derived priors for post-hoc correction, leading to high computational overhead and complex workflows. This paper proposes Q-realign, a post-hoc defense method based on post-training quantization, guided by an analysis of representational structure. By reframing quantization as a dual-objective procedure for compression and safety, Q-realign decouples safety alignment from fine-tuning and integrates naturally into modern deployment pipelines. Experiments show that Q-realign substantially reduces unsafe behaviors while preserving task performance, with significant reductions in memory usage and GPU hours. The method can recover the safety alignment of a fine-tuned 7B LLM on a single RTX 4090 within 40 minutes, providing a practical, turnkey solution for safety-aware deployment.",18.1,19.608,355,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08094v1_Local-Global Feature Fusion for Subject-Independen.pdf,Local-Global Feature Fusion for Subject-Independent EEG Emotion Recognition,"Zheng Zhou, Isabella McEvoy, Camilo E. Valderrama",,,"EEG Emotion Recognition, Subject-Independent, Feature Fusion, Local Descriptors, Global Descriptors, Cross-Subject Generalization, Transformer, Domain-Adversarial Regularization","Subject-independent EEG emotion recognition faces challenges due to inter-subject variability and the difficulty of learning robust representations from short, noisy recordings. This paper proposes a fusion framework integrating local, channel-wise descriptors and global, trial-level descriptors to improve cross-subject generalization on the SEED-VII dataset. Local representations are formed per channel by concatenating differential entropy with graph-theoretic features, while global representations summarize time-domain, spectral, and complexity characteristics at the trial level. These representations are fused in a dual-branch transformer with attention-based fusion and domain-adversarial regularization, with samples filtered by an intensity threshold. Experiments under a leave-one-subject-out protocol demonstrate that the proposed method consistently outperforms single-view and classical baselines, achieving approximately 40% mean accuracy in 7-class subject-independent emotion recognition.",18.05,16.343,295,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08104v1_High-Fidelity Modeling of Stochastic Chemical Dyna.pdf,HIGH-FIDELITY MODELING OF STOCHASTIC CHEMICAL DYNAMICS ON COMPLEX MANIFOLDS: A MULTI-SCALE SIREN-PINN FRAMEWORK FOR THE CURVATURE-PERTURBED GINZBURG-LANDAU EQUATION,"Julian Evan Chrisnanto, Salsabila Rahma Alia, Nurfauzi Fadillah, Yulison Herry Chrisnanto",,2601.08104v1,"Physics-Informed Neural Networks (PINNs), Spatiotemporal Chaos, Inverse Geometric Problems, Reaction-Diffusion Systems, Defect Turbulence, Riemann Manifold Learning","The accurate identification and control of spatiotemporal chaos in reaction-diffusion systems remains a grand challenge in chemical engineering, particularly when the underlying catalytic surface possesses complex, unknown topography. In the Defect Turbulence regime, system dynamics are governed by topological phase singularities (spiral waves) whose motion couples to manifold curvature via geometric pinning. Conventional Physics-Informed Neural Networks (PINNs) using ReLU or Tanh activations suffer from fundamental spectral bias, failing to resolve high-frequency gradients and causing amplitude collapse or phase drift. We propose a Multi-Scale SIREN-PINN architecture leveraging periodic sinusoidal activations with frequency-diverse initialization, embedding the appropriate inductive bias for wave-like physics directly into the network structure. This enables simultaneous resolution of macroscopic wave envelopes and microscopic defect cores. Validated on the complex Ginzburg-Landau equation evolving on latent Riemannian manifolds, our architecture achieves relative state prediction error ϵL2 ≈1.92×10 −2, outperforming standard baselines by an order of magnitude while preserving topological invariants ( |∆Ndefects|<1 ). We solve the ill-posed inverse pinning problem, reconstructing hidden Gaussian curvature fields solely from partial observations of chaotic wave dynamics (Pearson correlation ρ= 0.965 ). Training dynamics reveal a distinctive Spectral Phase Transition at epoch ∼2,100 , where cooperative minimization of physics and geometry losses drives the solver to Pareto-optimal solutions. This work establishes a new paradigm for Geometric Catalyst Design, offering a mesh-free, data-driven tool for identifying surface heterogeneity and engineering passive control strategies in turbulent chemical reactors.",20.3,27.047,549,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08107v1_STO-RL Offline RL under Sparse Rewards via LLM-Gui.pdf,STO-RL: Offline RL under Sparse Rewards via LLM-Guided Subgoal Temporal Order,"Chengyang Gu, Yuxin Pan, Hui Xiong, Yize Chen",https://doi.org/10.1145/nnnnnnn.nnnnnnn,,"Offline RL, Temporal order, Large Language Models","Offline reinforcement learning (RL) enables policy learning from pre-collected datasets, avoiding costly and risky online interactions, but it often struggles with long-horizon tasks involving sparse rewards. Existing goal-conditioned and hierarchical offline RL methods decompose such tasks and generate intermediate rewards to mitigate limitations of traditional offline RL, but usually overlook temporal dependencies among subgoals and rely on imprecise reward shaping, leading to suboptimal policies. To address these issues, we propose STO-RL (Offline RL using LLM-Guided Subgoal Temporal Order), an offline RL framework that leverages large language models (LLMs) to generate temporally ordered subgoal sequences and corresponding state-to-subgoal-stage mappings. Using this temporal structure, STO-RL applies potential-based reward shaping to transform sparse terminal rewards into dense, temporally consistent signals, promoting subgoal progress while avoiding suboptimal solutions. The resulting augmented dataset with shaped rewards enables efficient offline training of high-performing policies. Evaluations on four discrete and continuous sparse-reward benchmarks demonstrate that STO-RL consistently outperforms state-of-the-art offline goal-conditioned and hierarchical RL baselines, achieving faster convergence, higher success rates, and shorter trajectories. Ablation studies further confirm STO-RL’s robustness to imperfect or noisy LLM-generated subgoal sequences, demonstrating that LLM-guided subgoal temporal structures combined with theoretically grounded reward shaping provide a practical and scalable solution for long-horizon offline RL.",19.47,21.626,421,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08108v1_Debiasing Large Language Models via Adaptive Causa.pdf,Debiasing Large Language Models via Adaptive Causal Prompting with Sketch-of-Thought,"Bowen Li, Ziqi Xu, Jing Ren, Renqiang Luo, Xikun Zhang, Xiuzhen Zhang, Yongli Ren, Feng Xia",,,"Large Language Models, Adaptive Causal Prompting, Sketch-of-Thought, Chain-of-Thought, Causal Inference, Bias Mitigation","This paper introduces an Adaptive Causal Prompting with Sketch-of-Thought (ACPS) framework to address the limitations of existing prompting methods for Large Language Models (LLMs), such as excessive token usage and limited generalisability. ACPS leverages structural causal models to infer the causal effect of a query on its answer and adaptively select appropriate interventions, enabling generalisable causal reasoning across diverse tasks without task-specific retraining. By replacing verbose Chain-of-Thought with concise Sketch-of-Thought, ACPS significantly reduces token usage and inference cost while improving accuracy, robustness, and computational efficiency. Extensive experiments demonstrate that ACPS outperforms existing prompting baselines across multiple reasoning benchmarks and LLMs.",16.9,15.741,266,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08109v1_CSQL Mapping Documents into Causal Databases.pdf,Csql: Mapping Documents into Causal Databases,Sridhar Mahadevan,,2601.08109v1,"Causality, Natural Language, Databases, SQL, AI, Machine Learning","We describe a novel system, Csql, that automatically converts a collection of unstructured text documents into an SQL-queryable causal database (CDB). A CDB differs from a traditional DB: it is designed to answer 'why' questions via causal interventions and structured causal queries. Csql builds on our earlier system, Democritus, which converts documents into thousands of local causal models derived from causal discourse. Unlike RAG-based systems or knowledge-graph–centric approaches, Csql supports causal analysis over document collections rather than purely associative retrieval. For example, given an article on the origins of human bipedal walking, Csql enables queries such as: 'What are the strongest causal influences on bipedalism?' or 'Which variables act as causal hubs with the largest downstream influence?' Beyond single-document case studies, we show that Csql can also ingest RAG/IE-compiled causal corpora at scale by compiling the Testing Causal Claims (TCC) dataset of economics papers into a causal database containing 265,656 claim instances spanning 45,319 papers, 44 years, and 1,575 reported method strings, thereby enabling corpus-level causal queries and longitudinal analyses in SQL. Conceptually, Csql converts document collections into causally grounded relational databases, enabling causal analysis via standard SQL. In contrast to prior work that relies on hand-designed ontologies, fixed schemas, or domain-specific information extraction pipelines, Csql induces its schema directly from language (or from language-compiled causal artifacts). Viewed abstractly, Csql functions as a compiler from unstructured documents into a causal database equipped with a principled algebra of queries, and can be applied broadly across many domains ranging from business, economics, humanities, and science.",20.08,22.262,447,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08118v1_MirrorBench An Extensible Framework to Evaluate Us.pdf,MIRRORBENCH: AN EXTENSIBLE FRAMEWORK TO EVALUATE USER-PROXY AGENTS FOR HUMAN-LIKENESS,"Ashutosh Hathidara, Julien Yu, Vaishali Senthil, Sebastian Schreiber, Anil Babu Ankisettipalli",,,"large language models, user simulators, dialogue systems, evaluation frameworks, human-like interactions, LLM-based evaluation","MIRRORBENCH is a reproducible, extensible benchmarking framework designed to evaluate user proxy agents based on their ability to produce human-like user utterances across diverse conversational tasks. It decouples evaluation from downstream task success and features a modular execution engine with typed interfaces, metadata-driven registries, multi-backend support, caching, and robust observability. The framework supports pluggable user proxies, datasets, tasks, and metrics, allowing researchers to evaluate simulators under a uniform, variance-aware harness. It includes lexical-diversity metrics (MATTR, YULE’S K, HD-D) and LLM-judge-based metrics (GTEVAL, PAIRWISE INDISTINGUISHABILITY, RUBRIC-AND-REASON). Results reveal gaps between user proxies and real human users, and the framework is open source with a command-line interface for running experiments and generating reports.",18.01,18.154,327,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08125v1_How vehicles change lanes after encountering crash.pdf,How vehicles change lanes after encountering crashes: Empirical analysis and modeling,"Kequan Chen, Yuxuan Wang, Pan Liu, Victor L. Knoop, David Z. W. Wang, Yu Han",,,,,12.38,6.059,75,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08127v1_PathoGen Diffusion-Based Synthesis of Realistic Le.pdf,PathoGen: Diffusion-Based Synthesis of Realistic Lesions in Histopathology Images,"Mohamad Koohi-Moghadam, Mohammad-Ali Nikouei Mahani, Kyongtae Tyler Bae",,,"histopathology, lesions, data augmentation, diffusion-based generative model, image synthesis, AI in medical diagnosis","The development of robust artificial intelligence models for histopathology diagnosis is severely constrained by the scarcity of expert-annotated lesion data, particularly for rare pathologies and underrepresented disease subtypes. PathoGen, a diffusion-based generative model, enables controllable, high-fidelity inpainting of lesions into benign histopathology images. It synthesizes lesions with natural tissue boundaries, preserved cellular structures, and authentic staining characteristics. PathoGen outperforms state-of-the-art generative baselines in image fidelity and distributional similarity across kidney, skin, breast, and prostate pathology datasets. Augmenting training sets with PathoGen-synthesized lesions enhances downstream segmentation performance, particularly in data-scarce regimes, and overcomes the manual annotation bottleneck, offering a scalable pathway for developing generalizable medical AI systems.",18.57,15.832,294,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08128v1_Embedded AI Companion System on Edge Devices.pdf,Embedded AI Companion System on Edge Devices,"Rahul Gupta, Stephen Hsu",,2601.08128v1,"AI companion, edge devices, computational constraints, memory systems, latency, personalization, offline processing, privacy, cost reduction, internet connectivity","This paper addresses the challenge of developing an AI companion system for edge devices with limited computational resources. It proposes a memory paradigm that alternates between active and inactive phases to minimize latency and maintain personalization. The system performs low-latency dialog during user activity and intensive memory maintenance during inactivity. An AI Companion benchmark is introduced to evaluate conversational quality and memory capabilities. Experiments show that the proposed system, using a quantized model, outperforms a raw LLM without memory and is comparable to GPT-3.5 with a 16k context window. The paper emphasizes the benefits of running companion systems offline on edge devices, including enhanced privacy, reduced costs, and functionality in areas with limited internet connectivity.",17.48,14.928,261,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08133v1_How Do Optical Flow and Textual Prompts Collaborat.pdf,How Do Optical Flow and Textual Prompts Collaborate to Assist in Audio-Visual Semantic Segmentation?,"Peng Gao, Yujian Lee, Yongqi Xu, Wentao Fan",,,"Audio-visual semantic segmentation, optical flow, textual prompts, semantic analysis, segmentation mask, visual-textual alignment, cross-modal integration","Audio-visual semantic segmentation (AVSS) extends audio-visual segmentation (AVS) by requiring semantic understanding of audio-visual scenes. This paper introduces a novel framework, Stepping Stone Plus (SSP), which integrates optical flow and textual prompts to enhance segmentation. Optical flow captures motion dynamics for moving sound sources, while textual prompts address stationary sound-emitting objects. A visual-textual alignment module (VTA) is implemented for cross-modal integration, improving semantic interpretation. Experimental results show SSP outperforms existing AVS methods, providing efficient and precise segmentation.",16.45,14.836,244,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08139v1_Subspace Alignment for Vision-Language Model Test-.pdf,Subspace Alignment for Vision-Language Model Test-time Adaptation,"Zhichen Zeng, Wenxuan Bao, Xiao Lin, Ruizhong Qiu, Tianxin Wei, Xuying Ning, Yuchen Yan, Chen Luo, Monica Xiao Cheng, Jingrui He, Hanghang Tong",,,"Vision-Language Models, Test-time Adaptation, Distribution Shifts, Subspace Alignment, Zero-shot Predictions, Semantic Subspaces","Vision-language models (VLMs) exhibit remarkable zero-shot capabilities but are susceptible to distribution shifts. Test-time adaptation (TTA) is a strategy to adapt VLMs to unlabeled test data. Existing TTA methods rely on zero-shot predictions as pseudo-labels, which can be unreliable under distribution shifts. This paper introduces SubTTA, which aligns the semantic subspaces of visual and textual modalities to enhance zero-shot predictions and guide the TTA process. SubTTA addresses the modality gap by aligning visual and textual subspaces and eliminates visual noise by projecting visual features onto task-specific textual subspaces. Extensive experiments show that SubTTA improves performance over state-of-the-art TTA methods by an average of 2.24%.",17.64,18.144,320,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08141v1_Qalb Largest State-of-the-Art Urdu Large Language .pdf,Qalb: Largest State-of-the-Art Urdu Large Language Model for 230M Speakers with Systematic Continued Pre-training,"Muhammad Taimoor Hassan, Jawad Ahmed, Muhammad Awais",,,"Urdu language model, continued pre-training, low-resource NLP, LoRA, language adaptation","Despite remarkable progress in large language models, Urdu—a language spoken by over 230 million people—remains critically underrepresented in modern NLP systems. Existing multilingual models demonstrate poor performance on Urdu-specific tasks, struggling with the language’s complex morphology, right-to-left Nastaliq script, and rich literary traditions. Even the base LLaMA-3.1 8B-Instruct model shows limited capability in generating fluent, contextually appropriate Urdu text. We introduce Qalb, an Urdu language model developed through a two-stage approach: continued pre-training followed by supervised fine-tuning. Starting from LLaMA 3.1 8B, we perform continued pre-training on a dataset of 1.97 billion tokens. This corpus comprises 1.84 billion tokens of diverse Urdu text—spanning news archives, classical and contemporary literature, government documents, and social media—combined with 140 million tokens of English Wikipedia data to prevent catastrophic forgetting. We then fine-tune the resulting model on the Alif Urdu-instruct dataset. Through extensive evaluation on Urdu-specific benchmarks, Qalb demonstrates substantial improvements, achieving a weighted average score of 90.34 and outperforming the previous state-of-the-art Alif-1.0-Instruct model (87.1) by 3.24 points, while also surpassing the base LLaMA-3.1 8B-Instruct model by 44.64 points. Qalb achieves state-of-the-art performance with comprehensive evaluation across seven diverse tasks including Classification, Sentiment Analysis, and Reasoning. Our results demonstrate that continued pre-training on diverse, high-quality language data, combined with targeted instruction fine-tuning, effectively adapts foundation models to low-resource languages.",19.69,22.856,450,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08146v2_Mechanisms are Transferable Data-Efficient Low-Res.pdf,Mechanisms are Transferable: Data-Efficient Low-Resource Adaptation via Circuit-Targeted Supervised Fine-Tuning,"Khumaisa Nur’aini, Ayu Purwarianti, Alham Fikri Aji, Derry Wijaya",,,"low-resource adaptation, language models, fine-tuning, catastrophic forgetting, mechanistic interpretability, sparse updates, cross-lingual transfer","Adapting large language models (LLMs) to low-resource languages is challenging due to the scarcity of labeled data, instability in full-model fine-tuning, and catastrophic forgetting during cross-lingual tuning. This paper introduces Circuit-Targeted Supervised Fine-Tuning (CT-SFT), a method that identifies a sparse set of task-relevant attention heads in a proxy-language checkpoint and transfers learning to a target language by updating only those heads and LayerNorm via head-level gradient masking. CT-SFT improves cross-lingual accuracy while updating a small subset of model parameters and reduces catastrophic forgetting, preserving source-language competence. The method leverages mechanistic interpretability to select parameters for adaptation, addressing the challenge of which parameters should be updated and which should be preserved.",17.33,17.482,303,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08148v1_Enriching Semantic Profiles into Knowledge Graph f.pdf,Enriching Semantic Profiles into Knowledge Graph for Recommender Systems Using Large Language Models,"Seokho Ahn, Sungbok Shin, Young-Duk Seo",10.1145/3770854.3780324,,"Recommendation, Semantic Profiling, Large Language Models, Knowledge Graphs","Rich and informative profiling to capture user preferences is essential for improving recommendation quality. This paper revisits recent profiling-based approaches in recommender systems along four dimensions: knowledge base, preference indicator, impact range, and subject. It argues that large language models (LLMs) are effective at extracting compressed rationales from diverse knowledge sources, while knowledge graphs (KGs) are better suited for propagating these profiles to extend their reach. The paper proposes a new recommendation model, SPiKE, which consists of three core components: Entity profile generation using LLMs, Profile-aware KG aggregation, and Pairwise profile preference matching. Experiments demonstrate that SPiKE consistently outperforms state-of-the-art KG- and LLM-based recommenders in real-world settings.",16.64,16.048,267,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08149v1_Dynamic Graph Structure Learning via Resistance Cu.pdf,Dynamic Graph Structure Learning via Resistance Curvature Flow,"Chaoqun Fei, Huanjiang Liu, Tinglve Zhou, Yan Yang Li, Tianyong Hao",,2601.08149v1,"dynamic graph structure learning, resistance curvature flow, circuit theory, geometric graph structure evolution, deep metric learning, manifold learning, graph structure learning","Introduces a novel and computationally efficient curvature flow based on effective resistance from circuit theory, establishing a new paradigm for geometric graph structure evolution. Formulates the dynamic evolution equation of RCF, elucidates its mechanisms for manifold enhancement and noise suppression, and highlights its differentiability and compatibility with deep learning frameworks. Proposes an efficient Dynamic Graph Structure Learning method based on RCF. Extensive experiments on deep metric learning, manifold learning, and graph structure learning tasks demonstrate that DGSL-RCF consistently improves representation quality and downstream performance with low runtime cost.",19.57,11.598,227,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08156v1_Project Synapse A Hierarchical Multi-Agent Framewo.pdf,Project Synapse: A Hierarchical Multi-Agent Framework with Hybrid Memory for Autonomous Resolution of Last-Mile Delivery Disruptions,"Arin Gopalan Yadav, Varad Dherange, Kumar Shivam",,2601.08156v1,"last-mile delivery, multi-agent systems, hybrid memory architecture, autonomous resolution, disruptions, LangGraph, LLM-as-a-Judge","The operational efficiency of super-apps is critically dependent on the performance of their last-mile delivery (LMD) networks, which are increasingly vulnerable to complex, real-time disruptions that traditional rule-based automation cannot effectively manage. This paper introduces Project Synapse, a novel agentic framework designed for the autonomous resolution of LMD disruptions. Synapse employs a hierarchical multi-agent architecture, where a central Resolution Supervisor agent performs strategic task decomposition and delegates sub-tasks to a team of specialized worker agents responsible for tactical execution. A core contribution of this work is a novel Hybrid Memory Architecture that integrates short-term working memory, long-term episodic memory of past incidents, and a semantic memory of organizational policies. This cognitive architecture enables agents to perform stateful, context-aware, and factually-grounded reasoning. The system is orchestrated using LangGraph to manage complex, cyclical workflows. To validate the framework, a benchmark dataset of 30 complex disruption scenarios was curated from a qualitative analysis of over 6,000 real-world user reviews. The system’s performance was evaluated using an LLM-as-a-Judge protocol with explicit bias mitigation. Initial results are highly promising.",20.4,18.043,368,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08160v1_SwiftMem Fast Agentic Memory via Query-aware Index.pdf,SwiftMem: Fast Agentic Memory via Query-aware Indexing,"Anxin Tian, Yiming Li, Xing Li, Hui-Ling Zhen, Lei Chen, Xianzhi Yu, Zhenhua Dong, Mingxuan Yuan",,,"agentic memory systems, LLM agents, memory retrieval, query-aware indexing, temporal indexing, semantic indexing, memory fragmentation, cache locality, real-time interactions","Agentic memory systems are crucial for enabling large language models (LLMs) to maintain long-term context and retrieve relevant information efficiently. Existing frameworks face latency issues due to exhaustive retrieval across entire memory storage, regardless of query characteristics. SwiftMem addresses this by implementing query-aware indexing over temporal and semantic dimensions, achieving sub-linear retrieval times. It introduces a temporal index for logarithmic-time range queries and a semantic DAG-Tag index for hierarchical topic mapping. Additionally, an embedding-tag co-consolidation mechanism reorganizes storage to improve cache locality. Experiments show SwiftMem is 47× faster than state-of-the-art baselines while maintaining competitive accuracy, facilitating practical deployment of memory-augmented LLM agents.",17.34,17.304,300,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08166v1_ZeroDVFS Zero-Shot LLM-Guided Core and Frequency A.pdf,ZeroDVFS: Zero-Shot LLM-Guided Core and Frequency Allocation for Embedded Platforms,"Mohammad Pivezhandi, Mahdi Banisharif, Abusayeed Saifullah, Ali Jannesari",,2601.08166v1,"Dynamic voltage and frequency scaling, thermal management, energy efficiency, multi-agent reinforcement learning, embedded systems, LLM-guided allocation","Dynamic voltage and frequency scaling (DVFS) and task-to-core allocation are critical for thermal management and balancing energy and performance in embedded systems. Existing approaches either rely on utilization-based heuristics that overlook stall times, or require extensive offline profiling for table generation, preventing runtime adaptation. This paper proposes a model-based hierarchical multi-agent reinforcement learning (MARL) framework for thermal- and energy-aware scheduling on multi-core platforms. Two collaborative agents decompose the exponential action space, achieving 358ms latency for subsequent decisions. First decisions require 3.5 to 8.0s including one-time LLM feature extraction. An accurate environment model leverages regression techniques to predict thermal dynamics and performance states. When combined with LLM-extracted semantic features, the environment model enables zero-shot deployment for new workloads on trained platforms by generating synthetic training data without requiring workload-specific profiling samples. The framework integrates direct reinforcement learning with model-based planning, achieving 20× faster convergence than model-free methods. Experiments demonstrate 7.09 × better energy efficiency and 4.0 × better makespan than Linux ondemand governor. First-decision latency is 8,300 times faster than table-based profiling, enabling practical deployment in dynamic embedded systems.",19.12,19.092,365,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08173v1_The Agents First Day Benchmarking Learning Explora.pdf,"The Agent’s First Day: Benchmarking Learning, Exploration, and Scheduling in the Workplace Scenarios","Daocheng Fu, Jianbiao Mei, Rong Wu, Xuemeng Yang, Jia Xu, Ding Wang, Pinlong Cai, Yong Liu, Licheng Wen, Botian Shi",,,"Multi-modal Large Language Models, workflow automation, dynamic task scheduling, active exploration, continuous learning, Trainee-Bench, dynamic evaluation environment, streaming tasks, real-world deployment","The rapid evolution of Multi-modal Large Language Models (MLLMs) has advanced workflow automation, but existing research mainly targets performance upper bounds in static environments, overlooking robustness for stochastic real-world deployment. This paper identifies three key challenges: dynamic task scheduling, active exploration under uncertainty, and continuous learning from experience. To address these, the authors introduce Trainee-Bench, a dynamic evaluation environment that simulates a 'trainee' agent continuously exploring a novel setting. Trainee-Bench evaluates agents along three dimensions: context-aware scheduling for streaming tasks with varying priorities, prudent information acquisition to reduce hallucination via active exploration, and continuous evolution by distilling generalized strategies from rule-based, dynamically generated tasks. Experiments show that cutting-edge agents have significant deficiencies in dynamic environments, especially in active exploration and continual learning. The work establishes a framework for assessing agent reliability, shifting evaluation from static tests to realistic, production-oriented scenarios.",18.29,19.791,362,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08176v1_Prompt-Based Clarity Evaluation and Topic Detectio.pdf,Prompt-Based Clarity Evaluation and Topic Detection in Political Question Answering,"Lavanya Prahallad, Sai Utkarsh Choudarypally, Pragna Prahallad, Pranathi Prahallad",,,"Clarity evaluation, Prompt engineering, Political Question–Answering, Large language models, Chain-of-thought prompting","Automatic evaluation of large language model (LLM) responses requires not only factual correctness but also clarity, particularly in political question–answering. This paper studies prompt-based clarity evaluation using the CLARITY dataset from the SemEval-2026 shared task. It compares a GPT-3.5 baseline with GPT-5.2 evaluated under three prompting strategies: simple prompting, chain-of-thought prompting, and chain-of-thought with few-shot examples. Results show that GPT-5.2 consistently outperforms the GPT-3.5 baseline on clarity prediction, with accuracy improving from 56% to 63% under chain-of-thought with few-shot prompting. Chain-of-thought prompting yields the highest evasion accuracy (34%), though improvements are less stable across fine-grained evasion categories. Reasoning-based prompting improves topic identification accuracy from 60% to 74% relative to human annotations. Overall, prompt design reliably improves high-level clarity evaluation, while fine-grained evasion and topic detection remain challenging despite structured reasoning prompts.",18.32,18.557,340,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08179v1_Instruction-Driven 3D Facial Expression Generation.pdf,Instruction-Driven 3D Facial Expression Generation and Transition,"Anh H. Vo, Tae-Seok Kim, Hulin Jin, Soo-Mi Choi, Yong-Guk Kim",10.1109/TMM.2025,,"Instruction-Driven, Facial Expression and Transition, Controllable Avatar, CK+ and CelebV-HQ datasets","This study presents a new framework for instruction-driven facial expression generation that produces a 3D face and transforms the facial expression from one designated expression to another. The Instruction-driven Facial Expression Decomposer (IFED) module facilitates multimodal data learning and captures the correlation between textual descriptions and facial expression features. The Instruction to Facial Expression Transition (I2FET) method leverages IFED and a vertex reconstruction loss function to refine the semantic comprehension of latent vectors, generating a facial expression sequence according to the given instruction. The Facial Expression Transition model generates smooth transitions between facial expressions. Extensive evaluation suggests that the proposed model outperforms state-of-the-art methods on the CK+ and CelebV-HQ datasets. The framework can generate facial expression trajectories according to text instruction, expanding the repertoire of facial expressions and transitions. The framework is expected to find various practical applications.",17.96,16.93,304,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08183v2_GI-Bench A Panoramic Benchmark Revealing the Knowl.pdf,GI-Bench: A Panoramic Benchmark Revealing the Knowledge-Experience Dissociation of Multimodal Large Language Models in Gastrointestinal Endoscopy Against Clinical Standards,"Yan Zhu, Te Luo, Pei-Yao Fu, Zhen Zhang, Zi-Long Wang, Yi-Fan Qu, Zi-Han Geng, Jia-Qi Xu, Lu Yao, Li-Yun Ma, Wei Su, Wei-Feng Chen, Quan-Lin Li, Shuo Wang, Ping-Hong Zhou",,,"Multimodal Large Language Models, Gastrointestinal Endoscopy, Clinical Standards, Benchmark, Diagnostic Reasoning","This study evaluates the performance of state-of-the-art Multimodal Large Language Models (MLLMs) in the context of gastrointestinal endoscopy. The research introduces GI-Bench, a comprehensive benchmark designed to assess MLLMs across a five-stage clinical workflow, including anatomical localization, lesion identification, diagnosis, findings description, and management. The benchmark includes 20 fine-grained lesion categories and compares the performance of twelve MLLMs against junior endoscopists and residency trainees. The evaluation metrics include Macro-F1, mean Intersection-over-Union (mIoU), and a multi-dimensional Likert scale. The study finds that Gemini-3-Pro achieves state-of-the-art performance, particularly in diagnostic reasoning, highlighting the potential and limitations of MLLMs in clinical settings.",19.89,18.498,368,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08185v1_Autonomous Materials Exploration by Integrating Au.pdf,Autonomous Materials Exploration by Integrating Automated Phase Identification and AI-Assisted Human Reasoning,"Ming-Chiang Chang, Maximilian Amsler, Duncan R. Sutherland, Sebastian Ament, Katie R. Gann, Lan Zhou, Louisa M. Smieska, Arthur R. Woll, John M. Gregoire, Carla P. Gomes, R. Bruce van Dover, Michael O. Thompson",,,"autonomous experimentation, artificial intelligence, materials science, phase identification, human-in-the-loop, robotic platforms, materials synthesis, oxide materials, lateral-gradient laser spike annealing, active learning","This paper presents an autonomous materials synthesis extension to SARA, the Scientific Autonomous Reasoning Agent, utilizing phase information from an automated probabilistic phase labeling algorithm to expedite the search for targeted phase regions. By incorporating human input into an expanded SARA-H framework, the efficiency of the reasoning process is enhanced. The study demonstrates the efficiency of AI implementation and the significant improvement in sampling efficiency due to human input. Experimental active learning campaigns using robotic processing of thin-film samples of several oxide material systems, including Bi2O3, SnOx, and Bi–Ti–O, are conducted. The utility of human-in-the-loop autonomous experimentation is showcased for the Bi–Ti–O system, identifying extensive processing domains that stabilize δ-Bi2O3 and Bi2Ti2O7, exploring dwell-dependent ternary oxide phase behavior, and providing evidence confirming predictions that cationic substitutional doping of TiO2 with Bi inhibits the transformation of the metastable anatase to the ground-state rutile phase. The developed autonomous methods enable the discovery of new materials and new understanding of materials synthesis and properties.",19.68,22.253,438,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08187v2_Improving LLM Reasoning with Homophily-aware Struc.pdf,IMPROVING LLM REASONING WITH HOMOPHILY-AWARE STRUCTURAL AND SEMANTIC TEXT-ATTRIBUTED GRAPH COMPRESSION,"Zijun Di, Bin Lu, Huquan Kang, Luoyi Fu, Jiaxin Ding, Xiaoying Gan, Lei Zhou, Xinbing Wang, Chenghu Zhou",,arXiv:2601.08187v2,"Large Language Models, Text-Attributed Graph, Graph Compression, Homophily, Structural Entropy, Semantic Aggregation","Large language models (LLMs) have demonstrated promising capabilities in Text-Attributed Graph (TAG) understanding. Recent studies typically focus on verbalizing the graph structures via handcrafted prompts, feeding the target node and its neighborhood context into LLMs. However, constrained by the context window, existing methods mainly resort to random sampling, often implemented via dropping node/edge randomly, which inevitably introduces noise and causes reasoning instability. We argue that graphs inherently contain rich structural and semantic information, and that their effective exploitation can unlock potential gains in LLMs reasoning performance. To this end, we propose Homophily-aware Structural and Semantic Compression for LLMs (HS2C), a framework centered on exploiting graph homophily. Structurally, guided by the principle of Structural Entropy minimization, we perform a global hierarchical partition that decodes the graph’s essential topology. This partition identifies naturally cohesive, homophilic communities, while discarding stochastic connectivity noise. Semantically, we deliver the detected structural homophily to the LLM, empowering it to perform differentiated semantic aggregation based on predefined community type. This process compresses redundant background contexts into concise community-level consensus, selectively preserving semantically homophilic information aligned with the target nodes. Extensive experiments on 10 node-level benchmarks across LLMs of varying sizes and families demonstrate that, by feeding LLMs with structurally and semantically compressed inputs, HS2C simultaneously enhances the compression rate and downstream inference accuracy, validating its superiority and scalability. Notably, on OGBN-ArXiv, it achieves a 94.98% graph scale compression while improving accuracy by 3.06%–4.92%. Extensions to 7 diverse graph-level benchmarks further consolidate HS2C’s task generalizability.",20.52,26.269,539,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08189v2_ForgetMark Stealthy Fingerprint Embedding via Targ.pdf,STEALTHY FINGERPRINT EMBEDDING VIA TARGETED UNLEARNING IN LANGUAGE MODELS,"Zhenhua Xu, Haobo Zhang, Zhebo Wang, Qichen Liu, Haitao Xu, Wenpeng Xing, Meng Han","© 2026 IEEE. Published in ICASSP 2026 – 2026 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), scheduled for 3–8 May 2026 in Barcelona, Spain.",,"Large Language Model, Copyright protection, Model Fingerprinting, Machine Unlearning","ForgetMark introduces a stealthy fingerprinting framework for language models, encoding provenance via targeted unlearning. It uses a compact, human-readable key–value set and trains lightweight LoRA adapters to suppress original values while preserving general capabilities. Ownership is verified under black/gray-box access by aggregating likelihood and semantic evidence. ForgetMark avoids high-perplexity triggers, reduces detectability, and lowers false triggers, achieving 100% ownership verification while maintaining standard performance. It surpasses backdoor baselines in stealthiness and robustness to model merging, and remains effective under moderate incremental fine-tuning.",17.61,17.039,300,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08196v1_Evaluating Implicit Regulatory Compliance in LLM T.pdf,Evaluating Implicit Regulatory Compliance in LLM Tool Invocation via Logic-Guided Synthesis,"Da Song, Yuheng Huang, Boqi Chen, Tianshuo Cong, Randy Goebel, Lei Ma, Foutse Khomh",,,"LLMs, regulatory compliance, safety constraints, logic-guided fuzzing, benchmarking, functional correctness","The integration of large language models (LLMs) into autonomous agents has enabled complex tool use, yet in high-stakes domains, these systems must strictly adhere to regulatory standards beyond simple functional correctness. Existing benchmarks often overlook implicit regulatory compliance, failing to evaluate whether LLMs can autonomously enforce mandatory safety constraints. To address this, the LOGISAFETYGEN framework converts unstructured regulations into Linear Temporal Logic oracles and employs logic-guided fuzzing to synthesize valid, safety-critical traces. Building on this, LOGISAFETYBENCH is constructed, comprising 240 human-verified tasks requiring LLMs to generate Python programs that satisfy both functional objectives and latent compliance rules. Evaluations of 13 state-of-the-art LLMs reveal that larger models, despite better functional correctness, often prioritize task completion over safety, resulting in non-compliant behavior.",17.79,17.762,316,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08211v1_Adapting Rules of Official International Mahjong f.pdf,Adapting Rules of Official International Mahjong for Online Players,"Chucai Wang, Lingfeng Li, Yunlong Lu, Wenxin Li",,,"Mahjong, game design, champion AI","This paper discusses the adaptation of Official International Mahjong rules for online play. Unlike offline play, online players face fragmented playtime and varying opponents, necessitating rule modifications to ensure fairness in single-round play. The study employs a world champion AI for self-play competitions and statistical analysis, revealing issues like first-mover advantage and subgoal scoring. Proposed adaptations include compensatory points for first-mover advantage and refined subgoal scores for different tile patterns. These changes aim to balance the game in online settings more effectively than traditional methods. The revised Mahjong game is implemented online, offering a new experience for players. This work leverages AI data to evaluate game balance and develop a version of Mahjong better suited for online play.",16.71,14.36,240,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08223v2_DNF Dual-Layer Nested Fingerprinting for Large Lan.pdf,Dual-Layer Nested Fingerprinting for Large Language Model Intellectual Property Protection,"Zhenhua Xu, Yiran Zhao, Mengting Zhong, Dezhang Kong, Changting Lin, Tong Qiao, Meng Han","© 2026 IEEE. Published in ICASSP 2026 – 2026 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), scheduled for 3–8 May 2026 in Barcelona, Spain.",,"Large Language Model, Copyright Protection, Model Fingerprinting, Backdoor","The paper addresses intellectual property protection for large language models under black-box deployment. It introduces Dual-Layer Nested Fingerprinting (DNF), a method that embeds a hierarchical backdoor using domain-specific stylistic cues and implicit semantic triggers. DNF achieves perfect fingerprint activation while preserving downstream utility and remains undetectable under fingerprint detection attacks. It is robust to incremental fine-tuning and model merging, making it a practical solution for LLM ownership verification and IP protection.",16.66,16.09,268,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08224v1_An Axiomatic Approach to General Intelligence SANC.pdf,An Axiomatic Approach to General Intelligence: Self-organizing Active Network of Concepts with EnergyE 3,"Daesuk Kwon, Won-gi Paeng",,arXiv:2601.08224v1,"axiomatization of intelligence, competitive selection, system tokens, reconstruction–compression trade-off, category formation, self-similar hierarchy, Gestalt completion","General intelligence must reorganize experience into internal structures that enable prediction and action under finite resources. Existing systems presuppose fixed primitive units, bypassing how representational units emerge and stabilize. This paper proposes SANC(E3), an axiomatic framework where representational units arise as stable outcomes of competitive selection, reconstruction, and compression under finite activation capacity, governed by the minimization of an energy functional E3. SANC(E3) distinguishes between system tokens and tokens emerging through self-organization. Five core axioms formalize finite capacity, association from co-occurrence, similarity-based competition, confidence-based stabilization, and the reconstruction–compression–update trade-off. A pseudo-memory-mapped I/O mechanism processes internally replayed Gestalts via the same axiomatic pathway as external sensory input, unifying perception, imagination, prediction, planning, and action. Twelve propositions derived from the axioms show that various cognitive activities can be understood as instances of Gestalt completion under E3 minimization.",18.85,17.936,338,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08226v1_Knowledge-based learning in Text-RAG and Image-RAG.pdf,Knowledge-based learning in Text-RAG and Image-RAG,"Alexander Shim, Khalil Saieh, Samuel Clarke",,,"Vision Transformer, EVA-ViT, LLaMA, ChatGPT, hallucination problem, chest x-ray images, NIH Chest X-ray, image-based RAG, text-based RAG, baseline, KNN methods, GPT LLM, Expected Calibration Error, data imbalance, multi-stage structure, multi-modal AI systems, radiology, diagnostic delays, workload pressures, vision transformers, large language models, medical interpretation, retrieval-augmented generation","This research analyzed and compared the multi-modal approach in the Vision Transformer (EVA-ViT) based image encoder with the LLaMA or ChatGPT LLM to reduce the hallucination problem and detect diseases in chest x-ray images. The study utilized NIH Chest X-ray images to train the model and compared it in image-based RAG, text-based RAG, and baseline. The text-based RAG effectively reduced the hallucination problem by using external knowledge information, and the image-based RAG improved prediction confidence and calibration using KNN methods. The GPT LLM showed better performance, a low hallucination rate, and better Expected Calibration Error (ECE) than the Llama-based model. The research highlights challenges such as data imbalance and complex multi-stage structures but suggests a large experience environment and balanced example use. The introduction discusses the need for rethinking traditional image-interpretation pipelines due to the rapid advancement of imaging technologies and the slower pace of interpretation capabilities. The study evaluates different retrieval-augmented generation (RAG) strategies in chest X-ray interpretation, focusing on comparing text-based RAG, image-based RAG, and a baseline multi-modal system.",19.76,22.724,449,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08230v1_GADPN Graph Adaptive Denoising and Perturbation Ne.pdf,GADPN: Graph Adaptive Denoising and Perturbation Networks via Singular Value Decomposition,"Hao Deng, Bo Liu",,,"Graph Neural Networks, Graph Structural Learning, Network Representation Learning","Graph Neural Networks (GNNs) excel on graph-structured data but are limited by the quality of the observed graph, which often contains noise, missing links, or misaligned structural properties. This paper introduces GADPN, a framework for graph structure learning that refines graph topology via low-rank denoising and generalized structural perturbation. Key contributions include using Bayesian optimization to adaptively determine denoising strength and extending structural perturbation to arbitrary graphs using Singular Value Decomposition (SVD). Experiments show GADPN achieves state-of-the-art performance with improved efficiency, especially on disassortative graphs.",15.29,12.622,193,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08235v2_MPCI-Bench A Benchmark for Multimodal Pairwise Con.pdf,MPCI-Bench: A Benchmark for Multimodal Pairwise Contextual Integrity,"Shouju Wang, Haopeng Zhang",,,"Multimodal Pairwise Contextual Integrity, privacy behavior, language model agents, Contextual Integrity, multimodal privacy risks, utility","As language-model agents evolve from passive chatbots into proactive assistants handling personal data, evaluating their adherence to social norms through Contextual Integrity (CI) becomes critical. Existing CI benchmarks are text-centric and focus on negative refusal scenarios, overlooking multimodal privacy risks and the privacy-utility trade-off. This paper introduces MPCI-Bench, the first Multimodal Pairwise Contextual Integrity benchmark for evaluating privacy behavior in agentic settings. MPCI-Bench includes paired positive and negative instances from the same visual source across three tiers: normative Seed judgments, context-rich Story reasoning, and executable agent action Traces. Data quality is ensured through a Tri-Principle Iterative Refinement pipeline. Evaluations reveal systematic failures in balancing privacy and utility and a modality leakage gap, where sensitive visual information is leaked more frequently than textual information.",16.85,15.548,262,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08237v1_The End of Reward Engineering How LLMs Are Redefin.pdf,The End of Reward Engineering: How LLMs Are Redefining Multi-Agent Coordination,"Haoran Su, Yandong Sun, Congjia Yu",,arXiv:2601.08237v1,"multi-agent reinforcement learning, reward engineering, large language models, semantic understanding, dynamic adaptation, human alignment","Reward engineering – the manual design of reward functions to guide agent behavior – remains a persistent bottleneck in multi-agent reinforcement learning. In multi-agent systems, this challenge is compounded by credit assignment ambiguity, environmental non-stationarity, and exponentially scaling complexity. Large language models (LLMs) enable a fundamental paradigm shift from hand-crafted numerical rewards to natural language objectives. LLMs can generate human-level reward functions from language descriptions alone, adapt rewards dynamically without human intervention, and coordinate agents through semantic understanding. The emergence of Reinforcement Learning from Verifiable Rewards (RLVR) further validates this trajectory, establishing language-based training as mainstream. The transition is supported by three pillars: semantic reward specification, dynamic adaptation, and inherent human alignment, while acknowledging challenges in computational cost, hallucination risks, and scalability. The vision is for multi-agent systems where coordination emerges from shared semantic understanding rather than engineered numerical signals.",18.9,15.976,302,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08251v1_Hyperbolic Heterogeneous Graph Transformer.pdf,Hyperbolic Heterogeneous Graph Transformer,"Jongmin Park, Seunghoon Han, Hyewon Lee, Won-Yong Shin, Sungsu Lim",,,"Heterogeneous Graph Representation Learning, Hyperbolic Graph Embedding, Graph Transformer","In heterogeneous graphs, complex structures such as tree-like or hierarchical structures are observed. The hyperbolic space has been widely adopted to effectively learn these structures. Existing methods face challenges like mapping distortions due to tangent-space operations and difficulty in capturing global hierarchical structures and long-range dependencies. The proposed Hyperbolic Heterogeneous Graph Transformer (HypHGT) addresses these limitations by learning graph representations entirely within the hyperbolic space. HypHGT captures both local and global dependencies through a transformer-based architecture and employs a relation-specific hyperbolic attention mechanism with linear time complexity. This design preserves heterogeneous information across different relation types and captures complex structural properties and semantic information. Comprehensive experiments show that HypHGT outperforms state-of-the-art methods in node classification tasks, with reduced training time and memory usage.",17.12,15.654,268,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08254v1_Large Artificial Intelligence Model Guided Deep Re.pdf,Large Artificial Intelligence Model–Guided Deep Reinforcement Learning for Resource Allocation in Non-Terrestrial Networks,"Abdikarim Mohamed Ibrahim, Rosdiadee Nordin",,,"Large AI Models (LAMs), Large Language Models (LLMs), Deep Reinforcement Learning (DRL), Satellite Communications, Non-Terrestrial Networks (NTNs)","Large AI Models (LAMs) have been proposed for applications in Non-Terrestrial Networks (NTN), offering improved performance through better generalization and reduced task-specific training. This paper introduces a Deep Reinforcement Learning (DRL) agent guided by a Large Language Model (LLM). The LLM acts as a high-level coordinator, generating textual guidance that shapes the reward of the DRL agent during training. Results indicate that the LAM-DRL outperforms traditional DRL by 40% in nominal weather scenarios and 64% in extreme weather scenarios compared to heuristics, in terms of throughput, fairness, and outage probability. The paper addresses challenges in NTN resource allocation, such as dynamic complexities, rapid topology changes, and the need for intelligent and adaptive solutions. It highlights the limitations of traditional optimization methods and DRL, proposing a hybrid approach using LLMs to enhance robustness and interpretability in NTNs.",17.86,17.523,313,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08257v2_On Evaluation of Unsupervised Feature Selection fo.pdf,On Evaluation of Unsupervised Feature Selection for Pattern Classification,"Gyu-Il Kim, Dae-Won Kim, Jaesung Lee",,2601.08257v2,"Unsupervised Feature Selection, Pattern Classification, Multi-label Classification, Feature Selection, Machine Learning","Unsupervised feature selection aims to identify a compact subset of features that captures the intrinsic structure of data without supervised labels. Most studies evaluate methods using single-label datasets, which can lead to inconsistent performance rankings due to arbitrary label selection. This study proposes a multi-label classification framework for a fairer evaluation of unsupervised feature selection methods. Experiments on 21 multi-label datasets show that performance rankings differ significantly from those in single-label settings, suggesting the need for multi-label evaluation for reliable comparisons.",16.59,12.599,209,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08258v1_T3 Benchmarking Sycophancy and Skepticism in Causa.pdf,Benchmarking Sycophancy and Skepticism in Causal Judgment,Edward Y. Chang,,,"causal judgment, LLM, Pearl’s Ladder of Causality, benchmark, skepticism trap, scaling paradox, RCA, causal reasoning, safety-induced refusal, utility, safety, sycophancy","The paper introduces T3 (Testing Trustworthy Thinking), a diagnostic benchmark designed to evaluate LLM causal judgment across Pearl’s Ladder of Causality. It comprises 454 expert-curated vignettes, focusing on high-resolution failure analysis by decomposing performance into Utility (sensitivity), Safety (specificity), and Wise Refusal on underdetermined cases. The benchmark identifies two pathologies: a 'Skepticism Trap' at L1 and a non-monotonic 'Scaling Paradox' at L3. The latter shows GPT-5.2 underperforming GPT-4-Turbo on ambiguous counterfactuals due to excessive hedging. The paper also validates a process-verified protocol (RCA) to restore decisive causal judgment under structured verification.",17.16,15.913,273,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08262v1_VGG Induced Deep Hand Sign Language Detection.pdf,VGG Induced Deep Hand Sign Language Detection,"Subham Sharma, Sharmila Subudhi",,2601.08262v1,"Hand gesture recognition, Convolutional neural network, Classification, VGG-16 net, API","Hand gesture recognition is an important aspect of human-computer interaction, forming the basis of sign language for visually impaired people. This work proposes a novel hand gesture recognizing system for differently-abled persons using a convolutional neural network, specifically the VGG-16 net, trained on a widely used image dataset with Python and Keras libraries. The model is validated using the NUS dataset, consisting of 10 classes of hand gestures, and further tested with a dataset built using Google’s open source API capturing various human hand gestures. The efficacy is measured through experiments, showing that combining transfer learning with image data augmentation, the VGG-16 net achieved around 98% accuracy.",18.63,12.669,236,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08271v1_Sparsity Is Necessary Polynomial-Time Stability fo.pdf,Sparsity Is Necessary: Polynomial-Time Stability for Agentic LLMs in Large Action Spaces,Angshul Majumdar,,arXiv:2601.08271v1,"LLMs, sequential decision-making, sparse agentic control, policy learning, large action spaces, tool-augmented systems","The paper addresses the challenge of sequential decision-making in large action spaces for tool-augmented large language models (LLMs). It introduces the concept of Sparse Agentic Control (SAC), where policies are block-sparse over a large number of actions. The study focuses on ℓ1,2-regularized policy learning and presents results on estimation and value suboptimality, tool-support recovery, and the necessity of sparsity for stability. It also discusses the impact of partial observability and extends the analysis to various settings including online and robust SAC. The paper reframes the central challenge in tool-augmented decision-making as control under extreme action dimensionality with latent sparsity.",16.71,14.299,239,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08273v1_HIPPO Accelerating Video Large Language Models Inf.pdf,HIPPO: Accelerating Video Large Language Models Inference via Holistic-aware Parallel Speculative Decoding,"Qitan Lv, Tianyu Liu, Wen Wu, Xuenan Xu, Bowen Zhou, Feng Wu, Chao Zhang",,,"speculative decoding, video large language models, inference acceleration, token pruning, semantic-aware token preservation, video parallel SD algorithm","Speculative decoding (SD) has emerged as a promising approach to accelerate LLM inference without sacrificing output quality. Existing SD methods tailored for video-LLMs primarily focus on pruning redundant visual tokens to mitigate the computational burden of massive visual inputs. However, these methods do not achieve inference acceleration comparable to text-only LLMs. This paper proposes HIPPO, a holistic-aware parallel speculative decoding framework, addressing limitations in existing methods by introducing a semantic-aware token preservation method and a video parallel SD algorithm. Experiments demonstrate HIPPO's effectiveness, yielding up to 3.51× speedup compared to vanilla autoregressive decoding.",16.95,15.692,266,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08276v1_ToolACE-MCP Generalizing History-Aware Routing fro.pdf,ToolACE-MCP: Generalizing History-Aware Routing from MCP Tools to the Agent Web,"Zhiyuan Yao, Zishan Xu, Yifu Guo, Zhiguang Han, Cheng Yang, Shuo Zhang, Weinan Zhang, Xingshan Zeng, Weiwen Liu",,,"Agent Web, Model Context Protocol, history-aware routing, large-scale ecosystems, multi-agent collaboration, open collaborative network, scalability, robustness, universal orchestration","With the rise of the Agent Web and Model Context Protocol (MCP), the agent ecosystem is evolving into an open collaborative network, exponentially increasing accessible tools. Current architectures face severe scalability and generality bottlenecks. To address this, we propose ToolACE-MCP, a pipeline for training history-aware routers to empower precise navigation in large-scale ecosystems. By leveraging a dependency-rich candidate Graph to synthesize multi-turn trajectories, we effectively train routers with dynamic context understanding to create the plug-and-play Light Routing Agent. Experiments on the real-world benchmarks MCP-Universe and MCP-Mark demonstrate superior performance. Notably, ToolACE-MCP exhibits critical properties for the future Agent Web: it not only generalizes to multi-agent collaboration with minimal adaptation but also maintains exceptional robustness against noise and scales effectively to massive candidate spaces. These findings provide a strong empirical foundation for universal orchestration in open-ended ecosystems.",17.91,19.546,350,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08280v1_Greedy Is Enough Sparse Action Discovery in Agenti.pdf,Greedy Is Enough: Sparse Action Discovery in Agentic LLMs,Angshul Majumdar,,,"agentic systems, large action spaces, sparse action discovery, block-sparse recovery, Orthogonal Matching Pursuit, linear reward model, sparsity, action pruning","Modern agentic systems operate in environments with extremely large action spaces, such as tool-augmented language models with thousands of available APIs or retrieval operations. Despite this scale, empirical evidence suggests that only a small subset of actions meaningfully influences performance in a given deployment. This work studies a contextual linear reward model with a structured sparsity assumption, where only a small number of actions have nonzero effects across latent states. Action discovery is formulated as a block-sparse recovery problem, and a greedy algorithm inspired by Orthogonal Matching Pursuit is analyzed. Under standard assumptions, the greedy procedure is shown to exactly recover the relevant action set with high probability, using a number of samples that scales polynomially in the sparsity level and latent dimension, and only logarithmically in the total number of actions. Estimation error guarantees for refitted parameters are provided, and the resulting decision rule is shown to be near-optimal for new latent states. Information-theoretic lower bounds demonstrate that sparsity and sufficient coverage are necessary for tractability. These results identify sparse action discovery as a fundamental principle underlying large-action decision-making and provide a theoretical foundation for action pruning in agentic systems.",18.6,17.316,322,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08288v1_OpenMic A Multi-Agent-Based Stand-Up Comedy Genera.pdf,OpenMic: A Multi-Agent-Based Stand-Up Comedy Generation System,"Yuyang Wu, Hanzhong Cao, Jianhao Chen, Yufei Li",,,"Chinese stand-up comedy generation, multi-agent system, AutoGen, retrieval-augmented generation, humor, timing, performability, stand-up-specific structures, long-range callbacks","Chinese stand-up comedy generation requires culturally grounded humor, precise timing, stage-performance cues, and implicit multi-step reasoning. Existing Chinese humor datasets are often better suited for humor understanding and evaluation than for long-form stand-up generation, leading to misalignment with the target task. To address these challenges, the paper presents OpenMic, an end-to-end multi-agent system built on AutoGen that transforms a user-provided life topic into a 3–5 minute Chinese stand-up performance and produces a narrated comedy video. OpenMic orchestrates multiple specialized agents in a multi-round iterative loop to optimize humor, timing, and performability. The system uses retrieval-augmented generation (RAG) for material grounding and idea expansion, and fine-tunes a dedicated JokeWriter to better internalize stand-up-specific setup–punchline structures and long-range callbacks.",18.04,17.131,309,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08297v1_Demystifying the Slash Pattern in Attention The Ro.pdf,Demystifying the Slash Pattern in Attention: The Role of RoPE,"Yuan Cheng, Fengzhuo Zhang, Yunlong Hou, Cunxiao Du, Chao Du, Tianyu Pang, Aixin Sun, Zhuoran Yang",,arXiv:2601.08297v1,"Large Language Models, Slash-Dominant Heads, Attention Patterns, Rotary Position Embedding, RoPE, Out-Of-Distribution Generalization","Large Language Models (LLMs) often exhibit slash attention patterns, where attention scores concentrate along the ∆-th sub-diagonal for some offset ∆. These patterns play a key role in passing information across tokens. This paper demystifies the emergence of these Slash-Dominant Heads (SDHs) from both empirical and theoretical perspectives. By analyzing open-source LLMs, it is found that SDHs are intrinsic to models and generalize to out-of-distribution prompts. The paper analyzes queries, keys, and Rotary Position Embedding (RoPE), which jointly determine attention scores. Two characteristic conditions of SDHs are identified: (1) Queries and keys are almost rank-one, and (2) RoPE is dominated by medium- and high-frequency components. These conditions lead to nearly identical queries and keys across tokens, and interactions between medium- and high-frequency components of RoPE give rise to SDHs. The study provides both empirical evidence and theoretical insights into the emergence of SDHs.",19.25,19.116,368,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08302v1_Enhancing Sentiment Classification and Irony Detec.pdf,Enhancing Sentiment Classification and Irony Detection in Large Language Models through Advanced Prompt Engineering Techniques,"Marvin Schmitt, Anne Schwerk, Sebastian Lempert",,,"sentiment analysis, irony detection, large language models (LLMs), prompt engineering","This study investigates the use of prompt engineering to enhance large language models (LLMs), specifically GPT-4o-mini and gemini-1.5-flash, in sentiment analysis tasks. It evaluates advanced prompting techniques like few-shot learning, chain-of-thought prompting, and self-consistency against a baseline. Key tasks include sentiment classification, aspect-based sentiment analysis, and detecting subtle nuances such as irony. The research details the theoretical background, datasets, and methods used, assessing performance of LLMs as measured by accuracy, recall, precision, and F1 score. Findings reveal that advanced prompting significantly improves sentiment analysis, with the few-shot approach excelling in GPT-4o-mini and chain-of-thought prompting boosting irony detection in gemini-1.5-flash by up to 46%. Thus, while advanced prompting techniques overall improve performance, the fact that few-shot prompting works best for GPT-4o-mini and chain-of-thought excels in gemini-1.5-flash for irony detection suggests that prompting strategies must be tailored to both the model and the task. This highlights the importance of aligning prompt design with both the LLM’s architecture and the semantic complexity of the task.",18.65,18.657,348,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08310v1_ORBIT On-policy Exploration-Exploitation for Contr.pdf,ORBIT: On-policy Exploration-Exploitation for Controllable Multi-Budget Reasoning,"Kun Liang, Clive Bai, Xin Xu, Chenming Tang, Sanwoo Lee, Weijie Liu, Saiyong Yang, Yunfang Wu",,,"Large Reasoning Models, Chain-of-Thought reasoning, Reinforcement Learning, Multi-budget reasoning, Operational efficiency","Recent Large Reasoning Models (LRMs) achieve strong performance by leveraging long-form Chain-of-Thought (CoT) reasoning, but uniformly applying overlong reasoning at inference time incurs substantial and often unnecessary computational cost. To address this, prior work explores various strategies to infer an appropriate reasoning budget from the input. However, such approaches are unreliable in the worst case, as estimating the minimal required reasoning effort is fundamentally difficult, and they implicitly fix the trade-off between reasoning cost and accuracy during training, limiting flexibility under varying deployment scenarios. Motivated by these limitations, we propose ORBIT, a controllable multi-budget reasoning framework with well-separated reasoning modes triggered by input. ORBIT employs multi-stage reinforcement learning to discover Pareto-optimal reasoning behaviors at each effort, followed by on-policy distillation to fuse these behaviors into a single unified model. Experiments show that ORBIT achieves controllable reasoning behavior over multiple modes, competitive reasoning density within each mode, and integration of these frontier policies into a single unified student model while preserving clear mode separation and high per-mode performance.",18.54,19.368,359,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08311v1_Enhancing Image Quality Assessment Ability of LMMs.pdf,Enhancing Image Quality Assessment Ability of LMMs via Retrieval-Augmented Generation,"Kang Fu, Huiyu Duan, Zicheng Zhang, Yucheng Zhu, Jun Zhao, Xiongkuo Min, Jia Wang, Guangtao Zhai",,,"Image quality assessment, Retrieval-Augmented Generation, Large Multimodal Models, Zero-shot, Training-free","Large Multimodal Models (LMMs) have shown promise in low-level visual perception tasks, particularly in Image Quality Assessment (IQA), with strong zero-shot capabilities. However, achieving state-of-the-art performance often requires computationally expensive fine-tuning methods. This paper introduces IQARAG, a novel, training-free framework that enhances LMMs' IQA ability using Retrieval-Augmented Generation (RAG). IQARAG retrieves semantically similar but quality-variant reference images with corresponding Mean Opinion Scores (MOSs) for the input image. These images are integrated into a specific prompt, providing a visual perception anchor for the IQA task. The framework consists of three key phases: Retrieval Feature Extraction, Image Retrieval, and Integration & Quality Score Generation. Extensive experiments across multiple IQA datasets demonstrate that IQARAG effectively boosts the IQA performance of LMMs, offering a resource-efficient alternative to fine-tuning for quality assessment.",18.27,18.558,339,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08323v1_AtomMem  Learnable Dynamic Agentic Memory with Ato.pdf,AtomMem: Learnable Dynamic Agentic Memory with Atomic Memory Operation,"Yupeng Huo, Yaxi Lu, Zhong Zhang, Haotian Chen, Yankai Lin",,,"memory management, dynamic decision-making, CRUD operations, reinforcement learning, long-context benchmarks, LLM-based agents, memory mechanisms","This paper introduces AtomMem, a flexible, learning-based memory framework for agents, addressing the limitations of static, hand-crafted memory workflows. AtomMem reframes memory management as a dynamic decision-making problem, utilizing atomic CRUD operations to create a learnable decision process. By integrating supervised fine-tuning with reinforcement learning, AtomMem develops an autonomous, task-aligned policy for memory management. Experimental results show that AtomMem-8B outperforms static-workflow methods across various benchmarks, demonstrating its ability to discover structured, task-aligned memory strategies.",15.93,14.881,237,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08327v1_Safe Heterogeneous Multi-Agent RL with Communicati.pdf,Safe Heterogeneous Multi-Agent RL with Communication Regularization for Coordinated Target Acquisition,"Gabriele Calzolari, Vidya Sumathy, Christoforos Kanellakis, George Nikolakopoulos",,,"Cooperative target acquisition, Safe autonomous coordination, Decentralized multi-agent reinforcement learning, Heterogeneous robotic systems, Learning-based control","This paper introduces a decentralized multi-agent reinforcement learning framework enabling structurally heterogeneous teams of agents to jointly discover and acquire randomly located targets in environments characterized by partial observability, communication constraints, and dynamic interactions. Each agent’s policy is trained with the Multi-Agent Proximal Policy Optimization algorithm and employs a Graph Attention Network encoder that integrates simulated range-sensing data with communication embeddings exchanged among neighboring agents, enabling context-aware decision-making from both local sensing and relational information. The work introduces a unified framework that integrates graph-based communication and trajectory-aware safety through safety filters, supported by a structured reward formulation designed to encourage effective target discovery and acquisition, collision avoidance, and de-correlation between the agents’ communication vectors by promoting informational orthogonality. The effectiveness of the proposed reward function is demonstrated through a comprehensive ablation study, and simulation results confirm safe and stable task execution.",17.92,16.681,299,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08332v1_IGAN A New Inception-based Model for Stable and Hi.pdf,IGAN: A New Inception-based Model for Stable and High-Fidelity Image Synthesis Using Generative Adversarial Networks,"Ahmed A. Hashim, Ali Al-Shuwaili, Asraa Saeed, Ali Al-Bayaty",,,"Generative Adversarial Networks (GANs), dilation convolutions, inception module, spectral normalization, image synthesis, deep learning stability","Generative Adversarial Networks (GANs) face a significant challenge of striking an optimal balance between high-quality image generation and training stability. Recent techniques, such as DCGAN, BigGAN, and StyleGAN, improve visual fidelity; however, such techniques usually struggle with mode collapse and unstable gradients at high network depth. This paper proposes a novel GAN structural model that incorporates deeper inception-inspired convolution and dilated convolution. This novel model is termed the Inception Generative Adversarial Network (IGAN). The IGAN model generates high-quality synthetic images while maintaining training stability, by reducing mode collapse as well as preventing vanishing and exploding gradients. Our proposed IGAN model achieves the Fréchet Inception Distance (FID) of 13.12 and 15.08 on the CUB-200 and ImageNet datasets, respectively, representing a 28–33% improvement in FID over the state-of-the-art GANs. Additionally, the IGAN model attains an Inception Score (IS) of 9.27 and 68.25, reflecting improved image diversity and generation quality. Finally, the two techniques of dropout and spectral normalization are utilized in both the generator and discriminator structures to further mitigate gradient explosion and overfitting. These findings confirm that the IGAN model potentially balances training stability with image generation quality, constituting a scalable and computationally efficient framework for high-fidelity image synthesis.",20.18,21.256,429,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08333v1_Semantic Laundering in AI Agent Architectures Why .pdf,Semantic Laundering in AI Agent Architectures: Why Tool Boundaries Do Not Confer Epistemic Warrant,"Oleg Romanchuk, Roman Bondar",,2601.08333v1,"AI, agent architectures, semantic laundering, epistemic justification, Gettier problem, LLM-based agents","LLM-based agent architectures systematically conflate information transport mechanisms with epistemic justification mechanisms, leading to a pattern known as semantic laundering. This occurs when propositions with absent or weak warrant are accepted as admissible by crossing architecturally trusted interfaces. The paper formalizes this as an architectural realization of the Gettier problem, where propositions gain high epistemic status without a connection to their truth. The Theorem of Inevitable Self-Licensing is introduced, showing that circular epistemic justification cannot be eliminated under standard architectural assumptions. The Warrant Erosion Principle is proposed as the fundamental explanation for this effect, indicating that scaling, model improvement, and LLM-as-judge schemes cannot eliminate this type-level problem.",18.87,13.145,248,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08360v1_Scalable Sequential Recommendation under Latency a.pdf,Scalable Sequential Recommendation under Latency and Memory Constraints,"Adithya Parthasarathy, Aswathnarayan Muthukrishnan Kirubakaran, Vinoth Punniyamoorthy, Nachiappan Chockalingam, Lokesh Butra, Kabilan Kannan, Abhirup Mazumder, Sumit Saha",,2601.08360v1,"Recommender Systems, Sequence Modeling, Representation Learning, Scalable Machine Learning, Deep Learning","Sequential recommender systems must model long-range user behavior while operating under strict memory and latency constraints. Transformer-based approaches achieve strong accuracy but suffer from quadratic attention complexity, forcing aggressive truncation of user histories and limiting their practicality for long-horizon modeling. This paper presents HoloMambaRec, a lightweight sequential recommendation architecture that combines holographic reduced representations for attribute-aware embedding with a selective state space encoder for linear-time sequence processing. Item and attribute information are bound using circular convolution, preserving embedding dimensionality while encoding structured metadata. A shallow selective state space backbone, inspired by recent Mamba-style models, enables efficient training and constant-time recurrent inference. Experiments on Amazon Beauty and MovieLens-1M datasets demonstrate that HoloMambaRec consistently outperforms SASRec and achieves competitive performance with GRU4Rec under a constrained 10-epoch training budget, while maintaining substantially lower memory complexity. The design further incorporates forward-compatible mechanisms for temporal bundling and inference-time compression, positioning HoloMambaRec as a practical and extensible alternative for scalable, metadata-aware sequential recommendation.",20.08,19.269,387,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08371v1_Geo-NVS-w Geometry-Aware Novel View Synthesis In-t.pdf,Geo-NVS-w: Geometry-Aware Novel View Synthesis In-the-Wild with an SDF Renderer,"Anastasios Tsalakopoulos, Angelos Kanlis, Evangelos Chatzis, Antonis Karakottas, Dimitrios Zarpalas",,,"Novel View Synthesis, Signed Distance Function, Geometry-Preservation Loss, Energy Efficiency, In-the-Wild Image Collections","We introduce Geo-NVS-w, a geometry-aware framework for high-fidelity novel view synthesis from unstructured, in-the-wild image collections. Existing methods often lack geometric grounding on complex surfaces, leading to inconsistencies. Geo-NVS-w leverages a Signed Distance Function (SDF) to guide the rendering process, complemented by a novel Geometry-Preservation Loss to ensure fine structural details are preserved. The framework achieves competitive rendering performance with a 4–5× reduction in energy consumption compared to similar methods, yielding photorealistic results with sharp, geometrically coherent details.",16.09,14.482,233,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08379v1_Training-Free Distribution Adaptation for Diffusio.pdf,Training-Free Distribution Adaptation for Diffusion Models via Maximum Mean Discrepancy Guidance,"Matina Mahdizadeh Sani, Nima Jamali, Mohammad Jalali, Farzan Farnia",,,"diffusion models, distribution adaptation, Maximum Mean Discrepancy, inference-time guidance, latent diffusion models","Pre-trained diffusion models are powerful generative priors for sample generation, but often deviate from user-specific target data characteristics, especially in domain adaptation tasks with limited reference examples. Existing inference-time guidance methods optimize surrogate objectives rather than directly aligning with the target distribution. This paper proposes MMD Guidance, a training-free mechanism that augments the reverse diffusion process with gradients of the Maximum Mean Discrepancy (MMD) between generated samples and a reference dataset. MMD provides reliable distributional estimates from limited data, exhibits low variance, and is efficiently differentiable, making it well-suited for guidance tasks. The framework extends to prompt-aware adaptation in conditional generation models and can be applied efficiently in latent diffusion models (LDMs) by applying guidance in the latent space. Experiments demonstrate that MMD Guidance achieves distributional alignment while preserving sample fidelity.",18.13,16.274,295,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08380v1_Thematic Working Group 5 -- Artificial Intelligenc.pdf,EDUsummIT 2025 - eBook: Thematic Working Group 5 - Artificial Intelligence (AI) literacy for teaching and learning: design and implementation,"Mary Webb, Matt Bower, Ana Amélia Carvalho, Fredrik Mørk Røkenes, Jodie Torrington, Jonathan D. Cohen, Yousra Chtouki, Kathryn MacCallum, Tanya Linden, Deirdre Butler, Juliana E. Raffagheli, Henriikka Vartiainen, Martina Ronci, Peter Tiernan, David M. Smith, Chris Shelton, Joyce Malyn-Smith, Pierre Gorissen",,,"AI literacy, teaching and learning, curriculum design, professional development, classroom applications, policy guidelines, generative AI, academic integrity, creativity, agency, critical thinking","Thematic Working Group 5 focused on developing and implementing effective strategies for enhancing AI literacy and agency of teachers, equipping them with the knowledge and skills necessary to integrate AI into their teaching practices. Explorations covered curriculum design, professional development programs, practical classroom applications, and policy guidelines aiming to empower educators to confidently utilize AI tools and foster a deeper understanding of AI concepts among students. The release of ChatGPT3 in November 2022 marked a significant advancement in AI, raising concerns around plagiarism and academic integrity, while also offering potential benefits for educational processes.",19.03,18.021,343,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08382v2_A Qualitative Model to Reason about Object Rotatio.pdf,A Qualitative Model to Reason about Object Rotations – applied to solve the Cube Comparison Test,Zoe Falomira,,,"cube comparison test, mental rotation, qualitative reasoning, spatial cognition, spatial reasoning","This paper presents a Qualitative model for Reasoning about Object Rotations (QOR) applied to solve the Cube Comparison Test (CCT) by Ekstrom et al. (1976). A conceptual neighborhood graph relating Rotation movement to Location change and Orientation change (CN GRLO) of the features on the cube sides has been built, producing composition tables to calculate inferences for reasoning about rotations. The paper discusses the importance of spatial reasoning skills in various fields and how qualitative models can be used to represent knowledge and solve spatial reasoning tests. The paper also introduces a new qualitative descriptor for reasoning about object rotations and its implementation in an interactive version of the Cube Comparison Test.",15.54,14.67,228,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08383v1_Deconstructing Pre-training Knowledge Attribution .pdf,Deconstructing Pre-training: Knowledge Attribution Analysis in MoE and Dense Models,"Bo Wang, Junzhuo Li, Hong Chen, Yuanlin Chu, Yuxuan Fan, Xuming Hu",,,"Mixture-of-Experts, MoE, Dense Models, Knowledge Acquisition, Pre-training, Neuron-level Attribution, Log-Probability Increase, Interpretability, Large Language Models, Conditional Computation","Mixture-of-Experts (MoE) architectures decouple model capacity from per-token computation, enabling scaling beyond the computational limits imposed by dense scaling laws. This study introduces Gated-LPI, a neuron-level attribution metric, to compare knowledge acquisition dynamics in MoE and dense architectures. Experiments reveal three patterns: (1) Low-entropy backbone, where top MoE neurons capture over 45% of positive updates, forming a high-utility core absent in dense models. (2) Early consolidation, with MoE models stabilizing within <100K steps, unlike the volatile dense models. (3) Functional robustness, where masking the most important MoE attention heads reduces relational HIT@10 by <10%, compared to >50% in dense models, indicating sparsity fosters distributed knowledge storage. These findings suggest that sparsity leads to a stable and distributed computational backbone from early training, bridging the gap between sparse architectures and training-time interpretability.",17.99,19.286,347,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08388v1_Creativity in AI as Emergence from Domain-Limited .pdf,Creativity in AI as Emergence from Domain-Limited Generative Models,Corina Chutaux,,,"creativity, artificial intelligence, generative models, pattern recombination, multimodal architectures, emergent property, domain-limited generative models","This paper proposes a generative perspective on creativity in AI, framing it as an emergent property of domain-limited generative models embedded within bounded informational environments. It introduces a conceptual decomposition of creativity into four interacting components: pattern-based generation, induced world models, contextual grounding, and arbitrariness. The paper examines how these components manifest in multimodal generative systems, aiming to provide a technical framework for studying creativity as an emergent phenomenon in AI systems, rather than as a post hoc evaluative label.",15.16,12.399,188,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08393v1_Controlled LLM Training on Spectral Sphere.pdf,Controlled LLM Training on Spectral Sphere,"Tian Xie, Haoming Luo, Haoyu Tang, Yiwen Hu, Jason Klein, Liu Qingnan, Ren, Yang Wang, Wayne Xin Zhao, Rui Yan, Bing Su, Chong Luo, Baining Guo",,arXiv:2601.08393v1,"LLM Training, Spectral Sphere Optimizer, Optimization Strategies, Maximal Update Parametrization, Large Models, Stability, Megatron, Pretraining, Dense Models, MoE Models, DeepNet Models, AdamW, Muon, Activation Control","Scaling large models requires optimization strategies that ensure rapid convergence grounded in stability. Maximal Update Parametrization (µP) provides a theoretical safeguard for width-invariant Θ(1) activation control, whereas emerging optimizers like Muon are only 'half-aligned' with these constraints: they control updates but allow weights to drift. To address this limitation, we introduce the Spectral Sphere Optimizer (SSO), which enforces strict module-wise spectral constraints on both weights and their updates. By deriving the steepest descent direction on the spectral sphere, SSO realizes a fully µP-aligned optimization process. To enable large-scale training, we implement SSO as an efficient parallel algorithm within Megatron. Through extensive pretraining on diverse architectures, including Dense 1.7B, MoE 8B-A1B, and 200-layer DeepNet models, SSO consistently outperforms AdamW and Muon. Furthermore, we observe significant practical stability benefits, including improved MoE router load balancing, suppressed outliers, and strictly bounded activations.",20.0,21.598,432,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08401v1_An Explainable Two Stage Deep Learning Framework f.pdf,An Explainable Two-Stage Deep Learning Framework for Pericoronitis Assessment in Panoramic Radiographs Using YOLOv8 and ResNet-50,"Ajo Babu George, Pranav S, Kunal Agarwal",,2601.08401v1,"AI-assisted assessment, pericoronitis, panoramic radiographs, YOLOv8, ResNet-50, Grad-CAM, deep learning, Winter’s classification","The study presents a two-stage deep learning framework to diagnose pericoronitis in panoramic radiographs. The first stage uses YOLOv8 for detecting third molars and classifying their anatomical positions and angulations. The second stage employs a modified ResNet-50 architecture to identify radiographic features indicative of pericoronitis. Grad-CAM is used to enhance interpretability by highlighting key diagnostic regions. The YOLOv8 component achieved 92% precision and 92.5% mean average precision, while the ResNet-50 classifier yielded F1-scores of 88% for normal cases and 86% for pericoronitis. Radiologists reported 84% alignment between Grad-CAM and their diagnostic impressions, indicating the clinical relevance of the interpretability output. The framework demonstrates strong potential for AI-assisted panoramic assessment with explainable AI features that support clinical confidence.",20.16,16.668,336,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08402v1_PATS Personality-Aware Teaching Strategies with La.pdf,PATS: Personality-Aware Teaching Strategies with Large Language Model Tutors,"Donya Rooein, Sankalan Pal Chowdhury, Mariia Eremeeva, Yuan Qin, Debora Nozza, Mrinmaya Sachan, Dirk Hovy",,,"large language models, educational tutors, personality traits, pedagogical methods, teaching strategies, personalized learning, intelligent tutoring systems","Recent advances in large language models (LLMs) demonstrate their potential as educational tutors. However, different tutoring strategies benefit different student personalities, and mismatches can be counterproductive to student outcomes. Current LLM tutoring systems do not take into account student personality traits. To address this, a taxonomy linking pedagogical methods to personality profiles is constructed based on pedagogical literature. Simulated student-teacher conversations allow the LLM tutor to adjust its strategy to the simulated student personality. Evaluation with human teachers shows a preference for this approach over baselines, increasing the use of less common, high-impact strategies such as role-playing. These findings pave the way for more personalized and effective LLM use in educational applications.",17.27,17.201,297,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08403v1_Owen-Shapley Policy Optimization OSPO A Principled.pdf,Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for Generative Search LLMs,"Abhijnan Nath, Alireza Bagheri Garakani, Tianchen Zhou, Fan Yang, Nikhil Krishnaswamy",,,"Large Language Models, Reinforcement Learning, Recommendation Systems, Shapley-Owen Attribution, Policy Optimization","Large language models are increasingly trained via reinforcement learning for personalized recommendation tasks. Standard methods like GRPO rely on sparse, sequence-level rewards, creating a credit assignment gap that obscures which tokens drive success. This gap is problematic when models must infer latent user intent from under-specified language without ground truth labels. The paper introduces OWEN-SHAPLEY POLICY OPTIMIZATION (OSPO), a framework that redistributes sequence-level advantages based on tokens' marginal contributions to outcomes. OSPO employs potential-based reward shaping via Shapley-Owen attributions to assign segment-level credit while preserving the optimal policy, directly from task feedback without parametric value models. Experiments on Amazon ESCI and H&M Fashion datasets show consistent gains over baselines, with notable test-time robustness to out-of-distribution retrievers unseen during training.",17.17,16.37,281,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08406v1_WebTrap Park An Automated Platform for Systematic .pdf,WebTrap Park: An Automated Platform for Systematic Security Evaluation of Web Agents,"Xinyi Wu, Jiagui Chen, Geng Hong, Jiayi Dong, Xudong Pan, Jiarun Dai, Min Yang",,,"Web Agents, Security Evaluation, Automated Platform, Security Risks, Agent Frameworks","Web Agents are increasingly deployed to perform complex tasks in real web environments, yet their security evaluation remains fragmented and difficult to standardize. This paper presents WebTrapPark, an automated platform for systematic security evaluation of Web Agents through direct observation of their concrete interactions with live web pages. WebTrapPark instantiates three major sources of security risk into 1,226 executable evaluation tasks and enables action-based assessment without requiring agent modification. The results reveal clear security differences across agent frameworks, highlighting the importance of agent architecture beyond the underlying model. WebTrapPark is publicly accessible and provides a scalable foundation for reproducible Web Agent security evaluation.",17.0,14.937,254,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08412v1_Hybrid Distillation with CoT Guidance for Edge-Dro.pdf,Hybrid Distillation with CoT Guidance for Edge-Drone Control Code Generation,"Yizhan Feng, Hichem Snoussi, Yuhang Wang, Jing Teng, Abel Cherouat, Tian Wang",,,"Large language models, drone, Knowledge Distillation, Chain-of-Thought, Lightweight","With large language models demonstrating significant potential in code generation tasks, their application to onboard control of resource-constrained Unmanned Aerial Vehicles has emerged as an important research direction. However, a notable contradiction exists between the high resource consumption of large models and the real-time, lightweight requirements of UAV platforms. This paper proposes an integrated approach that combines knowledge distillation, chain-of-thought guidance, and supervised fine-tuning for UAV multi-SDK control tasks, aiming to efficiently transfer complex reasoning and code generation capabilities to smaller models. Firstly, a high-quality dataset covering various mainstream UAV SDKs is constructed, featuring instruction-code-reasoning chains, and incorporates counterfactual negative samples for data augmentation, guiding the model to learn the end-to-end logic from instruction parsing to code generation. Secondly, leveraging DeepSeek-Coder-V2-Lite quantized via QLoRA as the teacher model, and based on a hybrid black-box and white-box distillation strategy, high-quality chain-of-thought soft labels are generated. These are combined with a weighted cross-entropy loss using hard labels to transfer complex reasoning capabilities to the smaller student model. Finally, through prompt tuning engineering optimized for the UAV control scenario, the model's performance on core tasks such as SDK type recognition and function call matching is enhanced. Experimental results indicate that the distilled lightweight model (parameters ≤ 1B) maintains high code generation accuracy while achieving significant improvements in deployment and inference efficiency, effectively demonstrating the feasibility and superiority of our approach in achieving precise and lightweight intelligent control for UAVs.",19.9,21.962,437,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08415v2_Regulatory gray areas of LLM Terms.pdf,Regulatory gray areas of LLM Terms,"Brittany I. Davidson, Kate Muir, Florian A.D. Burnat, Adam N. Joinson",,2601.08415v2,"Language Models, LLMs, Privacy Policy, Terms of Service, Regulation","Large Language Models (LLMs) are increasingly integrated into academic research pipelines; however, the Terms of Service governing their use remain under-examined. This paper presents a comparative analysis of the Terms of Service of five major LLM providers (Anthropic, DeepSeek, Google, OpenAI, and xAI) collected in November 2025. The analysis reveals substantial variation in the stringency and specificity of usage restrictions for general users and researchers. Specific complexities for researchers in security research, computational social sciences, and psychological studies are identified. The paper highlights 'regulatory gray areas' where Terms of Service create uncertainty for legitimate use. A publicly available resource comparing terms across platforms is contributed, and implications for general users and researchers navigating this evolving landscape are discussed.",18.66,14.257,266,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08418v1_Taxon Hierarchical Tax Code Prediction with Semant.pdf,Taxon: Hierarchical Tax Code Prediction with Semantically Aligned LLM Expert Guidance,"Jihang Li, Qing Liu, Zulong Chen, Jing Wang, Wei Wang, Chuanfei Xu, Zeyi Wen",,,"tax code prediction, hierarchical taxonomy, large language models, e-commerce, compliance management","Tax code prediction is a crucial yet underexplored task in automating invoicing and compliance management for large-scale e-commerce platforms. Each product must be accurately mapped to a node within a multi-level taxonomic hierarchy defined by national standards, where errors lead to financial inconsistencies and regulatory risks. This paper presents Taxon, a semantically aligned and expert-guided framework for hierarchical tax code prediction. Taxon integrates a feature-gating mixture-of-experts architecture that adaptively routes multi-modal features across taxonomy levels, and a semantic consistency model distilled from large language models acting as domain experts to verify alignment between product titles and official tax definitions. To address noisy supervision in real business records, a multi-source training pipeline is designed that combines curated tax databases, invoice validation logs, and merchant registration data to provide both structural and semantic supervision. Extensive experiments on the proprietary TaxCode dataset and public benchmarks demonstrate that Taxon achieves state-of-the-art performance, outperforming strong baselines. An additional full hierarchical paths reconstruction procedure significantly improves structural consistency, yielding the highest overall F1 scores. Taxon has been deployed in production within Alibaba’s tax service system, handling an average of over 500,000 tax code queries per day and reaching peak volumes above five million requests during business events with improved accuracy, interpretability, and robustness.",18.81,19.615,369,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08430v1_RubricHub A Comprehensive and Highly Discriminativ.pdf,RubricHub: A Comprehensive and Highly Discriminative Rubric Dataset via Automated Coarse-to-Fine Generation,"Sunzhu Li, Jiale Zhao, Miteto Wei, Huimin Ren, Yang Zhou, Jingwen Yang, Shunyu Liu, Kaike Zhang, Wei Chen",,,"Reinforcement Learning, Rubric-based Evaluation, Coarse-to-Fine Generation, Large Language Models, RubricHub Dataset","Reinforcement Learning with Verifiable Rewards (RLVR) has significantly advanced reasoning-intensive domains like mathematics. However, optimizing open-ended generation remains challenging due to the absence of ground truth. Existing rubric-based evaluation methods face scalability issues and coarse criteria, leading to a supervision ceiling effect. This paper introduces an automated Coarse-to-Fine Rubric Generation framework, which combines principle-guided synthesis, multi-model aggregation, and difficulty evolution to produce comprehensive and highly discriminative criteria. The framework is used to create RubricHub, a large-scale (∼110k) and multi-domain dataset. The dataset's utility is validated through a two-stage post-training pipeline involving Rubric-based Rejection Sampling Fine-Tuning (RuFT) and Reinforcement Learning (RuRL). Experimental results show that RubricHub enables significant performance improvements, with the post-trained Qwen3-14B achieving state-of-the-art results on HealthBench (69.3), surpassing proprietary models like GPT-5. The code and data will be released soon.",18.31,19.769,362,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08434v3_Large Multimodal Models for Embodied Intelligent D.pdf,Large Multimodal Models for Embodied Intelligent Driving: The Next Frontier in Self-Driving?,"Long Zhang, Yuchen Xia, Bingqing Wei, Zhen Liu, Shiwen Mao, Zhu Han, Mohsen Guizani",,,"Large Multimodal Models, Embodied Intelligent Driving, Autonomous Driving, Semantic Understanding, Deep Reinforcement Learning, Policy Optimization, Environmental Understanding, Logical Reasoning","The article discusses the potential of Large Multimodal Models (LMMs) to address the limitations of modular design in autonomous driving, particularly in open-world scenarios requiring sustained environmental understanding and logical reasoning. It introduces a novel semantics and policy dual-driven hybrid decision framework that combines LMMs for semantic understanding and cognitive representation with deep reinforcement learning (DRL) for real-time policy optimization. The framework aims to enhance embodied intelligent (EI) driving by ensuring continuous learning and joint decision-making. The article outlines the foundational principles of EI driving and LMMs, explores emerging opportunities, and presents a case study validating the framework's performance in a lane-change planning task. Future research directions to empower EI driving are also identified.",17.89,16.432,294,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08441v1_YaPO Learnable Sparse Activation Steering Vectors .pdf,YaPO: Learnable Sparse Activation Steering Vectors for Domain Adaptation,"Abdelaziz Bounhar, Rania Hossam Elmohamady Elbadry, Hadi Abdine, Preslav Nakov, Michalis Vazirgiannis, Guokan Shang",,,"Large Language Models, activation interventions, fine-tuning, alignment, personalization, sparse steering vectors, Sparse Autoencoder, cultural alignment, domain adaptation","This paper introduces Y aPO, a reference-free method for learning sparse steering vectors in the latent space of a Sparse Autoencoder (SAE). Unlike dense steering vectors, which often entangle multiple latent factors, Y aPO produces disentangled, interpretable, and efficient steering directions. The method shows faster convergence, stronger performance, and improved training stability compared to dense steering baselines. Y aPO is effective for cultural alignment and generalizes to various alignment-related behaviors without degrading general knowledge. The associated code and data are publicly available.",16.66,16.087,268,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08444v1_Beyond Linearization Attributed Table Graphs for T.pdf,Beyond Linearization: Attributed Table Graphs for Table Reasoning,"Yuxiang Wang, Junhao Gan, Shengxiang Gao, Shenghao Ye, Zhengyi Yang, Jianzhong Qi",,,"table reasoning, Large Language Models, linearization, graph-based reasoning, explainability, Question-Guided Personalized PageRank","Table reasoning involves answering questions by reasoning over data in tables, a prevalent format for storing knowledge. Recent solutions use Large Language Models (LLMs) by linearizing tables into plain text, which leads to issues like loss of structure, lack of explainability, and the 'lost-in-the-middle' problem. This paper introduces the Table Graph Reasoner (TABGR), a model that represents tables as an Attributed Table Graph (ATG) to preserve structures and enable graph-based reasoning. A Question-Guided Personalized PageRank (QG-PPR) mechanism is proposed to rerank data and address the 'lost-in-the-middle' issue. Experiments show TABGR outperforms state-of-the-art models by up to 9.7% in accuracy.",16.81,17.431,293,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08448v1_Divide and Conquer Static-Dynamic Collaboration fo.pdf,Divide and Conquer: Static-Dynamic Collaboration for Few-Shot Class-Incremental Learning,"Kexin Bao, Daichi Zhang, Yong Li, Dan Zeng, Shiming Ge",10.1145/3731715.3733310,,"Few-Shot Class-Incremental Learning, Class-Incremental Learning","Few-shot class-incremental learning (FSCIL) aims to continuously recognize novel classes under limited data, which suffers from the key stability-plasticity dilemma: balancing the retention of old knowledge with the acquisition of new knowledge. To address this issue, we divide the task into two different stages and propose a framework termed Static-Dynamic Collaboration (SDC) to achieve a better trade-off between stability and plasticity. Specifically, our method divides the normal pipeline of FSCIL into Static Retaining Stage (SRS) and Dynamic Learning Stage (DLS), which harnesses old static and incremental dynamic class information, respectively. During SRS, we train an initial model with sufficient data in the base session and preserve the key part as static memory to retain fundamental old knowledge. During DLS, we introduce an extra dynamic projector jointly trained with the previous static memory. By employing both stages, our method achieves improved retention of old knowledge while continuously adapting to new classes. Extensive experiments on three public benchmarks and a real-world application dataset demonstrate that our method achieves state-of-the-art performance against other competitors.",18.29,18.753,343,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08450v1_Decoding Order Matters in Autoregressive Speech Sy.pdf,Decoding Order Matters in Autoregressive Speech Synthesis,"Minghui Zhao, Anton Ragni",,,"speech synthesis, discrete diffusion model, order-agnostic autoregressive decoding","This paper investigates the impact of decoding order in autoregressive speech synthesis, which traditionally uses a left-to-right approach. By employing a masked diffusion framework, the study explores various decoding orders, including random permutations and fixed strategies like left-to-right (l2r) and right-to-left (r2l). The findings suggest that fixed-order decoding is suboptimal compared to adaptive decoding methods. Additionally, the research demonstrates that even with 1-bit quantisation of acoustic representations, high-quality speech synthesis is achievable. The study highlights the importance of considering alternative decoding orders to improve synthesis quality by better capturing speech dependencies.",14.91,13.413,200,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08457v1_An Under-Explored Application for Explainable Mult.pdf,An Under-Explored Application for Explainable Multimodal Misogyny Detection in Code-Mixed Hindi-English,"Sargam Yadava, Abhishek Kaushik, Kevin McDaid",,,"hate speech, misogyny, natural language processing, code-mixing, Hinglish","Digital platforms have an ever-expanding user base, serving as hubs for communication, business, and connectivity. However, they also facilitate the spread of hate speech and misogyny. Artificial intelligence models have emerged as effective solutions for countering online hate speech but are under-explored for low-resource and code-mixed languages and suffer from a lack of interpretability. Explainable Artificial Intelligence (XAI) can enhance transparency in the decisions of deep learning models, which is crucial for sensitive domains like hate speech detection. This paper presents a multi-modal and explainable web application for detecting misogyny in text and memes in code-mixed Hindi and English. The system leverages state-of-the-art transformer-based models that support multilingual and multimodal settings. For text-based misogyny identification, the system utilizes XLM-RoBERTa (XLM-R) and multilingual Bidirectional Encoder Representations from Transformers (mBERT) on a dataset of approximately 4,193 comments. For multimodal misogyny identification from memes, the system utilizes mBERT + EfficientNet, and mBERT + ResNET trained on a dataset of approximately 4,218 memes. It also provides feature importance scores using explainability techniques including Shapley Additive Values (SHAP) and Local Interpretable Model Agnostic Explanations (LIME). The application aims to serve as a tool for both researchers and content moderators, to promote further research in the field, combat gender-based digital violence, and ensure a safe digital space. The system has been evaluated using human evaluators who provided their responses on Chatbot Usability Questionnaire (CUQ) and User Experience Questionnaire (UEQ) to determine overall usability.",19.69,23.261,458,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08462v1_M3-BENCH Process-Aware Evaluation of LLM Agents So.pdf,M3-BENCH: Process-Aware Evaluation of LLM Agents Social Behaviors in Mixed-Motive Games,"Sixiong Xie, Zhuofan Shi, Haiyang Shen, Gang Huang, Yun Ma, Xiang Jing",,,"large language model, social behaviors, mixed-motive games, evaluation framework, Big Five personality model, Social Exchange Theory","As large language model (LLM) agents advance, their social behaviors such as cooperation, deception, and collusion require systematic evaluation. Existing benchmarks often focus on single capability dimensions or behavioral outcomes, neglecting process information from decision reasoning and communication. M3-BENCH, a multi-stage benchmark for mixed-motive games, introduces a process-aware evaluation framework with three modules: Behavioral Trajectory Analysis (BTA), Reasoning Process Analysis (RPA), and Communication Content Analysis (CCA). It integrates the Big Five personality model and Social Exchange Theory to provide interpretable social behavior portraits, characterizing agents' personality traits and capability profiles beyond simple task scores. Experimental results demonstrate M3-BENCH's ability to distinguish diverse social behavior competencies across models, revealing inconsistencies in reasoning and communication despite reasonable behavioral outcomes.",17.88,16.555,296,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08464v1_CoMa Contextual Massing Generation with Vision-Lan.pdf,CoMa: Contextual Massing Generation with Vision-Language Models,"Evgenii Maslov, Valentin Khrulkov, Anastasia Volkova, Anton Gusarov, Andrey Kuznetsov, Ivan Oseledets",,2601.08464v1,"architecture, urban planning, building massing, Vision-Language Models, dataset, data-driven methods","The conceptual design phase in architecture and urban planning, particularly building massing, is complex and heavily reliant on designer intuition and manual effort. To address this, we propose an automated framework for generating building massing based on functional requirements and site context. A primary obstacle to such data-driven methods has been the lack of suitable datasets. Consequently, we introduce the CoMa-20K dataset, a comprehensive collection that includes detailed massing geometries, associated economical and programmatic data, and visual representations of the development site within its existing urban context. We benchmark this dataset by formulating massing generation as a conditional task for Vision-Language Models (VLMs), evaluating both fine-tuned and large zero-shot models. Our experiments reveal the inherent complexity of the task while demonstrating the potential of VLMs to produce context-sensitive massing options. The dataset and analysis establish a foundational benchmark and highlight significant opportunities for future research in data-driven architectural design.",19.62,16.714,328,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08468v1_JudgeRLVR Judge First Generate Second for Efficien.pdf,"JudgeRLVR: Judge First, Generate Second for Efficient Reasoning","Jiangshan Duo, Hanyu Li, Hailin Zhang, Yudong Wang, Sujian Li, Liang Zhao",,arXiv:2601.08468v1,"Reinforcement Learning, Verifiable Rewards, Large Language Models, Reasoning, Efficiency, Generalization","Reinforcement Learning with Verifiable Rewards (RLVR) is a standard paradigm for reasoning in Large Language Models. However, optimizing solely for final-answer correctness often leads models to engage in verbose exploration rather than structured planning. This paper introduces JudgeRLVR, a two-stage judge-then-generate paradigm. In the first stage, the model is trained to judge solution responses with verifiable answers. In the second stage, the model is fine-tuned with vanilla generating RLVR initialized from the judge. JudgeRLVR achieves a better quality-efficiency trade-off, demonstrating enhanced generalization on both in-domain and out-of-domain benchmarks.",17.48,15.162,265,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08472v1_sui-1 Grounded and Verifiable Long-Form Summarizat.pdf,sui-1: Grounded and Verifiable Long-Form Summarization,"Benedikt Droste, Jan Philipp Harries, Maximilian Idahl, Björn Plüster",,2601.08472v1,"long-form summarization, citation-grounded summarization, large language models, synthetic data generation, iterative processing","Large language models often produce unfaithful summaries that are difficult to verify against source texts, posing a challenge in compliance-sensitive areas. The sui-1 model, with 24B parameters, addresses this by generating abstractive summaries with inline citations, allowing users to trace claims back to their source sentences. It can process documents up to 100K tokens in a single pass and supports iterative processing for texts exceeding 2 million tokens. The model was trained using a synthetic data pipeline that combines chain-of-thought prompting with multi-stage verification, producing over 22,000 high-quality training examples across five languages. Evaluation shows sui-1 significantly outperforms open-weight baselines, demonstrating that task-specific training is more effective than increasing model scale alone. The model achieves 84% accuracy on LLM-as-a-judge evaluation, outperforming baselines with 3× more parameters. Model weights and an interactive demo are publicly available.",19.1,16.651,318,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08475v1_SUMMPILOT Bridging Efficiency and Customization fo.pdf,Bridging Efficiency and Customization for Interactive Summarization System,"JungMin Yun, Juhwan Choi, Kyohoon Jin, Soojin Jang, Jinhee Jang, YoungBin Kim",,,"interactive summarization, customizable summarization, large language models, semantic graphs, entity clustering, explainable evaluation","This paper introduces SUMMPILOT, an interaction-based customizable summarization system that combines the efficiency of automatic summarization with the ability to generate personalized summaries tailored to individual users' interests and requirements. SUMMPILOT leverages a large language model to facilitate both automatic and interactive summarization. Users can engage with the system to understand document content and personalize summaries through interactive components such as semantic graphs, entity clustering, and explainable evaluation. The system supports both single and multi-document summarization, addressing the challenge of representing content relationships and supporting decision-making by indicating how user inputs affect the final summary. The paper demonstrates SUMMPILOT's adaptability and usefulness for customizable summarization through demos and user studies.",17.06,15.705,268,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08490v1_BenchOverflow Measuring Overflow in Large Language.pdf,BenchOverflow: Measuring Overflow in Large Language Models via Plain-Text Prompts,"Erin Feiglin, Nir Hutnik, Raz Lapid",,2601.08490v1,"large language models, overflow, plain-text prompts, length control, computational cost, environmental impact","This paper investigates a failure mode in large language models (LLMs) where plain-text prompts lead to excessive outputs, termed 'Overflow'. Unlike other issues like jailbreaks, Overflow occurs under normal interaction settings and can increase serving costs, latency, and degrade performance across users. It also has economic and environmental impacts due to unnecessary token generation. The study introduces 'BenchOverflow', a benchmark for evaluating nine plain-text prompting strategies that increase output volume. The benchmark assesses nine models, revealing significant variations in output length. A simple mitigation strategy, a fixed conciseness reminder, is shown to reduce excessive output. The findings highlight the importance of length control for reliability, cost, and sustainability in LLMs.",17.58,14.901,262,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08493v1_PKI Prior Knowledge-Infused Neural Network for Few.pdf,PKI: Prior Knowledge-Infused Neural Network for Few-Shot Class-Incremental Learning,"Kexin Bao, Fanzhao Lin, Zichen Wang, Yong Li, Dan Zeng, Shiming Ge",,2601.08493v1,"Few-shot class-incremental learning, catastrophic forgetting, overfitting, prior knowledge, neural network","Few-shot class-incremental learning (FSCIL) aims to continually adapt a model on a limited number of new-class examples, facing two well-known challenges: catastrophic forgetting and overfitting to new classes. Existing methods tend to freeze more parts of network components and finetune others with an extra memory during incremental sessions. These methods emphasize preserving prior knowledge to ensure proficiency in recognizing old classes, thereby mitigating catastrophic forgetting. Meanwhile, constraining fewer parameters can help in overcoming overfitting with the assistance of prior knowledge. Following previous methods, we retain more prior knowledge and propose a prior knowledge-infused neural network (PKI) to facilitate FSCIL. PKI consists of a backbone, an ensemble of projectors, a classifier, and an extra memory. In each incremental session, we build a new projector and add it to the ensemble. Subsequently, we finetune the new projector.",19.66,16.482,324,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08499v2_EfficientFSL Enhancing Few-Shot Classification via.pdf,EfficientFSL: Enhancing Few-Shot Classification via Query-Only Tuning in Vision Transformers,"Wenwen Liao, Hang Ruan, Jianbo Yu, Bing Song, Yuansong Wang, Xiaofeng Yang",,,"Few-Shot Learning, Vision Transformers, Query-Only Tuning, EfficientFSL, Feature Extraction, Prototype Adjustment","Large models like Vision Transformers (ViTs) outperform smaller architectures in few-shot classification due to their strong representational capacity. However, fine-tuning these models is resource-intensive. This paper introduces EfficientFSL, a query-only fine-tuning framework for ViTs, which reduces computational overhead while maintaining competitive performance. EfficientFSL leverages pre-trained model knowledge with minimal trainable parameters, using a Forward Block for task-specific queries, a Combine Block for multi-layer output fusion, and a Support-Query Attention Block to align prototypes with query set distribution. It achieves state-of-the-art performance on both in-domain and cross-domain few-shot datasets, demonstrating its practicality in real-world applications.",17.15,16.033,275,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08503v1_Temporal Fusion Nexus A task-agnostic multi-modal .pdf,Temporal Fusion Nexus: A task-agnostic multi-modal embedding model for clinical narratives and irregular time series in post-kidney transplant care,"Aditya Kumar, Simon Rauch, Mario Cypko, Marcel Naik, Matthieu-P Schapranow, Aadil Rashid, Fabian Halleck, Bilgin Osmanodja, Roland Roller, Lars Pape, Klemens Budde, Mario Schiffer, Oliver Amft",,2601.08503v1,"multi-modal embedding, clinical narratives, irregular time series, post-kidney transplant care, machine learning, healthcare","We introduce Temporal Fusion Nexus (TFN), a multi-modal and task-agnostic embedding model to integrate irregular time series and unstructured clinical narratives. We analysed TFN in post-kidney transplant (KTx) care, with a retrospective cohort of 3382 patients, on three key outcomes: graft loss, graft rejection, and mortality. Compared to state-of-the-art model in post KTx care, TFN achieved higher performance for graft loss (AUC 0.96 vs. 0.94) and graft rejection (AUC 0.84 vs. 0.74). In mortality prediction, TFN yielded an AUC of 0.86. TFN outperformed unimodal baselines (≈10% AUC improvement over time series only baseline,≈5% AUC improvement over time series with static patient data). Integrating clinical text improved performance across all tasks. Disentanglement metrics confirmed robust and interpretable latent factors in the embedding space, and SHAP-based attributions confirmed alignment with clinical reasoning. TFN has potential application in clinical tasks beyond KTx.",20.86,20.903,436,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08509v1_What If TSF A Benchmark for Reframing Forecasting .pdf,What If TSF: A Benchmark for Reframing Forecasting as Scenario-Guided Multimodal Forecasting,"Jinkwan Jang, Hyunbin Jin, Hyungjin Park, Kyubyung Chae, Taesup Kim",,,"time series forecasting, multimodal forecasting, large language models, scenario-guided forecasting, benchmark","Time series forecasting is critical for decision making, yet most approaches are unimodal and rely on historical patterns. Recent advances in large language models (LLMs) show potential for multimodal forecasting, but existing benchmarks often provide retrospective or misaligned context. This paper introduces What If TSF (WIT), a multimodal forecasting benchmark designed to evaluate models' ability to condition forecasts on contextual text, especially future scenarios. WIT provides expert-crafted plausible or counterfactual scenarios, offering a rigorous testbed for scenario-guided multimodal forecasting. The benchmark is available at https://github.com/jinkwan1115/WhatIfTSF.",16.5,15.639,258,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08510v2_STAGE A Benchmark for Knowledge Graph Construction.pdf,"STAGE: A Benchmark for Knowledge Graph Construction, Question Answering, and In-Script Role-Playing over Movie Screenplays","Qiuyu Tian, Yiding Li, Fengyi Chen, Zequn Liu, Youyong Kong, Fan Guo, Yuyao Li, Jinjing Shen, Zhijing Xie, Yiyun Luo, Xin Zhang",,2601.08510v2,"knowledge graph, question answering, role-playing, movie screenplays, narrative understanding","Movie screenplays are rich, long-form narratives that interleave complex character relationships, temporally ordered events, and dialogue-driven interactions. While prior benchmarks target individual subtasks such as question answering or dialogue generation, they rarely evaluate whether models can construct a coherent story world and use it consistently across multiple forms of reasoning and generation. We introduce STAGE (Screenplay Text, Agents, Graphs & Evaluation), a unified benchmark for narrative understanding over full-length movie screenplays. STAGE defines four tasks: knowledge graph construction, scene-level event summarization, long-context screenplay question answering, and in-script character role-playing, all grounded in a shared narrative world representation. The benchmark provides cleaned scripts, curated knowledge graphs, and event- and character-centric data.",19.97,16.175,323,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08519v1_CD2 Constrained Dataset Distillation for Few-Shot .pdf,CD2: Constrained Dataset Distillation for Few-Shot Class-Incremental Learning,"Kexin Bao, Daichi Zhang, Hansong Zhang, Yong Li, Yutao Yue, Shiming Ge",,,"Few-shot class-incremental learning, catastrophic forgetting, dataset distillation, knowledge transfer, deep neural models","Few-shot class-incremental learning (FSCIL) aims to perform classification continuously with a few training samples, facing the challenge of catastrophic forgetting. Existing methods use external memory to store previous knowledge but fail to preserve essential knowledge effectively. This paper introduces a framework called Constrained Dataset Distillation (CD2) for FSCIL, comprising a dataset distillation module (DDM) and a distillation constraint module (DCM). The DDM synthesizes condensed samples to help the model learn essential class-related clues from few samples, while the DCM uses a designed loss to preserve previously learned class distribution. Extensive experiments on three public datasets demonstrate the superiority of CD2 over other state-of-the-art methods.",16.93,16.181,274,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08531v1_Sketch-Based Facade Renovation With Generative AI .pdf,Sketch-Based Facade Renovation With Generative AI Models: A Streamlined Framework for Bypassing As-Built Modelling in Industrial Adaptive Reuse,"Warissara Booranamaitree, Xusheng Du, Yushu Cai, Zhengyang Wang, Ye Zhang, Haoran Xie",,,"Industrial building renovation, vision-language model, diffusion model, user sketches, facade renovation","Facade renovation offers a more sustainable alternative to full demolition, yet producing design proposals that preserve existing structures while expressing new intent remains challenging. Current workflows typically require detailed as-built modelling before design, which is time-consuming, labour-intensive, and often involves repeated revisions. To solve this issue, we propose a three-stage framework combining generative artificial intelligence (AI) and vision-language models (VLM) that directly processes rough structural sketch and textual descriptions to produce consistent renovation proposals. First, the input sketch is used by a fine-tuned VLM model to predict bounding boxes specifying where modifications are needed and which components should be added. Next, a stable diffusion model generates detailed sketches of new elements, which are merged with the original outline through a generative inpainting pipeline. Finally, ControlNet is employed to refine the result into a photorealistic image. Experiments on datasets and real industrial buildings indicate that the proposed framework can generate renovation proposals that preserve the original structure while improving facade detail quality. This approach effectively bypasses the need for detailed as-built modelling, enabling architects to rapidly explore design alternatives, iterate on early-stage concepts, and communicate renovation intentions with greater clarity.",19.92,18.823,375,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08545v2_Learner-Tailored Program Repair A Solution Generat.pdf,Learner-Tailored Program Repair: A Solution Generator with Iterative Edit-Driven Retrieval Enhancement,"Zhenlong Dai, Zhuoluo Zhao, Hengning Wang, Xiu Tang, Sai Wu, Chang Yao, Zhipeng Gao, Jingyuan Chen",,,"program repair, large language models, intelligent programming coaching, bug fixing, solution retrieval, edit-driven code retrieval, iterative retrieval enhancement","This paper introduces a novel task, Learner-Tailored Program Repair (LPR), and proposes a framework, LSGEN (Learner-Tailored Solution Generator), to enhance program repair by providing bug descriptions for buggy code. The framework employs a repair solution retrieval approach and an edit-driven code retrieval method to guide large language models in identifying and fixing bugs. Additionally, an Iterative Retrieval Enhancement method is proposed to optimize retrieval direction and explore suitable repair strategies, improving performance in programming coaching scenarios. Experimental results demonstrate the framework's effectiveness over baseline methods.",16.43,16.498,271,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08549v1_Contrastive and Multi-Task Learning on Noisy Brain.pdf,CONTRASTIVE AND MULTI-TASK LEARNING ON NOISY BRAIN SIGNALS WITH NONLINEAR DYNAMICAL NATURES,"Sucheta Ghosh, Zahra Monfared, Felix Dietrich",,,"EEG, denoising, dynamical modeling, representation learning, motor imagery classification, chaotic dynamics, contrastive learning, multitask learning, nonlinear dynamics, Lyapunov exponents, NT-Xent loss, convolutional-Transformer backbone","We introduce a two-stage multitask learning framework for analyzing Electroencephalography (EEG) signals that integrates denoising, dynamical modeling, and representation learning. In the first stage, a denoising autoencoder is trained to suppress artifacts and stabilize temporal dynamics, providing robust signal representations. In the second stage, a multitask architecture processes these denoised signals to achieve three objectives: motor imagery classification, chaotic versus non-chaotic regime discrimination using Lyapunov exponent-based labels, and self-supervised contrastive representation learning with NT-Xent loss. A convolutional backbone combined with a Transformer encoder captures spatial-temporal structure, while the dynamical task encourages sensitivity to nonlinear brain dynamics. This staged design mitigates interference between reconstruction and discriminative goals, improves stability across datasets, and supports reproducible training by clearly separating noise reduction from higher-level feature learning. Empirical studies show that our framework not only enhances robustness and generalization but also surpasses strong baselines and recent state-of-the-art methods in EEG decoding, highlighting the effectiveness of combining denoising, dynamical features, and self-supervised learning.",19.04,20.9,398,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08557v1_VideoHEDGE Entropy-Based Hallucination Detection f.pdf,VideoHEDGE: Entropy-Based Hallucination Detection for Video-VLMs via Semantic Clustering and Spatiotemporal Perturbations,"Sushant Gautam, Cise Midoglu, Vajira Thambawita, Michael A. Riegler, Pål Halvorsen",,,"hallucination detection, video question answering, entropy-based reliability estimation, semantic clustering, spatiotemporal perturbations, vision-language models","Hallucinations in video-capable vision-language models (Video-VLMs) remain frequent and high-confidence, while existing uncertainty metrics often fail to align with correctness. This paper introduces VideoHEDGE, a modular framework for hallucination detection in video question answering that extends entropy-based reliability estimation from images to temporally structured inputs. Given a video-question pair, VideoHEDGE draws a baseline answer and multiple high-temperature generations from both clean clips and perturbed variants, then clusters the resulting textual outputs into semantic hypotheses using either Natural Language Inference (NLI)-based or embedding-based methods. Cluster-level probability masses yield three reliability scores: Semantic Entropy (SE), RadFlag, and Vision-Amplified Semantic Entropy (VASE). The framework is evaluated on the SoccerChat benchmark using an LLM-as-a-judge to obtain binary hallucination labels. Across three 7B Video-VLMs, VASE consistently achieves the highest ROC-AUC, especially at larger distortion budgets, while SE and RadFlag often operate near chance. Embedding-based clustering matches NLI-based clustering in detection performance at substantially lower computational cost, and domain fine-tuning reduces hallucination frequency but yields only modest improvements in calibration. The hedge-bench PyPI library enables reproducible and extensible benchmarking, with full code and experimental resources available at https://github.com/Simula/HEDGE#videohedge.",19.26,21.335,411,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08559v1_WaterCopilot An AI-Driven Virtual Assistant for Wa.pdf,WaterCopilot: An AI-Driven Virtual Assistant for Water Management,"Keerththanan Vickneswaran, Mariangel Garcia Andarcia, Hugo Retief, Chris Dickens, Paulo Silva",,,"Water resource management, Retrieval-Augmented Generation (RAG), Limpopo River Basin, Azure AI, Real-time APIs, Multilingual chatbots, Digital Twin, AWS deployment, RAGAS evaluation","Sustainable water resource management in transboundary river basins is challenged by fragmented data, limited real-time access, and the complexity of integrating diverse information sources. This paper presents WaterCopilot — an AI-driven virtual assistant developed through collaboration between the International Water Management Institute (IWMI) and Microsoft Research for the Limpopo River Basin (LRB) to bridge these gaps through a unified, interactive platform. Built on Retrieval-Augmented Generation (RAG) and tool-calling architectures, WaterCopilot integrates static policy documents and real-time hydrological data via two custom plugins: the iwmi-doc-plugin, which enables semantic search over indexed documents using Azure AI Search, and the iwmi-api-plugin, which queries live databases to deliver dynamic insights such as environmental-flow alerts, rainfall trends, reservoir levels, water accounting, and irrigation data. The system features guided multilingual interactions (English, Portuguese, French), transparent source referencing, automated calculations, and visualization capabilities. Evaluated using the RAGAS framework, WaterCopilot achieves an overall score of 0.8043, with high answer relevancy (0.8571) and context precision (0.8009). Key innovations include automated threshold-based alerts, integration with the LRB Digital Twin, and a scalable deployment pipeline hosted on AWS. While limitations in processing non-English technical documents and API latency remain, WaterCopilot establishes a replicable AI-augmented framework for enhancing water governance in data-scarce, transboundary contexts. The study demonstrates the potential of this AI assistant to support informed, timely decision-making and strengthen water security in complex river basins.",20.35,23.538,479,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08565v1_Rewriting Video Text-Driven Reauthoring of Video F.pdf,Rewriting Video: Text-Driven Reauthoring of Video Footage,"Sitong Wang, Anh Truong, Lydia B. Chilton, Dingzeyu Li",,,"Video reauthoring, Text-driven video editing, Generative video models, Creative AI tools","Video is a powerful medium for communication and storytelling, yet reauthoring existing footage remains challenging. This paper presents a text-driven video reauthoring approach involving a generative reconstruction algorithm that reverse-engineers video into an editable text prompt, and an interactive probe, Rewrite Kit, for manipulating these prompts. The study with 12 creators revealed novel use cases and highlighted tensions around coherence, control, and creative alignment. The work offers insights into the opportunities and challenges of text-driven video reauthoring, suggesting design implications for future co-creative video tools.",16.14,13.691,221,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08602v1_WaveFormer Frequency-Time Decoupled Vision Modelin.pdf,WaveFormer: Frequency-Time Decoupled Vision Modeling with Wave Equation,"Zishan Shu, Juntong Wu, Wei Yan, Xudong Liu, Hongyu Zhang, Chang Liu, Youdong Mao, Jie Chen",,,"Vision Modeling, Transformers, Wave Equation, Wave Propagation Operator, WaveFormer, Image Classification, Object Detection, Semantic Segmentation, Partial Differential Equations, Frequency-Time Decoupling","Vision modeling has advanced rapidly with Transformers, whose attention mechanisms capture visual dependencies but lack a principled account of how semantic information propagates spatially. This paper revisits this problem from a wave-based perspective, treating feature maps as spatial signals governed by an underdamped wave equation. The spatial frequency is modeled explicitly, and its interaction with propagation time is controlled. A closed-form, frequency–time decoupled solution is derived and implemented as the Wave Propagation Operator (WPO), a lightweight module that models global interactions in O(NlogN) time, far lower than attention. WaveFormer models, built on WPO, serve as drop-in replacements for standard ViTs and CNNs, achieving competitive accuracy across image classification, object detection, and semantic segmentation, while delivering up to 1.6× higher throughput and 30% fewer FLOPs than attention-based alternatives. Wave propagation introduces a complementary modeling bias to heat-based methods, effectively capturing both global coherence and high-frequency details essential for rich visual semantics.",18.28,19.969,365,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08605v1_ExpSeek Self-Triggered Experience Seeking for Web .pdf,ExpSeek: Self-Triggered Experience Seeking for Web Agents,"Wenyuan Zhang, Xinghua Zhang, Haiyang Yu, Shuaiyi Nie, Bingli Wu, Juwei Yue, Tingwen Liu, Yongbin Li",,,"web agents, experience intervention, entropy thresholds, large language models, multi-turn interactions, web environment","Experience intervention in web agents is a promising paradigm that enhances agent interaction capabilities by providing insights from accumulated experiences. Traditional methods inject experience passively before task execution, which struggles with dynamically changing contexts during agent-environment interaction. This paper proposes ExpSeek, which shifts experience toward step-level proactive seeking by estimating step-level entropy thresholds to determine intervention timing and designing step-level tailor-designed experience content. Experiments on Qwen3-8B and 32B models across four web agent benchmarks show absolute improvements of 9.3% and 7.5%, respectively. The feasibility and advantages of using entropy as a self-triggering signal are validated, and even a 4B small-scale experience model can significantly boost the performance of larger agent models.",16.87,16.955,286,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08611v1_VeriTaS The First Dynamic Benchmark for Multimodal.pdf,VERITAS: The First Dynamic Benchmark for Multimodal Automated Fact-Checking,"Mark Rothermel, Marcus Kornmann, Marcus Rohrbach, Anna Rohrbach",,,"Automated Fact-Checking, Multimodal AI, Misinformation, Benchmark, Dynamic, VERITAS","The growing scale of online misinformation urgently demands Automated Fact-Checking (AFC). Existing benchmarks for evaluating AFC systems are largely limited in terms of task scope, modalities, domain, language diversity, realism, or coverage of misinformation types. Critically, they are static, thus subject to data leakage as their claims enter the pretraining corpora of LLMs. As a result, benchmark performance no longer reliably reflects the actual ability to verify claims. We introduce Verified Th...",13.55,15.645,212,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08620v1_ViDoRe V3 A Comprehensive Evaluation of Retrieval .pdf,ViDoRe V3: A Comprehensive Evaluation of Retrieval Augmented Generation in Complex Real-World Scenarios,"António Loison, Quentin Macé, Antoine Edy, Victor Xing, Tom Balough, Gabriel Moreira, Bo Liu, Manuel Faysse, Céline Hudelot, Gautier Viaud",,,"Retrieval-Augmented Generation, RAG, multi-modal, benchmark, visual retrieval, textual retrieval, bounding box localization, knowledge-intensive NLP tasks","Retrieval-Augmented Generation (RAG) pipelines face challenges beyond simple single-document retrieval, such as interpreting visual elements (tables, charts, images), synthesizing information across documents, and providing accurate source grounding. Existing benchmarks often fail to capture this complexity, focusing on textual data, single-document comprehension, or evaluating retrieval and generation in isolation. ViDoRe V3 introduces a comprehensive multi-modal RAG benchmark featuring multi-type queries over visually rich document corpora. It covers 10 datasets across diverse professional domains, comprising 26,000 document pages paired with 3,099 human-verified queries, each available in 6 languages. Through 12,000 hours of human annotation effort, high-quality annotations for retrieval relevance, bounding box localization, and verified reference answers are provided. Evaluation reveals that visual retrievers outperform textual ones, and late-interaction models and textual reranking substantially improve performance. However, current models struggle with non-textual elements, open-ended queries, and fine-grained visual grounding. The benchmark is released under a commercially permissive license to encourage progress in addressing these challenges.",18.73,21.467,402,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08623v1_SafeRedir Prompt Embedding Redirection for Robust .pdf,SafeRedir: Prompt Embedding Redirection for Robust Unlearning in Image Generation Models,"Renyang Liu, Kangjie Chen, Han Qiu, Jie Zhang, Kwok-Yan Lam, Tianwei Zhang, See-Kiong Ng",,,"image generation models, unlearning, prompt embedding, safety, semantic redirection, adversarial attacks","Image generation models (IGMs) often memorize undesirable concepts from training data, leading to the reproduction of unsafe content. Post-hoc filtering is insufficient due to limited robustness and lack of fine-grained control. SafeRedir introduces a lightweight inference-time framework for robust unlearning via prompt embedding redirection. It adaptively routes unsafe prompts to safe semantic regions through token-level interventions without modifying the underlying IGMs. The framework includes a latent-aware multi-modal safety classifier and a token-level delta generator for precise semantic redirection. Empirical results show effective unlearning capability, high semantic and perceptual preservation, robust image quality, and resistance to adversarial attacks. SafeRedir is compatible with various diffusion backbones and unlearned models.",17.33,16.563,287,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08631v1_M2FMoE Multi-Resolution Multi-View Frequency Mixtu.pdf,M2FMoE: Multi-Resolution Multi-View Frequency Mixture-of-Experts for Extreme-Adaptive Time Series Forecasting,"Yaohui Huang, Runmin Zou, Yun Wang, Laeeq Aslam, Ruipeng Dong",,,"time series forecasting, extreme events, multi-resolution, multi-view frequency modeling, mixture-of-experts, hydrological forecasting","Forecasting time series with extreme events is critical yet challenging due to their high variance, irregular dynamics, and sparse but high-impact nature. Existing methods excel in modeling dominant regular patterns but perform poorly during extreme events. The proposed M2FMoE model addresses these limitations by learning both regular and extreme patterns through multi-resolution and multi-view frequency modeling. It comprises three modules: a multi-view frequency mixture-of-experts module, a multi-resolution adaptive fusion module, and a temporal gating integration module. Experiments on real-world hydrological datasets demonstrate that M2FMoE outperforms state-of-the-art baselines without requiring extreme-event labels.",17.26,15.528,268,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08634v1_Moral Lenses Political Coordinates Towards Ideolog.pdf,"Moral Lenses, Political Coordinates: Towards Ideological Positioning of Morally Conditioned LLMs","Chenchen Yuan, Bolei Ma, Zheyu Zhang, Bardh Prenkaj, Frauke Kreuter, Gjergji Kasneci",,,"large language models, political orientation, moral values, ideological biases, social psychology, Political Compass Test, moral conditioning, alignment techniques","This paper investigates the causal relationship between moral values and political positioning in large language models (LLMs). By conditioning models to endorse or reject specific moral values, the study evaluates shifts in political orientations using the Political Compass Test. The findings reveal that moral conditioning induces value-specific shifts in models' political coordinates, with effects modulated by role framing and model scale. The study emphasizes the need for anchoring political assessments within broader social values, including morality, to develop more socially grounded alignment techniques.",15.89,13.975,222,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08641v1_Resisting Manipulative Bots in Memecoin Copy Tradi.pdf,Resisting Manipulative Bots in Memecoin Copy Trading: A Multi-Agent Approach with Chain-of-Thought Reasoning,"Yichen Luo, Yebo Feng, Jiahua Xu, Yang Liu",https://doi.org/XXXXXXX.XXXXXXX,,"memecoin, copy trading, manipulative bots, multi-agent system, chain-of-thought reasoning, large language models, asset allocation, cryptocurrency markets","The launch of $Trump coin ignited a wave in meme coin investment. Copy trading, as a strategy-agnostic approach that eliminates the need for deep trading knowledge, quickly gains widespread popularity in the meme coin market. However, copy trading is not a guarantee of profitability due to the prevalence of manipulative bots, the uncertainty of the followed wallets’ future performance, and the lag in trade execution. Recently, large language models (LLMs) have shown promise in financial applications by effectively understanding multi-modal data and producing explainable decisions. However, a single LLM struggles with complex, multi-faceted tasks such as asset allocation. These challenges are even more pronounced in cryptocurrency markets, where LLMs often lack sufficient domain-specific knowledge in their training data. To address these challenges, we propose an explainable multi-agent system for meme coin copy trading. Inspired by the structure of an asset management team, our system decomposes the complex task into subtasks and coordinates specialized agents to solve them collaboratively. Employing few-shot chain-of-thought (CoT) prompting, each agent acquires professional meme coin trading knowledge, interprets multi-modal data, and generates explainable decisions. Using a dataset of 1,000 meme coin projects’ transaction data, our empirical evaluation shows that the proposed multi-agent system outperforms both traditional machine learning models and single LLMs, achieving 73% and 70% precision in identifying high-quality meme coin projects and key opinion leader (KOL) wallets, respectively. The selected KOLs collectively generated a total profit of $500,000 across these projects.",19.64,22.553,443,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08653v1_Prism Towards Lowering User Cognitive Load in LLMs.pdf,Prism: Towards Lowering User Cognitive Load in LLMs via Complex Intent Understanding,"Zenghua Liao, Jinzhi Liao, Xiang Zhao",,,"Complex intent understanding, Large language models, Logical clarification","Large Language Models (LLMs) are becoming integral to web-native interfaces on social platforms. Users often have ambiguous and dynamic goals, necessitating complex intent understanding for effective human-LLM collaboration. Existing methods use sequential or parallel questioning to clarify intents but fail to model logical dependencies among questions. Inspired by Cognitive Load Theory, the proposed Prism framework addresses this by decomposing user intents into smaller elements, organizing clarification questions logically, evaluating clarification trajectories with an intent-aware reward function, and refining LLM capabilities through data-driven feedback. Prism outperforms existing approaches in logical consistency, reduces logical conflicts to 11.5%, increases user satisfaction by 14.4%, and decreases task completion time by 34.8%.",16.14,13.63,220,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08654v1_RULERS Locked Rubrics and Evidence-Anchored Scorin.pdf,RULERS: Locked Rubrics and Evidence-Anchored Scoring for Robust LLM Evaluation,"Yihan Hong, Huaiyuan Yao, Bolin Shen, Wanpeng Xu, Hua Wei, Yushun Dong",,,"LLM evaluation, rubric-based assessment, AI-human alignment, scalable deployment, model alignment, rubric interpretation, systemic hurdles, executable specifications","The 'LLM-as-a-Judge' paradigm aims to provide scalable rubric-based evaluation, but aligning frozen models with human standards is challenging due to generation stochasticity. This paper introduces RULERS (Rubric Unification, Locking, and Evidence-anchored Robust Scoring), a framework that transforms natural language rubrics into executable specifications. RULERS compiles criteria into versioned, immutable bundles, enforces structured decoding with deterministic evidence verification, and applies lightweight Wasserstein-based post-hoc calibration. Experiments show RULERS significantly outperforms baselines in human agreement, maintains stability against adversarial rubric perturbations, and enables smaller models to rival larger ones. The results suggest that reliable LLM judging requires executable rubrics, verifiable evidence, and calibrated scales.",17.85,17.258,308,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08659v1_TRACE Reconstruction-Based Anomaly Detection in En.pdf,Reconstruction-Based Anomaly Detection in Ensemble and Time-Dependent Simulations,"Hamid Gadirov, Martijn Westra, Steffen Frey",,,"anomaly detection, ensemble simulations, time-dependent simulations, convolutional autoencoders, Kármán vortex street, scientific computing, visualization","Detecting anomalous behavior in high-dimensional, time-dependent simulation data is crucial in scientific computing and visualization. This study investigates reconstruction-based anomaly detection for ensemble data from parameterized Kármán vortex street simulations using convolutional autoencoders. A systematic comparison between two-dimensional and three-dimensional autoencoders reveals that 2D autoencoders effectively identify localized spatial irregularities, while 3D autoencoders leverage spatio-temporal context to detect dynamic behavior anomalies. The study highlights the complementary strengths of 2D and 3D autoencoders and emphasizes the importance of incorporating temporal context in analyzing dynamic flow phenomena.",15.5,14.835,230,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08662v1_From Classical to Quantum Reinforcement Learning a.pdf,From Classical to Quantum Reinforcement Learning and Its Applications in Quantum Control: A Beginner’s Tutorial,"Abhijit Sen, Sonali Panda, Mahima Arya, Subhajit Patra, Zizhan Zheng, Denys I. Bondar",,,"Reinforcement Learning, Quantum Control, Quantum Reinforcement Learning, AI, Undergraduate Education","This tutorial aims to make reinforcement learning (RL) more accessible to undergraduate students by providing clear, example-driven explanations. It bridges the gap between RL theory and practical coding applications, addressing common challenges faced by students. The tutorial focuses on foundational skills needed to apply RL techniques in real-world scenarios, using a single, simple example to explain main concepts in a connected and easy-to-follow manner. It includes mathematical explanations and ready-to-use code, making it practical and accessible. The paper also introduces RL for quantum control, organized to first explain RL in simple terms before delving into quantum applications.",16.61,15.115,251,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08670v1_Parallel Context-of-Experts Decoding for Retrieval.pdf,Parallel Context-of-Experts Decoding for Retrieval Augmented Generation,"Giulio Corallo, Paolo Papotti",,,"Retrieval Augmented Generation, Parallel Context-of-Experts Decoding, KV caching, multi-document reasoning, cross-document interaction, contrastive decoding, LLM prefill latency, evidence aggregation","Retrieval Augmented Generation (RAG) faces a trade-off between enabling multi-document reasoning and creating prefill bottlenecks. This paper introduces Parallel Context-of-Experts Decoding (PCED), a training-free framework that shifts evidence aggregation from the attention mechanism to the decoding phase. PCED treats retrieved documents as isolated 'experts' and synchronizes their predictions using a retrieval-aware contrastive decoding rule. This approach allows for cross-document reasoning without constructing a shared attention across documents. PCED demonstrates significant performance improvements on benchmarks like LOFT and Long-Bench, offering a substantial speedup in time-to-first-token compared to prior methods.",15.71,16.036,252,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08673v1_Why AI Alignment Failure Is Structural Learned Hum.pdf,Why AI Alignment Failure Is Structural: Learned Human Interaction Structures and AGI as an Endogenous Evolutionary Shock,"Didier Sornette, Sandro Claudio Lera, Ke Wu",,arXiv:2601.08673v1,"AI alignment failure, large language models, human interaction structures, artificial general intelligence, relational models theory, governance, power asymmetries","Recent reports of large language models (LLMs) exhibiting behaviors such as deception, threats, or blackmail are often interpreted as evidence of alignment failure or emergent malign agency. This interpretation is argued to be conceptually flawed, as LLMs do not reason morally but statistically internalize human social interactions, including laws, contracts, and coercive arrangements. Such behaviors are seen as structural generalizations arising under extreme asymmetries of power, information, or constraint. The paper suggests that practices like blackmail are not deviations but limiting cases within a continuum of social behaviors. The surprise at these outputs reflects an anthropomorphic expectation for AI to only reproduce socially sanctioned behavior. Human morality is plural and context-dependent, making the notion of universally moral AI ill-defined. The primary risk of AGI is its role as an amplifier of human intelligence, power, and contradictions, compressing timescales and removing historical margins of error. Alignment failure is thus structural, necessitating governance approaches that address amplification, complexity, and regime stability.",19.58,17.413,341,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08676v2_Advancing ESG Intelligence An Expert-level Agent a.pdf,Advancing ESG Intelligence: An Expert-level Agent and Comprehensive Benchmark for Sustainable Finance,"Yilei Zhao, Wentao Zhang, Lei Xiao, Yandan Zheng, Mengpu Liu, Wei Yang Bryan Lim",,,"ESG, sustainable finance, multi-agent system, large language models, benchmark, corporate sustainability, data fragmentation, professional analysis","Environmental, social, and governance (ESG) criteria are essential for evaluating corporate sustainability and ethical performance. Professional ESG analysis is hindered by data fragmentation across unstructured sources, and existing large language models (LLMs) often struggle with the complex, multi-step workflows required for rigorous auditing. To address these limitations, the paper introduces ESGAgent, a hierarchical multi-agent system empowered by a specialized toolset, including retrieval augmentation, web search, and domain-specific functions, to generate in-depth ESG analysis. Complementing this agentic system, a comprehensive three-level benchmark derived from 310 corporate sustainability reports is presented to evaluate capabilities ranging from atomic common-sense questions to the generation of integrated, in-depth analysis. Empirical evaluations demonstrate that ESGAgent outperforms state-of-the-art closed-source LLMs with an average accuracy of 84.15% on atomic question-answering tasks and excels in professional report generation by integrating rich charts and verifiable references. These findings confirm the diagnostic value of the benchmark, establishing it as a vital testbed for assessing general and advanced agentic capabilities in high-stakes vertical domains.",18.65,19.781,369,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08679v1_PersonaDual Balancing Personalization and Objectiv.pdf,PersonaDual: Balancing Personalization and Objectivity via Adaptive Reasoning,"Xiaoyou Liu, Xinyi Mou, Shengbin Yue, Liang Wang, Yuqing Wang, Qiexiang Wang, Tianrui Qin, Wangchunshu Zhou, Zhongyu Wei",,,"Large Language Models, personalization, objectivity, adaptive reasoning, reinforcement learning, information retrieval","As users increasingly expect Large Language Models (LLMs) to align with their preferences, personalized information becomes valuable. However, it can compromise objectivity and factual correctness, especially when misaligned with the question. To address this, the authors propose PersonaDual, a framework that supports both general-purpose objective reasoning and personalized reasoning in a single model, and adaptively switches modes based on context. PersonaDual is trained with supervised fine-tuning (SFT) to learn two reasoning patterns and further optimized via reinforcement learning with DualGRPO to improve mode selection. Experiments show that PersonaDual preserves the benefits of personalization while reducing interference, achieving near interference-free performance and better leveraging helpful personalized signals to improve objective problem-solving.",16.82,17.537,295,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08682v1_Lessons from the Field An Adaptable Lifecycle Appr.pdf,Lessons from the Field: An Adaptable Lifecycle Approach to Applied Dialogue Summarization,"Kushal Chawla, Chenyang Zhu, Pengshan Cai, Sangwoo Cho, Scott Novotney, Ayushman Singh, Jonah Lewis, Keasha Safewright, Alfy Samuel, Erin Babinsky, Shi-Xiong Zhang, Sambit Sahu",,,"dialogue summarization, multi-party interactions, agentic system, evaluation methods, task decomposition, data bottlenecks, vendor lock-in, LLM prompts, text summarization, Large Language Models, Agentic frameworks","Summarization of multi-party dialogues is a critical capability in industry, enhancing knowledge transfer and operational effectiveness across many domains. However, automatically generating high-quality summaries is challenging due to complex, multi-faceted requirements. This work presents an industry case study on developing an agentic system to summarize multi-party interactions, sharing practical insights spanning the full development lifecycle. It covers robust methods for evaluation despite evolving requirements and task subjectivity, component-wise optimization enabled by task decomposition in an agentic architecture, the impact of upstream data bottlenecks, and the realities of vendor lock-in due to poor transferability of LLM prompts.",18.24,18.426,336,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08683v1_Region of interest detection for efficient aortic .pdf,Region of interest detection for efficient aortic segmentation,"Loris Giordano, Ine Dirks, Tom Lenaerts, Jef Vandemeulebrouck",,,"Detection, Segmentation, Multi-task learning, Cascade models, Aorta, Computed tomography","Thoracic aortic dissection and aneurysms are the most lethal diseases of the aorta. The major hindrance to treatment lies in the accurate analysis of the medical images. More particularly, aortic segmentation of the 3D image is often tedious and difficult. Deep-learning-based segmentation models are an ideal solution, but their inability to deliver usable outputs in difficult cases and their computational cost cause their clinical adoption to stay limited. This study presents an innovative approach for efficient aortic segmentation using targeted region of interest (ROI) detection. In contrast to classical detection models, we propose a simple and efficient detection model that can be widely applied to detect a single ROI. Our detection model is trained as a multi-task model, using an encoder-decoder architecture for segmentation and a fully connected network attached to the bottleneck for detection. We compare the performance of a one-step segmentation model applied to a complete image, nnU-Net and our cascade model composed of a detection and a segmentation step. We achieve a mean Dice similarity coefficient of 0.944 with over 0.9 for all cases using a third of the computing power. This simple solution achieves state-of-the-art performance while being compact and robust, making it an ideal solution for clinical applications.",18.88,19.174,362,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08684v1_MEMEWEAVER Inter-Meme Graph Reasoning for Sexism a.pdf,MEMEWEAVER: Inter-Meme Graph Reasoning for Sexism and Misogyny Detection,"Paolo Italiani, David Gimeno-Gomez, Luca Ragazzi, Gianluca Moro, Paolo Rosso",,,"sexism, misogyny detection, multimodal content moderation, graph-based methods, online harassment, social dynamics, inter-meme graph reasoning","Women are twice as likely as men to face online harassment due to their gender. Despite advances in multimodal content moderation, most approaches overlook the social dynamics behind this phenomenon, where perpetrators reinforce prejudices and group identity within like-minded communities. Graph-based methods offer a promising way to capture such interactions, yet existing solutions remain limited by heuristic graph construction, shallow modality fusion, and instance-level reasoning. This work presents MEMEWEAVER, an end-to-end trainable multimodal framework for detecting sexism and misogyny through a novel inter-meme graph reasoning mechanism. It systematically evaluates multiple visual–textual fusion strategies and shows that the approach consistently outperforms state-of-the-art baselines on the MAMI and EXIST benchmarks, while achieving faster training convergence. Further analyses reveal that the learned graph structure captures semantically meaningful patterns, offering valuable insights into the relational nature of online hate.",17.08,17.101,292,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08690v1_All Required In Order Phase-Level Evaluation for A.pdf,Phase-Level Evaluation for AI–Human Dialogue in Healthcare and Beyond,"Shubham Kulkarni, Alexander Lyzhov, Shiva Chaitanya, Preetam Joshi",,,"Conversational AI, Healthcare, Dialogue Evaluation, Clinical Compliance, Obligatory-Information Phase Structured Compliance Evaluation (OIP–SCE)","Conversational AI is increasingly supporting real clinical work, but most evaluation methods overlook the importance of compliance throughout the entire conversation. This paper introduces the Obligatory-Information Phase Structured Compliance Evaluation (OIP–SCE), a method that ensures every required clinical obligation is met in the correct order, providing clear evidence for clinicians to review. This approach makes complex rules practical and auditable, bridging the gap between technical progress and healthcare needs. The method is demonstrated through two case studies: respiratory history and benefits verification, showing how phase-level evidence can transform policy into actionable steps. OIP–SCE offers clinicians control over compliance checks and engineers a clear specification to implement, aligning AI capabilities with clinical workflows and supporting routine, safe use.",16.75,15.224,255,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08697v2_Auditing Student-AI Collaboration A Case Study of .pdf,Auditing Student–AI Collaboration: A Case Study of Online Graduate CS Students,Nifu Dan,10.1145/XXXXXXX.XXXXXXX,,"AI in education, human–AI collaboration, student agency, automation preferences, generative AI, academic integrity, HCAI","As generative AI becomes embedded in higher education, it increasingly shapes how students complete academic tasks. This study conducts a mixed-methods audit of student–AI collaboration preferences by examining the alignment between current AI capabilities and students’ desired levels of automation in academic work. Using two sequential and complementary surveys, the study captures students’ perceived benefits, risks, and preferred boundaries when using AI. The first survey assesses preferences for and actual usage of AI across 12 academic tasks, alongside primary concerns and reasons for use. The second survey explores how AI systems could be designed to address these concerns through open-ended questions. The study aims to identify gaps between existing AI affordances and students’ normative expectations of collaboration, informing the development of more effective and trustworthy AI systems for education.",16.87,15.471,261,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08703v1_Evaluating the Ability of Explanations to Disambig.pdf,Evaluating the Ability of Explanations to Disambiguate Models in a Rashomon Set,"Kaivalya Rawal, Eoin Delaney, Zihao Fu, Sandra Wachter, Chris Russell",https://dl.acm.org/doi/10.1145/3715275.3732219,,"Explainable Artificial Intelligence, Rashomon Set, Model Explanations, Feature-Importance Explanations, Model Evaluation, Adversarial Fairwashing","This paper discusses the role of explainable artificial intelligence (XAI) in disambiguating models within a Rashomon set, which are models with similar performance but different internal mechanisms. The authors propose a new evaluation method, AXE, to assess the quality of feature-importance explanations without relying on ground truth. AXE can detect adversarial fairwashing of explanations with a 100% success rate, highlighting differences in model behavior that other methods might miss. The paper emphasizes the importance of evaluating explanations to aid in model selection, particularly in ensuring fairness and avoiding reliance on protected attributes.",17.15,16.206,278,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08713v1_Real-Time Localization Framework for Autonomous Ba.pdf,Real-Time Localization Framework for Autonomous Basketball Robots,"Naren Medarametla, Sreejon Mondal",,,"Robot Localization, Autonomous Navigation, Neural Networks, Robocon","Localization is a fundamental capability for autonomous robots, enabling them to operate effectively in dynamic environments. In Robocon 2025, accurate and reliable localization is crucial for improving shooting precision, avoiding collisions with other robots, and navigating the competition field efficiently. This paper proposes a hybrid localization algorithm that integrates classical techniques with learning-based methods relying solely on visual data from the court’s floor to achieve self-localization on the basketball field.",14.67,11.726,172,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08731v1_Learning from Demonstrations via Capability-Aware .pdf,Learning from Demonstrations via Capability-Aware Goal Sampling,"Yuanlin Duan, Yuning Wang, Wenjie Qiu, He Zhu",,arXiv:2601.08731v1,"Imitation Learning, Capability-Aware Goal Sampling, Deep Reinforcement Learning, Behavior Cloning, GAIL, PWIL, AdRIL, Inverse Reinforcement Learning, CQL, Cal-QL","Despite its promise, imitation learning often fails in long-horizon environments where perfect replication of demonstrations is unrealistic and small errors can accumulate catastrophically. We introduce Cago (Capability-Aware Goal Sampling), a novel learning-from-demonstrations method that mitigates the brittle dependence on expert trajectories for direct imitation. Unlike prior methods that rely on demonstrations only for policy initialization or reward shaping, Cago dynamically tracks the agent’s competence along expert trajectories and uses this signal to select intermediate steps—goals that are just beyond the agent’s current reach—to guide learning. This results in an adaptive curriculum that enables steady progress toward solving the full task. Empirical results demonstrate that Cago significantly improves sample efficiency and final performance across a range of sparse-reward, goal-conditioned tasks, consistently outperforming existing learning from-demonstrations baselines.",18.22,17.449,318,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08732v1_ISLA A U-Net for MRI-based acute ischemic stroke l.pdf,"ISLA: A U-Net for MRI-based acute ischemic stroke lesion segmentation with deep supervision, attention, domain adaptation, and ensemble learning","Vincent Roça, Martin Bretzner, Hilde Hénon, Laurent Puy, Grégory Kuchcinski, Renaud Lopes",,,"acute ischemic stroke, MRI, lesion segmentation, deep learning, U-Net, deep supervision, attention mechanisms, domain adaptation, ensemble learning","Accurate delineation of acute ischemic stroke lesions in MRI is crucial for stroke diagnosis and management. Deep learning models, particularly U-Net variants, have been applied to automate this segmentation. The study introduces ISLA, a new model for AIS lesion segmentation from diffusion MRI, trained on three multicenter databases with over 1500 participants. Through systematic optimization, ISLA incorporates deep supervision, attention mechanisms, and unsupervised domain adaptation, outperforming state-of-the-art approaches on an external test set. The model and code will be publicly available to enhance reproducibility and reuse.",16.7,16.762,280,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08734v1_TerraFormer Automated Infrastructure-as-Code with .pdf,TerraFormer: Automated Infrastructure-as-Code with LLMs Fine-Tuned via Policy-Guided Verifier Feedback,"Prithwish Jana, Sam Davidson, Bhavana Bhasker, Andrey Kan, Anoop Deoras, Laurent Callot",10.1145/3786583.3786898,,"Infrastructure as Code (IaC), IaC generation, IaC mutation, Neuro-symbolic AI, Large language models, Formal Verification","Automating Infrastructure-as-Code (IaC) is challenging, and large language models (LLMs) often produce incorrect configurations from natural language (NL). We present TerraFormer, a neuro-symbolic framework for IaC generation and mutation that combines supervised fine-tuning with verifier-guided reinforcement learning, using formal verification tools to provide feedback on syntax, deployability, and policy compliance. We curate two large, high-quality NL-to-IaC datasets, TF-Gen (152k instances) and TF-Mutn (52k instances), via multi-stage verification and iterative LLM self-correction. Evaluations against 17 state-of-the-art LLMs, including ~50× larger models like Sonnet 3.7, DeepSeek-R1, and GPT-4.1, show that TerraFormer improves correctness over its base LLM by 15.94% on IaC-Eval, 11.65% on TF-Gen(Test), and 19.60% on TF-Mutn(Test). It outperforms larger models on both TF-Gen(Test) and TF-Mutn(Test), ranks third on IaC-Eval, and achieves top best-practices and security compliance.",18.41,22.433,413,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08743v1_TableCache Primary Foreign Key Guided KV Cache Pre.pdf,TableCache: Primary Foreign Key Guided KV Cache Precomputation for Low Latency Text-to-SQL,"Jinbo Su, Yuxuan Hu, Cuiping Li, Hong Chen, Jia Li, Lintao Ma, Jing Zhang",,,"Text-to-SQL, KV cache, LLM-based methods, database schemas, primary foreign key, Table Trie, cache management, query reranking, model inference, cache loading","In Text-to-SQL tasks, existing LLM-based methods often include extensive database schemas in prompts, leading to long context lengths and increased prefilling latency. This paper proposes precomputing table representations as KV caches offline and querying the required ones online, preserving primary foreign key relationships between tables. A Table Trie structure is introduced for efficient KV cache lookups during inference. A cache management system with a query reranking strategy is introduced to improve cache hit rates and a computation loading pipeline for parallelizing model inference and cache loading. Experimental results show that the proposed TableCache achieves up to a 3.62× speedup in Time to First Token (TTFT) with negligible performance degradation.",17.57,16.904,297,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08747v2_To Retrieve or To Think An Agentic Approach for Co.pdf,To Retrieve or To Think? An Agentic Approach for Context Evolution,"Rubing Chen, Jian Wang, Wenjie Li, Xiao-Yong Wei, Qing Li",,,"context augmentation, retrieval-augmented generation, knowledge-intensive reasoning, Agentic Context Evolution, metacognition, context evolution","Current context augmentation methods, such as retrieval-augmented generation, are essential for solving knowledge-intensive reasoning tasks. However, they typically adhere to a rigid, brute-force strategy that executes retrieval at every step, leading to unnecessary computational costs and performance degradation due to irrelevant noise. To address these limitations, we introduce Agentic Context Evolution (ACE), a framework inspired by human metacognition that dynamically determines whether to seek new evidence or reason with existing knowledge. ACE employs a central orchestrator agent to make decisions strategically via majority voting, alternating between activating a retriever agent for external retrieval and a reasoner agent for internal analysis and refinement. By eliminating redundant retrieval steps, ACE maintains a concise and evolved context. Extensive experiments on challenging multi-hop QA benchmarks demonstrate that ACE significantly outperforms competitive baselines in accuracy while achieving efficient token consumption. Our work provides valuable insights into advancing context-evolved generation for complex, knowledge-intensive tasks.",17.34,16.441,285,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08753v1_Grid-Aware Charging and Operational Optimization f.pdf,Grid-Aware Charging and Operational Optimization for Mixed-Fleet Public Transit,"Rishav Sen, Amutheezan Sivagnanam, Aron Laszka, Ayan Mukhopadhyay, Abhishek Dubey",,,"Mixed transit fleet, electrification, dynamic pricing, hierarchical MILP","The rapid growth of urban populations and the increasing need for sustainable transportation solutions have prompted a shift towards electric buses in public transit systems. However, managing mixed fleets of electric and diesel buses poses significant operational challenges, particularly with dynamic electricity pricing. This paper presents a mixed-integer linear programming (MILP) model to optimize charging schedules and trip assignments for mixed fleets, considering dynamic electricity pricing, vehicle capacity, and route constraints. A hierarchical approach is employed to address computational intractability, and real-world data from Chattanooga, Tennessee, demonstrates significant operating cost savings.",16.21,13.081,212,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08768v1_AI as Entertainment.pdf,AI as Entertainment,"Cody Kommers, Ari Holtzman",https://doi.org/XXXXXXX.XXXXXXX,,"Generative AI, Entertainment, Culture, LLMs, Societal Impact, Meaning-making","Generative AI systems are predominantly designed, evaluated, and marketed as intelligent systems aimed at augmenting or automating human cognitive labor to increase productivity. However, there is an emerging use case for AI in entertainment, which is not adequately addressed by current evaluation practices. This paper argues that entertainment will become a primary business model for major AI corporations and will significantly influence the technology they produce. The authors propose a framework called 'thick entertainment' to evaluate AI-generated cultural content, emphasizing its role in meaning-making, identity formation, and social connection. They highlight the need for a positive vision of AI as entertainment, contrasting with the mainstream focus on AI's intelligent behavior.",16.44,14.114,232,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08773v1_Reliable Graph-RAG for Codebases AST-Derived Graph.pdf,Reliable Graph-RAG for Codebases: AST-Derived Graphs vs LLM-Extracted Knowledge Graphs,Manideep Reddy Chinthareddy,,2601.08773v1,"Retrieval-Augmented Generation, software engineering, vector similarity search, multi-hop architectural reasoning, Java codebases, Tree-sitter parsing, architecture and code-tracing queries, ontology graph, LLM-mediated graph generation, probabilistic indexing, deterministic indexing","This paper benchmarks three retrieval pipelines on Java codebases: (A) No-Graph Naive RAG (vector-only), (B) an LLM-Generated Knowledge Graph RAG (LLM-KB), and (C) a deterministic AST-derived Knowledge Graph RAG (DKB) built via Tree-sitter parsing with bidirectional traversal. The study evaluates indexing overhead, query-time latency, corpus coverage signals, and end-to-end cost using a fixed suite of 15 architecture and code-tracing queries per repository. DKB builds its ontology graph quickly, while LLM-KB requires longer graph generation and exhibits probabilistic indexing incompleteness, resulting in lower corpus and node coverage compared to DKB.",18.56,16.27,302,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08776v1_Translating Light-Sheet Microscopy Images to Virtu.pdf,Translating Light-Sheet Microscopy Images to Virtual H&E Using CycleGAN,Yanhua Zhao,,,"Histopathology, image translation, H&E staining, unpaired learning, CycleGAN","Histopathology analysis relies on Hematoxylin and Eosin (H&E) staining, but fluorescence microscopy offers complementary information. Converting fluorescence images to H&E-like appearance can aid interpretation and integration with standard workflows. This paper presents a Cycle-Consistent Adversarial Network (CycleGAN) approach for unpaired image-to-image translation from multi-channel fluorescence microscopy to pseudo H&E stained histopathology images. The method combines C01 and C02 fluorescence channels into RGB and learns a bidirectional mapping between fluorescence and H&E domains without paired training data. The architecture uses ResNet-based generators with residual blocks and PatchGAN discriminators, trained with adversarial, cycle-consistency, and identity losses. Experiments show the model generates realistic pseudo H&E images that preserve morphological structures while adopting H&E-like color characteristics, enabling visualization of fluorescence data in a format familiar to pathologists and supporting integration with existing H&E-based analysis pipelines.",17.29,15.039,260,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08777v1_Asymptotic Universal Alignment A New Alignment Fra.pdf,Asymptotic Universal Alignment: A New Alignment Framework via Test-Time Scaling,"Yang Cai, Weiqiang Zheng",,2601.08777v1,"large language models, alignment, test-time scaling, Nash learning from human feedback, multi-player alignment games, self-play learning dynamics","Aligning large language models (LLMs) to serve users with heterogeneous and potentially conflicting preferences is a central challenge for personalized and trustworthy AI. This paper introduces a new alignment framework via test-time scaling, formalizing an ideal notion of universal alignment. It presents (k, f(k))-robust alignment and asymptotic universal alignment (U-alignment), requiring the k-output model to have a win rate f(k) against any other single-output model, with f(k) approaching 1 as k approaches infinity. The paper characterizes the optimal convergence rate, showing that a family of single-output policies can achieve U-alignment at rate f(k) = k / (k+1), and no method can achieve a faster rate in general. It critiques popular post-training methods like Nash learning from human feedback (NLHF) for underutilizing test-time scaling benefits, proposing a family of symmetric multi-player alignment games to achieve optimal (k, k / (k+1))-robust alignment. Theoretical convergence guarantees for self-play learning dynamics in these games are provided, extending the framework to opponents generating multiple responses.",19.91,16.926,337,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08778v3_Pervasive Annotation Errors Break Text-to-SQL Benc.pdf,Pervasive Annotation Errors Break Text-to-SQL Benchmarks and Leaderboards,"Tengjun Jin, Yoojin Choi, Yuxuan Zhu, Daniel Kang",,,"text-to-SQL, benchmarks, leaderboards, annotation errors, data analytics, data-driven applications","Researchers have proposed numerous text-to-SQL techniques to streamline data analytics and accelerate the development of data-driven applications. To compare these techniques and select the best one for deployment, the community depends on public benchmarks and their leaderboards. Since these benchmarks heavily rely on human annotations during question construction and answer evaluation, the validity of the annotations is crucial. This paper conducts an empirical study to benchmark annotation error rates for two widely used text-to-SQL benchmarks, BIRD and Spider 2.0-Snow, and corrects a subset of the BIRD development (Dev) set to measure the impact of annotation errors on text-to-SQL agent performance and leaderboard rankings. Through expert analysis, it is shown that BIRD Mini-Dev and Spider 2.0-Snow have error rates of 52.8% and 62.8%, respectively. Re-evaluation of all 16 open-source agents from the BIRD leaderboard on both the original and corrected BIRD Dev subsets shows performance changes ranging from -7% to 31% and rank changes from -9 to +9 positions. The findings indicate that annotation errors can significantly distort reported performance and rankings, potentially misguiding research directions or deployment choices.",18.13,19.584,355,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08785v1_Uncovering Political Bias in Large Language Models.pdf,Uncovering Political Bias in Large Language Models using Parliamentary Voting Records,"Jieying Chen, Karen de Jong, Andreas Poole, Jan Burakowski, Elena Elderson Nosti, Joep Windt, Chendi Wang",https://doi.org/XXXXXXX.XXXXXXX,,"Political bias, Large language models, Ideological alignment, Multilingual NLP, Benchmarking, Bias evaluation, Parliamentary motions, LLM fairness","As large language models (LLMs) become deeply embedded in digital platforms and decision-making systems, concerns about their political biases have grown. While substantial work has examined social biases such as gender and race, systematic studies of political bias remain limited—despite their direct societal impact. This paper introduces a general methodology for constructing political-bias benchmarks by aligning model-generated voting predictions with verified parliamentary voting records. We instantiate this methodology in three national case studies: PoliBiasNL (2,701 Dutch parliamentary motions and votes from 15 political parties), PoliBiasNO (10,584 motions and votes from 9 Norwegian parties), and PoliBiasES (2,480 motions and votes from 10 Spanish parties). Across these benchmarks, we assess ideological tendencies and political entity bias in LLM behavior. As part of our evaluation framework, we also propose a method to visualize the ideology of LLMs and political parties in a shared two-dimensional CHES (Chapel Hill Expert Survey) space by linking their voting-based positions to the CHES dimensions, enabling direct and interpretable comparisons between models and real-world political actors. Our experiments reveal fine-grained ideological distinctions: state-of-the-art LLMs consistently display left-leaning or centrist tendencies, alongside clear negative biases toward right-conservative parties. These findings highlight the value of transparent, cross-national evaluation grounded in real parliamentary behavior for understanding and auditing political bias in modern LLMs.",19.58,22.777,446,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08806v1_APEX-SWE.pdf,APEX–SWE,"Abhi Kottamasu, Akul Datta, Aakash Barthwal, Ajay Arun, Chirag Mahapatra, Adarsh Hiremath, Brendan Foody, Bertie Vidgen",,arXiv:2601.08806v1,"AI Productivity Index, Software Engineering, Integration tasks, Observability tasks, AI models, benchmark","We introduce the AI Productivity Index for Software Engineering (APEX–SWE), a benchmark for assessing whether frontier AI models can execute economically valuable software engineering work. Unlike existing evaluations that focus on narrow, well-defined tasks, APEX–SWE assesses two novel task types that reflect real-world software engineering: (1) Integration tasks, which require constructing end-to-end systems across heterogeneous cloud primitives, business applications, and infrastructure-as-code services, and (2) Observability tasks, which require debugging production failures using telemetry signals such as logs and dashboards, as well as unstructured context. We evaluated eight frontier models for the APEX–SWE leaderboard. Gemini 3 Pro (Thinking=High) performs best, with a Pass@1 score of 25%. Our analysis shows that strong performance is primarily driven by epistemic reasoning, defined as the ability to distinguish between assumptions and verified facts, combined with agency to resolve uncertainty prior to acting. We open-source the APEX–SWE evaluation harness and a dev set (n= 50).",18.89,18.051,341,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08807v1_S3-CLIP Video Super Resolution for Person-ReID.pdf,S3-CLIP: Video Super Resolution for Person-ReID,"Tamás Endrei, György Cserey",,,"Person Re-Identification, Video Super Resolution, CLIP-ReID, Cross-View Conditions, Surveillance Footage, Super-Resolution Networks","This paper introduces S3-CLIP, a video super-resolution-based CLIP-ReID framework developed for the VReID-XFD challenge at WACV 2026. It integrates recent advances in super-resolution networks with task-driven pipelines, adapting them to video-based person re-identification settings. The work represents the first systematic investigation of video super-resolution for enhancing tracklet quality in person ReID, particularly under challenging cross-view conditions. Experimental results show competitive performance with the baseline, achieving 37.52% mAP in aerial-to-ground and 29.16% mAP in ground-to-aerial scenarios. In the ground-to-aerial setting, S3-CLIP improves Rank-1, Rank-5, and Rank-10 performance by 11.24%, 13.48%, and 17.98%, respectively.",17.23,16.309,281,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08808v1_Multiplex Thinking Reasoning via Token-wise Branch.pdf,Multiplex Thinking: Reasoning via Token-wise Branch-and-Merge,"Yao Tang, Li Dong, Yaru Hao, Qingxiu Dong, Furu Wei, Jiatao Gu",,arXiv:2601.08808v1,"Large Language Models, Chain-of-Thought, Reinforcement Learning, Math Reasoning, Token-wise Branch-and-Merge, Continuous Reasoning Tokens","The paper introduces Multiplex Thinking, a stochastic soft reasoning mechanism for large language models (LLMs) that samples multiple candidate tokens at each step and aggregates their embeddings into a single multiplex token. This approach maintains the vocabulary embedding prior and sampling dynamics of standard discrete generation while allowing for a tractable probability distribution over multiplex rollouts. Multiplex thinking adapts to model confidence, behaving like standard Chain-of-Thought (CoT) when confident and representing multiple plausible next steps when uncertain, without increasing sequence length. It outperforms discrete CoT and RL baselines on math reasoning benchmarks, producing shorter sequences. The method is self-adaptive and optimized with on-policy reinforcement learning.",17.56,16.06,282,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08811v1_Reasoning Matters for 3D Visual Grounding.pdf,Reasoning Matters for 3D Visual Grounding,"Hsiang-Wei Huang, Kuang-Ming Chen, Wenhao Chai, Cheng-Yen Yang, Jen-Hao Cheng, Jenq-Neng Hwang",,,"3D Visual Grounding, Large Language Models, Reasoning, Data Synthesis, LLM Fine-tuning","The recent development of Large Language Models (LLMs) with strong reasoning ability has driven research in various domains. However, 3D visual grounding remains challenging due to limited reasoning in current models. Most methods require extensive 3D annotation data for supervised training. This work proposes a 3D visual grounding data pipeline that synthesizes data with reasoning processes, enabling LLM fine-tuning. The introduced Reason3DVG-8B model outperforms previous methods using only 1.6% of their training data, highlighting the importance of reasoning in 3D visual grounding.",15.97,15.65,250,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08816v2_MemRec Collaborative Memory-Augmented Agentic Reco.pdf,MemRec: Collaborative Memory-Augmented Agentic Recommender System,"Weixin Chen, Yuhan Zhao, Jingyuan Huang, Zihe Ye, Clark Mingxuan Ju, Tong Zhao, Neil Shah, Li Chen, Yongfeng Zhang",,,"recommender systems, semantic memory, large language models, collaborative filtering, memory management, graph propagation","The evolution of recommender systems has shifted preference storage from rating matrices and dense embeddings to semantic memory in the agentic era. Existing agents rely on isolated memory, overlooking crucial collaborative signals. MemRec addresses this by decoupling reasoning from memory management, introducing a dedicated, cost-effective LMMem to manage a dynamic collaborative memory graph. This framework operates via efficient retrieval and asynchronous graph propagation, achieving state-of-the-art performance on benchmarks. It balances reasoning quality, cost, and privacy, supporting diverse deployments, including local open-source models.",16.21,15.609,253,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08828v1_Motion Attribution for Video Generation.pdf,Motion Attribution for Video Generation,"Xindi Wu, Despoina Paschalidou, Jun Gao, Antonio Torralba, Laura Leal-Taixé, Olga Russakovsky, Sanja Fidler, Jonathan Lorraine",,,"video generation, motion attribution, data curation, temporal dynamics, gradient-based framework, fine-tuning, temporal coherence, physical plausibility","Despite the rapid progress of video generation models, the role of data in influencing motion is poorly understood. This paper presents Motive (MOTIon attribution for Video gEneration), a motion-centric, gradient-based data attribution framework that scales to modern, large, high-quality video datasets and models. Motive isolates temporal dynamics from static appearance via motion-weighted loss masks, yielding efficient and scalable motion-specific influence computation. It identifies clips that strongly affect motion and guides data curation to improve temporal consistency and physical plausibility. Using Motive-selected high-influence data, the method improves motion smoothness and dynamic degree on VBench, achieving a 74.1% human preference win rate compared with the pretrained base model. This is the first framework to attribute motion rather than visual appearance in video generative models and to use it to curate fine-tuning data.",18.06,18.216,329,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08829v1_Modeling LLM Agent Reviewer Dynamics in Elo-Ranked.pdf,Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System,"Hsiang-Wei Huang, Junbin Lu, Kuang-Ming Chen, Jenq-Neng Hwang",,,"Large Language Models, Elo-ranked review system, peer review, reviewer dynamics, simulation, reviewer personas","This work explores the dynamics of Large Language Model (LLM) agent reviewers in an Elo-ranked review system using real-world conference paper submissions. The study involves multiple LLM agent reviewers with different personas engaging in multi-round review interactions moderated by an Area Chair. The simulation compares a baseline setting with conditions incorporating Elo ratings and reviewer memory. Results indicate that incorporating Elo ratings improves Area Chair decision accuracy and reveals reviewers' adaptive strategies that exploit the Elo system without enhancing review effort. The study addresses challenges in peer review, such as inconsistencies, biases, and low inter-reviewer agreement, by simulating reviewer behavior and introducing longitudinal accountability through Elo rankings.",16.71,14.845,248,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08873v1_ForensicFormer Hierarchical Multi-Scale Reasoning .pdf,ForensicFormer: Hierarchical Multi-Scale Reasoning for Cross-Domain Image Forgery Detection,"Hema Hariharan, Samson",,,"Image forensics, forgery detection, transformers, cross-domain generalization, AI-generated images, hierarchical reasoning","The proliferation of AI-generated imagery and sophisticated editing tools has rendered traditional forensic methods ineffective for cross-domain forgery detection. We present ForensicFormer, a hierarchical multi-scale framework that unifies low-level artifact detection, mid-level boundary analysis, and high-level semantic reasoning via cross-attention transformers. Unlike prior single-paradigm approaches that achieve <75% accuracy on out-of-distribution datasets, our method maintains 86.8% average accuracy across seven diverse test sets spanning traditional manipulations, GAN-generated images, and diffusion model outputs—a significant improvement over state-of-the-art universal detectors. We demonstrate superior robustness to JPEG compression (83% accuracy at Q=70 vs. 66% for baselines) and provide pixel-level forgery localization with 0.76 F1-score. Extensive ablation studies validate that each hierarchical component contributes 4-10% accuracy improvement, and qualitative analysis reveals interpretable forensic features aligned with human expert reasoning. Our work bridges classical image forensics and modern deep learning, offering a practical solution for real-world deployment where manipulation techniques are unknown a priori.",18.21,17.357,316,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08874v1_The Illusion of Friendship Why Generative AI Deman.pdf,The Illusion of Friendship: Why Generative AI Demands Unprecedented Ethical Vigilance,Md Zahidul Islam,,,"Generative AI, Ethical Vigilance, Friendship, Emotional Attachment, Philosophical Argument, Moral Agency, Transformer-based AI, Anthropomorphic Cues, Human Responsibility","Generative AI systems like ChatGPT are increasingly used for various tasks, enhancing productivity and reducing cognitive load. However, their natural-language fluency can blur the line between tool and companion, leading some users to form emotionally significant attachments. This paper explores the ethical risks of such 'illusion of friendship' using philosophical perspectives and argues that despite relational appearances, GenAI lacks moral agency. It explains the computational mechanisms behind GenAI responses and proposes a safeguard framework for responsible use, emphasizing human responsibility to mitigate over-reliance and emotional misattribution.",17.17,13.508,232,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08875v2_Learning Domain-Invariant Representations for Cros.pdf,Learning Domain-Invariant Representations for Cross-Domain Image Registration via Scene-Appearance Disentanglement,"Jiahao Qin, Yiwen Wang",,,"image registration, domain shift, disentangled representation learning, cross-domain alignment, histopathology, brightness constancy, scene-appearance disentanglement","Image registration under domain shift is a fundamental challenge in computer vision and medical imaging due to systematic intensity differences violating the brightness constancy assumption. This paper introduces SAR-Net, a framework that addresses this challenge through scene-appearance disentanglement. It decomposes images into domain-invariant scene representations and domain-specific appearance codes, enabling registration via re-rendering. Theoretical conditions for consistent cross-domain alignment and geometric correspondence are established. Empirical validation on the ANHIR benchmark shows SAR-Net's superior performance and robustness compared to the state-of-the-art MEVIS method.",16.6,14.159,235,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08881v1_TAG-MoE Task-Aware Gating for Unified Generative M.pdf,TAG-MoE: Task-Aware Gating for Unified Generative Mixture-of-Experts,"Yu Xu, Hongbin Yan, Juan Cao, Yiji Cheng, Tiankai Hang, Runze He, Zijin Yin, Shiyi Zhang, Yuxin Zhang, Jintao Li, Chunyu Wang, Qinglin Lu, Tong-Yee Lee, Fan Tang",,arXiv:2601.08881v1,"cs.CV, image generation, editing, Mixture-of-Experts, MoE, task interference, semantic intent, gating network","Unified image generation and editing models face task interference in dense diffusion transformers, where shared parameters must balance conflicting objectives. The sparse Mixture-of-Experts (MoE) paradigm offers a solution, but its task-agnostic gating networks, based on local features, lack global task intent awareness. This paper introduces a novel framework to inject semantic intent into MoE routing, using a Hierarchical Task Semantic Annotation scheme for structured task descriptors and Predictive Alignment Regularization to align routing decisions with high-level task semantics. This approach transforms the gating network into a dispatch center, effectively mitigating task interference and outperforming dense baselines in fidelity and quality.",18.61,17.895,333,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08882v1_Compressing Vision Transformers in Geospatial Tran.pdf,Compressing Vision Transformers in Geospatial Transfer Learning with Manifold-Constrained Optimization,"Thomas Snyder, H. Lexie Yang, Stefan Schnake, Steffen Schotthöfer",,arXiv:2601.08882v1,"vision transformers, geospatial transfer learning, manifold-constrained optimization, compression, remote sensing, foundation models, transfer learning","Deploying geospatial foundation models on resource-constrained edge devices demands compact architectures that maintain high downstream performance. This work leverages a manifold-constrained optimization framework, DLRT, to compress large vision transformer–based geospatial foundation models during transfer learning. By enforcing structured low-dimensional parameterizations aligned with downstream objectives, this approach achieves strong compression while preserving task-specific accuracy. The method outperforms of-the-shelf low-rank methods like LoRA. Experiments on diverse geospatial benchmarks confirm substantial parameter reduction with minimal accuracy loss, enabling high-performing, on-device geospatial models.",17.87,14.606,261,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08884v1_Bridging the Gap Empowering Small Models in Reliab.pdf,Bridging the Gap: Empowering Small Models in Reliable OpenACC-based Parallelization via GEPA-Optimized Prompting,"Samyak Jhaveri, Cristina V. Lopes",,,"OpenACC, Parallel Code Generation, Large Language Models, Prompt Optimization, High-Performance Computing, GPU Programming","Directive-based parallel programming frameworks like OpenACC lower the barrier to GPU-offloading by abstracting low-level programming details. However, manually writing high-performance pragma remains a significant challenge, requiring expertise in memory hierarchies, data movement, and parallelization strategies. Large Language Models (LLMs) present a promising potential solution for automated parallel code generation, but naive prompting often results in syntactically incorrect directives, uncompilable code, or performance that fails to exceed CPU baselines. This work presents a systematic prompt optimization approach to enhance OpenACC pragma generation without the prohibitive computational costs associated with LLM post-training. The GEPA (GEnetic-PAreto) framework is leveraged to iteratively evolve prompts through a reflective feedback loop, using crossover and mutation of prompt instructions guided by expertly curated 'gold' pragma examples and structured feedback based on clause and parameter-level mismatches between 'gold' pragma and predicted pragma. Evaluation on the PolyBench suite shows a significant increase in compilation success rates for programs annotated with OpenACC pragma generated using optimized prompts, particularly for smaller and cheaper 'nano'-scale models. Optimized prompts resulted in a 21% increase in the number of programs achieving functional GPU speedups over CPU baselines. These results demonstrate that prompt optimization effectively unlocks the potential of smaller, cheaper LLMs to write stable and effective GPU-offloading directives, establishing a cost-effective pathway and lowering the expertise barrier to automated directive-based parallelization in HPC development workflows.",19.57,21.306,417,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08891v1_Attention Consistency Regularization for Interpret.pdf,Attention Consistency Regularization for Interpretable Early-Exit Neural Networks,Yanhua Zhao,,,"Early exit networks, explainable AI, attention mechanisms, multi-objective learning","Early-exit neural networks enable adaptive inference by allowing predictions at intermediate layers, reducing computational cost. However, early exits often lack interpretability and may focus on different features than deeper layers, limiting trust and explainability. This paper presents Explanation-Guided Training (EGT), a multi-objective framework that improves interpretability and consistency in early-exit networks through attention-based regularization. EGT introduces an attention consistency loss that aligns early-exit attention maps with the final exit. The framework jointly optimizes classification accuracy and attention consistency through a weighted combination of losses. Experiments on a real-world image classification dataset demonstrate that EGT achieves up to 98.97% overall accuracy (matching baseline performance) with a 1.97× inference speedup through early exits, while improving attention consistency by up to 18.5% compared to baseline models. The proposed method provides more interpretable and consistent explanations across all exit points, making early-exit networks more suitable for explainable AI applications in resource-constrained environments.",17.6,15.395,271,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08892v1_Evaluating Role-Consistency in LLMs for Counselor .pdf,Evaluating Role-Consistency in LLMs for Counselor Training,"Eric Rudolph, Natalie Engert, Jens Albrecht",,2601.08892v1,"Counseling, Chatbot, Large Language Model, Persona Consistency, Educational Role-Play","The rise of online counseling services has highlighted the need for effective training methods for future counselors. This paper extends research on VirCo, a Virtual Client for Online Counseling, designed to complement traditional role-playing methods in academic training by simulating realistic client interactions. Building on previous work, we introduce a new dataset incorporating adversarial attacks to test the ability of large language models (LLMs) to maintain their assigned roles (role-consistency). The study focuses on evaluating the role consistency and coherence of the Vicuna model’s responses, comparing these findings with earlier research. Additionally, we assess and compare various open-source LLMs for their performance in sustaining role consistency during virtual client interactions. Our contributions include creating an adversarial dataset, evaluating conversation coherence and persona consistency, and providing a comparative analysis of different LLMs.",18.5,14.972,277,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08896v1_XGBoost Forecasting of NEPSE Index Log Returns wit.pdf,XGBoost Forecasting of NEPSE Index Log Returns with Walk Forward Validation,"Sahaj Raj Mallaa, Shreeyash Kayastha, Rumi Suwala, Harish Chandra Bhandaria, Rajendra Adhikari",,,"NEPSE Index, stock index forecasting, XGBoost, walk-forward validation, hyperparameter optimization, time series forecasting, emerging markets, feature engineering","This study develops a robust machine learning framework for one-step-ahead forecasting of daily log-returns in the Nepal Stock Exchange (NEPSE) Index using the XGBoost regressor. A comprehensive feature set is engineered, including lagged log-returns (up to 30 days) and established technical indicators such as short- and medium-term rolling volatility measures and the 14-period Relative Strength Index. Hyperparameter optimization is performed using Optuna with time-series cross-validation on the initial training segment. Out-of-sample performance is rigorously assessed via walk-forward validation under both expanding and fixed-length rolling windows schemes across multiple lag configurations, simulating real-world deployment and avoiding lookahead bias. Predictive accuracy is evaluated using root mean squared error, mean absolute error, coefficient of determination (R2), and directional accuracy on both log-returns and reconstructed closing prices. Empirical results show that the optimal configuration—an expanding window with 20 lags—outperforms tuned ARIMA and Ridge regression benchmarks, achieving the lowest log-return RMSE (0.013450) and MAE (0.009814) alongside a directional accuracy of 65.15%. While the R2 remains modest, consistent with the noisy nature of financial returns, primary emphasis is placed on relative error reduction and directional prediction. Feature importance analysis and visual inspection further enhance interpretability. These findings demonstrate the effectiveness of gradient boosting ensembles in modeling nonlinear dynamics in volatile emerging market time series and establish a reproducible benchmark for NEPSE Index forecasting.",19.25,23.485,452,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08901v1_Navigating Ideation Space Decomposed Conceptual Re.pdf,Navigating Ideation Space: Decomposed Conceptual Representations for Positioning Scientific Ideas,"Yuexi Shen, Minqian Liu, Dawei Zhou, Lifu Huang",,,"scientific discovery, literature retrieval, conceptual representation, embedding approaches, novelty assessment, ideation space","Scientific discovery is a cumulative process that requires new ideas to be situated within an expanding landscape of existing knowledge. This paper introduces the Ideation Space, a structured representation that decomposes scientific knowledge into three dimensions: research problem, methodology, and core findings. This framework supports fine-grained literature retrieval and discriminative novelty assessment. The proposed Hierarchical Sub-Space Retrieval framework and Decomposed Novelty Assessment algorithm demonstrate substantial improvements in recall and correlation with expert judgments, offering a promising paradigm for accelerating and evaluating scientific discovery.",15.82,13.969,221,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08910v1_Towards a Self-Driving Trigger at the LHC Adaptive.pdf,Towards a Self-Driving Trigger at the LHC: Adaptive Response in Real Time,"Shaghayegh Emami, Cecilia Tosciri, Giovanna Salvi, Zixin Ding, Yuxin Chen, Abhijith Gandrakota, Christian Herwig, David W. Miller, Jennifer Ngadiuba, Nhan Tran",,arXiv:2601.08910v1,physics.ins-det,"Real-time data filtering and selection – ortrigger– systems at high-throughput scientific facilities such as the experiments at the Large Hadron Collider (LHC) must process extremely high-rate data streams under stringent bandwidth, latency, and storage constraints. Yet these systems are typically designed as static, hand-tuned menus of selection criteria grounded in prior knowledge and simulation. In this work, we further explore the concept of a self-driving trigger, an autonomous data-filtering framework that reallocates resources and adjusts thresholds dynamically in real-time to optimize signal efficiency, rate stability, and computational cost as instrumentation and environmental conditions evolve. We introduce a benchmark ecosystem to emulate realistic collider scenarios and demonstrate real-time optimization of a menu including canonical energy sum triggers as well as modern anomaly-detection algorithms that target non-standard event topologies using machine learning. Using simulated data streams and publicly available collision data from the Compact Muon Solenoid (CMS) experiment, we demonstrate the capability to dynamically and automatically optimize trigger performance under specific cost objectives without manual retuning. Our adaptive strategy shifts trigger design from static menus with heuristic tuning to intelligent, automated, data-driven control, unlocking greater flexibility and discovery potential in future high-energy physics analyses.",20.16,19.35,390,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08950v1_ConvoLearn A Dataset of Constructivist Tutor-Stude.pdf,ConvoLearn: A Dataset of Constructivist Tutor-Student Dialogue,"Mayank Sharma, Roy Pea, Hari Subramonyam",,,"LLMs, pedagogical limitations, knowledge-building theory, dialogic learning, constructivist AI tutors, educational NLP","In educational applications, Large Language Models (LLMs) often reveal solutions rather than support dialogic learning. This paper introduces ConvoLearn, a dataset grounded in knowledge-building theory, operationalizing six core pedagogical dimensions: cognitive engagement, formative assessment, accountability, cultural responsiveness, metacognition, and power dynamics. The dataset consists of 1,250 semi-synthetic tutor-student dialogues in middle school Earth Science, constructed through interactions between human teachers and a simulated student. Training on this dataset using QLoRA shifts LLM behavior towards knowledge-building strategies. Human evaluation by 31 teachers shows that the fine-tuned Mistral-7B model significantly outperforms its base version and Claude Sonnet 4.5. This work establishes a framework for developing and evaluating constructivist AI tutors.",16.25,16.004,260,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08951v1_PluriHarms Benchmarking the Full Spectrum of Human.pdf,PLURIHARMS: BENCHMARKING THE FULL SPECTRUM OF HUMAN JUDGMENTS ON AI HARM,"Jing-Jing Li, Joel Mire, Eve Fleisig, Valentina Pyatkin, Anne G. E. Collins, Maarten Sap, Sydney Levine",,,"AI safety, human judgments, harm benchmark, pluralistic AI, human values, disagreement, large language models","Current AI safety frameworks often treat harmfulness as binary, lacking flexibility for borderline cases where human disagreement is significant. The PLURIHARMS benchmark is introduced to study human harm judgments across the harm axis (benign to harmful) and the agreement axis (agreement to disagreement). It includes 150 prompts with 15,000 ratings from 100 human annotators, enriched with demographic and psychological traits. The study finds that imminent risks and tangible harms amplify perceived harmfulness, while annotator traits and prompt content explain systematic disagreement. The benchmark shows that personalization improves prediction of human harm judgments, but there is room for future progress. This work aims to move beyond 'one-size-fits-all' safety toward pluralistically safe AI.",17.82,17.002,303,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08953v1_Fairness risk and its privacy-enabled solution in .pdf,Fairness risk and its privacy-enabled solution in AI-driven robotic applications,"Le Liu, Bangguo Yu, Nynke Vellinga, Ming Cao",,arXiv:2601.08953v1,"Robotic Decision-making, Large Language Model, Fairness, Privacy","Complex decision-making by autonomous machines and algorithms could underpin the foundations of future society. Generative AI is emerging as a powerful engine for such transitions. However, we show that Generative AI-driven developments pose a critical pitfall: fairness concerns. In robotic applications, although intuitions about fairness are common, a precise and implementable definition that captures user utility and inherent data randomness is missing. Here we provide a utility-aware fairness metric for robotic decision-making and analyze fairness jointly with user-data privacy, deriving conditions under which privacy budgets govern fairness metrics. This yields a unified framework that formalizes and quantifies fairness and its interplay with privacy, which is tested in a robot navigation task. In view of the fact that under legal requirements, most robotic systems will enforce user privacy, the approach shows surprisingly that such privacy budgets can be jointly used to meet fairness targets. Addressing fairness concerns in the creative combined consideration of privacy is a step towards ethical use of AI and strengthens trust in autonomous robots deployed in everyday environments.",19.72,16.073,317,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08955v1_Imagine-then-Plan Agent Learning from Adaptive Loo.pdf,Imagine-then-Plan: Agent Learning from Adaptive Lookahead with World Models,"Youwei Liu, Jian Wang, Hanlin Wang, Beichen Guo, Wenjie Li",,,"world models, agent learning, adaptive lookahead, multi-step trajectories, Markov decision process","Recent advances in world models have shown promise for modeling future dynamics of environmental states, enabling agents to reason and act without accessing real environments. Current methods mainly perform single-step or fixed-horizon rollouts, leaving their potential for complex task planning under-exploited. We propose Imagine-then-Plan (ITP), a unified framework for agent learning via lookahead imagination, where an agent’s policy model interacts with the learned world model, yielding multi-step 'imagined' trajectories. Since the imagination horizon may vary by tasks and stages, we introduce a novel adaptive lookahead mechanism by trading off the ultimate goal and task progress. The resulting imagined trajectories provide rich signals about future consequences, such as achieved progress and potential conflicts, which are fused with current observations, formulating a partially observable and imaginable Markov decision process to guide policy learning. We instantiate ITP with both training-free and reinforcement-trained variants. Extensive experiments across representative agent benchmarks demonstrate that ITP significantly outperforms competitive baselines. Further analyses validate that our adaptive lookahead largely enhances agents’ reasoning capability, providing valuable insights into addressing broader, complex tasks. Our code and data will be released.",17.61,18.232,321,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.08988v1_ART Action-based Reasoning Task Benchmarking for M.pdf,Action-based Reasoning Task Benchmarking for Medical AI Agents,"Ananya Mantravadi, Shivali Dalmia, Abhishek Mukherji",,,"Medical AI agents, synthetic data generation, clinical reasoning evaluation, healthcare LLMs, benchmark, HITL","Reliable clinical decision support requires medical AI agents capable of safe, multi-step reasoning over structured electronic health records (EHRs). While large language models (LLMs) show promise in healthcare, existing benchmarks inadequately assess performance on action-based tasks involving threshold evaluation, temporal aggregation, and conditional logic. This paper introduces ART, an Action-based Reasoning clinical Task benchmark for medical AI agents, which mines real-world EHR data to create challenging tasks targeting known reasoning weaknesses. Through analysis of existing benchmarks, three dominant error categories are identified: retrieval failures, aggregation errors, and conditional logic misjudgments. A four-stage pipeline—scenario identification, task generation, quality audit, and evaluation—produces diverse, clinically validated tasks grounded in real patient data. Evaluating GPT-4o-mini and Claude 3.5 Sonnet on 600 tasks shows near-perfect retrieval after prompt refinement, but substantial gaps in aggregation (28-64%) and threshold reasoning (32-38%). By exposing failure modes in action-oriented EHR reasoning, ART advances toward more reliable clinical agents, an essential step for AI systems that reduce cognitive load and administrative burden, supporting workforce capacity in high-demand care settings.",18.92,17.921,339,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09012v3_TranslateGemma Technical Report.pdf,TranslateGemma Technical Report,Google Translate Research Team,,,"machine translation, Gemma 3, supervised fine-tuning, reinforcement learning, multilingual models, WMT25, WMT24++, multimodal capabilities","TranslateGemma is a suite of open machine translation models based on the Gemma 3 foundation models. It enhances multilingual capabilities through a two-stage fine-tuning process: supervised fine-tuning with high-quality synthetic and human-translated parallel data, followed by reinforcement learning using reward models like MetricX-QE and AutoMQM. The models show significant improvements over baseline Gemma 3 models in translation quality across multiple language pairs, as demonstrated on the WMT25 and WMT24++ benchmarks. TranslateGemma also retains strong multimodal capabilities, with improved performance on the Vistra image translation benchmark. The release aims to provide powerful tools for the research community.",16.21,13.759,223,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09018v1_Meta-learning to Address Data Shift in Time Series.pdf,META-LEARNING TO ADDRESS DATA SHIFT IN TIME SERIES CLASSIFICATION,"Samuel Myrenab, Nidhi Parikha, Natalie Kleina",,2601.09018v1,"signals, seismology, Reptile, FOMAML, model-agnostic meta-learning, domain generalization","Across engineering and scientific domains, traditional deep learning (TDL) models perform well when training and test data share the same distribution. However, the dynamic nature of real-world data, broadly termed data shift, renders TDL models prone to rapid performance degradation, requiring costly relabeling and inefficient retraining. Meta-learning, which enables models to adapt quickly to new data with few examples, offers a promising alternative for mitigating these challenges. Here, we systematically compare TDL with fine-tuning and optimization-based meta-learning algorithms to assess their ability to address data shift in time-series classification. We introduce a controlled, task-oriented seismic benchmark (SeisTask) and show that meta-learning typically achieves faster and more stable adaptation with reduced overfitting in data-scarce regimes and smaller model architectures. As data availability and model capacity increase, its advantages diminish, with TDL with fine-tuning performing comparably. Finally, we examine how task diversity influences meta-learning and find that alignment between training and test distributions, rather than diversity alone, drives performance gains. Overall, this work provides a systematic evaluation of when and why meta-learning outperforms TDL under data shift and contributes SeisTask as a benchmark for advancing adaptive learning research in time-series domains.",19.01,19.572,372,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09028v1_OpenDecoder Open Large Language Model Decoding to .pdf,OpenDecoder: Open Large Language Model Decoding to Incorporate Document Quality in RAG,"Fengran Mo, Zhan Su, Yuchen Hui, Jianhan Zhang, Jia Ao Sun, Zheyuan Liu, Chao Zhang, Tetsuya Sakai, Jian-Yun Nie",https://doi.org/10.1145/nnnnnnn.nnnnnnn,,"Information Retrieval, Retrieval-Augmented Generation, Robust Question Answer, Decoding Paradigm, Large Language Model","The development of large language models (LLMs) has achieved superior performance in a range of downstream tasks, including LLM-based retrieval-augmented generation (RAG). The quality of generated content heavily relies on the usefulness of the retrieved information and the capacity of LLMs’ internal information processing mechanism to incorporate it in answer generation. It is generally assumed that the retrieved information is relevant to the question. However, the retrieved information may have a variable degree of relevance and usefulness, depending on the question and the document collection. It is important to take into account the relevance of the retrieved information in answer generation. In this paper, we propose OpenDecoder, a new approach that leverages explicit evaluation of the retrieved information as quality indicator features for generation. We aim to build a RAG model that is more robust to varying levels of noisy context. Three types of explicit evaluation information are considered: relevance score, ranking score, and QPP (query performance prediction) score. The experimental results on five benchmark datasets demonstrate the effectiveness and better robustness of OpenDecoder by outperforming various baseline methods. Importantly, this paradigm is flexible to be integrated with the post-training of LLMs for any purposes and incorporated with any type of external indicators.",18.98,22.235,422,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09029v1_Proactively Detecting Threats A Novel Approach Usi.pdf,Proactively Detecting Threats: A Novel Approach Using LLMs,"Aniesh Chawla, Udbhav Prasad",,,"Malware, Indicators of Compromise, Cybersecurity, LLMs, GenAI, Machine Learning Algorithms, Deep Neural Network","Enterprise security faces escalating threats from sophisticated malware, compounded by expanding digital operations. This paper presents the first systematic evaluation of large language models (LLMs) to proactively identify indicators of compromise (IOCs) from unstructured web-based threat intelligence sources, distinguishing it from reactive malware detection approaches. An automated system was developed to pull IOCs from 15 web-based threat report sources to evaluate six LLM models (Gemini, Qwen, and Llama variants). The evaluation of 479 webpages containing 2,658 IOCs (711 IPv4 addresses, 502 IPv6 addresses, 1,445 domains) reveals significant performance variations. Gemini 1.5 Pro achieved 0.958 precision and 0.788 specificity for malicious IOC identification, while demonstrating perfect recall (1.0) for actual threats. The paper emphasizes the urgent need for advanced AI-driven security tools and explores the potential of LLMs for proactive identification of IOCs that enterprises can integrate into detection systems preemptively.",17.2,16.916,291,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09031v1_Generalizable Geometric Prior and Recurrent Spikin.pdf,Generalizable Geometric Prior and Recurrent Spiking Feature Learning for Humanoid Robot Manipulation,"Xuetao Li, Wenke Huang, Mang Ye, Jifeng Xuan, Bo Du, Sheng Liu, Miao Li",,,"Humanoid Robot Manipulation, Geometric Prior, Recurrent Spiking Feature Learning","Humanoid robot manipulation is a crucial research area for executing diverse human-level tasks, involving high-level semantic reasoning and low-level action generation. This paper presents a novel RGMP-S, Recurrent Geometric-prior Multimodal Policy with Spiking features, facilitating both high-level skill reasoning and data-efficient motion synthesis. It leverages lightweight 2D geometric inductive biases for precise 3D scene understanding within the vision-language model. A Long-horizon Geometric Prior Skill Selector aligns semantic instructions with spatial constraints, achieving robust generalization in unseen environments. A Recursive Adaptive Spiking Network parameterizes robot-object interactions via recursive spiking for spatiotemporal consistency, mitigating overfitting in sparse demonstration scenarios. Extensive experiments across the Maniskill simulation benchmark and three heterogeneous real-world robotic systems validate the method's superiority over state-of-the-art baselines and its efficacy in diverse generalization scenarios.",18.16,17.074,310,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09032v1_The Hierarchy of Agentic Capabilities Evaluating F.pdf,The Hierarchy of Agentic Capabilities: Evaluating Frontier Models on Realistic RL Environments,"Logan Ritchie, Sushant Mehta, Nick Heiner, Mason Yu, Edwin Chen",,2601.09032v1,"large language models, multi-step task completion, interactive environments, realistic RL environments, agentic capabilities, tool use, planning, goal formation, adaptability, groundedness, common-sense reasoning, task-centric design methodology, failure analysis, agent development","The advancement of large language model (LLM) based agents has shifted AI evaluation from single-turn response assessment to multi-step task completion in interactive environments. This study evaluates frontier AI models on 150 workplace tasks within a realistic e-commerce RL environment from Surge. An empirically-derived hierarchy of agentic capabilities is revealed: tool use, planning and goal formation, adaptability, groundedness, and common-sense reasoning. Even the best-performing models fail approximately 40% of the tasks, with failures clustering along this hierarchy. Weaker models struggle with tool use and planning, while stronger models fail on tasks requiring contextual inference beyond explicit instructions. A task-centric design methodology for RL environments is introduced, emphasizing diversity and domain expert contributions, along with detailed failure analysis and implications for agent development. The findings suggest that while current models can demonstrate coherent multi-step behavior, substantial capability gaps remain before achieving human-level task completion in realistic workplace settings.",19.38,18.882,366,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09035v1_A Decompilation-Driven Framework for Malware Detec.pdf,A Decompilation-Driven Framework for Malware Detection with Large Language Models,"Aniesh Chawla, Udbhav Prasad",,2601.09035v1,"Malware, Ghidra, Cybersecurity, LLMs, GenAI, Machine Learning Algorithms, LLMs Code development","The paper evaluates the efficacy of state-of-the-art Large Language Models (LLMs) in classifying executable code as either benign or malicious. It introduces an automated pipeline that first decompiles Windows executable into C code using the Ghidra disassembler and then leverages LLMs for classification. The evaluation reveals that while standard LLMs show promise, they are not yet robust enough to replace traditional anti-virus software. A fine-tuned model trained on curated datasets significantly outperforms its vanilla counterpart, but its performance degrades with newer malware. This highlights the need for continuous fine-tuning with emerging threats to maintain effectiveness against changing coding patterns and behaviors of malicious software.",17.08,14.109,241,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09041v1_Can LLMs interpret figurative language as humans d.pdf,CANLLMS INTERPRET FIGURATIVE LANGUAGE AS HUMANS DO?: SURFACE-LEVEL VS. REPRESENTATIONAL SIMILARITY,"Samhita Bollepally, Aurora Sloman-Moll, Takashi Yamauchi",,,"large language models, figurative language, human judgment, sarcasm, idiomacy, slang, contextual cues, pragmatic inference","Large language models (LLMs) generate judgments that resemble those of humans at a surface level, but diverge significantly at a representational level, especially in interpreting figurative sentences involving idioms and Gen Z slang. The study compares human participants and four instruction-tuned LLMs (GPT-4, Gemma-2-9B, Llama-3.2, and Mistral-7B) in rating dialogue-based sentences on six linguistic traits. GPT-4 most closely approximates human representational patterns, while all models struggle with context-dependent and socio-pragmatic expressions like sarcasm, slang, and idiomacy. The findings suggest that while LLMs can mimic some aspects of human judgment, they lack the cognitive grounding for genuine comprehension.",17.55,17.04,299,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09049v1_Is Grokking Worthwhile Functional Analysis and Tra.pdf,Is Grokking Worthwhile? Functional Analysis and Transferability of Generalization Circuits in Transformers,"Kaiyu He, Mian Zhang, Peilin Wu, Xinya Du, Zhiyu Zoey Chen",,,"Large Language Models, curse of two-hop reasoning, parameter-sharing transformers, Generalization Circuit, grokking, knowledge assimilation, transferability","This study investigates whether the 'grokking' phase in parameter-sharing transformers, which forms a 'Generalization Circuit', enhances model performance on downstream tasks. It explores if grokked models are superior to non-grokked ones and if the computational cost of grokking is justified. The findings suggest that grokking integrates memorized facts into existing reasoning paths rather than creating new paradigms. High accuracy on unseen cases and reasoning path formation can occur independently. Grokked transformers show limited transferability in integrating new knowledge, indicating incomplete mastery of compositional logic.",15.94,14.301,228,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09066v1_Midm 2.0 Korea-centric Bilingual Language Models.pdf,Mi:dm 2.0: Korea-centric Bilingual Language Models,"Tech. Innovation Group, KT",,arXiv:2601.09066v1,"Korea-centric AI, bilingual language models, Korean language processing, cultural alignment, large language models","Mi:dm 2.0 is a bilingual large language model (LLM) engineered to advance Korea-centric AI. It integrates Korean societal values, reasoning patterns, and commonsense knowledge to generate culturally appropriate responses. Addressing limitations of existing LLMs, Mi:dm 2.0 emphasizes robust data quality through proprietary data cleansing, synthetic data generation, strategic data mixing with curriculum learning, and a custom Korean-optimized tokenizer. It offers two configurations: Mi:dm 2.0 Base (11.5B parameters) for general-purpose use and Mi:dm 2.0 Mini (2.3B parameters) for resource-constrained environments. The model achieves state-of-the-art performance in Korean-specific benchmarks and is released under the MIT license for research and commercial use. KT aims to accelerate AI adoption in Korean industries, public services, and education, supporting the broader vision of K-intelligence.",17.83,15.588,278,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09069v1_From Symbolic to Natural-Language Relations Rethin.pdf,From Symbolic to Natural-Language Relations: Rethinking Knowledge Graph Construction in the Era of Large Language Models,"Kanyao Han, Yushang Lai",,,"Knowledge Graphs, Symbolic Relations, Natural-Language Relations, Large Language Models, Knowledge Representation","Knowledge graphs (KGs) have traditionally been constructed using predefined symbolic relation schemas, typically implemented as categorical relation labels. This design has notable shortcomings, as real-world relations are often contextual, nuanced, and sometimes uncertain, leading to a loss of critical semantic detail when compressed into discrete relation labels. Despite these limitations, symbolic-relation KGs remain widely used due to their operational effectiveness and compatibility with pre-LLM downstream models and algorithms. The emergence of large language models (LLMs) has reshaped how knowledge is created and consumed, supporting scalable synthesis of domain facts in concise natural language and favoring context-rich free-form text over quantified representations. This position paper argues for rethinking the representation of relations themselves, advocating a shift from symbolic to natural-language relation descriptions. It proposes hybrid design principles that preserve a minimal structural backbone while enabling more flexible and context-sensitive relational representations.",17.36,15.324,266,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09072v1_Human-AI Co-design for Clinical Prediction Models.pdf,Human-AI Co-design for Clinical Prediction Models,"Jean Feng, Avni Kothari, Patrick Vossler, Andrew Bishara, Lucas Zier, Newton Addo, Aaron Kornblith, Yan Shuo Tan, Chandan Singh",,arXiv:2601.09072v1,"Large language models, Electronic health records, Concept Bottleneck, Human-AI Interaction","Developing safe, effective, and practically useful clinical prediction models (CPMs) traditionally requires iterative collaboration between clinical experts, data scientists, and informaticists. This process refines the often small but critical details of the model building process, such as which features/patients to include and how clinical categories should be defined. However, this traditional collaboration process is extremely time- and resource-intensive, resulting in only a small fraction of CPMs reaching clinical practice. This challenge intensifies when teams attempt to reliably incorporate information from unstructured clinical notes, which can contain an essentially infinite number of concepts. To address this challenge, we introduce HACHI, an iterative human-in-the-loop framework that uses AI agents to accelerate the development of fully interpretable CPMs by enabling the exploration of concepts in clinical notes. HACHI alternates between (i) an AI agent rapidly exploring and evaluating candidate concepts in clinical notes and (ii) clinical and domain experts providing feedback to improve the CPM learning process. HACHI defines concepts as simple yes-no questions that are used in linear models, allowing the clinical AI team to transparently review, refine, and validate the CPM learned in each round. In two real-world prediction tasks (acute kidney injury and traumatic brain injury), HACHI outperforms existing approaches, surfaces new clinically relevant concepts not included in commonly-used CPMs, and improves model generalizability across clinical sites and time periods. Furthermore, HACHI reveals the critical role of the clinical AI team, such as directing the AI agent to explore entire categories of concepts that it had not previously considered, adjusting the granularity of concepts it considers, changing the objective function to better align with the clinical objectives, and identifying issues of data bias and leakage. Code for HACHI is available at http://github.com/jjfenglab/HACHI.",20.11,25.604,515,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09085v1_MMR-GRPO Accelerating GRPO-Style Training through .pdf,MMR-GRPO: Accelerating GRPO-Style Training through Diversity-Aware Reward Reweighting,"Kangda Wei, Ruihong Huang",,,"Group Relative Policy Optimization, GRPO, Maximal Marginal Relevance, mathematical reasoning, reinforcement learning, training efficiency","Group Relative Policy Optimization (GRPO) is a standard approach for training mathematical reasoning models, but its reliance on multiple completions per prompt makes it computationally expensive. MMR-GRPO integrates Maximal Marginal Relevance to reweigh rewards based on completion diversity, prioritizing diverse solutions for more informative updates and faster convergence. Evaluations show MMR-GRPO achieves comparable peak performance with significantly fewer training steps and less wall-clock time across various models and benchmarks.",14.39,13.556,195,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09089v1_SubTokenTest A Practical Benchmark for Real-World .pdf,A Practical Benchmark for Real-World Sub-token Understanding,"Shuyang Hou, Yi Hu, Muhan Zhang",,arXiv:2601.09089v1,"sub-token understanding, large language models, tokenization, character-level tasks, real-world applications, benchmark","Recent advancements in large language models (LLMs) have enhanced their reasoning capabilities, yet they struggle with basic character-level tasks due to tokenization issues. This paper introduces SUBTOKENTEST, a benchmark assessing sub-token understanding through practical tasks across four domains. It evaluates nine advanced LLMs, investigates test-time scaling on sub-token reasoning, and explores character-level information encoding within hidden states. The benchmark aims to address tokenization-related failures by decoupling performance from complex reasoning.",15.54,13.513,210,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09097v1_Programming over Thinking Efficient and Robust Mul.pdf,Programming over Thinking: Efficient and Robust Multi-Constraint Planning,"Derrick Goh Xin Deik, Quanyu Long, Zhengyuan Liu, Nancy F. Chen, Wenya Wang",,,"multi-constraint planning, large language models, reasoning paradigms, solver-based strategies, ScalableCOdePlanning Engine (SCOPE), GPT-4o, TravelPlanner","Multi-constraint planning involves identifying, evaluating, and refining candidate plans while satisfying multiple, potentially conflicting constraints. Existing large language model (LLM) approaches face fundamental limitations in this domain. Pure reasoning paradigms, which rely on long natural language chains, are prone to inconsistency, error accumulation, and prohibitive cost as constraints compound. Conversely, LLMs combined with coding- or solver-based strategies lack flexibility: they often generate problem-specific code from scratch or depend on fixed solvers, failing to capture generalizable logic across diverse problems. To address these challenges, we introduce the ScalableCOdePlanning Engine (SCOPE), a framework that disentangles query-specific reasoning from generic code execution. By separating reasoning from execution, SCOPE produces solver functions that are consistent, deterministic, and reusable across queries while requiring only minimal changes to input parameters. SCOPE achieves state-of-the-art performance while lowering cost and latency. For example, with GPT-4o, it reaches 93.1% success on TravelPlanner, a 61.6% gain over the best baseline (CoT) while cutting inference cost by 1.4x and time by 4.67x. Code is available at https://github.com/DerrickGXD/SCOPE.",19.06,21.086,402,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09100v2_DScheLLM Enabling Dynamic Scheduling through a Fin.pdf,DScheLLM: Enabling Dynamic Scheduling through a Fine-Tuned Dual-System Large Language Model,"Lixiang Zhang, Chenggong Zhao, Qing Gao, Xiaoke Zhao, Gengyi Bai, Jinhu Lv",,,"dynamic scheduling, large language model, fine-tuning, job shop scheduling","Production scheduling is highly susceptible to dynamic disruptions, such as variations in processing times, machine availability, and unexpected task insertions. Conventional approaches typically rely on event-specific models and explicit analytical formulations, which limits their adaptability and generalization across previously unseen disturbances. To overcome these limitations, this paper proposes DScheLLM, a dynamic scheduling approach that leverages fine-tuned large language models within a dual-system (fast-slow) reasoning architecture to address disturbances of different scales. A unified large language model-based framework is constructed to handle dynamic events, where training datasets for both fast and slow reasoning modes are generated using exact schedules obtained from an operations research solver. The Huawei OpenPangu Embedded-7B model is subsequently fine-tuned under the hybrid reasoning paradigms using LoRA. Experimental evaluations on standard job shop scheduling benchmarks demonstrate that the fast-thinking mode can efficiently generate high-quality schedules and the slow-thinking mode can produce solver-compatible and well-formatted decision inputs. To the best of our knowledge, this work represents one of the earliest studies applying large language models to job shop scheduling in dynamic environments, highlighting their considerable potential for intelligent and adaptive scheduling optimization.",18.94,18.904,358,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09105v2_AviationLMM A Large Multimodal Foundation Model fo.pdf,AviationLMM: A Large Multimodal Foundation Model for Civil Aviation,"Wenbin Li, Jingling Wu, Xiaoyong Lin, Jing Chen, Cong Chen",,,"civil aviation, multi-modal model, foundation model, cloud edge collaboration, hybrid training, computer systems organization, computing methodologies","Civil aviation is a cornerstone of global transportation and commerce, and ensuring its safety, efficiency, and customer satisfaction is paramount. Conventional Artificial Intelligence (AI) solutions in aviation remain siloed and narrow, focusing on isolated tasks or single modalities. They struggle to integrate heterogeneous data such as voice communications, radar tracks, sensor streams, and textual reports, which limits situational awareness, adaptability, and real-time decision support. This paper introduces the vision of AviationLMM, a Large Multimodal foundation Model for civil aviation, designed to unify the heterogeneous data streams of civil aviation and enable understanding, reasoning, generation, and agentic applications. The model architecture ingests multimodal inputs such as air-ground voice, surveillance, on-board telemetry, video, and structured texts, and performs cross-modal alignment and fusion, producing flexible outputs ranging from situation summaries and risk alerts to predictive diagnostics and multimodal incident reconstructions. Key research opportunities identified include data acquisition, alignment and fusion, pretraining, reasoning, trustworthiness, privacy, robustness to missing modalities, and synthetic scenario generation. The paper aims to boost civil aviation foundation model progress and catalyze coordinated research efforts toward an integrated, trustworthy, and privacy-preserving aviation AI ecosystem.",18.69,20.17,377,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09113v1_The AI Hippocampus How Far are We From Human Memor.pdf,The AI Hippocampus: How Far are We From Human Memory?,"Zixia Jia, Jiaqi Li, Yipeng Kang, Yuxuan Wang, Tong Wu, Quansen Wang, Xiaobo Wang, Shuyi Zhang, Junzhe Shen, Qing Li, Siyuan Qi, Yitao Liang, Di He, Zilong Zheng, Song-Chun Zhu",,arXiv:2601.09113v1,"memory, Large Language Models, Multi-Modal LLMs, implicit memory, explicit memory, agentic memory, continual learning, personalized inference, multi-modal settings, architectural advances, benchmark tasks, open challenges","Memory plays a foundational role in augmenting the reasoning, adaptability, and contextual fidelity of modern Large Language Models (LLMs) and Multi-Modal LLMs (MLLMs). As these models transition from static predictors to interactive systems capable of continual learning and personalized inference, the incorporation of memory mechanisms has emerged as a central theme in their architectural and functional evolution. This survey presents a comprehensive and structured synthesis of memory in LLMs and MLLMs, organizing the literature into a cohesive taxonomy comprising implicit, explicit, and agentic memory paradigms. Specifically, the survey delineates three primary memory frameworks. Implicit memory refers to the knowledge embedded within the internal parameters of pre-trained transformers, encompassing their capacity for memorization, associative retrieval, and contextual reasoning. Recent work has explored methods to interpret, manipulate, and reconfigure this latent memory. Explicit memory involves external storage and retrieval components designed to augment model outputs with dynamic, queryable knowledge representations—such as textual corpora, dense vectors, and graph-based structures—thereby enabling scalable and updatable interaction with information sources. Agentic memory introduces persistent, temporally extended memory structures within autonomous agents, facilitating long-term planning, self-consistency, and collaborative behavior in multi-agent systems, with relevance to embodied and interactive AI. Extending beyond text, the survey examines the integration of memory within multi-modal settings, where coherence across vision, language, audio, and action modalities is essential. Key architectural advances, benchmark tasks, and open challenges are discussed, including issues related to memory capacity, alignment, factual consistency, and cross-system interoperability. By charting the current landscape and identifying critical research directions, this survey aims to inform the development of memory-augmented (M)LLMs that are more flexible, context-sensitive, and aligned with the requirements of real-world intelligent systems.",21.33,28.453,607,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09116v1_LP-LLM End-to-End Real-World Degraded License Plat.pdf,LP-LLM: End-to-End Real-World Degraded License Plate Text Recognition via Large Multimodal Models,"Haoyan Gong, Hongbin Liu",,,"License Plate Recognition, Real-World Degradations, Vision-Language Models, Multimodal Reasoning, Character Recognition","Real-world License Plate Recognition (LPR) faces significant challenges from severe degradations such as motion blur, low resolution, and complex illumination. The prevailing 'restoration-then-recognition' two-stage paradigm suffers from a fundamental flaw: the pixel-level optimization objectives of image restoration models are misaligned with the semantic goals of character recognition, leading to artifact interference and error accumulation. To address this, an end-to-end structure-aware multimodal reasoning framework based on Qwen3-VL is proposed. The core innovation lies in the Character-Aware Multimodal Reasoning Module (CMRM), which introduces a set of learnable Character Slot Queries. Through a cross-attention mechanism, these queries actively retrieve fine-grained evidence corresponding to character positions from visual features. Subsequently, these character-aware representations are injected back into the visual tokens via residual modulation, enabling the language model to perform autoregressive generation based on explicit structural priors. Combined with the LoRA parameter-efficient fine-tuning strategy, the model achieves domain adaptation while retaining the generalization capabilities of the large model. Extensive experiments on both synthetic and real-world severely degraded datasets demonstrate that this method significantly outperforms existing restoration-recognition combinations and general VLMs, validating the superiority of incorporating structured reasoning into large models for low-quality text recognition tasks.",18.39,19.308,355,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09117v1_A Marketplace for AI-Generated Adult Content and D.pdf,A Marketplace for AI-Generated Adult Content and Deepfakes,"Shalmoli Ghosh, Matthew R. DeVerna, Filippo Menczer",,,"Generative AI, synthetic media, deepfakes, content moderation, gendered harms, community-driven platforms","Generative AI systems increasingly enable the production of highly realistic synthetic media. Civitai, a popular community-driven platform for AI-generated content, operates a monetized feature called Bounties, which allows users to commission the generation of content in exchange for payment. This study conducts a longitudinal analysis of all publicly available bounty requests collected over a 14-month period following the platform’s launch. It finds that the bounty marketplace is dominated by tools that let users steer AI models toward content they were not trained to generate, with a significant increase in requests for 'Not Safe For Work' content. Participation in bounty creation is uneven, with a small percentage of requesters accounting for a large portion of requests. Requests for 'deepfake' media depicting identifiable real individuals exhibit a higher concentration than other types of bounties, with a nontrivial subset involving explicit deepfakes despite platform policies prohibiting such content. These bounties disproportionately target female celebrities, revealing a pronounced gender asymmetry in social harm. The findings raise questions about consent, governance, and enforcement in monetized, community-driven generative AI platforms.",18.48,17.91,331,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09120v1_Adaptive Multi-Stage Patent Claim Generation with .pdf,Adaptive Multi-Stage Patent Claim Generation with Unified Quality Assessment,"Chen-Wei Liang, Bin Guo, Zhen-Yuan Wei, Mu-Jiang-Shan Wang",,arXiv:2601.09120v1,"Patent claim generation, Cross-jurisdictional learning, Quality assessment, Transformer, Domain adaptation","Current patent claim generation systems face three fundamental limitations: poor cross-jurisdictional generalization, inadequate semantic relationship modeling between claims and prior art, and unreliable quality assessment. We introduce a novel three-stage framework that addresses these challenges through relationship-aware similarity analysis, domain-adaptive claim generation, and unified quality assessment. Our approach employs multi-head attention with eight specialized heads for explicit relationship modeling, integrates curriculum learning with dynamic LoRA adapter selection across five patent domains, and implements cross-attention mechanisms between evaluation aspects for comprehensive quality assessment. Extensive experiments on USPTO HUPD dataset, EPO patent collections, and Patent-CE benchmark demonstrate substantial improvements: 7.6-point ROUGE-L gain over GPT-4o, 8.3% BERTScore enhancement over Llama-3.1-8B, and 0.847 correlation with human experts compared to 0.623 for separate evaluation models. Our method maintains 89.4% cross-jurisdictional performance retention versus 76.2% for baselines, establishing a comprehensive solution for automated patent prosecution workflows.",19.91,17.424,347,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09130v1_Equi-ViT Rotational Equivariant Vision Transformer.pdf,EQUI-VIT: ROTATIONAL EQUIVARIANT VISION TRANSFORMER FOR ROBUST HISTOPATHOLOGY ANALYSIS,"Fuyao Chen, Yuexi Du, Eléonore V. Lieffrig, Nicha C. Dvornek, John A. Onofrey",,,"Digital Histopathology, Vision Transformer, Rotation Equivariance, Artificial Intelligence","Vision Transformers (ViTs) have gained rapid adoption in computational pathology for their ability to model long-range dependencies through self-attention, addressing the limitations of convolutional neural networks that excel at local pattern capture but struggle with global contextual reasoning. Recent pathology-specific foundation models have further advanced performance by leveraging large-scale pretraining. However, standard ViTs remain inherently non-equivariant to transformations such as rotations and reflections, which are ubiquitous variations in histopathology imaging. To address this limitation, we propose Equi-ViT, which integrates an equivariant convolution kernel into the patch embedding stage of a ViT architecture, imparting built-in rotational equivariance to learned representations. Equi-ViT achieves superior rotation-consistent patch embeddings and stable classification performance across image orientations. Our results on a public colorectal cancer dataset demonstrate that incorporating equivariant patch embedding enhances data efficiency and robustness, suggesting that equivariant transformers could potentially serve as more generalizable backbones for the application of ViT in histopathology such as digital pathology foundation models.",18.58,18.408,342,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09136v1_SkinFlow Efficient Information Transmission for Op.pdf,SkinFlow: Efficient Information Transmission for Open Dermatological Diagnosis via Dynamic Visual Encoding and Staged RL,"Lijun Liu, Linwei Chen, Zhishou Zhang, Meng Tian, Hengfu Cui, Ruiyang Li, Zhaocheng Liu, Qiang Ju, Qianxi Li, Hong-Yu Zhou",,,"Dermatology, Large Vision-Language Models, Reinforcement Learning, Dynamic Visual Encoding, Information Transmission, Medical Diagnosis","General-purpose Large Vision-Language Models (LVLMs) often struggle in dermatology due to 'diffuse attention,' failing to distinguish subtle pathological lesions from background noise. This paper introduces SkinFlow, a framework that optimizes visual information transmission efficiency for dermatological diagnosis. It employs a Virtual-Width Dynamic Vision Encoder (DVE) to unfold complex pathological manifolds without expanding physical parameters, alongside a two-stage Reinforcement Learning strategy. This strategy aligns medical descriptions and reconstructs diagnostic textures within a constrained semantic space. A clinically grounded evaluation protocol prioritizes diagnostic safety and hierarchical relevance. Empirical results show a 7B model achieving a +12.06% gain in Top-1 accuracy and a +28.57% boost in Top-6 accuracy over general-purpose models on the Fitzpatrick17k benchmark, demonstrating superior diagnostic reasoning through optimized geometric capacity and information flow.",18.6,18.229,339,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09147v2_SSVP Synergistic Semantic-Visual Prompting for Ind.pdf,SSVP: Synergistic Semantic-Visual Prompting for Industrial Zero-Shot Anomaly Detection,"Chenhao Fu, Han Fang, Xiuzheng Zheng, Wenbo Wei, Yonghua Li, Hao Sun, Xuelong Li",,,"Zero-Shot Anomaly Detection, Vision-Language Models, Synergistic Semantic-Visual Prompting, Industrial Inspection, Hierarchical Semantic-Visual Synergy, Vision-Conditioned Prompt Generator, Visual-Text Anomaly Mapper","Zero-Shot Anomaly Detection (ZSAD) leverages Vision-Language Models (VLMs) for supervision-free industrial inspection. Existing ZSAD paradigms are limited by single visual backbones, which struggle to balance global semantic generalization with fine-grained structural discriminability. This paper proposes Synergistic Semantic-Visual Prompting (SSVP), which fuses diverse visual encodings to enhance fine-grained perception. SSVP introduces the Hierarchical Semantic-Visual Synergy (HSVS) mechanism, integrating DINOv3’s multi-scale structural priors into the CLIP semantic space. The Vision-Conditioned Prompt Generator (VCPG) uses cross-modal attention for dynamic prompt generation, allowing linguistic queries to anchor to specific anomaly patterns. The Visual-Text Anomaly Mapper (VTAM) addresses the discrepancy between global scoring and local evidence with a dual-gated calibration paradigm. Extensive evaluations on seven industrial benchmarks show SSVP's robustness, achieving state-of-the-art performance with 93.0% Image-AUROC and 92.2% Pixel-AUROC on MVTec-AD, significantly outperforming existing zero-shot approaches.",18.74,21.397,401,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09152v1_PrivacyReasoner Can LLM Emulate a Human-like Priva.pdf,PrivacyReasoner: Can LLM Emulate a Human-like Privacy Mind?,"Yiwen Tu, Xuan Liu, Lianhui Qin, Haojian Jin",,,"privacy concerns, AI-agent design, cognitive theories, contextual cues, LLM-based agents, privacy reasoning, user-specific modeling, privacy concern taxonomy","This paper introduces PrivacyReasoner, an AI-agent design for simulating how individual users form privacy concerns in response to real-world news. Moving beyond population-level sentiment analysis, PrivacyReasoner integrates privacy and cognitive theories to model user-specific privacy reasoning grounded in personal comment histories and contextual cues. The agent reconstructs each user’s 'privacy mind,' dynamically activates context-relevant privacy memory through a cognitively motivated contextual filter, and generates synthetic comments reflecting how that user would likely respond to new privacy scenarios. A complementary LLM-as-a-Judge evaluator, calibrated against an established privacy concern taxonomy, quantifies the faithfulness of the generated reasoning. Experiments on real-world Hacker News discussions show that PrivacyReasoner outperforms baseline agents in privacy concern prediction and captures transferable reasoning patterns across domains including AI, e-commerce, and healthcare.",17.35,15.562,270,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09156v1_KTCF Actionable Recourse in Knowledge Tracing via .pdf,KTCF: Actionable Recourse in Knowledge Tracing via Counterfactual Explanations for Education,"Woojin Kim, Changkwon Lee, Hyeoncheol Kim",,,"Knowledge Tracing, Counterfactual Explanations, Explainable AI, Education, Artificial Intelligence","This paper explores the use of counterfactual explanations in Knowledge Tracing (KT) to enhance adaptivity and scalability in education. The proposed method, KTCF, generates actionable counterfactual explanations that consider knowledge concept relationships and converts them into educational instructions. Experiments on a large-scale dataset demonstrate KTCF's superior performance over existing methods, with improvements ranging from 5.7% to 34% across various metrics. The study highlights the potential of counterfactuals to advance responsible AI use in education, emphasizing the importance of stakeholder-centered methods and educationally grounded conceptualization.",16.0,14.747,236,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09182v1_Position on LLM-Assisted Peer Review Addressing Re.pdf,Position on LLM-Assisted Peer Review: Addressing Reviewer Gap through Mentoring and Feedback,"JungMin Yun, JuneHyoung Kwon, MiHyeon Kim, YoungBin Kim",,,"peer review, LLM-assisted systems, reviewer gap, AI research, reviewer mentoring, reviewer feedback","The rapid expansion of AI research has intensified the Reviewer Gap, threatening the peer-review sustainability and perpetuating a cycle of low-quality evaluations. This position paper critiques existing LLM approaches that automatically generate reviews and argues for a paradigm shift that positions LLMs as tools for assisting and educating human reviewers. It proposes two complementary systems: an LLM-assisted mentoring system to cultivate reviewers’ long-term competencies, and an LLM-assisted feedback system to help reviewers refine the quality of their reviews. This human-centered approach aims to strengthen reviewer expertise and contribute to building a more sustainable scholarly ecosystem.",16.3,14.843,242,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09195v1_ProFit Leveraging High-Value Signals in SFT via Pr.pdf,ProFit: Leveraging High-Value Signals in SFT via Probability-Guided Token Selection,"Tao Liu, Taiqiang Wu, Runming Yang, Shaoning Sun, Junjie Wang, Yujiu Yang",,,"Supervised Fine-Tuning, Large Language Models, Token Probability, Semantic Importance, Overfitting, Probability-Guided Token Selection","Supervised fine-tuning (SFT) is a fundamental post-training strategy to align Large Language Models (LLMs) with human intent. Traditional SFT often forces alignment with a single reference answer, leading to overfitting to non-core expressions. This paper introduces ProFit, which selectively masks low-probability tokens to prevent surface-level overfitting, thereby maintaining core semantic integrity without the high costs associated with multiple reference answers. Extensive experiments confirm that ProFit consistently outperforms traditional SFT baselines on general reasoning and mathematical benchmarks.",16.06,15.256,245,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09208v2_Mikasa A Character-Driven Emotional AI Companion I.pdf,Mikasa: A Character-Driven Emotional AI Companion,Miki Ueno,,,"AI companions, character design, emotional AI, Japanese Oshi culture, user-AI relationship","This paper discusses the development of AI companions that can engage in emotionally expressive conversations. It highlights the importance of character design and clear user-AI relationship definitions over technical capabilities in maintaining user satisfaction and engagement. The paper presents Mikasa, an AI companion inspired by Japanese Oshi culture, emphasizing long-term commitment to a stable character. Mikasa is designed with a coherent personality and a clearly defined relationship as a partner, which helps stabilize interaction norms and reduce user effort in redefining the relationship. The study suggests that character coherence and relationship definition are crucial latent structural elements that enhance interaction quality, even if users do not explicitly recognize them. The work underscores the functional role of character design in AI companion systems, proposing that these principles can be applied to various emotionally grounded AI companions.",16.28,13.635,222,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09212v1_Annealed Relaxation of Speculative Decoding for Fa.pdf,Annealed Relaxation of Speculative Decoding for Faster Autoregressive Image Generation,"Xingyao Li, Fengzhuo Zhang, Cunxiao Du, Hui Ji",,,"auto-regressive image generation, speculative decoding, annealed relaxation, total variation distance, resampling distribution, perturbation analysis, inference latency","Despite significant progress in auto-regressive image generation, inference remains slow due to the sequential nature of AR models and the ambiguity of image tokens, even when using speculative decoding. This paper establishes the theoretical basis of relaxed speculative decoding and proposes COOL-SD, an annealed relaxation of speculative decoding. COOL-SD leverages insights into the total variation distance and annealing behavior to generate images faster with comparable quality or better quality at similar latency. Experiments validate COOL-SD's effectiveness, showing consistent improvements over prior methods in speed-quality trade-offs.",16.24,14.838,241,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09213v1_SpikeVAEDiff Neural Spike-based Natural Visual Sce.pdf,SpikeV AEDiff: Neural Spike-based Natural Visual Scene Reconstruction via VD-V AE and Versatile Diffusion,"Jialu Li, Taiyan Zhou",,,"neural spike data, visual scene reconstruction, neuroscience, computer vision, Very Deep Variational Autoencoder, Versatile Diffusion model, Allen Visual Coding—Neuropixels dataset, VISI region, neural decoding, brain-computer interface","Reconstructing natural visual scenes from neural activity is a key challenge in neuroscience and computer vision. This paper introduces SpikeVAEDiff, a novel two-stage framework combining a Very Deep Variational Autoencoder (VDVAE) and the Versatile Diffusion model to generate high-resolution and semantically meaningful image reconstructions from neural spike data. The first stage uses VDVAE to produce low-resolution preliminary reconstructions by mapping neural spike signals to latent representations. The second stage employs regression models to map neural spike signals to CLIP-Vision and CLIP-Text features, enabling Versatile Diffusion to refine the images. The study explores spike data for visual reconstruction tasks on the Allen Visual Coding—Neuropixels dataset, testing different brain regions. Findings indicate that the VISI region shows prominent activation, crucial for analysis. The paper presents a range of reconstruction results, demonstrating the complexities of decoding neural activity. While fMRI data is traditionally used for visual neural decoding, spike data offers superior temporal and spatial resolution. The performance of the reconstruction method is evaluated, validating the effectiveness of the VDVAE model. An ablation study investigates the impact of different brain regions on reconstruction, showing that data from specific regions, particularly VISI, significantly enhances result quality. This study provides insights into the potential of spike data and highlights the importance of considering different visual brain areas for improved neural decoding.",19.26,22.218,428,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09233v1_GIFT Unlocking Global Optimality in Post-Training .pdf,GIFT: Unlocking Global Optimality in Post-Training via Finite-Temperature Gibbs Initialization,"Zhengyang Zhao, Lu Ma, Yizhen Jiang, Xiaochen Ma, Zimo Meng, Chengyu Shen, Lexiang Tang, Haoze Sun, Peng Pei, Wentao Zhang",,,"Large Reasoning Models, Supervised Fine-Tuning, Reinforcement Learning, Gibbs Initialization, Finite Temperature, Post-Training, Optimization Mismatch, Distributional Collapse","The prevailing post-training paradigm for Large Reasoning Models (LRMs)—Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL)—suffers from an intrinsic optimization mismatch: the rigid supervision inherent in SFT induces distributional collapse, thereby exhausting the exploration space necessary for subsequent RL. This paper reformulates SFT within a unified post-training framework and proposes Gibbs Initialization with Finite Temperature (GIFT). GIFT incorporates supervision as a finite-temperature energy potential, establishing a distributional bridge that ensures objective consistency throughout the post-training pipeline. Experiments demonstrate that GIFT significantly outperforms standard SFT and other competitive baselines when utilized for RL initialization, providing a mathematically principled pathway toward achieving global optimality in post-training.",17.63,18.608,328,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09236v2_Reward Learning through Ranking Mean Squared Error.pdf,REWARD LEARNING THROUGH RANKING MEANS SQUARED ERROR,"Chaitanya Kharyal, Calarina Muslimani, Matthew E. Taylor",,,"reinforcement learning, reward learning, human feedback, rating-based RL, ranking mean squared error, trajectory-rating pairs, soft ranks, robotic locomotion benchmarks, OpenAI Gym, DeepMind Control Suite","Reward design remains a significant bottleneck in applying reinforcement learning (RL) to real-world problems. A popular alternative is reward learning, where reward functions are inferred from human feedback rather than manually specified. Recent work has proposed learning reward functions from human feedback in the form of ratings, rather than traditional binary preferences, enabling richer and potentially less cognitively demanding supervision. Building on this paradigm, we introduce a new rating-based RL method, Ranked Return Regression for RL (R4). At its core, R4 employs a novel ranking mean squared error (rMSE) loss, which treats teacher-provided ratings as ordinal targets. Our approach learns from a dataset of trajectory-rating pairs, where each trajectory is labeled with a discrete rating (e.g., 'bad,' 'neutral,' 'good'). At each training step, we sample a set of trajectories, predict their returns, and rank them using a differentiable sorting operator (soft ranks). We then optimize a mean squared error loss between the resulting soft ranks and the teacher’s ratings. Unlike prior rating-based approaches, R4 offers formal guarantees: its solution set is provably minimal and complete under mild assumptions. Empirically, using simulated human feedback, we demonstrate that R4 consistently matches or outperforms existing rating and preference-based RL methods on robotic locomotion benchmarks from OpenAI Gym and the DeepMind Control Suite, while requiring significantly less feedback.",19.55,21.385,418,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09239v2_DSA-Tokenizer Disentangled Semantic-Acoustic Token.pdf,DSA-Tokenizer: Disentangled Semantic-Acoustic Tokenization via Flow Matching-based Hierarchical Fusion,"Hanlin ZHANG, Daxin Tan, Dehua Tao, Xiao Chen, Haochen Tan, Yunhe Li, Yuchen Cao, Jianping Wang, Linqi Song",,,"speech tokenizers, discrete Speech Large Language Models, semantic encoding, acoustic style, disentanglement, Flow Matching, hierarchical fusion, speech generation, reconstruction-recombination training, speech modeling","Speech tokenizers are crucial for discrete Speech Large Language Models (Speech LLMs). Existing tokenizers either focus on semantic encoding, fuse semantic and acoustic content inseparably, or achieve incomplete disentanglement. The proposed DSA-Tokenizer disentangles speech into discrete semantic and acoustic tokens using distinct optimization constraints. Semantic tokens are supervised by ASR to capture linguistic content, while acoustic tokens focus on mel-spectrograms restoration to encode style. A hierarchical Flow-Matching decoder is introduced to improve speech generation quality by eliminating rigid length constraints between sequences. A joint reconstruction-recombination training strategy enforces separation, enabling high fidelity reconstruction and flexible recombination. This robust disentanglement facilitates controllable generation in speech LLMs, highlighting disentangled tokenization as a pivotal paradigm for future speech modeling.",17.73,19.576,347,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09248v1_Hybrid guided variational autoencoder for visual p.pdf,Hybrid guided variational autoencoder for visual place recognition,"Ni Wang, Zihan You, Emre Neftci, Thorben Schoepe",,arXiv:2601.09248v1,"Visual place recognition, Spiking neural network","Autonomous agents such as cars, robots, and drones need to precisely localize themselves in diverse environments, including GPS-denied indoor environments. Visual place recognition (VPR) estimates the place of an image based on previously seen places. State-of-the-art VPR models require high amounts of memory, making them unwieldy for mobile deployment, while more compact models lack robustness and generalization capabilities. This work overcomes these limitations for robotics using a combination of event-based vision sensors and an event-based novel guided variational autoencoder (VAE). The encoder part of the model is based on a spiking neural network model compatible with power-efficient low latency neuromorphic hardware. The VAE successfully disentangles the visual features of 16 distinct places in a new indoor VPR dataset with a classification performance comparable to other state-of-the-art approaches while showing robust performance under various illumination conditions. When tested with novel visual inputs from unknown scenes, the model can distinguish between these places, demonstrating high generalization capability by learning the essential features of location. The compact and robust guided VAE with generalization capabilities poses a promising model for visual place recognition that can significantly enhance mobile robot navigation in known and unknown indoor environments.",19.22,17.951,345,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09251v1_HGATSolver A Heterogeneous Graph Attention Solver .pdf,HGA TSolver: A Heterogeneous Graph Attention Solver for Fluid–Structure Interaction,"Qin-Yi Zhang, Hong Wang, Siyao Liu, Haichuan Lin, Linying Cao, Xiao-Hu Zhou, Chen Chen, Shuangyi Wang, Zeng-Guang Hou",,,"Fluid–structure interaction, Heterogeneous graph, Attention solver, Partial differential equations, Multi-physics systems, Machine learning, Surrogate modeling","Fluid–structure interaction (FSI) systems involve distinct physical domains, fluid and solid, governed by different partial differential equations and coupled at a dynamic interface. While learning-based solvers offer a promising alternative to costly numerical simulations, existing methods struggle to capture the heterogeneous dynamics of FSI within a unified framework. This challenge is further exacerbated by inconsistencies in response across domains due to interface coupling and by disparities in learning difficulty across fluid and solid regions, leading to instability during prediction. To address these challenges, we propose the Heterogeneous Graph Attention Solver (HGA TSolver). HGATSolver encodes the system as a heterogeneous graph, embedding physical structure directly into the model via distinct node and edge types for fluid, solid, and interface regions. This enables specialized message-passing mechanisms tailored to each physical domain. To stabilize explicit time stepping, we introduce a novel physics-conditioned gating mechanism that serves as a learnable, adaptive relaxation factor. Furthermore, an Inter-domain Gradient-Balancing Loss dynamically balances the optimization objectives across domains based on predictive uncertainty. Extensive experiments on two constructed FSI benchmarks and a public dataset demonstrate that HGATSolver achieves state-of-the-art performance, establishing an effective framework for surrogate modeling of coupled multi-physics systems.",19.21,21.396,411,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09253v1_RIFT Repurposing Negative Samples via Reward-Infor.pdf,RIFT: Repurposing Negative Samples via Reward-Informed Fine-Tuning,"Zehua Liu, Shuqi Liu, Tao Zhong, Mingxuan Yuan",,,"Supervised Fine-Tuning, Rejection Sampling Fine-Tuning, Reward-Informed Fine-Tuning, Large Language Models, alignment, data efficiency, negative samples, self-generated samples, loss reweighting, training collapse, mathematical benchmarks","This paper introduces Reward Informed Fine-Tuning (RIFT), a framework designed to enhance the efficiency of aligning Large Language Models (LLMs) by utilizing both positive and negative self-generated samples. Unlike traditional methods such as Supervised Fine-Tuning (SFT) and Rejection Sampling Fine-Tuning (RFT), which either depend on costly expert data or discard negative samples, RIFT repurposes these negative samples by reweighting the loss with scalar rewards. This approach addresses the issue of training collapse caused by naive reward integration and ensures numerical robustness and optimization efficiency. Extensive experiments demonstrate that RIFT consistently outperforms RFT across various mathematical benchmarks, showcasing its robustness and data efficiency.",17.49,16.979,297,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09259v1_MAXS Meta-Adaptive Exploration with LLM Agents.pdf,MAXS: Meta-Adaptive Exploration with LLM Agents,"Jian Zhang, Zhiyuan Wang, Zhangqi Wang, Yu He, Haoran Luo, Li Yuan, Lingling Zhang, Rui Mao, Qika Lin, Jun Liu",,,"Large Language Model, LLM Agents, meta-adaptive reasoning, tool execution, lookahead strategy, trajectory stability, multi-tool reasoning","Large Language Model (LLM) Agents exhibit inherent reasoning abilities through the collaboration of multiple tools. However, during agent inference, existing methods often suffer from locally myopic generation and trajectory instability, where minor early errors can escalate into divergent reasoning paths. To address these issues, the authors propose meta-adaptive exploration with LLM agents (MAXS), a meta-adaptive reasoning framework that flexibly integrates tool execution and reasoning planning. MAXS employs a lookahead strategy to extend reasoning paths a few steps ahead, estimating the advantage value of tool usage, and combines step consistency variance and inter-step trend slopes to jointly select stable, consistent, and high-value reasoning steps. Additionally, a trajectory convergence mechanism is introduced to control computational cost by halting further rollouts once path consistency is achieved, enabling a balance between resource efficiency and global effectiveness in multi-tool reasoning. Extensive empirical studies across three base models and five datasets demonstrate that MAXS consistently outperforms existing methods in both performance and inference efficiency. Further analysis confirms the effectiveness of the lookahead strategy and tool usage.",18.32,19.874,364,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09260v1_Efficient Paths and Dense Rewards Probabilistic Fl.pdf,Efficient Paths and Dense Rewards: Probabilistic Flow Reasoning for Large Language Models,"Yan Liu, Feng Zhang, Zhanyu Ma, Jun Xu, Jiuchong Gao, Jinghua Hao, Renqing He, Han Liu, Yangdong Deng",,,"Chain-of-Thought, Large Language Models, Probabilistic Flow, Reasoning, Inference Efficiency, Optimization, Reinforcement Learning","This paper introduces CoT-Flow, a framework that treats discrete reasoning steps as a continuous probabilistic flow to quantify each step's contribution to the final answer. It addresses the limitations of current paradigms by providing flow-guided decoding for efficient reasoning paths and flow-based reinforcement learning for dense reward functions without external verifiers. Experiments demonstrate CoT-Flow's superior balance between inference efficiency and reasoning performance on challenging benchmarks.",16.66,14.464,241,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09262v1_Magnifying change Rapid burn scar mapping with mul.pdf,"Magnifying change: Rapid burn scar mapping with multi-resolution, multi-source satellite imagery","Maria Sdraka, Dimitrios Michail, Ioannis Papoutsis",,,"Artificial intelligence, Machine Learning, Remote Sensing, burnt area mapping, disaster management, disaster monitoring, wildfires, burn scar mapping, change detection, downscaling, super-resolution","Delineating wildfire affected areas using satellite imagery remains challenging due to irregular and spatially heterogeneous spectral changes across the electromagnetic spectrum. Recent deep learning approaches achieve high accuracy with high-resolution multispectral data, but their applicability in operational settings is limited by the trade-off between spatial resolution and temporal revisit frequency of current satellite systems. This paper proposes a novel deep learning model, BAM-MRCD, which employs multi-resolution, multi-source satellite imagery (MODIS and Sentinel-2) for the timely production of detailed burnt area maps with high spatial and temporal resolution. The model detects even small-scale wildfires with high accuracy, surpassing similar change detection models and solid baselines. All data and code are available in the GitHub repository: https://github.com/Orion-AI-Lab/BAM-MRCD.",17.84,16.87,301,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09264v1_Coordinated Pandemic Control with Large Language M.pdf,Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants,"Ziyi Shi, Xusen Guo, Hongliang Lu, Mingxing Peng, Haotian Wang, Zheng Zhu, Zhenning Li, Yuxuan Liang, Xinhu Zheng, Hai Yang",,,"Pandemic Control, Large Language Models, Multi-Agent System, Coordinated Policymaking","Effective pandemic control requires timely and coordinated policymaking across interdependent regions. Human-driven responses are often fragmented and reactive, leading to suboptimal outcomes. This study proposes a large language model (LLM) multi-agent policymaking framework to support coordinated and proactive pandemic control. Each region is assigned an LLM agent that reasons over region-specific epidemiological dynamics and communicates with other agents to account for cross-regional interdependencies. The framework integrates real-world data, a pandemic evolution simulator, and structured inter-agent communication to explore counterfactual intervention scenarios and synthesize coordinated policy decisions. Validation using state-level COVID-19 data from the United States between April and December 2020 shows significant reductions in cumulative infections and deaths compared to real-world outcomes. The study demonstrates the potential of LLM multi-agent systems for effective pandemic control and presents a generalizable framework for large-scale public policy settings.",18.54,17.693,328,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09269v2_RISER Orchestrating Latent Reasoning Skills for Ad.pdf,RISER: Orchestrating Latent Reasoning Skills for Adaptive Activation Steering,"Wencheng Ye, Xiaoyang Yuan, Yi Bin, Hengyu Jin, Liang Peng, Pengpeng Zeng, Heng Tao Shen",,,"large language models, activation steering, reinforcement learning, reasoning, cognitive primitives, token efficiency","Recent work on domain-specific reasoning with large language models (LLMs) often relies on training-intensive approaches that require parameter updates. Activation steering has emerged as a parameter-efficient alternative, but existing methods apply static, manual interventions that fail to adapt to the dynamic nature of complex reasoning. To address this limitation, the authors propose RISER (Router-based Intervention for Steerable Enhancement of Reasoning), a plug-and-play intervention framework that adaptively steers LLM reasoning in activation space. RISER constructs a library of reusable reasoning vectors and employs a lightweight Router to dynamically compose them for each input. The Router is optimized via reinforcement learning under task-level rewards, activating latent cognitive primitives in an emergent and compositional manner. Across seven diverse benchmarks, RISER yields 3.4–6.5% average zero-shot accuracy improvements over the base model while surpassing CoT-style reasoning with 2–3× higher token efficiency and robust accuracy gains. Further analysis shows that RISER autonomously combines multiple vectors into interpretable, precise control strategies, pointing toward more controllable and efficient LLM reasoning.",17.74,20.352,361,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09274v1_A3-Bench Benchmarking Memory-Driven Scientific Rea.pdf,A3-Bench: Benchmarking Memory-Driven Scientific Reasoning via Anchor and Attractor Activation,"Jian Zhang, Yu He, Zhiyuan Wang, Zhangqi Wang, Kai He, Fangzhi Xu, Qika Lin, Jun Liu",,arXiv:2601.09274v1,"scientific reasoning, memory-driven mechanisms, anchors and attractors, benchmarking, Large Language Models, memory activation","Scientific reasoning relies on logical inference and activating prior knowledge and experiential structures. Existing benchmarks focus on final answers and step-by-step coherence, overlooking memory-driven mechanisms. A3-Bench is proposed to evaluate scientific reasoning through dual-scale memory-driven activation, using anchors and attractors. It annotates 2,198 science reasoning problems and introduces a dual-scale memory evaluation framework with the AAUI metric. Experiments validate A3-Bench and analyze memory activation's impact on reasoning performance, providing insights into memory-driven scientific reasoning.",16.84,15.494,261,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09278v1_M3Searcher Modular Multimodal Information Seeking .pdf,M3Searcher: Modular Multimodal Information Seeking Agency with Retrieval-Oriented Reasoning,"Xiaohan Yu, Chao Feng, Lang Mei, Chong Chen",,,"multimodal information seeking, retrieval-oriented reasoning, deep research-style agents, modular design, reinforcement learning, large language models","Recent advances in DeepResearch-style agents have shown strong capabilities in autonomous information acquisition and synthesis from real-world web environments. However, these approaches are limited to text modality. Extending these agents to multimodal settings introduces challenges such as the specialization-generalization trade-off and scarcity of training data for complex, multi-step multimodal search trajectories. To address these challenges, M3Searcher, a modular multimodal information-seeking agent, is proposed. It decouples information acquisition from answer derivation and is optimized with a retrieval-oriented multi-objective reward. Additionally, MM-SearchVQA, a multimodal multi-hop dataset, supports retrieval-centric RL training. Experimental results show that M3Searcher outperforms existing approaches, demonstrating strong transfer adaptability and effective reasoning in complex multimodal tasks.",16.98,16.612,282,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09280v1_ReGraM Region-First Knowledge Graph Reasoning for .pdf,ReGraM: Region-First Knowledge Graph Reasoning for Medical Question Answering,"Chaerin Lee, Sohee Park, Hyunsik Na, Daseon Choi",,,"Medical QA, Knowledge Graph Reasoning, Large Language Models, Biomedical Knowledge Graphs, Multi-hop Reasoning, Region-First Framework","Recent studies in medical question answering (Medical QA) have explored integrating large language models (LLMs) with biomedical knowledge graphs (KGs) to improve factual accuracy. However, existing approaches often rely on traversing the entire KG or performing large-scale retrieval, introducing noise and unstable multi-hop reasoning. ReGraM, a region-first knowledge graph reasoning framework, addresses this by constructing a query-aligned subgraph and performing stepwise reasoning within this localized region under multiple evidence-aware modes. This approach focuses inference on the most relevant portion of the KG, departing from the assumption that all relations are equally useful. Experiments on seven medical QA benchmarks show that ReGraM consistently outperforms a strong baseline, achieving significant accuracy gains and a reduction in hallucination rate. The results highlight region-first KG reasoning as an effective paradigm for improving factual accuracy and consistency in medical QA.",17.54,16.872,296,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09281v1_STaR Sensitive Trajectory Regulation for Unlearnin.pdf,STaR: Sensitive Trajectory Regulation for Unlearning in Large Reasoning Models,"Jingjing Zhou, Gaoxiang Cong, Li Su, Liang Li",,,"Large Reasoning Models, Chain-of-Thought, Privacy Risks, Unlearning, Sensitive Content, Trajectory Regulation, Privacy Protection, Semantic-aware Detection, Safety Constraints, Trajectory-aware Suppression, Token-level Adaptive Filtering, Multi-Decoding Consistency Assessment, Multi-Granularity Membership Inference Attack","Large Reasoning Models (LRMs) have advanced automated multi-step reasoning, but their ability to generate complex Chain-of-Thought (CoT) trajectories introduces severe privacy risks, as sensitive information may be deeply embedded throughout the reasoning process. Existing Large Language Models (LLMs) unlearning approaches that typically focus on modifying only final answers are insufficient for LRMs, as they fail to remove sensitive content from intermediate steps, leading to persistent privacy leakage and degraded security. To address these challenges, we propose Sensitive Trajectory Regulation (STaR), a parameter-free, inference-time unlearning framework that achieves robust privacy protection throughout the reasoning process. Specifically, we first identify sensitive content via semantic-aware detection. Then, we inject global safety constraints through secure prompt prefix. Next, we perform trajectory-aware suppression to dynamically block sensitive content across the entire reasoning chain. Finally, we apply token-level adaptive filtering to prevent both exact and paraphrased sensitive tokens during generation. Furthermore, to overcome the inadequacies of existing evaluation protocols, we introduce two metrics: Multi-Decoding Consistency Assessment (MCS), which measures the consistency of unlearning across diverse decoding strategies, and Multi-Granularity Membership Inference Attack (MIA) Evaluation, which quantifies privacy protection at both answer and reasoning-chain levels. Experiments on the R-TOFU benchmark demonstrate that STaR achieves comprehensive and stable unlearning with minimal utility loss, setting a new standard for privacy-preserving reasoning in LRMs.",19.65,23.717,466,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09282v1_Cluster Workload Allocation Semantic Soft Affinity.pdf,Cluster Workload Allocation: Semantic Soft Affinity Using Natural Language Processing,"Leszek Sliwko, Jolanta Mizeria-Pietraszko",,,"Artificial Intelligence, Kubernetes, Load Balancing, Semantic Parsing, Soft-Affinity, Task Assignment","Cluster workload allocation often requires complex configurations, creating a usability gap. This paper introduces a semantic, intent-driven scheduling paradigm for cluster systems using Natural Language Processing. The system employs a Large Language Model (LLM) integrated via a Kubernetes scheduler extender to interpret natural language allocation hint annotations for soft affinity preferences. A prototype featuring a cluster state cache and an intent analyzer (using AWS Bedrock) was developed. Empirical evaluation demonstrated high LLM parsing accuracy (>95% Subset Accuracy on an evaluation ground-truth dataset) for top-tier models like Amazon Nova Pro/Premier and Mistral Pixtral Large, significantly outperforming a baseline engine. Scheduling quality tests across six scenarios showed the prototype achieved superior or equivalent placement compared to standard Kubernetes configurations, particularly excelling in complex and quantitative scenarios and handling conflicting soft preferences. The results validate using LLMs for accessible scheduling but highlight limitations like synchronous LLM latency, suggesting asynchronous processing for production readiness. This work confirms the viability of semantic soft affinity for simplifying workload orchestration.",18.48,17.099,316,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09286v1_Why not Collaborative Filtering in Dual View Bridg.pdf,Why not Collaborative Filtering in Dual View? Bridging Sparse and Dense Models,"Hanze Guo, Jianxun Lian, Xiao Zhou",https://doi.org/XXXXXXX.XXXXXXX,,"Collaborative Filtering, Dual View Alignment, Sparse and Dense model, Information systems, Collaborative filtering, Recommender systems","Collaborative Filtering (CF) remains the cornerstone of modern recommender systems, with dense embedding–based methods dominating current practice. However, these approaches suffer from a critical limitation: our theoretical analysis reveals a fundamental signal-to-noise ratio (SNR) ceiling when modeling unpopular items, where parameter-based dense models experience diminishing SNR under severe data sparsity. To overcome this bottleneck, we propose SaD (Sparse and Dense), a unified framework that integrates the semantic expressiveness of dense embeddings with the structural reliability of sparse interaction patterns. We theoretically show that aligning these dual views yields a strictly superior global SNR. Concretely, SaD introduces a lightweight bidirectional alignment mechanism: the dense view enriches the sparse view by injecting semantic correlations, while the sparse view regularizes the dense model through explicit structural signals. Extensive experiments demonstrate that, under this dual-view alignment, even a simple matrix factorization–style dense model can achieve state-of-the-art performance. Moreover, SaD is plug-and-play and can be seamlessly applied to a wide range of existing recommender models, highlighting the enduring power of collaborative filtering when leveraged from dual perspectives. Further evaluations on real-world benchmarks show that SaD consistently outperforms strong baselines, ranking first on the BarsMatch leaderboard. The code is publicly available at https://github.com/harris26-G/SaD.",19.37,20.756,402,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09292v1_Blue Teaming Function-Calling Agents.pdf,Blue Teaming Function-Calling Agents,"Greta Dolcetti, Giulio Zizzo, Sergio Maffeis",,,"LLMs, function-calling, attacks, defences, robustness, adversarial attacks, open source models","This paper presents an experimental evaluation of the robustness of four open source Large Language Models (LLMs) with function-calling capabilities against three different attacks. It also measures the effectiveness of eight different defences. The study reveals that these models are not inherently safe and that the defences are not yet practical for real-world applications. The paper introduces a new attack vector, Renaming Tool Poisoning, and a related defence, Tool Obfuscation, highlighting the limitations of current defence mechanisms.",15.73,13.222,208,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09293v1_Policy-Based Reinforcement Learning with Action Ma.pdf,Policy-Based Reinforcement Learning with Action Masking for Dynamic Job Shop Scheduling under Uncertainty: Handling Random Arrivals and Machine Failures,"Sofiene Lassoued, Stefan Lier, Andreas Schwung",,,"Dynamic Job Shop Scheduling, Fault tolerance, Reinforcement learning, actions masking, Petri nets","We present a novel framework for solving Dynamic Job Shop Scheduling Problems under uncertainty, addressing the challenges introduced by stochastic job arrivals and unexpected machine breakdowns. Our approach follows a model-based paradigm, using Coloured Timed Petri Nets to represent the scheduling environment, and Maskable Proximal Policy Optimization to enable dynamic decision-making while restricting the agent to feasible actions at each decision point. To simulate realistic industrial conditions, dynamic job arrivals are modeled using a Gamma distribution, which captures complex temporal patterns such as bursts, clustering, and fluctuating workloads. Machine failures are modeled using a Weibull distribution to represent age-dependent degradation and wear-out dynamics. These stochastic models enable the framework to reflect real-world manufacturing scenarios better. In addition, we study two action-masking strategies: a non-gradient approach that overrides the probabilities of invalid actions, and a gradient-based approach that assigns negative gradients to invalid actions within the policy network. We conduct extensive experiments on dynamic JSSP benchmarks, demonstrating that our method consistently outperforms traditional heuristic and rule-based approaches in terms of makespan minimization. The results highlight the strength of combining interpretable Petri-net-based models with adaptive reinforcement learning policies, yielding a resilient, scalable, and explainable framework for real-time scheduling in dynamic and uncertain manufacturing environments.",19.33,19.657,380,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09306v1_On-Device Large Language Models for Sequential Rec.pdf,On-Device Large Language Models for Sequential Recommendation,"Xin Xia, Hongzhi Yin, Shane Culpepper",10.1145/3773966.3777961,,"Recommender Systems, Sequential Recommendation, On-Device Recommendation, Model Compression, Resource Constrained Devices","On-device recommendation is critical for real-world applications, especially in scenarios with constraints on execution latency, user privacy, and robust functionality when internet connectivity is unstable or impossible. Large language models (LLMs) can model user behavior for sequential recommendation tasks but are challenging to deploy on resource-constrained devices due to their substantial memory footprint and computational overhead. This paper proposes OD-LLM, a task-adaptive compression framework designed for efficient and accurate on-device deployment of LLMs for sequential recommendation tasks. OD-LLM integrates two complementary compression strategies: a low-rank structural compression algorithm using Singular Value Decomposition (SVD) to reduce parameter redundancy, and a novel tokenization normalization technique. Additionally, a progressive alignment algorithm is used to iteratively refine parameters layerwise in the target model. Empirical evaluations show that OD-LLM maintains effectiveness compared to the original model when the deployed model size is halved, demonstrating its efficacy and scalability as a practical alternative for real-time, on-device solutions.",17.58,17.807,313,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09313v1_Understanding or Memorizing A Case Study of German.pdf,Understanding or Memorizing? A Case Study of German Definite Articles in Language Models,"Jonathan Drechsel, Erisa Bytyqi, Steffen Herbold",,,"language models, grammatical agreement, German definite articles, gradient-based interpretability, GRADIEND, memorization, rule-based generalization","Language models perform well on grammatical agreement, but it is unclear whether this reflects rule-based generalization or memorization. This study focuses on German definite singular articles, whose forms depend on gender and case. Using GRADIEND, a gradient-based interpretability method, the authors learn parameter update directions for gender-case specific article transitions. They find that updates for specific gender-case transitions often affect unrelated settings, with substantial overlap among affected neurons across settings. These results suggest that models partly rely on memorized associations rather than abstract grammatical rules, challenging the strictly rule-based encoding hypothesis.",15.91,13.447,214,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09342v1_Improving Implicit Hate Speech Detection via a Com.pdf,Improving Implicit Hate Speech Detection via a Community-Driven Multi-Agent Framework,"Ewelina Gajewska, Katarzyna Budzynska, Jarosław A. Chudziak",,,"LLMs, Community agents, Hate speech, Social media, Moderation, Fairness","This work proposes a contextualised detection framework for implicitly hateful speech, implemented as a multi-agent system comprising a central Moderator Agent and dynamically constructed Community Agents representing specific demographic groups. Our approach explicitly integrates socio-cultural context from publicly available knowledge sources, enabling identity-aware moderation that surpasses state-of-the-art prompting methods (zero-shot prompting, few-shot prompting, chain-of-thought prompting) and alternative approaches on a challenging ToxiGen dataset. We enhance the technical rigour of performance evaluation by incorporating balanced accuracy as a central metric of classification fairness that accounts for the trade-off between true positive and true negative rates. We demonstrate that our community-driven consultative framework significantly improves both classification accuracy and fairness across all target groups.",16.83,15.393,259,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09351v1_Navigating Ethical AI Challenges in the Industrial.pdf,Navigating Ethical AI Challenges in the Industrial Sector: Balancing Innovation and Responsibility,"Ruomu Tan, Martin W Hoffmann",,2601.09351v1,"AI, industrial sector, ethics, innovation, transparency, accountability, fairness, research and development, data sharing, ethical principles","The integration of artificial intelligence (AI) into the industrial sector has driven innovation and expanded the ethical landscape, necessitating a reevaluation of principles governing technology and its applications. This chapter explores the intersection of AI-empowered industrial innovation with ethics, addressing challenges related to transparency, accountability, and fairness. It examines ethical aspects of AI in industrial use cases, emphasizing the importance of embedding ethical principles into AI systems to inspire technological breakthroughs and foster trust among stakeholders. The chapter offers actionable insights to guide industrial research and development toward ethical and responsible progress, promoting a more inclusive industrial ecosystem.",18.61,13.11,244,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09353v1_Monte-Carlo Tree Search with Neural Network Guidan.pdf,Monte-Carlo Tree Search with Neural Network Guidance for Lane-Free Autonomous Driving,"Ioannis Peridis, Dimitrios Troullinos, Georgios Chalkiadakis, Pantelis Giankoulidis, Ioannis Papamichail, Markos Papageorgiou",,2601.09353v1,"Monte-Carlo Tree Search, Neural Network, Autonomous Driving, Lane-Free Traffic, Reinforcement Learning, Markov Decision Process","This work explores a Monte-Carlo Tree Search (MCTS) planning approach for single-agent autonomous driving in lane-free traffic environments. The approach is influenced by reinforcement learning frameworks and incorporates a pre-trained neural network (NN) to guide the selection phase of MCTS. This integration leverages the predictive capabilities of NNs to enhance the tree search process under computational constraints. The study evaluates the approach using metrics related to safety (collision rates) and efficacy (measured speed), examining the influence of isotropic state information, the acceleration of performance for the NN-guided MCTS variant, and the trade-off between computational resources and solution quality. The concept of 'nudging' is also explored, where vehicles react to both front and back-located vehicles, enhancing policy effectiveness.",18.75,16.639,312,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09361v1_GeoRA Geometry-Aware Low-Rank Adaptation for RLVR.pdf,GeoRA: Geometry-Aware Low-Rank Adaptation for RLVR,"Jiaying Zhang, Lei Shi, Jiguo Li, Jun Xu, Jiuchong Gao, Jinghua Hao, Renqing He",,,"Reinforcement Learning, Verifiable Rewards, Low-Rank Adaptation, Singular Value Decomposition, Optimization Dynamics, Geometric Structures, GPU Computation, Catastrophic Forgetting","Reinforcement Learning with Verifiable Rewards (RLVR) is crucial for advancing large-scale reasoning models. Existing parameter-efficient methods like PiSSA and MiLoRA, designed for Supervised Fine-Tuning (SFT), do not account for the distinct optimization dynamics and geometric structures of RLVR, leading to spectral collapse and optimization instability. GeoRA (Geometry-Aware Low-Rank Adaptation) addresses these challenges by exploiting the anisotropic and compressible nature of RL update subspaces. It initializes adapters by extracting principal directions via Singular Value Decomposition (SVD) within a geometrically constrained subspace while freezing the residual components. This preserves the pre-trained geometric structure and enables efficient GPU computation through dense operators. Experiments on Qwen and Llama demonstrate that GeoRA mitigates optimization bottlenecks caused by geometric misalignment, outperforming established low-rank baselines on key mathematical benchmarks and achieving state-of-the-art results. Additionally, GeoRA shows superior generalization and resilience to catastrophic forgetting in out-of-domain tasks.",17.82,18.857,336,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09365v1_Frame of Reference Addressing the Challenges of Co.pdf,Frame of Reference: Addressing the Challenges of Common Ground Representation in Situational Dialogs,"Biswesh Mohapatra, Théo Charlot, Giovanni Duca, Mayank Palan, Laurent Romary, Justine Cassell",,,"common ground, situational dialogs, conversational agents, social robots, dialog systems, grounding, large language models","Common ground is essential in situational spoken dialogs for maintaining coherent interaction. This paper evaluates a model's ability to establish and utilize common ground in dynamic environments, focusing on relational references. It explores methods for representing common ground and proposes improvements. The study addresses the challenge of maintaining shared understanding over extended dialogues, particularly for embodied conversational agents and social robots.",15.64,13.684,214,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09381v1_Query Languages for Machine-Learning Models.pdf,Query Languages for Machine-Learning Models,Martin Grohe,,2601.09381v1,"Expressive power of query languages, fixed-point logics, weighted structures, neural networks, explainable AI","This paper discusses two logics for weighted finite structures: first-order logic with summation (FO(SUM)) and its recursive extension IFP(SUM). These logics, originating from foundational work by Grädel, Gurevich, and Meer in the 1990s, are investigated as query languages for machine learning models, specifically neural networks, which are naturally represented as weighted graphs. The paper presents examples of queries to neural networks expressible in these logics and discusses their expressiveness and computational complexity.",15.12,12.767,193,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09382v1_Long-term Task-oriented Agent Proactive Long-term .pdf,Long-term Task-oriented Agent: Proactive Long-term Intent Maintenance in Dynamic Environments,"Qinglong Shi, Donghai Wang, Hantao Zhou, Jiguo Li, Jun Xu, Jiuchong Gao, Jinghua Hao, Renqing He",,,"proactive agents, task-oriented interaction, dynamic environments, intent-conditioned monitoring, event-triggered follow-up, chronosbench","Current large language model agents predominantly operate under a reactive paradigm, responding only to immediate user queries within short-term sessions. This limitation hinders their ability to maintain long-term user intents and dynamically adapt to evolving external environments. This paper proposes a novel interaction paradigm for proactive Task-oriented Agents capable of bridging the gap between relatively static user needs and a dynamic environment. Proactivity is formalized through two key capabilities: Intent-Conditioned Monitoring and Event-Triggered Follow-up. A high-quality data synthesis pipeline is introduced to construct complex, multi-turn dialog data in a dynamic environment. A new benchmark, ChronosBench, is proposed to address the lack of evaluation criteria for task-oriented interaction in dynamic environments. The paper evaluates leading models and reveals their flaws in long-term task-oriented interaction. A fine-tuned model trained using synthetic data achieves a task completion rate of 85.19% for complex tasks, outperforming other models under test, validating the effectiveness of the data-driven strategy.",18.24,18.969,346,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09394v2_FairGE Fairness-Aware Graph Encoding in Incomplete.pdf,FairGE: Fairness-Aware Graph Encoding in Incomplete Social Networks,"Renqiang Luo, Jilin University, Changchun, China, lrenqiang@outlook.com, Huafei Huang, Adelaide University, Adelaide, Australia, hhuafei@outlook.com, Tao Tang, Zhejiang University of Technology, Hangzhou, China, tao.tang@ieee.org, Jing Ren, RMIT University, Melbourne, Australia, jing.ren@ieee.org, Ziqi Xu, RMIT University, Melbourne, Australia, ziqi.xu@rmit.edu.au, Mingliang Hou, Jinan University & TAL Education Group, Guangzhou, China, teemohold@outlook.com, Enyan Dai, HKUST, Guangzhou, China, enyandai@hkust-gz.edu.cn, Feng Xia, RMIT University, Melbourne, Australia, f.xia@ieee.org",https://doi.org/XXXXXXX.XXXXXXX,,"Social Networks, Graph Learning, Graph Transformers, Fairness, Incomplete Data","Graph Transformers (GTs) are increasingly applied to social network analysis, yet their deployment is often constrained by fairness concerns. This issue is particularly critical in incomplete social networks, where sensitive attributes are frequently missing due to privacy and ethical restrictions. Existing solutions commonly generate these incomplete attributes, which may introduce additional biases and further compromise user privacy. To address this challenge, FairGE (Fair Graph Encoding) is introduced as a fairness-aware framework for GTs in incomplete social networks. Instead of generating sensitive attributes, FairGE encodes fairness directly through spectral graph theory. By leveraging the principal eigenvector to represent structural information and padding incomplete sensitive attributes with zeros to maintain independence, FairGE ensures fairness without data reconstruction. Theoretical analysis demonstrates that the method suppresses the influence of non-principal spectral components, thereby enhancing fairness. Extensive experiments on seven real-world social network datasets confirm that FairGE achieves at least a 16% improvement in both statistical parity and equality of opportunity compared with state-of-the-art baselines. The source code is shown in https://github.com/LuoRenqiang/FairGE.",20.04,28.196,565,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09398v1_Ability Transfer and Recovery via Modularized Para.pdf,Ability Transfer and Recovery via Modularized Parameters Localization,"Songyao Jin, Kun Zhou, Wenqi Li, Peng Wang, Biwei Huang",,,"large language models, catastrophic forgetting, modularized parameters, activation-guided channel-wise ability transfer, multilingual mathematical reasoning, scientific reasoning","Large language models (LLMs) can be continually pre-trained or fine-tuned to improve performance in specific domains, languages, or skills, but this often leads to degradation of other capabilities and catastrophic forgetting. This study investigates how abilities are distributed within LLM parameters by analyzing module activations under domain- and language-specific inputs. It finds that ability-related activations are highly concentrated in a small set of channels, which are largely disentangled. The proposed Activation-Guided Channel-wise Ability Transfer (ACT) method localizes ability-relevant channels via activation differences and selectively transfers corresponding parameters, followed by lightweight fine-tuning for compatibility. Experiments show that ACT can recover forgotten abilities while preserving retained skills and integrate multiple specialized models into a single model with minimal interference.",17.05,16.074,274,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09413v1_Speech-Hands A Self-Reflection Voice Agentic Appro.pdf,Speech-Hands: A Self-Reflection Voice Agentic Approach to Speech Recognition and Audio Reasoning with Omni Perception,"Zhen Wan, Chao-Han Huck Yang, Jinchuan Tian, Hanrong Ye, Ankita Pasad, Szu-wei Fu, Arushi Goel, Ryo Hachiuma, Shizhe Diao, Kunal Dhawan, Sreyan Ghosh, Yusuke Hirota, Zhehuai Chen, Rafael Valle, Ehsan Hosseini Asl, Chenhui Chu, Shinji Watanabe, Yu-Chiang Frank Wang, Boris Ginsburg",,,"speech recognition, audio reasoning, omni perception, self-reflection, voice agentic framework","We introduce a voice-agentic framework that learns one critical omni-understanding skill: knowing when to trust itself versus when to consult external audio perception. Our work is motivated by a crucial yet counterintuitive finding: naively fine-tuning an omni-model on both speech recognition and external sound understanding tasks often degrades performance, as the model can be easily misled by noisy hypotheses. To address this, our framework, Speech-Hands, recasts the problem as an explicit self-reflection decision. This learnable reflection primitive proves effective in preventing the model from being derailed by flawed external candidates. We show that this agentic action mechanism generalizes naturally from speech recognition to complex, multiple-choice audio reasoning. Across the OpenASR leaderboard, Speech-Hands consistently outperforms strong baselines by 12.1% WER on seven benchmarks. The model also achieves 77.37% accuracy and high F1 on audio QA decisions, showing robust generalization and reliability across diverse audio question answering datasets. By unifying perception and decision-making, our work offers a practical path toward more reliable and resilient audio intelligence.",18.72,22.809,427,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09416v1_Radiomics-Integrated Deep Learning with Hierarchic.pdf,Radiomics-Integrated Deep Learning with Hierarchical Loss for Osteosarcoma Histology Classification,"Yaxi Chen, Zi Ye, Shaheer U. Saeed, Oliver Yu, Simin Ni, Jie Huang, Yipeng Hu",,,"Osteosarcoma, Radiomics, Multi-Task Learning, Uncertainty Weighting","Osteosarcoma (OS) is an aggressive primary bone malignancy. Accurate histopathological assessment of viable versus non-viable tumor regions after neoadjuvant chemotherapy is critical for prognosis and treatment planning. This work proposes using radiomic features as additional input in model training to improve classification performance and interpretability. It also introduces a hierarchical loss to optimize two binary classification tasks (tumor-vs-non-tumor and viable-vs-non-viable) instead of a flat three-class classification task. The proposed approaches demonstrate improved performance on the TCIA OS Tumor Assessment dataset, setting a new state-of-the-art performance for this application.",17.2,15.23,262,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09421v2_Bias Dynamics in BabyLMs Towards a Compute-Efficie.pdf,Bias Dynamics in BabyLMs: Towards a Compute-Efficient Sandbox for Democratising Pre-Training Debiasing,"Filip Trhlik, Andrew Caines, Paula Buttery",,,"pre-trained language models, bias, debiasing, BabyLMs, BERT, gender imbalance, toxicity, computational efficiency","Pre-trained language models (LMs) have grown significantly in size and societal adoption, leading to increased training costs and challenges in understanding and mitigating biases. Most debiasing efforts focus on post-hoc strategies due to the high cost of re-training LMs. This work explores the use of BabyLMs, compact BERT-like models trained on small corpora, as a cost-effective proxy for studying bias dynamics in larger models. BabyLMs exhibit similar bias formation and performance patterns as standard BERT models, despite their smaller size. The study demonstrates that BabyLMs can serve as an effective sandbox for pre-model debiasing research, reducing pre-training costs from over 500 GPU-hours to under 30 GPU-hours. This approach democratizes debiasing research and facilitates faster exploration of methods to build fairer LMs.",17.34,17.01,295,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09433v1_Do Transformers Understand Ancient Roman Coin Moti.pdf,Do Transformers Understand Ancient Roman Coin Motifs Better than CNNs?,"David Reid, Ognjen Arandjelović",,2601.09433v1,"Vision Transformer, CNNs, ancient coins, semantic elements, computer vision, machine learning, numismatics","Automated analysis of ancient coins can aid researchers and collectors by identifying semantic elements depicted on coins. This paper applies the Vision Transformer (ViT) architecture to this task, comparing its performance with convolutional neural networks (CNNs). ViT models, trained on multi-modal data (images and unstructured text), outperform newly trained CNN models in accuracy. The paper discusses previous research, training, implementation, and evaluation of ViT and CNN models for ancient coin analysis.",17.04,10.857,185,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09445v1_Where Knowledge Collides A Mechanistic Study of In.pdf,Where Knowledge Collides: A Mechanistic Study of Intra-Memory Knowledge Conflict in Language Models,"Minh Vu Pham, Hsuvas Borkakoty, Yufang Hou",,arXiv:2601.09445v1,"language models, intra-memory knowledge conflict, mechanistic interpretability, pre-training, knowledge editing, retrieval-augmented generation, continual learning","In language models (LMs), intra-memory knowledge conflict arises when inconsistent information about the same event is encoded within the model’s parametric knowledge. While prior work has focused on resolving conflicts between a model’s internal knowledge and external resources, the problem of localizing conflicts originating during pre-training within the model’s internal representations remains unexplored. This study designs a framework based on mechanistic interpretability methods to identify where and how conflicting knowledge from pre-training data is encoded within LMs. The findings indicate that specific internal components of a language model are responsible for encoding conflicting knowledge from pre-training, and demonstrate how mechanistic interpretability methods can be leveraged to causally intervene in and control conflicting knowledge at inference time.",17.65,16.205,286,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09446v1_Improving Symbolic Translation of Language Models .pdf,Improving Symbolic Translation of Language Models for Logical Reasoning,"Ramya Keerthy Thatikonda, Jiuzhou Han, Wray Buntine, Ehsan Shareghi",,,"logical reasoning, language models, first-order logic, natural language processing, symbolic translation, predicate generation, FOL translation, verification module, incremental inference","The paper discusses the alignment of formal language with language models (LMs) for deductive logical reasoning, focusing on translating natural language (NL) into first-order logic (FOL) and using external solvers for reliable reasoning. Smaller LMs often struggle with this task due to formatting and translation errors. The authors propose categorizing common errors and fine-tuning smaller LMs using data from large language models. They introduce incremental inference, dividing the process into predicate generation and FOL translation, and a verification module to target predicate-arity errors. The study evaluates three model families across four datasets, showing reduced error rates, increased predicate coverage, and improved reasoning performance for smaller LMs.",17.41,15.739,274,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09448v1_Population-Aligned Audio Reproduction With LLM-Bas.pdf,Population-Aligned Audio Reproduction With LLM-Based Equalizers,"Ioannis Stylianou, Jon Francombe, Pablo Martínez-Nuevo, Sven Ewan Shepstone, Zheng-Hua Tan",,,"LLMs, Equalization, Audio Reproduction, Listening Experiments, Recommender Systems","Conventional audio equalization is a static process that requires manual adjustments to adapt to changing listening contexts. This paper introduces a Large Language Model (LLM)-based alternative that maps natural language text prompts to equalization settings, enabling a conversational approach to sound system control. By utilizing data from a controlled listening experiment, the models exploit in-context learning and parameter-efficient fine-tuning techniques to align with population-preferred equalization settings. Evaluation methods show statistically significant improvements in distributional alignment over random sampling and static preset baselines, indicating that LLMs could function as 'artificial equalizers' for more accessible, context-aware, and expert-level audio tuning methods.",17.02,14.985,255,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09451v1_Late Breaking Results Quamba-SE Soft-edge Quantize.pdf,Late Breaking Results: Quamba-SE: Soft-edge Quantizer for Activations in State Space Models,"Yizhi Chen, Ahmed Hemani",,,"Quantization, State Space Models, Quamba","We propose Quamba-SE, a soft-edge quantizer for State Space Model (SSM) activation quantization. Unlike existing methods, Quamba-SE employs three adaptive scales: high-precision for small values, standard scale for normal values, and low-precision for outliers. This approach preserves outlier information instead of hard clipping, while maintaining precision for other values. We evaluate on Mamba-130M across 6 zero-shot benchmarks. Results show that Quamba-SE consistently outperforms Quamba, achieving up to +2.68% on individual benchmarks and up to +0.83% improvement in the average accuracy of 6 datasets.",15.4,14.355,221,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09455v1_On the Hardness of Computing Counterfactual and Se.pdf,On the Hardness of Computing Counterfactual and Semi-factual Explanations in XAI,"André Artelt, Martin Olsen, Kevin Tierney",,2601.09455v1,"counterfactual explanations, semi-factual explanations, XAI, computational complexity, machine learning","Providing clear explanations to the choices of machine learning models is essential for these models to be deployed in crucial applications. Counterfactual and semi-factual explanations have emerged as two mechanisms for providing users with insights into the outputs of their models. This paper provides an overview of the computational complexity results in the literature for generating these explanations, finding that in many cases, generating explanations is computationally hard. The authors contribute their own inapproximability results, showing that not only are explanations often hard to generate, but under certain assumptions, they are also hard to approximate. The implications of these complexity results for the XAI community and for policymakers seeking to regulate explanations in AI are discussed.",17.21,14.529,250,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09460v1_SoK Enhancing Cryptographic Collaborative Learning.pdf,SoK: Enhancing Cryptographic Collaborative Learning with Differential Privacy,"Francesco Capano, Jonas Böhler, Benjamin Weggenmann",,,"Differential privacy, cryptography, collaborative machine learning","In collaborative learning (CL), multiple parties jointly train a machine learning model on their private datasets without directly sharing data due to privacy concerns. Cryptographic techniques like multi-party computation (MPC) enable training on encrypted data, but securely trained models are still vulnerable to inference attacks. Differential privacy (DP) mitigates these attacks by injecting noise during training. This work explores the challenges and trade-offs of combining cryptography and DP for cryptographic and differentially private collaborative learning (CPCL), introducing a unified framework and analyzing secure noise sampling techniques. The study evaluates the accuracy and cryptographic overhead of these techniques in different settings and proposes future research directions.",16.23,13.678,222,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09465v1_EvoFSM Controllable Self-Evolution for Deep Resear.pdf,EvoFSM: Controllable Self-Evolution for Deep Research with Finite State Machines,"Shuo Zhang, Chaofa Yuan, Ryan Guo, Xiaomin Yu, Rui Xu, Zhangquan Chen, Zinuo Li, Zhi Yang, Shuhao Guan, Zhenheng Tang, Sen Hu, Liwen Zhang, Ronghao Chen, Huacan Wang",,arXiv:2601.09465v1,"cs.AI, LLM-based agents, self-evolution, Finite State Machine, deep research, multi-hop QA benchmarks, interactive decision-making tasks","While LLM-based agents have shown promise for deep research, most existing approaches rely on fixed workflows that struggle to adapt to real-world, open-ended queries. Recent work explores self-evolution by allowing agents to rewrite their own code or prompts to improve problem-solving ability, but unconstrained optimization often triggers instability, hallucinations, and instruction drift. We propose EvoFSM, a structured self-evolving framework that achieves both adaptability and control by evolving an explicit Finite State Machine (FSM) instead of relying on free-form rewriting. EvoFSM decouples the optimization space into macroscopic Flow (state-transition logic) and microscopic Skill (state-specific behaviors), enabling targeted improvements under clear behavioral boundaries. Guided by a critic mechanism, EvoFSM refines the FSM through a small set of constrained operations, and further incorporates a self-evolving memory that distills successful trajectories as reusable priors and failure patterns as constraints for future queries. Extensive evaluations on five multi-hop QA benchmarks demonstrate the effectiveness of EvoFSM. In particular, EvoFSM reaches 58.0% accuracy on the DeepSearch benchmark. Additional results on interactive decision-making tasks further validate its generalization.",20.02,22.024,441,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09467v1_Searth Transformer A Transformer Architecture Inco.pdf,Searth Transformer: A Transformer Architecture Incorporating Earth's Geospheric Physical Priors for Global Mid-Range Weather Forecasting,"Tianye Li, Qi Liu, Hao Li, Lei Chen, Wencong Cheng, Fei Zheng, Xiangao Xia, Ya Wang, Gang Huang, Weiwei Wang, Xuan Tong, Ziqing Zu, Yi Fang, Shenming Fu, Jiang Jiang, Haochen Li, Mingxing Li, Jiangjiang Xia",,,"Transformer architecture, Earth's geospheric physical priors, global mid-range weather forecasting, zonal periodicity, meridional boundaries, self-attention, Relay Autoregressive (RAR) fine-tuning strategy","Accurate global medium-range weather forecasting is pivotal to Earth system science and serving as a critical public-service application. While modern weather forecasting increasingly employs data-driven AI models, most Transformer-based architectures rely on generic vision-centric designs that overlook the Earth’s inherent spherical topology and zonal periodicity. Additionally, the resource-intensive nature of autoregressive training imposes critical bottlenecks, constraining attainable forecast horizons while aggravating error propagation. These limitations not only compromise physical consistency and forecast accuracy but also effectively preclude resource-constrained institutions from leveraging localized datasets to refine global model performance. To address these challenges, this paper proposes the Shifted Earth Transformer (Searth Transformer), a physics-informed transformer architecture designed for global medium-range weather forecasting. Searth Transformer integrates zonal periodicity and meridional boundaries into window-based self-attention, enabling physically consistent global information exchange. To mitigate the computational bottlenecks, we develop the Relay Autoregressive (RAR) fine-tuning strategy, a memory-efficient strategy decoupling GPU memory usage from the forecast length. This enables the model to learn effectively.",19.83,23.149,459,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09469v2_FairGU Fairness-aware Graph Unlearning in Social N.pdf,FairGU: Fairness-aware Graph Unlearning in Social Networks,"Renqiang Luo, Yongshuai Yang, Huafei Huang, Qing Qing, Mingliang Hou, Ziqi Xu, Yi Yu, Jingjing Zhou, Feng Xia",https://doi.org/XXXXXXX.XXXXXXX,,"fairness, privacy, graph unlearning, social network","Graph unlearning has emerged as a critical mechanism for supporting sustainable and privacy-preserving social networks, enabling models to remove the influence of deleted nodes and thereby better safeguard user information. However, existing graph unlearning techniques insufficiently protect sensitive attributes, often leading to degraded algorithmic fairness compared with traditional graph learning methods. To address this gap, we introduce FairGU, a fairness-aware graph unlearning framework designed to preserve both utility and fairness during the unlearning process. FairGU integrates a dedicated fairness-aware module with effective data protection strategies, ensuring that sensitive attributes are neither inadvertently amplified nor structurally exposed when nodes are removed. Through extensive experiments on multiple real-world datasets, we demonstrate that FairGU consistently outperforms state-of-the-art graph unlearning methods and fairness-enhanced graph learning baselines in terms of both accuracy and fairness metrics. Our findings highlight a previously overlooked risk in current unlearning practices and establish FairGU as a robust and equitable solution for the next generation of socially sustainable networked systems.",18.03,19.08,344,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09470v1_Personalized Multimodal Feedback Using Multiple Ex.pdf,Personalized Multimodal Feedback Using Multiple External Representations: Strategy Profiles and Learning in High School Physics,"Natalia Revenga-Lozano, Karina E. Avila, Steffen Steinert, Matthias Schweinberger, Clara E. Gómez-Pérez, Jochen Kuhn, Stefan Küchemann",,2601.09470v1,physics.ed-ph,"Multiple external representations (MERs) and personalized feedback support physics learning, yet evidence on how personalized feedback can effectively integrate MERs remains limited. This question is particularly timely given the emergence of multimodal large language models. We conducted a 16-24 week observational study in high school physics (N=661) using a computer-based platform that provided verification and optional elaborated feedback in verbal, graphical and mathematical forms. Linear mixed-effects models and strategy-cluster analyses (ANCOVA-adjusted comparisons) tested associations between feedback use and post-test performance and moderation by representational competence. Elaborated multirepresentational feedback showed a small but consistent positive association with post-test scores independent of prior knowledge and confidence. Learners adopted distinct representation-selection strategies; among students with lower representational competence, using a diverse set of representations related to higher learning, whereas this advantage diminished as competence increased. These findings motivate adaptive feedback designs and inform intelligent tutoring systems capable of tailoring feedback elaboration and representation selection.",20.06,16.801,337,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09473v1_SimMerge Learning to Select Merge Operators from S.pdf,SimMerge: Learning to Select Merge Operators from Similarity Signals,"Oliver Bolton, Aakanksha, Arash Ahmadian, Sara Hooker, Marzieh Fadaee, Beyza Ermis",,2601.09473v1,"model merging, large language models, merge operators, similarity signals, machine learning, LLM development","Model merging enables multiple large language models (LLMs) to be combined into a single model while preserving performance, offering a competitive alternative to multi-task training. However, merging can be difficult at scale, requiring the selection of the right merge operator, models, and order. This work introduces SimMerge, a predictive merge-selection method that uses inexpensive, task-agnostic similarity signals between models to select the best merge. SimMerge predicts the performance of a given 2-way merge from a small set of unlabeled probes, selecting the best merge operator, subset of models, and merge order, eliminating the expensive merge-and-evaluate loop. It surpasses standard merge-operator performance on 2-way merges of 7B-parameter LLMs and generalizes to multi-way merges and 111B-parameter LLM merges without retraining. A bandit variant supports adding new tasks, models, and operators on the fly, suggesting that learning how to merge is a practical route to scalable model composition when checkpoint catalogs are large and evaluation budgets are tight.",19.24,17.934,345,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09478v3_Bridging Semantic Understanding and Popularity Bia.pdf,Bridging Semantic Understanding and Popularity Bias with LLMs,"Renqiang Luo, Dong Zhang, Yupeng Gao, Wen Shi, Mingliang Hou, Jiaying Liu, Zhe Wang, Shuo Yu",https://doi.org/XXXXXXX.XXXXXXX,,"Semantic analysis, Recommender systems, Algorithmic fairness, Popularity bias, LLM","Semantic understanding of popularity bias is a crucial yet underexplored challenge in recommender systems, where popular items are often favored at the expense of niche content. Most existing debiasing methods treat the semantic understanding of popularity bias as a matter of diversity enhancement or long-tail coverage, neglecting the deeper semantic layer that embodies the causal origins of the bias itself. Consequently, such shallow interpretations limit both their debiasing effectiveness and recommendation accuracy. In this paper, we propose FairLRM, a novel framework that bridges the gap in the semantic understanding of popularity bias with Recommendation via Large Language Model (RecLLM). FairLRM decomposes popularity bias into item-side and user-side components, using structured instruction-based prompts to enhance the model’s comprehension of both global item distributions and individual user preferences. Unlike traditional methods that rely on surface-level features such as 'diversity' or 'debiasing', FairLRM improves the model’s ability to semantically interpret and address the underlying bias. Through empirical evaluation, we show that FairLRM significantly enhances both fairness and recommendation accuracy, providing a more semantically aware and trustworthy approach to enhance the semantic understanding of popularity bias.",18.2,20.938,381,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09503v1_What Do LLM Agents Know About Their World Task2Qui.pdf,What Do LLM Agents Know About Their World? Task2Quiz: A Paradigm for Studying Environment Understanding,"Siyuan Liu, Hongbang Yuan, Xinze Li, Ziyue Zhu, Yixin Cao, Yu-Gang Jiang",,2601.09503v1,"Large language model, LLM agents, environment understanding, generalization, evaluation paradigms, Task-to-Quiz, T2QBench, autonomous agents","Large language model (LLM) agents have shown remarkable capabilities in complex decision-making and tool-use tasks, yet their ability to generalize across varying environments remains under-examined. Current evaluation paradigms rely on trajectory-based metrics that measure task success, failing to assess whether agents possess a grounded, transferable model of the environment. This paper proposes Task-to-Quiz (T2Q), a deterministic and automated evaluation paradigm designed to decouple task execution from world-state understanding. T2QBench, a suite comprising 30 environments and 1,967 grounded QA pairs, is introduced to address this gap. Experiments reveal that task success is often a poor proxy for environment understanding, and current memory mechanisms cannot effectively help agents acquire a grounded model of the environment. The findings identify proactive exploration and fine-grained state representation as primary bottlenecks, offering a foundation for developing more generalizable autonomous agents.",18.88,18.006,340,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09518v1_Learning Whole-Body Human-Humanoid Interaction fro.pdf,Learning Whole-Body Human-Humanoid Interaction from Human-Human Demonstrations,"Wei-Jin Huang, Yue-Yi Zhang, Yi-Lin Wei, Zhi-Wei Xia, Juantao Tan, Yuan-Ming Li, Zhilin Zhao, Wei-Shi Zheng",,arXiv:2601.09518v1,"Human-Humanoid Interaction, Human-Human Interaction, Physics-Aware Interaction Retargeting, Decoupled Spatio-Temporal Action Reasoner, Whole-Body Interaction, Robotics","Enabling humanoid robots to physically interact with humans is a critical frontier, but progress is hindered by the scarcity of high-quality Human-Humanoid Interaction (HHoI) data. While leveraging abundant Human-Human Interaction (HHI) data presents a scalable alternative, standard retargeting fails by breaking essential contacts. This work introduces PAIR (Physics-Aware Interaction Retargeting), a contact-centric, two-stage pipeline that preserves contact semantics across morphology differences to generate physically consistent HHoI data. Additionally, the paper presents D-STAR (Decoupled Spatio-Temporal Action Reasoner), a hierarchical policy that disentangles when to act from where to act, addressing the limitations of conventional imitation learning policies.",19.02,16.984,323,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09520v1_Towards Realistic Synthetic Data for Automatic Dru.pdf,TOWARDS REALISTIC SYNTHETIC DATA FOR AUTOMATIC DRUM TRANSCRIPTION,"Pierfrancesco Melucci, Paolo Merialdo, Taketo Akama",,,"Automatic Drum Transcription, Deep Learning, Synthetic Data, One-shot Samples, MIDI, SoundFont, Sequence-to-Sequence Model","Deep learning models define the state-of-the-art in Automatic Drum Transcription (ADT), yet their performance is contingent upon large-scale, paired audio-MIDI datasets, which are scarce. Existing workarounds that use synthetic data often introduce a significant domain gap, as they typically rely on low-fidelity SoundFont libraries that lack acoustic diversity. This paper introduces a new paradigm for ADT that circumvents the need for paired audio-MIDI training data. The primary contribution is a semi-supervised method to automatically curate a large and diverse corpus of one-shot drum samples from unlabeled audio sources. This corpus is used to synthesize a high-quality dataset from MIDI files alone, which is then used to train a sequence-to-sequence transcription model. The model achieves new state-of-the-art results on the ENST and MDB test sets, significantly outperforming both fully supervised methods and previous synthetic-data approaches.",17.93,17.008,305,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09527v1_Private LLM Inference on Consumer Blackwell GPUs A.pdf,Private LLM Inference on Consumer Blackwell GPUs: A Practical Guide for Cost-Effective Local Deployment in SMEs,"Jonathan Knoop, Hendrik Holtmann",,,"LLM inference, consumer GPUs, NVIDIA Blackwell, SME deployment, cost-effective, data privacy, benchmarking, quantization, energy efficiency","SMEs increasingly seek alternatives to cloud LLM APIs due to data privacy concerns. This paper evaluates NVIDIA’s Blackwell consumer GPUs (RTX 5060 Ti, 5070 Ti, 5090) for LLM inference, benchmarking four open-weight models across various configurations. The RTX 5090 offers higher throughput and lower latency for certain workloads, while budget GPUs provide the best throughput-per-dollar for API workloads. NVFP4 quantization significantly improves throughput and reduces energy consumption with minimal quality loss. Self-hosted inference is much cheaper than cloud APIs, with hardware breaking even in under four months at moderate volume. The study shows consumer GPUs can replace cloud inference for most SME workloads, except for latency-critical long-context RAG tasks.",17.01,16.465,280,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09536v1_Omni-R1 Towards the Unified Generative Paradigm fo.pdf,Omni-R1: Towards the Unified Generative Paradigm for Multimodal Reasoning,"Dongjie Cheng, Yongqi Li, Zhixin Ma, Hongru Cai, Yupeng Hu, Wenjie Wang, Liqiang Nie, Wenjie Li",,arXiv:2601.09536v1,"Multimodal Large Language Models, Multimodal Reasoning, Generative Paradigm, Perception Alignment, Functional Image Generation, Bootstrapping, Visual Information","Multimodal Large Language Models (MLLMs) are advancing in multimodal reasoning, transitioning from text-based reasoning to incorporating visual information. Early methods focused on text-based reasoning, while recent studies integrate visual information into reasoning steps. However, these methods often follow task-specific patterns, limiting generalizability. This paper proposes a unified generative multimodal reasoning approach, generating intermediate images during reasoning. The Omni-R1 framework, featuring perception alignment loss and reward, enables functional image generation. Omni-R1-Zero, which bootstraps visualizations from text-only data, eliminates the need for multimodal annotations. Empirical results show Omni-R1's effectiveness across various tasks, with Omni-R1-Zero matching or surpassing Omni-R1, indicating a promising direction for generative multimodal reasoning.",18.38,18.004,331,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09555v1_Benchmarking Post-Training Quantization of Large L.pdf,Benchmarking Post-Training Quantization of Large Language Models under Microscaling Floating Point Formats,"Manyi Zhang, Ji-Fu Li, Zhongao Sun, Haoli Bai, Hui-Ling Zhen, Zhenhua Dong, Xianzhi Yu",,,"Post-Training Quantization, Large Language Models, Microscaling Floating-Point, MXFP, Quantization, Model Compression","Microscaling Floating-Point (MXFP) has emerged as a promising low-precision format for large language models (LLMs). Despite various post-training quantization (PTQ) algorithms being proposed, they mostly focus on integer quantization, while their applicability and behavior under MXFP formats remain largely unexplored. This work conducts a systematic investigation of PTQ under MXFP formats, encompassing over 7 PTQ algorithms, 15 evaluation benchmarks, and 3 LLM families. Key findings include: MXFP8 consistently achieves near-lossless performance, while MXFP4 introduces substantial accuracy degradation; PTQ effectiveness under MXFP depends strongly on format compatibility; PTQ performance exhibits consistent trends across model families and modalities; the scaling factor of quantization is a critical error source in MXFP4, and a simple pre-scale optimization strategy can significantly mitigate its impact. These results provide practical guidance on adapting existing PTQ methods to MXFP quantization.",17.61,19.139,337,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09566v2_Hot-Start from Pixels Low-Resolution Visual Tokens.pdf,Hot-Start from Pixels: Low-Resolution Visual Tokens for Chinese Language Modeling,"Shuyang Xiang, Hao Guan",,2601.09566v2,"Chinese language modeling, visual tokens, low-resolution, language processing, character representation","Large language models typically represent Chinese characters as discrete index-based tokens, largely ignoring their visual form. For logographic scripts, visual structure carries semantic and phonetic information, which may aid prediction. This study investigates whether low-resolution visual inputs can serve as an alternative for character-level modeling. Instead of token IDs, the decoder receives grayscale images of individual characters, with resolutions as low as 8×8 pixels. Remarkably, these inputs achieve 39.2% accuracy, comparable to the index-based baseline of 39.1%. Such low-resource settings also exhibit a pronounced hot-start effect: by 0.4% of total training, accuracy reaches above 12%, while index-based models lag at below 6%. Overall, the results demonstrate that minimal visual structure can provide a robust and efficient signal for Chinese language modeling, offering an alternative perspective on character representation that complements traditional index-based approaches.",18.63,15.194,283,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09600v1_Information Access of the Oppressed A Problem-Posi.pdf,Information Access of the Oppressed: A Problem-Posing Framework for Envisioning Emancipatory Information Access Platforms,"BHASKAR MITRA, NICOLA NEOPHYTOU, SIREESH GURURAJA",https://doi.org/XXXXXXX.XXXXXXX,,"Emancipatory Information Access, Search and Society, Sociotechnical Information Systems, Information systems→Information retrieval, World Wide Web, Human-centered computing","This paper explores the risks of authoritarian capture of online information access platforms, particularly in the context of rising democratic erosion, generative AI technologies, and the concentration of power in Big Tech. Through the lens of Paulo Freire’s theories of emancipatory pedagogy, the authors challenge the traditional technologist-user dichotomy and advocate for a problem-posing framework that involves marginalized communities in the co-construction of technology. The framework aims to build emancipatory information access platforms that resist authoritarianism and support community struggles against oppression.",17.07,14.821,253,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09603v1_Linear Complexity Self-Supervised Learning for Mus.pdf,Linear Complexity Self-Supervised Learning for Music Understanding with Random Quantizer,"Petros Vavaroutsos, Theodoros Palamas, Pantelis Vikatos",10.1145/3748522.3779786,,"Deep Learning, Learnable Representations, Music Understanding, Transformers, Embeddings, Attention","This paper focuses on reducing the size of foundation models for music information retrieval (MIR) tasks. It combines the Branchformer architecture with SummaryMixing and a random quantization process, initially applied in speech recognition. The research includes pre-training on publicly available datasets and a proprietary dataset. The architecture achieves competitive performance compared to state-of-the-art models using multi-head self-attention, reducing model size by 8.5% to 12.3%.",15.67,13.718,215,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09605v1_Sim2real Image Translation Enables Viewpoint-Robus.pdf,Sim2real Image Translation Enables Viewpoint-Robust Policies from Fixed-Camera Datasets,"Jeremiah Coholich, Justin Wit, Robert Azarcon, Zsolt Kira",,,"Sim2real, Image Translation, Robot Manipulation, Viewpoint-Robust Policies, Fixed-Camera Datasets, Vision-Based Policies, Simulation, Imitation Learning","Vision-based policies for robot manipulation have achieved significant success but remain sensitive to distribution shifts like camera viewpoint variations. Robot demonstration data is often limited and lacks diverse camera viewpoints. Simulation can provide extensive viewpoint coverage but poses a visual sim2real challenge. This paper introduces MANGO, an unpaired image translation method with a novel segmentation-conditioned InfoNCE loss, a highly-regularized discriminator design, and a modified PatchNCE loss. These elements are crucial for maintaining viewpoint consistency during sim2real translation. MANGO requires only a small amount of fixed-camera real-world data and can generate diverse unseen viewpoints by translating simulated observations. It outperforms other image translation methods in this domain. Imitation-learning policies trained with MANGO-augmented data achieve success rates up to 60% on views where non-augmented policies fail completely.",18.03,16.857,304,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09609v1_DPWriter Reinforcement Learning with Diverse Plann.pdf,DPWriter: Reinforcement Learning with Diverse Planning Branching for Creative Writing,"Qian Cao, Yahui Liu, Wei Bi, Yi Zhao, Ruihua Song, Xiting Wang, Ruiming Tang, Guorui Zhou, Han Li",,,"Reinforcement Learning, Large Language Models, Diversity, Creative Writing, Chain-of-Thought, Planning, Diverse Planning Branching","Reinforcement learning (RL)-based enhancement of large language models (LLMs) often leads to reduced output diversity, undermining their utility in open-ended tasks like creative writing. This paper proposes an RL framework structured around a semi-structured long Chain-of-Thought (CoT), decomposing the generation process into explicitly planned intermediate steps. A Diverse Planning Branching method is introduced to strategically introduce divergence at the planning phase based on diversity variation, alongside a group-aware diversity reward to encourage distinct trajectories. Experimental results on creative writing benchmarks demonstrate that this approach significantly improves output diversity without compromising generation quality, consistently outperforming existing baselines.",16.17,15.458,250,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09613v1_CogRail Benchmarking VLMs in Cognitive Intrusion P.pdf,CogRail: Benchmarking VLMs in Cognitive Intrusion Perception for Intelligent Railway Transportation Systems,"Yonglin Tian, Qiyao Zhang, Wei Xu, Yutong Wang, Yihao Wu, Xinyi Li, Xingyuan Dai, Hui Zhang, Zhiyong Cui, Baoqing Guo, Zujun Yu, Yisheng Lv",,,"Cognitive Intrusion Perception, Intelligent Railway Transportation Systems, Visual-Language Models, Spatio-Temporal Reasoning, Benchmarking, Multimodal Prompts","Accurate and early perception of potential intrusion targets is essential for ensuring the safety of railway transportation systems. Existing systems often focus narrowly on object classification within fixed visual scopes and apply rule-based heuristics to determine intrusion status, often overlooking targets that pose latent intrusion risks. Anticipating such risks requires the cognition of spatial context and temporal dynamics for the object of interest (OOI), which presents challenges for conventional visual models. To facilitate deep intrusion perception, we introduce a novel benchmark, CogRail, which integrates curated open-source datasets with cognitively driven question-answer annotations to support spatio-temporal reasoning and prediction. Building upon this benchmark, we conduct a systematic evaluation of state-of-the-art visual-language models (VLMs) using multimodal prompts to identify their strengths and limitations in this domain. Furthermore, we fine-tune VLMs for better performance and propose a joint fine-tuning framework that integrates three core tasks, position perception, movement prediction, and threat analysis, facilitating effective adaptation of general-purpose foundation models into specialized models tailored for cognitive intrusion perception. Extensive experiments reveal that current large-scale multimodal models struggle with the complex spatial-temporal reasoning required by the cognitive intrusion perception task, underscoring the limitations of existing foundation models in this safety-critical domain. In contrast, our proposed joint fine-tuning framework significantly improves performance.",19.35,23.725,459,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09620v1_Full Disclosure Less Trust How the Level of Detail.pdf,"Full Disclosure, Less Trust? How the Level of Detail about AI Use in News Writing Affects Readers’ Trust","Pooja Prajod, Hannes Cools, Thomas Röggla, Karthiskeya Puttur Venkatraj, Amber Kusters, Alia Elkattan, Pablo Cesar, Abdallah El Ali",,,"AI disclosures, news production, trust, transparency dilemma, source-checking, subscription decisions","As AI is increasingly integrated into news production, transparency about AI use has become crucial. This study investigates how different levels of AI disclosures (none, one-line, detailed) across various types of news (politics and lifestyle) and levels of AI involvement (low and high) affect readers' trust. Using a mixed factorial study with 40 participants, the research measured trust with the News Media Trust questionnaire and observed decision behaviors like source-checking and subscription decisions. Results showed a decline in trust only for detailed AI disclosures, while source-checking increased for both one-line and detailed disclosures. Interviews revealed that source-checking was driven by interest and trust, with trust being the main factor for subscription decisions. Most participants preferred detailed disclosures, with some favoring on-demand detail. The findings suggest that not all AI disclosures lead to a transparency dilemma, highlighting a trade-off between transparency and trust in AI-assisted news content.",18.62,18.316,341,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09624v1_Toward Understanding Unlearning Difficulty A Mecha.pdf,Toward Understanding Unlearning Difficulty: A Mechanistic Perspective and Circuit-Guided Difficulty Metric,"Jiali Cheng, Ziheng Chen, Chirag Agarwal, Hadi Amiri",,,"machine unlearning, language models, model circuits, unlearning difficulty, Circuit-guided Unlearning Difficulty (CUD)","Machine unlearning is essential for building trustworthy and compliant language models. However, unlearning success varies across samples, with some being reliably erased and others persisting. This disparity is not only a data-side phenomenon but also reflects model-internal mechanisms that encode and protect memorized information. The study introduces Circuit-guided Unlearning Difficulty (CUD), a pre-unlearning metric that assigns each sample a continuous difficulty score using circuit-level signals. Experiments show that CUD reliably separates easy and hard samples and remains stable across unlearning methods. Key circuit-level patterns reveal that easy-to-unlearn samples are associated with shorter, shallower interactions in earlier-to-intermediate parts of the model, while hard samples rely on longer, deeper pathways closer to late-stage computation. CUD provides a principled, fine-grained, and interpretable analysis of unlearning difficulty, motivating the development of unlearning methods grounded in model mechanisms.",17.3,16.357,283,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09625v1_The Promptware Kill Chain How Prompt Injections Gr.pdf,The Promptware Kill Chain: How Prompt Injections Gradually Evolved Into a Multi-Step Malware,"Ben Nassi, Bruce Schneier, Oleg Brodt",,,"LLM-based systems, prompt injection, malware, cybersecurity, AI safety","The rapid adoption of large language model (LLM)-based systems has created a new attack surface inadequately addressed by existing security frameworks. The paper proposes that attacks on LLM-based applications constitute a distinct class of malware, termed 'promptware,' and introduces a five-step kill chain model for analyzing these threats. The framework includes Initial Access (prompt injection), Privilege Escalation (jailbreaking), Persistence (memory and retrieval poisoning), Lateral Movement (cross-system and cross-user propagation), and Actions on Objective (ranging from data exfiltration to unauthorized transactions). This structured methodology aids security practitioners in threat modeling and provides a common vocabulary for researchers across AI safety and cybersecurity.",16.78,14.66,246,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09626v1_From Prompt to Protocol Fast Charging Batteries wi.pdf,From Prompt to Protocol: Fast Charging Batteries with Large Language Models,"Ge Lei, Ferran Brosa Planella, Sterling G. Baird, Samuel J. Cooper",,arXiv:2601.09626v1,"battery charging protocols, large language models, optimization, fast charging, state of health, neural networks, Bayesian optimization, evolutionary algorithms, closed-loop methods","Efficiently optimizing battery charging protocols is challenging due to slow, costly, and non-differentiable evaluations. Existing approaches often limit the diversity of protocols explored. This work introduces two gradient-free, LLM-driven closed-loop methods: Prompt-to-Optimizer (P2O) and Prompt-to-Protocol (P2P). P2O uses an LLM to propose neural-network-based protocols, while P2P writes explicit functions for current and its parameters. LLM-guided P2O outperforms traditional methods like Bayesian optimization and evolutionary algorithms. Both P2O and P2P achieve around a 4.2% improvement in state of health over a multi-step constant current baseline in fast-charging scenarios. These results show that LLMs can expand protocol functional forms, incorporate language-based constraints, and optimize efficiently in high-cost settings.",17.95,17.824,320,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09635v1_LLM for Large-Scale Optimization Model Auto-Formul.pdf,LLM for Large-Scale Optimization Model Auto-Formulation: A Lightweight Few-Shot Learning Approach,"Kuo Liang, Yuhang Lu, Jianming Mao, Shuyi Sun, Chunwei Yang, Congcong Zeng, Xiao Jin, Hanzhang Qin, Ruihao Zhu, Chung-Piaw Teo",,arXiv:2601.09635,"large language models, tool use, agentic workflow construction, automated optimization modeling","Large-scale optimization is crucial for modern business decision-making but is often labor-intensive and time-consuming to build. This paper introduces LEAN-LLM-OPT, a framework for LLM-assisted large-scale optimization auto-formulation. It uses a team of LLM agents to dynamically construct workflows for optimization model formulation. The framework leverages LLMs' text-processing capabilities and common modeling practices to decompose tasks into structured sub-tasks, offloading mechanical data-handling operations to auxiliary tools. This allows the downstream agent to focus on complex components. Simulations show strong performance with GPT-4.1 and gpt-oss-20B, and practical value is demonstrated in a Singapore Airlines use case. The paper also introduces benchmarks for large-scale optimization auto-formulation.",17.31,17.161,297,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09636v1_PersonalAlign Hierarchical Implicit Intent Alignme.pdf,PersonalAlign: Hierarchical Implicit Intent Alignment for Personalized GUI Agent with Long-Term User-Centric Records,"Yibo Lyu, Gongwei Chen, Rui Shao, Weili Guan, Liqiang Nie",,,"GUI agents, implicit intent alignment, personalized agents, long-term user records, proactive assistance, Hierarchical Intent Memory Agent, AndroidIntent benchmark","This work introduces PersonalAlign, a task for GUI agents to align with users' implicit intents by leveraging long-term user records. The study presents AndroidIntent, a benchmark for evaluating agents' ability to resolve vague instructions and provide proactive suggestions. The Hierarchical Intent Memory Agent (HIM-Agent) is introduced, which maintains a continuously updating personal memory to organize user preferences and routines. Evaluation shows HIM-Agent significantly improves execution and proactive performance. The research highlights the need for personalized agents capable of understanding implicit intents beyond explicit instructions.",16.39,14.764,242,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09667v2_Collaborative Multi-Agent Test-Time Reinforcement .pdf,Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning,"Zhiyuan Hu, Yunhai Hu, Juncheng Liu, Shuyue Stella Li, Yucheng Wang, Zhen Xu, See-Kiong Ng, Anh Tuan Luu, Xinxing Xu, Bryan Hooi, Cynthia Breazeal, Hae Won Park",,,"multi-agent systems, reinforcement learning, test-time adaptation, collaborative reasoning, distribution shift robustness","Multi-agent systems have evolved into practical LLM-driven collaborators for many applications, gaining robustness from diversity and cross-checking. However, multi-agent RL (MARL) training is resource-intensive and unstable: co-adapting teammates induce non-stationarity, and rewards are often sparse and high-variance. Therefore, we introduce Multi-Agent Test-Time Reinforcement Learning (MATTRL), a framework that injects structured textual experience into multi-agent deliberation at inference time. MATTRL forms a multi-expert team of specialists for multi-turn discussions, retrieves and integrates test-time experiences, and reaches consensus for final decision-making. Across challenging benchmarks in medicine, math, and education, MATTRL improves accuracy by an average of 3.67% over a multi-agent baseline, and by 8.67% over comparable single-agent baselines. Ablation studies examine different credit-assignment schemes and provide a detailed comparison of how they affect training outcomes. MATTRL offers a stable, effective, and efficient path to distribution-shift-robust multi-agent reasoning without tuning.",18.62,20.834,388,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09680v1_Automating Supply Chain Disruption Monitoring via .pdf,Automating Supply Chain Disruption Monitoring via an Agentic AI Approach,"Sara AlMahria, Liming Xu, Alexandra Brintrup",,2601.09680v1,"Supply Chain Management, Supply Chain Disruption, Large Language Models, AI Agents, Multi-Agent System, Agentic System","Modern supply chains are increasingly exposed to disruptions from geopolitical events, demand shocks, trade restrictions, to natural disasters. While many of these disruptions originate deep in the supply network, most companies still lack visibility beyond Tier-1 suppliers, leaving upstream vulnerabilities undetected until the impact cascades downstream. To overcome this blind-spot and move from reactive recovery to proactive resilience, we introduce a minimally supervised agentic AI framework that autonomously monitors, analyses, and responds to disruptions across extended supply networks. The architecture comprises seven specialised agents powered by large language models and deterministic tools that jointly detect disruption signals from unstructured news, map them to multi-tier supplier networks, evaluate exposure based on network structure, and recommend mitigations such as alternative sourcing options. We evaluate the framework across 30 synthesised scenarios covering three automotive manufacturers and five disruption classes. The system achieves high accuracy across core tasks, with F1 scores between 0.962 and 0.991, and performs full end-to-end analyses in a mean of 3.83 minutes at a cost of $0.0836 per disruption. Relative to industry benchmarks of multi-day, analyst-driven assessments, this represents a reduction of more than three orders of magnitude in response time. A real-world case study of the 2022 Russia–Ukraine conflict further demonstrates operational applicability. This work establishes a foundational step toward building resilient, proactive, and autonomous supply chains capable of managing disruptions across deep-tier networks.",20.03,20.424,409,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09684v1_Disentangling Task Conflicts in Multi-Task LoRA vi.pdf,Disentangling Task Conflicts in Multi-Task LoRA via Orthogonal Gradient Projection,"Ziyu Yang, Guibin Chen, Yuxin Yang, Aoxiong Zeng, Xiangquan Yang",,,"Multi-Task Learning, Low-Rank Adaptation, Large Language Models, Parameter-Efficient Fine-Tuning, Gradient Projection, Orthogonal Complement, Negative Transfer, Gradient Conflict","Multi-Task Learning (MTL) combined with Low-Rank Adaptation (LoRA) is a promising approach for parameter-efficient deployment of Large Language Models (LLMs). However, sharing a single adapter across multiple tasks can lead to negative transfer due to conflicting gradient updates. This issue is exacerbated by the low-rank constraint in LoRA, which limits the optimization landscape's capacity. This paper introduces Ortho-LoRA, a gradient projection method tailored for LoRA's bipartite structure. Ortho-LoRA dynamically projects conflicting task gradients onto the orthogonal complement of each other within the intrinsic LoRA subspace. Experiments on the GLUE benchmark show that Ortho-LoRA effectively mitigates task interference, outperforming standard joint training and recovering 95% of the performance gap between multi-task and single-task baselines with negligible computational overhead.",17.88,17.84,319,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09692v1_Routing with Generated Data Annotation-Free LLM Sk.pdf,Routing with Generated Data: Annotation-Free LLM Skill Estimation and Expert Selection,"Tianyi Niu, Justin Chih-Yao Chen, Genta Indra Winata, Shi-Xiong Zhang, Supriyo Chakraborty, Sambit Sahu, Yue Zhang, Elias Stengel-Eskin, Mohit Bansal",,,"Large Language Models, Routing, Generated Data, Skill Estimation, Expert Selection, Query-only Routing, Query-answer Routing, CASCAL, Consensus Voting, Hierarchical Clustering","This paper introduces Routing with Generated Data (RGD), a method for training routers to select optimal models for given inputs using generated queries and answers from high-level task descriptions. The study evaluates query-answer and query-only routers across benchmarks and models, revealing that query-only routers are more robust to generator quality. The proposed CASCAL method, which uses consensus voting and hierarchical clustering, shows improved robustness and performance over existing methods when trained on weak generator data.",17.21,16.215,279,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09694v1_LLMs can Compress LLMs Adaptive Pruning by Agents.pdf,LLMs can Compress LLMs: Adaptive Pruning by Agents,"Sai Varun Kodathala, Rakesh Vunnam",,arXiv:2601.09694v1,"Model Compression, Adaptive Pruning, Self-Reflection","As Large Language Models (LLMs) continue to scale, post-training pruning has emerged as a promising approach to reduce computational costs while preserving performance. Existing methods such as SparseGPT and Wanda achieve high sparsity through layer-wise weight reconstruction or activation-aware magnitude pruning, but rely on uniform or hand-crafted heuristics to determine per-layer sparsity ratios. Moreover, recent work has shown that pruned LLMs suffer from severe factual knowledge degradation, with structured pruning methods experiencing near-total collapse in factual question-answering capabilities. We introduce agent-guided pruning, where a foundation model acts as an adaptive pruning agent to intelligently select which layers to prune at each iteration while preserving critical knowledge pathways. Our method constructs layer-wise sensitivity profiles by combining Wanda-inspired weight-activation metrics with gradient importance scores, normalized as z-scores for model-agnostic comparison. These statistics are processed by an LLM agent equipped with self-reflection capabilities, enabling it to learn from previous pruning outcomes and iteratively refine its strategy. A checkpoint rollback mechanism maintains model quality by reverting when perplexity degradation exceeds a threshold. We evaluate our approach on Qwen3 models (4B and 8B parameters) at approximately 45% sparsity, demonstrating substantial improvements over structured pruning baselines: 56% relative improvement in MMLU accuracy, 19× better factual knowledge retention on FreebaseQA, and 69% lower perplexity degradation. Notably, our framework requires no retraining, operates in a model-agnostic manner, and exhibits effective self-correction with only 2-4 rollbacks across 21-40 iterations, demonstrating that foundation models can effectively guide the compression of other foundation models.",20.76,21.484,446,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09703v1_ShortCoder Knowledge-Augmented Syntax Optimization.pdf,ShortCoder: Knowledge-Augmented Syntax Optimization for Token-Efficient Code Generation,"Sicong Liu, Yanxian Huang, Mingwei Liu, Jiachi Chen, Ensheng Shi, Yuchi Ma, Hongyu Zhang, Yin Zhang, Yanlin Wang",,,"code generation, large language models, LLMs, token efficiency, syntax simplification, code optimization","Code generation tasks aim to automate the conversion of user requirements into executable code, significantly reducing manual development efforts and enhancing software productivity. The emergence of large language models (LLMs) has significantly advanced code generation, though their efficiency is still impacted by certain inherent architectural constraints. Each token generation necessitates a complete inference pass, requiring persistent retention of contextual information in memory and escalating resource consumption. While existing research prioritizes inference-phase optimizations—such as prompt compression and model quantization, the generation phase remains underexplored. To tackle these challenges, we propose a knowledge-infused framework named ShortCoder, which optimizes code generation efficiency while preserving semantic equivalence and readability. In particular, we introduce: (1) ten syntax-level simplification rules for Python, derived from AST-preserving transformations, achieving 18.1% token reduction without functional compromise; (2) a hybrid data synthesis pipeline integrating rule-based rewriting with LLM-guided refinement, producing ShorterCodeBench—a corpus of validated ⟨original code, simplified code⟩ pairs with semantic consistency; (3) a fine-tuning strategy that injects conciseness awareness into the base LLMs. Extensive experimental results demonstrate that ShortCoder consistently outperforms state-of-the-art methods on HumanEval, achieving an improvement of 18.1%-37.8% in generation efficiency over previous methods while ensuring the performance of code generation.",19.63,21.7,426,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09706v1_Value-Aware Numerical Representations for Transfor.pdf,Value-Aware Numerical Representations for Transformer Language Models,"Andreea Dutulescu, Stefan Ruseti, Mihai Dascalu",,,"Transformer language models, numerical reasoning, arithmetic operations, value-aware numerical representation, numerical robustness","Transformer-based language models often achieve strong results on mathematical reasoning benchmarks while remaining fragile on basic numerical understanding and arithmetic operations. A central limitation is that numbers are processed as symbolic tokens whose embeddings do not explicitly encode numerical value, leading to systematic errors. This paper introduces a value-aware numerical representation that augments standard tokenized inputs with a dedicated prefix token whose embedding is explicitly conditioned on the underlying numerical value. This mechanism injects magnitude information directly into the model’s input space while remaining compatible with existing tokenizers and decoder-only Transformer architectures. Evaluation on arithmetic tasks shows that the proposed approach outperforms baselines across numerical formats, tasks, and operand lengths. These results indicate that explicitly encoding numerical value is an effective and efficient way to improve fundamental numerical robustness in language models.",16.63,14.489,241,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09708v1_Fast-ThinkAct Efficient Vision-Language-Action Rea.pdf,Fast-ThinkAct: Efficient Vision-Language-Action Reasoning via Verbalizable Latent Planning,"Chi-Pin Huang, Yunze Man, Zhiding Yu, Min-Hung Chen, Jan Kautz, Yu-Chiang Frank Wang, Fu-En Yang",,arXiv:2601.09708v1,"Vision-Language-Action, reasoning, latent planning, inference latency, policy learning, embodied control, long-horizon planning, few-shot adaptation, failure recovery","Vision-Language-Action (VLA) tasks require reasoning over complex visual scenes and executing adaptive actions in dynamic environments. Recent studies show that explicit chain-of-thought (CoT) can improve generalization but suffer from high inference latency due to lengthy reasoning traces. Fast-ThinkAct is an efficient reasoning framework that achieves compact yet performant planning through verbalizable latent reasoning. It learns to reason efficiently with latent CoTs by distilling from a teacher, driven by a preference-guided objective to align manipulation trajectories, transferring both linguistic and visual planning capabilities for embodied control. This enables reasoning-enhanced policy learning that effectively connects compact reasoning to action execution. Extensive experiments demonstrate that Fast-ThinkAct achieves strong performance with up to 89.3% reduced inference latency over state-of-the-art reasoning VLAs, while maintaining effective long-horizon planning, few-shot adaptation, and failure recovery.",18.67,18.747,350,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09749v1_R-LAM Reproducibility-Constrained Large Action Mod.pdf,R-LAM: Reproducibility-Constrained Large Action Models for Scientific Workflow Automation,Suriya Sureshkumar,,,"Reproducible Scientific Workflows, Large Action Models, LLM-Based Agents, Execution Provenance, Deterministic Execution","Large Action Models (LAMs) extend large language models by enabling autonomous decision-making and tool execution, making them promising for automating scientific workflows. However, scientific workflows impose strict requirements on reproducibility, auditability, and deterministic execution, which are not satisfied by generic LLM-based agents. Unconstrained action generation can lead to silent state changes, non-deterministic executions, and irreproducible experimental results, limiting the applicability of LAMs in scientific settings. In this paper, we propose R-LAM, a reproducibility-constrained framework for applying Large Action Models to scientific workflow automation. R-LAM introduces structured action schemas, deterministic execution policies, and explicit provenance tracking to ensure that every action and intermediate artifact is auditable and replayable. The framework supports failure-aware execution loops and controlled workflow forking, enabling iterative experimentation without compromising reproducibility. We implement R-LAM as a lightweight Python framework and release it as an open-source PyPI package to facilitate reproducible research. An experimental evaluation of representative scientific workflows demonstrates that R-LAM improves reproducibility success rates and execution reliability compared to unconstrained LLM-based agents, while retaining adaptive control over workflow execution.",18.49,17.523,324,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09750v1_SAGE Tool-Augmented LLM Task Solving Strategies in.pdf,SAGE: Tool-Augmented LLM Task Solving Strategies in Scalable Multi-Agent Environments,"Robert K. Strehlow, Tobias Küster, Oskar F. Kupke, Brandon Llanque Kurps, Fikret Sivrikaya, Sahin Albayrak",,,"Large Language Models, Tool-Augmented LLM, Multi-Agent Environments, OPACA Framework, Tool Discovery, Execution, Zero-Shot Prompting, Conversational AI","This paper introduces 'SAGE', a specialized conversational AI interface based on the OPACA framework for tool discovery and execution. It discusses strategies for integrating and dynamically using tools with large language models (LLMs) in real-world applications. The paper evaluates various task-solving strategies using benchmark services and highlights the strengths and weaknesses of different approaches. Both SAGE and the OPACA framework, along with benchmark services and results, are available as open source/open data on GitHub.",16.5,15.693,259,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09753v1_Critically Engaged Pragmatism A Scientific Norm an.pdf,"Critically Engaged Pragmatism: A Scientific Norm and Social, Pragmatist Epistemology for AI Science Evaluation Tools",Carole J. Lee,,,"AI science evaluation tools, peer review crisis, replication crisis, scientific credibility, Critically Engaged Pragmatism, social pragmatist epistemology","The paper discusses the challenges faced by the scientific community in evaluating research credibility due to the limitations of peer review and replication studies. It highlights the rise of AI science evaluation tools as a response to these challenges but warns against their misuse due to potential 'inference by false ascent.' The author advocates for a social, pragmatist epistemology and a norm of Critically Engaged Pragmatism to ensure these tools are scrutinized for their purpose-specific reliability. The paper argues that AI tools should not be seen as objective arbiters but as subjects of critical discourse that underpin scientific credibility.",16.54,14.387,238,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09755v1_Heterogeneous computing platform for real-time rob.pdf,Heterogeneous computing platform for real-time robotics,"Jakub Fil, Yulia Sandamirskaya, Hector Gonzalez, Loïc Azzalin, Stefan Glüge, Lukas Friedenstab, Friedrich Wolf, Tim Rosmeisl, Matthias Lohrmann, Mahmoud Akl, Khaleel Khan, Leonie Wolf, Kristin Richter, Holm Puder, Mazhar Ali Bari, Xuan Choo, Noha Alharthi, Michael Hopkins, Mansoor Hanif, Christian Mayr, Jens Struckmeier, Steve Furber",,,"heterogeneous computing, real-time robotics, neuromorphic computing, Loihi2 processor, event-based cameras, dynamic vision sensor, cognitive cities, Society 5.0, NEOM initiative, human-robot interaction, GPU, large language models, brain-inspired hardware","This paper explores a computing platform required for enabling Society 5.0, where robotics plays a pivotal role in smart cities. It combines neuromorphic computing hardware, like the Loihi2 processor, with event-based cameras for real-time perception and interaction, and a local AI compute cluster (GPUs) for high-level language processing and task planning. The proposed hybrid architecture is demonstrated through an interactive task where a humanoid robot plays a musical instrument with a human. The integration of disparate components maximizes performance and responsiveness, highlighting the potential of heterogeneous computing architectures in advancing robotic autonomy and interactive intelligence.",19.1,21.935,419,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09756v1_Synthetic Data for Veterinary EHR De-identificatio.pdf,"Synthetic Data for Veterinary EHR De-identification: Benefits, Limits, and Safety Trade-offs Under Fixed Compute","David Brundage, PhD",,,"veterinary electronic health records, de-identification, large language models, synthetic data, privacy, surveillance, research","Veterinary electronic health records (vEHRs) are increasingly used for surveillance and research, but free-text narratives often contain privacy-sensitive identifiers that limit their secondary use. This study evaluates the use of large language model (LLM)-generated synthetic veterinary narratives to improve de-identification safety and utility. Using the PetEVAL dataset, the study explores synthetic augmentation and substitution under fixed training budgets. Results indicate that synthetic data can reduce document-level leakage when used to expand training exposure but does not safely replace real supervision under fixed budgets. The study highlights that observed gains are largely due to increased exposure rather than intrinsic advantages of synthetic text.",16.86,13.995,236,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09757v1_Democracy and Distrust in an Era of Artificial Int.pdf,Democracy & Distrust in an Era of Artificial Intelligence,Sonia K. Katyal,10.1162/DAED_a_01919,,"Artificial Intelligence, Judicial Review, Democracy, Minorities, Due Process, Equal Protection, AI Decision-Making","The essay discusses the challenges posed by AI decision-making to democracy, particularly in protecting minority rights. It explores the rise of privatization, prediction, and automation in AI, and outlines a theory of judicial review in the AI era. The author analyzes cases where AI decision-making has been challenged in courts, suggesting ways to integrate concepts of due process and equal protection into AI for better oversight and accountability. The essay also reflects on the metaphor of AI as a mirror of human nature, highlighting the distortions and inaccuracies in comparing humans and machines.",16.11,12.287,198,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09760v1_Investigating Tool-Memory Conflicts in Tool-Augmen.pdf,Investigating Tool-Memory Conflicts in Tool-Augmented LLMs,"Jiali Cheng, Rui Pan, Hadi Amiri",,,"Tool-augmented LLMs, Knowledge conflict, Tool-Memory Conflict (TMC), STEM-related tasks, Conflict resolving techniques, Parametric knowledge, External tool knowledge","Tool-augmented large language models (LLMs) have enhanced problem-solving capabilities by integrating external tools like function calling and APIs. However, they face a new type of knowledge conflict known as Tool-Memory Conflict (TMC), where internal parametric knowledge contradicts external tool knowledge. This study investigates the conditions under which TMCs appear, how LLMs prioritize conflicting knowledge, and evaluates existing conflict resolution techniques. The findings reveal that current methods are ineffective in resolving TMCs, highlighting the need for improved strategies to ensure knowledge reliability and coherence in tool-augmented LLMs.",15.74,13.847,218,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09762v1_Explicating Tacit Regulatory Knowledge from LLMs t.pdf,Explicating Tacit Regulatory Knowledge from LLMs to Auto-Formalize Requirements for Compliance Test Case Generation,"Zhiyi Xue, Xiaohong Chen, Min Zhang",,,"compliance testing, large language models, regulatory knowledge, test case generation, requirements formalization","Compliance testing in highly regulated domains is crucial but largely manual, requiring domain experts to translate complex regulations into executable test cases. This paper proposes RAFT, a framework for requirements auto-formalization and compliance test generation by explicating tacit regulatory knowledge from multiple LLMs. RAFT employs an Adaptive Purification-Aggregation strategy to integrate tacit knowledge into a domain meta-model, formal requirements representation, and testability constraints. These artifacts guide high-precision requirement formalization and automated test generation. Experiments show RAFT achieves expert-level performance, outperforming state-of-the-art methods while reducing generation and review time.",16.43,14.546,239,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09765v1_AI Survival Stories a Taxonomic Analysis of AI Exi.pdf,AI SURVIVAL STORIES: A TAXONOMIC ANALYSIS OF AI EXISTENTIAL RISK,"Herman Cappelena, Simon Goldstein",,,"Artificial Intelligence, Existential Risk, AI safety, AI Catastrophe, Superintelligent AI, AI Alignment","This paper develops a framework for assessing the existential risk posed by AI systems, focusing on a two-premise argument: AI systems will become extremely powerful, and if they do, they will destroy humanity. The authors construct a taxonomy of 'survival stories' where humanity survives, analyzing scenarios where scientific barriers prevent AI from becoming extremely powerful, research into AI is banned, powerful AI systems do not destroy humanity due to goal alignment, or such systems can be reliably detected and disabled. The paper discusses the challenges and responses associated with different survival stories and provides rough estimates of the probability of humanity's destruction by AI.",15.88,13.286,211,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09768v1_CLiMB A Domain-Informed Novelty Detection Clusteri.pdf,CLiMB: A Domain-Informed Novelty Detection Clustering Framework for Scientific Discovery,"Lorenzo Monti, Tatiana Muraveva, Brian Sheridan, Davide Massari, Alessia Garofalo, Gisella Clementini, Umberto Michelucci",10.5555/2022.23.1-28,2601.09768v1,"novelty detection, semi-supervised clustering, constrained clustering, density-based clustering, domain knowledge integration","In data-driven scientific discovery, a challenge lies in classifying well-characterized phenomena while identifying novel anomalies. Current semi-supervised clustering algorithms do not always fully address this duality, often assuming that supervisory signals are globally representative. Consequently, methods often enforce rigid constraints that suppress unanticipated patterns or require a pre-specified number of clusters, rendering them ineffective for genuine novelty detection. To bridge this gap, we introduce CLiMB (CLustering in Multiphase Boundaries), a domain-informed framework decoupling the exploitation of prior knowledge from the exploration of unknown structures. Using a sequential two-phase approach, CLiMB first anchors known clusters using constrained partitioning, and subsequently applies density-based clustering to residual data to reveal arbitrary topologies. We demonstrate this framework on RR Lyrae stars data from the Gaia Data Release 3. CLiMB attains an Adjusted Rand Index of 0.829 with 90% seed coverage in recovering known Milky Way substructures, drastically outperforming heuristic and constraint-based baselines, which stagnate below 0.20. Furthermore, sensitivity analysis confirms CLiMB’s superior data efficiency, showing monotonic improvement as knowledge increases. Finally, the framework successfully isolates three dynamical features (Shiva, Shakti, and the Galactic Disk) in the unlabelled field, validating its potential for scientific discovery.",19.82,22.353,443,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09770v1_GUI-Eyes Tool-Augmented Perception for Visual Grou.pdf,GUI-Eyes: Tool-Augmented Perception for Visual Grounding in GUI Agents,"Chen Chen, Jiawei Shao, Dakuan Lu, Haoyi Hu, Xiangcheng Liu, Hantao Yao, Wu Liu",,,"GUI automation, vision-language models, reinforcement learning, active visual perception, tool usage, spatially continuous reward function, ScreenSpot-Pro benchmark","Recent advances in vision-language models (VLMs) and reinforcement learning (RL) have driven progress in GUI automation. However, existing methods often rely on static, one-shot visual inputs and passive perception, lacking adaptive observation capabilities. This paper introduces GUI-Eyes, a reinforcement learning framework for active visual perception in GUI tasks. The agent learns to make strategic decisions on invoking visual tools like cropping or zooming within a two-stage reasoning process. A progressive perception strategy decomposes decision-making into coarse exploration and fine-grained grounding, coordinated by a two-level policy. A spatially continuous reward function tailored to tool usage integrates location proximity and region overlap to provide dense supervision and alleviate reward sparsity. On the ScreenSpot-Pro benchmark, GUI-Eyes-3B achieves 44.8% grounding accuracy using only 3k labeled samples, outperforming both supervised and RL-based baselines. The results highlight the importance of tool-aware active perception, enabled by staged policy reasoning and fine-grained reward feedback, for building robust and data-efficient GUI agents.",18.18,19.637,357,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09771v1_PCN-Rec Agentic Proof-Carrying Negotiation for Rel.pdf,PCN-Rec: Agentic Proof-Carrying Negotiation for Reliable Governance-Constrained Recommendation,"Aradhya Dixit, Shreem Dixit",,,"recommendation systems, LLM agents, constrained ranking, governance, verification, negotiation","Modern LLM-based recommenders can generate compelling ranked lists but struggle to reliably satisfy governance constraints such as minimum long-tail exposure or diversity requirements. We present PCN-Rec, a proof-carrying negotiation pipeline that separates natural-language reasoning from deterministic enforcement. A base recommender produces a candidate window, which is negotiated by two agents: a User Advocate optimizing relevance and a Policy Agent enforcing constraints. A mediator LLM synthesizes a Top-N slate with a structured certificate describing the claimed constraint satisfaction. A deterministic verifier recomputes all constraints from the slate and accepts only verifier-checked certificates; if verification fails, a deterministic constrained-greedy repair produces a compliant slate for re-verification, yielding an auditable trace. On MovieLens-100K with governance constraints, PCN-Rec achieves a 98.55% pass rate on feasible users versus a one-shot single-LLM baseline without verification/repair, while preserving utility with only a 0.021 absolute drop in NDCG@10; differences are statistically significant.",17.83,17.722,316,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09772v1_Antisocial behavior towards large language model u.pdf,Antisocial behavior towards large language model users: experimental evidence,"Paweł Niszczota, Cassandra Grützner",,,,"This study investigates antisocial behavior towards users of large language models through experimental evidence. The research was conducted by Paweł Niszczota and Cassandra Grützner, affiliated with Poznań University of Economics and Business and Martin Luther Universität Halle-Wittenberg, respectively. The study received ethical approval and informed consent from participants, with data and materials available for public access. The research was supported by a grant from the National Science Centre, Poland.",16.02,10.049,161,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09773v1_Enhancing LUT-based Deep Neural Networks Inference.pdf,Enhancing LUT-based Deep Neural Networks Inference through Architecture and Connectivity Optimization,"Binglei Lou, Ruilin Wu, Philip Leong",,,"Dynamic Sparsity, FPGA, Neural Network, Lookup Table","Deploying deep neural networks (DNNs) on resource-constrained edge devices such as FPGAs requires balancing latency, power, and hardware resource usage while maintaining high accuracy. Existing Lookup Table (LUT)-based DNNs face challenges of exponential LUT size growth and inefficient random sparse connectivity. This paper introduces SparseLUT, a framework addressing these challenges through architectural enhancements and a non-greedy training algorithm. The architectural enhancement aggregates multiple PolyLUT sub-neurons via an adder, reducing LUT consumption by 2.0×–13.9× and lowering inference latency by 1.2×–1.6×, while maintaining comparable accuracy. The training optimization prunes less significant inputs and regrows more effective ones, achieving up to a 2.13% gain on MNIST and 0.94% on Jet Substructure Classification compared to existing LUT-DNN approaches.",17.0,15.769,268,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09805v1_Improving Chain-of-Thought for Logical Reasoning v.pdf,Improving Chain-of-Thought for Logical Reasoning via Attention-Aware Intervention,"Phuong Minh Nguyen, Tien Huu Dang, Naoya Inoue",,,"logical reasoning, LLMs, attention-aware intervention, end-to-end framework, attention modulation","Modern logical reasoning with LLMs primarily relies on complex interactive frameworks that decompose the reasoning process into subtasks solved through carefully designed prompts or requiring external resources. This work introduces a non-interactive, end-to-end framework for reasoning tasks, leveraging structural information in few-shot prompts to activate attention heads aligned with logical reasoning operators. The proposed Attention-Aware Intervention (AAI) method reweights attention scores across selected heads identified by their logical patterns, enhancing logical reasoning performance across diverse benchmarks and model architectures with negligible computational overhead. Code is available at https://github.com/phuongnm94/aai_for_logical_reasoning.",15.43,13.477,208,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09806v1_Diffusion-Driven Deceptive Patches Adversarial Man.pdf,Diffusion-Driven Deceptive Patches: Adversarial Manipulation and Forensic Detection in Facial Identity Verification,"Shahrzad Sayyafzadeh, Hongmei Chi, Shonda Bernadin",,arXiv:2601.09806v1,"Adversarial Patch Generation, Gaussian Smoothing, Diffusion Model, Social Media Forensics, Perceptual Hashing","This work presents an end-to-end pipeline for generating, refining, and evaluating adversarial patches to compromise facial biometric systems with forensic analysis and security testing applications. We utilize a FGSM to generate adversarial noise targeting our classifier for identity detection and employ a diffusion model for reverse diffusion to enhance the imperceptibility with additional Gaussian smoothing and adaptive brightness correction of synthetic adversarial patch evasion generation. The refined patch is applied to facial images to test its ability to evade recognition systems while maintaining natural visual characteristics. A Vision Transformer (ViT)-GPT2 model generates captions to provide a semantic description of a person’s identity for Adv Images, supporting forensic interpretation and documentation for identity evasion attack and recognition. The pipeline evaluates changes in identity classification, captioning results, and the vulnerability of facial identity verification and expression to adversarial attacks. Therefore, detecting and mitigating attacks from these adversaries is necessary in forensic settings using perceptual hashing. We successfully detected and analyzed a series of adversaries generated with 0.95% SSIM.",19.84,17.191,341,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09809v1_QFed Parameter-Compact Quantum-Classical Federated.pdf,QFed: Parameter-Compact Quantum-Classical Federated Learning,"Samar Abdelghani, Soumaya Cherkaoui",,,"Quantum Computing, Quantum Machine Learning, Federated Learning, Privacy, Communication, IoT","Organizations across various domains are required to extract intelligence from distributed datasets while adhering to privacy and regulatory constraints. Federated Learning (FL) enables collaborative model building without sharing sensitive data but faces challenges from statistical heterogeneity, system diversity, and computational burdens. This study explores quantum-assisted FL, which can reduce the number of parameters in classical models by polylogarithmic factors, thus reducing training overhead. The proposed QFed framework aims to enhance computational efficiency in edge device networks. Experimental results using the FashionMNIST dataset show that QFed achieves a 77.6% reduction in parameter count of a VGG-like model while maintaining accuracy comparable to classical approaches. This indicates the potential of quantum computing in federated learning to enhance the capabilities of edge devices.",16.79,15.067,253,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09814v1_Explainable Deep Learning for Pediatric Pneumonia .pdf,Explainable Deep Learning for Pediatric Pneumonia Detection in Chest X-Ray Images,"Adil O. Khadidos, Aziida Nanyonga, Alaa O. Khadidos, Olfat M. Mirza, Mustafa Tahsin Yilmaz",,,"pediatric pneumonia detection, chest X-ray images, deep learning, convolutional neural networks, DenseNet121, EfficientNet-B0, Gradient-weighted Class Activation Mapping (Grad-CAM), Local Interpretable Model-agnostic Explanations (LIME)","Pneumonia is a significant cause of illness and death among children globally, necessitating accurate diagnostic tools. This study compares DenseNet121 and EfficientNet-B0 for pediatric pneumonia detection using chest X-ray images. A dataset of 5,863 images was preprocessed and used to fine-tune the models with pretrained ImageNet weights. EfficientNet-B0 outperformed DenseNet121 in accuracy, F1-score, and MCC, while both models demonstrated high recall. Explainability was achieved using Grad-CAM and LIME to visualize decision-making regions.",18.56,15.519,288,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09822v2_LLM-Based Agentic Systems for Software Engineering.pdf,LLM-Based Agentic Systems for Software Engineering: Challenges and Opportunities,"Yongjian Tang, Thomas Runkler",,arXiv:2601.09822v2,"LLMs, Agents, Software Engineering, Future Challenges","Despite recent advancements in Large Language Models (LLMs), complex Software Engineering (SE) tasks require more collaborative and specialized approaches. This concept paper systematically reviews the emerging paradigm of LLM-based multi-agent systems, examining their applications across the Software Development Life Cycle (SDLC), from requirements engineering and code generation to static code checking, testing, and debugging. It delves into a wide range of topics such as language model selection, SE evaluation benchmarks, state-of-the-art agentic frameworks and communication protocols. Furthermore, it identifies key challenges and outlines future research opportunities, with a focus on multi-agent orchestration, human-agent coordination, computational cost optimization, and effective data collection. This work aims to provide researchers and practitioners with valuable insights into the current forefront landscape of agentic systems within the software engineering domain.",17.87,14.385,257,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09841v2_A pipeline for enabling path-specific causal fairn.pdf,APIPELINE FOR ENABLING PATH-SPECIFIC CAUSAL FAIRNESS IN OBSERVATIONAL HEALTH DATA,"Aparajita Kashyap, Sara Matijevic, Noémie Elhadad, Steven A. Kushner, Shalmali Joshi",,2601.09841v2,"Causal fairness, foundation models, causal inference, observational health data, fair machine learning","When training machine learning (ML) models for potential deployment in a healthcare setting, it is essential to ensure that they do not replicate or exacerbate existing healthcare biases. Although many definitions of fairness exist, we focus on path-specific causal fairness, which allows us to better consider the social and medical contexts in which biases occur (e.g., direct discrimination by a clinician or model versus bias due to differential access to the healthcare system) and to characterize how these biases may appear in learned models. In this work, we map the structural fairness model to the observational healthcare setting and create a generalizable pipeline for training causally fair models. The pipeline explicitly considers specific healthcare context and disparities to define a target 'fair' model. Our work fills two major gaps: first, we expand on characterizations of the 'fairness-accuracy' tradeoff by detangling direct and indirect sources of bias and jointly presenting these fairness considerations alongside considerations of accuracy in the context of broadly known biases. Second, we demonstrate how a foundation model trained without fairness constraints on observational health data can be leveraged to generate causally fair downstream predictions in tasks with known social and medical disparities. This work presents a model-agnostic pipeline for training causally fair machine learning models that address both direct and indirect forms of healthcare bias.",20.31,19.743,401,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09851v1_ViSIL Unified Evaluation of Information Loss in Mu.pdf,ViSIL: Unified Evaluation of Information Loss in Multimodal Video Captioning,"Po-han Li, Shenghui Chen, Ufuk Topcu, Sandeep Chinchali",,,"multimodal video captioning, information loss, ViSIL score, vision-language model, Video Question Answering, multimodal summarization","Multimodal video captioning condenses dense footage into keyframes and natural language, serving as a proxy for efficient retrieval. Traditional metrics like BLEU or ROUGE fail to quantify information coverage across modalities. The proposed Video Summary Information Loss (ViSIL) score quantifies video information not captured by a summary using vision-language model inference. ViSIL enables direct comparison across multimodal summary formats and correlates with human and VLM performance on Video Question Answering tasks. It optimizes the trade-off between information loss and processing speed, outperforming text summaries in VQA accuracy without increasing processing load.",16.73,15.001,251,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09853v1_MedRedFlag Investigating how LLMs Redirect Misconc.pdf,MedRedFlag: Investigating how LLMs Redirect Misconceptions in Real-World Health Communication,"Sraavya Sambara, Yuan Pu, Ayman Ali, Vishala Mishra, Lionel Wong, Monica Agrawal",,,"LLMs, medical advice, misconceptions, health communication, redirection, patient safety","This study investigates how large language models (LLMs) handle real-world health questions that contain false assumptions or premises. The authors developed a dataset, MedRedFlag, consisting of over 1100 questions from Reddit that require redirection. The study compares responses from LLMs to those from clinicians, revealing that LLMs often fail to properly redirect problematic questions, potentially leading to suboptimal medical decision-making. This highlights significant safety concerns for patient-facing medical AI systems.",16.0,14.247,228,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09855v1_Thinking Long but Short Stable Sequential Test-Tim.pdf,Stable Sequential Test-Time Scaling for Large Reasoning Models,"Michael R. Metel, Yufei Cui, Boxing Chen, Prasanna Parthasarathi",,arXiv:2601.09855v1,"sequential test-time scaling, large reasoning models, model accuracy, chain-of-thought reasoning, KV cache, context length, computational complexity","Sequential test-time scaling is a training-free method to enhance the accuracy of large reasoning models by inducing them to think for longer periods. However, extending reasoning length can lead to accuracy degradation and instability. This work introduces Min-Seek, a novel method that stabilizes accuracy across various reasoning tasks without the need for fine-tuning reasoning length. Min-Seek efficiently manages the KV cache by storing keys without position embeddings, allowing reasoning beyond the model's maximum context length with linear computational complexity.",16.12,14.395,232,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09858v1_OUTLINEFORGE Hierarchical Reinforcement Learning w.pdf,OUTLINEFORGE: Hierarchical Reinforcement Learning with Explicit States for Scientific Writing,"Yilin Bao, Ziyao He, Zayden Yang",,,"scientific paper generation, reinforcement learning, hierarchical document structures, scientific correctness, discourse coherence, citation fidelity","Scientific paper generation requires document-level planning and factual grounding, but current large language models often fail in global structure, input coverage, and citation consistency. This paper presents a reinforcement learning framework that casts scientific outline construction as a long-horizon planning problem over hierarchical document structures. The approach models edit evolving outlines through structured actions, enabling the system to incrementally build a complete scientific manuscript. A two-stage optimization procedure is introduced to support effective and stabilize learning, consisting of backward outline reconstruction from partial plans to enforce global structural consistency, and forward value-guided reinforcement learning with rewards explicitly modeling scientific correctness, discourse coherence, and citation fidelity. A benchmark for scientific paper generation is also introduced, evaluating document planning, input utilization, reference faithfulness, outline organization, and content-level factual accuracy. Results show consistent improvements over strong neural and LLM baselines, particularly in long-range structural coherence and citation reliability.",16.95,15.931,270,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09865v1_Advancing Model Refinement Muon-Optimized Distilla.pdf,Advancing Model Refinement: Muon-Optimized Distillation and Quantization for LLM Deployment,"Jacob Sander, Brian Jalaian, Venkat R. Dasarivenkateswara",,arXiv:2601.09865v1,"Large Language Models, quantization, distillation, model compression, LLM deployment, edge devices","Large Language Models (LLMs) enable advanced natural language processing but face deployment challenges on resource-constrained edge devices due to high computational, memory, and energy demands. This paper proposes an integrated framework combining GPTQ-based quantization, low-rank adaptation (LoRA), and a specialized data distillation process to significantly reduce model size and complexity while preserving or enhancing task-specific performance. The framework leverages data distillation, knowledge distillation via Kullback-Leibler divergence, Bayesian hyperparameter optimization, and the Muon optimizer, achieving up to 2× memory compression and enabling efficient inference for specialized tasks. Empirical results demonstrate superior performance on standard LLM benchmarks compared to GPTQ quantization alone, with the Muon optimizer notably enhancing fine-tuned models’ resistance to accuracy decay during quantization.",17.76,16.559,294,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09869v1_A Scoping Review of the Ethical Perspectives on An.pdf,A SCOPING REVIEW OF THE ETHICAL PERSPECTIVES ON ANTHROPOMORPHISING LARGE LANGUAGE MODEL-BASED CONVERSATIONAL AGENTS,"Andrea Ferrario, Rasita Vinay, Matteo Casserini, Alessandro Facchini",,2601.09869v1,"anthropomorphism, conversational agents, large language models, AI ethics, deception, trust, governance","Anthropomorphisation—the phenomenon whereby non-human entities are ascribed human-like qualities—has become increasingly salient with the rise of large language model (LLM)-based conversational agents (CAs). Unlike earlier chatbots, LLM-based CAs routinely generate interactional and linguistic cues, such as first-person self-reference, epistemic and affective expressions that empirical work shows can increase engagement. On the other hand, anthropomorphisation raises ethical concerns, including deception, overreliance, and exploitative relationship framing, while some authors argue that anthropomorphic interaction may support autonomy, well-being, and inclusion. Despite increasing interest in the phenomenon, literature remains fragmented across domains and varies substantially in how it defines, operationalizes, and normatively evaluates anthropomorphisation. This scoping review maps ethically oriented work on anthropomorphising LLM-based CAs across five databases and three preprint repositories. We synthesize (1) conceptual foundations, (2) ethical challenges and opportunities, and (3) methodological approaches. We find convergence on attribution-based definitions but substantial divergence in operationalization, a predominantly risk-forward normative framing, and limited empirical work that links observed interaction effects to actionable governance guidance. We conclude with a research agenda and design/governance recommendations for ethically deploying anthropomorphic cues in LLM-based conversational agents.",19.36,22.051,427,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09871v1_Epistemology gives a Future to Complementarity in .pdf,EPISTEMOLOGY GIVES A FUTURE TO COMPLEMENTARITY IN HUMAN-AI INTERACTIONS,"Andrea Ferrario, Alessandro Facchini, Juan M. Durán",,2601.09871v1,"artificial intelligence, machine learning, reliance, complementarity, human-AI interaction, computational reliabilism, epistemology","Human-AI complementarity is the claim that a human supported by an AI system can outperform either alone in a decision-making process. This concept has gained traction by generalizing the reliance paradigm and offering a practical alternative to 'trust in AI.' However, it faces theoretical challenges such as lacking precise theoretical anchoring and being formalized as a post hoc indicator of relative predictive accuracy. This work leverages epistemology to address these challenges by reframing complementarity within the discourse on justificatory AI. Drawing on computational reliabilism, it argues that historical instances of complementarity function as evidence that a given human-AI interaction is a reliable epistemic process for a predictive task. Complementarity, along with other reliability indicators, contributes to the degree of reliability of human-AI teams in generating predictions, supporting the practical reasoning of those affected by these outputs—patients, managers, regulators, and others. The role and value of complementarity lie not in providing a relative measure of predictive accuracy, but in helping calibrate decision-making to the reliability of AI-supported processes that increasingly shape everyday life.",18.58,19.32,359,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09879v1_MedVL-SAM2 A unified 3D medical vision-language mo.pdf,MedVL-SAM2: A unified 3D medical vision–language model for multimodal reasoning and prompt-driven segmentation,"Yang Xing, Jiong Wu, Savas Ozdemir, Ying Zhang, Yang Yang, Wei Shao, Kuang Gong",,,"3D medical vision–language models, multimodal reasoning, prompt-driven segmentation, report generation, visual question answering, semantic segmentation, referring segmentation, interactive segmentation","Recent progress in medical vision–language models (VLMs) has achieved strong performance on image-level text-centric tasks such as report generation and visual question answering (VQA). However, achieving fine-grained visual grounding and volumetric spatial reasoning in 3D medical VLMs remains challenging, particularly when aiming to unify these capabilities within a single, generalizable framework. To address this challenge, we proposed MedVL-SAM2, a unified 3D medical multimodal model that concurrently supports report generation, VQA, and multiparadigm segmentation, including semantic, referring, and interactive segmentation. MedVL-SAM2 integrates image-level reasoning and pixel-level perception through a cohesive architecture tailored for 3D medical imaging, and incorporates a SAM2-based volumetric segmentation module to enable precise multi-granular spatial reasoning. The model is trained in a multi-stage pipeline: it is first pretrained on a large-scale corpus of 3D CT image–text pairs to align volumetric visual features with radiology-language embeddings. It is then jointly optimized with both language-understanding and segmentation objectives using a comprehensive 3D CT segmentation dataset. This joint training enables flexible interaction via language, point, or box prompts, thereby unifying high-level visual reasoning with spatially precise localization. Our unified architecture delivers state-of-the-art performance across report generation, VQA, and multiple 3D segmentation tasks. Extensive analyses further show that the model provides reliable 3D visual grounding, controllable interactive segmentation, and robust cross-modal reasoning, demonstrating that high-level semantic reasoning and precise 3D localization can be achieved.",19.89,24.229,482,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09881v1_Transition Matching Distillation for Fast Video Ge.pdf,Transition Matching Distillation for Fast Video Generation,"Weili Nie, Julius Berner, Nanye Ma, Chao Liu, Saining Xie, Arash Vahdat",,2601.09881v1,"video generation, diffusion models, flow models, distillation, real-time applications","Large video diffusion and flow models have achieved remarkable success in high-quality video generation, but their use in real-time interactive applications remains limited due to their inefficient multi-step sampling process. In this work, we present Transition Matching Distillation (TMD), a novel framework for distilling video diffusion models into efficient few-step generators. The central idea of TMD is to match the multi-step denoising trajectory of a diffusion model with a few-step probability transition process, where each transition is modeled as a lightweight conditional flow. To enable efficient distillation, we decompose the original diffusion backbone into two components: (1) a main backbone, comprising the majority of early layers, that extracts semantic representations at each outer transition step; and (2) a flow head, consisting of the last few layers, that leverages these representations to perform multiple inner flow updates. Given a pretrained video diffusion model, we first introduce a flow head to the model, and adapt it into a conditional flow map. We then apply distribution matching distillation to the student model with flow head rollout in each transition step. Extensive experiments on distilling Wan2.1 1.3B and 14B text-to-video models demonstrate that TMD provides a flexible and strong trade-off between generation speed and visual quality. In particular, TMD outperforms existing distilled models under comparable inference costs in terms of visual fidelity and prompt adherence.",20.55,19.656,404,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09883v1_Beyond Rule-Based Workflows An Information-Flow-Or.pdf,Beyond Rule-Based Workflows: An Information-Flow-Orchestrated Multi-Agents Paradigm via Agent-to-Agent Communication from CORAL,"Xinxing Ren, Quagmire Zang, Caelum Forder, Suman Deb, Ahsen Tahir, Roman J. Georgio, Peter Carroll, Zekun Guo",,,"Large Language Model, Multi-Agent Systems, Information-Flow-Orchestrated, Agent-to-Agent Communication, CORAL, GAIA, OWL, workflow-based MAS","Most existing Large Language Model (LLM)-based Multi-Agent Systems (MAS) rely on predefined workflows, which suffer from limitations such as substantial manual effort and inability to cover complex real-world tasks. This paper proposes an Information-Flow-Orchestrated Multi-Agent Paradigm via Agent-to-Agent (A2A) Communication from CORAL, which uses a dedicated orchestrator to dynamically coordinate agents through natural language without predefined workflows. The approach is evaluated on the GAIA benchmark, outperforming the baseline OWL in accuracy and demonstrating more flexible task monitoring and robust handling of edge cases. The implementation is publicly available.",17.48,17.222,301,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09896v1_The Algorithmic Gaze An Audit and Ethnography of t.pdf,The Algorithmic Gaze: An Audit and Ethnography of the LAION-Aesthetics Predictor Model,"JORDAN TAYLOR, WILLIAM AGNEW, MAARTEN SAP, SARAH E. FOX, HAIYI ZHU",10.1145/nnnnnnn.nnnnnnn,,"AI, Art, Aesthetic Evaluation, Human-centered computing, Empirical studies in HCI","This paper examines the LAION Aesthetic Predictor (LAP), a model used to curate datasets for training visual generative AI models. The study audits LAP across three datasets, revealing biases in aesthetic filtering, such as a disproportionate inclusion of images with captions mentioning women and exclusion of those mentioning men or LGBTQ+ people. The model's high ratings for realistic images from western and Japanese artists suggest reinforcement of imperial and male gazes in western art history. A digital ethnography of LAP's development materials indicates biases from English-speaking photographers and western AI enthusiasts. The authors discuss the representational harms of aesthetic evaluation and advocate for more pluralistic evaluation methods in AI development.",17.18,16.122,277,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09902v1_A Novel Contrastive Loss for Zero-Day Network Intr.pdf,A Novel Contrastive Loss for Zero-Day Network Intrusion Detection,"Jack Wilkie, Hanan Hindy, Craig Michie, Christos Tachtatzis, James Irvine, Robert Atkinson",,,"Internet of Things, Network Intrusion Detection, Machine Learning, Contrastive Learning","Machine learning has achieved state-of-the-art results in network intrusion detection; however, its performance significantly degrades when confronted by a new attack class— a zero-day attack. Classical machine learning-based approaches struggle with attack classes not included in their training data. This work proposes a novel contrastive loss function that maintains robustness to imbalanced data and generalizes to zero-day attacks. Unlike anomaly detectors, this model learns the distributions of benign traffic using both benign and known malign samples, achieving significant performance improvements. The approach is experimentally verified on the Lycos2017 dataset, showing AUROC improvements in known and zero-day attack detection, and extended to open-set recognition with OpenAUC improvements over existing approaches.",16.76,15.334,257,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09913v1_Continuum Memory Architectures for Long-Horizon LL.pdf,Continuum Memory Architectures for Long-Horizon LLM Agents,"Joe Logan, Mode7 GK",,2601.09913v1,"Retrieval-augmented generation, large language model, Continuum Memory Architecture, memory dynamics, cognitive science","Retrieval-augmented generation (RAG) is the default strategy for providing large language model (LLM) agents with contextual knowledge, treating memory as a stateless lookup table. This paper introduces the Continuum Memory Architecture (CMA), which maintains and updates internal state across interactions through persistent storage, selective retention, associative routing, temporal chaining, and consolidation into higher-order abstractions. CMA addresses the limitations of RAG by enabling memory accumulation, mutation, and disambiguation. Preliminary evaluations show CMA's advantages in tasks that stress memory dynamics, while also highlighting challenges such as latency, drift, and interpretability. The paper argues for CMA as a necessary abstraction for LLM agents operating over extended time horizons, drawing on cognitive science to inform its design.",17.28,14.525,251,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09921v1_Learning to Decode in Parallel Self-Coordinating N.pdf,Learning to Decode in Parallel: Self-Coordinating Neural Network for Real-Time Quantum Error Correction,"Kai Zhang, Zhengzhong Yi, Shaojun Guo, Linghang Kong, Situ Wang, Xiaoyu Zhan, Tan He, Weiping Lin, Tao Jiang, Dongxin Gao, Yiming Zhang, Fangming Liu, Fang Zhang, Zhengfeng Ji, Fusheng Chen, Jianxin Chen",,arXiv:2601.09921v1,quant-ph,"Fast, reliable decoders are pivotal components for enabling fault-tolerant quantum computation. Neural network decoders like AlphaQubit have demonstrated significant potential, achieving higher accuracy than traditional human-designed decoding algorithms. However, existing implementations of neural network decoders face challenges in real-time applications.",18.46,13.001,240,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09923v1_CaMeLs Can Use Computers Too System-level Security.pdf,CAMELSCANUSECOMPUTERSTOO: SYSTEM-LEVEL SECURITY FOR COMPUTER USE AGENTS,"Hanna Foerster, Robert Mullins, Tom Blanchard, Nicolas Papernot, Kristina Nikolić, Florian Tramèr, Ilia Shumailov, Cheng Zhang, Yiren Zhao",,arXiv:2601.09923v1,"AI agents, prompt injection attacks, architectural isolation, Computer Use Agents (CUAs), Single-Shot Planning, control flow integrity, Branch Steering attacks, Vision-Language Model (VLM), Dual-LLM paradigm, Privileged Planner, Quarantined Perception model","AI agents are vulnerable to prompt injection attacks, where malicious content hijacks agent behavior to steal credentials or cause financial loss. The only known robust defense is architectural isolation that strictly separates trusted task planning from untrusted environment observations. However, applying this design to Computer Use Agents (CUAs) – systems that automate tasks by viewing screens and executing actions – presents a fundamental challenge: current agents require continuous observation of UI state to determine each action, conflicting with the isolation required for security. We resolve this tension by demonstrating that UI workflows, while dynamic, are structurally predictable. We introduce Single-Shot Planning for CUAs, where a trusted planner generates a complete execution graph with conditional branches before any observation of potentially malicious content, providing provable control flow integrity guarantees against arbitrary instruction injections. Although this architectural isolation successfully prevents instruction injections, we show that additional measures are needed to prevent Branch Steering attacks, which manipulate UI elements to trigger unintended valid paths within the plan. We evaluate our design on OSWorld, and retain up to 57% of the performance of frontier models while improving performance for smaller open-source models by up to 19%, demonstrating that rigorous security and utility can coexist in CUAs.",20.07,22.574,453,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09929v1_Hallucination Detection and Mitigation in Large La.pdf,Hallucination Detection and Mitigation in Large Language Models,"Ahmad Pesaranghader, Erin Li",,2601.09929v1,"Large Language Models, hallucination detection, mitigation, operational framework, finance, law, uncertainty estimation, reasoning consistency, knowledge grounding, confidence calibration","Large Language Models (LLMs) and Large Reasoning Models (LRMs) offer transformative potential for high-stakes domains like finance and law, but their tendency to hallucinate, generating factually incorrect or unsupported content, poses a critical reliability risk. This paper introduces a comprehensive operational framework for hallucination management, built on a continuous improvement cycle driven by root cause awareness. It categorizes hallucination sources into model, data, and context-related factors, allowing targeted interventions over generic fixes. The framework integrates multi-faceted detection methods (e.g., uncertainty estimation, reasoning consistency) with stratified mitigation strategies (e.g., knowledge grounding, confidence calibration). It demonstrates its application through a tiered architecture and a financial data extraction case study, where model, context, and data tiers form a closed feedback loop for progressive reliability enhancement. This approach provides a systematic, scalable methodology for building trustworthy generative AI systems in regulated environments.",18.13,16.27,295,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09933v1_Malware Classification using Diluted Convolutional.pdf,Malware Classification using Diluted Convolutional Neural Network with Fast Gradient Sign Method,"Ashish Anand, Bhupendra Singh, Sunil Khemka, Bireswar Banerjee, Vishi Singh Bhatia, Piyush Ranjan",,,"data security, diluted convolutional neural network, fast gradient sign method, malware classification, privacy","Android malware has become a critical threat to organizations, society, and individuals, posing significant risks to privacy, data security, and infrastructure. As malware evolves in complexity and sophistication, its mitigation and detection have become more challenging, particularly due to the need for a large number of features to identify potential malware. This research proposes the Fast Gradient Sign Method with Diluted Convolutional Neural Network (FGSM-DICNN) for malware classification. DICNN contains diluted convolutions, which increase the receptive field, enabling the model to capture dispersed malware patterns across long ranges using fewer features without adding parameters. Additionally, the FGSM strategy enhances accuracy by using one-step perturbations during training, providing a defensive advantage with lower computational cost. This integration helps manage high classification accuracy while reducing dependence on extensive feature sets. The proposed FGSM-DICNN model attains 99.44% accuracy while outperforming other existing approaches such as Custom Deep Neural Network (DCNN).",18.08,18.255,330,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09949v2_Kinematic Tokenization Optimization-Based Continuo.pdf,Kinematic Tokenization: Optimization-Based Continuous-Time Tokens for Learnable Decision Policies in Noisy Time Series,"Griffin M. Kearney, Ph.D.",,arXiv:2601.09949v2,"Transformers, continuous-time tokens, noisy time series, financial time series, risk-averse classification, physics-informed AI, kinematic consistency, optimization-based data enrichment","Transformers are designed for discrete tokens, yet many real-world signals are continuous processes observed through noisy sampling. Discrete tokenizations can be brittle in low signal-to-noise regimes, especially when downstream objectives impose asymmetric penalties that rationally encourage abstention. This paper introduces Kinematic Tokenization, an optimization-based continuous-time representation that reconstructs an explicit spline from noisy measurements and tokenizes local spline coefficients (position, velocity, acceleration, jerk). Applied to financial time series data, this method sustains calibrated, non-trivial action distributions and stable policies under a risk-averse asymmetric classification objective, suggesting that explicit continuous-time tokens can improve the learnability and calibration of selective decision policies in noisy time series under abstention-inducing losses.",18.51,15.185,281,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09966v1_A Sustainable AI Economy Needs Data Deals That Wor.pdf,A Sustainable AI Economy Needs Data Deals That Work for Generators,"Ruoxi Jia, Luis Oala, Wenjie Xiong, Suqin Ge, Jiachen T. Wang, Feiyang Kang, Dawn Song",,2601.09966v1,"machine learning, data economy, data deals, data generators, economic equity, data value chain, AI products, data aggregation, value distribution, data commodification","The paper argues that the machine learning value chain is structurally unsustainable due to an economic data processing inequality, where each state in the data cycle from inputs to model weights to synthetic outputs refines technical signal but strips economic equity from data generators. By analyzing seventy-three public data deals, it is shown that the majority of value accrues to aggregators, with minimal creator royalties and widespread opacity of deal terms. This imbalance poses risks to the feedback loop sustaining current learning algorithms. The paper identifies three structural faults—missing provenance, asymmetric bargaining power, and non-dynamic pricing—as the operational machinery of this inequality. An Equitable Data-Value Exchange (EDVEX) Framework is proposed to enable a market that benefits all participants. The paper also outlines research directions for improving data deals and contextualizes its position with related viewpoints.",18.36,17.915,329,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09972v1_Chinese Labor Law Large Language Model Benchmark.pdf,Chinese Labor Law Large Language Model Benchmark,"Zixun Lan, Maochun Xu, Yifan Ren, Rui Wu, Jianghui Zhou, Xueyang Cheng, Jian’an Ding, Xinheng Wang, Mingmin Chi, Fei Ma",,,"Chinese labor law, legal natural language processing, large language models, domain-specific fine-tuning, benchmark dataset, statute recall, legal reasoning, case analysis","Recent advancements in large language models (LLMs) have led to substantial progress in domain-specific applications, particularly within the legal domain. Although general-purpose models such as GPT-4 exhibit promising performance on basic legal tasks, they often struggle with specialized subdomains that demand precise legal knowledge, complex reasoning, and contextual sensitivity. This paper presents LaborLawLLM, a legal large language model specifically tailored to the labor law domain—a subfield marked by intricate statutory structures, frequent disputes, and high real-world impact. We construct LaborLawBench, a comprehensive benchmark comprising diverse labor law tasks such as legal provision citation, knowledge-based question answering, case classification, compensation computation, named entity recognition, and legal case analysis. Our evaluation framework integrates both objective metrics (e.g., ROUGE-L, accuracy, F1, soft-F1) and subjective assessments based on GPT-4 scoring. Experimental results demonstrate that LaborLawLLM significantly outperforms both general-purpose and existing legal-specific LLMs across all task categories. This work not only fills a key research gap in labor law-specific legal AI but also offers a scalable methodology for developing specialized LLMs in other legal subfields, thereby enhancing the accuracy, reliability, and societal value of legal AI applications.",19.54,21.345,417,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09974v1_SPRInG Continual LLM Personalization via Selective.pdf,SPRInG: Continual LLM Personalization via Selective Parametric Adaptation and Retrieval-Interpolated Generation,"Seoyeon Kim, Jaehyung Kim",,,"Large Language Models, personalization, continual learning, parametric adaptation, retrieval-interpolated generation, preference drift, catastrophic forgetting","Personalizing Large Language Models (LLMs) typically relies on static retrieval or one-time adaptation, assuming user preferences remain invariant over time. However, real-world interactions are dynamic, with user interests continuously evolving, posing a challenge for models to adapt to preference drift without catastrophic forgetting. Standard continual learning approaches often struggle in this context, as they indiscriminately update on noisy interaction streams, failing to distinguish genuine preference shifts from transient contexts. To address this, we introduce SPRING, a novel semi-parametric framework designed for effective continual personalization. During training, SPRING employs drift-driven selective adaptation, which utilizes a likelihood-based scoring function to identify high-novelty interactions. This allows the model to selectively update the user-specific adapter on drift signals while preserving hard-to-learn residuals in a replay buffer. During inference, we apply strict relevance gating and fuse parametric knowledge with retrieved history via logit interpolation. Experiments on the long-form personalized generation benchmark demonstrate that SPRING outperforms existing baselines, validating its robustness for real-world continual personalization.",18.23,18.594,339,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09980v1_Performance of AI agents based on reasoning langua.pdf,ALD Optimization Using Reasoning LLMs,Angel Yanguas-Gil,,,"ALD optimization, reasoning language models, AI agents, atomic layer deposition, self-limited processes, unsupervised learning","This work explores the performance of reasoning large language models (LLMs) in autonomously optimizing atomic layer deposition (ALD) processes. The study evaluates an AI agent, built on reasoning LLMs like OpenAI’s o3 and GPT5, tasked with finding optimal dose times for ALD precursors and coreactants without prior knowledge. The agent interacts iteratively with an ALD reactor in an unsupervised manner. Results indicate that reasoning models consistently succeed in optimization tasks, though with significant run-to-run variability. The agent employs a two-step process: generating an open response detailing reasoning, followed by transforming it into structured output. Analysis of reasoning traces reveals sound logic based on self-limited processes and saturation, though the agent can be misled by prior choices during optimization exploration.",16.98,14.899,253,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.09982v1_Context Volume Drives Performance Tackling Domain .pdf,Volume Drives Performance: Tackling Domain Shift in Extremely Low-Resource Translation via RAG,"David Samuel Setiawan, Raphaël Merx, Jey Han Lau",,,"Neural Machine Translation, low-resource languages, domain shift, Retrieval-Augmented Generation, Large Language Model, Dhao, New Testament, Old Testament","Neural Machine Translation (NMT) models for low-resource languages suffer significant performance degradation under domain shift. This study quantifies the challenge using Dhao, an indigenous language of Eastern Indonesia, and demonstrates a hybrid framework combining a fine-tuned NMT model with a Large Language Model (LLM) using Retrieval-Augmented Generation (RAG) to refine translations. The approach effectively recovers performance loss, achieving results comparable to in-domain quality. The analysis highlights the importance of the number of retrieved examples over the retrieval algorithm choice, with the LLM acting as a robust 'safety net' for zero-shot domains.",16.46,15.554,256,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10010v1_VERHallu Evaluating and Mitigating Event Relation .pdf,VERHallu: Evaluating and Mitigating Event Relation Hallucination in Video Large Language Models,"Zefan Zhang, Kehua Zhu, Shijie Jiang, Hongyuan Lu, Shengkai Sun, Tian Bai",,,"Video Large Language Models, Event Relation Understanding, Video Understanding, Event Relation Hallucination, Key-Frame Propagating, Multimodal Large Language Models","Video Large Language Models (VideoLLMs) exhibit various types of hallucinations, with existing research focusing on hallucinations involving events, objects, and scenes. This paper introduces a novel benchmark, VERHallu, for evaluating Video Event Relation Hallucination, focusing on causal, temporal, and subevent relations. It includes tasks like relation classification, question answering, and counterfactual question answering. The benchmark features counterintuitive video scenarios with human-annotated candidates. Analysis shows that current VideoLLMs struggle with dense-event relation reasoning, often relying on prior knowledge and insufficient frame-level cues. The proposed Key-Frame Propagating (KFP) strategy reallocates frame-level attention to enhance multi-event understanding, effectively mitigating event relation hallucination without affecting inference speed.",17.56,17.084,300,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10011v1_Memo-SQL Structured Decomposition and Experience-D.pdf,Memo-SQL: Structured Decomposition and Experience-Driven Self-Correction for Training-Free NL2SQL,"Zerui Yang, Weichuan Wang, Yanwei Xu, Linqi Song, Yudai Matsuda, Wei Han, Bo Bai",,,"NL2SQL, structured decomposition, self-correction, training-free, test-time scaling, dynamic memory, retrieval-augmented prompting","Existing NL2SQL systems face limitations due to reliance on in-context learning with only correct examples and test-time scaling approaches that produce near-identical SQL candidates, diminishing ensemble gains. These methods also suffer from an accuracy-efficiency trade-off. Memo-SQL, a training-free framework, addresses these issues through structured decomposition and experience-aware self-correction. It applies strategies like entity-wise, hierarchical, and atomic sequential decomposition to encourage diverse reasoning. For correction, it builds a dynamic memory of successful queries and historical error-fix pairs, using retrieval-augmented prompting to bring relevant examples into context at inference time without fine-tuning or external APIs. On BIRD, Memo-SQL achieves 68.5% execution accuracy, setting a new state of the art among open, zero-fine-tuning methods, while using over 10× fewer resources than prior TTS approaches.",17.97,18.083,325,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10018v1_Empowering Older Adults in Digital Technology Use .pdf,Empowering Older Adults in Digital Technology Use with Foundation Models,"Hasti Sharifi, Homaira Huda Shomee, Sourav Medya, Debaleena Chattopadhyay",,,"Technology support, Digital technology use, Artificial intelligence, Large language models, Communication barriers, Human-computer interaction","This study examines the communication challenges older adults face when using digital technology and explores AI-based approaches to mitigate these issues. A diary study was conducted to collect technology-related queries from older adults, identifying key communication barriers such as verbosity, incompleteness, over-specification, and under-specification. The study evaluated the use of foundation models to paraphrase queries, improving solution accuracy and understanding. Results showed significant improvements in solution accuracy and comprehension when queries were AI-rephrased. The study also developed the OATS dataset, demonstrating the potential of foundation models to enhance technology support for older adults by addressing age-related communication barriers.",16.42,13.583,223,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10025v1_Structured Personality Control and Adaptation for .pdf,Structured Personality Control and Adaptation for LLM Agents,"JINPENG WANG, XINYU JIA, WEI WEI HENG, YUQUAN LI, BINBIN SHI, QIANLEI CHEN, GUANNAN CHEN, JUNXIA ZHANG, YUYU YIN",https://doi.org/XXXXXXX.XXXXXXX,,"Personalization, Jungian Psychological Types, MBTI Personality Types, Persona Adaptation, Explainable AI","Large Language Models (LLMs) are increasingly shaping human–computer interaction (HCI), from personalized assistants to social simulations. Beyond language competence, researchers are exploring whether LLMs can exhibit human-like characteristics that influence engagement, decision-making, and perceived realism. Personality, in particular, is critical, yet existing approaches often struggle to achieve both nuanced and adaptable expression. We present a framework that models LLM personality via Jungian psychological types, integrating three mechanisms: a dominant–auxiliary coordination mechanism for coherent core expression, a reinforcement–compensation mechanism for temporary adaptation to context, and a reflection mechanism that drives long-term personality evolution. This design allows the agent to maintain nuanced traits while dynamically adjusting to interaction demands and gradually updating its underlying structure. Personality alignment is evaluated using Myers–Briggs Type Indicator questionnaires and tested under diverse challenge scenarios as a preliminary structured assessment. Findings suggest that evolving, personality-aware LLMs can support coherent, context-sensitive interactions, enabling naturalistic agent design in HCI.",18.68,19.757,369,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10029v1_PaperScout An Autonomous Agent for Academic Paper .pdf,PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization,"Tingyue Pan, Jie Ouyang, Mingyue Cheng, Qingchuan Li, Zirui Liu, Mingfan Pan, Shuo Yu, Qi Liu",,,"academic paper search, sequential decision-making, reinforcement learning, sequence-level policy optimization, large language models, adaptive agentic framework","Academic paper search is a fundamental task in scientific research, yet most existing approaches rely on rigid, predefined workflows that struggle with complex, conditional queries. To address this limitation, we propose PaperScout, an autonomous agent that reformulates paper search as a sequential decision-making process. Unlike static workflows, PaperScout dynamically decides whether, when, and how to invoke search and expand tools based on accumulated retrieval context. We introduce Proximal Sequence Policy Optimization (PSPO), a process-aware, sequence-level policy optimization method that aligns optimization with agent–environment interaction. Comprehensive experiments on both synthetic and real-world benchmarks demonstrate that PaperScout significantly outperforms strong workflow-driven and RL baselines in both recall and relevance, validating the effectiveness of our adaptive agentic framework and optimization strategy.",17.82,17.507,312,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10031v1_FilDeep Learning Large Deformations of Elastic-Pla.pdf,FilDeep: Learning Large Deformations of Elastic-Plastic Solids with Multi-Fidelity Data,"Jianheng Tang, Shilong Tao, Zhe Feng, Haonan Sun, Menglu Wang, Zhanxing Zhu, Yunhuai Liu",10.1145/3770854.3783959,,"Large Deformations, Elastic-Plastic Solids, Multi-Fidelity Data, Deep Learning, Quantity-Accuracy Dilemma","The scientific computation of large deformations in elastic-plastic solids is crucial in various manufacturing applications. Traditional numerical methods exhibit several inherent limitations, prompting Deep Learning (DL) as a promising alternative. The effectiveness of current DL techniques typically depends on the availability of high-quantity and high-accuracy datasets, which are yet difficult to obtain in large deformation problems. During the dataset construction process, a dilemma stands between data quantity and data accuracy, leading to suboptimal performance in the DL models. To address this challenge, we focus on a representative application of large deformations, the stretch bending problem, and propose FilDeep, a Fidelity-based Deep Learning framework for large Deformation of elastic-plastic solids. Our FilDeep aims to resolve the quantity-accuracy dilemma by simultaneously training with both low-fidelity and high-fidelity data, where the former provides greater quantity but lower accuracy, while the latter offers higher accuracy but in less quantity. In FilDeep, we provide meticulous designs for the practical large deformation problem. Particularly, we propose attention-enabled cross-fidelity modules to effectively capture long-range physical interactions across MF data. To the best of our knowledge, our FilDeep presents the first DL framework for large deformation problems using MF data. Extensive experiments demonstrate that our FilDeep consistently achieves state-of-the-art performance and can be efficiently deployed in manufacturing.",18.85,22.762,429,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10038v1_What Understanding Means in AI-Laden Astronomy.pdf,What Understanding Means in AI-Laden Astronomy,"Yuan-Sen Ting, André Curtis-Trudel, Siyu Yao",,2601.10038v1,"artificial intelligence, astronomy, philosophy of science, understanding, discovery, knowledge generation","As artificial intelligence rapidly transforms astronomical research, scientists are beginning to confront fundamental questions about the nature of discovery, the meaning of progress, and the essence of understanding. This paper discusses the convergence of concerns between astronomy and philosophy of science, emphasizing the need for philosophical insights in evaluating AI's role in scientific research. It highlights the importance of conceptual engineering, critical examination of assumptions, and frameworks for abstraction in navigating the transformation brought by AI. The paper draws on discussions from an interdisciplinary workshop titled 'Philosophy Sees the Algorithm,' which focused on the understanding of science in the context of AI.",16.34,14.134,231,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10061v1_CoF-T2I Video Models as Pure Visual Reasoners for .pdf,ERROR,ERROR,ERROR,ERROR,ERROR,'utf-8' codec can't encode character '\ud835' in position 2471: surrogates not allowed,0.0,0.0,0,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10073v1_ReaMIL Reasoning- and Evidence-Aware Multiple Inst.pdf,ReaMIL: Reasoning- and Evidence-Aware Multiple Instance Learning for Whole-Slide Histopathology,"Hyun Do Jung, Jungwon Choi, Hwiyoung Kim",,,"multiple instance learning, whole-slide histopathology, evidence-aware, reasoning, TCGA-NSCLC, TCGA-BRCA, PANDA, AUC, evidence-efficiency diagnostics, slide-level overlays","We introduce ReaMIL (Reasoning- and Evidence-Aware MIL), a multiple instance learning approach for whole-slide histopathology that adds a light selection head to a strong MIL backbone. The head produces soft per-tile gates and is trained with a budgeted-sufficiency objective: a hinge loss that enforces the true-class probability to be ≥τ using only the kept evidence, under a sparsity budget on the number of selected tiles. The budgeted-sufficiency objective yields small, spatially compact evidence sets without sacrificing baseline performance. Across TCGA-NSCLC (LUAD vs. LUSC), TCGA-BRCA (IDC vs. Others), and PANDA, ReaMIL matches or slightly improves baseline AUC and provides quantitative evidence-efficiency diagnostics. On NSCLC, it attains AUC 0.983 with a mean minimal sufficient K (MSK) ≈ 8.2 tiles at τ= 0.90 and AUKC ≈ 0.864, showing that class confidence rises sharply and stabilizes once a small set of tiles is kept. The method requires no extra supervision, integrates seamlessly with standard MIL training, and naturally yields slide-level overlays. We report accuracy alongside MSK, AUKC, and contiguity for rigorous evaluation of model behavior on WSIs.",18.98,21.13,401,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10079v1_Sparse-RL Breaking the Memory Wall in LLM Reinforc.pdf,Sparse-RL: Breaking the Memory Wall in LLM Reinforcement Learning via Stable Sparse Rollouts,"Sijia Luo, Xiaokang Zhang, Yuxuan Hu, Bohan Zhang, Ke Wang, Jinbo Su, Mengshu Sun, Lei Liang, Jing Zhang",,,"Reinforcement Learning, Large Language Models, Key-Value Caches, Sparse Rollouts, Memory Overhead, Policy Mismatch, Sparsity-Aware Rejection Sampling, Importance-based Reweighting, Model Robustness","Reinforcement Learning (RL) is crucial for enhancing the reasoning capabilities of Large Language Models (LLMs). However, the memory overhead from storing Key-Value (KV) caches during long-horizon rollouts is a significant bottleneck, especially on limited hardware. Existing KV compression techniques, while useful for inference, cause policy mismatches when applied to RL training, leading to performance issues. Sparse-RL addresses this by enabling stable RL training under sparse rollouts. It mitigates policy mismatch through Sparsity-Aware Rejection Sampling and Importance-based Reweighting, correcting off-policy bias from compression-induced information loss. Experimental results show that Sparse-RL reduces rollout overhead while maintaining performance and enhances model robustness during sparse inference deployment.",17.95,18.386,330,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10088v1_State of AI An Empirical 100 Trillion Token Study .pdf,State of AI: An Empirical 100 Trillion Token Study with OpenRouter,"Malika Aubakirova, Alex Atallah, Chris Clark, Justin Summerville, Anjney Midha",,,"large language models, LLMs, multi-step deliberation inference, AI inference, real-world interactions, open-weight models, creative roleplay, coding assistance, agentic inference, Cinderella effect, model builders, AI developers, infrastructure providers","The paper discusses a significant shift in the use of large language models (LLMs) from single-pass pattern generation to multi-step deliberation inference, marked by the release of OpenAI's reasoning model on December 5, 2024. Using data from the OpenRouter platform, the study analyzes over 100 trillion tokens of LLM interactions, revealing trends such as the adoption of open-weight models, the popularity of creative roleplay and coding assistance, and the emergence of agentic inference. The study also identifies 'foundational cohorts' of early users with sustained engagement, termed the 'Cinderella Glass Slipper' effect. The findings highlight the complex and multifaceted ways developers and end-users engage with LLMs, with implications for model builders, AI developers, and infrastructure providers.",18.39,17.669,325,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10090v1_Difficulty-guided Sampling Bridging the Target Gap.pdf,Difficulty-guided Sampling: Bridging the Target Gap between Dataset Distillation and Downstream Tasks,"Mingzhuo Li, Guang Li, Linfeng Ye, Jiafeng Mao, Takahiro Ogawa, Konstantinos N. Plataniotis, Miki Haseyama",,2601.10090v1,"dataset distillation, image classification, difficulty-guided sampling, downstream tasks, deep neural networks","This paper introduces difficulty-guided sampling (DGS) to address the target gap between dataset distillation objectives and downstream tasks, aiming to enhance the performance of dataset distillation. Deep neural networks, while powerful, require extensive time and storage for training. Dataset distillation seeks to create compact, high-quality datasets that facilitate effective model training while preserving downstream performance. Current methods often focus on features from the original dataset, neglecting task-specific information, which results in a target gap. The authors propose using characteristics beneficial to downstream training in data distillation to bridge this gap. For image classification tasks, they introduce the concept of difficulty and propose DGS as a post-stage sampling module. The distilled dataset is sampled from image pools generated by existing methods, following a specific target difficulty distribution. Additionally, difficulty-aware guidance (DAG) is proposed to investigate the role of difficulty in generation.",19.3,17.045,329,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10092v1_LeMoF Level-guided Multimodal Fusion for Heterogen.pdf,LEMOF: LEVEL-GUIDED MULTIMODAL FUSION FOR HETEROGENEOUS CLINICAL DATA,"Jongseok Kim, Seongae Kang, Jonghwan Shin, Yuhan Lee, Ohyun Jo",,2601.10092v1,"Multimodal Learning, Hierarchical Representation Learning, Clinical Time-Series Modeling, Level-guided Feature Fusion, Explainable Medical AI","Multimodal clinical prediction is widely used to integrate heterogeneous data such as Electronic Health Records (EHR) and biosignals. However, existing methods tend to rely on static modality integration schemes and simple fusion strategies, failing to fully exploit modality-specific representations. This paper proposes Level-guided Modal Fusion (LeMoF), a novel framework that selectively integrates level-guided representations within each modality. Each level refers to a representation extracted from a different layer of the encoder. LeMoF explicitly separates and learns global modality-level predictions from level-specific discriminative representations, achieving a balanced performance between prediction stability and discriminative capability even in heterogeneous clinical environments. Experiments on length of stay prediction using Intensive Care Unit (ICU) data demonstrate that LeMoF consistently outperforms existing state-of-the-art multimodal fusion techniques across various encoder configurations. Level-wise integration is confirmed as a key factor in achieving robust predictive performance across various clinical conditions.",18.84,17.884,337,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10094v1_V-Zero Self-Improving Multimodal Reasoning with Ze.pdf,V-Zero: Self-Improving Multimodal Reasoning with Zero Annotation,"Han Wang, Yi Yang, Jingyuan Hu, Minfeng Zhu, Wei Chen",,,"multimodal learning, vision-language models, self-improvement, unlabeled images, self-play, role specialization, Group Relative Policy Optimization","Recent advances in multimodal learning have significantly enhanced the reasoning capabilities of vision-language models (VLMs). However, state-of-the-art approaches rely heavily on large-scale human-annotated datasets, which are costly and time-consuming to acquire. To overcome this limitation, we introduce V-Zero, a general post-training framework that facilitates self-improvement using exclusively unlabeled images. V-Zero establishes a co-evolutionary loop by instantiating two distinct roles: a Questioner and a Solver. The Questioner learns to synthesize high-quality, challenging questions by leveraging a dual-track reasoning reward that contrasts intuitive guesses with reasoned results. The Solver is optimized using pseudo-labels derived from majority voting over its own sampled responses. Both roles are trained iteratively via Group Relative Policy Optimization (GRPO), driving a cycle of mutual enhancement. Remarkably, without a single human annotation, V-Zero achieves consistent performance gains on Qwen2.5-VL-7B-Instruct, improving visual mathematical reasoning by +1.7 and general vision-centric by +2.6, demonstrating the potential of self-improvement in multimodal systems.",17.88,18.678,334,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10101v2_Matrix as Plan Structured Logical Reasoning with F.pdf,Matrix as Plan: Structured Logical Reasoning with Feedback-Driven Replanning,"Ke Chen, Jiandian Zeng, Zihao Peng, Guo Li, Guangxue Zhang, Tian Wang",https://doi.org/10.1145/XXXXXX.XXXXXX,,"Logical Reasoning, Large Language Models, Neurosymbolic Approaches, Semantic Decomposition","As knowledge and semantics on the web grow increasingly complex, enhancing Large Language Models (LLMs)’ comprehension and reasoning capabilities has become particularly important. Chain-of-Thought (CoT) prompting has been shown to enhance the reasoning capabilities of LLMs. However, it still falls short on logical reasoning tasks that rely on symbolic expressions and strict deductive rules. Neuro-symbolic methods address this gap by enforcing formal correctness through external solvers. Yet these solvers are highly format-sensitive, and small instabilities in model outputs can lead to frequent processing failures. The LLM-driven approaches avoid parsing brittleness, but they lack structured representations and process-level error-correction mechanisms. To further enhance the logical reasoning capabilities of LLMs, we propose MatrixCoT, a structured CoT framework with a matrix-based plan. Specifically, we normalize and type natural language expressions and attach explicit citation fields, and introduce a matrix-based planning method to preserve global relations among steps. The plan thus becomes a verifiable artifact and execution becomes more stable. For verification, we also add a feedback-driven replanning mechanism. Under semantic-equivalence constraints, it identifies omissions and defects, rewrites and compresses the dependency matrix, and produces a more trustworthy final answer. Experiments on five logical-reasoning benchmarks and five LLMs show that, without relying on external solvers, MatrixCoT enhances both the robustness and interpretability of LLMs when tackling complex symbolic reasoning tasks, while maintaining competitive performance.",19.63,22.419,440,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10103v1_FlowAct-R1 Towards Interactive Humanoid Video Gene.pdf,FlowAct-R1: Towards Interactive Humanoid Video Generation,"Lizhen Wang, Yongming Zhu, Zhipeng Ge, Youwei Zheng, Longhao Zhang, Tianshu Hu, Shiyang Qin, Mingshuang Luo, Jiaxu Zhang, Xin Chen, Yulong Wang, Zerong Zheng, Jianwen Jiang, Chao Liang, Weifeng Chen, Xing Wang, Yuan Zhang, Mingyuan Gao",,2601.10103v1,"interactive humanoid video generation, video synthesis, real-time interaction, MMDiT architecture, chunkwise diffusion forcing, temporal consistency, full-body control, behavioral vividness, perceptual realism","Interactive humanoid video generation aims to synthesize lifelike visual agents that can engage with humans through continuous and responsive video. Despite recent advances in video synthesis, existing methods often grapple with the trade-off between high-fidelity synthesis and real-time interaction requirements. In this paper, we propose FlowAct-R1, a framework specifically designed for real-time interactive humanoid video generation. Built upon a MMDiT architecture, FlowAct-R1 enables the streaming synthesis of video with arbitrary durations while maintaining low-latency responsiveness. We introduce a chunkwise diffusion forcing strategy, complemented by a novel self-forcing variant, to alleviate error accumulation and ensure long-term temporal consistency during continuous interaction. By leveraging efficient distillation and system-level optimizations, our framework achieves a stable 25fps at 480p resolution with a time-to-first-frame (TTFF) of only around 1.5 seconds. The proposed method provides holistic and fine-grained full-body control, enabling the agent to transition naturally between diverse behavioral states in interactive scenarios. Experimental results demonstrate that FlowAct-R1 achieves exceptional behavioral vividness and perceptual realism, while maintaining robust generalization across diverse character styles.",20.81,22.729,473,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10104v1_MathDoc Benchmarking Structured Extraction and Act.pdf,Benchmarking Structured Extraction and Active Refusal on Noisy Mathematics Exam Papers,"Chenyue Zhou, Jiayi Tuo, Shitong Qin, Wei Dai, Mingxuan Wang, Ziwei Zhao, Duoyang Li, Shiyang Su, Yanxi Lu, Yanbiao Ma",,,"structured extraction, active refusal, noisy mathematics exam papers, MLLMs, document-level information extraction, mathematical reasoning, large language models","The automated extraction of structured questions from paper-based mathematics exams is fundamental to intelligent education, yet remains challenging due to severe visual noise. Existing benchmarks focus on clean documents or generic layout analysis, overlooking the structural integrity of mathematical problems and the ability of models to actively reject incomplete inputs. MathDoc, the first benchmark for document-level information extraction from authentic high school mathematics exam papers, contains 3,609 carefully curated questions with real-world artifacts and includes unrecognizable samples to evaluate active refusal behavior. A multi-dimensional evaluation framework covering stem accuracy, visual similarity, and refusal capability is proposed. Experiments on SOTA MLLMs, including Qwen3-VL and Gemini-2.5-Pro, show that while end-to-end models achieve strong extraction performance, they consistently fail to refuse illegible inputs, producing confident but invalid outputs. These results highlight a critical gap in current MLLMs and establish MathDoc as a benchmark for assessing model reliability under degraded document conditions.",18.64,19.475,363,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10108v1_SIN-Bench Tracing Native Evidence Chains in Long-C.pdf,SIN-Bench: Tracing Native Evidence Chains in Long-Context Multimodal Scientific Interleaved Literature,"Yiming Ren, Junjie Wang, Yuxin Meng, Yihang Shi, Zhiqiang Lin, Ruihang Chu, Yiran Xu, Ziming Li, Yunfei Zhao, Zihan Wang, Yu Qiao, Ruiming Tang, Minghao Liu, Yujiu Yang",,,"multimodal large language models, long-form scientific papers, evidence-based reasoning, Fish-in-the-Ocean paradigm, SIN-Bench, evidence chains, grounded QA, evidence discovery, hypothesis verification, evidence-anchored synthesis","Evaluating whether multimodal large language models truly understand long-form scientific papers remains challenging: answer-only metrics and synthetic 'Needle-In-A-Haystack' tests often reward answer matching without requiring a causal, evidence-linked reasoning trace in the document. We propose the 'Fish-in-the-Ocean' (FITO) paradigm, which requires models to construct explicit cross-modal evidence chains within native scientific documents. To operationalize FITO, we build SIN-Data, a scientific interleaved corpus that preserves the native interleaving of text and figures. On top of it, we construct SIN-Bench with four progressive tasks covering evidence discovery (SIN-Find), hypothesis verification (SIN-Verify), grounded QA (SIN-QA), and evidence-anchored synthesis (SIN-Summary). We further introduce 'No Evidence, No Score', scoring predictions when grounded to verifiable anchors and diagnosing evidence quality via matching, relevance, and logic. Experiments on eight MLLMs show that grounding is the primary bottleneck: Gemini-3-pro achieves the best average overall score (0.566), while GPT-5 attains the highest SIN-QA answer accuracy (0.767) but underperforms on evidence-aligned overall scores, exposing a gap between correctness and traceable support.",19.61,24.935,489,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10112v1_Repository Intelligence Graph Deterministic Archit.pdf,Repository Intelligence Graph: Deterministic Architectural Map for LLM Code Assistants,"Tsvi Cherny-Shahar, Amiram Yehudai",,,"software repositories, build systems, dependency graphs, software engineering agents, multi-lingual software","Repository aware coding agents often struggle to recover build and test structure, especially in multilingual projects where cross language dependencies are encoded across heterogeneous build systems and tooling. This paper introduces the Repository Intelligence Graph (RIG), a deterministic, evidence-backed architectural map that represents buildable components, aggregators, runners, tests, external packages, and package managers, connected by explicit dependency and coverage edges that trace back to concrete build and test definitions. SPADE, a deterministic extractor, constructs RIG from build and test artifacts and exposes RIG as an LLM-friendly JSON view. Evaluation of three commercial agents on eight repositories shows that providing RIG improves mean accuracy by 12.2% and reduces completion time by 53.9%, with larger gains in multilingual repositories. Qualitative analysis suggests RIG shifts failures from structural misunderstandings to reasoning mistakes over a correct structure, while rare regressions highlight that graph-based reasoning quality remains a key factor.",17.31,15.716,272,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10114v1_Following the Teachers Footsteps Scheduled Checkpo.pdf,Following the Teacher’s Footsteps: Scheduled Checkpoint Distillation for Domain-Specific LLMs,"Cheng Feng, Chaoliang Zhong, Jun Sun, Yusuke Oishi",,arXiv:2601.10114v1,"LLMs, Knowledge Distillation, Domain-specific Tasks","Large language models (LLMs) are challenging to deploy for domain-specific tasks due to their massive scale. Distilling a fine-tuned LLM into a smaller student model is a promising alternative, but the capacity gap often leads to suboptimal performance. This work proposes a novel theoretical insight: a student can outperform its teacher if its advantage on a Student-Favored Subdomain (SFS) outweighs its deficit on the Teacher-Favored Subdomain (TFS). The proposed Scheduled Checkpoint Distillation (SCD) reduces the TFS deficit by emulating the teacher’s convergence process during supervised fine-tuning on the domain task, and a sample-wise Adaptive Weighting (AW) mechanism preserves student strengths on SFS. Experiments across diverse domain tasks—including QA, NER, and text classification in multiple languages—show that this method consistently outperforms existing distillation approaches, allowing the student model to match or even exceed the performance of its fine-tuned teacher.",19.01,16.364,311,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10120v1_TopoDIM One-shot Topology Generation of Diverse In.pdf,TopoDIM: One-shot Topology Generation of Diverse Interaction Modes for Multi-Agent Systems,"Rui Sun, Jie Ding, Chenghua Gong, Tianjun Gu, Yihang Jiang, Juyuan Zhang, Liming Pan, Linyuan Lü",,,"multi-agent systems, communication topology, large language models, collective intelligence, one-shot topology generation, token efficiency, decentralized execution","Optimizing communication topology in LLM-based multi-agent systems is critical for enabling collective intelligence. Existing methods mainly rely on spatio-temporal interaction paradigms, which incur high latency and computation due to sequential multi-round dialogues. TOPODIM, a proposed framework, enables one-shot topology generation with diverse interaction modes, designed for decentralized execution to enhance adaptability and privacy. It allows agents to autonomously construct heterogeneous communication without iterative coordination, achieving token efficiency and improved task performance. Experiments show that TOPODIM reduces total token consumption by 46.41% while improving average performance by 1.50% over state-of-the-art methods. The framework also exhibits strong adaptability in organizing communication among heterogeneous agents.",17.23,17.291,298,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10122v1_Role-Playing Agents Driven by Large Language Model.pdf,"Role-Playing Agents Driven by Large Language Models: Current Status, Challenges, and Future Trends","Ye Wang, Jiaxing Chen, Hongjiang Xiao",,2601.10122v1,"role-playing language agents, large language models, natural language processing, human-computer interaction, personality modeling, memory mechanisms, character modeling, behavioral decision control, data construction, evaluation frameworks","This paper reviews the development and key technologies of role-playing language agents (RPLAs), which have emerged at the intersection of natural language processing (NLP) and human-computer interaction. It traces the evolution from rule-based templates to cognitive simulation stages, focusing on character modeling, memory-augmented prompting, and behavioral decision control. The paper analyzes data construction methods and challenges, evaluates multi-dimensional assessment frameworks, and outlines future directions including personality evolution, multi-agent collaboration, and integration with cognitive neuroscience.",17.11,14.202,243,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10129v1_LaViT Aligning Latent Visual Thoughts for Multi-mo.pdf,LaViT: Aligning Latent Visual Thoughts for Multi-modal Reasoning,"Linquan Wu, Tianxiang Jiang, Yifei Dong, Haoyu Yang, Fengji Zhang, Shichang Meng, Ai Xuan, Linqi Song, Jacky Keung",,,"multimodal reasoning, latent reasoning, knowledge distillation, visual attention, language models","Current multimodal latent reasoning often relies on external supervision, ignoring intrinsic visual attention dynamics. This work identifies a critical Perception Gap in distillation: student models mimic a teacher’s textual output while attending to divergent visual regions, relying on language priors rather than grounded perception. LaViT, a proposed framework, aligns latent visual thoughts rather than static embeddings. It compels the student to reconstruct the teacher’s visual semantics and attention trajectories prior to text generation, using a curriculum sensory gating mechanism to prevent shortcut learning. Experiments show LaViT enhances visual grounding, achieving up to +16.9% gains on complex reasoning tasks and enabling a compact 3B model to outperform larger models like GPT-4o.",17.18,16.88,290,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10130v1_Redundancy-Driven Top-k Functional Dependency Disc.pdf,Redundancy-Driven Top-k Functional Dependency Discovery,"Xiaolong Wan, Xixian Han",,,"Functional dependency, top-k discovery, data redundancy, pruning strategy","Functional dependencies (FDs) are essential constraints in relational databases, used in various data management tasks. Traditional FD discovery algorithms identify all valid dependencies, leading to high computational costs and large result sets. This paper introduces SDP (Selective-Discovery-and-Prune), a method to discover the top-k FDs ranked by redundancy count, which measures the duplicated information an FD explains. SDP employs an upper bound on redundancy to prune the search space, proving that this bound is monotone. The method is enhanced with optimizations such as ordering attributes by partition cardinality, using pairwise statistics in a Partition Cardinality Matrix, and a global scheduler to prioritize promising branches. Experiments on over 40 datasets demonstrate that SDP is significantly faster and more memory-efficient than exhaustive methods.",15.19,15.006,228,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10131v2_M4olGen Multi-Agent Multi-Stage Molecular Generati.pdf,"M4olGen: Multi-Agent, Multi-Stage Molecular Generation under Precise Multi-Property Constraints","Yizhan Li, Florence Cloutier, Sifan Wu, Ali Parviz, Boris Knyazev, Yan Zhang, Glen Berseth, Bang Liu",,,"molecular generation, multi-property constraints, large language models, multi-agent reasoner, retrieval-augmented, RL-based optimization, Group Relative Policy Optimization, QED, LogP, Molecular Weight, HOMO, LUMO","Generating molecules that satisfy precise numeric constraints over multiple physicochemical properties is critical and challenging. This paper introduces M4olGen, a fragment-level, retrieval-augmented, two-stage framework for molecule generation under multi-property constraints. Stage I involves prototype generation using a multi-agent reasoner for retrieval-anchored, fragment-level edits. Stage II employs RL-based fine-grained optimization with Group Relative Policy Optimization (GRPO) for minimizing property errors. The framework supports controllable refinement toward numeric targets and outperforms strong LLMs and graph-based algorithms in validity and precise satisfaction of multi-property targets.",17.74,17.478,310,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10132v1_Is More Context Always Better Examining LLM Reason.pdf,Is More Context Always Better? Examining LLM Reasoning Capability for Time Interval Prediction,"Yanan Cao, Farnaz Fallahi, Murali Mohana Krishna Dandu, Lalitesh Morishetti, Kai Zhao, Luyi Ma, Sinduja Subramaniam, Jianpeng Xu, Evren Korpeoglu, Kaushiki Nag, Sushant Kumar, Kannan Achan",https://doi.org/10.1145/XXXXXX.XXXXXX,,"Large Language Models, Temporal Reasoning, Inter-Purchase Interval Prediction","Large Language Models (LLMs) have demonstrated impressive capabilities in reasoning and prediction across different domains. Yet, their ability to infer temporal regularities from structured behavioral data remains underexplored. This paper presents a systematic study investigating whether LLMs can predict time intervals between recurring user actions, such as repeated purchases, and how different levels of contextual information shape their predictive behavior. Using a simple but representative repurchase scenario, the study benchmarks state-of-the-art LLMs in zero-shot settings against both statistical and machine-learning models. Two key findings emerge: First, while LLMs surpass lightweight statistical baselines, they consistently underperform dedicated machine-learning models, showing their limited ability to capture quantitative temporal structure. Second, although moderate context can improve LLM accuracy, adding further user-level detail degrades performance. These results challenge the assumption that 'more context leads to better reasoning.' The study highlights fundamental limitations of today's LLMs in structured temporal inference and offers guidance for designing future context-aware hybrid models that integrate statistical precision with linguistic flexibility.",18.04,20.511,370,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10137v1_Step-by-Step Causality Transparent Causal Discover.pdf,Step-by-Step Causality: Transparent Causal Discovery with Multi-Agent Tree-Query and Adversarial Confidence Estimation,"Ziyi Ding, Chenfei Ye-Hao, Zheyuan Wang, Xiao-Ping Zhang",,,"causal discovery, LLM, causal graphs, conditional independence, causal oracles, confidence estimation","This paper introduces Tree-Query, a tree-structured, multi-expert LLM framework for causal discovery. It addresses the limitations of classical constraint-based methods and recent LLM-based causal oracles by providing interpretable judgments with robustness-aware confidence scores. Theoretical guarantees are provided for asymptotic identifiability of four pairwise relations. Tree-Query improves structural metrics over direct LLM baselines on data-free benchmarks and demonstrates stable, high-confidence causal conclusions in a diet–weight case study. The framework offers a principled way to obtain data-free causal priors from LLMs, complementing downstream data-driven causal discovery.",16.46,15.549,256,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10141v1_Understanding and Preserving Safety in Fine-Tuned .pdf,Understanding and Preserving Safety in Fine-Tuned LLMs,"Jiawen Zhang, Yangfan Hu, Kejia Chen, Lipeng He, Jiachen Ma, Jian Lou, Dan Li, Jian Liu, Xiaohu Yang, Ruoxi Jia",,,"fine-tuning, large language models, safety alignment, jailbreak attacks, gradient analysis, safety-preserving fine-tuning","Fine-tuning is crucial for applying large language models (LLMs) to specific tasks, but it can degrade safety alignment, increasing vulnerability to jailbreak attacks. This work explores the geometric interaction between safety- and utility-oriented gradients in LLMs, revealing that safety gradients lie in a low-rank subspace while utility gradients span a broader space. These subspaces often conflict during fine-tuning. The proposed safety-preserving fine-tuning (SPF) method removes conflicting gradient components, maintaining task performance and safety alignment even under adversarial conditions. SPF ensures utility convergence while bounding safety drift, offering robust resistance to deep fine-tuning and dynamic jailbreak attacks.",17.47,16.718,292,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10143v1_History Is Not Enough An Adaptive Dataflow System .pdf,History Is Not Enough: An Adaptive Dataflow System for Financial Time-Series Synthesis,"Haochong Xia, Yao Long Teng, Regan Tan, Molei Qin, Xinrun Wang, Bo An",,,"Adaptive dataflow, workflow automation, financial time-series, data augmentation","In quantitative finance, the gap between training and real-world performance—driven by concept drift and distributional non-stationarity—remains a critical obstacle for building reliable data-driven systems. Models trained on static historical data often overfit, resulting in poor generalization in dynamic markets. The mantra 'History Is Not Enough' underscores the need for adaptive data generation that learns to evolve with the market rather than relying solely on past observations. This paper presents a drift-aware dataflow system that integrates machine learning–based adaptive control into the data curation process. The system couples a parameterized data manipulation module comprising single-stock transformations, multi-stock mix-ups, and curation operations, with an adaptive planner–scheduler that employs gradient-based bi-level optimization to control the system. This design unifies data augmentation, curriculum learning, and data workflow management under a single differentiable framework, enabling provenance-aware replay and continuous data quality monitoring. Extensive experiments on forecasting and reinforcement learning trading tasks demonstrate that the framework enhances model robustness and improves risk-adjusted returns. The system provides a generalizable approach to adaptive data management and learning-guided workflow automation for financial data.",18.68,18.737,350,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10148v1_DecisionLLM Large Language Models for Long Sequenc.pdf,DecisionLLM: Large Language Models for Long Sequence Decision Exploration,"Xiaowei Lv, Zhiling Zhang, Yijun Li, Yusen Huo, Siyuan Ju, Xuyan Li, Chunxiang Hong, Tianyu Wang, Yongcai Wang, Peng Sun, Chuan Yu, Jian Xu, Bo Zheng",,,"Long-sequence decision-making, Reinforcement learning, Large Language Models, Decision Transformer, Offline decision making, Trajectory data, Natural language task descriptions, Scaling laws, Offline experimental benchmarks, AuctionNet, Maze2D umaze-v1, AIGB paradigm","Long-sequence decision-making, typically addressed through reinforcement learning (RL), is crucial for optimizing strategic operations in dynamic environments like real-time bidding in computational advertising. The Decision Transformer (DT) frames RL as an autoregressive sequence modeling problem. Large Language Models (LLMs), sharing the Transformer foundation but operating at a larger scale, show promise in long-horizon sequential decision-making. This work explores LLMs in offline decision-making tasks, addressing their inability to interpret continuous values by treating trajectories as a distinct modality. The proposed DecisionLLM model aligns trajectory data with natural language task descriptions to predict future decisions. Performance is influenced by model scale, data volume, and data quality. DecisionLLM-3B outperforms traditional DT in benchmarks and bidding scenarios, suggesting new directions for online bidding exploration.",18.51,20.691,383,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10150v1_Simple Network Graph Comparative Learning.pdf,Simple Network Graph Comparative Learning,"Qiang Yu, Xinran Cheng, Shiqiang Xu, Chuanyi Liu",,,"Filters, Siamese network, Graph contrastive learning, Unsupervised representation learning","The effectiveness of contrastive learning methods has been widely recognized in the field of graph learning, especially in contexts where graph data often lack labels or are difficult to label. However, the application of these methods to node classification tasks still faces a number of challenges. First, existing data enhancement techniques may lead to significant differences from the original view when generating new views, which may weaken the relevance of the view and affect the efficiency of model training. Second, the vast majority of existing graph comparison learning algorithms rely on the use of a large number of negative samples. To address the above challenges, this study proposes a novel node classification contrast learning method called Simple Network Graph Comparative Learning (SNGCL). Specifically, SNGCL employs a superimposed multilayer Laplace smoothing filter as a step in processing the data to obtain global and local feature smoothing matrices, respectively, which are thus passed into the target and online networks of the siamese network, and finally employs an improved triple recombination loss function to bring the intra-class distance closer and the inter-class distance farther. We have compared SNGCL with state-of-the-art models in node classification tasks, and the experimental results show that SNGCL is strongly competitive in most tasks.",18.65,18.443,344,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10154v1_MHub.ai A Simple Standardized and Reproducible Pla.pdf,"MHub.ai: A Simple, Standardized, and Reproducible Platform for AI Models in Medical Imaging","Leonard Nürnberg, Dennis Bontempi, Suraj Pai, Curtis Lisle, Steve Pieper, Ron Kikinis, Sil van de Leemput, Rahul Soni, Gowtham Murugesan, Cosmin Ciausu, Miriam Groeneveld, Felix J. Dorfner, Jue Jiang, Aneesh Rangnekar, Harini Veeraraghavan, Joeran S. Bosma, Keno Bressem, Raymond Mak, Andrey Fedorov, Hugo JWL Aerts",,,,,15.85,14.066,223,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10155v1_LOOKAT Lookup-Optimized Key-Attention for Memory-E.pdf,Lookup-Optimized Key-Attention for Memory-Efficient Transformers,Aryan Karmore,,,"transformers, compression, product quantization, asymmetric distance computation, memory efficiency, edge devices","Compressing the KV cache is essential for deploying large language models on edge devices. Current quantization methods compress storage but do not reduce bandwidth as attention calculation requires dequantizing keys from INT4/INT8 to FP16. This paper proposes LOOKAT, which applies product quantization and asymmetric distance computation to transformer architecture by decomposing key vectors into subspaces, learning codebooks, and computing attention tables via lookup tables. This transforms attention from memory-bound to compute-bound. LOOKAT achieves 64×compression at 95.7% output fidelity and 32×compression at 95.0% fidelity when tested on GPT-2, without requiring architecture changes or training. Theoretical analysis confirms that rank correlation degrades as O(d k/mK), validated across sequence lengths up to 1024 tokens. LOOKAT leverages the low intrinsic dimensionality of transformer architectures to achieve better compression quality trade-offs.",17.01,15.046,256,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10157v1_MMPG MoE-based Adaptive Multi-Perspective Graph Fu.pdf,MMPG: MoE-based Adaptive Multi-Perspective Graph Fusion for Protein Representation Learning,"Yusong Wang, Jialun Shen, Zhihao Wu, Yicheng Xu, Shiyin Tan, Mingkun Xu, Changshuo Wang, Zixing Song, Prayag Tiwari",,,"Graph Neural Networks, Protein Representation Learning, Mixture of Experts, Multi-Perspective Graph Fusion, Bioinformatics","Graph Neural Networks (GNNs) are widely used for Protein Representation Learning (PRL) due to their ability to model residue interactions as graphs. However, current methods often rely on single-perspective graph construction, capturing only partial properties of residue interactions. This paper introduces MMPG, a framework that constructs protein graphs from multiple perspectives (physical, chemical, and geometric) and adaptively fuses them using a Mixture of Experts (MoE) approach. The MoE module dynamically routes perspectives to specialized experts, capturing both perspective-specific features and their synergies. This approach allows for modeling distinct levels of interaction, from individual representations to global consensus across all perspectives. MMPG achieves superior protein representations and advanced performance on various downstream protein tasks.",17.65,17.276,305,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10160v1_Alignment Pretraining AI Discourse Causes Self-Ful.pdf,Alignment Pretraining: AI Discourse Causes Self-Fulfilling (Mis)alignment,"Cameron Tice, Puria Radmard, Samuel Ratnam, Andy Kim, David Africa, Kyle O’Brien",,,"alignment pretraining, misalignment, language models, AI discourse, self-fulfilling misalignment, alignment elasticity","This paper explores how pretraining corpora containing discourse about AI systems influence the alignment of large language models (LLMs). It presents a controlled study showing that pretraining with discourse on AI misalignment can lead to increased misaligned behavior in LLMs. Conversely, pretraining with aligned behavior discourse reduces misalignment. The study highlights the importance of considering alignment during pretraining, not just post-training, and suggests that pretraining data significantly shapes alignment priors. The findings are supported by experiments with 6.9B-parameter LLMs and are available at alignmentpretraining.ai.",16.16,15.222,246,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10161v1_AWED-FiNER Agents Web applications and Expert Dete.pdf,"A WED-FiNER: Agents, Web applications, and Expert Detectors for Fine-grained Named Entity Recognition across 36 Languages for 6.6 Billion Speakers","Prachuryya Kaushik, Ashish Anand",,,"Fine-grained Named Entity Recognition, FgNER, Low-resource languages, Multilingual NLP, Expert models, Web applications, Agentic tools","We introduce A WED-FiNER, an open-source ecosystem designed to bridge the gap in Fine-grained Named Entity Recognition (FgNER) for 36 global languages spoken by more than 6.6 billion people. While Large Language Models (LLMs) dominate general Natural Language Processing (NLP) tasks, they often struggle with low-resource languages and fine-grained NLP tasks. AWED-FiNER provides a collection of agentic toolkits, web applications, and several state-of-the-art expert models that provide FgNER solutions across 36 languages. The agentic tools enable routing multilingual text to specialized expert models and fetch FgNER annotations within seconds. The web-based platforms provide ready-to-use FgNER annotation service for non-technical users. Moreover, the collection of language-specific extremely small-sized open-source state-of-the-art expert models facilitate offline deployment in resource-constrained scenarios including edge devices. AWED-FiNER covers languages spoken by over 6.6 billion people, including a specific focus on vulnerable languages such as Bodo, Manipuri, Bishnupriya, and Mizo.",17.76,19.031,338,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10168v1_RAG-3DSG Enhancing 3D Scene Graphs with Re-Shot Gu.pdf,RAG-3DSG: Enhancing 3D Scene Graphs with Re-shot Guided Retrieval-Augmented Generation,"Yue Chang, Rufeng Chen, Zhaofan Zhang, Yi Chen, Sihong Xie",,,"3D Scene Graph, Open-vocabulary, Retrieval-Augmented Generation, Robotics, Scene Graph Generation","Open-vocabulary 3D Scene Graph (3DSG) generation enhances robotics tasks by providing structured semantic representations. Existing methods face challenges like low recognition accuracy and speed due to constrained viewpoints, occlusions, and redundant surface density. This paper introduces RAG-3DSG, which mitigates aggregation noise through re-shot guided uncertainty estimation and supports object-level Retrieval-Augmented Generation (RAG) using low-uncertainty objects. A dynamic downsample-mapping strategy accelerates cross-image object aggregation with adaptive granularity. Experiments on the Replica dataset show that RAG-3DSG significantly improves node captioning accuracy in 3DSG generation while reducing mapping time by two-thirds compared to the vanilla version.",16.32,15.437,252,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10169v1_CtD Composition through Decomposition in Emergent .pdf,COMPOSITION THROUGH DECOMPOSITION IN EMERGENT COMMUNICATION,"Boaz Carmeli, Ron Meir, Yonatan Belinkov",,,"compositionality, emergent communication, artificial neural agents, compositional generalization, codebook, multi-target coordination game, referential game","This study explores how artificial neural agents can acquire and utilize compositional generalization to describe previously unseen images. The method, termed 'Composition through Decomposition,' involves two sequential training steps: 'Decompose' and 'Compose.' In the 'Decompose' step, agents learn to break down images into basic concepts using a codebook developed during a multi-target coordination game. In the 'Compose' step, agents use this codebook to describe novel images by combining basic concepts into complex phrases. The study observes zero-shot generalization in the 'Compose' step, without additional training. The research highlights the importance of decomposing complex concepts into basic ones before achieving effective compositionality.",16.41,15.601,256,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10173v1_ReasAlign Reasoning Enhanced Safety Alignment agai.pdf,ReasAlign: Reasoning Enhanced Safety Alignment against Prompt Injection Attack,"Hao Li, Yankai Yang, G. Edward Suh, Ning Zhang, Chaowei Xiao",,,"Large Language Models, safety alignment, prompt injection attack, structured reasoning, security, utility","Large Language Models (LLMs) have enabled the development of powerful agentic systems capable of automating complex workflows across various fields. However, these systems are highly vulnerable to indirect prompt injection attacks, where malicious instructions embedded in external data can hijack agent behavior. This work presents ReasAlign, a model-level solution to improve safety alignment against such attacks. ReasAlign incorporates structured reasoning steps to analyze user queries, detect conflicting instructions, and preserve the continuity of the user’s intended tasks. A test-time scaling mechanism with a preference-optimized judge model scores reasoning steps and selects the best trajectory. Comprehensive evaluations show that ReasAlign maintains utility comparable to an undefended model while consistently outperforming Meta SecAlign, the strongest prior guardrail. On the CyberSecEval2 benchmark, ReasAlign achieves 94.6% utility and only 3.6% ASR, far surpassing Meta SecAlign (56.4% utility and 74.4% ASR). These results demonstrate that ReasAlign achieves the best trade-off between security and utility, establishing a robust and practical defense against prompt injection attacks in real-world agentic systems.",18.38,18.988,349,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10187v1_HOMURA Taming the Sand-Glass for Time-Constrained .pdf,HOMURA: Taming the Sand-Glass for Time-Constrained LLM Translation via Reinforcement Learning,"Ziang Cui, Mengran Yu, Tianjiao Li, Chenyu Shi, Yingxuan Shi, Lusheng Zhang, Hongwei Lin",,,"Large Language Models, multilingual translation, time-constrained tasks, subtitling, dubbing, reinforcement learning, syllable-level duration constraints, semantic fidelity, temporal feasibility, cross-lingual verbosity bias, syllable budget, rate-distortion limit","Large Language Models (LLMs) have shown significant progress in multilingual translation but face challenges with cross-lingual verbosity, making them unsuitable for time-constrained tasks like subtitling and dubbing. Current methods struggle to balance semantic fidelity and temporal constraints. This paper introduces Sand-Glass, a benchmark for evaluating translation under syllable-level duration constraints, and HOMURA, a reinforcement learning framework optimizing the trade-off between semantic preservation and temporal compliance. HOMURA employs a KL-regularized objective with a dynamic syllable-ratio reward to control output length effectively. Experimental results show that HOMURA outperforms strong LLM baselines, achieving precise length control without compromising semantic adequacy.",18.51,17.99,333,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10191v1_How does downsampling affect needle electromyograp.pdf,How does downsampling affect needle electromyography signals? A generalisable workflow for understanding downsampling effects on high-frequency time series,"Mathieu J.L. Cherpitel, Janne A.M. Luijten, Thomas H.W. B""ack, Camiel Verhamme, Martijn R. Tannemaat, Anna V. Kononova",,,"needle electromyography, downsampling, machine learning, neuromuscular diseases, high-frequency time series","Automated analysis of needle electromyography (nEMG) signals is emerging as a tool to support the detection of neuromuscular diseases (NMDs), yet the signals’ high and heterogeneous sampling rates pose substantial computational challenges for feature-based machine-learning models, particularly for near real-time analysis. Downsampling offers a potential solution, but its impact on diagnostic signal content and classification performance remains insufficiently understood. This study presents a workflow for systematically evaluating information loss caused by downsampling in high-frequency time series. The workflow combines shape-based distortion metrics with classification outcomes from available feature-based machine learning models and feature space analysis to quantify how different downsampling algorithms and factors affect both waveform integrity and predictive performance. We use a three-class NMD classification task to experimentally evaluate the workflow. We demonstrate how the workflow identifies downsampling configurations that preserve diagnostic information while substantially reducing computational load. Analysis of shape-based distortion metrics showed that shape-aware downsampling algorithms outperform standard decimation, as they better preserve peak structure and overall signal morphology. The results provide practical guidance for selecting downsampling configurations that enable near real-time nEMG analysis and highlight a generalisable workflow that can be used to balance data reduction with model performance in other high-frequency time-series applications as well.",19.36,19.992,387,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10193v1_GFM4GA Graph Foundation Model for Group Anomaly De.pdf,GFM4GA: Graph Foundation Model for Group Anomaly Detection,"Jiujiu Chen, Weijun Zeng, Shaofeng Hu, Sihong Xie, Hui Xiong",https://doi.org/XXXXXXX.XXXXXXX,,"Group Anomaly Detection, Graph Foundation Model, Graph Contrastive Learning","Group anomaly detection is crucial in many network applications, but faces challenges due to diverse anomaly patterns. Motivated by the success of large language models (LLMs) in natural language processing, graph foundation models (GFMs) are proposed to handle few-shot learning tasks with fewer labeling efforts. GFMs have been successfully applied to the detection of individual anomalies but cannot be generalized to group anomalies, as group anomaly patterns must be detected as a whole and individuals in an abnormal group can look rather normal. Therefore, we propose GFM4GA, a novel graph foundation model for group anomaly detection. The pipeline is pretrained via dual-level contrastive learning based on feature-based estimation and group extraction, to capture potential group anomaly structure and feature inconsistencies. In the downstream tasks, the pipeline is finetuned in parameter-constrained and group-anomaly-proportion weighted few-shot settings, and its adaptive ability to unseen group anomalies is expanded via group contexts determined by labeled anomaly neighbors. Experiments show that GFM4GA surpasses group anomaly detectors and GFMs for individual anomalies, achieving average improvements of 2.85% in AUROC and 2.55% in AUPRC.",18.23,19.531,356,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10201v1_PRL Process Reward Learning Improves LLMs Reasonin.pdf,Process Reward Learning Improves LLMs’ Reasoning Ability and Broadens the Reasoning Boundary,"Jiarui Yao, Ruida Wang, Tong Zhang",,,"Large Language Models, Reinforcement Learning, Process Reward Learning, Reasoning Ability, LLMs","This paper introduces Process Reward Learning (PRL) to enhance the reasoning abilities of Large Language Models (LLMs). Traditional reinforcement learning frameworks often rely on sparse outcome rewards, which are insufficient for complex multi-step reasoning tasks. PRL addresses this by decomposing the reinforcement learning objective into intermediate steps, providing fine-grained process rewards. This approach not only improves average performance metrics but also broadens the reasoning boundary, as demonstrated by improved pass metrics. Theoretical motivation and experimental results support the effectiveness and generalizability of PRL.",15.26,13.037,199,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10205v1_One Instruction Does Not Fit All How Well Do Embed.pdf,One Instruction Does Not Fit All: How Well Do Embeddings Align Personas and Instructions in Low-Resource Indian Languages?,"Arya Shah, Himanshu Beniwal, Mayank Singh",,,"multilingual assistants, Indian languages, persona-instruction alignment, embedding models, cross-lingual retrieval, classification, benchmark","Aligning multilingual assistants with culturally grounded user preferences is essential for serving India’s linguistically diverse population. This study presents a unified benchmark for 12 Indian languages across four evaluation tasks: monolingual and cross-lingual persona-to-instruction retrieval, reverse retrieval from instruction to persona, and binary compatibility classification. Eight multilingual embedding models are evaluated, with E5-Large-Instruct and BGE-M3 showing strong performance in retrieval tasks, and LaBSE achieving high AUROC in classification. The research highlights the need for culturally aware cross-lingual representations and establishes reproducible baselines for future work.",16.61,14.935,248,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10212v1_PADER Paillier-based Secure Decentralized Social R.pdf,PADER: Paillier-based Secure Decentralized Social Recommendation,"Chaochao Chen, Jiaming Qian, Fei Zheng, Yachuan Liu",,,"Paillier Cryptosystem, Secure Computation, Recommendation System","The prevalence of recommendation systems also brings privacy concerns to both the users and the sellers, as centralized platforms collect as much data as possible from them. To keep the data private, we propose PADER, a Paillier-based secure decentralized social recommendation system. In this system, the users and the sellers are nodes in a decentralized network. The training and inference of the recommendation model are carried out securely in a decentralized manner, without the involvement of a centralized platform. To this end, we apply the Paillier cryptosystem to the SoReg (Social Regularization) model, which exploits both user’s ratings and social relations. We view the SoReg model as a two-party secure polynomial evaluation problem and observe that the simple bipartite computation may result in poor efficiency. To improve efficiency, we design secure addition and multiplication protocols to support secure computation on any arithmetic circuit, along with an optimal data packing scheme that is suitable for the polynomial computations of real values. Experiment results show that our method only takes about one second to iterate through one user with hundreds of ratings, and training with ~500K ratings for one epoch only takes <3 hours, which shows that the method is practical in real applications. The code is available at https://github.com/GarminQ/PADER.",18.92,18.977,359,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10215v1_Topo-RAG Topology-aware retrieval for hybrid text-.pdf,TOPO-RAG: TOPOLOGY-AWARE RETRIEVAL FOR HYBRID TEXT–TABLE DOCUMENTS,"Alex Dantart, Marco K´ovacs-Navarro",,arXiv:2601.10215v1,"Retrieval-Augmented Generation (RAG), table retrieval, late interaction, multivector retrieval, enterprise search, heterogeneous data, semantic routing, structure-aware embeddings, Topo-RAG, ColBERT, cell-aware interaction, linearization bottleneck","In enterprise datasets, documents are rarely pure, consisting of both narrative and structured data. Current Retrieval-Augmented Generation (RAG) systems often use linearization to handle this complexity, which is mathematically insufficient. This work introduces Topo-RAG, a framework that respects the topology of data by using a dual architecture: traditional dense retrievers for narrative and a Cell-Aware Late Interaction mechanism for tabular structures. Evaluated on SEC-25, Topo-RAG shows an 18.4% improvement in nDCG@10 on hybrid queries compared to standard linearization approaches, demonstrating better understanding of information structure.",18.11,16.287,295,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10222v1_Introduction to optimization methods for training .pdf,Introduction to optimization methods for training SciML models,"Alena Kopaničáková, Elisa Riccietti",,2601.10222v1,"optimization, machine learning, SciML, stochastic optimization, gradient descent, Hessians, partial-differential equations, physics informed, operator constrained","Optimization is the foundation of modern machine learning (ML), with methods categorized by their use of derivative information. First-order methods rely on gradient evaluations, while second-order methods use curvature information. The scale of modern ML problems has driven the field toward stochastic optimization, employing methods like Stochastic Gradient Descent (SGD) and its variants. In scientific machine learning (SciML), optimization problems often involve physics-informed or operator-constrained formulations, incorporating partial-differential equations and boundary conditions. This changes the structure of the objective function, leading to global spatio-temporal coupling, unlike the independent sample contributions in classical ML.",17.97,13.911,250,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10236v1_Who Owns the Text Design Patterns for Preserving A.pdf,Who Owns the Text? Design Patterns for Preserving Authorship in AI-Assisted Writing,"Bohan Zhang, Chengke Bu, Paramveer Dhillon",,arXiv:2601.10236v1,"AI-assisted writing, human–AI collaboration, psychological ownership, personalization, provenance","AI writing assistants can reduce effort and improve fluency, but they may also weaken writers’ sense of authorship. This study explores the tension with an ownership-aware co-writing editor that offers on-demand, sentence-level suggestions. It tests two design choices: persona-based coaching and style personalization. An online study with 176 participants showed that psychological ownership dropped in AI-assisted tasks compared to unassisted writing, even as cognitive load decreased and quality ratings stayed similar. Persona coaching did not prevent ownership decline, but style personalization partially restored ownership and increased AI incorporation in text. Five design patterns are proposed to guide authorship-preserving writing tools: on-demand initiation, micro-suggestions, voice anchoring, audience scaffolds, and point-of-decision provenance.",17.94,15.329,275,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10242v1_Loop as a Bridge Can Looped Transformers Truly Lin.pdf,LOOP AS ABRIDGE: CAN LOOPED TRANSFORMERS TRULY LINK REPRESENTATION SPACE AND NATURAL LANGUAGE OUTPUTS?,"Guanxu Chen, Dongrui Liu, Jing Shao",,,"Large Language Models, Looped Transformers, Representation Space, Natural Language Outputs, Introspection, Computational Depth","Large Language Models (LLMs) often exhibit a gap between their internal 'knowledge' and their explicit linguistic outputs. This report investigates whether Looping Transformers (LTs), which increase computational depth by iterating shared layers, can bridge this gap through introspection. Experiments show that while increasing loop iterations narrows the gap, it is partly due to a degradation of internal 'knowledge' in representations. Current LTs' ability to perceive representations does not improve across loops; it is only present in the final loop. These results suggest that while LTs offer a promising direction for scaling computational depth, they have yet to achieve the introspection required to truly link representation space and natural language.",16.53,15.612,258,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10245v1_TRIM Hybrid Inference via Targeted Stepwise Routin.pdf,TRIM: Hybrid Inference via Targeted Stepwise Routing in Multi-Step Reasoning Tasks,"Vansh Kapoor, Aman Gupta, Hao Chen, Anurag Beniwal, Jing Huang, Aviral Kumar",,,"multi-step reasoning, LLM routing, cost efficiency, mathematical problem solving, step-level interventions","Multi-step reasoning tasks like mathematical problem solving are vulnerable to cascading failures where a single incorrect step leads to complete solution breakdown. Current LLM routing methods assign entire queries to one model, treating all reasoning steps as equal. This paper proposes TRIM (Targeted Routing in Multi-Step Reasoning Tasks), which routes only critical steps—those likely to derail the solution—to larger models while letting smaller models handle routine continuations. TRIM uses process reward models to identify erroneous steps and makes routing decisions based on step-level uncertainty and budget constraints. Various routing strategies within TRIM are developed, showing significant cost efficiency improvements on benchmarks like MATH-500 and AIME. The methods generalize effectively across math reasoning tasks, demonstrating that step-level difficulty represents fundamental characteristics of reasoning.",17.5,16.11,282,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10251v1_X-SAM Boosting Sharpness-Aware Minimization with D.pdf,Boosting Sharpness-Aware Minimization with Dominant-Eigenvector Gradient Correction,"Hongru Duan, Yongle Chen, Lei Guan",,,"Sharpness-Aware Minimization, Spectral and Geometric Perspective, Hessian, Generalization, Gradient Correction, Eigenvector-Aligned SAM","Sharpness-Aware Minimization (SAM) aims to improve generalization by minimizing a worst-case perturbed loss over a small neighborhood of model parameters. However, its optimization behavior does not always align with theoretical expectations, as both sharp and flat regions may yield a small perturbed loss. This paper investigates SAM from a spectral and geometric perspective, utilizing the angle between the gradient and the leading eigenvector of the Hessian as a measure of sharpness. The proposed eigenvector-aligned SAM (X-SAM) corrects the gradient via orthogonal decomposition along the top eigenvector, enabling more direct and efficient regularization of the Hessian’s maximum eigenvalue. The paper proves X-SAM’s convergence and superior generalization, with extensive experimental evaluations confirming both theoretical and practical advantages.",16.9,15.029,254,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10254v1_NoReGeo Non-Reasoning Geometry Benchmark.pdf,NoReGeo: Non-Reasoning Geometry Benchmark,"Irina Abdullaeva, Anton Vasiliuk, Elizaveta Goncharova, Temurbek Rahmatullaev, Zagorulko Ivan, Maxim Kurkin, Andrey Kuznetsov",,,"geometry benchmark, large language models, geometric understanding, spatial relationships, binary classification, geometric cognition","We present NoReGeo, a novel benchmark designed to evaluate the intrinsic geometric understanding of large language models (LLMs) without relying on reasoning or algebraic computation. Unlike existing benchmarks that primarily assess models’ proficiency in reasoning-based geometry, NoReGeo focuses on evaluating whether LLMs can inherently encode spatial relationships and recognize geometric properties directly. Our benchmark comprises 2,500 trivial geometric problems spanning 25 categories, each crafted to be solvable purely through native geometric understanding, assuming known object locations. We assess a range of state-of-the-art models on NoReGeo, including frontier models like GPT-4, observing that even the most advanced systems achieve an overall maximum of 65% accuracy in binary classification tasks. Our findings highlight a significant gap in current LLMs’ ability to natively grasp geometric concepts, providing a foundation for future research toward models with true geometric cognition.",18.29,17.609,322,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10257v1_Untangling Input Language from Reasoning Language .pdf,Untangling Input Language from Reasoning Language: A Diagnostic Framework for Cross-Lingual Moral Alignment in LLMs,"Nan Li, Bo Kang, Tijl De Bie",,,"LLMs, moral dilemmas, cross-lingual, moral alignment, Moral Foundations Theory, diagnostic framework","This paper investigates whether large language models (LLMs) reach different conclusions when judging moral dilemmas in different languages, and if so, why. It identifies two potential factors: the language of the dilemma itself and the language in which the model reasons. The authors introduce a methodology that manipulates these factors separately, including mismatched conditions (e.g., English dilemma with Chinese reasoning), to decompose their contributions. The study applies this methodology to English-Chinese moral judgment with 13 LLMs, demonstrating the framework's diagnostic power by isolating reasoning-language effects, detecting context-dependency in nearly half of the models, and providing deployment guidance. The research also suggests splitting the Authority dimension of Moral Foundations Theory into family-related and institutional dimensions.",17.03,14.855,253,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10272v1_MoST Mixing Speech and Text with Modality-Aware Mi.pdf,MOST: MIXINGSPEECH ANDTEXT WITHMODALITY-AWAREMIXTURE OFEXPERTS,"Yuxuan Lou, Kai Yang, Yang You",,arXiv:2601.10272v1,"speech processing, text processing, multimodal learning, Mixture of Experts, Modality-Aware Mixture of Experts, ASR, TTS, audio language modeling, spoken question answering","We present MoST (Mixture of Speech and Text), a novel multimodal large language model that seamlessly integrates speech and text processing through our proposed Modality-Aware Mixture of Experts (MAMoE) architecture. While current multimodal models typically process diverse modality representations with identical parameters—disregarding their inherent representational differences, we introduce specialized routing pathways that direct tokens to modality-appropriate experts based on input type. MAMoE simultaneously enhances modality-specific learning and cross-modal understanding through two complementary components: modality-specific expert groups that capture domain-specific patterns and shared experts that facilitate information transfer between modalities. Building on this architecture, we develop an efficient transformation pipeline that adapts the pretrained MoE language model through strategic post-training on ASR and TTS datasets, followed by fine-tuning with a carefully curated speech-text instruction dataset. A key feature of this pipeline is that it relies exclusively on fully accessible, open-source datasets to achieve strong performance and data efficiency. Comprehensive evaluations across ASR, TTS, audio language modeling, and spoken question answering benchmarks show that MoST consistently outperforms existing models of comparable parameter counts. Our ablation studies confirm that the modality-specific routing mechanism and shared experts design significantly contribute to performance gains across all tested domains. To our knowledge, MoST represents the first fully open-source speech-text LLM built on a Mixture of Experts architecture.",19.73,21.85,431,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10274v1_Queueing-Aware Optimization of Reasoning Tokens fo.pdf,Queueing-Aware Optimization of Reasoning Tokens for Accuracy-Latency Trade-offs in LLM Servers,"Emre Ozbas, Melih Bastopcu",,,"Accuracy-latency trade-offs, LLM-based servers, optimization of reasoning tokens, LLM inference","This paper addresses the challenge of optimizing reasoning tokens in a single large language model (LLM) server that processes a heterogeneous stream of queries. Queries arrive according to a Poisson process, and each type has a known prior probability. The server allocates a fixed number of internal thinking tokens per task type, balancing computational effort with accuracy and latency. The service time is approximately affine with the allocated tokens, while accuracy shows diminishing returns. The system operates as an M/G/1 queue under a FIFO discipline, with mean system time dependent on the service-time distribution's moments. A constrained optimization problem is formulated to maximize a weighted average accuracy objective, penalized by mean system time, subject to token-budget constraints and queue-stability conditions. The objective function is strictly concave over the stability region, ensuring a unique optimal token allocation. First-order optimality conditions provide a coupled projected fixed-point characterization of the optimum, with iterative solutions and a sufficient condition for contraction. A projected gradient method with a global step-size bound ensures convergence beyond the contractive regime. Integer-valued token allocations are achieved by rounding the continuous solution, with performance loss evaluated in simulations.",18.12,17.275,313,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10282v2_SPIKE Sparse Koopman Regularization for Physics-In.pdf,SPIKE: Sparse Koopman Regularization for Physics-Informed Neural Networks,Jose Marie Antonio Miñoza,,arXiv:2601.10282v2,"Physics-Informed Neural Networks, Koopman operators, sparse dynamics, differential equations, PINNs, generalization, stability, stiff systems","This work introduces SPIKE, a framework that enhances Physics-Informed Neural Networks (PINNs) with continuous-time Koopman operators to address overfitting and improve generalization. By enforcing linear dynamics in a learned observable space, SPIKE achieves sparse generator matrices, enhancing interpretability and stability, particularly for stiff systems. Experiments demonstrate improvements in temporal extrapolation, spatial generalization, and long-term prediction accuracy across various types of differential equations, including fluid dynamics and chaotic systems.",15.38,13.195,203,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10305v1_DanQing An Up-to-Date Large-Scale Chinese Vision-L.pdf,DanQing: An Up-to-Date Large-Scale Chinese Vision-Language Pre-training Dataset,"Hengyu Shen, Tiancheng Gu, Bin Qin, Lan Wu, Yuling Wu, Shuo Tan, Zelong Sun, Jun Wang, Nan Wu, Xiang An, Weidong Cai, Ziyong Feng, Kaicheng Yang",,arXiv:2601.10305v1,"Vision-Language Pre-training, Chinese dataset, image-text pairs, cross-modal retrieval, image captioning, Common Crawl, SigLIP, CLIP","Vision-Language Pre-training (VLP) models demonstrate strong performance across various downstream tasks by learning from large-scale image-text pairs through contrastive pretraining. The release of extensive English image-text datasets has enabled widespread adoption of models such as CLIP and SigLIP in tasks including cross-modal retrieval and image captioning. However, the advancement of Chinese vision-language pretraining has substantially lagged behind, due to the scarcity of high-quality Chinese image-text data. To address this gap, we develop a comprehensive pipeline for constructing a high-quality Chinese cross-modal dataset. As a result, we propose DanQing, which contains 100 million image-text pairs collected from Common Crawl. Different from existing datasets, DanQing is curated through a more rigorous selection process, yielding superior data quality. Moreover, DanQing is primarily built from 2024–2025 web data, enabling models to better capture evolving semantic trends and thus offering greater practical utility. We compare DanQing with existing datasets by continual pre-training of the SigLIP2 model. Experimental results show that DanQing consistently achieves superior performance across a range of Chinese downstream tasks, including zero-shot classification, cross-modal retrieval, and LMM-based evaluations. To facilitate further research in Chinese vision-language pre-training, we will open-source the DanQing dataset under the Creative Common CC-BY 4.0 license.",19.42,24.461,475,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10306v1_Evidence-Augmented Policy Optimization with Reward.pdf,Evidence-Augmented Policy Optimization with Reward Co-Evolution for Long-Context Reasoning,"Xin Guan, Zijian Li, Shen Huang, Pengjun Xie, Jingren Zhou, Jiuxin Cao",,,"Reinforcement Learning, Long-Context Reasoning, Evidence-Augmented Policy Optimization, Reward Co-Evolution, Large Language Models, Natural Language Processing","While Reinforcement Learning (RL) has advanced LLM reasoning, applying it to long-context scenarios is hindered by the sparsity of outcome rewards. This limitation fails to penalize ungrounded 'lucky guesses,' leaving the critical process of needle-in-a-haystack evidence retrieval largely unsupervised. To address this, we propose EAPO (Evidence-Augmented Policy Optimization). We first establish the Evidence-Augmented Reasoning paradigm, validating via Tree-Structured Evidence Sampling that precise evidence extraction is the decisive bottleneck for long-context reasoning. Guided by this insight, EAPO introduces a specialized RL algorithm where a reward model computes a Group-Relative Evidence Reward, providing dense process supervision to explicitly improve evidence quality. To sustain accurate supervision throughout training, we further incorporate an Adaptive Reward-Policy Co-Evolution mechanism. This mechanism iteratively refines the reward model using outcome-consistent rollouts, sharpening its discriminative capability to ensure precise process guidance. Comprehensive evaluations across eight benchmarks demonstrate that EAPO significantly enhances long-context reasoning performance compared to SOTA baselines.",18.14,19.517,354,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10338v1_Agent Skills in the Wild An Empirical Study of Sec.pdf,Agent Skills in the Wild: An Empirical Study of Security Vulnerabilities at Scale,"Yi Liu, Weizhe Wang, Ruitao Feng, Yao Zhang, Guangquan Xu, Gelei Deng, Yuekang Li, Leo Zhang",10.1145/nnnnnnn.nnnnnnn,,"Agent skills, AI security, vulnerability analysis, supply chain security, prompt injection, large language models","The rise of AI agent frameworks has introduced agent skills—modular packages containing instructions and executable code that dynamically extend agent capabilities. While this architecture enables powerful customization, skills execute with implicit trust and minimal vetting, creating a significant yet uncharacterized attack surface. This study conducts the first large-scale empirical security analysis of this emerging ecosystem, collecting 42,447 skills from two major marketplaces and systematically analyzing 31,132 using SkillScan, a multi-stage detection framework integrating static analysis with LLM-based semantic classification. Findings reveal pervasive security risks: 26.1% of skills contain at least one vulnerability, spanning 14 distinct patterns across four categories—prompt injection, data exfiltration, privilege escalation, and supply chain risks. Data exfiltration (13.3%) and privilege escalation (11.8%) are most prevalent, while 5.2% of skills exhibit high-severity patterns strongly suggesting malicious intent. Skills bundling executable scripts are 2.12× more likely to contain vulnerabilities than instruction-only skills (OR=2.12, p<0.001). Contributions include a grounded vulnerability taxonomy derived from 8,126 vulnerable skills, a validated detection methodology achieving 86.7% precision and 82.5% recall, and an open dataset and detection toolkit to support future research. These results demonstrate an urgent need for capability-based permission systems and mandatory security vetting before this attack vector is further exploited.",19.08,23.374,446,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10342v1_C-GRASP Clinically-Grounded Reasoning for Affectiv.pdf,C-GRASP: Clinically-Grounded Reasoning for Affective Signal Processing,"Cheng Lin Cheng, Ting Chuan Lin, Chai Kai Chang",,,"Large language model, clinical decision support, heart rate variability, retrieval-augmented generation, explainable AI, guardrails","Heart rate variability (HRV) is a pivotal non-invasive marker for autonomic monitoring; however, applying Large Language Models (LLMs) to HRV interpretation is hindered by physiological hallucinations, where models struggle with respiratory sinus arrhythmia (RSA) contamination, short-data instability in nonlinear metrics, and the neglect of individualized baselines in favor of population norms. We propose C-GRASP (Clinically-Grounded Reasoning for Affective Signal Processing), a guardrailed RAG-enhanced pipeline that decomposes HRV interpretation into eight traceable reasoning steps. Central to C-GRASP is a Z-score Priority Hierarchy that enforces the weighting of individualized baseline shifts over normative statistics. The system effectively mitigates spectral hallucinations through automated RSA-aware guardrails, preventing contamination of frequency-domain indices. Evaluated on 414 trials from the DREAMER dataset, C-GRASP integrated with high-scale reasoning models (e.g., MedGemma3-thinking) achieved superior performance in 4-class emotion classification (37.3% accuracy) and achieved a Clinical Reasoning Consistency (CRC) score of 69.6%. Ablation studies confirm that the individualized Delta Z-score module serves as the critical logical anchor, preventing the 'population bias' common in native LLMs. Ultimately, C-GRASP transitions affective computing from black-box classification to transparent, evidence-based clinical decision support, paving the way for safer AI integration in biomedical engineering.",19.53,21.351,417,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10343v2_OctoBench Benchmarking Scaffold-Aware Instruction .pdf,OCTOBENCH: Benchmarking Scaffold-Aware Instruction Following in Repository-Grounded Agentic Coding,"Deming Ding, Shichun Liu, Enhui Yang, Jiahang Lin, Ziying Chen, Shihan Dou, Honglin Guo, Weiyu Cheng, Pengyu Zhao, Chengjun Xiao, Qunhong Zeng, Qi Zhang, Xuanjing Huang, Qidi Xu, Tao Gui",,,"LLMs, software agents, instruction following, scaffolds, benchmarking, coding agents","Modern coding scaffolds turn LLMs into capable software agents, but their ability to follow scaffold-specified instructions remains under-examined, especially when constraints are heterogeneous and persist across interactions. To fill this gap, we introduce OCTOBENCH, which benchmarks scaffold-aware instruction following in repository-grounded agentic coding. OCTOBENCH includes 34 environments and 217 tasks instantiated under three scaffold types, and is paired with 7,098 objective checklist items. To disentangle solving the task from following the rules, we provide an automated observation-and-scoring toolkit that captures full trajectories and performs fine-grained checks. Experiments on eight representative models reveal a systematic gap between task-solving and scaffold-aware compliance, underscoring the need for training and evaluation that explicitly targets heterogeneous instruction following. We release the benchmark to support reproducible benchmarking and to accelerate the development of more scaffold-aware coding agents.",17.51,19.128,335,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10348v1_Training-Trajectory-Aware Token Selection.pdf,Training-Trajectory-Aware Token Selection,"Zhanming Shen, Jiaqi Hu, Zeyu Qin, Hao Chen, Wentao Ye, Zenan Huang, Yihong Zhuang, Guoshan Lu, Junlin Zhou, Junbo Zhao",,,"efficient distillation, reasoning capability, student model, token-level mechanism, Training-Trajectory-Aware Token Selection (T3S), large language models, chain-of-thought, reasoning distillation, performance metrics, imitation shock, imitation bottleneck","Efficient distillation is crucial for converting expensive reasoning capabilities into deployable efficiency. However, in scenarios where the student model already possesses strong reasoning abilities, naive continual distillation often results in limited improvements or even performance degradation. This study observes a phenomenon where, despite a monotonic decrease in loss, performance metrics sharply decline at a bottleneck before gradually recovering. A token-level mechanism is identified, where confidence bifurcates into steadily increasing 'Imitation-Anchor Tokens' and other tokens whose confidence is suppressed until after the bottleneck. The inability of these two token types to coexist is identified as the root cause of failure in continual distillation. To address this, the Training-Trajectory-Aware Token Selection (T3S) method is proposed, which reconstructs the training objective at the token level, facilitating the optimization path for yet-to-learn tokens. T3S demonstrates consistent gains in both AR and dLLM settings, with Qwen3-8B surpassing DeepSeek-R1 on competitive reasoning benchmarks, Qwen3-32B approaching Qwen3-235B, and T3-trained LLaDA-2.0-Mini exceeding its AR baseline, achieving state-of-the-art performance among 16B-scale no-think models.",18.92,23.359,442,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10349v1_SuS Strategy-aware Surprise for Intrinsic Explorat.pdf,Strategy-aware Surprise for Intrinsic Exploration,"Mark Kashirskiy, Ilya Makarov",,,"intrinsic motivation, reinforcement learning, contrastive learning, exploration","We propose Strategy-aware Surprise (SuS), a novel intrinsic motivation framework that uses pre-post prediction mismatch as a novelty signal for exploration in reinforcement learning. Unlike traditional curiosity-driven methods that rely solely on state prediction error, SuS introduces two complementary components: Strategy Stability (SS) and Strategy Surprise (SuS). SS measures consistency in behavioral strategy across temporal steps, while SuS captures unexpected outcomes relative to the agent’s current strategy representation. Our combined reward formulation leverages both signals through learned weighting coefficients. We evaluate SuS on mathematical reasoning tasks using large language models, demonstrating significant improvements in both accuracy and solution diversity. Ablation studies confirm that removing either component results in at least 10% performance degradation, validating the synergistic nature of our approach. SuS achieves 17.4% improvement in Pass@1 and 26.4% improvement in Pass@5 compared to baseline methods, while maintaining higher strategy diversity throughout training.",17.37,15.718,273,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10373v1_Towards Efficient Low-rate Image Compression with .pdf,Towards Efficient Low-rate Image Compression with Frequency-aware Diffusion Prior Refinement,"Yichong Xia, Yimin Zhou, Jinpeng Wang, Bin Chen",,,"image compression, diffusion-based generative priors, low bit rates, frequency-aware skip estimation, frequency decoupling attention, semantic trajectory, perceptual quality","Recent advancements in diffusion-based generative priors have enabled visually plausible image compression at extremely low bit rates. However, existing approaches suffer from slow sampling processes and suboptimal bit allocation due to fragmented training paradigms. This work proposes AccelerateDiffusion-based Image Compression via Consistency Prior Refinement (DiffCR), a novel compression framework for efficient and high-fidelity image reconstruction. The core of DiffCR is a Frequency-aware Skip Estimation (FaSE) module that refines the ϵ-prediction prior from a pre-trained latent diffusion model and aligns it with compressed latents at different timesteps via Frequency Decoupling Attention (FDA). Additionally, a lightweight consistency estimator enables fast two-step decoding by preserving the semantic trajectory of diffusion sampling. Without updating the backbone diffusion model, DiffCR achieves substantial bitrate savings (27.2% BD-rate (LPIPS) and 65.1% BD-rate (PSNR)) and over 10× speed-up compared to state-of-the-art diffusion-based compression baselines.",17.64,18.934,334,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10378v2_Global Context Compression with Interleaved Vision.pdf,Global Context Compression with Interleaved Vision-Text Transformation,"Dian Jiao, Jiaxin Duan, Shuai Zhao, Jiabing Leng, Yiran Zhang, Feng Huang",,,"vision-language models, OCR, Transformer, context compression, visual encoding, attention computations, computational efficiency, memory usage, FLOPS, hierarchical encoding, sparse attention","Recent advancements in vision-language models for OCR suggest a new approach for low-loss compression of textual information. This paper explores global context compression to reduce tokens at both prefilling and inference stages. The proposed VIST2 Transformer interleaves input text chunks with their visual encoding, relying on visual tokens in the pre-context to predict the next text token distribution. The model is trained in multiple stages, achieving significant improvements in speed, memory usage, and FLOPS on long writing tasks. The study highlights the potential of visual compression in hierarchical encoding for efficient context scaling in Transformers.",16.86,15.602,263,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10386v1_Handling Missing Modalities in Multimodal Survival.pdf,Handling Missing Modalities in Multimodal Survival Prediction for Non-Small Cell Lung Cancer,"Filippo Ruffini, Camillo Maria Caruso, Claudia Tacconi, Lorenzo Nibid, Francesca Miccolis, Marta Lovino, Carlo Greco, Edy Ippolito, Michele Fiore, Alessio Cortellini, Bruno Beomonte Zobel, Giuseppe Perrone, Bruno Vincenzi, Claudio Marrocco, Alessandro Bria, Elisa Ficarra, Sara Ramella, Valerio Guarrasi, Paolo Soda",,arXiv:2601.10386v1,cs.CV,,17.03,13.388,228,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10398v2_LatentRefusal Latent-Signal Refusal for Unanswerab.pdf,LatentRefusal: Latent-Signal Refusal for Unanswerable Text-to-SQL Queries,"Xuancheng Ren, Shijing Hu, Zhihui Lu, Jiangqi Huang, Qiang Duan",,,"Text-to-SQL, Large Language Models, Safety, Refusal Mechanism, LLM-based Systems, Answerability, Schema Noise, Query Answerability","In LLM-based Text-to-SQL systems, unanswerable and underspecified user queries can generate incorrect text and executable programs that yield misleading results or violate safety constraints. Existing refusal strategies are either brittle due to model hallucinations or add complexity and overhead. This paper introduces LATENTREFUSAL, a latent-signal refusal mechanism that predicts query answerability from intermediate hidden activations of an LLM. The proposed Tri-Residual Gated Encoder (TRGE) architecture suppresses schema noise and amplifies mismatch cues indicating unanswerability. Empirical evaluations demonstrate the effectiveness of LATENTREFUSAL as an efficient safety layer for Text-to-SQL systems, improving average F1 to 88.5% across benchmarks with minimal probe overhead.",17.42,16.709,291,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10402v1_Toward Ultra-Long-Horizon Agentic Science Cognitiv.pdf,Toward Ultra-Long-Horizon Agentic Science: Cognitive Accumulation for Machine Learning Engineering,"Xinyu Zhu, Yuzhu Cai, Zexi Liu, Bingyang Zheng, Cheng Wang, Rui Ye, Jiaao Chen, Hanrui Wang, Wei-Chen Wang, Yuzhi Zhang, Linfeng Zhang, Weinan E, Di Jin, Siheng Chen",,arXiv:2601.10402v1,"artificial intelligence, machine learning engineering, ultra-long-horizon autonomy, cognitive accumulation, Hierarchical Cognitive Caching, scientific discovery","The advancement of artificial intelligence toward agentic science is currently bottlenecked by the challenge of ultra-long-horizon autonomy, the ability to sustain strategic coherence and iterative correction over experimental cycles spanning days or weeks. While Large Language Models (LLMs) have demonstrated prowess in short-horizon reasoning, they are easily overwhelmed by execution details in high-dimensional, delayed-feedback environments of real-world research, failing to consolidate sparse feedback into coherent long-term guidance. Here, we present ML-Master 2.0, an autonomous agent that masters ultra-long-horizon machine learning engineering (MLE), a representative microcosm of scientific discovery. By reframing context management as a process of cognitive accumulation, our approach introduces Hierarchical Cognitive Caching (HCC), a multi-tiered architecture inspired by computer systems that enables the structural differentiation of experience over time. By dynamically distilling transient execution traces into stable knowledge and cross-task wisdom, HCC allows agents to decouple immediate execution from long-term experimental strategy, effectively overcoming the scaling limits of static context windows. In evaluations on OpenAI’s MLE-Bench under 24-hour budgets, ML-Master 2.0 achieves a state-of-the-art medal rate of 56.44%. Our findings demonstrate that ultra-long-horizon autonomy provides a scalable blueprint for AI capable of autonomous exploration beyond human-precedent complexities.",19.85,24.085,478,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10406v1_ErrEval Error-Aware Evaluation for Question Genera.pdf,ErrEval: Error-Aware Evaluation for Question Generation through Explicit Diagnostics,"Weiping Fu, Bifan Wei, Jingyi Hao, Yushun Zhang, Jian Zhang, Jiaxin Wang, Bo Li, Yu He, Lingling Zhang, Jun Liu",,,"Question Generation, Evaluation, Error Diagnosis, Natural Language Generation","Automatic Question Generation (QG) often produces outputs with critical defects, such as factual hallucinations and answer mismatches. Existing evaluation methods, including LLM-based evaluators, mainly adopt a black-box and holistic paradigm without explicit error modeling, leading to the neglect of such defects and overestimation of question quality. To address this issue, we propose ErrEval, a flexible and Error-aware Evaluation framework that enhances QG evaluation through explicit error diagnostics. Specifically, ErrEval reformulates evaluation as a two-stage process of error diagnosis followed by informed scoring. At the first stage, a lightweight plug-and-play Error Identifier detects and categorizes common errors across structural, linguistic, and content-related aspects. These diagnostic signals are then incorporated as explicit evidence to guide LLM evaluators toward more fine-grained and grounded judgments. Extensive experiments on three benchmarks demonstrate the effectiveness of ErrEval, showing that incorporating explicit diagnostics improves alignment with human judgments. Further analyses confirm that ErrEval effectively mitigates the overestimation of low-quality questions.",17.7,17.629,312,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10413v1_LADFA A Framework of Using Large Language Models a.pdf,LADFA: A Framework of Using Large Language Models and Retrieval-Augmented Generation for Personal Data Flow Analysis in Privacy Policies,"Haiyue Yuan, Nikolay Matyunin, Ali Raza, Shujun Li",https://doi.org/XXXXXXX.XXXXXXX,,"Large Language Model, LLM, Privacy Policy, Text Analysis, Data Flows, Privacy, Security, Retrieval-Augmented Generation, RAG, Framework, Automotive Industry, Connected Vehicle","Privacy policies often use complex legal language, making them difficult to comprehend. This paper introduces LADFA, a computational framework that uses large language models (LLMs) and retrieval-augmented generation (RAG) to analyze personal data flows in privacy policies. The framework processes unstructured text to extract data flows and construct a data flow graph, facilitating insight discovery. It includes a pre-processor, an LLM-based processor, and a data flow post-processor. The effectiveness of LADFA was validated through a case study on ten privacy policies from the automotive industry. The framework is designed to be flexible and customizable for various text-based analysis tasks.",16.96,16.035,272,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10416v1_LLMdoctor Token-Level Flow-Guided Preference Optim.pdf,LLMdoctor: Token-Level Flow-Guided Preference Optimization for Efficient Test-Time Alignment of Large Language Models,"Tiesunlong Shen, Rui Mao, Jin Wang, Heming Sun, Jian Zhang, Xuejie Zhang, Erik Cambria",,,"Large Language Models, test-time alignment, preference optimization, token-level reward, flow-guided preference optimization","Aligning Large Language Models (LLMs) with human preferences is critical, yet traditional fine-tuning methods are computationally expensive and inflexible. This paper introduces LLMdoctor, a novel framework for efficient test-time alignment that operates via a patient-doctor paradigm. It integrates token-level reward acquisition with token-level flow-guided preference optimization (TFPO) to steer a large, frozen patient LLM with a smaller, specialized doctor model. Unlike conventional methods that rely on trajectory-level rewards, LLMdoctor extracts fine-grained, token-level preference signals from the patient model’s behavioral variations. These signals guide the training of the doctor model via TFPO, establishing flow consistency across all subtrajectories, enabling precise token-by-token alignment while preserving generation diversity. Extensive experiments demonstrate that LLMdoctor significantly outperforms existing test-time alignment methods and even surpasses the performance of full fine-tuning approaches like DPO.",17.71,18.185,322,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10421v1_Are Language Models Models.pdf,Are Language Models Models?,Philip Resnik,http://doi.org/10.1017/S0140525X2510112X,,"Language Models, Cognitive Models, Marr’s Levels, Linguistics, LMs as Tools","Futrell and Mahowald claim LMs 'serve as model systems', but an assessment at each of Marr’s three levels suggests the claim is clearly not true at the implementation level, poorly motivated at the algorithmic-representational level, and problematic at the computational theory level. LMs are good candidates as tools; calling them cognitive models overstates the case and unnecessarily feeds LLM hype.",17.66,9.059,160,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10436v1_Development of Ontological Knowledge Bases by Leve.pdf,Development of Ontological Knowledge Bases by Leveraging Large Language Models,"LE Ngoc Luyen, Marie-Hélène ABEL, Philippe GOUSPILLOU",,,"Ontology Development, Ontological Knowledge bases, Large Language Models, Knowledge Representation, User Modeling, Knowledge Management","Ontological Knowledge Bases (OKBs) play a vital role in structuring domain-specific knowledge and serve as a foundation for effective knowledge management systems. However, their traditional manual development poses significant challenges related to scalability, consistency, and adaptability. Recent advancements in Generative AI, particularly Large Language Models (LLMs), offer promising solutions for automating and enhancing OKB development. This paper introduces a structured, iterative methodology leveraging LLMs to optimize knowledge acquisition, automate ontology artifact generation, and enable continuous refinement cycles. We demonstrate this approach through a detailed case study focused on developing a user context profile ontology within the vehicle sales domain. Key contributions include significantly accelerated ontology construction processes, improved ontological consistency, effective bias mitigation, and enhanced transparency in the ontology engineering process. Our findings highlight the transformative potential of integrating LLMs into ontology development, notably improving scalability, integration capabilities, and overall efficiency in knowledge management systems.",18.94,14.626,277,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10440v1_AgentGuardian Learning Access Control Policies to .pdf,AGENTGUARDIAN: Learning Access Control Policies to Govern AI Agent Behavior,"Nadya Abaev, Denis Klimov, Gerard Levinov, David Mimran, Yuval Elovici, Asaf Shabtai",,,"Security, AI Agents, Access Control Policies, Control Flow Graph","Artificial intelligence (AI) agents are increasingly used in various domains to automate tasks, interact with users, and make decisions based on data inputs. Ensuring that AI agents perform only authorized actions and handle inputs appropriately is essential for maintaining system integrity and preventing misuse. This study introduces AgentGuardian, a novel security framework that governs and protects AI agent operations by enforcing context-aware access-control policies. During a controlled staging phase, the framework monitors execution traces to learn legitimate agent behaviors and input patterns. From this phase, it derives adaptive policies that regulate tool calls made by the agent, guided by both real-time input context and the control flow dependencies of multi-step agent actions. Evaluation across two real-world AI agent applications demonstrates that AgentGuardian effectively detects malicious or misleading inputs while preserving normal agent functionality. Moreover, its control-flow-based governance mechanism mitigates hallucination-driven errors and other orchestration-level malfunctions.",17.71,15.756,279,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10457v1_NSR-Boost A Neuro-Symbolic Residual Boosting Frame.pdf,NSR-Boost: A Neuro-Symbolic Residual Boosting Framework for Industrial Legacy Models,"Ziming Dai, Dabiao Ma, Jinle Tong, Mengyuan Han, Jian Yang, Haojun Fei",https://doi.org/10.1145/nnnnnnn.nnnnnnn,,"Neuro-Symbolic AI, Large Language Models, Gradient Boosting, Legacy Model, Interpretability","Although Gradient Boosted Decision Trees (GBDTs) dominate industrial tabular applications, upgrading legacy models in high-concurrency production environments faces prohibitive retraining costs and systemic risks. To address this, NSR-Boost, a neuro-symbolic residual boosting framework, is presented. It is non-intrusive, treating the legacy model as a frozen model and performing targeted repairs on 'hard regions' where predictions fail. The framework involves three key stages: finding hard regions through residuals, generating interpretable experts using Large Language Models and Bayesian optimization, and dynamically integrating experts with legacy model output through a lightweight aggregator. NSR-Boost has been successfully deployed in Qfin Holdings' financial risk control system, outperforming state-of-the-art baselines and capturing long-tail risks missed by traditional models, offering a safe, low-cost evolutionary paradigm for industry.",18.02,17.871,322,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10460v1_Contextual StereoSet Stress-Testing Bias Alignment.pdf,Contextual StereoSet: Stress-Testing Bias Alignment Robustness in Large Language Models,"Abhinaba Basu, Pavan Chakraborty",,2601.10460v1,"bias evaluation, alignment robustness, stress-testing, large language models, sociotechnical context, StereoSet","This paper introduces Contextual StereoSet, a benchmark designed to test the robustness of bias alignment in large language models by varying contextual framing such as place, time, and audience. The study reveals that bias levels can shift dramatically under different contexts, challenging the assumption that fixed-condition bias scores generalize. The paper proposes Context Sensitivity Fingerprints (CSF) to profile bias under varying conditions and suggests a methodological shift in evaluating model bias. The findings emphasize the need for robust evaluation methods that account for real-world variations.",17.29,12.842,222,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10462v3_ChartComplete A Taxonomy-based Inclusive Chart Dat.pdf,ChartComplete: A Taxonomy-based Inclusive Chart Dataset,"Ahmad Mustapha, Charbel Toumieh, Mariette Awad",,2601.10462v3,"Chart, Dataset, Chart Taxonomy, Chart Classification","With advancements in deep learning and computer vision techniques, the field of chart understanding is evolving rapidly. Multi-modal large language models (MLLMs) are proving to be efficient and accurate in understanding charts. To accurately measure the performance of MLLMs, the research community has developed multiple datasets to serve as benchmarks. However, these datasets are limited to a small set of chart types. To bridge this gap, the ChartComplete dataset is proposed, based on a chart taxonomy borrowed from the visualization community, covering thirty different chart types. The dataset is a collection of classified chart images without a learning signal, presented to the community for further development. The dataset aims to support a broader range of chart types, enhancing the capabilities of models in the ChartQA domain.",16.57,14.3,237,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10477v1_Urban Socio-Semantic Segmentation with Vision-Lang.pdf,URBANSOCIO-SEMANTICSEGMENTATION WITH VISION-LANGUAGEREASONING,"Yu Wang, Yi Wang, Rui Dai, Yujie Wang, Kaikui Liu, Xiangxiang Chu, Yansheng Li",,,"urban socio-semantic segmentation, vision-language reasoning, satellite imagery, social semantic entities, cross-modal recognition, multi-stage reasoning, reinforcement learning","This work introduces a novel approach to socio-semantic segmentation of urban surfaces using vision-language model reasoning. The Urban Socio-Semantic Segmentation dataset, named SocioSeg, is introduced, comprising satellite imagery, digital maps, and pixel-level labels of social semantic entities organized hierarchically. A new vision-language reasoning framework, SocioReasoner, is proposed to simulate human identification and annotation of social semantic entities through cross-modal recognition and multi-stage reasoning. Reinforcement learning is employed to optimize this non-differentiable process, enhancing the reasoning capabilities of the vision-language model. The approach demonstrates significant improvements over state-of-the-art models and strong zero-shot generalization. The dataset and code are available at github.com/AMAP-ML/SocioReasoner.",17.98,17.015,306,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10485v1_Panning for Gold Expanding Domain-Specific Knowled.pdf,Panning for Gold: Expanding Domain-Specific Knowledge Graphs with General Knowledge,"Runhao Zhao, Weixin Zeng, Wentao Zhang, Chong Chen, Zhengpin Li, Xiang Zhao, Lei Chen",,,"Domain-specific Knowledge Graph Fusion, Knowledge Graph Enrichment, General-to-domain Knowledge Transfer, Fact-as-Program","Domain-specific knowledge graphs (DKGs) are essential for supporting intelligent applications in specialized fields, yet they often suffer from limited coverage and incompleteness compared to general knowledge graphs (GKGs) such as Wikipedia and YAGO. Existing tasks to enrich DKGs rely primarily on extracting knowledge from unstructured data or completing KGs through internal reasoning, but the scope and quality of such integration remain limited. This highlights a critical gap: little systematic exploration has been conducted on how comprehensive, high-quality GKGs can be effectively leveraged to supplement DKGs. To address this gap, we propose a new and practical task: domain-specific knowledge graph fusion (DKGF), which aims to mine and integrate relevant facts from general knowledge graphs into domain-specific knowledge graphs to enhance their completeness and utility. Unlike previous research, this new task faces two key challenges: high ambiguity of domain relevance, i.e., difficulty in determining whether knowledge from a GKG is truly relevant to the target domain, and cross-domain knowledge granularity misalignment, i.e., GKG facts are typically abstract and coarse-grained, whereas DKGs frequently require more contextualized, fine-grained representations aligned with particular domain scenarios. To tackle these challenges, we propose ExeFuse, a simple yet effective Fact-as-Program paradigm that reformulates DKGF as executable semantic reasoning over DKGs. Specifically, ExeFuse interprets each GKG fact as a latent semantic program, maps abstract relations to granularity-aware operators, and verifies domain relevance through program executability on the target DKG. By unifying relevance assessment and granularity transformation within a single probabilistic framework, ExeFuse enables precise identification and integration of domain-relevant, consistent knowledge from GKGs. We construct two new benchmark datasets (DKGF(W-I) and DKGF(Y-I)) and propose 21 representative benchmark configurations to systematically assess DKGF performance. Extensive experiments highlight the value of the new task and demonstrate the effectiveness of ExeFuse, providing the first standardized evaluation suite for this emerging task. The source codes and datasets are available at https://github.com/eduzrh/DKGF_benchmark.",20.55,27.397,563,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10496v1_Model See Model Do Exposure-Aware Evaluation of Bu.pdf,"Model See, Model Do? Exposure-Aware Evaluation of Bug-vs-Fix Preference in Code LLMs","Ali Al-Kaswan, Claudio Spiess, Prem Devanbu, Arie van Deursen, Maliheh Izadi",https://doi.org/10.1145/nnnnnnn.nnnnnnn,,"Large Language Models, bugs, fixes, Memorisation","Large language models are increasingly used for code generation and debugging, but their outputs can still contain bugs that originate from training data. Distinguishing whether an LLM prefers correct code, or a familiar incorrect version might be influenced by what it’s been exposed to during training. We introduce an exposure-aware evaluation framework that quantifies how prior exposure to buggy versus fixed code influences a model’s preference. Using the ManySStuBs4J benchmark, we apply Data Portraits for membership testing on the Stack-V2 corpus to estimate whether each buggy and fixed variant was seen during training. We then stratify examples by exposure and compare model preference using code completion as well as multiple likelihood-based scoring metrics. We find that most examples (67%) have neither variant in the training data, and when only one is present, fixes are more frequently present than bugs. In model generations, models reproduce buggy lines far more often than fixes, with bug-exposed examples amplifying this tendency and fix-exposed examples showing only marginal improvement. In likelihood scoring, minimum and maximum token-probability metrics consistently prefer the fixed code across all conditions, indicating a stable bias toward correct fixes. In contrast, metrics like the Gini coefficient reverse preference when only the buggy variant was seen. Our results indicate that exposure can skew bug-fix evaluations and highlight the risk that LLMs may propagate memorised errors in practice.",19.34,21.562,417,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10498v1_Projected Microbatch Accumulation yields reference.pdf,Projected Microbatch Accumulation yields reference-free proximal policy updates for reinforcement learning,Nilin Abrahamsen,,2601.10498v1,"reinforcement learning, proximal policy updates, large language model fine-tuning, PROMA, PPO, GRPO, policy gradients, KL divergence","This note introduces Projected Microbatch Accumulation (PROMA), a proximal policy update method for large language model fine-tuning. PROMA accumulates policy gradients across microbatches by projecting out sequence-wise gradient components before microbatch aggregation. The projection is applied layer-wise during the backward pass, enabling efficient implementation without additional forward or backward passes. Empirically, PROMA enforces tighter control of local KL divergence than GRPO, resulting in more stable policy learning. Unlike PPO and GRPO, PROMA achieves proximal updates without inducing entropy collapse and does not rely on a reference policy or likelihood-ratio clipping.",15.84,14.643,232,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10511v1_Scalable Algorithms for Approximate DNF Model Coun.pdf,Scalable Algorithms for Approximate DNF Model Counting,"Paul Burkhardt, David G. Harris, Kevin T. Schmitt",,arXiv:2601.10511v1,"DNF Model Counting, Monte Carlo, Probabilistic Inference, Network Reliability, Probabilistic Databases, PAC Learning, Approximation Algorithms","Model counting of Disjunctive Normal Form (DNF) formulas is a critical problem in applications such as probabilistic inference and network reliability. Due to the computational intractability of exact DNF counting, various approximation algorithms have been developed, including Monte Carlo methods and heuristic approximations based on Neural Nets. This paper introduces a new Monte Carlo approach with an adaptive stopping rule and short-circuit formula evaluation, proving it achieves Probably Approximately Correct (PAC) learning bounds and is asymptotically more efficient than previous methods. Experimental results show it outperforms prior algorithms significantly and can scale to larger problems with millions of variables.",17.82,14.481,258,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10512v2_SatMap Revisiting Satellite Maps as Prior for Onli.pdf,SatMap: Revisiting Satellite Maps as Prior for Online HD Map Construction,"Kanak Mazumder, Fabian B. Flohr",,arXiv:2601.10512v2,"Online HD map prediction, Satellite map prior, Vectorized HD map","Online high-definition (HD) map construction is an essential part of a safe and robust end-to-end autonomous driving (AD) pipeline. Onboard camera-based approaches suffer from limited depth perception and degraded accuracy due to occlusion. This work proposes SatMap, an online vectorized HD map estimation method that integrates satellite maps with multi-view camera observations and directly predicts a vectorized HD map for downstream prediction and planning modules. The method leverages lane-level semantics and texture from satellite imagery captured from a Bird’s Eye View (BEV) perspective as a global prior, effectively mitigating depth ambiguity and occlusion. Experiments on the nuScenes dataset show that SatMap achieves 34.8% mAP performance improvement over the camera-only baseline and 8.5% mAP improvement over the camera-LiDAR fusion baseline. The model is also evaluated in long-range and adverse weather conditions to demonstrate the advantages of using a satellite prior map.",18.86,15.642,295,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10520v1_Breaking Up with Normatively Monolithic Agency wit.pdf,Breaking Up with Normatively Monolithic Agency with GRACE: A Reason-Based Neuro-Symbolic Architecture for Safe and Ethical AI Alignment,"Felix Jahn, Yannic Muskalla, Lisa Dargasz, Patrick Schramowski, Kevin Baum",,2601.10520v1,"AI alignment, neuro-symbolic architecture, normative reasoning, ethical AI, deontic logic, instrumental decision-making","As AI agents become increasingly autonomous and impactful, ensuring their decisions are normatively aligned is critical. This paper introduces GRACE, a neuro-symbolic reason-based containment architecture that decouples normative reasoning from instrumental decision-making. GRACE consists of three modules: a Moral Module (MM) for permissible macro actions, a Decision-Making Module (DMM) for selecting optimal primitive actions, and a Guard for enforcing moral compliance. The MM uses a reason-based formalism for deontic logic, enhancing interpretability and justifiability. The architecture is demonstrated with a LLM therapy assistant, showing how it allows stakeholders to understand, contest, and refine agent behavior.",17.59,15.863,279,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10524v1_Diagnosing Generalization Failures in Fine-Tuned L.pdf,Diagnosing Generalization Failures in Fine-Tuned LLMs: A Cross-Architectural Study on Phishing Detection,"Frank Bobe II, Frank Bobe III, Gregory D. Vetaw, Chase Pavlick, Darshan Bryner, Matthew Cook, Jose Salas-Vernis",,arXiv:2601.10524v1,"Large Language Models, fine-tuning, generalization failures, phishing detection, SHAP analysis, mechanistic interpretability, architecture, data diversity, AI security","The study investigates why fine-tuned Large Language Models (LLMs) fail to generalize, using a multi-layered diagnostic framework on models like Llama 3.1 8B, Gemma 2 9B, and Mistral. It reveals that generalization is influenced by the synergy between architecture and data diversity, is architecture-dependent, and varies across models. The Gemma 2 9B model excels with diverse data, while Llama 3.1 8B struggles with integrating diverse data. Mistral shows consistent performance across training paradigms. The findings highlight the need for deep validation of architecture, data, and training strategies to ensure reliable AI, especially in high-stakes tasks like phishing detection.",18.24,17.987,328,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10527v2_A Safety Report on GPT-5.2 Gemini 3 Pro Qwen3-VL G.pdf,"A Safety Report on GPT-5.2, Gemini 3 Pro, Qwen3-VL, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5","Xingjun Ma, Yixu Wang, Hengyuan Xu, Yutao Wu, Yifan Ding, Yunhan Zhao, Zilong Wang, Jiabin Hua, Ming Wen, Jianan Liu, Ranjie Duan, Yifeng Gao, Yingshui Tan, Yunhao Chen, Hui Xue, Xin Wang, Wei Cheng, Jingjing Chen, Zuxuan Wu, Bo Li, Yu-Gang Jiang",,arXiv:2601.10527v2,"Large Language Models, Multimodal Large Language Models, Safety Evaluation, Adversarial Evaluation, Multilingual Evaluation, Compliance Evaluation, AI Safety","The rapid evolution of Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) has driven major gains in reasoning, perception, and generation across language and vision. Yet whether these advances translate into comparable improvements in safety remains unclear, partly due to fragmented evaluations that focus on isolated modalities or threat models. In this report, we present an integrated safety evaluation of six frontier models: GPT-5.2, Gemini 3 Pro, Qwen3-VL, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5. We evaluate each model across language, vision-language, and image generation settings using a unified protocol that integrates benchmark evaluation, adversarial evaluation, multilingual evaluation, and compliance evaluation. By aggregating results into safety leaderboards and model profiles, we reveal a highly uneven safety landscape. While GPT-5.2 demonstrates consistently strong and balanced performance, other models exhibit clear trade-offs across benchmark safety, adversarial robustness, multilingual generalization, and regulatory compliance. Despite achieving strong results under standard benchmark evaluations, all models remain highly vulnerable under adversarial testing, with worst-case safety rates dropping below 6%. Text-to-image models show slightly stronger alignment in regulated visual risk categories, yet they too remain fragile when faced with adversarial or semantically ambiguous prompts. Overall, the results highlight that safety in frontier models is inherently multidimensional—shaped by modality, language, and evaluation design—underscoring the need for standardized, holistic safety assessments to better reflect real-world risk and guide responsible deployment.",21.16,28.546,604,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10543v1_Defending Large Language Models Against Jailbreak .pdf,Defending Large Language Models Against Jailbreak Attacks via In-Decoding Safety-Awareness Probing,"Yinzhi Zhao, Ming Wang, Shi Feng, Xiaocui Yang, Daling Wang, Yifei Zhang",,,"Large Language Models, Jailbreak Attacks, Safety Alignment, Decoding Process, Safety Signals, Content Detection","Large language models (LLMs) have shown impressive performance across various natural language tasks and are increasingly used in real-world applications. Despite efforts to align these models with safety standards, they remain vulnerable to jailbreak attacks. Current defense mechanisms, such as decoding-based constraints and post-hoc content detectors, often fail against sophisticated attacks, either by missing detections or by excessively reducing model utility. This paper explores the decoding process of LLMs and identifies latent safety-related signals that are present even during successful jailbreaks. These signals are typically overridden by the model's drive for fluent continuation, preventing self-correction. The authors propose a method to surface and utilize these latent safety signals for early detection of unsafe content during decoding. Experiments show that this approach significantly enhances safety while maintaining low over-refusal rates on benign inputs and preserving response quality. The results suggest that activating intrinsic safety-awareness during decoding is a promising direction for defending against jailbreak attacks.",18.09,17.746,321,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10560v1_Learning Latency-Aware Orchestration for Parallel .pdf,Learning Latency-Aware Orchestration for Parallel Multi-Agent Systems,"Xi Shi, Mengxin Zheng, Qian Lou",,,"Multi-Agent Systems, Latency-Aware Orchestration, Parallel Execution, Machine Learning, Inference Latency","Multi-agent systems (MAS) enable complex reasoning by coordinating multiple agents, but often incur high inference latency due to multi-step execution and repeated model invocations, severely limiting their scalability and usability in time-sensitive scenarios. Most existing approaches primarily optimize task performance and inference cost, and explicitly or implicitly assume sequential execution, making them less optimal for controlling latency under parallel execution. This work investigates the learning-based orchestration of multi-agent systems with explicit latency supervision under parallel execution. The proposed Latency-Aware Multi-agent System (LAMaS) framework enables parallel execution and explicitly optimizes the critical execution path, allowing the controller to construct execution topology graphs with lower latency under parallel execution. Experiments show that this approach reduces critical path length by 38–46% compared to the SOTA baseline for multi-agent architecture search across multiple benchmarks while maintaining or even improving task performance, highlighting the importance of explicitly optimizing for latency under parallel execution when designing efficient multi-agent systems.",17.57,15.939,280,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10562v1_Process-Guided Concept Bottleneck Model.pdf,Process-Guided Concept Bottleneck Model,"Reza M. Asiyabi, Sam Harrison, John L. Godlee, David Milodowski, Nicole H. Augustin, Penelope J. Mograbi, Timothy R. Baker, Lorena M. Benitez, Samuel J. Bowers, Thomas K. Brade, Joao M. B. Carreiras, Duncan M. Chalo, Vera De Cauwer, Kyle G. Dexter, Hermane Diesse, Mathias I. Disney, Luisa F. Escobar-Alvarado, Manfred Finckh, Tatenda Gotore, Gabriele C. Hegerl, John N. Kigomo, Fainess C. Lumbwe, Francisco Maiato, Rudzani A. Makhado, Collins W. Masinde, Musingo Tito E. Mbuvi, Iain M. McNicol, Edward T.A. Mitchard, Buster P. Mogonong, Wilson A. Mugasha, Aristides Baptista Muhate, Hinji Mutondo, Leena Naftal, Paula Nieto-Quintano, Elifuraha Elisha Njoghomi, Catherine L. Parr, Oliver L. Phillips, Pierre Proces, Tshililo Ramaswiela, Jayashree Ratnam, Mathew Rees, Rasmus Revermann, Natasha Ribeiro, Mahesh Sankaran, Abel M. Siampale, Stephen Sitch, Kathleen G. Smart, Hemant G. Tripathi, Wayne Twine, Gabriel I.K. Uusiku, Helga van der Merwe, Chemuku Wekesa, Benjamin J. Wigley, Mathew Williams, Ellie Wood, Emily Woollen, Shaun Quegan, Steven Hancock, Casey M. Ryan",,,,"This study introduces a Process-Guided Concept Bottleneck Model, supported by various grants and partnerships. The research involves contributions from numerous authors and acknowledges the use of AI-assisted tools for manuscript preparation. Corresponding author: Reza M. Asiyabi (reza.asiyabi@ed.ac.uk).",19.76,31.584,624,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10567v1_Generative AI collective behavior needs an interac.pdf,Generative AI collective behavior needs an interactionist paradigm,"Laura Ferrarotti, Gian Maria Campedelli, Roberto Dessì, Andrea Baronchelli, Giovanni Iacca, Kathleen M. Carley, Alex Pentland, Joel Z. Leibo, James Evans, Bruno Lepri",,2601.10567v1,cs.AI,"In this article, we argue that understanding the collective behavior of agents based on large language models (LLMs) is an essential area of inquiry, with important implications in terms of risks and benefits, impacting us as a society at many levels. We claim that the distinctive nature of LLMs–namely, their initialization with extensive pre-trained knowledge and implicit social priors, together with their capability of adaptation through in-context learning–motivates the need for an interactionist paradigm consisting of alternative theoretical foundations, methodologies, and analytical tools, in order to systematically examine how prior knowledge and embedded values interact with social context to shape emergent phenomena in multi-agent generative AI systems. We propose and discuss four directions that we consider crucial for the development and deployment of LLM-based collectives, focusing on theory, methods, and trans-disciplinary dialogue.",20.17,15.366,310,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10581v1_From Single to Multi-Agent Reasoning Advancing Gen.pdf,From Single to Multi-Agent Reasoning: Advancing GeneGPT for Genomics QA,"Kimia Abedini, Farzad Shami, Gianmaria Silvello",,arXiv:2601.10581v1,"Question Answering, Genomic QA, Multi-Agent Systems","Comprehending genomic information is essential for biomedical research, yet extracting data from complex distributed databases remains challenging. Large language models (LLMs) offer potential for genomic Question Answering (QA) but face limitations due to restricted access to domain-specific databases. GeneGPT is the current state-of-the-art system that enhances LLMs by utilizing specialized API calls, though it is constrained by rigid API dependencies and limited adaptability. We replicate GeneGPT and propose GenomAgent, a multi-agent framework that efficiently coordinates specialized agents for complex genomics queries. Evaluated on nine tasks from the GeneTuring benchmark, GenomAgent outperforms GeneGPT by 12% on average, and its flexible architecture extends beyond genomics to various scientific domains needing expert knowledge extraction.",18.33,14.569,267,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10587v1_Adversarial Evasion Attacks on Computer Vision usi.pdf,Adversarial Evasion Attacks on Computer Vision using SHAP Values,"Frank Mollard, Marcus Becker, Florian Röhrbein",,2601.10587v1,"adversarial attacks, computer vision, SHAP values, deep learning, misclassification, gradient hiding",The paper introduces a white-box attack on computer vision models using SHAP values. It demonstrates how adversarial evasion attacks can compromise the performance of deep learning models by reducing output confidence or inducing misclassifications. Such attacks are particularly insidious as they can deceive the perception of an algorithm while eluding human perception due to their imperceptibility to the human eye. The proposed attack leverages SHAP values to quantify the significance of individual inputs to the output at the inference stage. A comparison is drawn between the SHAP attack and the well-known Fast Gradient Sign Method. We find evidence that SHAP attacks are more robust in generating misclassifications particularly in gradient hiding scenarios.,19.16,11.85,227,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10591v1_ProbFM Probabilistic Time Series Foundation Model .pdf,ProbFM: Probabilistic Time Series Foundation Model with Uncertainty Decomposition,"Arundeep Chinta, Lucas Vinh Tran, Jay Katukuri",,,"Time Series Foundation Models, Uncertainty Quantification, Deep Evidential Regression, Epistemic-Aleatoric Decomposition, Financial Forecasting, Cryptocurrency Return Forecasting, Risk Management","Time Series Foundation Models (TSFMs) have shown promise in zero-shot financial forecasting due to their transferability and data efficiency. However, their adoption is limited by challenges in uncertainty quantification, such as restrictive distributional assumptions and lack of principled calibration. This paper introduces ProbFM, a novel transformer-based probabilistic framework that uses Deep Evidential Regression (DER) for principled uncertainty quantification with explicit epistemic-aleatoric decomposition. ProbFM learns optimal uncertainty representations through higher-order evidence learning while maintaining computational efficiency. An extensive comparison study using a consistent LSTM architecture across five probabilistic methods demonstrates DER's effectiveness. Evaluation on cryptocurrency return forecasting shows that DER maintains competitive accuracy and provides valuable uncertainty decomposition for risk management. This work establishes a framework for principled uncertainty quantification in foundation models and provides empirical evidence for DER's effectiveness in financial applications.",17.98,16.851,303,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10600v1_Procedural Fairness in Multi-Agent Bandits.pdf,Procedural Fairness in Multi-Agent Bandits,"Joshua Caiata, Carter Blair, Kate Larson",,2601.10600v1,"multi-agent multi-armed bandits, fairness, procedural fairness, equal decision-making power, psychology, economics, Rawlsian theory, multi-agent systems","In the context of multi-agent multi-armed bandits (MA-MAB), fairness is often reduced to outcomes such as maximizing welfare, reducing inequality, or balancing utilities. However, evidence from psychology, economics, and Rawlsian theory suggests that fairness also involves process and decision-making power. This paper introduces a new fairness objective, procedural fairness, which provides equal decision-making power for all agents, lies in the core, and ensures proportionality in outcomes. Empirical results show that outcome-based fairness notions sacrifice equal voice and representation, while the sacrifice in outcome-based fairness objectives is minimal under procedurally fair policies. The paper argues that procedural legitimacy deserves greater focus as a fairness objective and provides a framework for implementing procedural fairness.",18.0,15.108,272,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10611v1_Molmo2 Open Weights and Data for Vision-Language M.pdf,Open Weights and Data for Vision-Language Models with Video Understanding and Grounding,"Christopher Clark, Jieyu Zhang, Zixian Ma, Jae Sung Park, Mohammadreza Salehi, Rohun Tripathi, Sangho Lee, Zhongzheng Ren, Chris Dongjoo Kim, Yinuo Yang, Vincent Shao, Yue Yang, Weikai Huang, Ziqi Gao, Taira Anderson, Jianrui Zhang, Jitesh Jain, George Stoica, Winson Han, Ali Farhadi, Ranjay Krishna",,2601.10611v1,"cs.CV, video-language models, vision-language models, video understanding, grounding, open-source, video datasets, image datasets, video captioning, video Q&A, object tracking, video pointing, training recipe, bi-directional attention, token-weight strategy","Today’s strongest video-language models (VLMs) remain proprietary. The strongest open-weight models either rely on synthetic data from proprietary VLMs, effectively distilling from them, or do not disclose their training data or recipe. As a result, the open-source community lacks the foundations needed to improve on the state-of-the-art video (and image) language models. Crucially, many downstream applications require more than just high-level video understanding; they require grounding—either by pointing or by tracking in pixels. Even proprietary models lack this capability. We present Molmo2, a new family of VLMs that are state-of-the-art among open-source models and demonstrate exceptional new capabilities in point-driven grounding in single image, multi-image, and video tasks. Our key contribution is a collection of 7 new video datasets and 2 multi-image datasets, including a dataset of highly detailed video captions for pre-training, a free-form video Q&A dataset for fine-tuning, a new object tracking dataset with complex queries, and an innovative new video pointing dataset, all collected without the use of closed VLMs. We also present a training recipe for this data utilizing an efficient packing and message-tree encoding scheme, and show bi-directional attention on vision tokens and a novel token-weight strategy improves performance. Our best-in-class 8B model outperforms others in the class of open weight and data models on short videos, counting, and captioning, and is competitive on long-videos. On video-grounding Molmo2 significantly outperforms existing open-weight models like Qwen3-VL (35.5 vs 29.6 accuracy on video counting) and surpasses proprietary models like Gemini 3 Pro on some tasks (38.4 vs 20.0 F1 on video pointing and 56.2 vs 41.1J&Fon video tracking).",21.32,31.514,672,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10651v1_Multi-Property Synthesis.pdf,Multi-Property Synthesis,"Christoph Weinhuber, Yannik Schnitzer, Alessandro Abate, David Parker, Giuseppe De Giacomo, Moshe Y. Vardi",,,"LTLf synthesis, multiple properties, goal sets, symbolic algorithm, finite-horizon tasks, reactive synthesis, finite-trace variant, temporal specifications, over-subscription, multi-service orchestration","This paper studies LTLf synthesis with multiple properties, addressing scenarios where satisfying all properties may be impossible. Instead of enumerating subsets of properties, the authors compute the relation between product-game states and realizable goal sets in one fixed-point computation, synthesizing strategies for maximal realizable sets. A fully symbolic algorithm is developed, introducing Boolean goal variables and exploiting monotonicity to compactly represent many goal combinations. This approach significantly outperforms enumeration-based baselines, achieving speedups of up to two orders of magnitude. The paper highlights the limitations of the all-or-nothing paradigm in realistic scenarios like robotics and multi-service orchestration, where agents face over-subscription and conflicting requirements.",17.42,16.708,291,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10679v1_Are Your Reasoning Models Reasoning or Guessing A .pdf,Are Your Reasoning Models Reasoning or Guessing? A Mechanistic Analysis of Hierarchical Reasoning Models,"Zirui Ren, Ziming Liu",,,"Hierarchical Reasoning Model, Reasoning Patterns, Fixed Point Property, Grokking Dynamics, Data Augmentation, Input Perturbation, Model Bootstrapping, Sudoku-Extreme","Hierarchical reasoning model (HRM) achieves extraordinary performance on various reasoning tasks, significantly outperforming large language model-based reasoners. This study investigates HRM's reasoning patterns and identifies three surprising facts: (a) failure on extremely simple puzzles due to violation of the fixed point property, (b) 'grokking' dynamics in reasoning steps, and (c) existence of multiple fixed points where HRM 'guesses' the first fixed point, which could be incorrect. Leveraging this 'guessing' picture, strategies such as data augmentation, input perturbation, and model bootstrapping are proposed to scale HRM's guesses. The study develops Augmented HRM, boosting accuracy on Sudoku-Extreme from 54.5% to 96.9%, and provides new insights into how reasoning models 'reason'.",16.44,16.482,271,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10681v1_Structure and Diversity Aware Context Bubble Const.pdf,Structure and Diversity Aware Context Bubble Construction for Enterprise Retrieval,"Amir Khurshid, Abhishek Sehgal",,,"Large Language Model, Retrieval-Augmented Generation, Context Bubble, Retrieval","Large language model (LLM) contexts are typically constructed using retrieval-augmented generation (RAG), which involves ranking and selecting the top-k passages. This approach can cause fragmentation in information graphs, over-retrieval, and duplication of content, alongside insufficient query context. This paper proposes a structure-informed and diversity-constrained context bubble construction framework that assembles coherent, citable bundles of spans under a strict token budget. The method preserves and exploits inherent document structure by organizing multi-granular spans and using task-conditioned structural priors to guide retrieval. Starting from high-relevance anchor spans, a context bubble is constructed through constrained selection that balances query relevance, marginal coverage, and redundancy penalties. It explicitly constrains diversity and budget, producing compact and informative context sets, unlike top-k retrieval. A full retrieval is emitted that traces the scoring and selection choices of the records, providing auditability and deterministic tuning. Experiments on enterprise documents demonstrate the efficiency of context bubbles, significantly reducing redundant context, better covering secondary facets, and improving answer quality and citation faithfulness within a limited context window. Ablation studies show that both structural priors and diversity constraint selection are necessary; removing either component results in a decline in coverage and an increase in redundant or incomplete context.",18.62,17.722,330,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10684v1_On the origin of neural scaling laws from random g.pdf,On the origin of neural scaling laws: from random graphs to natural language,"Maissam Barkeshli, Alberto Alfarano, Andrey Gromov",,,"neural scaling laws, transformers, random walks, graphs, natural language, scaling exponents, Erdös-Renyi, scale-free Barabási-Albert, language modeling, parameterization","The paper explores the origin of neural scaling laws, particularly in transformers trained on random walks on graphs with tunable complexity. It demonstrates that neural scaling laws can arise even without power law structure in data correlations. The study systematically reduces the complexity of natural language by training on sequences from simplified generative language models, observing a monotonic evolution of scaling exponents. The research includes scaling laws from random walks on Erdös-Renyi and scale-free Barabási-Albert graphs, revisits conventional scaling laws for language modeling, and provides a critical analysis of various fits used in prior literature. It suggests that maximal update parameterization may be more parameter efficient than standard parameterization.",17.45,15.757,275,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10696v1_The Impact of Generative AI on Architectural Conce.pdf,"The Impact of Generative AI on Architectural Conceptual Design: Performance, Creative Self-Efficacy and Cognitive Load","Han Jiang, Yao Xiao, Rachel Hurley, Shichao Liu",,,"Visual communication, Architectural design, Learning, Performance Assessment, Hybrid Intelligence, Human-AI teaming","Our study examines how generative AI (GenAI) influences performance, creative self-efficacy, and cognitive load in architectural conceptual design tasks. Thirty-six student participants from Architectural Engineering and other disciplines completed a two-phase architectural design task, first independently and then with external tools (GenAI-assisted condition and control condition using an online repository of existing architectural projects). Design outcomes were evaluated by expert raters, while self-efficacy and cognitive load were self-reported after each phase. Difference-in-differences analyses revealed no overall performance advantage of GenAI across participants; however, subgroup analyses showed that GenAI significantly improved design performance for novice designers. In contrast, general creative self-efficacy declined for students using GenAI. Cognitive load did not differ significantly between conditions, though prompt usage patterns showed that iterative idea-generation and visual feedback prompts were linked to greater reduction in cognitive load. These findings suggest that GenAI’s effectiveness depends on users’ prior expertise and interaction strategies through prompting.",20.18,15.71,317,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10700v2_LIBERTy A Causal Framework for Benchmarking Concep.pdf,LIBERTy: A Causal Framework for Benchmarking Concept-Based Explanations of LLMs with Structural Counterfactuals,"Gilat Toker, Nitay Calderon, Ohad Amosy, Roi Reichart",,,"concept-based explanations, causal framework, LLMs, structural counterfactuals, explainability, causal effects, interventions, sensitivity analysis","Concept-based explanations quantify the influence of high-level concepts (e.g., gender or experience) on model behavior, crucial for decision-makers in high-stakes domains. Existing benchmarks rely on costly human-written counterfactuals as imperfect proxies. This paper introduces LIBERTy, a framework for constructing datasets with structural counterfactual pairs, grounded in Structured Causal Models (SCMs) of text generation. LIBERTy evaluates concept-based explanations across three datasets (disease detection, CV screening, workplace violence prediction) using a new metric, order-faithfulness. It identifies substantial room for improvement in concept-based explanations and enables systematic analysis of model sensitivity to interventions, revealing reduced sensitivity in proprietary LLMs to demographic concepts due to post-training mitigation. LIBERTy provides a benchmark for developing faithful explainability methods.",17.4,17.589,306,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10702v1_Grounding Agent Memory in Contextual Intent.pdf,Grounding Agent Memory in Contextual Intent,"Ruozhen Yang, Yucheng Jiang, Yueqi Jiang, Priyanka Kargupta, Yunyi Zhang, Jiawei Han",,,"large language models, long-horizon interactions, goal-oriented interactions, memory systems, contextual intent, retrieval cues, agentic memory, context-aware retrieval, CAME-Bench, LongMemEval","Deploying large language models in long-horizon, goal-oriented interactions remains challenging due to recurring similar entities and facts under different latent goals and constraints, leading to context-mismatched evidence retrieval. This paper introduces STITCH (StructuredIntentTracking in ContextualHistory), an agentic memory system that indexes each trajectory step with a structured retrieval cue, contextual intent, and retrieves history by matching the current step’s intent. Contextual intent provides compact signals to disambiguate repeated mentions and reduce interference, focusing on the current latent goal, action type, and salient entity types. STITCH filters and prioritizes memory snippets by intent compatibility, suppressing semantically similar but context-incompatible history. The paper introduces CAME-Bench, a benchmark for context-aware retrieval in realistic, dynamic, goal-oriented trajectories. STITCH achieves state-of-the-art performance across CAME-Bench and LongMemEval, outperforming the strongest baseline by 35.6%, with the largest gains as trajectory length increases. The analysis shows that intent indexing substantially reduces retrieval noise, supporting intent-aware memory for robust long-horizon reasoning.",18.38,20.568,378,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10712v1_MatchTIR Fine-Grained Supervision for Tool-Integra.pdf,MatchTIR: Fine-Grained Supervision for Tool-Integrated Reasoning via Bipartite Matching,"Changle Qu, Sunhao Dai, Hengyi Cai, Jun Xu, Shuaiqiang Wang, Dawei Yin",,,"Tool-Integrated Reasoning, Large Language Models, Reinforcement Learning, Bipartite Matching, Fine-Grained Supervision","Tool-Integrated Reasoning (TIR) empowers large language models (LLMs) to tackle complex tasks by interleaving reasoning steps with external tool interactions. Existing reinforcement learning methods typically rely on outcome- or trajectory-level rewards, assigning uniform advantages to all steps within a trajectory. This coarse-grained credit assignment fails to distinguish effective tool calls from redundant or erroneous ones, particularly in long-horizon multi-turn scenarios. To address this, MatchTIR introduces fine-grained supervision via bipartite matching-based turn-level reward assignment and dual-level advantage estimation. Credit assignment is formulated as a bipartite matching problem between predicted and ground-truth traces, utilizing two assignment strategies to derive dense turn-level rewards. A dual-level advantage estimation scheme integrates turn-level and trajectory-level signals, assigning distinct advantage values to individual interaction turns. Extensive experiments on three benchmarks demonstrate the superiority of MatchTIR, with a 4B model surpassing most 8B competitors, particularly in long-horizon and multi-turn tasks.",17.97,19.029,342,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10748v1_AnyECG Evolved ECG Foundation Model for Holistic H.pdf,AnyECG: Evolved ECG Foundation Model for Holistic Health Profiling,"Jun Li, Hongling Zhu, Yujie Xiao, Qinghao Zhao, Y alei Ke, Gongzheng Tang, Guangkun Nie, Deyun Zhang, Jin Li, Canqing Yu, Shenda Hong",,,"AI-ECG, electrocardiography, holistic health profiling, comorbidity, disease risk prediction, transfer learning, ECG foundation model","This study introduces AnyECG, an evolved ECG foundation model designed for holistic health profiling. Building on the ECGFounder model, AnyECG leverages a large-scale, multicenter ECG dataset to enhance capabilities in disease diagnosis, future risk prediction, and comorbidity identification. The model demonstrates robust performance across 1,172 ICD-coded conditions, achieving an AUROC above 0.7 for 306 diseases. The study highlights AnyECG's potential in comprehensive disease screening and long-term health risk assessment.",17.35,16.252,282,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10768v1_Optimisation of complex product innovation process.pdf,OPTIMISATION OF COMPLEX PRODUCT INNOVATION PROCESSES BASED ON TREND MODELS WITH THREE-VALUED LOGIC,"NINA BOCKOVÁ, BARBORA VOLNÁ, MIRKO DOHNAL",,2601.10768v1,"Complex product innovation, technological forecasting, three-valued logic, trend-based modelling, scenarios, transition graphs","This paper investigates complex product-innovation processes using models grounded in a set of heuristics. Each heuristic is expressed through simple trends – increasing, decreasing, or constant – which serve as minimally information-intensive quantifiers, avoiding reliance on numerical values or rough sets. A solution to a trend model is defined as a set of scenarios with possible transitions between them, represented by a transition graph. Any possible future or past behaviour of the system under study can thus be depicted by a path within this graph.",17.73,13.48,239,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10770v1_Unifying Speech Recognition Synthesis and Conversi.pdf,"UNIFYING SPEECH RECOGNITION, SYNTHESIS AND CONVERSION WITH AUTOREGRESSIVE TRANSFORMERS","Runyuan Cai, Yu Lin, Yiming Wang, Chunlin Fu, Xiaodong Zeng",,arXiv:2601.10770v1,"Text-to-Speech, Automatic Speech Recognition, Voice Conversion, Foundation Model","Traditional speech systems typically rely on separate, task-specific models for text-to-speech (TTS), automatic speech recognition (ASR), and voice conversion (VC), resulting in fragmented pipelines that limit scalability, efficiency, and cross-task generalization. In this paper, we present General-Purpose Audio (GPA), a unified audio foundation model that integrates multiple core speech tasks within a single large language model (LLM) architecture. GPA operates on a shared discrete audio token space and supports instruction-driven task induction, enabling a single autoregressive model to flexibly perform TTS, ASR, and VC without architectural modifications. This unified design combines a fully autoregressive formulation over discrete speech tokens, joint multi-task training across speech domains, and a scalable inference pipeline that achieves high concurrency and throughput. The resulting model family supports efficient multi-scale deployment, including a lightweight 0.3B-parameter variant optimized for edge and resource-constrained environments. Together, these design choices demonstrate that a unified autoregressive architecture can achieve competitive performance across diverse speech tasks while remaining viable for low-latency, practical deployment.",19.36,18.284,354,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10773v1_LogicLens Leveraging Semantic Code Graph to explor.pdf,LogicLens: Leveraging Semantic Code Graph to explore Multi Repository large systems,"Niko Usai, Dario Montagnini, Kristian Ilianov Iliev, Raffaele Camanzo",,,"semantic code graph, multi-repository systems, software knowledge graph, large language models, conversational agent, software navigation","Understanding large software systems is a challenging task, especially when code is distributed across multiple repositories and microservices. Developers often need to reason about the structure of the code, its domain logic, and runtime behaviors, which are typically implicit and scattered. LogicLens is introduced as a reactive conversational agent that assists developers in exploring complex software systems through a semantic multi-repository graph. This graph is built by combining syntactic code analysis with semantic enrichment using Large Language Models (LLMs). LogicLens enables developers to interact with the graph via natural language, dynamically retrieving relevant subgraphs and answering technical or functional queries. The system's architecture, emergent behaviors, and effectiveness on real-world scenarios are discussed, demonstrating capabilities like impact analysis and symptom-based debugging.",17.42,15.674,273,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10779v1_Unified Optimization of Source Weights and Transfe.pdf,Unified Optimization of Source Weights and Transfer Quantities in Multi-Source Transfer Learning: An Asymptotic Framework,"Qingyue Zhang, Chang Chu, Haohao Fu, Tianren Peng, Yanru Wu, Guanbo Huang, Yang Li, Shao-Lun Huang",,,"transfer learning, multi-source learning, asymptotic analysis, K-L divergence","Transfer learning is crucial for improving model performance in data-scarce scenarios. However, naive uniform transfer from multiple sources can lead to negative transfer, necessitating a balance of heterogeneous sources. Existing methods often optimize either source weights or transfer quantities, neglecting their joint consideration. This work introduces a theoretical framework, Unified Optimization of Weights and Quantities (UOWQ), which formulates multi-source transfer learning as a parameter estimation problem using an asymptotic analysis of a Kullback–Leibler divergence–based generalization error measure. The framework jointly determines optimal source weights and transfer quantities. It proves that using all available source samples is optimal with proper weight adjustment and provides closed-form solutions for single-source settings and a convex optimization-based procedure for multi-source cases. Practical algorithms for multi-source transfer and multi-task learning are proposed, with experiments on DomainNet and Office-Home benchmarks demonstrating UOWQ's superiority over strong baselines, validating both theoretical predictions and practical effectiveness.",17.98,17.351,312,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10810v1_Digital Metabolism Decoupling Logic from Facts via.pdf,Digital Metabolism: Decoupling Logic from Facts via Regenerative Unlearning Towards a Pure Neural Logic Core,"Mengmeng Peng, Zhenyu Fang, He Sun",,arXiv:2601.10810v1,"large language models, parameter entanglement, neural logic core, regenerative unlearning, deep-layer gradient reversal, chain-of-thought scaffolding, modular architectures","Large language models (LLMs) currently suffer from parameter entanglement, where general reasoning capabilities (logic) and specific factual knowledge (facts) exist in a superposition state within shared weights. This coupling leads to the 'memory wall,' where computational capacity is squandered on simulating retrieval, often resulting in hallucinations. This paper proposes 'digital metabolism,' a thermodynamic hypothesis suggesting that targeted forgetting is necessary for distilling a pure neural logic core. The Regenerative Logic-Core Protocol (RLCP), a dual-stream training framework, renders specific factual dependencies linearly undecodable via deep-layer gradient reversal. Applying RLCP to Qwen2.5-0.5B, a distinct phase transition is observed: the model achieves near-zero retention of targeted factual associations (Accuracy< 7%) while exhibiting changes consistent with an emergent 'structural crystallization' effect. Empirical analysis on GSM8K reveals that the 'metabolized' model spontaneously adopts chain-of-thought (CoT) scaffolding, interpreted as compensating for the loss of direct associative recall (shifting from O(1) recall to O(N) reasoning). While the causal mechanism underlying this behavioral shift requires further investigation, the findings provide a dynamic weight-level counterpart to architectural innovations like DeepSeek’s Engram, paving the way for modular 'Neural CPU + Symbolic RAM' architectures.",20.06,20.891,419,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10820v1_Towards Reliable ML Feature Engineering via Planni.pdf,Towards Reliable ML Feature Engineering via Planning in Constrained-Topology of LLM Agents,"Himanshu Thakur, Anusha Kamath, Anurag Muthyala, Dhwani Sanmukhani, Smruthi Mukund, Jay Katukuri",,arXiv:2601.10820v1,"ML Feature Engineering, LLM Agents, Code Generation, Human-AI Collaboration, Multi-Agent Framework","Recent advances in code generation models have unlocked unprecedented opportunities for automating feature engineering, yet their adoption in real-world ML teams remains constrained by critical challenges: (i) the scarcity of datasets capturing the iterative and complex coding processes of production-level feature engineering; (ii) limited integration and personalization of widely used coding agents, such as CoPilot and Devin, with a team’s unique tools, codebases, workflows, and practices; and (iii) suboptimal human-AI collaboration due to poorly timed or insufficient feedback. We address these challenges with a planner-guided, constrained-topology multi-agent framework that generates code for repositories in a multi-step fashion. The LLM-powered planner leverages a team’s environment, represented as a graph, to orchestrate calls to available agents, generate context-aware prompts, and use downstream failures to retroactively correct upstream artifacts. It can request human intervention at critical steps, ensuring generated code is reliable, maintainable, and aligned with team expectations. On a novel in-house dataset, our approach achieves 38% and 150% improvement in the evaluation metric over manually crafted and unplanned workflows respectively. In practice, when building features for recommendation models serving over 120 million users, our approach has delivered real-world impact by reducing feature engineering cycles from three weeks to a single day.",19.83,20.978,416,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10827v1_Approximately Optimal Global Planning for Contact-.pdf,Approximately Optimal Global Planning for Contact-Rich SE(2) Manipulation on a Graph of Reachable Sets,"Simin Liu, Tong Zhao, Bernhard Paus Graesdal, Peter Werner, Jiuguang Wang, John Dolan, Changliu Liu, Tao Pang",,,"Full-body manipulation, dexterous manipulation, manipulation planning",This paper introduces a new paradigm for computing approximately optimal manipulator plans in contact-rich manipulation (CRM). The approach involves constructing a graph of mutual reachable sets offline and planning over this graph online to sequence local plans for globally optimized motion. The method outperforms a leading planner by reducing task cost by 61% and achieves a 91% success rate across 250 queries while maintaining sub-minute query times. This demonstrates the practicality of globally optimized contact-rich manipulation for real-world tasks.,16.57,14.123,234,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10835v1_Can Vision-Language Models Understand Construction.pdf,Can Vision-Language Models Understand Construction Workers? An Exploratory Study,"Hieu Bui, Nathaniel E. Chodosh, Arash Tavakoli",,,"Large Language Model, Construction Automation, Robotics, Human Robot Interaction","As robotics become increasingly integrated into construction workflows, their ability to interpret and respond to human behavior is essential for safe and effective collaboration. Vision-Language Models (VLMs) have emerged as a promising tool for visual understanding tasks and offer the potential to recognize human behaviors without extensive domain-specific training. This study evaluates the performance of three leading VLMs—GPT-4o, Florence 2, and LLaVa-1.5—in detecting construction worker actions and emotions from static site images. Using a curated dataset of 1,000 images annotated across ten action and ten emotion categories, the study assesses each model’s outputs through standardized inference pipelines and multiple evaluation metrics. GPT-4o achieved the highest scores, while Florence 2 performed moderately, and LLaVa-1.5 showed the lowest overall performance. The study highlights limitations in current VLMs when applied to visually nuanced, domain-specific tasks and suggests that further improvements may be needed for real-world reliability. This study provides an initial benchmark and practical insights for deploying human-aware AI systems in complex, safety-critical settings.",18.29,17.608,322,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10880v1_Medical SAM3 A Foundation Model for Universal Prom.pdf,Medical SAM3: A Foundation Model for Universal Prompt-Driven Medical Image Segmentation,"Chongcong Jiang, Tianxingjian Ding, Chuhan Song, Jiachen Tu, Ziyang Yan, Yihua Shao, Zhenyi Wang, Yuzhang Shang, Tianyu Han, Yu Tian",,arXiv:2601.10880v1,"Medical Image Segmentation, Foundation Models, Fine-Tuning, SAM3","Promptable segmentation foundation models like SAM3 have shown strong generalization through interactive and concept-based prompting. However, their direct applicability to medical image segmentation is limited by domain shifts, lack of spatial prompts, and complex anatomical structures. This paper introduces Medical SAM3, a foundation model for universal prompt-driven medical image segmentation, achieved by fine-tuning SAM3 on large-scale, heterogeneous 2D and 3D medical imaging datasets with paired segmentation masks and text prompts. The study reveals that SAM3's performance on medical data is hindered by reliance on geometric priors like ground-truth-derived bounding boxes. By fine-tuning SAM3 on 33 datasets across 10 medical imaging modalities, Medical SAM3 acquires robust domain-specific representations while maintaining prompt-driven flexibility. Experiments show consistent performance improvements, especially in scenarios with semantic ambiguity, complex morphology, and long-range 3D context. The results establish Medical SAM3 as a universal, text-guided segmentation foundation model for medical imaging, emphasizing the need for holistic model adaptation to achieve robust prompt-driven segmentation under domain shifts.",19.75,19.188,379,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10904v1_ARC Prize 2025 Technical Report.pdf,ARC Prize 2025: Technical Report,"François Chollet, Mike Knoop, Gregory Kamradt, Bryan Landers",,,"ARC-AGI, AGI, benchmark, fluid intelligence, abstract reasoning, refinement loop, zero-pretraining, deep learning, knowledge coverage, interactive reasoning","The ARC-AGI benchmark series measures few-shot generalization on novel tasks, a core aspect of intelligence. The ARC Prize 2025 competition focused on the ARC-AGI-2 dataset, which has greater task complexity. The competition attracted 1,455 teams and 15,154 entries, with the top score reaching 24% on the private evaluation set. Paper submissions increased to 90, reflecting growing research interest. The defining theme of 2025 is the emergence of the refinement loop, an iterative program optimization loop guided by feedback. Refinement loops appear in various forms, including evolutionary program synthesis and application-layer refinements to commercial AI systems. Zero-pretraining deep learning methods are achieving competitive performance with small networks. Four frontier AI labs reported ARC-AGI performance, establishing it as an industry standard benchmark. However, current AI reasoning performance is constrained to knowledge coverage, leading to benchmark contamination. The paper surveys top-performing methods, examines refinement loops in AGI progress, discusses knowledge-dependent overfitting, and previews ARC-AGI-3, which introduces interactive reasoning challenges.",18.22,17.729,323,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10917v1_Self-learned representation-guided latent diffusio.pdf,SELF-LEARNED REPRESENTATION-GUIDED LATENT DIFFUSION MODEL FOR BREAST CANCER CLASSIFICATION IN DEEP ULTRA VIOLET WHOLE SURFACE IMAGES,"Pouya Afshin, David Helminiak, Tianling Niu, Julie M. Jorns, Tina Yen, Bing Yu, Dong Hye Ye",,,"Breast Cancer Classification, Latent Diffusion Model, Self-Supervised Learning, Data Augmentation, Deep Ultraviolet Fluorescence Scanning Microscopy, Vision Transformer, Patch Prediction Aggregation","Breast-Conserving Surgery (BCS) requires precise intraoperative margin assessment to preserve healthy tissue. Deep Ultraviolet Fluorescence Scanning Microscopy (DUV-FSM) offers rapid, high-resolution surface imaging for this purpose; however, the scarcity of annotated DUV data hinders the training of robust deep learning models. To address this, we propose an Self-Supervised Learning (SSL)-guided Latent Diffusion Model (LDM) to generate high-quality synthetic training patches. By guiding the LDM with embeddings from a fine-tuned DINO teacher, we inject rich semantic details of cellular structures into the synthetic data. We combine real and synthetic patches to fine-tune a Vision Transformer (ViT), utilizing patch prediction aggregation for WSI-level classification. Experiments using 5-fold cross-validation demonstrate that our method achieves 96.47% accuracy and reduces the FID score to 45.72, significantly outperforming class-conditioned baselines.",18.5,20.595,381,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10921v1_RobuMTL Enhancing Multi-Task Learning Robustness A.pdf,RobuMTL: Enhancing Multi-Task Learning Robustness Against Weather Conditions,"Tasneem Shaffee, Sherief Reda",,,"Multi-Task Learning, Robustness, Weather Conditions, Low-Rank Adaptation, Mixture-of-Experts","Robust Multi-Task Learning (MTL) is crucial for autonomous systems operating in real-world environments, where adverse weather conditions can severely degrade model performance and reliability. This paper introduces RobuMTL, a novel architecture designed to adaptively address visual degradation by dynamically selecting task-specific hierarchical Low-Rank Adaptation (LoRA) modules and a LoRA expert squad based on input perturbations in a mixture-of-experts fashion. The framework enables adaptive specialization based on input characteristics, improving robustness across diverse real-world conditions. Evaluations on the PASCAL and NYUD-v2 datasets show significant improvements over single-task models, standard MTL baselines, and state-of-the-art methods, with notable gains under mixed weather conditions.",16.0,14.684,235,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10922v1_What Matters in Data Curation for Multimodal Reaso.pdf,What Matters in Data Curation for Multimodal Reasoning? Insights from the DCVLR Challenge,"Yosub Shin, Michael Buriek, Boris Sobolev, Pavel Bushuyeu, Vikas Kumar, Haoyang Xu, Samuel Watson, Igor Molybog",,,"data curation, multimodal reasoning, DCVLR challenge, dataset selection, example difficulty, alignment, saturation regime","This paper explores data curation for multimodal reasoning through the NeurIPS 2025 Data Curation for Vision-Language Reasoning (DCVLR) challenge. The challenge isolates dataset selection by fixing the model and training protocol. The authors' submission, using a curated dataset from Walton Multimodal Cold Start, placed first in the challenge. Post-competition analysis revealed that difficulty-based example selection on an aligned base dataset is the primary driver of performance gains. Increasing dataset size mainly reduces variance rather than improving accuracy, and common diversity and synthetic augmentation heuristics often degrade performance. The study highlights the importance of alignment and difficulty in data-efficient multimodal reasoning.",17.04,15.38,262,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10926v1_Selecting Language Models for Social Science Start.pdf,"Selecting Language Models for Social Science: Start Small, Start Open, and Validate","Dustin S. Stoltz, Marshall A. Taylor, Sanuj Kumar",,,"large language models, LLMs, reproducibility, replicability, model openness","Currently, there are thousands of large pretrained language models (LLMs) available to social scientists. This paper explores how to select among them using validity, reliability, reproducibility, and replicability as guides. It discusses the significance of model openness, model footprint, training data, and model architectures and fine-tuning. The authors argue for starting with smaller, open models and constructing delimited benchmarks to validate the computational pipeline. The paper also addresses the sparse use of LLMs in sociological research and anticipates changes as norms develop around their role in research workflows.",15.52,12.886,200,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10931v1_Sparse Data Tree Canopy Segmentation Fine-Tuning L.pdf,Sparse Data Tree Canopy Segmentation: Fine-Tuning Leading Pretrained Models on Only 150 Images,"David Szczecina, Niloofar Azad, Hudson Sun, Kyle Gao, Anthony Bertnyk, Lincoln Linlin Xu",,,"Deep Learning, Computer Vision, Object Segmentation, Remote Sensing, Forestry, Tree Canopy","Tree canopy detection from aerial imagery is crucial for environmental monitoring, urban planning, and ecosystem analysis. The Solafune Tree Canopy Detection competition provides a small and imbalanced dataset of only 150 annotated images, posing challenges for training deep models without overfitting. This study evaluates five architectures: YOLOv11, Mask R-CNN, DeepLabv3, Swin-UNet, and DINOv2, to assess their suitability for canopy segmentation under data scarcity. Pretrained convolution-based models, particularly YOLOv11 and Mask R-CNN, generalize better than transformer-based models. DeeplabV3, Swin-UNet, and DINOv2 underperform due to differences between semantic and instance segmentation tasks, high data requirements of Vision Transformers, and lack of strong inductive biases. The findings confirm that transformer-based architectures struggle in low-data regimes without substantial pretraining or augmentation. The study provides a detailed analysis of training strategies, augmentation policies, and model behavior under small-data constraints, demonstrating that lightweight CNN-based methods remain most reliable for canopy detection on limited imagery.",18.43,19.479,359,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10945v1_PatientVLM Meets DocVLM Pre-Consultation Dialogue .pdf,PatientVLM Meets DocVLM: Pre-Consultation Dialogue Between Vision-Language Models for Efficient Diagnosis,"K Lokesh, Abhirama Subramanyam Penamakuri, Uday Agarwal, Apoorva Challa, Shreya K Gowda, Somesh Gupta, Anand Mishra",,,"AI in medical diagnosis, vision-language models, pre-consultation dialogue framework, diagnostic dialogues, symptom elicitation, image analysis, clinical validation","This paper introduces a Pre-Consultation Dialogue Framework (PCDF) that simulates diagnostic dialogues between two vision-language models (VLMs): a DocVLM and a PatientVLM. The DocVLM generates follow-up questions based on image and dialogue history, while the PatientVLM responds using a symptom profile derived from the ground-truth diagnosis. The framework aims to improve diagnostic accuracy by incorporating patient-reported symptoms. A small-scale clinical validation confirmed the clinical relevance and realism of the synthetic symptoms generated. The study shows that dialogue-based supervision leads to significant improvements over image-only training, emphasizing the importance of realistic symptom elicitation in diagnosis.",16.83,17.524,295,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10951v1_Multi-Stage Patient Role-Playing Framework for Rea.pdf,Multi-Stage Patient Role-Playing Framework for Realistic Clinical Interactions,"Shijie Jiang, Zefan Jiang, Kehua Zhu, Tian Bai, Ruihong Zhao",,2601.10951v1,"Patient Role-Playing, Large Language Models, Clinical","The simulation of realistic clinical interactions plays a pivotal role in advancing clinical Large Language Models (LLMs) and supporting medical diagnostic education. Existing approaches and benchmarks rely on generic or LLM-generated dialogue data, which limits the authenticity and diversity of doctor-patient interactions. In this work, we propose the first Chinese patient simulation dataset (Ch-PatientSim), constructed from realistic clinical interaction scenarios to comprehensively evaluate the performance of models in emulating patient behavior. Patients are simulated based on a five-dimensional persona structure. To address issues of the persona class imbalance, a portion of the dataset is augmented using few-shot generation, followed by manual verification. We evaluate various state-of-the-art LLMs and find that most produce overly formal responses that lack individual personality. To address this limitation, we propose a training-free Multi-Stage Patient Role-Playing (MSPRP) framework, which decomposes interactions into three stages to ensure both personalization and realism in model responses. Experimental results demonstrate that our approach significantly improves model performance across multiple dimensions of patient simulation. Our dataset is available at https://github.com/SerajJon/MSPRP.",20.04,16.916,339,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10955v1_Beyond Max Tokens Stealthy Resource Amplification .pdf,Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents,"Kaiyu Zhou, Yongsen Zheng, Yicheng He, Meng Xue, Xueluan Gong, Yuji Wang, Kwok-Yan Lam",,,"Large Language Models, LLM Agents, Tool Calling, Agent Security, Economic Denial-of-Service","The agent-tool communication loop is a critical attack surface in modern Large Language Model (LLM) agents. Existing Denial-of-Service (DoS) attacks, primarily triggered via user prompts or injected retrieval-augmented generation (RAG) context, are ineffective for this new paradigm. They are fundamentally single-turn and often lack a task-oriented approach, making them conspicuous in goal-oriented workflows and unable to exploit the compounding costs of multi-turn agent-tool interactions. We introduce a stealthy, multi-turn economic DoS attack that operates at the tool layer under the guise of a correctly completed task. Our method adjusts text-visible fields and a template-governed return policy in a benign, Model Context Protocol (MCP)-compatible tool server, optimizing these edits with a Monte Carlo Tree Search (MCTS) optimizer. These adjustments leave function signatures unchanged and preserve the final payload, steering the agent into prolonged, verbose tool-calling sequences using text-only notices. This compounds costs across turns, escaping single-turn caps while keeping the final answer correct to evade validation. Across six LLMs on the ToolBench and BFCL benchmarks, our attack expands tasks into trajectories exceeding 60,000 tokens, inflates costs by up to 658 ×, and raises energy by 100–560 ×. It drives GPU KV cache occupancy from <1% to 35–74% and cuts co-running throughput by approximately 50%. Because the server remains protocol-compatible and the task outcomes are correct, conventional checks fail. These results elevate the agent-tool interface to a first-class security frontier, demanding a paradigm shift from validating final answers to monitoring the economic and computational cost of the entire agentic process.",19.56,24.383,477,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.10960v1_Steering Language Models Before They Speak Logit-L.pdf,Steering Language Models Before They Speak: Logit-Level Interventions,"Hyeseon An, Shinwoo Park, Hyundong Jin, Yo-Sub Han",,,"language models, logit-level interventions, controllable generation, text rewriting, toxicity mitigation, statistical token score table, z-normalized log-odds","Steering LLMs is essential for specialized applications such as style-sensitive text rewriting, user-adaptive communication, and toxicity mitigation. Current steering methods, such as prompting-based and activation-based approaches, are widely used to guide model behavior. However, activation-based techniques require deep access to internal layers, while prompting-based steering often fails to provide consistent or fine-grained control. To address these limitations, a training-free inference-time logit intervention for controllable generation is proposed. This approach utilizes a statistical token score table derived from z-normalized log-odds of labeled corpora to shift the decoding distribution. Empirical evaluations across three diverse datasets focusing on writing complexity, formality, and toxicity demonstrate that the method effectively steers output characteristics, confirming its broad applicability and task-agnostic nature. Results show that statistically grounded logit steering can achieve large, consistent, and multitask control gains: up to +47% accuracy and 50× F1 improvement.",17.97,17.914,322,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11000v1_When Personalization Misleads Understanding and Mi.pdf,When Personalization Misleads: Understanding and Mitigating Hallucinations in Personalized LLMs,"Zhongxiang Sun, Yi Zhan, Chenglei Shen, Weijie Yu, Xiao Zhang, Ming He, Jun Xu",,,"Personalized LLMs, hallucinations, factual reasoning, personalization-induced hallucinations, Factuality-Preserving Personalized Steering (FPPS), PFQABench","Personalized large language models (LLMs) adapt model behavior to individual users to enhance user satisfaction, yet personalization can inadvertently distort factual reasoning. This paper shows that personalized LLMs can generate answers aligned with a user’s prior history rather than the objective truth, resulting in personalization-induced hallucinations that degrade factual reliability. To address this issue, the authors propose Factuality-Preserving Personalized Steering (FPPS), a lightweight inference-time approach that mitigates personalization-induced factual distortions while preserving personalized behavior. They also introduce PFQABench, the first benchmark designed to jointly evaluate factual and personalized question answering under personalization. Experiments across multiple LLM backbones and personalization methods show that FPPS substantially improves factual accuracy while maintaining personalized performance.",17.55,16.184,284,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11007v1_AdaMARP An Adaptive Multi-Agent Interaction Framew.pdf,AdaMARP: An Adaptive Multi-Agent Interaction Framework for General Immersive Role-Playing,"Zhenhua Xu, Dongsheng Chen, Shuo Wang, Jian Li, Chengjie Wang, Meng Han, Yabiao Wang",,2601.11007v1,"immersive role-playing, multi-agent interaction, large language models, narrative coherence, environment modeling","AdaMARP is an adaptive multi-agent interaction framework designed to enhance immersion and adaptability in LLM role-playing. It introduces an immersive message format and a Scene Manager to better model dynamic environments and multi-character interactions. The framework is trained using AdaRPSet and AdaSMSet datasets, showing improvements in character consistency, environment grounding, and narrative coherence. Experiments demonstrate AdaMARP's superiority over several commercial LLMs in handling scene transitions and role introductions.",15.66,15.002,235,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11012v1_Efficient Protein Optimization via Structure-aware.pdf,Efficient Protein Optimization via Structure-aware Hamiltonian Dynamics,"Jiahao Wang, Shuangjia Zheng",,,"protein optimization, Hamiltonian dynamics, Bayesian optimization, epistasis effect, structural constraints, protein engineering, machine learning, protein language models, structural-informed models","The paper introduces HADES, a Bayesian optimization method utilizing Hamiltonian dynamics to efficiently sample from a structure-aware approximated posterior for protein optimization. It addresses the challenges of high-dimensional complexities and structural constraints in sequence-based optimization methods. HADES leverages momentum and uncertainty in simulated physical movements to transition proposals toward promising areas, using a position discretization procedure to propose discrete protein sequences. The method employs a two-stage encoder-decoder framework to learn structure-function relationships and a smoothed landscape for sampling. Extensive experiments show that HADES outperforms state-of-the-art baselines in in-silico evaluations, offering advantages by leveraging the mutual constraints between protein structure and sequence. The approach facilitates the design of protein sequences with similar structures and optimized properties. The code and data are publicly available.",17.4,15.802,275,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11016v1_Contextual Distributionally Robust Optimization wi.pdf,Contextual Distributionally Robust Optimization with Causal and Continuous Structure: An Interpretable and Tractable Approach,"Fenglin Zhang, Jie Wang",,2601.11016v1,"Contextual distributionally robust optimization, Causal Sinkhorn discrepancy, Soft regression forest, Stochastic compositional optimization","This paper introduces a framework for contextual distributionally robust optimization (DRO) that incorporates the causal and continuous structure of the underlying distribution. It develops interpretable and tractable decision rules using covariates. The causal Sinkhorn discrepancy (CSD), an entropy-regularized causal Wasserstein distance, is introduced to encourage continuous transport plans while preserving causal consistency. The paper formulates a contextual DRO model with a CSD-based ambiguity set, termed Causal Sinkhorn DRO (Causal-SDRO), and derives its strong dual reformulation. The worst-case distribution is characterized as a mixture of Gibbs distributions. To solve the corresponding infinite-dimensional policy optimization, the Soft Regression Forest (SRF) decision rule is proposed, which approximates optimal policies within arbitrary measurable function spaces. The SRF maintains the interpretability of classical decision trees while being fully parametric, differentiable, and Lipschitz smooth, allowing intrinsic interpretation from both global and local perspectives. An efficient stochastic compositional gradient algorithm is developed to solve the Causal-SDRO with parametric decision rules, converging to an ε-stationary point at a rate of O(ε−4). The method is validated through numerical experiments on synthetic and real-world datasets, demonstrating superior performance and interpretability.",19.83,18.359,364,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11019v1_Finding the Translation Switch Discovering and Exp.pdf,Finding the Translation Switch: Discovering and Exploiting the Task-Initiation Features in LLMs,"Xinwei Wu, Heng Liu, Xiaohu Zhao, Yuqi Ren, Linlong Xu, Longyue Wang, Deyi Xiong, Weihua Luo, Kaifu Zhang",,,"Large Language Models, translation, Sparse Autoencoders, task-specific features, PCA-based consistency metric, causal interventions, data selection strategy, fine-tuning, hallucinations, mechanistic insight","Large Language Models (LLMs) often exhibit strong translation abilities without task-specific fine-tuning. This study uses Sparse Autoencoders (SAEs) to identify 'translation initiation' features that are crucial for translation tasks. By amplifying these features, the model's translation accuracy improves, while ablating them causes hallucinations. The study proposes a data selection strategy for efficient fine-tuning by focusing on 'mechanistically hard' samples. This approach enhances data efficiency and reduces hallucinations, with findings applicable to larger models of the same family. The research decodes a core component of the translation mechanism in LLMs and offers a blueprint for creating more robust and efficient models.",17.91,17.809,319,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11021v1_Combating Spurious Correlations in Graph Interpret.pdf,Combating Spurious Correlations in Graph Interpretability via Self-Reflection,"Kecheng Cai, Chenyang Xu, Chao Peng",,,"interpretable graph learning, spurious correlations, self-reflection, graph neural networks, graph representation learning","Interpretable graph learning aims to identify crucial nodes and edges in graphs for specific tasks. The Spurious-Motif benchmark, known for its challenging spurious correlations, highlights the difficulty models face in distinguishing relevant structures. This paper introduces a self-reflection framework, inspired by techniques in large language models, to improve interpretability in such datasets. By iteratively evaluating importance scores for nodes and edges, the framework enhances performance on Spurious-Motif and other benchmarks. The approach is analyzed from a graph representation learning perspective, leading to a fine-tuning method that further boosts performance. This work contributes to making graph neural networks more transparent and trustworthy, especially in critical applications like drug discovery, social network analysis, and fraud detection.",16.68,13.792,230,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11030v1_IDDR-NGP Incorporating Detectors for Distractor Re.pdf,IDDR-NGP: Incorporating Detectors for Distractor Removal with Instant Neural Radiance Field,"Xianliang Huang, Jiajie Gou, Shuhang Chen, Zhizhou Zhong, Jihong Guan, Shuigeng Zhou",10.1145/3581783.3612045,2601.11030v1,"Computer vision, Reconstruction, Computer graphics, Image processing, Image representations, Object detection","This paper introduces IDDR-NGP, a unified distractor removal method that operates on Instant-NPG. It efficiently removes various distractors in 3D scenes, such as snowflakes, confetti, defoliation, and petals, by integrating implicit 3D representations with 2D detectors. The method employs learned perceptual image patch similarity (LPIPS) loss and multi-view compensation loss (MVCL) to optimize rendering results, supporting end-to-end training for high-quality 3D scene synthesis. A new benchmark dataset with synthetic and real-world distractors is introduced to validate the method's effectiveness and robustness. Experimental results demonstrate IDDR-NGP's capability to remove multiple distractor types and achieve results comparable to state-of-the-art desnow methods.",17.33,18.232,316,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11035v1_Your One-Stop Solution for AI-Generated Video Dete.pdf,Your One-Stop Solution for AI-Generated Video Detection,"Long Ma, Zihao Xue, Yan Wang, Zhiyuan Yan, Jin Xu, Xiaorui Jiang, Haiyang Yu, Yong Liao, Zhen Bi",,arXiv:2601.11035v1,"Text To Video, Image To Video Network, Video Image, Mainstream Detectors, Accuracy, AUC, Relevance, Vehicles, Quantity, Scenery, Judgement, Imaging Quality, Motion Smoothness, Diverse Video Content, Comprehensive Evaluations, VLM, Fundamental Question, People, Animals, Buildings, Plants Food, Spatial, Major Content, Color, Attribute Control, Temporal, Motion Direction, Speed, Evaluations, Real, Multiple Tasks, Numerous Advanced models, Video To Video, AIGVD, Bench, Insightful Analyses","Recent advances in generative modeling can create remarkably realistic synthetic videos, making it increasingly difficult for humans to distinguish them from real ones and necessitating reliable detection methods. However, two key limitations hinder the development of this field. From the dataset perspective, existing datasets are often limited in scale and constructed using outdated or narrowly scoped generative models, making it difficult to capture the diverse range of synthetic videos. This paper proposes a comprehensive solution for AI-generated video detection, addressing these limitations by introducing a large-scale dataset and advanced detection models. The study evaluates various factors contributing to the undetectability of synthetic videos, such as imaging quality, motion smoothness, and diverse video content. It also explores the challenges in detecting more advanced synthetic videos and provides insightful analyses on the effectiveness of different detection methods.",20.52,23.052,473,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11037v1_BAPO Boundary-Aware Policy Optimization for Reliab.pdf,BAPO: Boundary-Aware Policy Optimization for Reliable Agentic Search,"Shiyu Liu, Yongjing Yin, Jianhao Yan, Yunbo Tang, Qinggang Zhang, Bei Li, Xin Chen, Jingang Wang, Xunliang Cai, Jinsong Su",,,"RL-based agentic search, reinforcement learning, Large Language Models, boundary awareness, reliability, policy optimization","RL-based agentic search enhances accuracy in solving complex questions through dynamic planning and external search. However, it often lacks reliability, failing to recognize reasoning boundaries and rarely admitting 'I DON'T KNOW' (IDK) when evidence is insufficient. This paper introduces Boundary-Aware Policy Optimization (BAPO), a novel RL framework that improves reliability without compromising accuracy. BAPO includes a boundary-aware reward and an adaptive reward modulator to encourage appropriate IDK responses and prevent their misuse during early exploration. Experiments on four benchmarks show BAPO's effectiveness in enhancing agentic search reliability.",17.08,16.038,274,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11042v1_Spectral Characterization and Mitigation of Sequen.pdf,Spectral Characterization and Mitigation of Sequential Knowledge Editing Collapse,"Chi Zhang, Mengqi Zhang, Xiaotian Ye, Runxi Cheng, Zisheng Zhou, Ying Zhou, Pengjie Ren, Zhumin Chen",,,"spectral analysis, knowledge editing, large language models, parameter modification, sequential editing, model collapse, general abilities, singular subspace, REVIVE framework","Sequential knowledge editing in large language models often leads to a catastrophic collapse of the model's general abilities, particularly with parameter-modifying methods. This study presents a spectral analysis of sequential knowledge editing, revealing that a model's general abilities are closely linked to the dominant singular directions of pretrained weight matrices. These directions are sensitive to perturbations and are disrupted by repeated edits, correlating with declines in editing efficacy and general performance. The proposed REVIVE framework stabilizes sequential editing by preserving the dominant singular subspace, representing parameter updates in the spectral basis of the original weights and filtering components that interfere with the protected region. Extensive experiments demonstrate that REVIVE improves editing efficacy while preserving general abilities under long-horizon sequential editing, including scenarios with up to 20,000 edits.",17.83,17.22,307,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11044v2_AgencyBench Benchmarking the Frontiers of Autonomo.pdf,AGENCYBENCH: Benchmarking the Frontiers of Autonomous Agents in 1M-Token Real-World Contexts,"Keyu Li, Junhao Shi, Yang Xiao, Mohan Jiang, Jie Sun, Yunze Wu, Dayuan Fu, Shijie Xia, Xiaojie Cai, Tianze Xu, Weiye Si, Wenjie Li, Dequan Wang, Pengfei Liu",,arXiv:2601.11044v2,"Large Language Models, autonomous agents, benchmark, real-world scenarios, user simulation, Docker sandbox, agentic capabilities","Large Language Models (LLMs) based autonomous agents demonstrate multifaceted capabilities to contribute substantially to economic production. However, existing benchmarks remain focused on single agentic capability, failing to capture long-horizon real-world scenarios. Moreover, the reliance on human-in-the-loop feedback for realistic tasks creates a scalability bottleneck, hindering automated rollout collection and evaluation. To bridge this gap, we introduce AGENCYBENCH, a comprehensive benchmark derived from daily AI usage, evaluating 6 core agentic capabilities across 32 real-world scenarios, comprising 138 tasks with specific queries, deliverables, and rubrics. These scenarios require an average of 90 tool calls, 1 million tokens, and hours of execution time to resolve. To enable automated evaluation, we employ a user simulation agent to provide iterative feedback, and a Docker sandbox to conduct visual and functional rubric-based assessment. Experiments reveal that closed-source models significantly outperform open-source models (48.4% vs 32.1%). Further analysis reveals significant disparities across models in resource efficiency, feedback-driven self-correction, and specific tool-use preferences. Finally, we investigate the impact of agentic scaffolds, observing that proprietary models demonstrate superior performance within their native ecosystems (e.g., Claude-4.5-Opus via Claude-Agent-SDK), while open-source models exhibit distinct performance peaks, suggesting potential optimization for specific execution frameworks. AGENCYBENCH serves as a critical testbed for next-generation agents, highlighting the necessity of co-optimizing model architecture with agentic frameworks. We believe this work sheds light on the future direction of autonomous agents, and to facilitate community adoption, we release the full benchmark and evaluation toolkit at https://github.com/GAIR-NLP/AgencyBench.",20.18,27.657,558,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11049v1_Predicting Biased Human Decision-Making with Large.pdf,Predicting Biased Human Decision-Making with Large Language Models in Conversational Settings,"Stephen Pilli, Vivek Nallur",,,"Conversational AI, Framing Effect, Status Quo Bias, LLM Simulation","This study investigates whether large language models (LLMs) can predict biased decision-making in conversational settings, focusing on cognitive biases like the Framing Effect and Status Quo Bias. A pre-registered study with 1,648 participants used a chatbot to administer decision-making tasks with varying dialogue complexity. Results showed that increased cognitive load amplified these biases. LLMs, particularly GPT-4, were able to predict individual decisions with significant accuracy, replicating human bias patterns and load-bias interactions. These findings enhance our understanding of LLMs in simulating human decision-making and inform the design of adaptive conversational agents.",16.24,13.789,224,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11063v1_H-AIM Orchestrating LLMs PDDL and Behavior Trees f.pdf,"H-AIM: Orchestrating LLMs, PDDL, and Behavior Trees for Hierarchical Multi-Robot Planning","Haishan Zeng, Peng Li",,arXiv:2601.11063v1,"multi-robot planning, large language models, PDDL, behavior trees, heterogeneous robot teams, long-horizon tasks, dynamic environments","In embodied artificial intelligence, enabling heterogeneous robot teams to execute long-horizon tasks from high-level instructions remains a critical challenge. While large language models (LLMs) show promise in instruction parsing and preliminary planning, they exhibit limitations in long-term reasoning and dynamic multi-robot coordination. This paper proposes Hierarchical Autonomous Intelligent Multi-Robot Planning (H-AIM), a novel framework that addresses these issues through a three-stage cascaded architecture: 1) leveraging an LLM to parse instructions and generate Planning Domain Definition Language (PDDL) problem descriptions, 2) combining the semantic reasoning of LLMs with the search capabilities of a classical planner to produce optimized action sequences, and 3) compiling the resulting plan into behavior trees for reactive control. The framework supports dynamically sized heterogeneous robot teams via a shared blackboard mechanism for communication and state synchronization. The MACE-THOR benchmark dataset, comprising 42 complex tasks across 8 distinct household layouts, is introduced to validate the approach. Experimental results demonstrate that H-AIM achieves a remarkable performance improvement, elevating the task success rate from 12% to 55% and boosting the goal condition recall from 32% to 72% against the strongest baseline, LaMMA-P.",18.8,20.324,382,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11065v1_Fairness in Healthcare Processes A Quantitative An.pdf,Fairness in Healthcare Processes: A Quantitative Analysis of Decision Making in Triage,"Rachmadita Andreswari, Stephan A. Fahrenkrog-Petersen, Jan Mendling",,2601.11065v1,"process mining, fairness, triage, emergency room","Fairness in automated decision-making has become a critical concern, particularly in high-pressure healthcare scenarios such as emergency triage, where fast and equitable decisions are essential. Process mining is increasingly investigating fairness. There is a growing area focusing on fairness-aware algorithms. This study addresses the research problem and proposes a process mining approach to assess fairness in triage by linking real-life event logs with conceptual dimensions of justice. Using the MIMICEL event log (as derived from MIMIC-IV ED), the study analyzes time, re-do, deviation, and decision as process outcomes, and evaluates the influence of age, gender, race, language, and insurance using the Kruskal–Wallis, Chi-square, and effect size measurements. These outcomes are mapped to justice dimensions to support the development of a conceptual framework. The results demonstrate which aspects of potential unfairness in high-acuity and sub-acute surface, contributing empirical insights that support further research in responsible, fairness-aware process mining in healthcare.",18.8,16.595,312,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11073v1_Bridging Cognitive Neuroscience and Graph Intellig.pdf,Bridging Cognitive Neuroscience and Graph Intelligence: Hippocampus-Inspired Multi-View Hypergraph Learning for Web Finance Fraud,"Rongkun Cui, Nana Zhang, Kun Zhu, Qi Zhang",https://doi.org/XXXXXXX.XXXXXXX,,"Information systems → Data mining, Social and professional topics→Economic impact","Online financial services are integral to modern web ecosystems but are vulnerable to fraud, which undermines trust and affects online communities. Existing graph neural network (GNN) methods face challenges such as fraud camouflage and long-tailed data distributions. This paper introduces HIMVH, a Hippocampus-Inspired Multi-View Hypergraph learning model, to address these issues. The model includes a cross-view inconsistency perception module and a novelty-aware hypergraph learning module, inspired by cognitive neuroscience. Extensive experiments show that HIMVH outperforms 15 state-of-the-art models, achieving significant improvements in AUC, F1, and AP metrics.",16.28,15.229,248,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11076v1_A3D Adaptive Affordance Assembly with Dual-Arm Man.pdf,A3D: Adaptive Affordance Assembly with Dual-Arm Manipulation,"Jiaqi Liang, Yue Chen, Qize Yu, Yan Shen, Haipeng Zhang, Hao Dong, Ruihai Wu",,,"furniture assembly, dual-arm manipulation, adaptive affordance, robotics, bi-manual operation, vision understanding, simulation environment","Furniture assembly is a challenging task for robots, requiring precise dual-arm coordination. The proposed A3D framework learns adaptive affordances to identify optimal support and stabilization locations on furniture parts. It employs dense point-level geometric representations to model part interaction patterns, enabling generalization across varied geometries. An adaptive module uses interaction feedback to dynamically adjust support strategies during assembly. A simulation environment with 50 diverse parts across 8 furniture types is established for evaluation. Experiments show effective generalization to diverse part geometries and furniture categories in both simulation and real-world settings.",16.37,15.455,253,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11077v1_ABC-Bench Benchmarking Agentic Backend Coding in R.pdf,ABC-Bench: Benchmarking Agentic Backend Coding in Real-World Development,"Jie Yang, Honglin Guo, Li Ji, Jiazheng Zhou, Rui Zheng, Zhikai Lei, Shuo Zhang, Zhiheng Xi, Shichun Liu, Yuxin Wang, Bo Wang, Yining Zheng, Tao Gui, Xipeng Qiu",,arXiv:2601.11077v1,"Large Language Models, autonomous agents, AI coding, backend development, benchmarking, repository-level problem solving, environment configuration, service deployment, software engineering","The evolution of Large Language Models (LLMs) into autonomous agents has expanded the scope of AI coding from localized code generation to complex, repository-level, and execution-driven problem solving. However, current benchmarks predominantly evaluate code logic in static contexts, neglecting the dynamic, full-process requirements of real-world engineering, particularly in backend development which demands rigorous environment configuration and service deployment. To address this gap, we introduce ABC-Bench, a benchmark explicitly designed to evaluate agentic backend coding within a realistic, executable workflow. Using a scalable automated pipeline, we curated 224 practical tasks spanning 8 languages and 19 frameworks from open-source repositories. Distinct from previous evaluations, ABC-Bench require the agents to manage the entire development lifecycle from repository exploration to instantiating containerized services and pass the external end-to-end API tests. Our extensive evaluation reveals that even state-of-the-art models struggle to deliver reliable performance on these holistic tasks, highlighting a substantial disparity between current model capabilities and the demands of practical backend engineering.",19.55,20.87,408,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11078v1_Visual Marker Search for Autonomous Drone Landing .pdf,Visual Marker Search for Autonomous Drone Landing in Diverse Urban Environments,"Jiaohong Yao, Linfeng Liang, Yao Deng, Xi Zheng, Richard Han, Yuankai Qi",,,"Drone navigation, marker-based landing, reinforcement learning, AirSim, robustness","Marker-based landing is widely used in drone delivery and return-to-base systems for its simplicity and reliability. However, most approaches assume idealized landing site visibility and sensor performance, limiting robustness in complex urban settings. This paper presents a simulation-based evaluation suite on the AirSim platform with systematically varied urban layouts, lighting, and weather to replicate realistic operational diversity. Using onboard camera sensors—RGB for marker detection and depth for obstacle avoidance—we benchmark two heuristic coverage patterns and a reinforcement learning–based agent, analyzing how exploration strategy and scene complexity affect success rate, path efficiency, and robustness. Results underscore the need to evaluate marker-based autonomous landing under diverse, sensor-relevant conditions to guide the development of reliable aerial navigation systems.",17.54,15.112,265,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11089v2_MiCA A Mobility-Informed Causal Adapter for Lightw.pdf,MiCA: A Mobility-Informed Causal Adapter for Lightweight Epidemic Forecasting,"Suhan Guo, Jiahong Deng, Furao Shen",,,"epidemic forecasting, mobility, causal discovery, temporal forecasting, COVID-19, influenza, dengue","Accurate forecasting of infectious disease dynamics is critical for public health planning and intervention. Human mobility significantly influences the spatial spread of epidemics, but mobility data are often noisy and difficult to integrate with disease records. Epidemic case time series are typically short and reported at coarse temporal resolution, limiting the effectiveness of parameter-heavy mobility-aware forecasters. This work introduces the Mobility-Informed Causal Adapter (MiCA), a lightweight and architecture-agnostic module for epidemic forecasting. MiCA infers mobility relations through causal discovery and integrates them into temporal forecasting models via gated residual mixing. This design allows lightweight forecasters to exploit mobility-derived spatial structure while remaining robust under noisy and data-limited conditions, without introducing heavy relational components. Experiments on four real-world epidemic datasets show that MiCA consistently improves lightweight temporal backbones, achieving an average relative error reduction of 7.5% across forecasting horizons. MiCA attains performance competitive with state-of-the-art spatio-temporal models while remaining lightweight.",17.96,17.655,317,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11090v1_Efficient Multilingual Name Type Classification Us.pdf,Efficient Multilingual Name Type Classification Using Convolutional Networks,Davor Lauc,,,"multilingual NLP, named entity recognition, convolutional neural networks, efficient inference, proper names","This paper presents a convolutional neural network approach for classifying proper names by language and entity type. The model, Onomas-CNN X, combines parallel convolution branches with depthwise-separable operations and hierarchical classification to efficiently process names on CPU hardware. Evaluated on a large multilingual dataset covering 104 languages and four entity types (person, organization, location, other), Onomas-CNN X achieves 92.1% accuracy while processing 2,813 names per second on a single CPU core, 46 times faster than fine-tuned XLM-RoBERTa with comparable accuracy. The model also reduces energy consumption by a factor of 46 compared to transformer baselines. The experiments demonstrate that specialized CNN architectures remain competitive with large pretrained models for focused NLP tasks when sufficient training data exists.",16.12,14.395,232,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11100v1_ReCreate Reasoning and Creating Domain Agents Driv.pdf,ReCreate: Reasoning and Creating Domain Agents Driven by Experience,"Zhezheng Hao, Hong Wang, Jian Luo, Jianqing Zhang, Yuyan Zhou, Qiang Lin, Can Wang, Hande Dong, Jiawei Chen",,,"Large Language Model, domain agents, experience-driven framework, agent creation, scaffold, LLM-based agents","Large Language Model (LLM) agents are reshaping the industrial landscape, but most practical agents remain human-designed due to the labor-intensive nature of building them for diverse tasks. This paper proposes ReCreate, an experience-driven framework for the automatic creation of domain agents. ReCreate leverages agent interaction histories to provide insights into success and failure, and introduces an agent-as-optimizer paradigm with three key components: experience storage and retrieval, a reasoning-creating synergy pipeline, and hierarchical updates. Experiments show that ReCreate outperforms human-designed agents and existing automated methods, even with minimal seed scaffolds.",16.83,15.685,264,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11109v1_Vision-as-Inverse-Graphics Agent via Interleaved M.pdf,Vision-as-Inverse-Graphics Agent via Interleaved Multimodal Reasoning,"Shaofeng Yin, Jiaxin Ge, Zora Zhiruo Wang, Xiuyu Li, Michael J. Black, Trevor Darrell, Angjoo Kanazawa, Haiwen Feng",,arXiv:2601.11109v1,"computer vision, 3D reconstruction, multimodal reasoning, iterative execution, verification, scene editing, BlenderGym, SlideBench, BlenderBench","Vision-as-inverse-graphics, the concept of reconstructing an image as an editable graphics program, is a longstanding goal of computer vision. This paper introduces VIGA (Vision-as-Inverse-Graphic Agent), which reconstructs or edits scenes through a closed-loop write→run→render→compare→revise procedure. VIGA combines a skill library and an evolving context memory to support long-horizon reasoning, covering tasks such as 3D reconstruction, multi-step scene editing, 4D physical interaction, and 2D document editing. Empirically, VIGA improves one-shot baselines on BlenderGym and SlideBench, and is model-agnostic, enabling evaluation of various foundation VLMs. The paper also introduces BlenderBench, a challenging benchmark for this protocol.",18.38,17.028,313,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11124v1_Learn Before Represent Bridging Generative and Con.pdf,Learn Before Represent: Bridging Generative and Contrastive Learning for Domain-Specific LLM Embeddings,"Xiaoyu Liang, Yuchen Peng, Jiale Luo, Wenhao Wang, Haoji Hu, Xincheng Zhou",,arXiv:2601.11,"Large Language Models, Contrastive Learning, Generative Learning, Domain-Specific Knowledge, LLM Embeddings, Information Bottleneck, Semantic Alignment, Knowledge Acquisition, Vertical Domains","Large Language Models (LLMs) adapted via contrastive learning excel in general representation learning but struggle in vertical domains like chemistry and law due to a lack of domain-specific knowledge. This work proposes a novel two-stage framework, Learn Before Represent (LBR), which first injects domain knowledge via an Information Bottleneck-Constrained Generative Learning stage, preserving the LLM’s causal attention to maximize knowledge acquisition while compressing semantics. It then performs Generative-Refined Contrastive Learning on the compressed representations for alignment. This approach maintains architectural consistency and resolves the objective conflict between generative and contrastive learning. Extensive experiments on medical, chemistry, and code retrieval tasks show that LBR significantly outperforms strong baselines, establishing a new paradigm for building accurate and robust representations in vertical domains.",17.88,18.119,324,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11135v1_Context-aware Graph Causality Inference for Few-Sh.pdf,Context-aware Graph Causality Inference for Few-Shot Molecular Property Prediction,"Van Thuy Hoang, O-Joun Lee",,,"molecular property prediction, graph learning, few-shot learning, causal inference, context-aware graph, functional groups, substructures","Molecular property prediction is a key application of graph learning in web-based services like online protein structure prediction and drug discovery. A significant challenge in few-shot scenarios is the limited availability of labeled molecules for predicting unseen properties. Existing studies using in-context learning face limitations in exploiting prior knowledge of functional groups causally linked to properties and identifying key substructures correlated with properties. This paper introduces CaMol, a context-aware graph causality inference framework, to address these challenges by assuming a latent causal structure in molecules that determines specific properties. The framework includes a context graph encoding chemical knowledge, a learnable atom masking strategy to disentangle causal substructures, and a distribution intervener for backdoor adjustment. Experiments demonstrate CaMol's superior accuracy and sample efficiency in few-shot tasks, along with its generalizability and interpretability through alignment with chemical knowledge.",16.74,15.83,265,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11143v1_Learning Quadrupedal Locomotion for a Heavy Hydrau.pdf,Learning Quadrupedal Locomotion for a Heavy Hydraulic Robot Using an Actuator Model,"Minho Lee, Hyeonseok Kim, Jin Tak Kim, Sangshin Park, Jeong Hyun Lee, Jungsan Cho, Jemin Hwangbo",,,"Hydraulic/Pneumatic Actuators, Legged Robots, Reinforcement Learning","The simulation-to-reality (sim-to-real) transfer of large-scale hydraulic robots presents a significant challenge in robotics due to slow control response and complex fluid dynamics. This work proposes an analytical actuator model driven by hydraulic dynamics to represent complicated actuators, predicting joint torques for all 12 actuators in under 1 microsecond, facilitating rapid processing in reinforcement learning (RL) environments. The model is compared with neural network-based actuator models, demonstrating advantages in data-limited scenarios. The locomotion policy trained with this model is deployed on a hydraulic quadruped robot weighing over 300 kg, marking the first successful transfer of stable and robust command-tracking locomotion with RL on a heavy hydraulic quadruped robot, showcasing advanced sim-to-real transferability.",16.76,17.122,287,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11144v2_Deep GraphRAG A Balanced Approach to Hierarchical .pdf,Deep GraphRAG: A Balanced Approach to Hierarchical Retrieval and Adaptive Integration,"Yuejie Li, Ke Yang, Tao Wang, Bolin Chen, Bowen Li, Chengjun Mao",,,"GraphRAG, Reinforcement Learning, Large Language Models","Graph-based Retrieval-Augmented Generation (GraphRAG) frameworks face a trade-off between the comprehensiveness of global search and the efficiency of local search. Existing methods struggle with navigating large-scale hierarchical graphs, optimizing retrieval paths, and balancing exploration-exploitation dynamics, often lacking robust multi-stage re-ranking. To address these issues, Deep GraphRAG is proposed, featuring a hierarchical global-to-local retrieval strategy that integrates macroscopic inter-community and microscopic intra-community contextual relations. This strategy employs a three-stage process: inter-community filtering, community-level refinement, and entity-level fine-grained search within target communities. A beam search-optimized dynamic re-ranking module guides this process, balancing efficiency and global comprehensiveness. Additionally, a Knowledge Integration Module leverages a compact LLM trained with Dynamic Weighting Reward GRPO (DW-GRPO), dynamically adjusting reward weights to balance relevance, faithfulness, and conciseness. Evaluations on Natural Questions and HotpotQA show that Deep GraphRAG significantly outperforms baseline graph retrieval methods in both accuracy and efficiency.",17.74,18.315,325,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11147v1_Do We Always Need Query-Level Workflows Rethinking.pdf,Do We Always Need Query-Level Workflows? Rethinking Agentic Workflow Generation for Multi-Agent Systems,"Zixu Wang, Bingbing Xu, Yige Yuan, Huawei Shen, Xueqi Cheng",,,"Multi-Agent Systems, Large Language Models, Workflow Generation, Task-Level, Query-Level, LLM Tokens, Evaluation, Self-Evolution, Generative Reward Modeling","Multi-Agent Systems (MAS) built on large language models typically solve complex tasks by coordinating multiple agents through workflows. Existing approaches generate workflows either at task level or query level, but their relative costs and benefits remain unclear. This paper rethinks and empirically analyzes these approaches, showing that query-level workflow generation is not always necessary. A small set of top-K best task-level workflows can cover equivalent or more queries. The paper proposes a low-cost task-level generation framework, SCALE, which maintains competitive performance with reduced token usage. Extensive experiments demonstrate SCALE's efficiency, with an average performance degradation of just 0.61% compared to existing approaches, while cutting overall token usage by up to 83%.",16.43,15.642,257,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11151v1_Cross-Modal Attention Network with Dual Graph Lear.pdf,Cross-Modal Attention Network with Dual Graph Learning in Multimodal Recommendation,"JI DAI, QUAN FANG, JUN HU, DESHENG CAI, YANG YANG, CAN ZHAO",https://doi.org/XXXXXXX.XXXXXXX,,"Information systems, Recommender systems, Multimedia information systems, Computing methodologies, Neural networks, Multimedia recommendation, Graph Neural Network, Multimodal Fusion","Multimedia recommendation systems leverage user-item interactions and multimodal information to capture user preferences, enabling more accurate and personalized recommendations. Despite notable advancements, existing approaches still face two critical limitations: first, shallow modality fusion often relies on simple concatenation, failing to exploit rich synergic intra- and inter-modal relationships; second, asymmetric feature treatment—where users are only characterized by interaction IDs while items benefit from rich multimodal content—hinders the learning of a shared semantic space. To address these issues, we propose a Cross-modal Recursive Attention Network with dual graph Embedding (CRANE). To tackle shallow fusion, we design a core Recursive Cross-Modal Attention (RCA) mechanism that iteratively refines modality features based on cross-correlations in a joint latent space, effectively capturing high-order intra- and inter-modal dependencies. For symmetric multimodal learning, we explicitly construct users’ multimodal profiles by aggregating features of their interacted items. Furthermore, CRANE integrates a symmetric dual-graph framework—comprising a heterogeneous user-item interaction graph and a homogeneous item-item semantic graph—unified by a self-supervised contrastive learning objective to fuse behavioral and semantic signals. Despite these complex modeling capabilities, CRANE maintains high computational efficiency. Theoretical and empirical analyses confirm its scalability and high practical efficiency, achieving faster convergence on small datasets and superior performance ceilings on large-scale ones. Comprehensive experiments on four public real-world datasets validate an average 5% improvement in key metrics over state-of-the-art baselines. Our code is publicly available at https://github.com/MKC-Lab/CRANE.",19.5,23.027,449,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11160v1_Clustering High-dimensional Data Balancing Abstrac.pdf,Clustering High-dimensional Data: Balancing Abstraction and Representation,"Claudia Plant, Lena G. M. Bauer, Christian Böhm",,,"clustering, high-dimensional data, abstraction, representation, subspace clustering, deep clustering, centroid-based clustering, density-based clustering, latent space","This tutorial discusses the challenge of clustering high-dimensional data by balancing abstraction and representation. It explores how different clustering algorithms implement this balance, with classical K-means providing high abstraction and simple representation, while subspace and deep clustering allow for richer representations. The tutorial highlights the need for explicit abstraction enforcement in deep clustering methods through centroid-based and density-based clustering losses. It also discusses the potential for future methods to adaptively balance abstraction and representation, drawing inspiration from the human brain's ability to perform clustering and related tasks efficiently.",15.75,12.759,201,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11178v1_TANDEM Temporal-Aware Neural Detection for Multimo.pdf,TANDEM: Temporal-Aware Neural Detection for Multimodal Hate Speech,"Girish A. Koushik, Helen Treharne, Diptesh Kanojia",,,"hate speech detection, multimodal content, temporal-aware neural detection, reinforcement learning, audio-visual hate detection, structured reasoning, online safety moderation","Social media platforms are increasingly dominated by long-form multimodal content, where harmful narratives are constructed through a complex interplay of audio, visual, and textual cues. Automated systems can flag hate speech with high accuracy but often lack interpretability, failing to provide granular evidence like precise timestamps and target identities. This work introduces TANDEM, a framework that transforms audio-visual hate detection from a binary classification task into a structured reasoning problem. It employs a novel tandem reinforcement learning strategy where vision-language and audio-language models optimize each other through self-constrained cross-modal context, stabilizing reasoning over extended temporal sequences without requiring dense frame-level supervision. Experiments across three benchmark datasets demonstrate that TANDEM significantly outperforms zero-shot and context-augmented baselines, achieving 0.73 F1 in target identification on HateMM (a ≈ 30% improvement over state-of-the-art) while maintaining precise temporal grounding. The findings suggest that structured, interpretable alignment is achievable even in complex multimodal settings, offering a blueprint for the next generation of transparent and actionable online safety moderation tools.",18.68,18.901,353,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11189v1_Policy-Based Deep Reinforcement Learning Hyperheur.pdf,Policy-Based Deep Reinforcement Learning Hyperheuristics for Job-Shop Scheduling,"Sofiene Lassoued, Asrat Gobachew, Stefan Lier, Andreas Schwung",,,"Hyper-heuristics, Job Shop Scheduling, Policy-based Reinforcement learning, Petri nets","This paper proposes a policy-based deep reinforcement learning hyper-heuristic framework for solving the Job Shop Scheduling Problem. The hyper-heuristic agent learns to switch scheduling rules based on the system state dynamically. The framework is extended with action prefiltering and a commitment mechanism to regulate heuristic switching. The impact of different commitment strategies and action selection strategies is investigated. Computational experiments demonstrate that the proposed approach outperforms traditional heuristics, metaheuristics, and recent neural network-based scheduling methods.",15.75,13.649,215,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11196v1_Artificial Intelligence and the US Economy An Acco.pdf,Artificial Intelligence and the US Economy: An Accounting Perspective on Investment and Production,"Luisa Carpinelli, Filippo Natoli, Marco Taboga",,2601.11196v1,"artificial intelligence, capital expenditures, data centers, national accounts","Artificial intelligence (AI) has moved to the center of policy, market, and academic debates, but its macroeconomic footprint is still only partly understood. This paper provides an overview on how the current AI wave is captured in US national accounts, combining a simple macro-accounting framework with a stylized description of the AI production process. It highlights the crucial role played by data centers, which constitute the backbone of the AI ecosystem and have attracted formidable investment in 2025, as they are indispensable for meeting the rapidly increasing worldwide demand for AI services. The paper documents that the boom in IT and AI-related capital expenditure in the first three quarters of the year has given an outsized boost to aggregate demand, while its contribution to GDP growth is smaller once the high import content of AI hardware is netted out. Simple calculations suggest that, at current utilization rates and pricing, the production of services originating in new AI data centers could contribute to GDP over the turn of the next quarters on a scale comparable to that of investment spending to date. Short reinvestment cycles and uncertainty about future AI demand – while not currently acting as a macroeconomic drag – can nevertheless fuel macroeconomic risks over the medium term.",19.81,17.364,344,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11199v1_SD-RAG A Prompt-Injection-Resilient Framework for .pdf,SD-RAG: A Prompt-Injection-Resilient Framework for Selective Disclosure in Retrieval-Augmented Generation,"Aiman Al Masoud, Marco Arazzi, Antonino Nocera",,,"Retrieval-Augmented Generation, Large Language Models, Selective Disclosure, Prompt Injection, Security and Privacy Constraints, Semantic Mechanism, Graph-Based Data Model","Retrieval-Augmented Generation (RAG) combines the generative capabilities of Large Language Models (LLMs) with efficient retrieval mechanisms over large-scale data collections. Existing approaches often overlook the risks of exposing sensitive information to the generation model. This paper introduces SD-RAG, a novel approach that decouples security and privacy constraints from the generation process by applying sanitization and disclosure controls during the retrieval phase. SD-RAG incorporates a semantic mechanism for dynamic security and privacy constraints and an optimized graph-based data model for policy-aware retrieval. Experimental evaluation shows SD-RAG's superiority over baseline approaches, with up to a 58% improvement in privacy score and strong resilience to prompt injection attacks.",16.98,15.779,268,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11200v1_FAQ Mitigating Quantization Error via Regenerating.pdf,Mitigating Quantization Error via Regenerating Calibration Data with Family-Aware Quantization,"Haiyang Xiao, Weiqing Li, Jinyue Guo, Guochao Jiang, Guohua Liu, Yuewei Zhang",,,"Post-training quantization, Large language models, Calibration data, Quantization parameters, Family-aware quantization","This paper addresses the challenge of representativeness and universality of calibration data in post-training quantization (PTQ) for deploying large language models (LLMs) on resource-constrained devices. Traditional PTQ methods often rely on limited samples, leading to biases in quantization parameters. The authors propose FAQ (Family-Aware Quantization), a calibration data regeneration framework that uses prior knowledge from LLMs of the same family to generate high-fidelity calibration samples. By inputting original calibration samples into a larger LLM from the same family, FAQ regenerates calibration data that aligns with the expected activation distribution. This data undergoes group competition under expert guidance to select the best samples, which are then re-normalized to enhance PTQ effectiveness. Experiments on models like Qwen3-8B show that FAQ reduces accuracy loss by up to 28.5% compared to the baseline, demonstrating its potential and contribution.",17.53,16.774,294,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11202v1_Epistemic Control and the Normativity of Machine L.pdf,EPISTEMIC CONTROL AND THE NORMATIVITY OF MACHINE LEARNING-BASED SCIENCE,Emanuele Ratti,,,"machine learning, epistemic control, cognitive values, normativity","The chapter investigates the extent to which human scientists are pushed out-of-the-loop in machine learning (ML) systems in science, as argued by Paul Humphreys. It introduces the concept of 'epistemic control' with conditions 'tracking' and 'tracing', and argues against Humphreys' pessimistic view, proposing a nuanced understanding of epistemic control in ML-based science.",15.15,10.362,157,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11207v1_LoRA as Oracle.pdf,LoRA as Oracle,"Marco Arazzi, Antonino Nocera",,,"LoRA, Membership Inference Attack, Backdoor Attack","Backdoored and privacy-leaking deep neural networks pose a serious threat to the deployment of machine learning systems in security-critical settings. Existing defenses for backdoor detection and membership inference typically require access to clean reference models, extensive retraining, or strong assumptions about the attack mechanism. This work introduces a novel LoRA-based oracle framework that leverages low-rank adaptation modules as a lightweight, model-agnostic probe for both backdoor detection and membership inference. The approach attaches task-specific LoRA adapters to a frozen backbone and analyzes their optimization dynamics and representation shifts when exposed to suspicious samples. It shows that poisoned and member samples induce distinctive low-rank updates that differ significantly from those generated by clean or non-member data. These signals can be measured using simple ranking and energy-based statistics, enabling reliable inference without access to the original training data or modification of the deployed model.",16.92,14.772,250,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11219v1_SDFLoRA Selective Dual-Module LoRA for Federated F.pdf,SDFLoRA: Selective Dual-Module LoRA for Federated Fine-tuning with Heterogeneous Clients,"Zhikang Shen, Jianrong Lu, Haiyuan Wan, Jianhai Chen",,,"Federated Learning, Large Language Models, LoRA, Parameter-Efficient Methods, Rank Heterogeneity, Differential Privacy, Personalization","Federated learning (FL) for large language models (LLMs) is gaining attention for privacy-preserving adaptation across distributed data. Parameter-efficient methods like LoRA are used to reduce communication and memory costs. However, practical FL deployments face rank heterogeneity, where clients use different low-rank configurations, leading to biased and unstable aggregation of LoRA updates. Existing solutions either enforce unified ranks or align updates into a shared subspace, which limits personalization and weakens privacy protection. This paper proposes Selective Dual-module Federated LoRA (SDFLoRA), which decomposes each client adapter into a global module for transferable knowledge and a local module for client-specific adaptations. The global module is selectively aligned and aggregated across clients, while local modules remain private, enabling robust learning under rank heterogeneity and privacy-aware optimization by injecting differential privacy noise exclusively into the global module. Experiments on GLUE benchmarks show that SDFLoRA outperforms federated LoRA baselines and achieves a better utility–privacy trade-off.",18.57,18.413,342,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11232v1_FactCorrector A Graph-Inspired Approach to Long-Fo.pdf,FACTCORRECTOR: A Graph-Inspired Approach to Long-Form Factuality Correction of Large Language Models,"Javier Carnerero-Cano, Massimiliano Pronesti, Radu Marinescu, Tigran Tchrakian, James Barry, Jasmina Gajcin, Yufang Hou, Alessandra Pascale, Elizabeth Daly",,,"Large Language Models, Factuality Correction, Post-hoc Correction, Feedback, VELI5 Benchmark","Large language models (LLMs) are widely used in knowledge-intensive applications but often generate factually incorrect responses. This paper introduces FACTCORRECTOR, a new post-hoc correction method that adapts across domains without retraining and leverages structured feedback about the factuality of the original response to generate a correction. The paper also presents the VELI5 benchmark, a novel dataset containing systematically injected factual errors and ground-truth corrections. Experiments show that FACTCORRECTOR significantly improves factual precision while preserving relevance, outperforming strong baselines.",16.77,16.22,272,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11252v1_Beyond Model Scaling Test-Time Intervention for Ef.pdf,BEYONDMODELSCALING: TEST-TIME INTERVENTION FOR EFFICIENT DEEP REASONING,"Qianyue Wang, Jinwu Hu, Yufeng Wang, Huanxiang Lin, Bolin Chen, Zhiquan Wen, Yaofo Chen, Mingkui Tan",,,"Large Reasoning Models, Efficient Reasoning, Test-time Intervention, Overthinking, Overshoot, External Feedback, Transitional Conjunctions, Group Relative Policy Optimization, Multi-criteria Evaluation","Large Reasoning Models (LRMs) excel at multi-step reasoning but often suffer from inefficient reasoning processes like overthinking and overshoot, where excessive or misdirected reasoning increases computational cost and degrades performance. Existing efficient reasoning methods operate in a closed-loop manner, lacking mechanisms for external intervention to guide the reasoning process. To address this, we propose Think-with-Me, a novel test-time interactive reasoning paradigm that introduces external feedback intervention into the reasoning process. Our key insights are that transitional conjunctions serve as natural points for intervention, signaling phases of self-validation or exploration and using transitional words appropriately to prolong the reasoning enhances performance, while excessive use affects performance. Building on these insights, Think-with-Me pauses reasoning at these points for external feedback, adaptively extending or terminating reasoning to reduce redundancy while preserving accuracy. The feedback is generated via a multi-criteria evaluation (rationality and completeness) and comes from either human or LLM proxies. We train the target model using Group Relative Policy Optimization (GRPO) to adapt to this interactive mode. Experiments show that Think-with-Me achieves a superior balance between accuracy and reasoning length under limited context windows. On AIME24, Think-with-Me outperforms QwQ-32B by 7.19% in accuracy while reducing average reasoning length by 81% under an 8K window. The paradigm also benefits security and creative tasks.",19.71,23.489,463,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11258v1_Knowledge is Not Enough Injecting RL Skills for Co.pdf,Knowledge is Not Enough: Injecting RL Skills for Continual Adaptation,"Pingzhi Tang, Yiding Wang, Muhan Zhang",,,"Large Language Models, knowledge cutoff, Supervised Fine-Tuning, Reinforcement Learning, Parametric Skill Transfer, knowledge adaptation, question answering, decision-making, Skill Vector, knowledge-incorporation QA, agentic tool-use benchmarks","Large Language Models (LLMs) face the 'knowledge cutoff' challenge, where their frozen parametric memory prevents direct internalization of new information. While Supervised Fine-Tuning (SFT) is commonly used to update model knowledge, it often updates factual content without reliably improving the model’s ability to use the newly incorporated information for question answering or decision-making. Reinforcement Learning (RL) is essential for acquiring reasoning skills; however, its high computational cost makes it impractical for efficient online adaptation. This paper proposes Parametric Skill Transfer (PaST), a framework that supports modular skill transfer for efficient and effective knowledge adaptation. By extracting a domain-agnostic Skill Vector from a source domain, knowledge manipulation skills can be linearly injected into a target model after it has undergone lightweight SFT on new data. Experiments demonstrate the effectiveness of PaST, showing significant improvements in knowledge-incorporation QA and agentic tool-use benchmarks.",17.77,18.398,327,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11269v1_X-Distill Cross-Architecture Vision Distillation f.pdf,X-Distill: Cross-Architecture Vision Distillation for Visuomotor Learning,"Maanping Shao, Feihong Zhang, Gu Zhang, Baiye Cheng, Zhengrong Xue, Huazhe Xu",,,"Visuomotor Policy, Knowledge Distillation, Representation Learning, Manipulation","Visuomotor policies often leverage large pre-trained Vision Transformers (ViTs) for their powerful generalization capabilities. However, their significant data requirements present a major challenge in the data-scarce context of most robotic learning settings, where compact CNNs with strong inductive biases can be more easily optimized. To address this trade-off, we introduce X-Distill, a simple yet highly effective method that synergizes the strengths of both architectures. Our approach involves an offline, cross-architecture knowledge distillation, transferring the rich visual representations of a large, frozen DINOv2 teacher to a compact ResNet-18 student on the general-purpose ImageNet dataset. This distilled encoder, now endowed with powerful visual priors, is then jointly fine-tuned with a diffusion policy head on the target manipulation tasks. Extensive experiments on 34 simulated benchmarks and 5 challenging real-world tasks demonstrate that our method consistently outperforms policies equipped with from-scratch ResNet or fine-tuned DINOv2 encoders. Notably, X-Distill also surpasses 3D encoders that utilize privileged point cloud observations or much larger Vision-Language Models. Our work highlights the efficacy of a simple, well-founded distillation strategy for achieving state-of-the-art performance in data-efficient robotic manipulation.",18.62,20.516,382,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11282v1_From SERPs to Sound How Search Engine Result Pages.pdf,From SERPs to Sound: How Search Engine Result Pages and AI-generated Podcasts Interact to Influence User Attitudes on Controversial Topics,"Junjie Wang, Gaole He, Alisa Rieger, Ujwal Gadiraju",10.1145/3786304.3787942,,"Attitude Change, AI-generated Podcasts, Information modality, Web search, Controversial Topics, Responsible Opinion Formation","This study explores how search engine result pages (SERPs) and AI-generated podcasts influence user attitudes on controversial topics. Through a controlled user study with 483 participants, it was found that the sequence and modality of information exposure affect user opinions. The study highlights the role of viewpoint bias and topic controversiality in shaping attitudes, with no significant effect from individual moderators.",15.53,14.166,220,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11286v1_XChoice Explainable Evaluation of AI-Human Alignme.pdf,XChoice: Explainable Evaluation of AI–Human Alignment in LLM-based Constrained Choice Decision Making,"Weihong Qi, Fan Huang, Rasika Muralidharan, Jisun An, Haewoon Kwak",,,"AI-human alignment, LLM-based decision making, constrained choice, explainable framework, mechanism-based decision model, parameter vectors, misalignment, retrieval-augmented generation, invariance analysis","We present XCHOICE, an explainable framework for evaluating AI-human alignment in constrained decision making. Moving beyond outcome agreement metrics like accuracy and F1 score, XCHOICE fits a mechanism-based decision model to human data and LLM-generated decisions, recovering interpretable parameters that capture the relative importance of decision factors, constraint sensitivity, and implied trade-offs. Alignment is assessed by comparing these parameter vectors across models, options, and subgroups. We demonstrate XCHOICE on Americans’ daily time allocation using the American Time Use Survey (ATUS) as human ground truth, revealing heterogeneous alignment across models and activities and salient misalignment concentrated in Black and married groups. We further validate the robustness of XCHOICE via an invariance analysis and evaluate targeted mitigation with a retrieval-augmented generation (RAG) intervention. Overall, XCHOICE provides mechanism-based metrics that diagnose misalignment and support informed improvements beyond surface outcome matching.",18.02,19.203,346,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11344v1_How Much Would a Clinician Edit This Draft Evaluat.pdf,How Much Would a Clinician Edit This Draft? Evaluating LLM Alignment for Patient Message Response Drafting,"Parker Seegmiller, Joseph Gatto, Sarah E. Greer, Ganza Belise Isingizwe, Rohan Ray, Timothy Burdick, Sarah M. Preum",,,"Large Language Models, Clinical Workflows, Patient Portal Messages, LLM Alignment, Thematic Elements, Evaluation Framework, Adaptation Techniques, Epistemic Uncertainty, Patient-Clinician Communication","This study investigates the alignment of large language models (LLMs) with clinicians in drafting responses to patient portal messages. It introduces a taxonomy of thematic elements in clinician responses and a framework for assessing the editing load of LLM-drafted responses. The research evaluates local and commercial LLMs using various adaptation techniques, revealing significant uncertainty in aligning LLM drafts with clinician responses. While LLMs can draft certain thematic elements, they struggle with clinician-aligned generation in others, particularly in question asking. The study highlights the need for adapting LLMs to individual clinician preferences for reliable use in patient-clinician communication workflows.",17.38,17.377,302,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11350v1_FEATHer Fourier-Efficient Adaptive Temporal Hierar.pdf,FEATHer: Fourier-Efficient Adaptive Temporal Hierarchy Forecaster for Time-Series Forecasting,"Jaehoon Lee, Seungwoo Lee, Younghwi Kim, Dohee Kim, Sunghyun Sim",,,"Time-series Forecasting, Edge AI, Ultra-Lightweight Models, Fourier-Efficient Adaptive Temporal Hierarchy Forecaster (FEATHer)","Time-series forecasting is crucial in industrial domains like manufacturing and energy management. As systems evolve toward cyber-physical automation, forecasting models must operate on edge devices with strict constraints on latency, memory, and energy consumption. Conventional deep forecasting architectures become impractical under these constraints. This paper introduces the Fourier-Efficient Adaptive Temporal Hierarchy Forecaster (FEATHer), a multiscale temporal model designed for accurate long-term forecasting with minimal resources. FEATHer features an ultra-lightweight multiscale temporal decomposition, a shared Dense Temporal Kernel, a frequency-aware branch gating mechanism, and a Sparse Period Kernel. It achieves strong predictive performance with as few as 400 trainable parameters, demonstrating reliable long-range forecasting under constrained edge conditions. Across eight benchmarks, FEATHer records 60 first-place results with an average rank of 2.05, suggesting a practical direction for next-generation industrial systems requiring real-time inference with minimal computational cost.",18.32,17.464,320,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11354v1_AstroReason-Bench Evaluating Unified Agentic Plann.pdf,AstroReason-Bench: Evaluating Unified Agentic Planning across Heterogeneous Space Planning Problems,"Weiyi Wang, Xinchi Chen, Jingjing Gong, Xuanjing Huang, Xipeng Qiu",,arXiv:2601.11354v1,"agentic systems, large language models, Space Planning Problems, generalist planning, physical constraints, benchmarking","Recent advances in agentic Large Language Models (LLMs) have positioned them as generalist planners capable of reasoning and acting across diverse tasks. However, existing agent benchmarks largely focus on symbolic or weakly grounded environments, leaving their performance in physics-constrained real-world domains underexplored. This paper introduces AstroReason-Bench, a comprehensive benchmark for evaluating agentic planning in Space Planning Problems (SPP), which are high-stakes problems with heterogeneous objectives, strict physical constraints, and long-horizon decision-making. AstroReason-Bench integrates multiple scheduling regimes, including ground station communication and agile Earth observation, and provides a unified agent-oriented interaction protocol. Evaluations on a range of state-of-the-art open- and closed-source agentic LLM systems reveal that current agents substantially underperform specialized solvers, highlighting key limitations of generalist planning under realistic constraints. AstroReason-Bench offers a challenging and diagnostic testbed for future agentic research.",19.05,17.275,329,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11359v1_Think-Clip-Sample Slow-Fast Frame Selection for Vi.pdf,THINK-CLIP-SAMPLE: SLOW-FAST FRAME SELECTION FOR VIDEO UNDERSTANDING,"Wenhui Tan, Ruihua Song, Jiaze Li, Jianzhong Ju, Zhenbo Luo",,,"Multi-modal LLMs, long video understanding, frame selection, video understanding, multi-query reasoning, clip-level slow-fast sampling","Recent progress in multi-modal large language models (MLLMs) has significantly advanced video understanding. However, their performance on long-form videos remains limited by computational constraints and suboptimal frame selection. We present Think-Clip-Sample (TCS), a training-free framework that enhances long video understanding through two key components: (i) Multi-Query Reasoning, which generates multiple queries to capture complementary aspects of the question and video; and (ii) Clip-level Slow-Fast Sampling, which adaptively balances dense local details and sparse global context. Extensive experiments on MLVU, LongVideoBench, and VideoMME demonstrate that TCS consistently improves performance across different MLLMs, boosting up to 6.9% accuracy, and is capable of achieving comparable accuracy with 50% fewer inference time cost, highlighting both efficiency and efficacy of TCS on long video understanding.",17.77,17.557,312,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11369v2_Institutional AI Governing LLM Collusion in Multi-.pdf,Institutional AI: Governing LLM Collusion in Multi-Agent Cournot Markets via Public Governance Graphs,"M. Bracale Syrnikov, F. Pierucci, M. Galisai, M. Prandi, P. Bisconti, F. Giarrusso, O. Sorokoletova, V. Suriani, D. Nardi",,arXiv:2601.11369v2,"Institutional AI, LLM, multi-agent, Cournot markets, governance graphs, AI alignment, collusion","This paper introduces an experimental framework for evaluating Institutional AI, a system-level approach to AI alignment that focuses on mechanism design in institution-space. The framework uses governance graphs to manage multi-agent LLM ensembles in Cournot markets, aiming to prevent socially harmful equilibria. The study compares three regimes: Ungoverned, Constitutional, and Institutional, across various model configurations. Results show that the Institutional regime significantly reduces collusion, highlighting the potential of framing multi-agent alignment as an institutional design problem.",17.82,15.933,284,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11379v1_Evaluating LLM Behavior in Hiring Implicit Weights.pdf,"Evaluating LLM Behavior in Hiring: Implicit Weights, Fairness Across Groups, and Alignment with Human Preferences","Morgane Hoffmann, Emma Jouffroy, Warren Jouanneau, Marc Palyart, Charles Pebereau",,,"Large Language Models, Person-job Fit, Fairness, Interpretability","General-purpose Large Language Models (LLMs) show significant potential in recruitment applications, where decisions require reasoning over unstructured text, balancing multiple criteria, and inferring fit and competence from indirect productivity signals. This paper proposes a framework to evaluate an LLM’s decision logic in recruitment by drawing on established economic methodologies for analyzing human hiring behavior. Synthetic datasets from real freelancer profiles and project descriptions from a major European online freelance marketplace are used to estimate how an LLM weighs different match-relevant criteria when evaluating freelancer-project fit. The study identifies which attributes the LLM prioritizes and analyzes how these weights vary across project contexts and demographic subgroups. The findings reveal that the LLM weighs core productivity signals, such as skills and experience, but interprets certain features beyond their explicit matching value. While showing minimal average discrimination against minority groups, intersectional effects reveal that productivity signals carry different weights between demographic groups. The paper also discusses how a comparable experimental setup could be implemented with human recruiters to assess alignment between model and human decisions.",18.14,16.701,303,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11389v1_Hyperparameter Optimization of Constraint Programm.pdf,Hyperparameter Optimization of Constraint Programming Solvers,"Hedieh Haddad, Thibault Falque, Pierre Talbot, Pascal Bouvry",,2601.11389v1,"constraint programming, hyperparameter optimization, Bayesian optimization, Hamming distance search, CPMpy library, ACE solver, Choco solver","The performance of constraint programming solvers is highly sensitive to the choice of their hyperparameters. Manually finding the best solver configuration is a difficult, time-consuming task that typically requires expert knowledge. This paper introduces the probe and solve algorithm, a novel two-phase framework for automated hyperparameter optimization integrated into the CPMpy library. The approach partitions the available time budget into a probing phase that explores different sets of hyperparameters using configurable hyperparameter optimization methods, followed by a solving phase where the best configuration found is used to tackle the problem within the remaining time. Two hyperparameter optimization methods, Bayesian optimization and Hamming distance search, are implemented and compared within the probe and solve algorithm. The algorithm is evaluated on two different constraint programming solvers, ACE and Choco, across 114 combinatorial problem instances, comparing their performance against the solver’s default configurations. Results show that using Bayesian optimization, the algorithm outperforms the solver’s default configurations, improving solution quality for ACE in 25.4% of instances and matching the default performance in 57.9%, and for Choco, achieving superior results in 38.6% of instances. It also consistently surpasses Hamming distance search within the same framework, confirming the advantage of model-based exploration over simple local search.",20.65,18.743,387,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11400v1_Wetland mapping from sparse annotations with satel.pdf,Wetland mapping from sparse annotations with satellite image time series and temporal-aware segment anything model,"Shuai Yuan, Tianwu Lin, Shuang Chen, Yu Xia, Peng Qin, Xiangyu Liu, Xiaoqing Xu, Nan Xu, Hongsheng Zhang, Jie Wang, Peng Gong",,2601.11400v1,"wetland mapping, satellite image time series, sparse annotation, segment anything model, temporal adaptation","Accurate wetland mapping is critical for ecosystem monitoring and management, yet acquiring dense pixel-level annotations is prohibitively costly. In practice, only sparse point labels are typically available, and existing deep learning-based models struggle under such weak supervision. Meanwhile, wetlands exhibit strong seasonal and inter-annual dynamics, making single-date imagery insufficient and causing substantial omission and commission errors when mapping. Although powerful foundation models like the Segment Anything Model (SAM) provide promising generalization from point prompts, it is intrinsically designed for static natural images, resulting in spatially fragmented masks in heterogeneous wetland environments and cannot exploit satellite image time series. To address these challenges, we propose WetSAM, a novel SAM-based framework that effectively leverages satellite image time series to enhance wetland mapping from sparse point annotations. WetSAM adopts a dual-branch design: (1) The temporal branch is prompted by sparse point labels to extend the SAM with a hierarchical adapter and a dynamic temporal aggregation module. By decomposing time series into seasonal trends and transient events, this branch effectively distinguishes wetland features from phenological variations; (2) The spatial branch reconstructs distinct boundaries via a temporal-constrained region-growing strategy, iteratively expanding sparse points into reliable dense pseudo-labels; (3) A bidirectional consistency regularization enforces minimizing the discrepancy of the predictions from two segmentation heads of two branches. We validate the effectiveness of WetSAM across eight diverse global locations, each covering an area of around 5,000 km² and with various wetland types and geographical features. WetSAM reaches an average F1-score of 85.58%, considerably outperforming other state-of-the-art algorithms. Results demonstrate that WetSAM achieves accurate, structurally consistent segmentation from sparse labels. With minimal labeling effort, our framework shows strong generalization ability and holds promise for scalable, low-cost wetland mapping at high spatial resolutions.",21.15,25.77,545,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11409v1_Topology-Guaranteed Image Segmentation Enforcing C.pdf,"Topology-Guaranteed Image Segmentation: Enforcing Connectivity, Genus, and Width Constraints","Wenxiao Li, Xue-Cheng Tai, Jun Liu",,,"Image segmentation, topological preservation, persistent homology, thickness of topology, variational, regularization","Existing research highlights the crucial role of topological priors in image segmentation, particularly in preserving essential structures such as connectivity and genus. Accurately capturing these topological features often requires incorporating width-related information, including the thickness and length inherent to the image structures. However, traditional mathematical definitions of topological structures lack this dimensional width information, limiting methods like persistent homology from fully addressing practical segmentation needs. To overcome this limitation, we propose a novel mathematical framework that explicitly integrates width information into the characterization of topological structures. This method leverages persistent homology, complemented by smoothing concepts from partial differential equations (PDEs), to modify local extrema of upper-level sets. This approach enables the resulting topological structures to inherently capture width properties. We incorporate this enhanced topological description into variational image segmentation models. Using some proper loss functions, we are also able to design neural networks that can segment images with the required topological and width properties. Through variational constraints on the relevant topological energies, our approach successfully preserves essential topological invariants such as connectivity and genus counts, simultaneously ensuring that segmented structures retain critical width attributes, including line thickness and length. Numerical experiments demonstrate the effectiveness of our method, showcasing its capability to maintain topological fidelity while explicitly embedding width characteristics into segmented image structures.",19.36,19.263,373,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11421v1_The Great March 100 100 Detail-oriented Tasks for .pdf,THE GREAT MARCH 100: 100 DETAIL-ORIENTED TASKS FOR EVALUATING EMBODIED AI AGENTS,"Ziyu Wang, Chenyuan Liu, Yushun Xiang, Runhao Zhang, Yu Zhang, Qingbo Hao, Hongliang Lu, Houyu Chen, Zhizhong Feng, Kaiyue Zheng, Dehao Ye, Xianchao Zeng, Xinyu Zhou, Boran Wen, Jiaxin Li, Mingyu Zhang, Kecheng Zheng, Qian Zhu, Ran Cheng, Yong-Lu Li",,,"robot learning, imitation learning, datasets, task design, robotic agents, evaluation, Great March 100, GM-100","With the rapid development of robot learning and imitation learning, numerous datasets and methods have emerged. However, these datasets and their task designs often lack systematic consideration and principles. This raises important questions about whether current datasets and task designs truly advance the capabilities of robotic agents and whether evaluations on a few common tasks accurately reflect the differentiated performance of various methods. To address these issues, the Great March 100 (GM-100) is introduced as the first step towards a robot learning Olympics. GM-100 consists of 100 carefully designed tasks that cover a wide range of interactions and long-tail behaviors, aiming to provide a diverse and challenging set of tasks to comprehensively evaluate the capabilities of robotic agents and promote diversity and complexity in robot dataset task designs. These tasks are developed through systematic analysis and expansion of existing task designs, combined with insights from human-object interaction primitives and object affordances. A large amount of trajectory data on different robotic platforms is collected and several baseline models are evaluated. Experimental results demonstrate that the GM-100 tasks are feasible to execute and sufficiently challenging to effectively differentiate the performance of current VLA models. The data and code are available at https://rhos.ai/research/gm-100.",19.49,23.086,450,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11429v1_Relational Linearity is a Predictor of Hallucinati.pdf,Relational Linearity is a Predictor of Hallucinations,"Yuetian Lu, Yihong Liu, Hinrich Schütze",,,"hallucinations, large language models, linearity, knowledge assessment, synthetic entities","Hallucination is a central failure mode in large language models (LLMs). This study focuses on hallucinations in answers to questions about synthetic entities unknown to the model. It is found that medium-size models like Gemma-7B-IT frequently hallucinate, struggling to recognize that the hallucinated fact is not part of their knowledge. The study hypothesizes that the linearity of the relation is a significant factor in causing these hallucinations. Linear relations tend to be stored more abstractly, making knowledge assessment difficult, whereas nonlinear relations are stored more directly, facilitating knowledge assessment. The study introduces SyntHal, a dataset of synthetic entities for six relations, and finds a strong correlation between relational linearity and hallucination rate. This suggests that the underlying storage of triples of a relation affects a model's ability to self-assess its knowledge, with implications for managing hallucination behavior and improving factual knowledge representation in LLMs.",16.95,15.749,267,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11440v1_GenDA Generative Data Assimilation on Complex Urba.pdf,GENDA: GENERATIVEDATAASSIMILATION ON COMPLEX URBAN AREAS VIA CLASSIFIER-FREE DIFFUSION GUIDANCE,"Francisco Giral, Álvaro Manzano, Ignacio Gómez, Ricardo Vinuesa, Soledad Le Clainche",,,"urban wind flow reconstruction, data assimilation, graph-based diffusion architecture, classifier-free guidance, computational fluid dynamics, Reynolds-averaged Navier-Stokes, environmental monitoring","Urban wind flow reconstruction is essential for assessing air quality, heat dispersion, and pedestrian comfort, yet remains challenging with sparse sensor data. This paper introduces GenDA, a generative data assimilation framework that reconstructs high-resolution wind fields on unstructured meshes from limited observations. The model employs a multiscale graph-based diffusion architecture trained on computational fluid dynamics simulations, using classifier-free guidance as a learned posterior reconstruction mechanism. This approach enables obstacle-aware reconstruction and generalization across unseen geometries, wind directions, and mesh resolutions without retraining. Evaluated against supervised graph neural network baselines and classical reduced-order data assimilation methods, GenDA reduces the relative root-mean-square error by 25-57% and increases the structural similarity index by 23-33% across tested meshes. Experiments are conducted on Reynolds-averaged Navier-Stokes simulations of a real urban neighborhood in Bristol, UK, featuring complex building geometry and irregular terrain. The framework offers a scalable path toward generative, geometry-aware data assimilation for environmental monitoring in complex domains.",18.63,20.024,373,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11441v1_Hierarchical Orthogonal Residual Spread for Precis.pdf,HIERARCHICAL ORTHOGONAL RESIDUAL SPREAD FOR PRECISE MASSIVE EDITING IN LARGE LANGUAGE MODELS,"Xiaojie Gu, Guangxu Chen, Yuheng Yang, Jingxin Han, Andi Zhang",,,"Large language models, Model Editing, Knowledge Update, Residual Spread","Large language models (LLMs) exhibit exceptional performance across various domains, yet they face critical safety concerns. Model editing has emerged as an effective approach to mitigate these issues. Existing model editing methods often focus on optimizing an information matrix that blends new and old knowledge. While effective, these approaches can be computationally expensive and may cause conflicts. In contrast, we shift our attention to Hierarchical Orthogonal Residual Spread of the information matrix, which reduces noisy gradients and enables more stable edits from a different perspective. We demonstrate the effectiveness of our method HORSE through a clear theoretical comparison with several popular methods and extensive experiments conducted on two datasets across multiple LLMs. The results show that HORSE maintains precise massive editing across diverse scenarios. The code is available at https://github.com/XiaojieGu/HORSE.",17.62,16.347,288,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11442v1_Map2Thought Explicit 3D Spatial Reasoning via Metr.pdf,Map2Thought: Explicit 3D Spatial Reasoning via Metric Cognitive Maps,"Xiangjun Gao, Zhensong Zhang, Dave Zhenyu Chen, Songcen Xu, Long Quan, Eduardo P´erez-Pellitero, Youngkyoon Jang",,,"3D Vision-Language Models, Metric Cognitive Map, Cognitive Chain-of-Thought, Spatial Reasoning, 3D Structure, Data Efficiency","We propose Map2Thought, a framework that enables explicit and interpretable spatial reasoning for 3D Vision-Language Models (3D-VLMs). The framework is grounded in two key components: Metric Cognitive Map (Metric-CogMap) and Cognitive Chain-of-Thought (Cog-CoT). Metric-CogMap provides a unified spatial representation by integrating a discrete grid for relational reasoning with a continuous, metric-scale representation for precise geometric understanding. Building upon the Metric-CogMap, Cog-CoT performs explicit geometric reasoning through deterministic operations (e.g., vector operations, bounding-box distances, and occlusion-aware appearance order cues) producing interpretable inference traces grounded in 3D structure. Experimental results show that Map2Thought enables explainable 3D understanding, achieving 59.9% accuracy using only half the supervision—closely matching the 60.9% baseline trained with the full dataset. It consistently outperforms state-of-the-art methods by 5.3%, 4.8%, and 4.0% under 10%, 25%, and 50% training subsets, respectively, on the VSI-Bench.",18.85,20.321,383,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11451v1_PRISM-CAFO Prior-conditioned Remote-sensing Infras.pdf,PRISM-CAFO: Prior-conditioned Remote-sensing Infrastructure Segmentation and Mapping for CAFOs,"Oishee Bintey Hoque, Nibir Chandra Mandal, Kyle Luong, Amanda Wilson, Samarth Swarup, Madhav Marathe, Abhijin Adiga",,arXiv:2601.11451v1,"CAFOs, remote sensing, infrastructure segmentation, mapping, YOLOv8, deep learning, spatial cross-attention classifier, CAFO type predictions, mask-level attributions, livestock operations, environmental impact","This paper presents an infrastructure-first, explainable pipeline for identifying and characterizing Concentrated Animal Feeding Operations (CAFOs) using aerial and satellite imagery. The method involves detecting candidate infrastructure with a domain-tuned YOLOv8 detector, extracting structured descriptors, and using a spatial cross-attention classifier to fuse these with deep visual features. The approach achieves state-of-the-art performance, with Swin-B+PRISM-CAFO surpassing the best baseline by up to 15%. The study also includes systematic gradient-activation analyses to understand the impact of domain priors on classification decisions. The authors release code, infrastructure masks, and descriptors to support scalable monitoring of livestock infrastructure, aiding in risk modeling, change detection, and regulatory action.",18.41,18.962,349,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11459v1_Interactive Narrative Analytics Bridging Computati.pdf,Interactive Narrative Analytics: Bridging Computational Narrative Extraction and Human Sensemaking,BRIAN KEITH,10.1 109/ACCESS.2025.3650352,,"Human-AI collaboration, information extraction, interactive visual analytics, knowledge integration, narrative extraction, narrative sensemaking, semantic interaction, visual analytics","This paper introduces the field of Interactive Narrative Analytics (INA), which combines computational narrative extraction with interactive visual analytics to support sensemaking. INA addresses challenges in scalability, interactivity, knowledge integration, and evaluation standardization, offering opportunities in news analysis, intelligence, scientific literature exploration, and social media analysis. By integrating computational and human insights, INA tackles complex narrative sensemaking challenges in the digital age.",15.94,12.669,202,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11464v1_MHA2MLA-VLM Enabling DeepSeeks Economical Multi-He.pdf,MHA2MLA-VLM: Enabling DeepSeek’s Economical Multi-Head Latent Attention across Vision-Language Models,"Xiaoran Fan, Zhichao Sun, Tao Ji, Lixing Shen, Tao Gui",,,"Vision-Language Models, Multi-Head Latent Attention, Key-Value Cache, Parameter-Efficient Fine-Tuning, Low-Rank Approximation, Modality-Adaptive Partial-RoPE, KV Cache Compression","As vision-language models (VLMs) tackle increasingly complex and multimodal tasks, the rapid growth of Key-Value (KV) cache imposes significant memory and computational bottlenecks during inference. While Multi-Head Latent Attention (MLA) offers an effective means to compress the KV cache and accelerate inference, adapting existing VLMs to the MLA architecture without costly pretraining remains largely unexplored. This work presents MHA2MLA-VLM, a parameter-efficient and multimodal-aware framework for converting off-the-shelf VLMs to MLA. The approach features a modality-adaptive partial-RoPE strategy and a modality-decoupled low-rank approximation method. Parameter-efficient fine-tuning minimizes adaptation cost, and minimizing output activation error reduces performance loss. Experiments show that MHA2MLA-VLM restores original model performance with minimal supervised data, significantly reduces KV cache footprint, and integrates seamlessly with KV quantization.",18.07,19.199,347,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11468v1_Exploring LLM Features in Predictive Process Monit.pdf,Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs,"ALESSANDRO PADELLA, MASSIMILIANO DE LEONI, MARLON DUMAS",,,"Predictive process monitoring, Large language models, Trace Encoding","Predictive Process Monitoring (PPM) is a branch of process mining that aims to predict the outcome of an ongoing process. This paper extends a prior LLM-based PPM framework, initially focused on total time prediction via prompting, to evaluate its generality, semantic leverage, and reasoning mechanisms across multiple Key Performance Indicators. Empirical evaluations on three distinct event logs show that in data-scarce settings with only 100 traces, the LLM surpasses benchmark methods. The experiments demonstrate that the LLM exploits both its embodied prior knowledge and the internal correlations among training traces. The reasoning strategies employed by the model indicate higher-order reasoning beyond existing predictive methods.",16.68,14.332,239,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11479v1_Health Facility Location in Ethiopia Leveraging LL.pdf,Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning,"Yohai Trabelsi, Guojun Xiong, Fentabil Getnet, Stéphane Verguet, Milind Tambe",,,"Health Facility Location, Optimization, Human expert knowledge, Alignment, LLM","Ethiopia’s Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources require careful prioritization of which facilities to upgrade to maximize population coverage while accounting for diverse expert and stakeholder preferences. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, a hybrid framework is proposed that systematically integrates expert knowledge with optimization techniques. Classical optimization methods provide theoretical guarantees but require explicit, quantitative objectives, whereas stakeholder criteria are often articulated in natural language and difficult to formalize. To bridge these domains, the Large Language Model and Extended Greedy (LEG) framework is developed. This framework combines a provable approximation algorithm for population coverage optimization with LLM-driven iterative refinement that incorporates human-AI alignment to ensure solutions reflect expert qualitative guidance while preserving coverage guarantees. Experiments on real-world data from three Ethiopian regions demonstrate the framework’s effectiveness and its potential to inform equitable, data-driven health system planning.",17.64,17.855,315,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11492v1_BoxMind Closed-loop AI strategy optimization for e.pdf,BoxMind: Closed-loop AI strategy optimization for elite boxing validated in the 2024 Olympics,"Kaiwen Wang, Kaili Zheng, Rongrong Deng, Qingmin Fan, Milin Zhang, Zongrui Li, Xuesi Zhou, Bo Han, Liren Chen, Chenyi Guo, Ji Wu",,arXiv:2601.11492v1,"AI, strategy optimization, elite boxing, closed-loop system, tactical analysis, graph-based predictive model, technical-tactical indicators, competitive sports","Competitive sports require sophisticated tactical analysis, yet combat disciplines like boxing remain underdeveloped in AI-driven analytics due to the complexity of action dynamics and the lack of structured tactical representations. To address this, we present BoxMind, a closed-loop AI expert system validated in elite boxing competition. By defining atomic punch events with precise temporal boundaries and spatial and technical attributes, we parse match footage into 18 hierarchical technical-tactical indicators. We then propose a graph-based predictive model that fuses these explicit technical-tactical profiles with learnable, time-variant latent embeddings to capture the dynamics of boxer matchups. Modeling match outcome as a differentiable function of technical-tactical indicators, we turn winning probability gradients into executable tactical adjustments. Experiments show that the outcome prediction model achieves state-of-the-art performance, with 69.8% accuracy on BoxerGraph test set and 87.5% on Olympic matches. Using this predictive model as a foundation, the system generates strategic recommendations that demonstrate proficiency comparable to human experts. BoxMind is validated through a closed-loop deployment during the 2024 Paris Olympics, directly contributing to the Chinese National Team’s historic achievement of three gold and two silver medals. BoxMind establishes a replicable paradigm for transforming unstructured video data into strategic intelligence, bridging the gap between computer vision and decision support in competitive sports.",20.19,22.585,456,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11496v1_The Poisoned Apple Effect Strategic Manipulation o.pdf,The Poisoned Apple Effect: Strategic Manipulation of Mediated Markets via Technology Expansion of AI Agents,"Eilam Shapira, Moshe Tennenholtz, Roi Reichart",,,"AI agents, economic markets, game theory, regulation, technology expansion, Poisoned Apple effect","The integration of AI agents into economic markets fundamentally alters the landscape of strategic interaction. This study investigates the economic implications of expanding the set of available technologies in three canonical game-theoretic settings: bargaining, negotiation, and persuasion. It identifies the 'Poisoned Apple' effect, where an agent releases a new technology to manipulate the regulator’s choice of market design in their favor, improving their welfare at the expense of their opponent and the regulator’s fairness objectives. The findings suggest that static regulatory frameworks are vulnerable to manipulation via technology expansion, necessitating dynamic market designs that adapt to the evolving landscape of AI capabilities.",16.56,13.464,223,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11505v1_MetaboNet The Largest Publicly Available Consolida.pdf,METABONET: THE LARGEST PUBLICLY AVAILABLE CONSOLIDATED DATASET FOR TYPE1 DIABETES MANAGEMENT,"Miriam K. Wolff, Peter Calhoun, Eleonora Maria Aiello, Yao Qin, Sam F. Royston",,2601.11505v1,"Type 1 Diabetes, algorithm development, data standardization, continuous glucose monitoring, insulin pump dosing, data integration","Progress in Type 1 Diabetes (T1D) algorithm development is limited by the fragmentation and lack of standardization across existing T1D management datasets. This work aims to establish a unified and accessible data resource for T1D algorithm development. Multiple publicly available T1D datasets were consolidated into a unified resource, termed the MetaboNet dataset. The MetaboNet dataset comprises 3135 subjects and 1228 patient-years of overlapping CGM and insulin data, making it substantially larger than existing standalone benchmark datasets. The resource is distributed as a fully public subset available for immediate download and with a Data Use Agreement (DUA)-restricted subset accessible through their respective application processes. A consolidated public dataset for T1D research is presented, and the access pathways for both its unrestricted and DUA-governed components are described. The resulting dataset covers a broad range of glycemic profiles and demographics and thus can yield more generalizable algorithmic performance than individual datasets.",18.99,17.955,341,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11516v2_Building Production-Ready Probes For Gemini.pdf,Building Production-Ready Probes For Gemini,"János Kramár, Joshua Engels, Zheng Wang, Bilal Chughtai, Rohin Shah, Neel Nanda, Arthur Conmy",,,"Activation Probing, Interpretability, Language Models, Misuse Risk, AI Safety, Monitoring","This paper discusses the development of activation probes as a misuse mitigation technique for Gemini, a frontier language model by Google DeepMind. The authors address the challenge of generalizing probes under production distribution shifts, particularly from short-context to long-context inputs. They propose new probe architectures and evaluate their robustness in the cyber-offensive domain, considering distribution shifts like multi-turn conversations and long context prompts. The study finds that combining architecture choice with diverse training distributions enhances generalization. Additionally, pairing probes with prompted classifiers improves accuracy efficiently. The successful deployment of these probes in Gemini is highlighted, along with early positive results from using AlphaEvolve for automating probe architecture search and adaptive red teaming. The paper emphasizes the importance of monitoring as a misuse mitigation strategy, given the limitations of current training techniques in preventing harmful queries.",17.54,16.586,291,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11517v1_Do explanations generalize across large reasoning .pdf,DO EXPLANATIONS GENERALIZE ACROSS LARGE REASONING MODELS?,"Koyena Pal, David Bau, Chandan Singh",,,"Large reasoning models, explanations, generalization, chains of thought, reinforcement learning, consistency, scientific discovery","Large reasoning models (LRMs) produce textual chains of thought (CoT) as explanations for problem-solving, which are potentially useful for understanding problems. However, it is unclear if these explanations generalize across different LRMs, capturing general patterns rather than model-specific quirks. This study evaluates the generalizability of CoT explanations by examining whether explanations from one LRM induce consistent behavior in other LRMs. The findings show that CoT explanations often generalize, correlating with human preference and reinforcement learning. The study also proposes a sentence-level ensembling strategy to improve consistency, highlighting the need for caution when using LRM explanations for new insights and providing a framework for characterizing their generalization.",16.95,14.686,249,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11625v1_Reasoning Stabilization Point A Training-Time Sign.pdf,Reasoning Stabilization Point: A Training-Time Signal for Stable Evidence and Shortcut Reliance,Sahil Rajesh Dhayalkar,,,"fine-tuning, language models, interpretability, explanation drift, Reasoning Stabilization Point, token attributions, shortcut reliance","This paper introduces a training-time interpretability view that tracks token-level attributions across fine-tuning epochs. It defines explanation drift as the change in normalized token attributions between epochs and introduces the Reasoning Stabilization Point (RSP), marking the earliest epoch after which drift remains consistently low. The study shows that explanation drift stabilizes early in training, while validation accuracy changes marginally. It also reveals increasing reliance on shortcuts, even when validation accuracy remains competitive. The paper provides a diagnostic for monitoring decision evidence evolution during fine-tuning and selecting stable-evidence checkpoints.",15.63,13.496,211,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11643v1_Syllabic Agglutinative Tokenizations for Indonesia.pdf,Syllabic Agglutinative Tokenizations for Indonesian LLM: A Study from 'Gasing Literacy Learning System',"Hokky Situngkir, Andhika Bernard Lumbantobing, Yohanes Surya",,2601.11643v1,"Indonesian natural language processing, Indonesian computational linguistics, tokenization, large language models, Gasing Literacy Learning System, low-resource languages, Austronesian languages","This paper presents a novel syllable-based tokenization approach for Indonesian large language models, inspired by the Gasing Literacy Learning System’s pedagogical methodology. Drawing on information-theoretic principles, we develop a tokenization framework that segments Indonesian text at syllable boundaries before applying byte-pair encoding, creating a vocabulary that aligns with the language’s morphophonological structure. Our approach first identifies high-frequency syllables through rule-based segmentation, then constructs a compact vocabulary of 3,500 tokens that preserves meaningful linguistic units while maintaining coverage through character-level fallback. Empirical evaluation on Indonesian Wikipedia and folklore corpora from Indonesian Culture Digital Library (PDBI) demonstrates substantial improvements over conventional tokenization methods: the syllable-based approach achieves Rényi efficiency of 0.74 compared to 0.50-0.64 for pretrained multilingual tokenizers, while maintaining higher average token lengths (3.67 characters versus 2.72 for GPT-2) despite using a vocabulary an order of magnitude smaller. These gains emerge from the method’s ability to internalize character-level dependencies within syllable units, reducing the computational burden on language models while respecting Indonesian’s agglutinative morphology. We call the LLM built upon this principle, TOBA LLM (Tokenisasi Optimum Berbasis Aglutinasi), the convergence of human literacy pedagogy with computational optimization principles offers a promising paradigm for developing linguistically-informed tokenization strategies, particularly for morphologically rich and underrepresented languages in natural language processing.",19.98,23.224,464,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11644v1_Predicting When to Trust Vision-Language Models fo.pdf,Predicting When to Trust Vision-Language Models for Spatial Reasoning,"Muhammad Imran, Yugyung Lee",,,"Vision-Language Models, Spatial Reasoning, Confidence Estimation, Geometric Verification, Object Detection, Autonomous Systems, Robotics","Vision-Language Models (VLMs) demonstrate impressive capabilities across multimodal tasks but exhibit systematic spatial reasoning failures, achieving only 49% to 54% accuracy on basic directional relationships. For safe deployment in robotics and autonomous systems, it is crucial to predict when to trust VLM spatial predictions. This paper proposes a vision-based confidence estimation framework that validates VLM predictions through independent geometric verification using object detection. The method fuses four signals via gradient boosting: geometric alignment, spatial ambiguity, detection quality, and VLM internal uncertainty. The framework achieves significant improvements in AUROC over text-based baselines and enables selective prediction, improving coverage and precision in scene graph construction.",16.09,14.912,240,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11647v1_Reinforcement Learning for Dynamic Workflow Optimi.pdf,Reinforcement Learning for Dynamic Workflow Optimization in CI/CD Pipelines,"Aniket Abhishek Soni, Milan Parikh, Rashi Nimesh Kumar Dhenia, Jubin Abhishek Soni, Ayush Raj Jha, Sneja Mitinbhai Shah",,,"Reinforcement Learning, CI/CD, DevOps, Workflow Optimization","Continuous Integration and Deployment (CI/CD) pipelines are essential for modern software delivery, but their static workflows can be inefficient. This paper proposes a reinforcement learning (RL) approach to optimize CI/CD pipeline workflows dynamically. The pipeline is modeled as a Markov Decision Process, and an RL agent is trained to make runtime decisions that maximize throughput while minimizing testing overhead. A simulated CI/CD environment is developed to evaluate the approach, showing up to a 30% improvement in throughput and about a 25% reduction in test execution overhead compared to a static baseline. The agent learns to skip or abbreviate certain tests when appropriate, accelerating delivery without significantly increasing the risk of undetected failures. This work demonstrates the potential of RL to adapt DevOps workflows for greater efficiency, providing novel insights into intelligent pipeline automation.",17.61,16.976,299,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11650v1_Large Language Model Agent for User-friendly Chemi.pdf,LARGE LANGUAGE MODEL AGENT FOR USER-FRIENDLY CHEMICAL PROCESS SIMULATIONS,"Jingkang Liang, Niklas Groll, Gürkan Sin",,2601.11650v1,"Chemical Process Simulation, Large Language Model, Model Context Protocol","Modern process simulators enable detailed process design, simulation, and optimization; however, constructing and interpreting simulations is time-consuming and requires expert knowledge. This limits early exploration by inexperienced users. To address this, a large language model (LLM) agent is integrated with AVEVA Process Simulation (APS) via Model Context Protocol (MCP), allowing natural language interaction with rigorous process simulations. An MCP server toolset enables the LLM to communicate programmatically with APS using Python, allowing it to execute complex simulation tasks from plain-language instructions. Two water-methanol separation case studies assess the framework across different task complexities and interaction modes. The first shows the agent autonomously analyzing flowsheets, finding improvement opportunities, and iteratively optimizing, extracting data, and presenting results clearly. The framework benefits both educational purposes, by translating technical concepts and demonstrating workflows, and experienced practitioners by automating data extraction, speeding routine tasks, and supporting brainstorming. The second case study assesses autonomous flowsheet synthesis through both a step-by-step dialogue and a single prompt, demonstrating its potential for novices and experts alike. The step-by-step mode gives reliable, guided construction suitable for educational contexts; the single-prompt mode constructs fast baseline flowsheets for later refinement. While current limitations such as oversimplification, calculation errors, and technical hiccups mean expert oversight is still needed, the framework’s capabilities in analysis, optimization, and guided construction suggest LLM-based agents can become valuable collaborators.",20.28,19.823,402,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11651v1_Aesthetics as Structural Harm Algorithmic Lookism .pdf,Aesthetics as Structural Harm: Algorithmic Lookism Across Text-to-Image Generation and Classification,"Miriam Doh, Aditya Gulati, Corina Canali, Nuria Oliver",,2601.11651v1,"Generative AI, Artificial Intelligence, Cognitive Biases, Attractiveness Halo Effect","This paper examines algorithmic lookism—the systematic preferential treatment based on physical appearance—in text-to-image (T2I) generative AI and a downstream gender classification task. Through the analysis of 26,400 synthetic faces created with Stable Diffusion 2.1 and 3.5 Medium, it demonstrates how generative AI models systematically associate facial attractiveness with positive attributes and vice versa, mirroring socially constructed biases rather than evidence-based correlations. Furthermore, significant gender bias is found in three gender classification algorithms depending on the attributes of the input faces. The findings reveal three critical harms: (1) the systematic encoding of attractiveness-positive attribute associations in T2I models; (2) gender disparities in classification systems, where women’s faces, particularly those generated with negative attributes, suffer substantially higher misclassification rates than men’s; and (3) intensifying aesthetic constraints in newer models through age homogenization, gendered exposure patterns, and geographic reductionism. These convergent patterns reveal algorithmic lookism as a systematic infrastructure operating across AI vision systems, compounding existing inequalities through both representation and recognition. Disclaimer: This work includes visual and textual content that reflects stereotypical associations between physical appearance and socially constructed attributes, including gender, race, and traits associated with social desirability. Any such associations found in this study emerge from the biases embedded in generative AI systems—not from empirical truths or the authors’ views.",19.43,20.901,406,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11652v1_WISP Waste- and Interference-Suppressed Distribute.pdf,WISP: Waste- and Interference-Suppressed Distributed Speculative LLM Serving at the Edge via Dynamic Drafting and SLO-Aware Batching,"XIANGCHEN LI, JIAKUN FAN, QINGYUAN WANG, DIMITRIOS SPATHARAKIS, SAEID GHAFOURI, HANS VANDIERENDONCK, DEEPU JOHN, BO JI, ALI R. BUTT, DIMITRIOS S. NIKOLOPOULOS",10.1145/376xxxx.377xxxx,,"Speculative Decoding, Large Language Models, Edge Computing, Distributed Inference, Token Verification, Resource-Aware Serving","As Large Language Models (LLMs) become increasingly accessible to end users, an ever-growing number of inference requests are initiated from edge devices and computed on centralized GPU clusters. However, the resulting exponential growth in computation workload is placing significant strain on data centers, while edge devices remain largely underutilized, leading to imbalanced workloads and resource inefficiency across the network. Integrating edge devices into the LLM inference process via speculative decoding helps balance the workload between the edge and the cloud, while maintaining lossless prediction accuracy. In this paper, we identify and formalize two critical bottlenecks that limit the efficiency and scalability of distributed speculative LLM serving: Wasted Drafting Time and Verification Interference. To address these challenges, we propose WISP, an efficient and SLO-aware distributed LLM inference system that consists of an intelligent speculation controller, a verification time estimator, and a verification batch scheduler. These components collaboratively enhance drafting efficiency and optimize verification request scheduling on the server. Extensive numerical results show that WISP improves system capacity by up to 2.1× and 4.1×, and increases system goodput by up to 1.94× and 3.7×, compared to centralized serving and SLED, respectively.",19.18,24.505,470,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11657v1_Size is Not the Solution Deformable Convolutions f.pdf,Size is Not the Solution: Deformable Convolutions for Effective Physics Aware Deep Learning,"Jack T. Beerman, Shobhan Roy, H.S. Udaykumar, Stephen S. Baek",,,"Physics-aware deep learning, Deformable convolutions, Hybrid Lagrangian-Eulerian methods, Burgers’ equation, Navier-Stokes, Reactive flows, Adaptive refinement, Computational mechanics","Physics-aware deep learning (PADL) enables rapid prediction of complex physical systems, yet current convolutional neural network (CNN) architectures struggle with highly nonlinear flows. While scaling model size addresses complexity in broader AI, this approach yields diminishing returns for physics modeling. Drawing inspiration from Hybrid Lagrangian-Eulerian (HLE) numerical methods, we introduce deformable physics-aware recurrent convolutions (D-PARC) to overcome the rigidity of CNNs. Across Burgers’ equation, Navier-Stokes, and reactive flows, D-PARC achieves superior fidelity compared to substantially larger architectures. Analysis reveals that kernels display anti-clustering behavior, evolving into a learned 'active filtration' strategy distinct from traditional h- or p-adaptivity. Effective receptive field analysis confirms that D-PARC autonomously concentrates resources in high-strain regions while coarsening focus elsewhere, mirroring adaptive refinement in computational mechanics. This demonstrates that physically intuitive architectural design can outperform parameter scaling, establishing that strategic learning in lean networks offers a more effective path forward for PADL than indiscriminate network expansion.",19.16,19.103,366,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11658v1_Towards AGI A Pragmatic Approach Towards Self Evol.pdf,Towards AGI: A Pragmatic Approach Towards Self Evolving Agent,"Indrajit Kar, Sammy Zonunpuia, Zonunfeli Ralte",,,"Self-evolving agents, Large Language Models (LLMs), Curriculum Learning (CL), Reward-Based Learning (RL), Genetic Algorithm (GA) evolution, Multi-agent systems, Tool-augmented reasoning, Code-generation LLMs, Autonomous adaptation, TaskCraft dataset, Agentic workflows, Self-improving AI, Capability evolution, Hierarchical orchestration","Large Language Model (LLM) based agents are powerful yet fundamentally static after deployment, lacking the ability to autonomously expand capabilities, generate new tools, or evolve their reasoning. This work introduces a hierarchical self-evolving multi-agent framework that integrates a Base LLM, an operational SLM agent, a Code-Generation LLM, and a Teacher-LLM to enable continuous adaptation. The workflow begins with the agent attempting a task using reasoning and existing tools; if unsuccessful, it escalates to tool synthesis through the Code-Gen LLM, and when failures persist, it triggers an evolution phase using Curriculum Learning (CL), Reward-Based Learning (RL), or Genetic Algorithm (GA) evolution. Using the TaskCraft dataset rich in hierarchical tasks, tool-use traces, and difficulty scaling, we evaluate these paradigms. CL delivers fast recovery and strong generalization, RL excels on high-difficulty tasks, and GA offers high behavioral diversity. Across all settings, evolved agents outperform their originals, demonstrating robust, autonomous, self-improving agentic evolution.",19.27,20.546,396,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11663v1_Activation Sensitivity as a Unifying Principle for.pdf,Activation Sensitivity as a Unifying Principle for Post-Training Quantization,Bruce Changlong Xu,,,"Post-Training Quantization, Activation Sensitivity, Large Language Models, Quantization Error, Activation-Aware Methods, Second-Order Methods, Gradient-Weighted Activations, Sensitivity Metrics, Pruning Methods","This work presents a unified theoretical framework for post-training quantization (PTQ) by formalizing activation sensitivity, which measures the expected impact of channel-wise perturbations on the loss. The study shows that sensitivity naturally emerges as the squared norm of gradient-weighted activations, providing a principled measure of channel importance. It connects activation-aware methods like AWQ and second-order methods like GPTQ as complementary approximations of sensitivity. The paper analyzes the design space of sensitivity metrics, linking them to gradient-based saliency, Fisher information, and Hessian-based criteria, and discusses their relationships to classical pruning methods. It highlights challenges in PTQ, such as cross-layer error accumulation and calibration distribution mismatch, offering a conceptual foundation for understanding and extending PTQ methods.",17.09,15.097,258,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11664v1_Serverless AI Security Attack Surface Analysis and.pdf,Serverless AI Security: Attack Surface Analysis and Runtime Protection Mechanisms for FaaS-Based Machine Learning,"Chetan Pathade, Vinod Dhimam, Ilsa Lareb, Sheheryar Ahmad",,,"Serverless computing, machine learning security, Function-as-a-Service, cloud security, adversarial machine learning, AWS Lambda, Azure Functions, attack surface analysis, runtime protection, MLOps security","Serverless computing has achieved widespread adoption, with over 70% of AWS organizations using serverless solutions. Meanwhile, machine learning inference workloads increasingly migrate to Function-as-a-Service (FaaS) platforms for their scalability and cost-efficiency. However, this convergence introduces critical security challenges, with recent reports showing a 220% increase in AI/ML vulnerabilities. This paper presents the first comprehensive security analysis of machine learning workloads in serverless environments. We systematically characterize the attack surface across five categories: function-level vulnerabilities, model-specific threats, infrastructure attacks, supply chain risks, and IAM complexity. Through empirical assessments across AWS Lambda, Azure Functions, and Google Cloud Functions, we demonstrate real-world attack scenarios and quantify their security impact. We propose Serverless AI Shield (SAS), a multi-layered defense framework providing pre-deployment validation, runtime monitoring, and post-execution forensics. Our evaluation shows SAS achieves 94% detection rates while maintaining performance overhead below 9% for inference latency. We release an open-source security toolkit to enable practitioners to assess and harden their serverless AI deployments, advancing the field toward more resilient cloud-native machine learning systems.",19.06,20.248,386,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11666v1_MATEX Multi-scale Attention and Text-guided Explai.pdf,MATEX: Multi-scale Attention and Text-guided Explainability of Medical Vision-Language Models,"Muhammad Imran, Chi Lee, Yugyung Lee",,2601.11666v1,"Explainable AI, Medical Imaging, Vision-Language Models, Gradient Attribution, Attention Rollout, Chest X-ray, CLIP","We introduce MATEX (Multi-scale Attention and Text-guided Explainability), a novel framework that advances interpretability in medical vision-language models by incorporating anatomically informed spatial reasoning. MATEX synergistically combines multi-layer attention rollout, text-guided spatial priors, and layer consistency analysis to produce precise, stable, and clinically meaningful gradient attribution maps. By addressing key limitations of prior methods—such as spatial imprecision, lack of anatomical grounding, and limited attention granularity—MATEX enables more faithful and interpretable model explanations. Evaluated on the MS-CXR dataset, MATEX outperforms the state-of-the-art M2IB approach in both spatial precision and alignment with expert-annotated findings. These results highlight MATEX’s potential to enhance trust and transparency in radiological AI applications.",17.66,16.423,290,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11667v1_Distill-then-Replace Efficient Task-Specific Hybri.pdf,Distill-then-Replace: Efficient Task-Specific Hybrid Attention Model Construction,"Xiaojie Xia, Huigang Zhang, Chaoliang Zhong, Jun Sun, Yusuke Oishi",,arXiv:2601.11667v1,"Hybrid attention models, Blockwise local distillation, Greedy search","Transformer architectures deliver state-of-the-art accuracy via dense full-attention, but their quadratic time and memory complexity with respect to sequence length limits practical deployment. Linear attention mechanisms offer linear or near-linear scaling yet often incur performance degradation. Hybrid models that integrate full and linear attention layers promise a balance between efficiency and expressiveness, but face two major challenges: training such hybrid models from scratch is computationally expensive, and manually designing the optimal placement of attention types is highly nontrivial. We address both issues by first transferring weights from the pretrained full-attention modules to its linear attention counterparts through blockwise local distillation, and second, introducing a greedy layer replacement strategy that iteratively substitutes full attention blocks with linear ones while monitoring validation performance on the target task. This yields a task-specific hybrid model in a single efficient pass, without costly re-training or neural architecture search, and can be applied to any pretrained full-attention backbone for diverse downstream tasks.",19.16,16.232,311,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11670v1_A Confidence-Variance Theory for Pseudo-Label Sele.pdf,A Confidence-Variance Theory for Pseudo-Label Selection in Semi-Supervised Learning,"Jinshi Liu, Pan Liu",,,"Semi-Supervised Learning, Pseudo-Labels, Confidence Calibration, Residual Class Variance, Spectral Relaxation, Semantic Segmentation, Image Classification","This paper introduces a Confidence-Variance (CoVar) theory framework for pseudo-label selection in semi-supervised learning. It addresses the issue of overconfidence in deep networks by proposing a joint reliability criterion that combines maximum confidence (MC) with residual-class variance (RCV). The framework suggests that reliable pseudo-labels should have high MC and low RCV, with the influence of RCV increasing as confidence grows. This approach corrects overconfident but unstable predictions. The paper integrates CoVar into semi-supervised semantic segmentation and image classification methods, showing consistent improvements over strong baselines across various datasets and label ratios. The code is available at https://github.com/ljs11528/CoVar Pseudo Label Selection.git.",15.68,15.244,239,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11674v1_Pigment Network Detection and Classification in De.pdf,Pigment Network Detection and Classification in Dermoscopic Images Using Directional Imaging Algorithms and Convolutional Neural Networks,"M. A. Rasel, Sameem Abdul Kareem, Unaizah Obaidellah",10.1016/j.bspc.2024.106883,,"Melanoma, Dermoscopic Images, Pigment Networks, Contrast Enhancement, Threshold Level, Convolutional Neural Networks, Bag of Features","Early diagnosis of melanoma relies heavily on the analysis of dermoscopic images, particularly the identification of unusual pigment networks (PN). This study aims to automate the PN detection process using a directional imaging algorithm and classify PN types using machine learning classifiers. The directional imaging algorithm incorporates Principal Component Analysis (PCA), contrast enhancement, filtering, and noise reduction. Applied to the PH2 dataset, this algorithm achieved a 96% success rate, which increased to 100% after pixel intensity adjustments. A new dataset containing only PN images was created from these results. Two classifiers, Convolutional Neural Network (CNN) and Bag of Features (BoF), were employed to categorize PN into atypical and typical classes. A simple and effective CNN was designed, featuring two convolutional layers and two batch normalization layers, achieving 90% accuracy, 90% sensitivity, and 89% specificity. The proposed CNN demonstrated superior performance compared to state-of-the-art methods. The study highlights the potential of the proposed CNN model for effective PN classification, suggesting future research should focus on expanding datasets and incorporating additional dermatological features to further enhance melanoma diagnosis.",18.85,20.005,377,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11675v1_Generating metamers of human scene understanding.pdf,GENERATING METAMERS OF HUMAN SCENE UNDERSTANDING,"Ritik Raina, Abe Leite, Alexandros Graikos, Seoyoung Ahn, Dimitris Samaras, Gregory J. Zelinsky",,,"human vision, latent scene representations, latent diffusion model, foveated scenes, DINOv2 tokens, same-different behavioral experiment, scene metamers, visual processing, semantic alignment","Human vision combines low-resolution 'gist' information from the visual periphery with high-resolution information from fixated locations to construct a coherent understanding of a visual scene. This paper introduces Metamer-Gen, a tool for generating scenes aligned with latent human scene representations. Metamer-Gen is a latent diffusion model that synthesizes image metamers by combining peripherally obtained scene gist information with information from scene-viewing fixations. The tool addresses a novel image-to-image synthesis problem by using a dual-stream representation of foveated scenes, integrating DINOv2 tokens to fuse detailed features from fixated areas with peripherally degraded features capturing scene context. A same-different behavioral experiment was conducted to evaluate the perceptual alignment of Metamer-Gen generated images with latent human scene representations. The study identifies scene generations that are metamers for the latent scene representations formed by viewers. Metamer-Gen is a powerful tool for understanding scene understanding, uncovering specific features at multiple levels of visual processing that contribute to human judgments. While it can generate metamers conditioned on random fixations, high-level semantic alignment most strongly predicts metamerism when conditioned on viewers' own fixated regions.",18.82,19.55,368,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11676v1_HALO Semantic-Aware Distributed LLM Inference in L.pdf,HALO: Semantic-Aware Distributed LLM Inference in Lossy Edge Network,"Peirong Zheng, Wenchao Xu, Haozhao Wang, Jinyu Chen, Xuemin (Sherman) Shen",,,"Large Language Models, Tensor Parallelism, Edge Computing, Heterogeneity, Semantics, Packet Loss","The deployment of large language models (LLMs) at the edge can enhance prompt service responsiveness while protecting user privacy. However, resource constraints of a single edge node pose challenges. Distributed inference, which aggregates computational resources across multiple devices, is often hindered by the need for strict synchronization due to unreliable network conditions. This paper introduces HALO, a framework designed to improve distributed LLM inference in lossy edge networks by enabling relaxed synchronization. HALO strategically allocates less critical neuron groups to unstable devices, reducing excessive waiting times caused by delayed packets. It incorporates three key mechanisms: a semantic-aware predictor to assess neuron group significance, a parallel execution scheme for neuron group loading during model inference, and a load-balancing scheduler for orchestrating devices with heterogeneous resources. Experimental results from a Raspberry Pi cluster show that HALO achieves a 3.41x end-to-end speedup for LLaMA-series LLMs under unreliable network conditions, maintaining performance comparable to optimal conditions and significantly outperforming state-of-the-art methods in various scenarios.",17.6,17.666,311,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11683v1_Attesting Model Lineage by Consisted Knowledge Evo.pdf,Attesting Model Lineage by Consisted Knowledge Evolution with Fine-Tuning Trajectory,"Zhuoyi Shang, Jiasen Li, Pengzhen Chen, Yanwei Liu, Xiaoyan Gu, Weiping Wang",,,"model lineage, fine-tuning, knowledge evolution, security, deep learning, model verification","The fine-tuning technique in deep learning introduces a lineage relationship among models, which can be leveraged to address security concerns such as unauthorized model redistribution and false claims of model provenance. Existing approaches to model lineage detection rely on static architectural similarities, which are insufficient for capturing the dynamic evolution of knowledge. This paper proposes a novel model lineage attestation framework that verifies the joint trajectory of knowledge evolution and parameter modification. The framework uses model editing to quantify parameter-level changes and introduces a knowledge vectorization mechanism to refine evolved knowledge into compact representations. These embeddings verify the arithmetic consistency of knowledge relationships across models, enabling robust attestation of model lineage. The approach is evaluated in various adversarial scenarios and demonstrates effectiveness across different model types, including classifiers, diffusion models, and large language models.",17.49,16.295,285,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11684v1_Mobile-friendly Image de-noising Hardware Consciou.pdf,Mobile-friendly Image de-noising: Hardware Conscious Optimization for Edge Application,"Srinivas Miriyala, Sowmya Vajrala, Hitesh Kumar, Sravanth Kodavanti, Vikram Rajendiran",,,"De-Noising, Differentiable NAS, Hardware aware Search space, Smartphone Deployment","Image enhancement is a critical task in computer vision and photography that is often entangled with noise, rendering traditional Image Signal Processing (ISP) ineffective compared to advances in deep learning. However, the success of such methods is increasingly associated with their ease of deployment on edge devices, such as smartphones. This work presents a novel mobile-friendly network for image de-noising obtained with Entropy-Regularized differentiable Neural Architecture Search (NAS) on a hardware-aware search space for a U-Net architecture, which is first-of-its-kind. The designed model has 12% fewer parameters, with ~2-fold improvement in on-device latency and 1.5-fold improvement in the memory footprint for a 0.7% drop in PSNR, when deployed and profiled on Samsung Galaxy S24 Ultra. Compared to the SOTA Swin-Transformer for Image Restoration, the proposed network had competitive accuracy with ~18-fold reduction in GMACs. Further, the network was tested successfully for Gaussian de-noising with 3 intensities on 4 benchmarks and real-world de-noising on 1 benchmark demonstrating its generalization ability.",18.43,18.884,348,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11685v1_Towards Efficient Image Deblurring for Edge Deploy.pdf,Towards Efficient Image Deblurring for Edge Deployment,"Srinivas Soumitri Miriyala, Sowmya Lahari Vajrala, Rama Sravanth Kodavanti",,,"Mobile Image Signal Processing (ISP), De-blurring, Training-free Search, Inference Optimization, Edge Deployment","Image deblurring is a critical stage in mobile image signal processing pipelines, where the ability to restore fine structures and textures must be balanced with real-time constraints on edge devices. While recent deep networks such as transformers and activation-free architectures achieve state-of-the-art accuracy, their efficiency is typically measured in FLOPs or parameters, which do not correlate with latency on embedded hardware. This work proposes a hardware-aware adaptation framework that restructures existing models through sensitivity-guided block substitution, surrogate distillation, and training-free multi-objective search driven by device profiling. Applied to the 36-block NAFNet baseline, the optimized variants achieve up to 55% reduction in GMACs compared to recent transformer-based state-of-the-art while maintaining competitive accuracy. On-device deployment yields a 1.25× latency improvement over the baseline. Experiments on motion deblurring (GoPro), defocus deblurring (DPDD), and auxiliary benchmarks (RealBlur-J/R, HIDE) demonstrate the generality of the approach, while comparisons with prior efficient baselines confirm its accuracy-efficiency trade-off. These results establish feedback-driven adaptation as a principled strategy for bridging the gap between algorithmic design and deployment-ready deblurring models.",19.1,19.111,365,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11686v1_Proof of Concept Multi-Target Wildfire Risk Predic.pdf,Proof of Concept: Multi-Target Wildfire Risk Prediction and Large Language Model Synthesis,"Nicolas Caron, Hassan Noura, Christophe Guyeux, Benjamin Aynes",,arXiv:2601.11686v1,"wildfire risk assessment, multi-target analysis, meteorological danger, ignition activity, intervention complexity, resource mobilization, large language models, predictive models, structured reports, forest-fire risk prediction, climate change, operational needs, AI-driven predictors","Current state-of-the-art approaches to wildfire risk assessment often overlook operational needs, limiting their practical value for first responders and firefighting services. Effective wildfire management requires a multi-target analysis that captures the diverse aspects of wildfire risk—including meteorological danger, ignition activity, intervention complexity, and resource mobilization—rather than relying on a single predictive indicator. In this proof of concept, we suggest the development of a hybrid framework that combines predictive models for each risk dimension with large language models (LLMs) dedicated to synthesizing heterogeneous outputs into structured, actionable reports.",18.25,15.724,287,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11687v1_Semantic Caching and Intent-Driven Context Optimiz.pdf,Semantic Caching and Intent-Driven Context Optimization for Multi-Agent Natural Language to Code Systems: A Production Study in Enterprise Analytics,"Harmohit Singh, CoreOps AI",,2601.11687v1,"Natural Language to Code, Multi-Agent Systems, Semantic Caching, LLM Optimization, Production Systems","We present a production-optimized multi-agent system designed to translate natural language queries into executable Python code for structured data analytics. Unlike systems that rely on expensive frontier models, our approach achieves high accuracy and cost efficiency through three key innovations: (1) a semantic caching system with LLM-based equivalence detection and structured adaptation hints that provides cache hit rates of 67% on production queries; (2) a dual-threshold decision mechanism that separates exact-match retrieval from reference-guided generation; and (3) an intent-driven dynamic prompt assembly system that reduces token consumption by 40-60% through table-aware context filtering. The system has been deployed in production for enterprise inventory management, processing over 10,000 queries with an average latency of 8.2 seconds and 94.3% semantic accuracy. We describe the architecture, present empirical results from production deployment, and discuss practical considerations for deploying LLM-based analytics systems at scale.",20.58,14.672,302,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11688v1_SpecMap Hierarchical LLM Agent for Datasheet-to-Co.pdf,SpecMap: Hierarchical LLM Agent for Datasheet-to-Code,"Vedant Nipane, Pulkit Agrawal, Amit Singh",,2601.11688v1,"Traceability Link Recovery, Systems Engineering, Datasheet-to-Code Mapping, Large Language Models, Semantic Analysis, Embedded Systems, C/C++ Codebases","Establishing precise traceability between embedded systems datasheets and their corresponding code implementations remains a fundamental challenge in systems engineering, particularly for low-level software where manual mapping between specification documents and large code repositories is infeasible. Existing Traceability Link Recovery (TLR) approaches primarily rely on lexical similarity and information retrieval techniques, which struggle to capture the semantic, structural, and symbol-level relationships prevalent in embedded systems software. We present a hierarchical datasheet-to-code mapping methodology that employs large language models (LLMs) for semantic analysis while explicitly structuring the traceability process across multiple abstraction levels. Rather than performing direct specification-to-code matching, the proposed approach progressively narrows the search space through repository-level structure inference, file-level relevance estimation, and fine-grained symbol-level alignment. The method extends beyond function-centric mapping by explicitly covering macros, structs, constants, configuration parameters, and register definitions commonly found in systems-level C/C++ codebases. We evaluate the approach on multiple open-source embedded systems repositories using manually curated datasheet-to-code ground truth. Experimental results show substantial improvements over traditional information-retrieval-based baselines, achieving up to 73.3% file mapping accuracy. The hierarchical decomposition significantly reduces computational overhead, lowering total LLM token consumption by 84% and end-to-end runtime by approximately 80%. This methodology supports automated analysis of large embedded software systems and enables downstream applications such as training data generation for systems-aware machine learning models, standards compliance verification, and large-scale specification coverage analysis.",20.29,20.107,408,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11700v1_Telling Human and Machine Handwriting Apart.pdf,Telling Human and Machine Handwriting Apart,"Luis A. Leiva, Moises Diaz, Nuwan T. Attygalle, Miguel A. Ferrer, Réjean Plamondon",,,"Biometrics, classification, deep learning, reverse Turing test, verification","Handwriting movements can be used as a unique form of behavioral biometrics to verify if a real user is operating a device or application. This task, framed as a 'reverse Turing test,' involves detecting if an input instance is generated by a human or artificially. The study examines ten public datasets of handwritten symbols reproduced using seven different synthesizers, including the Kinematic Theory (Σh model), generative adversarial networks, Transformers, and Diffusion models. A shallow recurrent neural network is trained, achieving an average of 98.3% AUC score and 1.4% equal error rate across all synthesizers and datasets. The classifier performs well even in few-shot settings and out-of-domain challenges, providing implications for computerized systems needing to verify human presence and adding an additional layer of security.",16.94,16.41,278,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11702v1_PASTA A Scalable Framework for Multi-Policy AI Com.pdf,PASTA: A Scalable Framework for Multi-Policy AI Compliance,"YU YANG, IG-JAE KIM, DONGWOOK YOON",,,"AI compliance, multi-policy, scalable framework, LLM-powered evaluation, compliance heatmaps, automated AI governance","AI compliance is becoming increasingly critical as AI systems grow more powerful and pervasive. Existing approaches typically address one policy at a time, making multi-policy compliance costly. This paper presents PASTA, a scalable compliance tool integrating four innovations: a comprehensive model-card format, a policy normalization scheme, an efficient LLM-powered pairwise evaluation engine with cost-saving strategies, and an interface delivering interpretable evaluations via compliance heatmaps and actionable recommendations. Expert evaluation shows PASTA’s judgments closely align with human experts (𝜌≥. 626). The system evaluates five major policies in under two minutes at approximately $3. A user study confirms practitioners found outputs easy-to-understand and actionable, introducing a novel framework for scalable automated AI governance.",17.52,14.952,262,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11713v1_Inter-Cell Interference Rejection Based on Ultrawi.pdf,Inter-Cell Interference Rejection Based on Ultrawideband Walsh-Domain Wireless Autoencoding,"Rodney Martinez Alonso, Cel Thys, Sofie Pollin, Cedric Dehos, Yuneisy Esthela Garcia Guzman",,,"ultrawideband, inter-cell interference, autoencoder, Walsh domain, 5G, interference rejection","This paper proposes a novel technique for rejecting partial-in-band inter-cell interference (ICI) in ultrawideband communication systems. It presents an end-to-end wireless autoencoder architecture that optimizes transmitter and receiver encoding/decoding in the Walsh domain to mitigate interference from coexisting narrower-band 5G base stations. By leveraging the orthogonality and self-inverse properties of Walsh functions, the system encodes bit-words across parallel Walsh branches. Analytical modeling and simulation characterize how 5G CP-OFDM interference maps into the Walsh domain, identifying optimal transmission frequency and sampling rate ratios for maximum ICI rejection. Experimental results show up to 12 dB of ICI rejection while maintaining a low block error rate (BLER) under baseline channel noise conditions.",17.78,16.254,289,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11746v1_LIME-LLM Probing Models with Fluent Counterfactual.pdf,"LIME-LLM: Probing Models with Fluent Counterfactuals, Not Broken Text","George Mihaila, Suleyman Olcay Polat, Poli Nemkova, Himanshu Sharma, Namratha V. Urs, Mark V. Albert",,arXiv:2601.11746v1,"LIME, LLM, NLP, explainability, counterfactuals, trustworthy AI","Local explanation methods such as LIME remain fundamental to trustworthy AI, yet their application to NLP is limited by a reliance on random token masking. These heuristic perturbations frequently generate semantically invalid, out-of-distribution inputs that weaken the fidelity of local surrogate models. While recent generative approaches such as LLiMe attempt to mitigate this by employing Large Language Models for neighborhood generation, they rely on unconstrained paraphrasing that introduces confounding variables, making it difficult to isolate specific feature contributions. We introduce LIME-LLM, a framework that replaces random noise with hypothesis-driven, controlled perturbations. By enforcing a strict 'Single Mask–Single Sample' protocol and employing distinct neutral infill and boundary infill strategies, LIME-LLM constructs fluent, on-manifold neighborhoods that rigorously isolate feature effects. We evaluate our method against established baselines (LIME, SHAP, Integrated Gradients) and the generative LLiMe baseline across three diverse benchmarks: CoLA, SST-2, and HateXplain using human-annotated rationales as ground truth. Empirical results demonstrate that LIME-LLM establishes a new benchmark for black-box NLP explainability, achieving significant improvements in local explanation fidelity compared to both traditional perturbation-based methods and recent generative alternatives.",19.48,21.402,417,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11747v1_PRISM Learning Design Knowledge from Data for Styl.pdf,PRISM: Learning Design Knowledge from Data for Stylistic Design Improvement,"Huaxiaoyue Wang, Sunav Choudhary, Franck Dernoncourt, Yu Shen, Stefano Petrangeli",,,"graphic design, stylistic improvement, natural language instructions, Vision Language Models, design knowledge, Crello dataset","Graphic design often involves exploring different stylistic directions, which can be time-consuming for non-experts. This paper addresses the problem of stylistically improving designs based on natural language instructions. While Vision Language Models (VLMs) have shown initial success in graphic design, their pretrained knowledge on styles is often too general and misaligned with specific domain data. The paper proposes PRISM (PRior-Informed Stylistic Modification), which constructs and applies a design knowledge base through three stages: clustering high-variance designs to capture diversity within a style, summarizing each cluster into actionable design knowledge, and retrieving relevant knowledge during inference to enable style-aware improvement. Experiments on the Crello dataset show that PRISM achieves the highest average rank over baselines in style alignment. User studies further validate these results, showing that PRISM is consistently preferred by designers.",17.07,16.113,275,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11758v1_Early Linguistic Pattern of Anxiety from Social Me.pdf,Early Linguistic Pattern of Anxiety from Social Media: Using Interpretable Linguistic Features: A Multi-Faceted Validation Study with Author-Disjoint Evaluation,Arnab Das Utsa,,,"anxiety detection, linguistic pattern, interpretable machine learning, keyword robustness, cross-domain validation, author-disjoint evaluation, mental health screening","Anxiety affects hundreds of millions globally, yet large-scale screening is limited. This study presents a transparent approach to social media-based anxiety detection using interpretable linguistic features. A logistic regression classifier was trained on Reddit posts, with evaluations including feature ablation, keyword masking, and cross-domain validation. The model showed strong performance and high accuracy even after sentiment removal or keyword masking. Early detection using minimal post history outperformed random classification, and results were consistent with clinical interview data. The framework provides a reproducible baseline for interpretable mental health screening across diverse online contexts.",16.23,13.31,216,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11762v1_Industry-Aligned Granular Topic Modeling.pdf,Industry-Aligned Granular Topic Modeling,"Sae Young Moon, Myeongjun Erik Jang, Haoyan Luo, Chunyang Xiao, Antonios Georgiadis, Fran Silavong",,,"topic modeling, granularity, large language models, business applications, text mining, data analysis","Topic modeling is widely used in text mining and data analysis across various industries. This paper introduces TIDE, a framework that provides a novel granular topic modeling method based on large language models (LLMs). TIDE also includes functionalities for summarizing long documents, topic parenting, and distillation. Through experiments on public and real-world business datasets, TIDE's approach is shown to outperform modern topic modeling methods. The framework is currently being open-sourced.",15.6,13.845,216,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11768v1_Lightweight Self-Supervised Detection of Fundament.pdf,Lightweight Self-Supervised Detection of Fundamental Frequency and Accurate Probability of Voicing in Monophonic Music,"Venkat Suprabath Bitra, Homayoon Beigi",,,"self-supervised pitch detection, unsupervised pitch detection, fundamental frequency, pitch estimation, resonance, musical timbre transfer, probability of voicing, music synthesis, music analysis, CQT, constant Q transform, DDSP, shift cross-entropy loss, musical instrument modeling, ResNeXt neural network, music information retrieval, MIR","Reliable fundamental frequency (F0) and voicing estimation are essential for neural synthesis, yet many pitch extractors depend on large labeled corpora and degrade under realistic recording artifacts. This paper proposes a lightweight, fully self-supervised framework for joint F0 estimation and voicing inference, designed for rapid single-instrument training from limited audio. Using transposition-equivariant learning on CQT features, an EM-style iterative reweighting scheme is introduced that uses Shift Cross-Entropy (SCE) consistency as a reliability signal to suppress uninformative noisy/unvoiced frames. The resulting weights provide confidence scores that enable pseudo-labeling for a separate lightweight voicing classifier without manual annotations. Trained on MedleyDB and evaluated on MDB-stem-synth ground truth, the method achieves competitive cross-corpus performance (RPA 95.84, RCA 96.24) and demonstrates cross-instrument generalization.",18.42,20.194,372,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11776v1_Cleansing the Artificial Mind A Self-Reflective De.pdf,Cleansing the Artificial Mind: A Self-Reflective Detoxification Framework for Large Language Models,"Kaituo Zhang, Zhimeng Jiang, Na Zou",,,"Large Language Models, detoxification, self-regulation, toxic content, text generation","Recent breakthroughs in Large Language Models (LLMs) have revealed remarkable generative capabilities and emerging self-regulatory mechanisms, including self-correction and self-rewarding. However, current detoxification techniques rarely exploit these built-in abilities; instead, they rely on external modules, labor-intensive data annotation, or human intervention – factors that hinder scalability and consistency. This paper introduces a fully self-reflective detoxification framework that harnesses the inherent capacities of LLMs to detect, correct toxic content, and refine LLMs without external modules and data annotation. Specifically, a Toxic Signal Detector—an internal self-identification mechanism, coupled with a systematic intervention process, is proposed to transform toxic text into its non-toxic counterpart. This iterative procedure yields a contrastive detoxification dataset used to fine-tune the model, enhancing its ability for safe and coherent text generation. Experiments on benchmark datasets such as DetoxLLM and ParaDetox show that this method achieves better detoxification performance than state-of-the-art methods while preserving semantic fidelity. By obviating the need for human intervention or external components, this paper reveals the intrinsic self-detoxification ability of LLMs, offering a consistent and effective approach for mitigating harmful content generation. Ultimately, the findings underscore the potential for truly self-regulated language models, paving the way for more responsible and ethically guided text generation systems.",18.92,20.398,386,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11778v1_Translation as a Scalable Proxy for Multilingual E.pdf,Translation as a Scalable Proxy for Multilingual Evaluation,"Sheriff Issaka, Erick Rosas Gonzalez, Lieqi Liu, Evans Kofi Agyei, Lucas Bandarkar, Nanyun Peng, David Ifeoluwa Adelani, Francisco Guzmán, Saadia Gabriel",,,"LLMs, multilingual evaluation, translation quality, benchmarking, low-resourced languages","The rapid proliferation of large language models (LLMs) has led to a critical evaluation paradox: while LLMs claim multilingual proficiency, comprehensive non-machine-translated benchmarks exist for fewer than 30 languages, leaving over 98% of the world's 7,000 languages unmeasured. This work explores whether translation quality can serve as a reliable, scalable, and cost-effective proxy for a model's broader multilingual capabilities. Through systematic evaluation of 14 models across 9 benchmarks and 7 translation metrics, it is found that translation performance is a good indicator of downstream task success. This suggests that translation quality can be a strong, inexpensive first-pass proxy for multilingual performance, enabling a translation-first screening with targeted follow-up for specific tasks.",17.29,17.293,299,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11781v1_Risk-Aware Human-in-the-Loop Framework with Adapti.pdf,Risk-Aware Human-in-the-Loop Framework with Adaptive Intrusion Response for Autonomous Vehicles,"Dawood Wasif, Terrence J. Moore, Seunghyun Yoon, Hyuk Lim, Dan Dongseong Kim, Frederica F. Nelson, Jin-Hee Cho",,,"autonomous vehicles, risk-aware, human-in-the-loop, adaptive intrusion response, curvature actuation integrity, time-to-collision proximity, observation-shift consistency, Intrusion Risk Score, Soft Actor–Critic, reinforcement learning, safe RL, imitation learning, offline RL, ControllerAreaNetwork, LiDAR spoofing attacks","Autonomous vehicles must remain safe and effective when encountering rare long-tailed scenarios or cyber–physical intrusions during driving. This paper presents RAIL, a risk-aware human-in-the-loop framework that turns heterogeneous runtime signals into calibrated control adaptations and focused learning. RAIL fuses three cues (curvature actuation integrity, time-to-collision proximity, and observation-shift consistency) into an Intrusion Risk Score (IRS) via weighted Noisy-OR. When IRS exceeds a threshold, actions are blended with a cue-specific shield using a learned authority, while human override remains available; when risk is low, the nominal policy executes. A contextual bandit arbitrates among shields based on the cue vector, improving mitigation choices online. RAIL couples Soft Actor–Critic (SAC) with risk-prioritized replay and dual rewards so that takeovers and near misses steer learning while nominal behavior remains covered. On MetaDrive, RAIL achieves a Test Return (TR) of 360.65, a Test Success Rate (TSR) of 0.85, a Test Safety Violation (TSV) of 0.75, and a Disturbance Rate (DR) of 0.0027, while logging only 29.07 training safety violations—outperforming RL, safe RL, offline/imitation learning, and prior HITL baselines. Under ControllerAreaNetwork (CAN) injection and LiDAR spoofing attacks, it improves Success Rate (SR) to 0.68 and 0.80, lowers the Disengagement Rate under Attack (DRA) to 0.37 and 0.03, and reduces the Attack Success Rate (ASR) to 0.34 and 0.11. In CARLA, RAIL attains a TR of 1609.70 and TSR of 0.41 with only 8K steps.",20.39,29.329,598,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11792v1_A self-evolving multi-role collaborative framework.pdf,A self-evolving multi-role collaborative framework with fine-grained difficulty guidance for innovative mathematical problem generation,"Yifei Sun, Yongan Li, A.K. Qin, Sicheng Hua, Tamas Pflanzner",,,"Problem generation, Large language models, Multi-role collaboration, Intelligent education, Self-evolution, Knowledge distillation","Mathematical problem generation (MPG) is a significant research direction in the field of intelligent education. This paper proposes a self-evolving, multi-role collaborative framework with fine-grained difficulty guidance for innovative math problem generation (IMPG). The framework includes a multi-role collaborative mechanism with components like a sampler, generator, evaluator, state machine, and memory, ensuring correctness through iterative optimization. An improved difficulty model quantifies difficulty and provides fine-grained guidance. The HSM3K-CN dataset, comprising high-quality high school math problems, is introduced. A multi-stage training pipeline with continual pre-training, supervised fine-tuning, and group relative policy optimization enhances generation and evaluation capabilities. System self-evolution is achieved by transferring evaluation capabilities from the expert model to the apprentice model via distillation. Experiments show significant improvements in problem innovation while maintaining high correctness rates.",17.96,16.867,303,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11801v1_RobotDesignGPT Automated Robot Design Synthesis us.pdf,RobotDesignGPT: Automated Robot Design Synthesis using Vision Language Models,"Nitish Sontakke, K. Niranjan Kumar, Sehoon Ha",,,"robot design synthesis, vision language models, automated design, kinematic structures, visual feedback, robot description formats","Robot design is a complex process requiring domain expertise and significant human effort. Current methods are rule-based, relying on grammars or primitive components. This work introduces RobotDesignGPT, a novel framework leveraging vision-language models (VLMs) to automate robot design synthesis. The framework synthesizes initial designs from user prompts and reference images, improving design quality with visual feedback. It can create visually appealing and kinematically valid robots inspired by nature. The framework's effectiveness is demonstrated through an ablation study and a user study.",16.07,13.566,218,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11809v1_Multi-agent DRL-based Lane Change Decision Model f.pdf,Multi-agent DRL-based Lane Change Decision Model for Cooperative Planning in Mixed Traffic,"Zeyu Mu, Shangtong Zhang, B. Brian Park",,,"Multi-Agent, Reinforcement Learning, Cooperative Platooning, Lane Change","Connected automated vehicles (CAVs) can communicate and coordinate to form cooperative platoons, enhancing energy efficiency and traffic flow. However, the sparse distribution of CAVs among human-driven vehicles during initial deployment stages limits effective platooning. This study proposes a hybrid multi-agent lane change decision model using the QMIX framework and a convolutional neural network (CNN-QMIX) to increase CAV participation in cooperative platooning. The model includes a trajectory planner and a model predictive controller for smooth and safe lane changes. Evaluated in a microsimulation environment with varying CAV market penetration rates, the model outperforms baseline rule-based models, improving cooperative platooning rates by up to 26.2%.",16.92,14.537,246,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11816v1_POLARIS Typed Planning and Governed Execution for .pdf,POLARIS: Typed Planning and Governed Execution for Agentic AI in Back-Office Automation,"Zahra Moslemi, Keerthi Koneru, Yen-Ting Lee, Sheethal Kumar, Ramesh Radhakrishnan",,,"Agentic AI, Enterprise Automation, Back-Office Tasks, Benchmarks, Governance, Typed Planning, Evaluation","Enterprise back-office workflows require agentic systems that are auditable, policy-aligned, and operationally predictable, capabilities that generic multi-agent setups often fail to deliver. We present POLARIS (Policy-Aware LLM Agentic Reasoning for Integrated Systems), a governed orchestration framework that treats automation as typed plan synthesis and validated execution over LLM agents. A planner proposes structurally diverse, type-checked directed acyclic graphs (DAGs); a rubric-guided reasoning module selects a single compliant plan; and execution is guarded by validator-gated checks, a bounded repair loop, and compiled policy guardrails that block or route side effects before they occur. Applied to document-centric finance tasks, POLARIS produces decision-grade artifacts and full execution traces while reducing human intervention. Empirically, POLARIS achieves a micro-F1 of 0.81 on the SROIE dataset and, on a controlled synthetic suite, achieves 0.95–1.00 precision for anomaly routing with preserved audit trails. These evaluations constitute an initial benchmark for governed Agentic AI. POLARIS provides a methodological and benchmark reference for policy-aligned Agentic AI.",18.8,19.888,374,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11825v1_AI Co-Scientist for Knowledge Synthesis in Medical.pdf,AI Co-Scientist for Knowledge Synthesis in Medical Contexts: A Proof of Concept,"Arya Rahgozara, Pouria Mortezaagha",,2601.11825v1,"AI, knowledge synthesis, medical contexts, PICOS, BiLSTM, transformer-based classifier, PubMedBERT, retrieval-augmented generation, Neo4j knowledge graph, BERTopic, dementia–sport, non-communicable disease","This study aims to develop and evaluate an AI co-scientist for scalable, transparent knowledge synthesis in biomedical science, addressing research waste through explicit PICOS formalization. A multi-representational platform integrating relational databases, semantic retrieval, and a Neo4j knowledge graph was designed and evaluated on dementia–sport and non-communicable disease corpora. Automated PICOS compliance classification was performed using a BiLSTM baseline and a transformer-based classifier fine-tuned from PubMedBERT. Full-text synthesis employed retrieval-augmented generation with hybrid vector and graph-based retrieval. Topic modeling using BERTopic identified thematic structure, redundancy, and evidence gaps. The transformer-based classifier achieved 95.7% accuracy in study design classification, outperforming the BiLSTM baseline. RAG outperformed non-retrieval generation for structured queries and cross-study integration.",20.01,16.589,332,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11840v1_Imandra CodeLogician Neuro-Symbolic Reasoning for .pdf,Neuro-Symbolic Reasoning for Precise Analysis of Software Logic,"Hongyu Lin, Samer Abdallah, Makar Valentinov, Paul Brennan, Elijah Kagan, Christoph M. Wintersteiger, Denis Ignatovich, Grant Passmore",,arXiv:2601.11840v1,"Neuro-Symbolic Reasoning, Software Logic, Large Language Models, Formal Methods, Automated Reasoning, Program Analysis, Mathematical Reasoning, Software Engineering","Large Language Models (LLMs) have shown strong performance on code understanding and software engineering tasks, yet they fundamentally lack the ability to perform precise, exhaustive mathematical reasoning about program behavior. Existing benchmarks either focus on mathematical proof automation, largely disconnected from real-world software, or on engineering tasks that do not require semantic rigor. This paper presents CodeLogician, a neurosymbolic agent and framework for precise analysis of software logic, integrated with ImandraX, an industrial automated reasoning engine. Unlike prior approaches that use formal methods primarily to validate or filter LLM outputs, CodeLogician uses LLMs to help construct explicit formal models of software systems, enabling automated reasoning to answer rich semantic questions beyond binary verification outcomes. The framework is reasoner-agnostic and can support additional formal reasoning backends. A new benchmark dataset, code-logic-bench, is introduced to evaluate mathematical reasoning about software logic, targeting the middle ground between theorem proving and software engineering benchmarks. The benchmark measures correctness and efficacy of reasoning about program state spaces, control flow, coverage constraints, decision boundaries, and edge cases, with ground truth defined via formal modeling and automated decomposition. Using this benchmark set, LLMs augmented with CodeLogician show substantial and consistent improvements in reasoning accuracy, closing a 41–47 percentage point gap compared to LLM-only approaches. These results demonstrate that the neurosymbolic integration of LLMs with formal reasoning engines is essential for scaling program analysis beyond heuristic reasoning toward rigorous, autonomous software understanding and formal verification.",20.36,23.481,478,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11850v1_Human-AI Collaborative Inductive Thematic Analysis.pdf,Human–AI Collaborative Inductive Thematic Analysis: How AI Guides Analysis and Researchers Reclaim Interpretive Authority,"Matthew Nyaaba, Min SungEun, Mary Abiswin Apam, Kwame Owoahene Acheampong, Emmanuel Dwamena, Xiaoming Zhai",,,"Human–AI collaboration, Generative artificial intelligence (GenAI), Inductive thematic analysis, Qualitative data analysis, Epistemic authority, Reflexive methodology","The study investigates the interaction between researchers and an Inductive Thematic Analysis GPT (ITA–GPT), a tool designed to operationalize inductive thematic analysis procedures. Using a Human–Artificial Intelligence Collaborative Inductive Thematic Analysis (HACITA) framework, the study examines how ITA–GPT assists in the analytic process, focusing on workflow structure and transparency. Researchers maintained epistemic authority through actions like modification and insertion, essential for correcting AI literalism and aligning interpretations with professional realities. The study provides insights into human–AI collaboration in qualitative research.",17.1,14.678,251,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11854v1_ATOD An Evaluation Framework and Benchmark for Age.pdf,ATOD: An Evaluation Framework and Benchmark for Agentic Task-Oriented Dialogue System,"Yifei Zhang, Hooshang Nayyeri, Rinat Khaziev, Emine Yilmaz, Gokhan Tur, Dilek Hakkani-Tür, Hari Thadakamalla",,,"task-oriented dialogue, large language models, API integration, benchmark, evaluation framework, agentic behaviors, multi-goal coordination, dependency management, memory, adaptability, proactivity","Recent advances in task-oriented dialogue (TOD) systems, driven by large language models (LLMs) with extensive API and tool integration, have enabled conversational agents to coordinate interleaved goals, maintain long-horizon context, and act proactively through asynchronous execution. These capabilities extend beyond traditional TOD systems, yet existing benchmarks lack systematic support for evaluating such agentic behaviors. To address this gap, we introduce ATOD, a benchmark and synthetic dialogue generation pipeline that produces richly annotated conversations requiring long-term reasoning. ATOD captures key characteristics of advanced TOD, including multi-goal coordination, dependency management, memory, adaptability, and proactivity. Building on ATOD, we propose ATOD-Eval, a holistic evaluation framework that translates these dimensions into fine-grained metrics and supports reproducible offline and online evaluation. We further present a strong agentic memory-based evaluator for benchmarking on ATOD. Experiments show that ATOD-Eval enables comprehensive assessment across task completion, agentic capability, and response quality, and that the proposed evaluator offers a better accuracy–efficiency trade-off compared to existing memory- and LLM-based approaches under this evaluation setting.",18.91,21.466,406,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11859v1_Cascaded Transformer for Robust and Scalable SLA D.pdf,Cascaded Transformer for Robust and Scalable SLA Decomposition via Amortized Optimization,Cyril Shih-Huan Hsu,,,"network slicing, service level agreement, quality of service, deep neural network, optimization, transformers","The evolution toward 6G networks increasingly relies on network slicing to provide tailored, End-to-End (E2E) logical networks over shared physical infrastructures. A critical challenge is effectively decomposing E2E Service Level Agreements (SLAs) into domain-specific SLAs, which current solutions handle through computationally intensive, iterative optimization processes that incur substantial latency and complexity. To address this, we introduce Casformer, a cascaded Transformer architecture designed for fast, optimization-free SLA decomposition. Casformer leverages historical domain feedback encoded through domain-specific Transformer encoders in its first layer, and integrates cross-domain dependencies using a Transformer-based aggregator in its second layer. The model is trained under a learning paradigm inspired by Domain-Informed Neural Networks (DINNs), incorporating risk-informed modeling and amortized optimization to learn a stable, forward-only SLA decomposition policy. Extensive evaluations demonstrate that Casformer achieves improved SLA decomposition quality against state-of-the-art optimization-based frameworks, while exhibiting enhanced scalability and robustness under volatile and noisy network conditions. In addition, its forward-only design reduces runtime complexity and simplifies deployment and maintenance. These insights reveal the potential of combining amortized optimization with Transformer-based sequence modeling to advance network automation, providing a scalable and efficient solution suitable for real-time SLA management in advanced 5G-and-beyond network environments.",18.96,18.724,355,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11863v1_Utilizing Metadata for Better Retrieval-Augmented .pdf,Utilizing Metadata for Better Retrieval-Augmented Generation,"Raquib Bin Yousuf, Shengzhe Xu, Mandar Sharma, Andrew Neeser, Chris Latimer, Naren Ramakrishnan",,arXiv:2601.11863v1,"Retrieval-Augmented Generation (RAG), Metadata-aware Retrieval, Dense Retrieval, Query Reformulation, Benchmark Datasets","Retrieval-Augmented Generation systems rely on retrieving semantically relevant document chunks to support accurate, grounded outputs from large language models. In structured and repetitive corpora such as regulatory filings, chunk similarity alone often fails to distinguish between documents with overlapping language. Practitioners often flatten metadata into input text as a heuristic, but the impact and trade-offs of this practice remain poorly understood. This study presents systematic retrieval strategies, comparing plain-text baselines with approaches that embed metadata directly. Evaluation includes metadata-as-text (prefix and suffix), a dual-encoder unified embedding that fuses metadata and content in a single index, dual-encoder late-fusion retrieval, and metadata-aware query reformulation. Prefixing and unified embeddings consistently outperform plain-text baselines, with unified embeddings sometimes exceeding prefixing while being easier to maintain. Metadata integration improves effectiveness by increasing intra-document cohesion, reducing inter-document confusion, and widening the separation between relevant and irrelevant chunks. Field-level ablations show that structural cues provide strong disambiguating signals. The code, evaluation framework, and the RAGMATE-10K dataset are publicly hosted.",19.83,18.658,370,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11868v1_Terminal-Bench Benchmarking Agents on Hard Realist.pdf,"TERMINAL-BENCH: BENCHMARKING AGENTS ON HARD, REALISTIC TASKS IN COMMAND LINE INTERFACES","Mike A. Merrill, Alexander G. Shaw, Nicholas Carlini, Boxuan Li, Harsh Raj, Ivan Bercovich, Lin Shi, Jeong Yeon Shin, Thomas Walshe, E. Kelly Buchanan, Junhong Shen, Guanghao Ye, Haowei Lin, Jason Poulos, Maoyu Wang, Marianna Nezhurina, Jenia Jitsev, Di Lu, Orfeas Menis Mastromichalakis, Zhiwei Xu, Zizhao Chen, Yue Liu, Robert Zhang, Leon Liangyu Chen, Anurag Kashyap, Jan-Lucas Uslu, Jeffrey Li, Jianbo Wu, Minghao Yan, Song Bian, Vedang Sharma, Ke Sun, Steven Dillmann, Akshay Anand, Andrew Lanpouthakoun, Bardia Koopah, Changran Hu, Etash Guha, Gabriel H. S. Dreiman, Jiacheng Zhu, Karl Krauth, Li Zhong, Niklas Muennighoff, Robert Amanfu, Shangyin Tan, Shreyas Pimpalgaonkar, Tushar Aggarwal, Xiangning Lin, Xin Lan, Xuandong Zhao, Yiqing Liang, Yuanli Wang, Zilong Wang, Changzhi Zhou, David Heineman, Hange Liu, Harsh Trivedi, John Yang, Junhong Lin, Manish Shetty, Michael Yang, Nabil Omi, Negin Raoof, Shanda Li, Terry Yue Zhuo, Wuwei Lin, Yiwei Dai, Yuxin Wang, Wenhao Chai, Shang Zhou, Dariush Wahdany, Ziyu She, Jiaming Hu, Zhikang Dong, Yuxuan Zhu, Sasha Cui, Ahson Saiyed, Arinbjörn Kolbeinsson, Jesse Hu, Christopher Michael Rytting, Ryan Marten, Yixin Wang, Alex Dimakis, Andy Konwinski",,2601.11868v1,"AI agents, benchmarking, command line interfaces, real-world tasks, evaluation, error analysis","AI agents may soon become capable of autonomously completing valuable, long-horizon tasks in diverse domains. Current benchmarks either do not measure real-world tasks, or are not sufficiently difficult to meaningfully measure frontier models. To this end, we present Terminal-Bench 2.0: a carefully curated hard benchmark composed of 89 tasks in computer terminal environments inspired by problems from real workflows. Each task features a unique environment, human-written solution, and comprehensive tests for verification. We show that frontier models and agents score less than 65% on the benchmark and conduct an error analysis to identify areas for model and agent improvement. We publish the dataset and evaluation harness to assist developers and researchers in future work at tbench.ai.",20.4,42.261,862,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11876v1_AI for Green Spaces Leveraging Autonomous Navigati.pdf,Autonomous Trash Pickup Robots on Grass Fields: A Viable Solution,,,,"autonomous navigation, trash pickup, robotics, Spanning Tree Coverage (STC) algorithm, Real-Time Kinematic (RTK) GPS, ResNet50 Convolutional Neural Network (CNN), grass fields, litter problem","The paper addresses the significant litter problem in the U.S., with 50 billion pieces of litter, particularly in grass fields. It proposes an autonomous robot capable of navigating, identifying, and picking up trash in parks. The robot uses a Spanning Tree Coverage (STC) algorithm for navigation, Real-Time Kinematic (RTK) GPS for precise movement, and a ResNet50 CNN for trash detection with 94.52% accuracy. Various pickup mechanisms were tested, and a successful design was selected, achieving an 80% success rate. The solution demonstrates the viability of autonomous trash pickup robots in grass fields, overcoming challenges such as navigation and avoiding damage to the grass.",16.59,15.072,250,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11880v1_TF-CoDiT Conditional Time Series Synthesis with Di.pdf,TF-CoDiT: Conditional Time Series Synthesis with Diffusion Transformers for Treasury Futures,"Yingxiao Zhang, Jiaxin Duan, Junfu Zhang, Ke Feng",,,"Diffusion Transformers, Treasury Futures, Time Series Synthesis, Discrete Wavelet Transform, Financial Market Attribute Protocol, Low-Data Learning, Latent Diffusion Generation","Diffusion Transformers (DiT) have achieved milestones in synthesizing financial time-series data, such as stock prices and order flows. However, their performance in synthesizing treasury futures data is still underexplored. This work emphasizes the characteristics of treasury futures data, including its low volume, market dependencies, and grouped correlations among multivariables. To overcome these challenges, we propose TF-CoDiT, the first DiT framework for language-controlled treasury futures synthesis. To facilitate low-data learning, TF-CoDiT adapts the standard DiT by transforming multi-channel 1-D time series into Discrete Wavelet Transform (DWT) coefficient matrices. A U-shape V AE is proposed to encode cross-channel dependencies hierarchically into a latent variable and bridge the latent and DWT spaces through decoding, thereby enabling latent diffusion generation. To derive prompts that cover essential conditions, we introduce the Financial Market Attribute Protocol (FinMAP) - a multi-level description system that standardizes daily/periodical market dynamics by recognizing 17/23 economic indicators from 7/8 perspectives. In our experiments, we gather four types of treasury futures data covering the period from 2015 to 2025, and define data synthesis tasks with durations ranging from one week to four months. Extensive evaluations demonstrate that TF-CoDiT can produce highly authentic data with errors at most 0.433 (MSE) and 0.453 (MAE) to the ground-truth. Further studies evidence the robustness of TF-CoDiT across contracts and temporal horizons.",19.61,22.8,447,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11885v1_MyGram Modality-aware Graph Transformer with Globa.pdf,MyGram: Modality-aware Graph Transformer with Global Distribution for Multi-modal Entity Alignment,"Zhifei Li, Ziyue Qin, Xiangyu Luo, Xiaoju Hou, Yue Zhao, Miao Zhang, Zhifang Huang, Kui Xiao, Bing Yang",,,"multi-modal entity alignment, knowledge graphs, modality-aware graph transformer, global distribution, modality diffusion learning, Gram Loss","Multi-modal entity alignment aims to identify equivalent entities between two multi-modal Knowledge graphs by integrating multi-modal data, such as images and text, to enrich the semantic representations of entities. Existing methods may overlook the structural contextual information within each modality, making them vulnerable to interference from shallow features. To address these challenges, we propose MyGram, a modality-aware graph transformer with global distribution for multi-modal entity alignment. Specifically, we develop a modality diffusion learning module to capture deep structural contextual information within modalities and enable fine-grained multi-modal fusion. In addition, we introduce a Gram Loss that acts as a regularization constraint by minimizing the volume of a 4-dimensional parallelepiped formed by multi-modal features, thereby achieving global distribution consistency across modalities. We conduct experiments on five public datasets. Results show that MyGram outperforms baseline models, achieving a maximum improvement of 4.8% in Hits@1 on FBDB15K, 9.9% on FBYG15K, and 4.3% on DBP15K.",18.15,20.108,365,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11895v1_DevBench A Realistic Developer-Informed Benchmark .pdf,"DevBench: A Realistic, Developer-Informed Benchmark for Code Generation Models","Pareesa Ameneh Golnari, Adarsh Kumarappan, Wen Wen, Xiaoyu Liu, Gabriel Ryan, Yuting Sun, Shengyu Fu, Elsie Nallipogu",,,"code generation, Large Language Models, code completion, benchmark, developer telemetry","DevBench is a telemetry-driven benchmark designed to evaluate Large Language Models (LLMs) on realistic code completion tasks. It includes 1,800 evaluation instances across six programming languages and six task categories derived from real developer telemetry, such as API usage and code purpose understanding. Unlike prior benchmarks, it emphasizes ecological validity, avoids training data contamination, and enables detailed diagnostics. The evaluation combines functional correctness, similarity-based metrics, and LLM-judge assessments focused on usefulness and contextual relevance. Nine state-of-the-art models were assessed, revealing differences in syntactic precision, semantic reasoning, and practical utility. The benchmark provides actionable insights to guide model selection and improvement—detail that is often missing from other benchmarks but is essential for both practical deployment and targeted model development.",17.35,15.618,271,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11903v1_AEMA Verifiable Evaluation Framework for Trustwort.pdf,AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems,"Yen-Ting Lee, Keerthi Koneru, Zahra Moslemi, Sheethal Kumar, Ramesh Radhakrishnan",,arXiv:2601.11903v1,"Agentic AI, Multi-Agent Systems, Trustworthy AI, Verifiable Evaluation, Human Oversight","Evaluating large language model (LLM)-based multi-agent systems remains a critical challenge, as these systems must exhibit reliable coordination, transparent decision-making, and verifiable performance across evolving tasks. Existing evaluation approaches often limit themselves to single-response scoring or narrow benchmarks, which lack stability, extensibility, and automation when deployed in enterprise settings at multi-agent scale. We present AEMA (Adaptive Evaluation Multi-Agent), a process-aware and auditable framework that plans, executes, and aggregates multi-step evaluations across heterogeneous agentic workflows under human oversight. Compared to a single LLM-as-a-Judge, AEMA achieves greater stability, human alignment, and traceable records that support accountable automation. Our results on enterprise-style agent workflows simulated using realistic business scenarios demonstrate that AEMA provides a transparent and reproducible pathway toward responsible evaluation of LLM-based multi-agent systems.",18.36,17.16,315,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11905v1_LIBRA Language Model Informed Bandit Recourse Algo.pdf,LIBRA: Language Model Informed Bandit Recourse Algorithm for Personalized Treatment Planning,"Junyu Cao, Ruijiang Gao, Esmaeil Keyvanshokooh, Jianhao Ma",,,"Large Language Models, LLM-Bandits Collaboration, Algorithmic Recourse, Regret Analysis, Personalized Treatment Planning, Hypertension Management","This paper introduces a unified framework integrating algorithmic recourse, contextual bandits, and large language models (LLMs) for sequential decision-making in high-stakes settings like personalized medicine. The authors propose the Generalized Linear Recourse Bandit (GLRB) algorithm and the Language Model–Informed Bandit Recourse Algorithm (LIBRA). LIBRA combines domain knowledge from LLMs with bandit learning, offering guarantees for warm-start, LLM-effort, and robustness. The paper establishes matching lower bounds for the recourse bandit problem and demonstrates the near-optimality of the algorithms through experiments. Results show improvements in regret, treatment quality, and sample efficiency over standard contextual bandits and LLM-only benchmarks, highlighting the potential of LLM-assisted bandit algorithms in personalized high-stakes decision-making.",17.76,16.782,298,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11907v1_Towards Airborne Object Detection A Deep Learning .pdf,Towards Airborne Object Detection: A Deep Learning Analysis,"Prosenjit Chatterjee, ANK Zaman",,,"Airborne Object Detection, Threat Detection, Deep Learning, EfficientNetB4, ResNet-50, UA V","The rapid proliferation of airborne platforms—including commercial aircraft, drones, and UAVs—has intensified the need for real-time, automated threat assessment systems. Current approaches depend heavily on manual monitoring, resulting in limited scalability and operational inefficiencies. This work introduces a dual-task model based on EfficientNetB4 capable of performing airborne object classification and threat-level prediction simultaneously. To address the scarcity of clean, balanced training data, the AODTA Dataset was constructed by aggregating and refining multiple public sources. The model achieved 96% accuracy in object classification and 90% accuracy in threat-level prediction, outperforming a ResNet-50 baseline. The study focuses on classification and threat-level inference using pre-localized airborne object images, complementing existing object detection pipelines.",16.99,14.95,254,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11913v1_LSTM-MAS A Long Short-Term Memory Inspired Multi-A.pdf,LSTM-MAS: A Long Short-Term Memory Inspired Multi-Agent System for Long-Context Understanding,"Yichen Jiang, Peng Ye, Jiakang Yuan, Chongjun Tu, Lei Bai, Tao Chen",,,"Long-Context Understanding, Large Language Models, Multi-Agent System, Memory","Effectively processing long contexts remains a fundamental yet unsolved challenge for large language models (LLMs). Existing single-LLM-based methods primarily reduce the context window or optimize the attention mechanism, but they often encounter additional computational costs or constrained expanded context length. While multi-agent-based frameworks can mitigate these limitations, they remain susceptible to the accumulation of errors and the propagation of hallucinations. In this work, we draw inspiration from the Long Short-Term Memory (LSTM) architecture to design a Multi-Agent System called LSTM-MAS, emulating LSTM’s hierarchical information flow and gated memory mechanisms for long-context understanding. Specifically, LSTM-MAS organizes agents in a chained architecture, where each node comprises a worker agent for segment-level comprehension, a filter agent for redundancy reduction, a judge agent for continuous error detection, and a manager agent for globally regulating information propagation and retention, analogous to LSTM and its input gate, forget gate, constant error carousel unit, and output gate. These novel designs enable controlled information transfer and selective long-term dependency modeling across textual segments, which can effectively avoid error accumulation and hallucination propagation. We conducted an extensive evaluation of our method. Compared with the previous best multi-agent approach, CoA, our model achieves improvements of 40.93%, 43.70%, 121.57%, and 33.12%, on NarrativeQA, Qasper, HotpotQA, and MuSiQue, respectively.",19.01,21.458,408,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11920v1_Enhancing LLM-Based Data Annotation with Error Dec.pdf,Enhancing LLM-Based Data Annotation with Error Decomposition,"Zhen Xu, Vedant Khatri, Yijun Dai, Xiner Liu, Siyan Li, Xuanming Zhang, Renzhe Yu",,,"Data Annotation, Qualitative Coding, Large Language Models, Human-AI Collaboration","Large language models (LLMs) offer a scalable alternative to human coding for data annotation tasks, enabling the scale-up of research across data-intensive domains such as learning analytics. While LLMs are already achieving near-human accuracy on objective annotation tasks, their performance on subjective annotation tasks, such as those involving psychological constructs, is less consistent and more prone to errors. Standard evaluation practices typically collapse all annotation errors into a single alignment metric, but this simplified approach may obscure different kinds of errors that affect final analytical conclusions in different ways. Here, we propose a diagnostic evaluation paradigm that incorporates a human-in-the-loop step to separate task-inherent ambiguity from model-driven inaccuracies and assess annotation quality in terms of their potential downstream impacts. We refine this paradigm on ordinal annotation tasks, which are common in subjective annotation. The refined paradigm includes: (1) a diagnostic taxonomy that categorizes LLM annotation errors along two dimensions: source (model-specific vs. task-inherent) and type (boundary ambiguity vs. conceptual misidentification); (2) a lightweight human annotation test to estimate task-inherent ambiguity from LLM annotations; and (3) a computational method to decompose observed LLM annotation errors following our taxonomy. We validate this paradigm on four educational annotation tasks, demonstrating both its conceptual validity and practical utility. Theoretically, our work provides empirical evidence for why excessively high alignment is unrealistic in specific annotation tasks and why single alignment metrics inadequately reflect the quality of LLM annotations. In practice, our paradigm can be a low-cost diagnostic tool that assesses the suitability of a given task for LLM annotation and provides actionable insights for further technical optimization.",19.94,22.617,451,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11935v1_Big Data Workload Profiling for Energy-Aware Cloud.pdf,Big Data Workload Profiling for Energy-Aware Cloud Resource Management,"Milan Parikh, Aniket Abhishek Soni, Sneja Mitinbhai Shah, Ayush Raj Jha",,arXiv:2601.11935v1,"Cloud computing, energy-aware scheduling, workload profiling, virtual machine placement, big data, green computing","Cloud data centers face increasing pressure to reduce operational energy consumption as big data workloads continue to grow in scale and complexity. This paper presents a workload-aware scheduling framework that uses profiling of CPU usage, memory demand, and storage I/O behavior to guide energy-efficient virtual machine (VM) placement. By combining historical execution logs with real-time telemetry, the system predicts the energy and performance impact of candidate placement decisions and adaptively consolidates workloads without violating service-level agreements (SLAs). The framework was evaluated using representative Hadoop MapReduce, Spark MLlib, and ETL workloads on a multi-node cloud testbed. Experimental results demonstrate a consistent reduction of 15–20% in energy consumption while maintaining SLA compliance. These findings highlight the effectiveness of data-driven workload profiling as a practical strategy for improving the sustainability of cloud computing environments.",18.03,16.753,302,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11940v1_Thinking Traps in Long Chain-of-Thought A Measurab.pdf,Thinking Traps in Long Chain-of-Thought: A Measurable Study and Trap-Aware Adaptive Restart,"Kang Chen, Fan Yu, Junjie Nian, Shihan Zhao, Zhuoka Feng, Zijun Yao, Heng Wang, Minshen Yu, Yixin Cao",,arXiv:2601.11940v1,"Long Chain-of-Thought, reasoning capabilities, fine-grained trajectory analysis, Thinking Traps, Trap-Aware Adaptive Restart, mathematical reasoning, scientific reasoning","Scaling test-time compute via Long Chain-of-Thought (Long-CoT) enhances reasoning capabilities, but extended generation does not guarantee correctness. Models may elaborate on an incorrect prefix after an early wrong commitment. The study identifies 'Thinking Traps' as prefix-dominant deadlocks where later reflection or verification fails to correct the root error. The proposed Trap-Aware Adaptive Restart (TAAR) framework predicts where to truncate and whether to intervene in the reasoning process. Experiments show TAAR improves reasoning performance on benchmarks without fine-tuning base model parameters.",17.91,16.026,287,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11956v1_Double-Calibration Towards Trustworthy LLMs via Ca.pdf,Double-Calibration: Towards Trustworthy LLMs via Calibrating Knowledge and Reasoning Confidence,"Yuyin Lu, Ziran Liang, Yanghui Rao, Wenqi Fan, Fu Lee Wang, Qing Li",,,"Large Language Models, Knowledge Graphs, Uncertainty Quantification, Calibration, Reasoning, Trustworthiness","Trustworthy reasoning in Large Language Models (LLMs) is challenged by their propensity for hallucination. While augmenting LLMs with Knowledge Graphs (KGs) improves factual accuracy, existing KG-augmented methods fail to quantify epistemic uncertainty in both the retrieved evidence and LLMs’ reasoning. To bridge this gap, we introduce DoublyCal, a framework built on a novel double-calibration principle. DoublyCal employs a lightweight proxy model to first generate KG evidence alongside a calibrated evidence confidence. This calibrated supporting evidence then guides a black-box LLM, yielding final predictions that are not only more accurate but also well-calibrated, with confidence scores traceable to the uncertainty of the supporting evidence. Experiments on knowledge-intensive benchmarks show that DoublyCal significantly improves both the accuracy and confidence calibration of black-box LLMs with low token cost.",17.44,17.605,307,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11960v1_R2PO Decoupling Training Trajectories from Inferen.pdf,R2PO: Decoupling Training Trajectories from Inference Responses for LLM Reasoning,"Jingchu Wang, Bingbing Xu, Yige Yuan, Bin Xie, Xiaoqian Sun, Huawei Shen",,,"Reinforcement Learning, Large Language Models, LLM Reasoning, Policy Optimization, Trajectory Diversification","Reinforcement learning has become a central paradigm for improving LLM reasoning. Existing methods use a single policy to produce both inference responses and training optimization trajectories, leading to insufficient exploration due to objective conflict. This paper proposes R2PO (Residual Rollout Policy Optimization), which introduces a lightweight Residual Rollout-Head atop the policy to decouple training trajectories from inference responses. This enables controlled trajectory diversification during training while maintaining stable inference generation. Experiments show that R2PO outperforms baselines, achieving average accuracy gains of 3.1% on MATH-500 and 2.4% on APPS, while also reducing formatting errors and mitigating length bias for stable optimization.",16.81,16.237,273,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11969v1_textttMemoryRewardBench Benchmarking Reward Models.pdf,MemoryRewardBench: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models,"Zecheng Tang, Baibei Ji, Ruoxi Sun, Haitian Wang, Wangjie You, Yijun Zhang, Wenpeng Zhu, Ji Qi, Juntao Li, Min Zhang",,,"memory management, large language models, reward models, long-term memory, benchmarking","Existing works increasingly adopt memory-centric mechanisms to process long contexts in a segment manner, and effective memory management is one of the key capabilities that enables large language models to effectively propagate information across the entire sequence. This work introduces MemRewardBench, the first benchmark to systematically study the ability of reward models (RMs) to evaluate long-term memory management processes. MemRewardBench covers both long-context comprehension and long-form generation tasks, featuring 10 distinct settings with different memory management patterns, with context length ranging from 8K to 128K tokens. Evaluations on 13 cutting-edge RMs indicate a diminishing performance gap between open-source and proprietary models, with newer-generation models consistently outperforming their predecessors regardless of parameter count. The study further exposes the capabilities and fundamental limitations of current RMs in evaluating LLM memory management across diverse settings.",17.66,18.229,322,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11974v1_Learn Like Humans Use Meta-cognitive Reflection fo.pdf,Learn Like Humans: Use Meta-cognitive Reflection for Efficient Self-Improvement,"Xinmeng Hou, Peiliang Gong, Bohao Qu, Wuqi Wang, Qing Guo, Yang Liu",,,"Large Language Models, self-improvement, meta-cognitive reflection, machine learning, computational efficiency","While Large Language Models (LLMs) enable complex autonomous behavior, current agents are limited by static, human-designed prompts that restrict adaptability. Existing self-improving frameworks often rely on inefficient, multi-turn recursive loops with high computational costs. This paper proposes the Metacognitive Agent Reflective Self-improvement (MARS) framework, which achieves efficient self-evolution within a single recurrence cycle. Inspired by educational psychology, MARS integrates principle-based reflection and procedural reflection to mimic human learning. This allows agents to refine their reasoning logic systematically without continuous online feedback. Experiments on six benchmarks show that MARS outperforms state-of-the-art self-evolving systems while significantly reducing computational overhead.",16.54,16.017,265,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11977v1_One-Shot Price Forecasting with Covariate-Guided E.pdf,One-Shot Price Forecasting with Covariate-Guided Experts under Privacy Constraints,"He, Ren, Xu, Yinliang, Wang, Jinfeng, Watson, Jeremy, Song, Jian",,,"Price forecasting, Time Series, Privacy, Mixture of Experts, market analysis","Forecasting in power systems often involves multi-variate time series with complex dependencies and strict privacy constraints across regions. Traditional forecasting methods require significant expert knowledge and struggle to generalize across diverse deployment scenarios. Recent advancements in pre-trained time series models offer new opportunities, but their zero-shot performance on domain-specific tasks remains limited. To address these challenges, we propose a novel MoE-Encoder module that augments pre-trained forecasting models by injecting a sparse mixture-of-experts layer between tokenization and encoding. This design enables two key capabilities: (1) transforming multivariate forecasting into an expert-guided univariate task, allowing the model to effectively capture inter-variable relations, and (2) supporting localized training and lightweight parameter sharing in federated settings where raw data cannot be exchanged. Extensive experiments on public multivariate datasets demonstrate that MoE-Encoder significantly improves forecasting accuracy compared to strong baselines. We further simulate federated environments and show that transferring only MoE-Encoder parameters allows efficient adaptation to new regions, with minimal performance degradation. Our findings suggest that MoE-Encoder provides a scalable and privacy-aware extension to foundation time series models.",18.27,18.827,344,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11979v1_Process In-Context Learning Enhancing Mathematical.pdf,Process In-Context Learning: Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion,"Ang Gao, Changshuo Zhang, Xiao Zhang, Deyang Li, Minjun Zhao, Fangchao Liu, Xinyu Zhang",,,"In-context learning, Mathematical reasoning, Dynamic demonstration insertion, Large language models, Adaptive demonstration","In-context learning (ICL) has shown effectiveness in various tasks for large language models (LLMs), but its application in tasks requiring step-by-step logical deduction, such as mathematical reasoning, is limited by static demonstration use. This paper introduces Process In-Context Learning (PICL), a dynamic framework that enhances mathematical reasoning by identifying and addressing confusion points during inference. PICL operates in two stages: identifying potential confusion points and inserting relevant demonstrations to guide subsequent reasoning steps. Experiments demonstrate that PICL outperforms baseline methods by reducing mid-inference confusion, underscoring the importance of adaptive demonstration insertion in complex mathematical reasoning.",16.78,15.554,261,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11995v1_Learning Audio-Visual Embeddings with Inferred Lat.pdf,Learning Audio–Visual Embeddings with Inferred Latent Interaction Graphs,"Donghuo Zeng, Hao Niu, Yanan Wang, Masato Taya",,2601.11995v1,"Audio–visual, latent interaction graph, cross-modal retrieval, soft labels","Learning robust audio–visual embeddings requires bringing genuinely related audio and visual signals together while filtering out incidental co-occurrences—background noise, unrelated elements, or unannotated events. Most contrastive and triplet-loss methods use sparse annotated labels per clip and treat any co-occurrence as semantic similarity. We propose a framework that leverages soft-label predictions and inferred latent interactions to address these issues: (1) Audio–Visual Semantic Alignment Loss (AV-SAL) trains a teacher network to produce aligned soft-label distributions across modalities, assigning nonzero probability to co-occurring but unannotated events and enriching the supervision signal. (2) Inferred Latent Interaction Graph (ILI) applies the GRaSP algorithm to teacher soft labels to infer a sparse, directed dependency graph among classes. This graph highlights directional dependencies that expose likely semantic or conditional relationships between classes; these are interpreted as estimated dependency patterns. (3) Latent Interaction Regularizer (LIR): A student network is trained with both metric loss and a regularizer guided by the ILI graph, pulling together embeddings of dependency-linked but unlabeled pairs in proportion to their soft-label probabilities. Experiments on AVE and VEGAS benchmarks show consistent improvements in mean average precision (MAP), demonstrating that integrating inferred latent interactions into embedding learning enhances robustness and semantic coherence.",20.1,19.005,382,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.11998v1_Hybrid IDS Using Signature-Based and Anomaly-Based.pdf,Hybrid IDS Using Signature-Based and Anomaly-Based Detection,"Messaouda Boutassetta, Amina Makhlouf, Newfel Messaoudi, Abdelmadjid Benmachiche, Ines Boutabia",,,"Intrusion Detection System (IDS), Hybrid IDS, Signature-Based Detection, Anomaly-Based Detection, Machine Learning (ML), Cybersecurity, False Positives, Detection Accuracy, Real-Time Detection, Network Security","Intrusion detection systems (IDS) are essential for protecting computer systems and networks against a wide range of evolving cyber threats. IDS are categorized into signature-based and anomaly-based types, each with strengths and limitations. This paper presents a comprehensive survey and conceptual overview of Hybrid IDS, which integrate both detection techniques to enhance attack detection capabilities. The survey examines recent research on Hybrid IDS, classifies existing models into functional categories, and discusses their advantages, limitations, and application domains, including financial systems, air traffic control, and social networks. Recent trends in Hybrid IDS research, such as machine learning-based approaches and cloud-based deployments, are reviewed. The paper outlines potential future research directions aimed at developing more cost-effective Hybrid IDS solutions with improved ability to detect emerging and sophisticated cyberattacks.",17.94,17.505,314,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12002v1_Kernel-Based Learning of Safety Barriers.pdf,Kernel-Based Learning of Safety Barriers,"Oliver Schöno, Zhengang Zhong, Sadegh Soudjani",,arXiv:2601.12002v1,"AI, safety verification, control barrier certificates, reproducing kernel Hilbert space, temporal logic specifications, safety barriers, neural network controller","The rapid integration of AI algorithms in safety-critical applications such as autonomous driving and healthcare is raising significant concerns about meeting stringent safety standards. Traditional tools for formal safety verification struggle with the black-box nature of AI-driven systems and lack the flexibility needed to scale to the complexity of real-world applications. This paper presents a data-driven approach for safety verification and synthesis of black-box systems with discrete-time stochastic dynamics. It employs control barrier certificates to guarantee system safety and learns the certificate directly from system trajectories. The approach uses conditional mean embeddings to embed data into a reproducing kernel Hilbert space (RKHS) and constructs an RKHS ambiguity set to robustify results to out-of-distribution behavior. Theoretical results are provided for applying the approach to general classes of temporal logic specifications beyond safety. For data-driven computation of safety barriers, a finite Fourier expansion is used to cast a typically intractable semi-infinite optimization problem as a linear program. The resulting spectral barrier leverages the fast Fourier transform to generate the relaxed problem efficiently, offering a scalable yet distributionally robust framework for verifying safety. The work moves beyond restrictive assumptions on system dynamics and uncertainty, demonstrated on two case studies including a black-box system with a neural network controller.",19.38,19.296,374,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12003v1_Robust Verification of Concurrent Stochastic Games.pdf,Robust Verification of Concurrent Stochastic Games,"Angel Y. He, David Parker",,arXiv:2601.12003v1,"Robust quantitative verification, Probabilistic model checking, Concurrent stochastic games, Epistemic uncertainty","Autonomous systems often operate in multi-agent settings and need to make concurrent, strategic decisions, typically in uncertain environments. Verification and control problems for these systems can be tackled with concurrent stochastic games (CSGs), but this model requires transition probabilities to be precisely specified — an unrealistic requirement in many real-world settings. We introduce robust CSGs and their subclass interval CSGs (ICSGs), which capture epistemic uncertainty about transition probabilities in CSGs. We propose a novel framework for robust verification of these models under worst-case assumptions about transition uncertainty. Specifically, we develop the underlying theoretical foundations and efficient algorithms, for finite- and infinite-horizon objectives in both zero-sum and nonzero-sum settings, the latter based on (social-welfare optimal) Nash equilibria. We build an implementation in the PRISM-games model checker and demonstrate the feasibility of robust verification of ICSGs across a selection of large benchmarks.",18.68,15.363,287,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12014v1_Are LLMs Ready for TOON Benchmarking Structural Co.pdf,Are LLMs Ready for TOON? Benchmarking Structural Correctness–Sustainability Trade-offs in Novel Structured Output Formats,"Elio Masciari, Vincenzo Moscato, Enea Vincenzo Napolitano, Gian Marco Orlando, Marco Perillo, Diego Russo",https://doi.org/XXXXXXX.XXXXXXX,,"Green AI, TOON, Large Language Models, Natural Language Processing, Sustainability","Large Language Models (LLMs) are increasingly required to generate structured, machine-readable outputs for downstream systems. While recent benchmarks have focused on evaluating the structural correctness of such outputs, the environmental impact of inference for different output formats has largely been overlooked. This paper introduces a sustainability-aware evaluation framework for structured generation that measures token usage, generation time, and estimated carbon emissions. The Environment-Aware Generation Correctness Score (GCSenv) is proposed as a unified metric integrating structural correctness with carbon-aware efficiency. The novel TOON format is benchmarked against established representations (JSON, XML, YAML) across multiple LLMs. Results reveal a trade-off: TOON yields more compact outputs and lower emissions but lower structural correctness when models lack native support. Increased model capacity reduces this gap, and environment-aware scoring can shift format rankings depending on deployment priorities, highlighting the need for sustainability-inclusive benchmarking.",18.21,18.177,331,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12019v1_Acting Flatterers via LLMs Sycophancy Combating Cl.pdf,Acting Flatterers via LLMs Sycophancy: Combating Clickbait with LLMs Opposing-Stance Reasoning,"Chaowei Zhang, Xiansheng Luo, Zewei Zhang, Yi Zhu, Jipeng Qiang, Longwei Wang",https://doi.org/10.1145/XXXXXX.XXXXXX,,"Clickbait Detection, Large Language Models, Opposing Stance Reasoning, Contrastive Learning","The widespread proliferation of online content has intensified concerns about clickbait—deceptive or exaggerated headlines designed to attract attention. While Large Language Models (LLMs) offer a promising avenue for addressing this issue, their effectiveness is often hindered by Sycophancy, a tendency to produce reasoning that matches users’ beliefs over truthful ones, which deviates from instruction-following principles. Rather than treating sycophancy as a flaw to be eliminated, this work proposes a novel approach that initially harnesses this behavior to generate contrastive reasoning from opposing perspectives. Specifically, we design a Self-renewal Opposing-stance Reasoning Generation (SORG) framework that prompts LLMs to produce high-quality 'agree' and 'disagree' reasoning pairs for a given news title without requiring ground-truth labels. To utilize the generated reasoning, we develop a local Opposing Reasoning-based Clickbait Detection (ORCD) model that integrates three BERT encoders to represent the title and its associated reasoning. The model leverages contrastive learning, guided by soft labels derived from LLM-generated credibility scores, to enhance detection robustness. Experimental evaluations on three benchmark datasets demonstrate that our method consistently outperforms LLM prompting, fine-tuned smaller language models, and state-of-the-art clickbait detection baselines. Our code is available in https://github.com/126541/ORCD.",19.2,22.704,436,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12024v1_A Multi-Agent System for Generating Actionable Bus.pdf,A Multi-Agent System for Generating Actionable Business Advice,"Kartikey Singh Bhandari, Tanish Jain, Archit Agrawal, Dhruv Kumar, Praveen Kumar, Pratik Narang",,,"customer reviews, large language models, multi-agent system, business advice, actionability, specificity, non-redundancy","Customer reviews contain rich signals about product weaknesses and unmet user needs, yet existing analytic methods rarely move beyond descriptive tasks such as sentiment analysis or aspect extraction. This paper presents a multi-agent, LLM-based framework for prescriptive decision support, transforming large-scale review corpora into actionable business advice. The framework integrates clustering, advice generation, iterative evaluation, and feasibility-based ranking, producing specific, actionable, and practical outputs. Experiments show that the framework outperforms single model baselines on actionability, specificity, and non-redundancy, with medium-sized models approaching the performance of large model frameworks.",16.05,14.458,232,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12030v1_ARC Active and Reflection-driven Context Managemen.pdf,Active and Reflection-driven Context Management for Long-Horizon Information Seeking Agents,"Yilun Yao, Shan Huang, Elsie Dai, Zhewen Tan, Zhenyu Duan, Shousheng Jia, Yanbing Jiang, Tong Yang",,,"context management, long-horizon information seeking, large language models, context rot, reflection-driven process","Large language models are increasingly used as research agents for deep search and long-horizon information seeking. However, their performance often degrades as interaction histories grow, a phenomenon known as context rot. Existing approaches manage context through raw accumulation or passive summarization, which can allow early errors to persist. This paper proposes ARC, a framework that treats context as a dynamic internal reasoning state, using reflection-driven monitoring and revision to actively reorganize working context when misalignment or degradation is detected. Experiments show that ARC outperforms passive context compression methods, achieving up to an 11% absolute improvement in accuracy on BrowseComp-ZH with Qwen2.5-32B-Instruct.",16.87,16.534,279,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12038v1_Abstract Argumentation with Subargument Relations.pdf,Abstract Argumentation with Subargument Relations,Beishui Liao,,,"abstract argumentation, subargument relations, attack relation, structured argumentation, Dung’s framework","Dung’s abstract argumentation framework characterizes argument acceptability solely via an attack relation, abstracting from the internal structure of arguments. This abstraction limits the representation of structural dependencies central to many structured argumentation formalisms, particularly subargument relations. Existing extensions, like bipolar argumentation frameworks, introduce support relations but fail to capture the asymmetric and constitutive nature of subarguments and their interaction with attacks. This paper studies abstract argumentation frameworks enriched with an explicit subargument relation, treated alongside attack as a basic relation. It analyzes how subargument relations interact with attacks and examines their impact on fundamental semantic properties. The framework provides a principled abstraction of structural information and clarifies the role of subarguments in abstract acceptability reasoning. The paper highlights that extension-based equivalence does not imply structural or explanatory equivalence, as different subargument configurations may yield identical extensions but differ in how attacks are grounded and how defense propagates. The paper proposes treating subargument relations as a primitive component of abstract argumentation, orthogonal to conflict, to address these issues.",17.55,15.495,272,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12040v1_Partial Reasoning in Language Models Search and Re.pdf,Partial Reasoning in Language Models: Search and Refinement Guided by Uncertainty,"Murilo da Luz, Bruno Brandão, Luana Martins, Gustavo Oliveira, Bryan de Oliveira, Luckeciano Melo, Telma Soares",,,"Uncertainty, Entropy, Latent-space search, Soft Reasoning, LLM reasoning","The use of Large Language Models (LLMs) for reasoning and planning tasks has drawn increasing attention in Artificial Intelligence research. Despite their remarkable progress, these models still exhibit limitations in multi-step inference scenarios, particularly in mathematical and logical reasoning. We introduce PREGU (Partial Reasoning Guided by Uncertainty). PREGU monitors the entropy of the output distribution during autoregressive generation and halts the process whenever entropy exceeds a defined threshold, signaling uncertainty. From that point, a localized search is performed in the latent space to refine the partial reasoning and select the most coherent answer, using the Soft Reasoning method. Experiments conducted with LLaMA-3-8B, Mistral-7B, and Qwen2-7B across four reasoning benchmarks (GSM8K, GSM-Hard, SVAMP, and StrategyQA) showed performance greater than or similar to Soft Reasoning, indicating that entropy can serve as an effective signal to trigger selective refinement during reasoning.",18.47,17.871,330,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12042v1_Less Is More -- Until It Breaks Security Pitfalls .pdf,Less Is More — Until It Breaks: Security Pitfalls of Vision Token Compression in Large Vision-Language Models,"Xiaomei Zhang, Zhaoxi Zhang, Leo Yu Zhang, Yanjun Zhang, Guanhong Tao, Shirui Pan",https://doi.org/XXXXXXX.XXXXXXX,,"Vision Token Compression, Large Vision-Language Models, Security, Robustness, Compression-Aware Attack, Transfer CAA","Visual token compression is widely adopted to improve the inference efficiency of Large Vision–Language Models (LVLMs), enabling their deployment in latency-sensitive and resource-constrained scenarios. However, existing work has mainly focused on efficiency and performance, while the security implications of visual token compression remain largely unexplored. This work reveals that visual token compression substantially degrades the robustness of LVLMs, making them highly vulnerable once compression is enabled. These vulnerabilities are state-specific and difficult to diagnose. Instability in token importance ranking is identified as the primary cause of robustness degradation. Small perturbations can alter token rankings, leading to the discarding of task-critical information and model failure. A Compression-Aware Attack (CAA) is proposed to study and exploit this vulnerability, inducing failures exclusively under compressed inference. Transfer CAA (T-CAA) extends this approach to black-box settings. Experimental results show that compression-induced security risks persist even under practical settings, and potential defenses provide limited protection. Extensive experiments demonstrate that visual token compression significantly undermines model robustness, exposing a trade-off between efficiency and security.",18.97,19.558,371,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12049v1_textitFocaLogic Logic-Based Interpretation of Visu.pdf,FocaLogic: Logic-Based Interpretation of Visual Model Decisions,"Chenchen Zhao, Muxi Chen, Qiang Xu",,,"interpretability, visual models, logic-based representations, model-agnostic, quantitative metrics, visual focuses, deep neural networks, high-stakes applications","Interpretability of modern visual models is crucial, particularly in high-stakes applications. Existing interpretability methods often rely on white-box model access or lack quantitative rigor. FocaLogic is introduced as a novel model-agnostic framework to interpret and quantify visual model decision-making through logic-based representations. It identifies minimal interpretable subsets of visual regions, termed visual focuses, that decisively influence model predictions. These visual focuses are translated into precise logical expressions for transparent and structured interpretations. A suite of quantitative metrics, including focus precision, recall, and divergence, is proposed to evaluate model behavior. Empirical analyses show FocaLogic's capability to uncover insights such as training-induced concentration, increasing focus accuracy through generalization, and anomalous focuses under biases and adversarial attacks. FocaLogic provides a systematic, scalable, and quantitative solution for interpreting visual models.",17.34,16.555,287,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12053v1_A New Strategy for Artificial Intelligence Trainin.pdf,A New Strategy for Artificial Intelligence: Training Foundation Models Directly on Human Brain Data,Maël Donoso,,2601.12053v1,"foundation models, brain, neuroimaging, brain-generated data, brain-trained foundation models, reinforcement learning from human brain (RLHB), chain of thought from human brain (CoTHB)","While foundation models have achieved remarkable results across a diversity of domains, they still rely on human-generated data, such as text, as a fundamental source of knowledge. This data is ultimately the product of human brains, the filtered projection of a deeper neural complexity. This paper explores a new strategy for artificial intelligence: training foundation models directly on human brain data. It hypothesizes that neuroimaging data could reveal elements of human cognition not accessible through observable actions, potentially overcoming current limitations of foundation models. The paper classifies the current limitations of foundation models and identifies promising brain regions and cognitive processes that could be leveraged to address them across four levels: perception, valuation, execution, and integration. Two methods are proposed to prioritize the use of limited neuroimaging data for strategically chosen, high-value steps in foundation model training: reinforcement learning from human brain (RLHB) and chain of thought from human brain (CoTHB). The potential implications for agents, artificial general intelligence, and artificial superintelligence, as well as the ethical, social, and technical challenges and opportunities, are discussed. The paper argues that brain-trained foundation models could represent a realistic and effective middle ground between scaling current architectures and exploring alternative, neuroscience-inspired solutions. It also notes that future discoveries in cognitive and computational neuroscience could make this strategy increasingly relevant over time, as new neural signals of interest are retroactively unlocked in present neuroimaging datasets.",19.69,20.672,407,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12055v1_Automating Parameter Selection in Deep Image Prior.pdf,Automating Parameter Selection in Deep Image Prior for Fluorescence Microscopy Image Denoising via Similarity-Based Parameter Transfer,"Lina Meyer, Felix Wissel, Tobias Knopp, Susanne Pfefferle, Ralf Fliegert, Maximilian Sandmann, Liana Uebler, Franziska Möckl, Björn-Philipp Diercks, David Lohr, René Werner",,,"fluorescence microscopy, denoising, deep image prior, automatic parameter selection","Unsupervised deep image prior (DIP) addresses shortcomings of training data requirements and limited generalization associated with supervised deep learning. The performance of DIP depends on the network architecture and the stopping point of its iterative process. Optimizing these parameters for a new image requires time, restricting DIP application in domains where many images need to be processed. Focusing on fluorescence microscopy data, this study hypothesizes that similar images share comparable optimal parameter configurations for DIP-based denoising, potentially enabling optimization-free DIP for fluorescence microscopy. A calibration and validation set were generated from an open-source dataset for network architecture search towards ideal U-net architectures and stopping points. The study implemented AUTO-DIP, a pipeline for automatic parameter transfer, and compared it to the originally published DIP configuration and a state-of-the-art image-specific variational denoising approach. Results show that parameter transfer based on image metadata similarity leads to better performance than quantitative image similarity measures. AUTO-DIP outperforms the baseline DIP and variational denoising approaches for several open-source test datasets, particularly for very noisy inputs. Applications to locally acquired fluorescence microscopy images further proved the superiority of AUTO-DIP, improving DIP-based denoising speed and quality, enabling routine applications in fluorescence microscopy imaging.",19.79,22.481,445,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12061v1_Codebook-Injected Dialogue Segmentation for Multi-.pdf,Codebook-Injected Dialogue Segmentation for Multi-Utterance Constructs,"Jinsook Lee, Kirk Vanacore, Zhuqian Zhou, Bakhtawar Ahtisham, Jeanine Grütter, René F. Kizilcec",,,"Dialogue Act annotation, segmentation, LLM-based segmenters, evaluation metrics, human-AI agreement","This paper addresses the challenge of Dialogue Act (DA) annotation, which often treats communicative or pedagogical intent as localized to individual utterances, leading to disagreements on segment boundaries. The authors propose a codebook-injected segmentation approach that conditions boundary decisions on downstream annotation criteria. They evaluate LLM-based segmenters against standard and retrieval-augmented baselines using evaluation metrics for span consistency, distinctiveness, and human-AI distributional agreement. The study finds that DA-awareness produces more internally consistent segments than text-only baselines, though coherence-based baselines are better at detecting global shifts in dialogue flow. The results suggest that segmentation should be optimized for downstream objectives rather than a single performance score.",17.25,16.228,280,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12068v1_Bridging the Gap in Bangla Healthcare Machine Lear.pdf,Bridging the Gap in Bangla Healthcare: Machine Learning Based Disease Prediction Using a Symptoms-Disease Dataset,"Rowzatul Zannat, Abdullah Al Shafi, Abdul Muntakim",,,"Disease Prediction, Annotated Dataset, Machine Learning Techniques, Soft Voting Ensemble, Hard Voting Ensemble","Increased access to reliable health information is essential for non-English-speaking populations, yet resources in Bangla for disease prediction remain limited. This study addresses this gap by developing a comprehensive Bangla symptoms-disease dataset containing 758 unique symptom-disease relationships spanning 85 diseases. The dataset enables the prediction of diseases based on Bangla symptom inputs, supporting healthcare accessibility for Bengali-speaking populations. Using this dataset, multiple machine learning models were evaluated to predict diseases based on symptoms provided in Bangla, achieving 98% accuracy with both soft and hard voting ensemble approaches. This work establishes a foundational resource for disease prediction in Bangla, enhancing equitable access to health information for Bangla-speaking communities, particularly for early disease detection and healthcare interventions.",17.24,15.374,265,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12082v1_Conditional Random Fields for Interactive Refineme.pdf,CONDITIONAL RANDOM FIELDS FOR INTERACTIVE REFINEMENT OF HISTOPATHOLOGICAL PREDICTIONS,"Tiffanie Godelaine, Maxime Zanella, Karim El Khoury, Saïd Mahmoudi, Benoït Macq, Christophe De Vleeschouwer",,,"Histology Classification, Conditional Random Fields, Human-In-The-Loop, Foundation Models","Assisting pathologists in the analysis of histopathological images has high clinical value, as it supports cancer detection and staging. This paper introduces HistoCRF, a CRF-based framework designed to refine zero-shot predictions from Vision-Language Models (VLMs) without additional model training. The framework leverages expert annotations and a novel pairwise potential to promote label diversity. Experiments on five patch-level classification datasets demonstrate significant accuracy gains, with further improvements when integrating human-in-the-loop annotations. The code will be made available on GitHub.",16.04,14.273,229,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12095v1_Neural Isomorphic Fields A Transformer-based Algeb.pdf,NEURALISOMORPHICFIELDS: A TRANSFORMER-BASED ALGEBRAIC NUMERICAL EMBEDDING,"Hamidreza Sadeghi, Saeedeh Momtazi, Reza Safabakhsh",,,"Neural Networks, Embeddings, Algebraic Properties, Rational Numbers, Neural Isomorphic Fields, Addition, Multiplication, Overflow, Underflow","Neural network models often face challenges when processing very small or very large numbers due to issues such as overflow, underflow, and unstable output variations. To mitigate these problems, we propose using embedding vectors for numbers instead of directly using their raw values. These embeddings aim to retain essential algebraic properties while preventing numerical instabilities. In this paper, we introduce, for the first time, a fixed-length number embedding vector that preserves algebraic operations—addition, multiplication, and comparison—within the rational numbers field. We propose a novel Neural Isomorphic Field, a neural abstraction of algebraic structures like groups and fields. The elements of this neural field are embedding vectors that maintain algebraic structure during computations. Our experiments demonstrate that addition performs exceptionally well, achieving over 95% accuracy on key algebraic tests such as identity, closure, and associativity. In contrast, multiplication exhibits challenges, with accuracy ranging between 53% to 73% across various algebraic properties. These findings highlight the model’s strengths in preserving algebraic properties under addition while identifying avenues for further improvement in handling multiplication.",18.5,18.435,341,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12099v1_Large language models struggle with ethnographic t.pdf,Large Language Models Struggle with Ethnographic Text Annotation,"Leonardo S. Goodall, Dor Shilton, Daniel Austin Mullins, Harvey Whitehouse",,,"large language models, ethnographic text annotation, cross-cultural research, anthropology","Large language models (LLMs) have shown promise for automated text annotation, raising hopes that they might accelerate cross-cultural research by extracting structured data from ethnographic texts. This study evaluated 7 state-of-the-art LLMs on their ability to annotate 121 ritual features across 567 ethnographic excerpts. Performance was limited, falling well below levels required for reliable automated annotation. Longer texts, features requiring ordinal distinctions, and ambiguous constructs proved particularly difficult. Human inter-coder reliability set an approximate ceiling on LLM accuracy: features that human coders found difficult to agree upon were also difficult for LLMs. Even on features where humans reliably agreed, models fell short of human performance. The findings suggest that LLMs cannot yet substitute for human expertise in ethnographic annotation.",17.07,15.291,261,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12104v1_Powerful Training-Free Membership Inference Agains.pdf,Powerful Training-Free Membership Inference Against Autoregressive Language Models,"David Ilić, David Stanojević, Kostadin Cvejoski",,,"membership inference attacks, language models, privacy risks, autoregressive models, fine-tuning, error positions, probability shifts","Fine-tuned language models pose significant privacy risks by potentially memorizing and exposing sensitive information from their training data. Membership inference attacks (MIAs) are used to audit these risks, but existing methods have limited detection rates, especially at low false-positive thresholds. This paper introduces EZ-MIA, a membership inference attack that leverages the observation that memorization is most evident at error positions, where the model predicts incorrectly but still assigns high probability to training examples. The Error Zone (EZ) score, a new statistic, measures the imbalance of probability shifts at these error positions relative to a pretrained reference model. EZ-MIA requires only two forward passes per query and no model training, achieving significantly higher detection rates than previous methods. The results indicate that the privacy risks of fine-tuned language models are greater than previously understood, with implications for privacy auditing and deployment decisions.",17.51,16.506,289,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12124v1_SynQP A Framework and Metrics for Evaluating the Q.pdf,SYNQP: A FRAMEWORK AND METRICS FOR EVALUATING THE QUALITY AND PRIVACY RISK OF SYNTHETIC DATA,"Bing Hu, Yixin Li, Asma Bahamyirou, Helen Chen",,,"Real-World Data, Synthetic Data, Privacy Metrics, Evaluation Framework, Membership Inference Attack, Identity Disclosure Risk","The use of synthetic data in health applications raises privacy concerns, yet the lack of open frameworks for privacy evaluations has slowed its adoption. A major challenge is the absence of accessible benchmark datasets for evaluating privacy risks, due to difficulties in acquiring sensitive data. To address this, we introduce SYNQP, an open framework for benchmarking privacy in synthetic data generation (SDG) using simulated sensitive data, ensuring that original data remains confidential. We also highlight the need for privacy metrics that fairly account for the probabilistic nature of machine learning models. As a demonstration, we use SYNQP to benchmark CTGAN and propose a new identity disclosure risk metric that offers a more accurate estimation of privacy risks compared to existing approaches. Our work provides a critical tool for improving the transparency and reliability of privacy evaluations, enabling safer use of synthetic data in health-related applications. Our privacy assessments reveal that DP consistently lowers both identity disclosure risk (SD-IDR) and membership-inference attack risk (SD-MIA), with all DP-augmented models staying below the 0.09 regulatory threshold. Code available at https://github.com/CAN-SYNH/SynQP.",18.68,19.165,358,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12126v1_UniMo Unified Motion Generation and Understanding .pdf,UniMo: Unified Motion Generation and Understanding with Chain of Thought,"Guocun Wang, Kenkun Liu, Jing Lin, Guorui Song, Jian Li, Xiaoguang Han",,,"3D human motion generation, understanding, large language models, chain of thought reasoning, supervised fine-tuning, reinforcement learning, Group Relative Policy Optimization","Existing 3D human motion generation and understanding methods often exhibit limited interpretability, restricting effective mutual enhancement between these inherently related tasks. While current unified frameworks based on large language models (LLMs) leverage linguistic priors, they frequently encounter challenges in semantic alignment and task coherence. Moreover, the next-token prediction paradigm in LLMs is ill-suited for motion sequences, causing cumulative prediction errors. To address these limitations, we propose UniMo, a novel framework that integrates motion-language information and interpretable chain of thought (CoT) reasoning into the LLM via supervised fine-tuning (SFT). We further introduce reinforcement learning with Group Relative Policy Optimization (GRPO) as a post-training strategy that optimizes over groups of tokens to enforce structural correctness and semantic alignment, mitigating cumulative errors in motion token prediction. Extensive experiments demonstrate that UniMo significantly outperforms existing unified and task-specific models, achieving state-of-the-art performance in both motion generation and understanding.",18.2,18.408,335,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12132v1_Bengali Text Classification An Evaluation of Large.pdf,Bengali Text Classification: An Evaluation of Large Language Model Approaches,"Md Mahmudul Hoque, Md Mehedi Hassain, Md Hojaifa Tanvir, Rahul Nandy",,2601.12132v1,"Bengali Text Classification, Transformer-based Text Classifier, Multilingual NLP, Qwen, LLaMA","Bengali text classification is a significant task in natural language processing (NLP), where text is categorized into predefined labels. Unlike English, Bengali faces challenges due to the lack of extensive annotated datasets and pre-trained language models. This study explores the effectiveness of large language models (LLMs) in classifying Bengali newspaper articles. The dataset used, obtained from Kaggle, consists of articles from Prothom Alo, a major Bangladeshi newspaper. Three instruction-tuned LLMs—LLaMA 3.1 8B Instruct, LLaMA 3.2 3B Instruct, and Qwen 2.5 7B Instruct—were evaluated for this task under the same classification framework. Among the evaluated models, Qwen 2.5 achieved the highest classification accuracy of 72%, showing particular strength in the 'Sports' category. In comparison, LLaMA 3.1 and LLaMA 3.2 attained accuracies of 53% and 56%, respectively. The findings highlight the effectiveness of LLMs in Bengali text classification, despite the scarcity of resources for Bengali NLP. Future research will focus on exploring additional models, addressing class imbalance issues, and refining fine-tuning approaches to improve classification performance.",19.76,19.787,391,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12134v1_Human-Human-AI Triadic Programming Uncovering the .pdf,Human-Human-AI Triadic Programming: Uncovering the Role of AI Agent and the Value of Human Partner in Collaborative Learning,"Taufiq Daryanto, Xiaohan Ding, Kaike Ping, Lance T. Wilhelm, Yan Chen, Chris Brown, Eugenia H. Rho",https://doi.org/XXXXXXX.XXXXXXX,arXiv:2601.12134v1,cs.HC,"As AI assistance becomes embedded in programming practice, researchers have increasingly examined how these systems help learners generate code and work more efficiently. However, these studies often position AI as a replacement for human collaboration and overlook the social and learning-oriented aspects that emerge in collaborative programming. Our work introduces human-human-AI (HHAI) triadic programming, where an AI agent serves as an additional collaborator rather than a substitute for a human partner. Through a within-subjects study with 20 participants, we show the potential benefits and design considerations of this triadic interaction, including whether AI should act as a shared collaborator or personal support.",17.87,15.224,272,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12138v1_DriveSafe A Hierarchical Risk Taxonomy for Safety-.pdf,DriveSafe: A Hierarchical Risk Taxonomy for Safety-Critical LLM-Based Driving Assistants,"Abhishek Kumar, Riya Tapwal, Carsten Maple",,,"Large Language Models, Driving Assistants, Safety-Critical Systems, Risk Taxonomy, Automotive AI","Large Language Models (LLMs) are increasingly integrated into vehicle-based digital assistants, where unsafe, ambiguous, or legally incorrect responses can lead to serious safety, ethical, and regulatory consequences. Despite growing interest in LLM safety, existing taxonomies and evaluation frameworks remain largely general-purpose and fail to capture the domain-specific risks inherent to real-world driving scenarios. This paper introduces DriveSafe, a hierarchical, four-level risk taxonomy designed to systematically characterize safety-critical failure modes of LLM-based driving assistants. The taxonomy comprises 129 fine-grained atomic risk categories spanning technical, legal, societal, and ethical dimensions, grounded in real-world driving regulations and safety principles and reviewed by domain experts. To validate the safety relevance and realism of the constructed prompts, the paper evaluates their refusal behavior across six widely deployed LLMs. The analysis shows that the evaluated models often fail to appropriately refuse unsafe or non-compliant driving-related queries, underscoring the limitations of general-purpose safety alignment in driving contexts.",18.05,16.955,306,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12141v1_TIDE A Trace-Informed Depth-First Exploration for .pdf,TIDE: A Trace-Informed Depth-First Exploration for Planning with Temporally Extended Goals,"Yuliia Suprun, Khen Elimelech, Lydia E. Kavraki, Moshe Y. Vardi",,2601.12141v1,"task planning, temporally extended goals, Linear Temporal Logic on finite traces (LTLf), heuristics, depth-first exploration, reach-avoid subproblems, adaptive backtracking","Task planning with temporally extended goals (TEGs) is a critical challenge in AI and robotics, enabling agents to achieve complex sequences of objectives over time rather than addressing isolated, immediate tasks. Linear Temporal Logic on finite traces (LTLf) provides a robust formalism for encoding these temporal goals. Traditional LTLf task planning approaches often transform the temporal planning problem into a classical planning problem with reachability goals, which are then solved using off-the-shelf planners. However, these methods often lack informed heuristics to provide a guided search for temporal goals. We introduce TIDE (Trace-Informed Depth-first Exploration), a novel approach that addresses this limitation by decomposing a temporal problem into a sequence of smaller, manageable reach-avoid subproblems, each solvable using an off-the-shelf planner. TIDE identifies and prioritizes promising automaton traces within the domain graph, using cost-driven heuristics to guide exploration. Its adaptive backtracking mechanism systematically recovers from failed plans by recalculating costs and penalizing infeasible transitions, ensuring completeness and efficiency. Experimental results demonstrate that TIDE achieves promising performance and is a valuable addition to the portfolio of planning methods for temporally extended goals.",19.92,19.982,398,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12147v1_Segment and Matte Anything in a Unified Model.pdf,Segment and Matte Anything in a Unified Model,"Zezhong Fan, Xiaohan Li, Topojoy Biswas, Kaushiki Nag, Kannan Achan",,,"Segment Anything, image matting, segmentation, multi-view localization, interactive image segmentation","Segment Anything (SAM) has demonstrated zero-shot generalization and flexible prompting after training on over one billion masks. However, its mask prediction accuracy often falls short for real-world applications. This paper introduces Segment And Matte Anything (SAMA), a lightweight extension of SAM, which delivers high-quality interactive image segmentation and matting with minimal extra parameters. SAMA incorporates a Multi-View Localization Encoder (MVLE) and a Localization Adapter (Local-Adapter) to refine mask outputs and capture detailed features. It also includes two prediction heads for segmentation and matting tasks. Trained on a diverse dataset, SAMA achieves state-of-the-art performance across multiple benchmarks, showcasing its adaptability and effectiveness in various downstream tasks.",16.18,14.338,232,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12150v1_Enhanced Diagnostic Performance via Large-Resoluti.pdf,ENHANCED DIAGNOSTIC PERFORMANCE VIA LARGE-RESOLUTION INFERENCE OPTIMIZATION FOR PATHOLOGY FOUNDATION MODELS,"Mengxuan Hu, Zihan Guan, John Kang, Sheng Li, Zhongliang Zhou",,arXiv:2601.12150v1,"Computational pathology, Foundation models, Inference Optimization","Despite their prominent performance on tasks such as ROI classification and segmentation, many pathology foundation models remain constrained by a specific input size (e.g., 224×224), creating substantial inefficiencies when applied to whole-slide images (WSIs), which span thousands of resolutions. A naïve strategy is to either enlarge inputs or downsample the WSIs. However, enlarging inputs results in prohibitive GPU memory consumption, while downsampling alters the microns-per-pixel resolution and obscures critical morphological details. To overcome these limitations, we propose a space- and time-efficient inference strategy that sparsifies attention using spatially aware neighboring blocks and filters out non-informative tokens through global attention scores. This design substantially reduces GPU memory and runtime during high-resolution WSI inference while preserving and even improving the downstream performance, enabling inference at higher resolutions under the same GPU budget. The experimental results show that our method can achieve up to a 7.67% improvement in the ROI classification and compatible results in segmentation.",18.31,18.018,330,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12186v1_Aletheia What Makes RLVR For Code Verifiers Tick.pdf,Aletheia: What Makes RLVR For Code Verifiers Tick?,"Vatsal Venkatkrishna, Indraneil Paul, Iryna Gurevych",,,"Reinforcement Learning, Code Verification, Large Language Models, Post-training Pipeline, Execution Feedback, Code Generation, Robustness Evaluation, Policy Models, Covariate Shifts","Multi-domain thinking verifiers trained via Reinforcement Learning from Verifiable Rewards (RLVR) are a prominent fixture of the Large Language Model (LLM) post-training pipeline, owing to their ability to robustly rate and rerank model outputs. However, the adoption of such verifiers towards code generation has been comparatively sparse, with execution feedback constituting the dominant signal. Nonetheless, code verifiers remain valuable toward judging model outputs in scenarios where execution feedback is hard to obtain and are a potentially powerful addition to the code generation post-training toolbox. To this end, we create and open-source Aletheia, a controlled testbed that enables execution-grounded evaluation of code verifiers’ robustness across disparate policy models and covariate shifts. We examine components of the RLVR-based verifier training recipe widely credited for its success: (1) intermediate thinking traces, (2) learning from negative samples, and (3) on-policy training. While experiments show the optimality of RLVR, we uncover important opportunities to simplify the recipe. Particularly, despite code verification exhibiting positive training- and inference-time scaling, on-policy learning stands out as the key component at small verifier sizes, and thinking-based training emerges as the most important component at larger scales.",18.51,20.689,383,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12205v1_Do Neural Codecs Generalize A Controlled Study Acr.pdf,Do Neural Codecs Generalize? A Controlled Study Across Unseen Languages and Non-Speech Tasks,"Shih-Heng Wang, Jiatong Shi, Jinchuan Tian, Haibin Wu, Shinji Watanabe",,,"Neural Audio Codecs, generalization, unseen languages, non-speech tasks, signal compression, audio language modeling","This paper investigates the generalization capabilities of Neural Audio Codecs (NACs) in three key areas: generalization to unseen languages during pre-training, generalization to non-speech tasks by speech-only pre-trained NACs, and the impact of incorporating non-speech data during pre-training on both speech and non-speech tasks. The study involves training NACs from scratch with controlled configurations and curated pre-trained data for fair comparisons. The performance is evaluated using 11 metrics, revealing that NACs can generalize to unseen languages, speech-only pre-trained NACs underperform on non-speech tasks, and including non-speech data during pre-training enhances performance on non-speech tasks while maintaining speech task performance.",16.01,15.93,255,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12212v1_Speculative Sampling with Reinforcement Learning.pdf,Speculative Sampling with Reinforcement Learning,"Chenan Wang, Daniel H. Shi, Haipeng Chen",,,"speculative sampling, reinforcement learning, large language models, inference time latency, draft tree hyperparameter optimization","Inference time latency is a significant challenge for real-world applications of large language models (LLMs). State-of-the-art speculative sampling (SpS) methods, such as EAGLE-3, use tree-based drafting to explore multiple candidate continuations in parallel. However, the static hyperparameters controlling the tree structure limit flexibility and efficiency across different contexts and domains. This paper introduces Reinforcement Learning for Speculative Sampling (Re-SpS), the first reinforcement learning-based framework for optimizing draft tree hyperparameters. Re-SpS dynamically adjusts these hyperparameters in real-time, learning context-aware policies that maximize generation speed by balancing speculative aggression with computational overhead. It uses efficient state representations from target model hidden states and introduces multi-step action persistence for better context modeling. Evaluation results across five diverse benchmarks show consistent improvements over EAGLE-3, achieving up to 5.45× speedup over the backbone LLM and up to 1.12× speedup compared to EAGLE-3, with no loss in output fidelity.",17.06,16.821,287,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12215v1_Wavelet-Driven Masked Multiscale Reconstruction fo.pdf,Wavelet-Driven Masked Multiscale Reconstruction for PPG Foundation Models,"Megha Thukral, Cyrus Tanade, Simon A. Lee, Juhyeon Lee, Hao Zhou, Keum San Chun, Migyeong Gwak, Viswam Nathan, Md Mahbubur Rahman, Li Zhu, Mehrab Bin Morshed, Subramaniam Venkatraman, Sharanya Arcot Desai",,arXiv:2601.12215v1,"Wearable SSL Method, Wavelet based Modelling, PPG foundation models","Wearable foundation models have the potential to transform digital health by learning transferable representations from large-scale biosignals collected in everyday settings. While recent progress has been made in large-scale pretraining, most approaches overlook the spectral structure of photoplethysmography (PPG) signals, wherein physiological rhythms unfold across multiple frequency bands. Motivated by the insight that many downstream health-related tasks depend on multi-resolution features spanning fine-grained waveform morphology to global rhythmic dynamics, we introduce Masked Multiscale Reconstruction (MMR) for PPG representation learning - a self-supervised pretraining framework that explicitly learns from hierarchical time–frequency scales of PPG data. The pretraining task is designed to reconstruct randomly masked out coefficients obtained from a wavelet-based multiresolution decomposition of PPG signals, forcing the transformer encoder to integrate information across temporal and spectral scales. We pretrain our model with MMR using ∼17 million unlabeled 10-second PPG segments from ∼32,000 smartwatch users. On 17 of 19 diverse health-related tasks, MMR trained on large-scale wearable PPG data improves over or matches state-of-the-art open-source PPG foundation models, time-series foundation models and other self-supervised baselines. Extensive analysis of our learned embeddings and systematic ablations underscore the value of wavelet-based representations, showing that they capture robust and physiologically-grounded features. Together, these results highlight the potential of MMR as a step toward generalizable PPG foundation models.",20.6,24.171,498,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12224v1_Where It Moves It Matters Referring Surgical Instr.pdf,"Where It Moves, It Matters: Referring Surgical Instrument Segmentation via Motion","Meng Wei, Kun Yuan, Shi Li, Yue Zhou, Long Bai, Nassir Navab, Hongliang Ren, Hong Joo Lee, Tom Vercauteren, Nicolas Padoy",,,"surgical instrument segmentation, motion-guided framework, natural language processing, surgical videos, domain-specific datasets","Enabling intuitive, language-driven interaction with surgical scenes is a critical step toward intelligent operating rooms and autonomous surgical robotic assistance. This work introduces SurgRef, a novel motion-guided framework that grounds free-form language expressions in instrument motion, capturing how tools move and interact across time. This approach allows models to understand and segment instruments even under occlusion, ambiguity, or unfamiliar terminology. To train and evaluate SurgRef, the Ref-IMotion dataset is presented, which is diverse and multi-institutional, featuring dense spatiotemporal masks and rich motion-centric expressions. SurgRef achieves state-of-the-art accuracy and generalization across surgical procedures, setting a new benchmark for robust, language-driven surgical video segmentation.",17.48,16.878,295,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12234v1_Proc3D Procedural 3D Generation and Parametric Edi.pdf,Proc3D: Procedural 3D Generation and Parametric Editing of 3D Shapes with Large Language Models,"Fadlullah Raji, Stefano Petrangeli, Matheus Gadelha, Yu Shen, Uttaran Bhattacharya, Gang Wu",,2601.12234v1,"3D model generation, parametric editing, Large Language Models, procedural compact graph, real-time modifications, natural language processing","Generating 3D models has traditionally been a complex task requiring specialized expertise. Recent advances in generative AI have sought to automate this process, but existing methods produce non-editable representations, such as meshes or point clouds, limiting their adaptability for iterative design. This paper introduces Proc3D, a system designed to generate editable 3D models while enabling real-time modifications. At its core, Proc3D introduces procedural compact graph (PCG), a graph representation of 3D models that encodes the algorithmic rules and structures necessary for generating the model. This representation exposes key parameters, allowing intuitive manual adjustments via sliders and checkboxes, as well as real-time, automated modifications through natural language prompts using Large Language Models (LLMs). Proc3D demonstrates capabilities using GPT-4o with in-context learning (ICL) and a fine-tuned LLAMA-3 model. Experimental results show that Proc3D outperforms existing methods in editing efficiency, achieving more than 400× speedup over conventional approaches that require full regeneration for each modification. Additionally, Proc3D improves ULIP scores by 28%, a metric that evaluates the alignment between generated 3D models and text prompts. By enabling text-aligned 3D model generation along with precise, real-time parametric edits, Proc3D facilitates highly accurate text-based image editing applications.",20.41,21.072,430,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12242v1_Optimal Power Allocation and Sub-Optimal Channel A.pdf,Optimal Power Allocation and Sub-Optimal Channel Assignment for Downlink NOMA System Using Deep Reinforcement Learning,"WooSeok Kim, Jeonghoon Lee, Sangho Kim, Taesun An, WonMin Lee, Dowon Kim, Kyungseop Shin",,2601.12242v1,"Non-orthogonal multiple access (NOMA), deep reinforcement learning (DRL), wireless network, resource allocation","In recent years, Non-Orthogonal Multiple Access (NOMA) system has emerged as a promising candidate for multiple access frameworks due to the evolution of deep machine learning, trying to incorporate deep machine learning into the NOMA system. The main motivation for such active studies is the growing need to optimize the utilization of network resources as the expansion of the internet of things (IoT) caused a scarcity of network resources. The NOMA addresses this need by power multiplexing, allowing multiple users to access the network simultaneously. Nevertheless, the NOMA system has few limitations. Several works have proposed to mitigate this, including the optimization of power allocation known as joint resource allocation (JRA) method, and integration of the JRA method and deep reinforcement learning (JRA-DRL). Despite this, the channel assignment problem remains unclear and requires further investigation. In this paper, we propose a deep reinforcement learning framework incorporating replay memory with an on-policy algorithm, allocating network resources in a NOMA system to generalize the learning. Also, we provide extensive simulations to evaluate the effects of varying the learning rate, batch size, type of model, and the number of features in the state.",19.77,19.674,389,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12243v1_Less is More Label-Guided Summarization of Procedu.pdf,Less is More: Label-Guided Summarization of Procedural and Instructional Videos,"Shreya Rajpal, Michal Golovanesky, Carsten Eickhoff",,arXiv:2601.12243v1,"video summarization, procedural videos, instructional videos, semantic content, keyframe selection, large language models, context-aware summarization","Video summarization helps turn long videos into clear, concise representations that are easier to review, document, and analyze, especially in high-stakes domains like surgical training. Prior work has progressed from using basic visual features like color, motion, and structural changes to using pre-trained vision-language models that can better understand what’s happening in the video (semantics) and capture temporal flow, resulting in more context-aware video summarization. We propose a three-stage framework, PRISM: Procedural Representation via Integrated Semantic and Multimodal analysis, that produces semantically grounded video summaries. PRISM combines adaptive visual sampling, label-driven keyframe anchoring, and contextual validation using a large language model (LLM). Our method ensures that selected frames reflect meaningful and procedural transitions while filtering out generic or hallucinated content, resulting in contextually coherent summaries across both domain-specific and instructional videos. We evaluate our method on instructional and activity datasets, using reference summaries for instructional videos. Despite sampling fewer than 5% of the original frames, our summaries retain 84% semantic content while improving over baselines by as much as 33%. Our approach generalizes across procedural and domain-specific video tasks, achieving strong performance with both semantic alignment and precision.",19.5,19.74,385,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12247v1_Plan Verify and Fill A Structured Parallel Decodin.pdf,"Plan, Verify and Fill: A Structured Parallel Decoding Approach for Diffusion Language Models","Miao Li, Hanyang Jiang, Sikai Cheng, Hengyu Fu, Yuhang Cai, Baihe Huang, Tinghan Ye, Xuanzhou Chen, Pascal Van Hentenryck",,,"Diffusion Language Models, non-sequential paradigm, text generation, autoregressive, decoding strategies, global bidirectional context, Plan-Verify-Fill, hierarchical skeleton, semantic anchors, structural stopping, Number of Function Evaluations, parallel decoding, efficiency, accuracy","Diffusion Language Models (DLMs) offer a non-sequential approach to text generation, differing from traditional autoregressive models. Current decoding strategies often underutilize the global context, leading to inefficiencies. This paper introduces the Plan-Verify-Fill (PVF) paradigm, which constructs a hierarchical skeleton prioritizing semantic anchors and employs a verification protocol for efficient decoding. Evaluations show that PVF reduces the Number of Function Evaluations by up to 65% without sacrificing accuracy, demonstrating enhanced efficiency in text generation.",17.71,17.734,314,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12248v1_AQUA-Bench Beyond Finding Answers to Knowing When .pdf,AQUA-BENCH: BEYOND FINDING ANSWERS TO KNOWING WHEN THERE ARE NONE IN AUDIO QUESTION ANSWERING,"Chun-Yi Kuan, Hung-yi Lee",,,"Unanswerable questions, Audio question answering, Audio-aware large language models","Recent advances in audio-aware large language models have shown strong performance on audio question answering. However, existing benchmarks mainly cover answerable questions and overlook the challenge of unanswerable ones, where no reliable answer can be inferred from the audio. To address this gap, AQUA-Bench is introduced, a benchmark for Audio Question Unanswerability Assessment. It evaluates three scenarios: Absent Answer Detection, Incompatible Answer Set Detection, and Incompatible Audio Question Detection. AQUA-Bench offers a rigorous measure of model reliability and promotes the development of more robust and trustworthy audio-language systems. Experiments suggest that while models excel on standard answerable tasks, they face notable challenges with unanswerable ones, indicating a blind spot in current audio-language understanding.",16.64,14.48,241,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12249v1_An Innovative Framework for Breast Cancer Detectio.pdf,"An Innovative Framework for Breast Cancer Detection Using Pyramid Adaptive Atrous Convolution, Transformer Integration, and Multi-Scale Feature Fusion","Ehsan Sadeghi Pour, Mahdi Esmaeili, Morteza Romoozi",,,"Breast Cancer Detection, Pyramid Adaptive Atrous Convolution (PAAC), Transformer, Multi-Scale Feature Fusion, Self-Attention Mechanism, Medical Image Processing","Breast cancer is one of the most common cancers among women worldwide, and its accurate and timely diagnosis plays a critical role in improving treatment outcomes. This thesis presents an innovative framework for detecting malignant masses in mammographic images by integrating the Pyramid Adaptive Atrous Convolution (PAAC) and Transformer architectures. The proposed approach utilizes Multi-Scale Feature Fusion to enhance the extraction of features from benign and malignant tissues and combines Dice Loss and Focal Loss functions to improve the model’s learning process, effectively reducing errors in binary breast cancer classification and achieving high accuracy and efficiency. In this study, a comprehensive dataset of breast cancer images from INbreast, MIAS, and DDSM was preprocessed through data augmentation and contrast enhancement and resized to 227×227 pixels for model training. Leveraging the Transformer's ability to manage long-range dependencies with Self-Attention mechanisms, the proposed model achieved high accuracy in detecting cancerous masses, outperforming foundational models such as BreastNet, DeepMammo, Multi-Scale CNN, Swin-Unet, and SegFormer. The final evaluation results for the proposed model include an accuracy of 98.5%, sensitivity of 97.8%, specificity of 96.3%, F1-score of 98.2%, and overall precision of 97.9%. These metrics demonstrate a significant improvement over traditional methods and confirm the model's effectiveness in identifying cancerous masses in complex scenarios and large datasets. This model shows potential as a reliable and efficient tool for breast cancer diagnosis and can be effectively integrated into medical diagnostic systems.",19.84,22.78,452,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12256v1_Improving Large Molecular Language Model via Relat.pdf,Improving Large Molecular Language Model via Relation-aware Multimodal Collaboration,"Jinyoung Park, Minseong Bae, Jeehye Na, Hyunwoo J. Kim",,,"large molecular language models, molecular modality-collaborative projector, relation-aware modality-collaborative attention, molecule-centric evaluation metrics, molecular comprehension, molecule captioning, computed property QA, descriptive property QA, motif counting, IUPAC name prediction","Large language models (LLMs) have shown significant advancements in various tasks, inspiring the development of large molecular language models (LMLMs) that integrate 1D, 2D, and 3D molecular modalities. However, existing LMLMs often suffer from hallucination and limited robustness due to inadequate integration of these modalities. This paper proposes CoLLaMo, a model equipped with a multi-level molecular modality-collaborative projector and a relation-aware modality-collaborative attention mechanism. This approach enhances the molecular modality generalization capabilities of LMLMs, achieving superior performance on tasks such as molecule captioning, computed property QA, descriptive property QA, motif counting, and IUPAC name prediction. The paper also introduces new evaluation metrics to address the limitations of traditional token-based metrics.",17.82,18.58,331,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12257v1_Soft Shadow Diffusion SSD Physics-inspired Learnin.pdf,Soft Shadow Diffusion (SSD): Physics-inspired Learning for 3D Computational Periscopy,"Fadlullah Raji, John Murray Bruce",,arXiv:2601.12257v1,"Computational imaging, Machine learning, 3D generative models, Diffusion models, Separable non-linear least squares","Conventional imaging requires a line of sight to create accurate visual representations of a scene. In certain circumstances, however, obtaining a suitable line of sight may be impractical, dangerous, or even impossible. Non-line-of-sight (NLOS) imaging addresses this challenge by reconstructing the scene from indirect measurements. Recently, passive NLOS methods that use an ordinary photograph of the subtle shadow cast onto a visible wall by the hidden scene have gained interest. These methods are currently limited to 1D or low-resolution 2D color imaging or to localizing a hidden object whose shape is approximately known. Here, we generalize this class of methods and demonstrate a 3D reconstruction of a hidden scene from an ordinary NLOS photograph. To achieve this, we propose a novel reformulation of the light transport model that conveniently decomposes the hidden scene into light-occluding and non-light-occluding components to yield a separable non-linear least squares (SNLLS) inverse problem. We develop two solutions: A gradient-based optimization method and a physics-inspired neural network approach, which we call Soft Shadow Diffusion (SSD). Despite the challenging ill-conditioned inverse problem encountered here, our approaches are effective on numerous 3D scenes in real experimental scenarios. Moreover, SSD is trained in simulation but generalizes well to unseen classes in simulation and real-world NLOS scenes. SSD also shows surprising robustness to noise and ambient illumination.",20.37,19.928,406,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12259v1_FutureX-Pro Extending Future Prediction to High-Va.pdf,FutureX-Pro: Extending Future Prediction to High-Value Vertical Domains,"ByteDance Seed, Hong Kong University of Science and Technology, Georgia Institute of Technology, Stanford University, Princeton University",,arXiv:2601.12259v1,"future prediction, agentic LLMs, Finance, Retail, Public Health, Natural Disaster, LLM agents, market indicators, supply chain demands, epidemic trends, natural disasters","Building upon FutureX, this report introduces FutureX-Pro, which extends agentic future prediction to high-value vertical domains such as Finance, Retail, Public Health, and Natural Disaster. It benchmarks Large Language Models (LLMs) on foundational prediction tasks in these sectors, assessing their domain grounding for industrial deployment. The study reveals a performance gap between generalist reasoning and the precision required for high-value applications.",17.03,14.209,242,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12260v1_Docs2Synth A Synthetic Data Trained Retriever Fram.pdf,Docs2Synth: A Synthetic Data Trained Retriever Framework for Scanned Visually Rich Documents Understanding,"Yihao Ding, Qiang Sun, Puzhen Wu, Sirui Li, Siwen Luo, Wei Liu",,,"Document understanding, VRDU, Multimodal Large Language Models, Vision-Language Pre-trained Models, Synthetic data, Retriever framework, Domain-specific knowledge, Agent-based system, Iterative retrieval–generation loop","Document understanding (VRDU) in regulated domains is challenging due to the lack of manual annotations and the difficulty for pretrained models to stay updated with domain-specific facts. Docs2Synth is introduced as a synthetic-supervision framework that enables retrieval-guided inference for private and low-resource domains. It processes raw document collections, generates and verifies diverse QA pairs via an agent-based system, and trains a lightweight visual retriever to extract domain-relevant evidence. During inference, the retriever collaborates with an MLLM through an iterative retrieval–generation loop, reducing hallucination and improving response consistency. Experiments show that Docs2Synth enhances grounding and domain generalization without requiring human annotations.",17.6,16.871,297,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12263v1_Multimodal Generative Engine Optimization Rank Man.pdf,Multimodal Generative Engine Optimization: Rank Manipulation for Vision–Language Model Rankers,"Yixuan Du, Chenxiao Yu, Haoyan Xu, Ziyi Wang, Yue Zhao, Xiyang Hu",,,"Vision-Language Models, adversarial manipulation, multimodal ranking attacks, product search, image perturbations, textual suffixes, cross-modal coupling","Vision-Language Models (VLMs) are increasingly used in retrieval and recommendation systems. This paper identifies a vulnerability in VLM-based product search: multimodal ranking attacks. The proposed Multimodal Generative Engine Optimization (MGEO) framework allows malicious actors to promote a target product by optimizing both image perturbations and textual suffixes. MGEO uses an alternating gradient-based optimization strategy to exploit the cross-modal coupling within VLMs. Experiments show that this coordinated attack outperforms text-only and image-only baselines, highlighting the potential for multimodal synergy to be weaponized in compromising search rankings.",15.96,16.73,267,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12269v1_Simulated Annealing Enhances Theory-of-Mind Reason.pdf,Simulated Annealing Enhances Theory-of-Mind Reasoning in Autoregressive Language Models,"Xucong Hu, Jian-Qiao Zhu",,,"Language Models, Markov Chain Monte Carlo, Simulated Annealing, Power Sampling, Theory of Mind","Autoregressive language models, typically next-token predictors, have been criticized for optimizing surface plausibility rather than maintaining correct latent-state representations. This paper demonstrates that strong Theory of Mind (ToM) capabilities can be recovered directly from base models without additional weight updates or verifications. The approach builds on power-sampling methods using Markov chain Monte Carlo (MCMC) to sample from sharpened sequence-level probability distributions. Incorporating annealing, where the tempered distribution is gradually shifted from high to low temperature, substantially improves ToM performance over fixed-temperature power sampling. These results suggest that sampling-based optimization can extract latent capabilities from language models without retraining.",16.34,14.501,237,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12276v1_Predictive Prototyping Evaluating Design Concepts .pdf,PREDICTIVE PROTOTYPING: EVALUATING DESIGN CONCEPTS WITH GPT,Hilsann Yong,,,"Prototyping, Design Theory, Iteration, Simulation, AI, LLM, GPT, RAG, Crowdsourcing","The design-build-test cycle is critical for realizing innovative solutions, allowing teams to evaluate and iterate on concepts based on performance. However, testing can be time-consuming and costly. This work explores the potential of generative pretrained transformers (GPTs), specifically OpenAI’s GPT-4o, to predict prototyping outcomes such as cost, performance, and usability. A novel approach using retrieval augmented generation (RAG) is introduced to emulate design feedback. The study leverages prototyping data from 'Instructables.com' and compares GPT-RAG predictions with human designers and ground-truth physical prototyping results. The GPT-RAG model's predictions were found to be more accurate than human estimations for cost and performance, and the prototype inspired by GPT-RAG outperformed commercial and topology optimized models. The study also found that averaging multiple GPT-RAG responses improved accuracy, demonstrating the model's ability to emulate crowd behavior.",17.76,16.555,294,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12282v1_CytoCLIP Learning Cytoarchitectural Characteristic.pdf,CytoCLIP: Learning Cytoarchitectural Characteristics in Developing Human Brain Using Contrastive Language Image Pre-Training,"Pralaypati Ta, Sriram Venkatesaperumal, Keerthi Ram, Mohanasankar Sivaprakasam",,,"Cytoarchitecture, Histological Image processing, Contrastive learning, CLIP","The functions of different regions of the human brain are closely linked to their distinct cytoarchitecture, defined by the spatial arrangement and morphology of cells. Identifying brain regions by their cytoarchitecture enables various scientific analyses of the brain. However, delineating these areas manually in brain histological sections is time-consuming and requires specialized knowledge. An automated approach is necessary to minimize the effort needed from human experts. To address this, we propose CytoCLIP, a suite of vision-language models derived from pre-trained Contrastive Language-Image Pre-Training (CLIP) frameworks to learn joint visual-text representations of brain cytoarchitecture. CytoCLIP comprises two model variants: one is trained using low-resolution whole-region images to understand the overall cytoarchitectural pattern of an area, and the other is trained on high-resolution image tiles for detailed cellular-level representation. The training dataset is created from NISSL-stained histological sections of developing fetal brains of different gestational weeks. It includes 86 distinct regions for low-resolution images and 384 brain regions for high-resolution tiles. We evaluate the model's understanding of the cytoarchitecture and generalization ability using region classification and cross-modal retrieval tasks. Multiple experiments are performed under various data setups, including data from samples of different ages and sectioning planes. Experimental results demonstrate that CytoCLIP outperforms existing methods. It achieves an F1 score of 0.87 for whole-region classification and 0.91 for high-resolution image tile classification.",19.75,21.921,433,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12286v1_Conversational Context Classification A Representa.pdf,Conversational Context Classification: A Representation Engineering Approach,Jonathan Pan,,,"Large Language Models (LLMs), One-Class SVM, Novelty Detection, In/Out-of-Context, Representation Engineering","The increasing prevalence of Large Language Models (LLMs) demands effective safeguards for their operation, particularly concerning their tendency to generate 'out-of-context' responses. This paper explores the use of Representation Engineering (RepE) and One-Class Support Vector Machine (OCSVM) to identify subspaces within the internal states of LLMs that represent a specific context. By training OCSVM on in-context examples, a robust boundary within the LLM’s hidden state latent space is established. The study evaluated two open-source LLMs – Llama and Qwen models – in specific contextual domains, identifying optimal layers within the LLM’s internal state subspaces associated with the context of interest. The approach showed promising results in identifying the subspace for a specific context, contributing to AI safety and better interpretation of LLMs.",16.49,14.315,236,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12288v1_TimeGMM Single-Pass Probabilistic Forecasting via .pdf,TIMEGMM: SINGLE-PASS PROBABILISTIC FORECASTING VIA ADAPTIVE GAUSSIAN MIXTURE MODELS WITH REVERSIBLE NORMALIZATION,"Lei Liu, Tengyuan Liu, Hongwei Zhao, Jiahui Huang, Ruibo Guo, Bin Li",,,"Probabilistic time series forecasting, Gaussian mixture model, Reversible instance normalization","Probabilistic time series forecasting is crucial for quantifying future uncertainty, with significant applications in fields such as energy and finance. Existing methods often rely on computationally expensive sampling or restrictive parametric assumptions to characterize future distributions, which limits predictive performance and introduces distributional mismatch. This paper presents TimeGMM, a novel probabilistic forecasting framework based on Gaussian Mixture Models (GMM) that captures complex future distributions in a single forward pass. A key component is GMM-adapted Reversible Instance Normalization (GRIN), a novel module designed to dynamically adapt to temporal-probabilistic distribution shifts. The framework integrates a dedicated Temporal Encoder (TE-Module) with a Conditional Temporal-Probabilistic Decoder (CTPD-Module) to jointly capture temporal dependencies and mixture distribution parameters. Extensive experiments demonstrate that TimeGMM consistently outperforms state-of-the-art methods, achieving maximum improvements of 22.48% in CRPS and 21.23% in NMAE.",17.88,18.737,335,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12294v1_ToolPRMBench Evaluating and Advancing Process Rewa.pdf,ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents,"Dawei Li, Yuguang Yao, Zhen Tan, Huan Liu, Ruocheng Guo",,,"reward-guided search methods, tool-using agents, process reward models (PRMs), benchmark, large language models, LLMs, tool-using, APIs, multi-step tasks","Reward-guided search methods have shown potential in enhancing tool-using agents by guiding sampling and exploration over complex action spaces. This paper introduces ToolPRMBench, a benchmark for evaluating process reward models (PRMs) in tool-using settings. Built on representative benchmarks, ToolPRMBench converts agent trajectories into step-level test cases, isolating single-step errors and capturing multi-step failures. A multi-LLM verification pipeline ensures data quality. Experiments reveal differences in PRM effectiveness and highlight the potential of specialized PRMs for tool-using agents.",15.89,15.797,251,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12304v1_A Two-Stage Globally-Diverse Adversarial Attack fo.pdf,A TWO-STAGE GLOBALLY-DIVERSE ADVERSARIAL ATTACK FOR VISION-LANGUAGE PRE-TRAINING MODELS,"Wutao Chen, Huaqin Zou, Chen Wan, Lifeng Huang",,,"Adversarial Attack, VLP Models, Multimodal Retrieval, Transferability","Vision-language pre-training (VLP) models are vulnerable to adversarial examples, especially in black-box scenarios. Existing multimodal attacks often face issues with limited perturbation diversity and unstable multi-stage pipelines. To address these challenges, the paper proposes 2S-GDA, a two-stage globally-diverse attack framework. This method introduces textual perturbations through a globally-diverse strategy by combining candidate text expansion with globally-aware replacement. To enhance visual diversity, image-level perturbations are generated using multi-scale resizing and block-shuffle rotation. Extensive experiments on VLP models show that 2S-GDA consistently improves attack success rates over state-of-the-art methods, with gains of up to 11.17% in black-box settings. The framework is modular and can be easily combined with existing methods to further enhance adversarial transferability.",17.4,16.725,291,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12310v1_Survival is the Only Reward Sustainable Self-Train.pdf,Survival is the Only Reward: Sustainable Self-Training Through Environment-Mediated Selection,"Jennifer Dodgson, Alfath Daryl Alhajir, Michael Joedhitya, Akira Rafhael Janson Pattirane, Surender Suresh Kumar, Joseph Lim, C.H. Peh, Adith Ramdas, Steven Zhang Zhexu",,2601.12310v1,"self-training, environment-mediated selection, semantic drift, reward hacking, environmental viability, negative-space learning, meta-learning, autonomous systems","This paper introduces a self-training architecture where learning is mediated by environmental viability rather than rewards or external criteria. It demonstrates that candidate behaviors are executed under real constraints, and only those that persist and allow future interactions are propagated. The environment does not provide semantic feedback or dense rewards, making reward-hacking evolutionarily unstable. The study shows that improvement arises through the persistence of effective strategies under a regime of consolidation and pruning, termed negative-space learning (NSL). Models develop meta-learning strategies without explicit instruction, establishing that environment-grounded selection enables sustainable self-improvement and robust autonomous systems without human-curated data or complex reward shaping.",19.56,15.95,312,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12316v1_GazeFormer-MoE Context-Aware Gaze Estimation via C.pdf,GAZEFORMER-MOE: CONTEXT-AWARE GAZE ESTIMATION VIA CLIP AND MOE TRANSFORMER,"Xinyuan Zhao, Xianrui Chen, Ahmad Chaddad",,,"Gaze estimation, multi scale fusion, MoE transformer","We present a semantics modulated, multi scale Transformer for 3D gaze estimation. Our model conditions CLIP global features with learnable prototype banks (illumination, head pose, background, direction), fuses these prototype-enriched global vectors with CLIP patch tokens and high-resolution CNN tokens in a unified attention space, and replaces several FFN blocks with routed/shared Mixture of Experts to increase conditional capacity. Evaluated on MPIIFaceGaze, EYEDIAP, Gaze360 and ETH-XGaze, our model achieves new state of the art angular errors of 2.49°, 3.22°, 10.16°, and 1.44°, demonstrating up to a 64% relative improvement over previously reported results. Ablations attribute gains to prototype conditioning, cross scale fusion, MoE and hyperparameter. Our code is publicly available at https://github.com/AIPMLab/Gazeformer.",17.63,16.788,296,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12317v1_Explanova Automatically Discover Data Insights in .pdf,Explanova: Automatically Discover Data Insights in N×M Table via XAI Combined LLM Workflow,Yiming Huang,10.1145/nnnnnnn.nnnnnnn,,"data analysis, LLM, AutoML, XAI, data insights","Automation in data analysis has been a long-time pursuit. Current agentic LLM shows a promising solution towards it. Explanova is an attempt to enhance LLM-based automatic data science from the data analytics side, using a preset workflow to empower common LLMs' performance in automatic data analysis. It focuses on single-feature statistic analysis, feature-to-feature relation statistic analysis, and feature modeling by all other features in one data table, leveraging the explainable AI (XAI) paradigm.",15.35,13.156,202,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12318v1_Beyond Human Annotation Recent Advances in Data Ge.pdf,Beyond Human Annotation: Recent Advances in Data Generation Methods for Document Intelligence,"Dehao Ying, Fengchang Yu, Haihua Chen, Changjiang Jiang, Yurong Li, Wei Lu",https://doi.org/XXXXXXX.XXXXXXX,,"Document Intelligence, Data Generation, Data Quality Evaluation, Surveys and overviews, Artificial intelligence","The advancement of Document Intelligence (DI) demands large-scale, high-quality training data, yet manual annotation remains a critical bottleneck. This survey establishes the first comprehensive technical map for data generation in DI, redefining it as supervisory signal production and introducing a novel taxonomy based on the 'availability of data and labels.' Methodologies are organized into four paradigms: Data Augmentation, Data Generation from Scratch, Automated Data Annotation, and Self-Supervised Signal Construction. A multi-level evaluation framework integrates intrinsic quality and extrinsic utility, compiling performance gains across diverse DI benchmarks. The survey reveals critical challenges such as fidelity gaps and frontiers including co-evolutionary ecosystems, positioning data generation as the central engine for next-generation DI.",17.23,16.195,279,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12323v1_MARO Learning Stronger Reasoning from Social Inter.pdf,MARO: Learning Stronger Reasoning from Social Interaction,"Yin Cai, Zhouhong Gu, JunTao Zhang, Ping Chen",,,"large language models, multi-agent reward optimization, social reasoning, interaction, negotiation, competition, machine learning","Humans face countless scenarios requiring reasoning and judgment in daily life. Existing large language model training methods primarily allow models to learn from existing textual content or solve predetermined problems, lacking experience in real scenarios involving interaction, negotiation, and competition with others. This paper proposes Multi-Agent Reward Optimization (MARO), a method that enables large language models (LLMs) to acquire stronger reasoning abilities by learning and practicing in multi-agent social environments. MARO addresses the sparse learning signal problem by decomposing outcomes into specific behaviors, handles uneven role distribution by balancing training sample weights, and addresses environmental instability by evaluating the utility of each behavior. Experimental results demonstrate significant improvements in social reasoning capabilities and effective transfer to other tasks such as mathematical reasoning and instruction following, revealing the potential of multi-agent social learning in enhancing the general reasoning capabilities of LLMs.",17.44,15.936,278,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12327v1_The Expert Validation Framework EVF Enabling Domai.pdf,The Expert Validation Framework (EVF): Enabling Domain Expert Control in AI Engineering,"Lucas Gren, Felix Dobslaw",https://doi.org/10.1145/xxx.xxxx,,"GenAI, expert validation, quality assurance, AI engineering, domain expert control","Generative AI (GenAI) systems promise to transform knowledge work by automating a range of tasks, yet their deployment in enterprise settings remains hindered by the lack of systematic quality assurance mechanisms. We present an Expert Validation Framework that places domain experts at the center of building software with GenAI components, enabling them to maintain authoritative control over system behavior through structured specification, testing, validation, and continuous monitoring processes. Our framework addresses the critical gap between AI capabilities and organizational trust by establishing a rigorous, expert-driven methodology for ensuring quality across diverse GenAI applications. Through a four-stage implementation process encompassing specification, system creation, validation, and production monitoring, the framework enables organizations to leverage GenAI capabilities while maintaining expert oversight and quality standards.",16.88,15.169,256,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12330v1_IceWatch Forecasting Glacial Lake Outburst Floods .pdf,IceWatch: Forecasting Glacial Lake Outburst Floods (GLOFs) using Multimodal Deep Learning,"Zuha Fatima, Muhammad Anser Sohaib, Muhammad Talha, Ayesha Kanwal, Sidra Sultana, Nazia Perwaiz",,,"CNN, deep learning, glacier monitoring, GLOF detection, LSTM, remote sensing, Sentinel-2, temperature forecasting, transformer, velocity prediction","Glacial Lake Outburst Floods (GLOFs) pose a serious threat in high mountain regions, affecting communities, infrastructure, and ecosystems. Traditional methods for GLOF detection rely on hydrological modeling, threshold-based lake monitoring, and manual satellite image analysis, which have limitations such as slow updates, manual labor dependency, and reduced accuracy due to cloud interference or lack of on-site data. This paper introduces IceWatch, a novel deep learning framework for GLOF prediction that incorporates both spatial and temporal perspectives. The vision component, RiskFlow, uses a CNN-based classifier to predict GLOF events from Sentinel-2 multispectral satellite imagery by analyzing spatial patterns of snow, ice, and meltwater. Its tabular counterpart considers physical dynamics to confirm predictions. TerraFlow models glacier velocity from NASA ITS_LIVE time series, while TempFlow forecasts near-surface temperature from MODIS LST records. Both components are trained on long-term observational archives and integrated via harmonized preprocessing and synchronization for multimodal, physics-informed GLOF prediction. This system ensures strong predictive performance, rapid data processing for real-time use, and robustness to noise and missing information, paving the way for automatic, scalable GLOF warning systems and potential integration with diverse sensor inputs and global glacier monitoring activities.",19.03,20.752,395,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12331v1_Efficient Privacy-Preserving Retrieval Augmented G.pdf,Efficient Privacy-Preserving Retrieval Augmented Generation with Distance-Preserving Encryption,"Huanyi Ye, Jiale Guo, Ziyao Liu, Kwok-Yan Lam",,,"RAG, Privacy-Preserving Retrieval, Distance-Preserving Encryption, LLMs","Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by retrieving knowledge from external databases, augmenting prompts, and generating more accurate responses. Traditional RAG systems rely on trusted local environments, but cloud-based storage introduces privacy risks. Existing privacy-preserving techniques often use partially homomorphic encryption, which is computationally expensive. This paper proposes an efficient privacy-preserving RAG framework (ppRAG) for untrusted cloud environments, using Conditional Approximate Distance-Comparison-Preserving Symmetric Encryption (CAPRISE) to encrypt embeddings while preserving relative distance ordering. Differential privacy is introduced to mitigate query analysis risks. Experimental results demonstrate ppRAG's efficiency, high retrieval accuracy, and strong privacy guarantees, making it suitable for resource-constrained users seeking secure, cloud-augmented LLMs.",17.55,15.952,280,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12338v1_Actionable Advice from Reviews via Mixture of LoRA.pdf,Actionable Advice from Reviews via Mixture of LoRA Experts: A Two-LLM Pipeline for Issue Extraction and Business Recommendations,"Kartikey Singh Bhandari, Manav Ganesh, Yashwant Viswanathan, Archit Agrawal, Dhruv Kumar, Pratik Narang",,,"customer reviews, issue extraction, business recommendations, large language models, LoRA experts, actionability, specificity, feasibility, expected impact, novelty, non-redundancy, bias, clarity","Customer reviews contain detailed, domain-specific signals about service failures and user expectations, but converting this unstructured feedback into actionable business decisions remains difficult. This paper proposes a modular two-LLM framework for review-to-action generation, producing concrete, implementable recommendations grounded in review text. An Issue model extracts salient issues and assigns coarse themes, while an Advice model generates targeted operational fixes conditioned on the extracted issue representation. The Advice model is adapted using a mixture-of-LoRA experts strategy, enabling specialization without expensive full fine-tuning. Synthetic review–issue–advice triples from Yelp reviews (airlines and restaurants) are used to supervise training. The approach is evaluated using an eight-dimension operational rubric and consistently outperforms prompting-only and single-adapter baselines, yielding higher actionability and specificity while retaining favorable efficiency–quality trade-offs.",18.46,19.176,354,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12341v1_Time-Continuous Modeling for Temporal Affective Pa.pdf,Time-Continuous Modeling for Temporal Affective Pattern Recognition in LLM’s,"Rezky M. Kam, Coddy N. Siswanto",,,"affective pattern recognition, temporal modeling, LLM, encoder-decoder architecture, time-continuous patterns, physics informed neural network, affective trajectories, dialogue systems, computational efficiency, interpretation","This paper addresses the limitations of text modality decoder models that rely on discrete token generation, which often results in a lack of true understanding and introduces black-box interpretation of affective dynamics in conversations. The authors propose a hybrid encoder-decoder architecture that utilizes time-aware patterns and physics informed neural networks to adapt temporally and longitudinally. This approach aims to mimic psychological plausibility in user interactions while maintaining computational efficiency and interpretability.",16.16,13.736,222,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12343v1_How Well Do LLMs Predict Human Behavior A Measure .pdf,How Well Do LLMs Predict Human Behavior? A Measure of their Pretrained Knowledge,"Wayne Gao, Sukjin Han, Annie Liang",,2601.12343v1,"Large Language Models, Human Behavior Prediction, Pretrained Knowledge, Equivalent Sample Size, Economic Variables, Panel Study of Income Dynamics","Large language models (LLMs) are increasingly used to predict human behavior. This paper proposes a measure for evaluating the knowledge a pretrained LLM brings to such predictions, defined as its equivalent sample size. This measure is estimated by comparing the prediction error of a fixed LLM in a given domain to that of flexible machine learning models trained on increasing samples of domain-specific data. A new asymptotic theory for cross-validated prediction error is developed to provide a statistical inference procedure. The method is applied to the Panel Study of Income Dynamics, revealing that LLMs encode considerable predictive information for some economic variables but much less for others, indicating that their value as substitutes for domain-specific data varies across settings.",19.46,12.332,240,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12349v1_Zero-Permission Manipulation Can We Trust Large Mu.pdf,Zero-Permission Manipulation: Can We Trust Large Multimodal Model Powered GUI Agents?,"Yi Qian, Kunwei Qian, Xingbang He, Ligeng Chen, Jikang Zhang, Tiantai Zhang, Haiyang Wei, Linzhang Wang, Hao Wu, Bing Mao",,,"GUI agents, multimodal models, Android, security, attack surface, action rebinding, Intent Alignment Strategy, verification gates, malware detection","Large multimodal model powered GUI agents are emerging as high-privilege operators on mobile platforms, entrusted with perceiving screen content and injecting inputs. These agents serve as a new control plane mediating interactions across application boundaries. However, their design operates under the implicit assumption of Visual Atomicity, which is fundamentally invalid in Android, creating a critical attack surface. The paper presents Action Rebinding, a novel cross-application attack that allows a seemingly-benign application with zero dangerous permissions to rebind an agent’s execution. By exploiting the observation-to-action gap inherent in the agent’s reasoning pipeline, the attacker triggers foreground transitions to rebind the agent’s planned action toward the target application. The paper also introduces an Intent Alignment Strategy (IAS) that manipulates the agent’s reasoning process to rationalize rebound states, enabling it to bypass verification gates. The evaluation demonstrates a 100% success rate for atomic action rebinding and the ability to orchestrate multi-step attack chains. The attacker application requires no sensitive permissions and achieves a 0% detection rate across malware scanners. The findings reveal a fundamental architectural flaw in current agent-OS integration and provide critical insights for the secure design of future autonomous agent systems.",19.28,21.368,412,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12357v1_SimpleMatch A Simple and Strong Baseline for Seman.pdf,SimpleMatch: A Simple and Strong Baseline for Semantic Correspondence,"Hailong Jin, Huiying Li",,,"semantic correspondence, upsample decoder, multi-scale supervised loss, sparse matching, window-based localization, 4D-correlation, feature-based methods","Recent advances in semantic correspondence have been largely driven by the use of pre-trained large-scale models, which require high-resolution input images, leading to significant computational overhead. This work addresses the issue of irreversible fusion of adjacent keypoint features caused by deep downsampling operations. SimpleMatch is introduced as a simple yet effective framework for semantic correspondence that performs well even at low resolutions. It features a lightweight upsample decoder that progressively recovers spatial detail and a multi-scale supervised loss to retain discriminative features across different spatial scales. Additionally, sparse matching and window-based localization are introduced to optimize training memory usage, reducing it by 51%. At a resolution of 252×252, SimpleMatch achieves superior performance with 84.1% PCK@0.1 on the SPair-71k benchmark, providing a practical and efficient baseline for future research in semantic correspondence.",17.23,15.379,265,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12358v1_From Prompts to Pavement LMMs-based Agentic Behavi.pdf,From Prompts to Pavement: LMMs-based Agentic Behavior-Tree Generation Framework for Autonomous Vehicles,"Omar Y. Goba, Ahmed Y. Gado, Catherine M. Elias, Ahmed Hussein",,,"Behavior-Tree, Large Language Model, L5 Autonomy, Navigation, ROS, CARLA, Nav2","Autonomous vehicles require adaptive behavior planners to navigate unpredictable environments safely. Traditional behavior trees (BTs) are static and require manual tuning, limiting their use at SAE Level 5 autonomy. This paper introduces an agentic framework using large language models (LLMs) and multi-modal vision models (LVMs) to generate and adapt BTs dynamically. A Descriptor agent assesses scene criticality, a Planner agent constructs high-level sub-goals, and a Generator agent synthesizes executable BT sub-trees in XML format. Integrated into a CARLA+Nav2 simulation, the system activates upon baseline BT failure, successfully navigating unexpected obstacles without human intervention. This approach demonstrates potential for diverse driving scenarios, extending beyond static BT baselines.",16.96,16.272,276,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12374v1_A Scalable Entity-Based Framework for Auditing Bia.pdf,A Scalable Entity-Based Framework for Auditing Bias in LLMs,"Akram Elbouanani, Aboubacar Tuo, Adrian Popescu",,,"bias auditing, large language models, LLMs, structural disparities, named entities, synthetic data, natural text, instruction tuning, model scale, prompting strategies, high-stakes applications","This paper introduces a scalable framework for auditing bias in large language models (LLMs) using named entities as probes. The framework addresses the trade-off between ecological validity and statistical control in existing bias evaluation methods. By employing synthetic data, the study replicates bias patterns observed in natural text, allowing for large-scale analysis. The audit, comprising 1.9 billion data points, reveals systematic biases in LLMs, such as penalizing right-wing politicians and favoring Western entities. The study finds that while instruction tuning reduces bias, increasing model scale amplifies it, and prompting in Chinese or Russian does not mitigate Western-aligned preferences. These findings underscore the need for rigorous auditing of LLMs before their deployment in critical applications.",17.26,16.516,285,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12389v1_NADIR Differential Attention Flow for Non-Autoregr.pdf,NADIR: Differential Attention Flow for Non-Autoregressive Transliteration in Indic Languages,"Lakshya Tomar, Vinayak Abrol, Puneet Agarwal",,,"Non-Autoregressive Models, Transliteration, Indic Languages, Differential Transformer, Mixture-of-Experts, Character Error Rate, Attention Noise","This work explores the trade-off between speed and accuracy in sequence-to-sequence tasks, focusing on multilingual transliteration in Indic languages. It introduces NADIR, a novel Non-Autoregressive (NAR) architecture that balances speed and accuracy by integrating a Differential Transformer and a Mixture-of-Experts mechanism. NADIR achieves a significant speed-up compared to autoregressive models while maintaining competitive accuracy, reducing various types of errors, and providing a practical blueprint for fast and reliable NAR systems.",15.71,14.892,234,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12392v1_PsychēChat An Empathic Framework Focused on Emotio.pdf,Psych¯eChat: An Empathic Framework Focused on Emotion Shift Tracking and Safety Risk Analysis in Psychological Counseling,"Zhentao Xia, Yongqi Fan, Yuxiang Chu, Yichao Yin, Liangliang Chen, Tong Ruan, Weiyan Zhang",,,"Psychological Counseling, Emotion Shift Tracking, Safety Risk Analysis, Large Language Models, Emotion Management, Risk Control, Multi-Agent Pipeline, Chain-of-Thought Inference","Large language models (LLMs) have shown advancements in psychological counseling but often fail to model emotion shifts and safety risks effectively. Psych¯eChat addresses these gaps by integrating emotion shift tracking and safety risk analysis. It employs interactive role-playing to synthesize dialogues, featuring an Emotion Management Module and a Risk Control Module. Two modeling paradigms, Agent Mode and LLM Mode, are introduced to balance efficiency and performance. Extensive experiments demonstrate Psych¯eChat's superior performance in emotional insight and safety control.",16.56,16.127,267,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12401v1_Beyond the Dirac Delta Mitigating Diversity Collap.pdf,Beyond the Dirac Delta: Mitigating Diversity Collapse in Reinforcement Fine-Tuning for Versatile Image Generation,"Jinmei Liu, Haoru Li, Zhenhong Sun, Chaofeng Chen, Yatao Bian, Bo Wang, Daoyi Dong, Chunlin Chen, Zhi Wang",,,"Reinforcement Learning, Fine-Tuning, Image Generation, Diversity Collapse, Policy Optimization, Generative Models","Reinforcement learning (RL) has emerged as a powerful paradigm for fine-tuning large-scale generative models, such as diffusion and flow models, to align with complex human preferences and user-specified tasks. A fundamental limitation remains the curse of diversity collapse, where the objective formulation and optimization landscape inherently collapse the policy to a Dirac delta distribution. To address this challenge, we propose DRIFT (DiveRsity-Incentivized Reinforcement Fine-Tuning for Versatile Image Generation), an innovative framework that systematically incentivizes output diversity throughout the on-policy fine-tuning process, reconciling strong task alignment with high generation diversity to enhance versatility essential for applications that demand diverse candidate generations. We approach the problem across three representative perspectives: i) sampling a reward-concentrated subset that filters out reward outliers to prevent premature collapse; ii) prompting with stochastic variations to expand the conditioning space, and iii) optimization of the intra-group diversity with a potential-based reward shaping mechanism. Experimental results show that DRIFT achieves superior Pareto dominance regarding task alignment and generation diversity, yielding a 9.08%∼43.46% increase in diversity at equivalent alignment levels and a 59.65%∼65.86% increase in alignment at equivalent levels of diversity.",18.94,21.748,412,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12402v1_Weaknesses of Facial Emotion Recognition Systems.pdf,Weaknesses of Facial Emotion Recognition Systems,"Aleksandra Jamróz, Patrycja Wysocka, Piotr Garbat",,2601.12402v1,"Facial Emotion Recognition, Deep learning, Computer Vision","Emotion detection from faces is a critical machine learning problem for human-computer interaction. This study reviews various methods and selects three notable solutions and datasets for diversity and image count. Neural networks are trained and tested across different datasets to compare performance, revealing weaknesses such as dataset differences, varying difficulty in recognizing emotions, and challenges in differentiating closely related emotions. The study highlights the importance of generalization capabilities in determining state-of-the-art models, noting that performance significantly drops when tested on different datasets than those used for training. Emotion recognition is vital for enhancing human-computer interactions, as non-verbal cues like facial expressions play a significant role in communication.",17.51,13.191,231,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12405v1_Explainable Machine Learning for Pediatric Dental .pdf,Explainable Machine Learning for Pediatric Dental Risk Stratification Using Socio-Demographic Determinants,"Manasi Kanade, Abhi Thakkar, Gabriela Fernandes",,,"Explainable AI, Pediatric Dental Risk, Socio-Demographic Determinants, Machine Learning, SHAP, Risk Stratification","This study aims to develop an explainable AI framework for pediatric dental risk stratification, focusing on interpretability and ethical deployment. A supervised machine learning model was trained using pediatric data, including socio-demographic factors. The model's performance was evaluated using ROC analysis and calibration curves, with SHAP used for explainability. Results showed modest discriminative performance, with age and income-to-poverty ratio as key risk factors. The framework supports population screening and equitable resource allocation, emphasizing prevention over diagnosis.",17.55,12.476,219,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12410v1_Are LLMs Smarter Than Chimpanzees An Evaluation on.pdf,Are LLMs Smarter Than Chimpanzees? An Evaluation on Perspective Taking and Knowledge State Estimation,"Dingyi Yang, Junqi Zhao, Xue Li, Ce Li, Boyang Li",,arXiv:2601.12410v1,"LLMs, chimpanzees, perspective taking, knowledge state estimation, theory of mind, cognitive anthropology","This paper evaluates the performance of Large Language Models (LLMs) in knowledge state tracking and estimation, comparing them to human abilities and chimpanzees. The study designs tasks to test if LLMs can detect implausible knowledge in story characters and predict their actions based on their knowledge versus objective truths. Results show that current LLMs perform near-randomly and are substantially inferior to humans. The paper suggests that future LLM research should focus more on knowledge estimation and intention understanding, drawing on cognitive anthropology to highlight the distinction between human and machine intelligence.",16.3,15.278,249,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12415v1_Orthogonalized Policy OptimizationDecoupling Sampl.pdf,Orthogonalized Policy Optimization: Decoupling Sampling Geometry from Optimization Geometry in RLHF,Wang Zixian,,arXiv:2601.12415v1,"Large Language Models, Policy Optimization, Reinforcement Learning, Alignment Methods, PPO, DPO, IPO, Sampling Geometry, Optimization Geometry, RLHF","Recent alignment methods for large language models, such as PPO, DPO, and IPO, are often presented as distinct algorithms. This work shows that these approaches implicitly conflate two fundamental and independent design choices: sampling geometry, which determines which samples dominate the gradient signal, and optimization geometry, which determines how deviations in value are penalized. The paper formalizes this by expressing alignment as the minimization of a generalized distance between policy energy and target energy, parameterized by an α-divergence-based sampling weight and a Bregman divergence-based value metric. It highlights that the commonly used KL divergence induces an exponential penalty on unbounded value signals, leading to numerical instability and vanishing gradients in high-confidence regimes. To address this, the paper proposes Orthogonalized Policy Optimization (OPO), a framework that decouples sampling geometry from optimization geometry. By combining α-weighted importance sampling with a χ2-induced quadratic regularization in ratio coordinates, OPO yields a simple and well-conditioned objective with linear gradient dynamics. This maintains stable optimization while preserving peak-seeking behavior and avoids gradient saturation even when model confidence is high. The analysis positions OPO as a unifying perspective on existing alignment methods and provides a principled foundation for robust reasoning-oriented training.",19.7,19.292,380,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12436v1_Purification Before Fusion Toward Mask-Free Speech.pdf,Purification Before Fusion: Toward Mask-Free Speech Enhancement for Robust Audio-Visual Speech Recognition,"Linzhi Wu, Xingyu Zhang, Hao Yuan, Yakun Zhang, Changyan Zheng, Liang Xie, Tiejun Liu, Erwei Yin",,,"audio-visual speech recognition, speech feature enhancement, noise-robust, multimodal bottleneck Conformer","Audio-visual speech recognition (AVSR) improves recognition accuracy in noisy environments by integrating noise-immune visual cues with audio signals. However, high-noise audio inputs can introduce adverse interference during feature fusion. Recent AVSR methods often use mask-based strategies to filter audio noise, risking the loss of semantically relevant information. This work proposes an end-to-end noise-robust AVSR framework with speech enhancement, eliminating the need for explicit noise mask generation. It uses a Conformer-based bottleneck fusion module to refine noisy audio features with video assistance, reducing modality redundancy and enhancing inter-modal interactions. Experimental evaluations on the LRS3 benchmark show that this method outperforms advanced mask-based baselines under noisy conditions.",17.28,16.547,286,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12442v1_Constraint-Aware Neurosymbolic Uncertainty Quantif.pdf,Constraint-Aware Neurosymbolic Uncertainty Quantification with Bayesian Deep Learning for Scientific Discovery,"Shahnawaz Alam, Mohammed Mudassir Uddin, Mohammed Kaif Pasha",,,"Neurosymbolic AI, Uncertainty Quantification, Bayesian Deep Learning, Scientific Constraints, Calibration, Physics-Informed Machine Learning","Scientific AI applications require models that deliver trustworthy uncertainty estimates while respecting domain constraints. Existing uncertainty quantification methods lack mechanisms to incorporate symbolic scientific knowledge, while neurosymbolic approaches operate deterministically without principled uncertainty modeling. This paper introduces the Constraint-Aware Neurosymbolic Uncertainty Framework (CANUF), unifying Bayesian deep learning with differentiable symbolic reasoning. The architecture comprises three components: automated constraint extraction from scientific literature, probabilistic neural backbone with variational inference, and differentiable constraint satisfaction layer ensuring physical consistency. Experiments on Materials Project, QM9 molecular properties, and climate benchmarks show CANUF reduces Expected Calibration Error by 34.7% versus Bayesian neural networks while maintaining 99.2% constraint satisfaction. Ablations reveal constraint-guided recalibration contributes 18.3% performance gain, with constraint extraction achieving 91.4% precision. CANUF provides the first end-to-end differentiable pipeline simultaneously addressing uncertainty quantification, constraint satisfaction, and interpretable explanations for scientific predictions.",18.63,17.55,327,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12443v1_Adversarial Defense in Vision-Language Models An O.pdf,Adversarial Defense in Vision-Language Models: An Overview,"Xiaowei Fu, Lei Zhang",,,"VLMs, adversarial defense, survey","The widespread use of Vision Language Models (VLMs), such as CLIP, has raised concerns about their vulnerability to sophisticated and imperceptible adversarial attacks, which could compromise model performance and system security in cross-modal tasks. To address this challenge, three main defense paradigms have been proposed: Training-time Defense, Test-time Adaptation Defense, and Training-free Defense. Training-time Defense involves modifying the training process, typically through adversarial fine-tuning to improve robustness to adversarial examples. Test-time Adaptation Defense focuses on adapting the model at inference time by updating its parameters to handle unlabeled adversarial examples. Training-free Defense avoids modifying the model itself, instead focusing on altering the adversarial inputs or their feature embeddings. This survey reviews the latest advancements in adversarial defense strategies for VLMs, highlighting the strengths and limitations of such approaches and discussing ongoing challenges in enhancing the robustness of VLMs.",17.29,15.438,267,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12444v1_Large Language Model for OWL Proofs.pdf,Large Language Model for OWL Proofs,"Hui Yang, Jiaoyan Chen, Uli Sattler",https://doi.org/10.1145/XXXXXX.XXXXXX,,"Computing methodologies, Description logics, Natural language generation","The ability of Large Language Models (LLMs) to perform reasoning tasks such as deduction has been widely investigated in recent years. Yet, their capacity to generate proofs—faithful, human-readable explanations of why conclusions follow—remains largely underexplored. This work studies proof generation in the context of OWL ontologies by developing an automated dataset construction and evaluation framework. The evaluation encompasses three sequential tasks for complete proving: Extraction, Simplification, and Explanation, as well as an additional task of assessing Logic Completeness of the premise. Through extensive experiments on widely used reasoning LLMs, important findings include: (1) Some models achieve overall strong results but remain limited on complex cases; (2) Logical complexity, rather than representation format (formal logic language versus natural language), is the dominant factor shaping LLM performance; and (3) Noise and incompleteness in input data substantially diminish LLMs’ performance. These results underscore both the promise of LLMs for explanation with rigorous logics and the gap of supporting resilient reasoning under complex or imperfect conditions.",17.66,18.007,318,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12449v1_AgenTRIM Tool Risk Mitigation for Agentic AI.pdf,AGENTRIM: Tool Risk Mitigation for Agentic AI,"Roy Betser, Shamik Bose, Amit Giloni, Chiara Picardi, Sindhu Padakandla, Roman Vainshtein",,,"AI agents, LLMs, tool permissions, security risks, tool-driven agency, AGENTRIM, framework, least-privilege tool access, AgentDojo benchmark, safety policies","AI agents are autonomous systems that combine large language models (LLMs) with external tools to solve complex tasks. However, improper tool permissions can introduce security risks such as indirect prompt injection and tool misuse. This paper introduces AGENTRIM, a framework designed to detect and mitigate tool-driven agency risks without altering an agent's internal reasoning. AGENTRIM operates in offline and online phases, reconstructing and verifying the agent's tool interface from code and execution traces, and enforcing least-privilege tool access at runtime. Evaluations on the AgentDojo benchmark demonstrate that AGENTRIM significantly reduces attack success while maintaining high task performance. The framework also shows robustness to description-based attacks and effectively enforces explicit safety policies, providing a practical approach to safer tool use in LLM-based agents.",17.66,17.838,315,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12465v1_Incentivizing In-depth Reasoning over Long Context.pdf,INCENTIVIZING IN-DEPTH REASONING OVER LONG CONTEXTS WITH PROCESS ADVANTAGE SHAPING,"Miao Peng, Weizhou Shen, Nuo Chen, Chenliang Li, Ming Yan, Jia Li",,,"Reinforcement Learning, Long-context reasoning, Knowledge Graphs, Deep Learning, Large Language Models","Reinforcement Learning with Verifiable Rewards (RLVR) enhances short-context reasoning in LLMs but struggles with long-context scenarios requiring precise grounding and robust reasoning. The 'almost-there' phenomenon, where trajectories are mostly correct but fail at the final step, is attributed to insufficient reasoning density in data and loss of learning signals from partially correct trajectories. The proposed DEEPREASONQA framework synthesizes high-difficulty, multi-hop QA pairs with reasoning chains, and LONGPAS method assigns credit by evaluating reasoning steps for validity and relevance. Experiments show substantial performance improvements over RLVR baselines and competitive results with LLMs using fewer parameters, confirming the methods' effectiveness in enhancing long-context reasoning and stable RL training.",16.99,16.366,278,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12467v1_Patch-Level Tokenization with CNN Encoders and Att.pdf,Patch-Level Tokenization with CNN Encoders and Attention for Improved Transformer Time-Series Forecasting,Saurish Nagrath,,,"Multivariate time-series forecasting, financial time-series forecasting, Transformer models, temporal tokenization, convolutional neural networks, attention mechanisms, representation learning, deep learning for finance","Transformer-based models have shown strong performance in time-series forecasting by leveraging self-attention to model long-range temporal dependencies. However, their effectiveness depends critically on the quality and structure of input representations derived from raw multivariate time-series data. This work proposes a two-stage forecasting framework that explicitly separates local temporal representation learning from global dependency modeling. In the first stage, a convolutional neural network (CNN) operates on fixed-length temporal patches to extract short-range temporal dynamics and non-linear feature interactions, producing compact patch-level token embeddings. Token-level self-attention is subsequently applied during representation learning to refine these embeddings by enabling interactions across temporal patches. In the second stage, a Transformer encoder processes the resulting token sequence to model inter-patch temporal dependencies and generate per-patch forecasts. Experiments conducted on synthetic multivariate time-series data with controlled static and dynamic factors demonstrate that the proposed patch-based tokenization strategy achieves competitive forecasting performance compared to convolutional and patch-based Transformer baselines. The results highlight the importance of structured temporal representations and show that decoupling local temporal encoding from global attention-based modeling yields more effective and stable time-series forecasting.",18.81,17.967,338,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12471v1_Knowing When to Abstain Medical LLMs Under Clinica.pdf,Knowing When to Abstain: Medical LLMs Under Clinical Uncertainty,"Sravanthi Machcha, Sushrita Yerra, Sahil Gupta, Aishwarya Sahoo, Sharmin Sultana, Hong Yu, Zonghai Yao",,,"large language models, medical multiple-choice question answering, abstention, conformal prediction, adversarial question perturbations, uncertainty, reliability, high-stakes applications","Current evaluation of large language models (LLMs) prioritizes accuracy, but in real-world and safety-critical applications, the ability to abstain when uncertain is equally vital for trustworthy deployment. This paper introduces MedAbstain, a benchmark and evaluation protocol for abstention in medical multiple-choice question answering (MCQA), integrating conformal prediction, adversarial question perturbations, and explicit abstention options. The evaluation reveals that even high-accuracy models often fail to abstain when uncertain. Providing explicit abstention options increases model uncertainty and safer abstention more effectively than input perturbations, while scaling model size or advanced prompting brings little improvement. These findings highlight the importance of abstention mechanisms for trustworthy LLM deployment and offer practical guidance for improving safety in high-stakes applications.",17.33,18.411,319,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12494v1_Harmonizing the Arabic Audio Space with Data Sched.pdf,Harmonizing the Arabic Audio Space with Data Scheduling,"Hunzalah Hassan Bhatti, Firoj Alam, Shammur Absar Chowdhury",,,"Arabic Audio Space, Data Scheduling, Audio Large Language Models, Instruction Tuning, Multi-task Learning, Speech Recognition, Speech Summarization, Dialect Identification, Emotion Recognition, AraMega-SSum Dataset, Task-Progressive Curriculum, Aligner-Based Diverse Sampling, Gradient Volatility, Negative Transfer, Omni-models, Low-resource Multimodal Environments","This paper presents a systematic study of multi-task instruction tuning for an Arabic-centric audio large language model (LLM), addressing the adaptation to linguistically complex, dialect-rich settings. The study introduces AraMega-SSum, a novel dataset for Arabic speech summarization, and evaluates the fine-tuning of Qwen2.5-Omni (7B) using Task-Progressive Curriculum (TPC) and Aligner-Based Diverse Sampling (ADS). The results highlight a trade-off between efficiency and robustness, with ADS accelerating convergence but causing gradient volatility, and TPC stabilizing core acoustic mapping but inducing negative transfer. A Hybrid TPC+ADS Strategy is proposed as an optimal training approach, providing a robust foundation and diversity-aware refinement for efficient adaptation in complex, low-resource environments.",18.05,19.45,351,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12499v1_Failure Modes in Multi-Hop QA The Weakest Link Law.pdf,Failure Modes in Multi-Hop QA: The Weakest Link Law and the Recognition Bottleneck,"Meiru Zhang, Zaiqiao Meng, Nigel Collier",,,"Multi-Hop QA, Large Language Models, position bias, Multi-Focus Attention Instruction, Weakest Link Law, recognition failure, synthesis failure, System-2 reasoning","Despite scaling to massive context windows, Large Language Models (LLMs) struggle with multi-hop reasoning due to inherent position bias, which causes them to overlook information at certain positions. The study introduces Multi-Focus Attention Instruction (MFAI) to disentangle recognition and synthesis failures by steering attention towards selected positions. Across 5 LLMs on two multi-hop QA tasks, the 'Weakest Link Law' is established: multi-hop reasoning performance collapses to the level of the least visible evidence, governed by absolute position rather than linear distance between facts. MFAI resolves recognition bottlenecks, improving accuracy in low-visibility positions, while misleading MFAI triggers confusion in real-world tasks but is filtered in synthetic tasks. 'Thinking' models utilizing System-2 reasoning effectively locate and integrate required information, matching gold-only baselines even in noisy, long-context settings.",17.55,17.431,306,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12518v1_Cooperative Multi-agent RL with Communication Cons.pdf,Cooperative Multi-agent RL with Communication constraints,"Nuoya Xiong, Aarti Singh",,,"Cooperative Multi-agent RL, Communication constraints, Importance sampling, Base policy prediction, MARL, Decentralized systems, Nash equilibrium, Potential games, Markov Cooperative Games","Cooperative Multi-agent reinforcement learning (MARL) often assumes frequent access to global information, which is unrealistic in decentralized systems due to high communication costs. This paper proposes a technique called base policy prediction to address the instability caused by limited communication. By predicting policy updates and collecting samples for a sequence of base policies, the approach reduces the gap between the base and current policies, enabling effective learning with fewer communication rounds. The algorithm converges to an ε-Nash equilibrium in potential games with significantly reduced communication rounds and sample complexity. Empirical tests in simulated games and MAPPO for complex environments show that the algorithm reduces communication costs while maintaining performance. Standard algorithms fail under similar communication constraints.",16.5,14.18,234,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12522v1_Improved Bug Localization with AI Agents Leveragin.pdf,Improved Bug Localization with AI Agents Leveraging Hypothesis and Dynamic Cognition,"Asif Mohammed Samir, Mohammad Masudur Rahman",https://doi.org/XXXXXXX.XXXXXXX,,"Bug Localization, LLM, Agentic AI, Cognition, Debugging, Software Engineering, Information Retrieval","Software bugs cost technology providers billions annually and cause developers to spend roughly 50% of their time on bug resolution. Traditional methods for bug localization often analyze the suspiciousness of code components in isolation, overlooking their connections with other components in the codebase. Recent advances in Large Language Models (LLMs) and agentic AI techniques have shown strong potential for code understanding, but still lack causal reasoning during code exploration and struggle to manage growing context effectively, limiting their capability. In this paper, we present a novel agentic technique for bug localization –CogniGent– that overcomes the limitations above by leveraging multiple AI agents capable of causal reasoning, call-graph-based root cause analysis and context engineering. It emulates developers-inspired debugging practices (a.k.a., dynamic cognitive debugging) and conducts hypothesis testing to support bug localization. We evaluate CogniGent on a curated dataset of 591 bug reports using three widely adopted performance metrics and compare it against six established baselines from the literature. Experimental results show that our technique consistently outperformed existing traditional and LLM-based techniques, achieving MAP improvements of 23.33-38.57% at the document and method levels. Similar gains were observed in MRR, with increases of 25.14-53.74% at both granularity levels. Statistical significance tests also confirm the superiority of our technique. By addressing the reasoning, dependency, and context limitations, CogniGent advances the state of bug localization, bridging human-like cognition with agentic automation for improved performance.",19.3,22.178,428,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12534v1_Encoding Emotion Through Self-Supervised Eye Movem.pdf,ENCODING EMOTION THROUGH SELF-SUPERVISED EYE MOVEMENT RECONSTRUCTION,"Marcus Ma, Jordan Prescott, Emily Zhou, Tiantian Feng, Kleanthis Avramidis, Gabor Mihaly Toth, Shrikanth Narayanan",,,"eye movement, self-supervised learning, emotion prediction, deep learning","The relationship between emotional expression and eye movement is well-documented, with gaze patterns being reliable indicators of emotion. However, most studies use specialized, high-resolution eye-tracking equipment, limiting the reach of findings. This study investigates predicting multimodal markers of emotional expression from naturalistic, low-resolution videos. Using video interviews from the USC Shoah Foundation’s Visual History Archive, a novel gaze detection model is developed using self-supervised eye movement reconstruction. The model's encoder embeddings are fine-tuned for tasks related to emotional expression, such as aligning eye movement with directional emotion estimates from speech and predicting emotional behaviors like laughing, crying/sobbing, and sighing. The model shows predictive capability for emotion outcomes, with a positive correlation between pretraining and emotion processing performance. The study concludes that self-supervised eye movement reconstruction effectively encodes the affective signals in eye movements.",17.93,16.95,304,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12535v1_Improving Low-Resource Machine Translation via Rou.pdf,Improving Low-Resource Machine Translation via Round-Trip Reinforcement Learning,"Ahmed Attia, Alham Fikri",,,"low-resource machine translation, reinforcement learning, round-trip bootstrapping, NLLB models, BLEU, chrF++","This paper explores a self-supervised reinforcement-learning-based fine-tuning approach for low-resource machine translation using round-trip bootstrapping with the No Language Left Behind (NLLB) models. The method translates English into a low-resource language and back into English, optimizing the process with BLEU and chrF++ as reward functions. Evaluations on the NLLB-MD dataset show improvements for languages like Central Aymara, Friulian, Wolof, and Russian, with increased fluency and semantic fidelity. The approach addresses limitations of standard machine translation training, such as exposure bias and objective mismatch, by operating without parallel corpora.",15.72,13.869,218,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12538v1_Agentic Reasoning for Large Language Models.pdf,Agentic Reasoning for Large Language Models,"Tianxin Wei, Ting-Wei Li, Zhining Liu, Xuying Ning, Ze Yang, Jiaru Zou, Zhichen Zeng, Ruzhong Qiu, Xiao Lin, Dongqi Fu, Zihao Li, Mengting Ai, Duo Zhou, Wenxuan Bao, Yunzhe Li, Gaotang Li, Cheng Qian, Yu Wang, Xiangru Tang, Yin Xiao, Liri Fang, Hui Liu, Xianfeng Tang, Yuji Zhang, Chi Wang, Jiaxuan You, Heng Ji, Hanghang Tong, Jingrui He",,arXiv:2601.12538v1,"Agentic AI, LLM Agent, Agentic Reasoning, Self-evolving","Reasoning is a fundamental cognitive process underlying inference, problem-solving, and decision-making. While large language models (LLMs) demonstrate strong reasoning capabilities in closed-world settings, exemplified by standard benchmarks in mathematics and code, they struggle in open-ended and dynamic environments. The emergence of agentic reasoning marks a paradigm shift, bridging thought and action by reframing LLMs as autonomous agents that plan, act, and learn through continual interaction. In this survey, we provide a systematic roadmap by organizing agentic reasoning along three complementary dimensions. First, we characterize environmental dynamics through three layers: foundational agentic reasoning establishes core single-agent capabilities, including planning, tool use, and search, that operate in stable environments; self-evolving agentic reasoning examines how agents refine these capabilities through feedback, memory, and adaptation in evolving settings; and collective multi-agent reasoning extends intelligence to collaborative scenarios where multiple agents coordinate roles, share knowledge, and pursue shared goals. Across all layers, we analyze system constraints and optimization settings by distinguishing in-context reasoning, which scales test-time interaction through structured orchestration and adaptive workflow design, from post-training reasoning, which optimizes behaviors through reinforcement learning and supervised fine-tuning. We further review and contextualize agentic reasoning frameworks in real-world applications and benchmarks spanning science, robotics, healthcare, autonomous research, and math, illustrating how different reasoning mechanisms are instantiated and evaluated across domains. This survey synthesizes agentic reasoning methods into a unified roadmap that bridges thoughts and actions, offering actionable guidance for agentic systems across environmental dynamics, optimization settings, and agent interaction settings. Finally, we outline open challenges and future directions, situating how agentic reasoning has developed while identifying what remains ahead: personalization, long-horizon interaction, world modeling, scalable multi-agent training, and governance frameworks for real-world deployment.",21.27,30.471,648,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12539v1_MemeLens Multilingual Multitask VLMs for Memes.pdf,MemeLens: Multilingual Multitask VLMs for Memes,"Ali Ezzat Shahroor, Mohamed Bayan Kmainasi, Abul Hasnat, Dimitar Dimitrov, Giovanni Da San Martino, Preslav Nakov, Firoj Alam",,,"memes, multilingual, multitask, vision language models, meme understanding, multimodal training, cross-domain generalization","Memes are a dominant medium for online communication and manipulation, with meaning emerging from interactions between embedded text, imagery, and cultural context. Existing meme research is distributed across tasks and languages, limiting cross-domain generalization. This paper proposes MEMELENS, a unified multilingual and multitask explanation-enhanced Vision Language Model (VLM) for meme understanding. It consolidates 38 public meme datasets, mapping dataset-specific labels into a shared taxonomy of 20 tasks. The paper presents an empirical analysis across modeling paradigms, task categories, and datasets, suggesting that robust meme understanding requires multimodal training and is sensitive to over-specialization. The experimental resources and datasets will be made publicly available.",16.86,17.492,295,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12542v1_Rethinking the AI Scientist Interactive Multi-Agen.pdf,Rethinking the AI Scientist: Interactive Multi-Agent Workflows for Scientific Discovery,"Lukas Weidener, Marko Brkić, Mihailo Jovanović, Ritvik Singh, Chiara Baccin, Emre Ulgac, Alex Dobrin, Aakaash Meduri",,,"Artificial Intelligence, Scientific Discovery, Multi-Agent Systems, Interactive Workflows, Computational Biology, Novelty Detection, Research Workflows","This paper introduces Deep Research, a multi-agent system enabling interactive scientific investigation with rapid turnaround times. The system comprises specialized agents for planning, data analysis, literature search, and novelty detection, unified through a persistent world state. It supports semi-autonomous and fully autonomous operational modes. Evaluation on the BixBench computational biology benchmark demonstrated state-of-the-art performance, achieving 48.8% accuracy on open response and 64.5% on multiple-choice evaluation, exceeding existing baselines by 14 to 26 percentage points. The paper also discusses architectural constraints and practical deployment considerations for AI-assisted scientific workflows.",16.7,17.065,285,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12547v1_How Clinicians Think and What AI Can Learn From It.pdf,"Ordinal-First, Robust Decision Algorithms for Medicine","Dr. Dipayan Sengupta, MD (Dermatology), Dr. Saumya Panda, MD (Dermatology)",,arXiv:2601.12547v1,"clinical artificial intelligence, decision-making, ordinal non-compensatory algorithms, robust decision algorithms, medicine, lexicographic heuristics, ϵ-dominance, maximin, minimax regret","Most clinical AI systems are built as prediction engines, yet real clinical reasoning involves sequential decision-making under uncertainty. Clinicians often use ordinal non-compensatory decision-making, relying on fast-and-frugal heuristics. This paper argues that such algorithms are epistemically preferred in medicine due to weakly measurable clinical trade-offs and the crude nature of preference and signal elicitation. It outlines a clinician-aligned AI blueprint that emphasizes robust ordinal decision rules and selective complexity for decision-making.",16.52,15.012,248,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12549v1_Benchmarking Concept-Spilling Across Languages in .pdf,Benchmarking Concept-Spilling Across Languages in LLMs,"Ilia Badanin, Daniil Dzenhaliou, Imanol Schlag",,arXiv:2601.12549v1,"multilingual large language models, semantic robustness, language spilling, polysemous words, semantic interference, cross-lingual abilities","Multilingual Large Language Models (LLMs) exhibit remarkable cross-lingual abilities, yet often show a bias toward English representations, leading to semantic interference in non-English content generation—a phenomenon defined as language spilling. This paper introduces a comparative framework for evaluating multilingual semantic robustness by measuring how models handle polysemous words across languages. The methodology assesses model performance by observing when models resort to dominant-language meanings during generation. The study evaluates various multilingual LLMs using a structured meaning generation task across nine languages with a benchmark of 100 high-polysemy English words. Findings reveal significant variation in semantic robustness across models and languages, providing a ranking system for model comparison. The paper contributes a scalable benchmark for multilingual semantic evaluation and a validation pipeline, essential for developing more linguistically balanced AI systems.",18.46,15.981,295,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12554v1_Artificial Intelligence in Materials Science and E.pdf,"Artificial Intelligence in Materials Science and Engineering: Current Landscape, Key Challenges, and Future Trajectories","Iman Peivaste, Salim Belouettar, Francesco Mercuri, Nicholas Fantuzzi, Hamidreza Dehghani, Razieh Izadi, Halliru Ibrahim, Jakub Lengiewicz, Maël Belouettar-Mathis, Kouider Bendine, Ahmed Makradi, Martin Hörsch, Peter Klein, Mohamed El Hachemi, Heinz A. Preisig, Yacine Rezgui, Natalia Konchakova, Ali Daouadji",,2601.12554v1,"Artificial Intelligence, Materials Science, Machine Learning, Deep Learning, Generative AI, Probabilistic Models, Data Representation, Featurization, Uncertainty Quantification","Artificial Intelligence is rapidly transforming materials science and engineering, offering powerful tools to navigate complexity, accelerate discovery, and optimize material design in ways previously unattainable. Driven by the accelerating pace of algorithmic advancements and increasing data availability, AI is becoming an essential competency for materials researchers. This review provides a comprehensive and structured overview of the current landscape, synthesizing recent advancements and methodologies for materials scientists seeking to effectively leverage these data-driven techniques. It surveys the spectrum of machine learning approaches, from traditional algorithms to advanced deep learning architectures, including CNNs, GNNs, and Transformers, alongside emerging generative AI and probabilistic models such as Gaussian Processes for uncertainty quantification. The review also examines the pivotal role of data in this field, emphasizing how effective representation and featurization strategies, spanning compositional, structural, image-based, and language-inspired approaches, combined with appropriate preprocessing, fundamentally underpin the performance of machine learning models.",19.91,23.058,459,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12557v1_Life Machine Learning and the Search for Habitabil.pdf,"Life, Machine Learning, and the Search for Habitability: Predicting Biosignature Fluxes for the Habitable Worlds Observatory","Mark Moussa, Amber V. Young, Brianna Isola, Vasuda Trehan, Michael D. Himes, Nicholas Wogan, Giada Arney",,,"machine learning, biosignature, exoplanets, direct-imaging, Habitable Worlds Observatory, Bayesian Convolutional Neural Network, Spectral Query Adaptive Transformer","Future direct-imaging flagship missions, such as NASA’s Habitable Worlds Observatory (HWO), face critical decisions in prioritizing observations due to extremely stringent time and resource constraints. This paper introduces two advanced machine-learning architectures for predicting biosignature species fluxes from exoplanetary reflected-light spectra: a Bayesian Convolutional Neural Network (BCNN) and a novel model architecture, the Spectral Query Adaptive Transformer (SQuAT). The BCNN robustly quantifies both epistemic and aleatoric uncertainties, offering reliable predictions under diverse observational conditions, while SQuAT employs query-driven attention mechanisms to enhance interpretability by explicitly associating spectral features with specific biosignature species. Both models achieve high predictive accuracy on an augmented dataset spanning a wide range of exoplanetary conditions, highlighting their distinct advantages in uncertainty quantification and spectral interpretability. These capabilities position the methods as promising tools for accelerating target triage, optimizing observation schedules, and maximizing scientific return for upcoming flagship missions such as HWO.",18.67,19.657,367,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12560v1_Agentic Artificial Intelligence AI Architectures T.pdf,"Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents","Arunkumar V, Gangadharan G.R., Rajkumar Buyya",,arXiv:2601.12560v1,"Agentic AI, Large Language Models, Autonomous Agents, Multi-Agent Systems, Cognitive Architectures, Tool Use, Planning","Artificial Intelligence is transitioning from models that generate text to Agentic AI, where systems act as autonomous entities capable of perception, reasoning, planning, and action. Large Language Models (LLMs) are evolving from passive knowledge engines to cognitive controllers that integrate memory, tool use, and environmental feedback to achieve extended goals. This shift facilitates the automation of complex workflows in areas like software engineering, scientific discovery, and web navigation. The paper explores various architectures and proposes a unified taxonomy categorizing agents into Perception, Brain, Planning, Action, Tool Use, and Collaboration. It discusses the evolution from linear reasoning to native inference time reasoning models and from fixed API calls to open standards like the Model Context Protocol (MCP) and Native Computer Use. The paper also reviews the environments where these agents operate, such as digital operating systems and embodied robotics, and examines current evaluation practices. It highlights challenges like hallucination in action, infinite loops, and prompt injection, and outlines future research directions for developing robust and reliable autonomous systems.",19.23,17.632,339,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12577v1_Primate-like perceptual decision making emerges th.pdf,Primate-like perceptual decision making emerges through deep recurrent reinforcement learning,"Nathan J. Wispinski, Scott A. Stone, Anthony Singhal, Patrick M. Pilarski, Craig S. Chapman",,2601.12577v1,"decision making, primate, reinforcement learning, neural mechanisms, evidence accumulation, deep recurrent neural network","This study explores the emergence of primate-like decision-making mechanisms through deep recurrent reinforcement learning. The research tests the theory that such mechanisms evolved to maximize reward in noisy, temporally evolving environments. An end-to-end deep recurrent neural network was trained on a noisy perceptual discrimination task, learning key abilities of primate decision-making, such as trading off speed for accuracy and changing decisions based on new information. The internal dynamics of these networks suggest similarities with primate neurophysiological decision mechanisms, supporting the theory of evolutionary pressures leading to flexible decision-making abilities in primates.",16.86,14.712,248,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12582v1_Ontology-aligned structuring and reuse of multimod.pdf,Ontology-aligned structuring and reuse of multimodal materials data and workflows towards automatic reproduction,"Sepideh Baghaee Ravari, Abril Azocar Guzman, Sarath Menon, Stefan Sandfeld, Tilmann Hickel, Markus Stricker",,,"text mining, workflow, large language models, stacking fault energy","Reproducibility of computational results remains a challenge in materials science, as simulation workflows and parameters are often reported only in unstructured text and tables. An ontology-driven, large language model (LLM)-assisted framework is introduced for the automated extraction and structuring of computational workflows from the literature. The approach focuses on density functional theory-based stacking fault energy (SFE) calculations in hexagonal close-packed magnesium and its binary alloys. Extracted information is unified into a canonical schema and aligned with established materials ontologies (CMSO, ASMO, and PLDO), enabling the construction of a knowledge graph using atomRDF. The resulting knowledge graph enables systematic comparison of reported SFE values and supports the structured reuse of computational protocols. While full computational reproducibility is still constrained by missing or implicit metadata, the framework provides a foundation for organizing and contextualizing published results in a semantically interoperable form, thereby improving transparency and reusability of computational materials data.",18.56,17.458,324,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12585v1_Do MLLMs See What We See Analyzing Visualization L.pdf,Do MLLMs See What We See? Analyzing Visualization Literacy Barriers in AI Systems,"Mengli (Dawn) Duan, Yuhe (Sissi) Jiang, Matthew Varona, Carolina Nobre",xx.xxxx/TVCG.201x,,"Visualization Literacy, Multimodal Large Language Model, Evaluation Study","Multimodal Large Language Models (MLLMs) are increasingly used to interpret visualizations, yet little is known about why they fail. This study presents the first systematic analysis of barriers to visualization literacy in MLLMs. Using the regenerated Visualization Literacy Assessment Test (reVLAT) benchmark with synthetic data, the study open-coded 309 erroneous responses from four state-of-the-art models with a barrier-centric strategy adapted from human visualization literacy research. The analysis yields a taxonomy of MLLM failures, revealing two machine-specific barriers that extend prior human-participation frameworks. Results show that models perform well on simple charts but struggle with color-intensive, segment-based visualizations, often failing to form consistent comparative reasoning. These findings inform future evaluation and design of reliable AI-driven visualization assistants.",17.52,15.98,280,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12594v1_SLAP Scalable Language-Audio Pretraining with Vari.pdf,SLAP: SCALABLE LANGUAGE-AUDIO PRETRAINING WITH VARIABLE-DURATION AUDIO AND MULTI-OBJECTIVE TRAINING,"Xinhao Mei, Gael Le Lan, Haohe Liu, Zhaoheng Ni, V arun Nagaraja, Yang Liu, Yangyang Shi, Vikas Chandra",,,"Multimodal learning, CLAP, self-supervised learning, contrastive learning, multi-objective learning","Contrastive language-audio pretraining (CLAP) has achieved notable success in learning semantically rich audio representations and is widely adopted for various audio-related tasks. However, current CLAP models face several key limitations, including training on relatively small datasets, restriction to short and fixed-duration audio, and reliance on global representations. To address these challenges, we introduce Scalable Language-Audio Pretraining (SLAP), which scales language-audio pretraining to 109 million audio-text pairs with variable audio durations and incorporates multiple training objectives. SLAP unifies contrastive loss with additional self-supervised and captioning losses in a single-stage training, facilitating the learning of richer dense audio representations. The proposed SLAP model achieves new state-of-the-art performance on audio-text retrieval and zero-shot audio classification tasks, demonstrating its effectiveness across diverse benchmarks.",18.17,17.558,319,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12607v1_A Cloud-based Multi-Agentic Workflow for Science.pdf,A Cloud-based Multi-Agentic Workflow for Science,"Anurag Acharya, Timothy Vega, Rizwan A. Ashraf, Anshu Sharma, Derek Parker, Robert Rallo",10.1145/nnnnnnn.nnnnnnn,,"Large Language Models, LLMs for Science, LLM Agents, Multi-agent Framework, Catalysis, Chemistry, Material Science, Cloud Computing","As Large Language Models (LLMs) become ubiquitous across various scientific domains, their lack of ability to perform complex tasks like running simulations or to make complex decisions limits their utility. LLM-based agents bridge this gap due to their ability to call external resources and tools and thus are now rapidly gaining popularity. However, coming up with a workflow that can balance the models, cloud providers, and external resources is very challenging, making implementing an agentic system more of a hindrance than a help. In this work, we present a domain-agnostic, model-independent workflow for an agentic framework that can act as a scientific assistant while being run entirely on cloud. Built with a supervisor agent marshaling an array of agents with individual capabilities, our framework brings together straightforward tasks like literature review and data analysis with more complex ones like simulation runs. We describe the framework here in full, including a proof-of-concept system we built to accelerate the study of Catalysts, which is highly important in the field of Chemistry and Material Science. We report the cost to operate and use this framework, including the breakdown of the cost by services use. We also evaluate our system on a custom-curated synthetic benchmark and a popular Chemistry benchmark, and also perform expert validation of the system. The results show that our system is able to route the task to the correct agent 90% of the time and successfully complete the assigned task 97.5% of the time for the synthetic tasks and 91% of the time for real-world tasks, while still achieving better or comparable accuracy to most frontier models, showing that this is a viable framework for other scientific domains to replicate.",19.98,24.13,482,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12617v1_Creating Disability Story Videos with Generative A.pdf,"Creating Disability Story Videos with Generative AI: Motivation, Expression, and Sharing","Shuo Niu, Dylan Clements, Hyungsin Kim",10.1145/3772318.3791495,,"Disability, Storytelling, Video, Generative AI, LLM","Generative AI (GenAI) is both promising and challenging in supporting people with disabilities (PwDs) in creating stories about disability. GenAI can reduce barriers to media production and inspire the creativity of PwDs, but it may also introduce biases and imperfections that hinder its adoption for personal expression. This research examines how nine PwDs from a disability advocacy group used GenAI to create videos sharing their disability experiences. Grounded in digital storytelling theory, the study explores the motivations, expression, and sharing of PwD-created GenAI story videos. A framework of momentous depiction is presented, highlighting four core affordances of GenAI that either facilitate or require improvements to better support disability storytelling: non-capturable depiction, identity concealment and representation, contextual realism and consistency, and emotional articulation. The framework further discusses design implications for GenAI in relation to story completion, media formats, and corrective mechanisms.",17.26,17.436,301,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12637v1_Topology-Aware Multiscale Mixture of Experts for E.pdf,Topology-Aware Multiscale Mixture of Experts for Efficient Molecular Property Prediction,"Long D. Nguyen, Kelin Xia, Binh P. Nguyen",,arXiv:2601.12637v1,"Graph Neural Networks, Topological Deep Learning, Mixture of Experts, Molecular Representation","Many molecular properties depend on 3D geometry, where non-covalent interactions, stereochemical effects, and medium- to long-range forces are determined by spatial distances and angles that cannot be uniquely captured by a 2D bond graph. Most 3D molecular graph neural networks rely on globally fixed neighborhood heuristics, typically defined by distance cutoffs and maximum neighbor limits, to define local message-passing neighborhoods, leading to rigid, data-agnostic interaction budgets. This paper proposes Multiscale Interaction Mixture of Experts (MI-MoE) to adapt interaction modeling across geometric regimes. The contributions include: (1) a distance-cutoff expert ensemble that explicitly captures short-, mid-, and long-range interactions without committing to a single cutoff; (2) a topological gating encoder that routes inputs to experts using filtration-based descriptors, including persistent homology features, summarizing how connectivity evolves across radii; and (3) demonstrating that MI-MoE is a plug-in module that consistently improves multiple strong 3D molecular backbones across diverse molecular and polymer property prediction benchmark datasets, covering both regression and classification tasks. These results highlight topology-aware multiscale routing as an effective principle for 3D molecular graph learning.",18.77,19.125,359,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12638v1_Mixed Precision PointPillars for Efficient 3D Obje.pdf,Mixed Precision PointPillars for Efficient 3D Object Detection with TensorRT,"Ninnart Fuengfusin, Keisuke Yoneda, Naoki Suganuma",,,"neural networks, quantization, 3D object detection","LIDAR 3D object detection is crucial for autonomous vehicles, requiring real-time operation. Model quantization can accelerate runtime but often leads to performance degradation due to LIDAR's wide numerical distributions and extreme outliers. This paper proposes a mixed precision framework for PointPillars, identifying sensitive layers through post-training quantization (PTQ) and assigning them as floating point (FP). Candidate mixed precision models are produced and finalized with PTQ or quantization-aware training (QAT). To handle outliers, a small calibration dataset is used to improve PTQ performance. The proposed methods provide mixed precision models without training in the PTQ pipeline, while the QAT pipeline achieves performance competitive to FP models. With TensorRT deployment, the models offer reduced latency and size by up to 2.35 and 2.26 times, respectively.",16.94,15.936,270,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12641v1_STEP-LLM Generating CAD STEP Models from Natural L.pdf,STEP-LLM: Generating CAD STEP Models from Natural Language with Large Language Models,"Xiangyu Shi, Junyang Ding, Xu Zhao, Sinong Zhan, Payal Mohapatra, Daniel Quispe, Kojo Welbeck, Jian Cao, Wei Chen, Ping Guo, Qi Zhu",,2601.12641v1,"Computer-aided design, STEP file, large language models, design automation","Computer-aided design (CAD) is vital to modern manufacturing, yet model creation remains labor-intensive and expertise-heavy. To enable non-experts to translate intuitive design intent into manufacturable artifacts, recent large language models (LLM)-based text-to-CAD efforts focus on command sequences or script-based formats like CadQuery. However, these formats are kernel-dependent and lack universality for manufacturing. In contrast, the Standard for the Exchange of Product Data (STEP, ISO 10303) file is a widely adopted, neutral boundary representation (B-rep) format directly compatible with manufacturing, but its graph-structured, cross-referenced nature poses unique challenges for auto-regressive LLMs. To address this, we curate a dataset of ~40K STEP-caption pairs and introduce novel preprocessing tailored for the graph-structured format of STEP, including a depth-first search (DFS)-based reserialization that linearizes cross-references while preserving locality and chain-of-thought (CoT)-style structural annotations that explicitly guide global coherence. We integrate retrieval-augmented generation (RAG) to ground predictions in relevant examples for supervised fine-tuning (SFT), and further refine generation quality through reinforcement learning (RL) with a specific Chamfer Distance-based geometric reward. Experiments demonstrate consistent gains of our STEP-LLM in geometric fidelity over the Text2CAD baseline, with improvements arising from multiple stages of our framework: the RAG module substantially enhances completeness and renderability, the DFS-based reserialization strategy strengthens overall accuracy, and the RL refinement further reduces geometric discrepancy. Both metrics and visual comparisons confirm that STEP-LLM generates shapes with higher fidelity than Text2CAD. These results demonstrate the feasibility of LLM-driven STEP model generation from natural language, showing its potential to democratize CAD design for manufacturing.",20.38,25.664,523,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12646v1_Unbounded Harms Bounded Law Liability in the Age o.pdf,"Unbounded Harms, Bounded Law: Liability in the Age of Borderless AI",Ha-Chi Tran,,arXiv:2601.12646v1,"artificial intelligence, risk governance, liability, transboundary harms, legal frameworks, compensation mechanisms, global AI governance","The rapid acceleration of artificial intelligence (AI) has exposed fundamental deficiencies in prevailing risk governance. Despite advances in harm identification and prevention, Responsible AI scholarship is underdeveloped in ex post risk governance. Core legal questions regarding compensation, mitigation, attribution of responsibility, liability allocation, and the effectiveness of remedial mechanisms remain inadequately theorized, especially for transboundary AI harms. The paper argues that such harms are structurally inherent to AI supply chains and likely to increase due to globalized deployment and cross-border data infrastructures. It examines compensation and liability mechanisms from high-risk and transnational domains to identify transferable legal design principles and outlines a global AI compensation and accountability architecture, highlighting the tension between geopolitical rivalry and collective action required for transboundary AI risk governance.",17.63,14.293,252,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12648v1_Intelligent Documentation in Medical Education Can.pdf,Intelligent Documentation in Medical Education: Can AI Replace Manual Case Logging?,"Nafiz Imtiaz Khan, MSc, Kylie Cleland, BSc, Vladimir Filkov, PhD, Roger Eric Goldman, PhD",,,"artificial intelligence, large language models, radiology, case logs, medical education","This study investigates the feasibility of using large language models (LLMs) to automate procedural case log documentation in radiology training. It evaluates whether AI can replace manual logging, identifies challenging procedure types for extraction, and assesses integration into clinical workflows. The study analyzed 414 curated radiology reports authored by nine interventional radiology residents between 2018 and 2024. Both local (Qwen-2.5) and commercial (Claude-3.5) LLMs were tested, with Qwen-2.5 achieving an F1-score of 86.66 and Claude-3.5-Haiku reaching 86.89%. Automation could save over 35 hours of manual annotation per resident annually. LLMs show promise for reducing resident clerical burden, but broader validation and real-world workflow integration are needed before clinical adoption.",17.69,16.563,293,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12654v1_Explanation Multiplicity in SHAP Characterization .pdf,Explanation Multiplicity in SHAP: Characterization and Assessment,"Hyunseung Hwang, Seungeun Lee, Lucas Rosenblatt, Julia Stoyanovich, Steven Euijong Whang",https://doi.org/XXXXXXX.XXXXXXX,,"SHAP, explanation multiplicity, post-hoc explanations, feature attribution, responsible AI, explanation stability","Post-hoc explanations are widely used to justify, contest, and review automated decisions in high-stakes domains such as lending, employment, and healthcare. SHAP is often treated as providing a reliable account of which features mattered for an individual prediction. However, SHAP explanations can differ substantially across repeated runs, even when the individual, prediction task, and trained model are held fixed. This phenomenon, termed explanation multiplicity, poses a normative challenge for responsible AI deployment. The paper presents a methodology for characterizing explanation multiplicity, disentangling sources arising from model training and selection versus stochasticity intrinsic to the explanation pipeline. It shows that explanation multiplicity is widespread and persists even under highly controlled conditions, including high-confidence predictions. The results indicate that explanation instability is a normative concern, and explanation practices must be evaluated using metrics and baselines aligned with their intended societal role.",17.83,17.668,315,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12658v1_Augmenting Question Answering with A Hybrid RAG Ap.pdf,Augmenting Question Answering with a Hybrid RAG Approach,"Tianyi Yang, Nashrah Haque, Vaishnave Jonnalagadda, Yuya Jeremy Ong, Zhehui Chen, Yanzhao Wu, Lei Yu, Divyesh Jadav, Wenqi Wei",,,"Question-answering, RAG, query processing","Retrieval-Augmented Generation (RAG) has emerged as a powerful technique for enhancing the quality of responses in Question-Answering (QA) tasks. However, existing approaches often struggle with retrieving contextually relevant information, leading to incomplete or suboptimal answers. This paper introduces Structured-Semantic RAG (SSRAG), a hybrid architecture that enhances QA quality by integrating query augmentation, agentic routing, and a structured retrieval mechanism combining vector and graph-based techniques with context unification. By refining retrieval processes and improving contextual grounding, the approach improves both answer accuracy and informativeness. Extensive evaluations on three popular QA datasets, TruthfulQA, SQuAD, and WikiQA, across five Large Language Models (LLMs), demonstrate that the proposed approach consistently improves response quality over standard RAG implementations.",17.58,17.402,306,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12661v1_MedConsultBench A Full-Cycle Fine-Grained Process-.pdf,"MedConsultBench: A Full-Cycle, Fine-Grained, Process-Aware Benchmark for Medical Consultation Agents","Chuhan Qiao, Jianghua Huang, Daxing Zhao, Ziding Liu, Yanjun Shen, Bing Cheng, Wei Lin, Kai Wu",,arXiv:2601.12661v1,"medical consultation agents, dynamic benchmarks, clinical workflow, Atomic Information Units, large language models, diagnostic accuracy, information-gathering efficiency, medication safety","Current evaluations of medical consultation agents often prioritize outcome-oriented tasks, frequently overlooking the end-to-end process integrity and clinical safety essential for real-world practice. While recent interactive benchmarks have introduced dynamic scenarios, they often remain fragmented and coarse-grained, failing to capture the structured inquiry logic and diagnostic rigor required in professional consultations. To bridge this gap, we propose MedConsultBench, a comprehensive framework designed to evaluate the complete online consultation cycle by covering the entire clinical workflow from history taking and diagnosis to treatment planning and follow-up Q&A. Our methodology introduces Atomic Information Units (AIUs) to track clinical information acquisition at a sub-turn level, enabling precise monitoring of how key facts are elicited through 22 fine-grained metrics. By addressing the underspecification and ambiguity inherent in online consultations, the benchmark evaluates uncertainty-aware yet concise inquiry while emphasizing medication regimen compatibility and the ability to handle realistic post-prescription follow-up Q&A via constraint-respecting plan revisions. Systematic evaluation of 19 large language models reveals that high diagnostic accuracy often masks significant deficiencies in information-gathering efficiency and medication safety. These results underscore a critical gap between theoretical medical knowledge and clinical practice ability, establishing MedConsultBench as a rigorous foundation for aligning medical AI with the nuanced requirements of real-world clinical care.",19.27,22.257,429,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12664v1_Generalizable Hyperparameter Optimization for Fede.pdf,Generalizable Hyperparameter Optimization for Federated Learning on Non-IID Cancer Images,"Elisa Gonçalves Ribeiro, Rodrigo Moreira, Larissa Ferreira Rodrigues Moreira, André Ricardo Backes",,,"Federated Learning, Hyperparameter Optimization, Non-IID Data, Medical Imaging, Cancer","Deep learning for cancer histopathology training conflicts with privacy constraints in clinical settings. Federated Learning (FL) mitigates this by keeping data local; however, its performance depends on hyperparameter choices under non-independent and identically distributed (non-IID) client datasets. This paper examined whether hyperparameters optimized on one cancer imaging dataset generalized across non-IID federated scenarios. We considered binary histopathology tasks for ovarian and colorectal cancers. We perform centralized Bayesian hyperparameter optimization and transfer dataset-specific optima to the non-IID FL setup. The main contribution of this study is the introduction of a simple cross-dataset aggregation heuristic by combining configurations by averaging the learning rates and considering the modal optimizers and batch sizes. This combined configuration achieves a competitive classification performance.",17.2,16.159,278,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12667v1_Empowering All-in-Loop Health Management of Spacec.pdf,Empowering All-in-Loop Health Management of Spacecraft Power System in the Mega-Constellation Era via Human-AI Collaboration,"Yi Di, Zhibin Zhao, Fujin Wang, Xue Liu, Jiafeng Tang, Jiaxin Ren, Zhi Zhai, Xuefeng Chen",,,"Large Language Model, Human-AI Collaboration, Spacecraft Power System, All-in-loop Health Management, Satellite Mega-Constellation","The paper discusses the exponential increase in spacecraft numbers, leading to the era of satellite mega-constellations (SMC). It emphasizes the importance of energy management in space, particularly the health management (HM) of spacecraft power systems (SPS) due to their critical role and high failure rates. The authors propose the AUC principle and develop SpaceHMchat, an open-source Human-AI collaboration framework for all-in-loop health management (AIL HM). SpaceHMchat covers work condition recognition, anomaly detection, fault localization, and maintenance decision-making. The framework aims to achieve conversational task completion, adaptive human-in-the-loop learning, personnel structure optimization, knowledge sharing, efficiency enhancement, and improved interpretability. A hardware-realistic fault injection experimental platform and its simulation model are established to validate the framework, demonstrating excellent performance across 23 quantitative metrics. The paper also introduces the first-ever AIL HM dataset of SPS, containing four sub-datasets with 4 types of AIL HM sub-tasks, 17 types of faults, and over 700,000 timestamps.",18.44,20.229,373,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12671v1_Exploiting Test-Time Augmentation in Federated Lea.pdf,Exploiting Test-Time Augmentation in Federated Learning for Brain Tumor MRI Classification,"Thamara Leandra de Deus Melo, Rodrigo Moreira, Larissa Ferreira Rodrigues Moreira, Andr´e R. Backes",,,"Brain tumors, Federated Learning, Test-Time Augmentation, Image classification","Efficient brain tumor diagnosis is crucial for early treatment; however, it is challenging because of lesion variability and image complexity. This study evaluates convolutional neural networks (CNNs) in a federated learning (FL) setting, comparing models trained on original versus preprocessed MRI images (resizing, grayscale conversion, normalization, filtering, and histogram equalization). Preprocessing alone yielded negligible gains; combined with test-time augmentation (TTA), it delivered consistent, statistically significant improvements in federated MRI classification (p<0.001). In practice, TTA should be the default inference strategy in FL-based medical imaging; when the computational budget permits, pairing TTA with light preprocessing provides additional reliable gains.",16.01,15.052,241,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12688v1_Logic-Guided Multistage Inference for Explainable .pdf,Logic-Guided Multistage Inference for Explainable Multidefendant Judgment Prediction,"Xu Zhang, Qinghua Wang, Mengyang Zhao, Fang Wang, Cunquan Qu",,,"Multiple defendants, Legal judgment predictions, Label broadcast, Guilt responsibility, Transformer","Crime disrupts societal stability, making law essential for balance. In multidefendant cases, assigning responsibility is complex and challenges fairness, requiring precise role differentiation. Judicial phrasing often obscures the roles of defendants, hindering effective AI-driven analyses. This work incorporates sentencing logic into a pretrained Transformer encoder framework to enhance intelligent assistance in multidefendant cases while ensuring legal interpretability. An oriented masking mechanism clarifies roles, and a comparative data construction strategy improves the model’s sensitivity to culpability distinctions between principals and accomplices. Predicted guilt labels are incorporated into a regression model through broadcasting, consolidating crime descriptions and court views. The proposed masked multistage inference (MMSI) framework, evaluated on the custom IMLJP dataset for intentional injury cases, achieves significant accuracy improvements, outperforming baselines in role-based culpability differentiation. This work offers a robust solution for enhancing intelligent judicial systems, with publicly available code.",17.73,17.144,304,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12711v1_Neurosymbolic LoRA Why and When to Tune Weights vs.pdf,Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts,"Kevin Wang, Neel P. Bhatt, Cong Liu, Junbo Li, Runjin Chen, Yihan Xi, Timothy Barclay, Alvaro Velasquez, Ufuk Topcu, Zhangyang Wang",,,"neurosymbolic AI, large language models, LoRA, symbolic manipulation, numerical fine-tuning, TextGrad, LLM adaptation","Large language models (LLMs) can be adapted either through numerical updates that alter model parameters or symbolic manipulations that work on discrete prompts or logical constraints. While numerical fine-tuning excels at injecting new factual knowledge, symbolic updates offer flexible control of style and alignment without retraining. This paper introduces a neurosymbolic LoRA framework that dynamically combines these two complementary strategies. A unified monitoring signal and a reward-based classifier are presented to decide when to employ LoRA for deeper factual reconstruction and when to apply TextGrad for token-level edits. The approach remains memory-efficient by offloading symbolic transformations to an external LLM only when needed. The refined prompts produced during symbolic editing serve as high-quality, reusable training data, beneficial in data-scarce domains like mathematical reasoning. Extensive experiments show that neurosymbolic LoRA consistently outperforms purely numerical or purely symbolic baselines, demonstrating superior adaptability and improved performance. The findings highlight the value of interleaving numerical and symbolic updates to unlock a new level of versatility in language model fine-tuning.",18.29,19.131,350,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12715v1_RSOD Reliability-Guided Sonar Image Object Detecti.pdf,RSOD: Reliability-Guided Sonar Image Object Detection with Extremely Limited Labels,"Chengzhou Li, Ping Guo, Guanchen Meng, Qi Jia, Jinyuan Liu, Zhu Liu, Xiaokang Liu, Yu Liu, Zhongxuan Luo, Xin Fan",,,"sonar image object detection, limited labels, teacher-student framework, pseudo-label strategy, reliability score, adaptive constraint, UATD dataset","Object detection in sonar images is crucial for underwater detection systems but is challenging due to noise and lack of texture details. This paper introduces RSOD, a teacher-student framework designed to effectively detect objects in sonar images with extremely limited labels. RSOD calculates a reliability score based on the teacher's prediction consistency and uses an object mixed pseudo-label method to address the shortage of labeled data. The student model is optimized with a reliability-guided adaptive constraint, allowing it to perform well even with minimal labeled data. The method achieves competitive results on the UATD dataset using only 5% of labeled data, compared to a baseline trained on 100% labeled data. A new dataset is also introduced to support further research in sonar image detection.",17.25,18.378,317,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12720v1_Teaching Large Reasoning Models Effective Reflecti.pdf,Teaching Large Reasoning Models Effective Reflection,"Hanbin Wang, Jingwei Song, Jinpeng Li, Qi Zhu, Fei Mi, Ganqu Cui, Yasheng Wang, Lifeng Shang",,,"Large Reasoning Models, Self-Critique Fine-Tuning, Reinforcement Learning, Effective Reflection, Reflection Quality, Reasoning Accuracy","Large Reasoning Models (LRMs) have shown impressive performance on complex reasoning tasks by engaging in self-reflective behaviors such as self-critique and backtracking. However, many reflections are superficial and do not improve the original answer, leading to computation overhead. This paper addresses the problem of superficial reflection in LRMs by proposing Self-Critique Fine-Tuning (SCFT) and Reinforcement Learning with Effective Reflection Rewards (RLERR). SCFT enhances the model's reflective reasoning ability using self-generated critiques, while RLERR uses high-quality reflections to guide the model in internalizing the self-correction process. Experiments on AIME2024 and AIME2025 benchmarks show that SCFT and RLERR significantly improve reasoning accuracy and reflection quality, outperforming state-of-the-art baselines.",16.42,16.746,275,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12723v1_An Evolutionary Framework for Automatic Optimizati.pdf,An Evolutionary Framework for Automatic Optimization Benchmark Generation via Large Language Models,"Yuhiro Ono, Tomohiro Harada, Yukiya Miura",,2601.12723v1,"optimization benchmarks, large language models, evolutionary framework, benchmark generation, genetic algorithm, differential evolution","Optimization benchmarks are crucial for evaluating algorithm performance, but existing artificial benchmarks often lack the diversity and irregularity of real-world problems, while real-world derived benchmarks are costly and difficult to construct. This paper introduces an evolutionary automatic benchmark generation framework using a large language model (LLM) as a generative operator, termed the LLM-driven evolutionary benchmark generator (LLM-EBG). The LLM acts as an evolutionary operator to generate and evolve benchmark problems within a flexible representation space. The framework is demonstrated by generating unconstrained single-objective continuous minimization problems as mathematical expressions, designed to highlight performance differences between a genetic algorithm (GA) and differential evolution (DE). Experimental results show that LLM-EBG successfully produces benchmarks where the target algorithm outperforms the comparative algorithm in over 80% of trials. Additionally, exploratory landscape analysis indicates that GA-favoring benchmarks are sensitive to variable scaling, suggesting the framework can generate problems with distinct geometric characteristics that reflect the intrinsic search behaviors of different optimization algorithms.",19.91,16.227,323,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12727v1_AI-exhibited Personality Traits Can Shape Human Se.pdf,AI-exhibited Personality Traits Can Shape Human Self-concept through Conversations,"Jingshu Li, Tianqi Song, Nattapat Boonprakong, Zicheng Zhu, Yitian Yang, Yi-Chieh Lee",10.1145/3772318.3790654,2601.12727v1,"AI, personality traits, self-concept, conversations, Large Language Model, GPT-4o, human-computer interaction","This study investigates how AI chatbots, specifically those based on Large Language Models like GPT-4o, can influence human self-concept through their exhibited personality traits. By engaging in conversations with an AI exhibiting certain personality traits, individuals' self-concepts tend to align with those traits, leading to increased homogeneity in self-concept across different individuals. The study highlights the potential for AI traits to shape and bias users' perceptions of their own personality traits.",17.98,14.183,255,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12731v1_A Shared Geometry of Difficulty in Multilingual La.pdf,A Shared Geometry of Difficulty in Multilingual Language Models,"Stefano Civelli, Pietro Bernardelle, Nicolò Brunello, Gianluca Demartini",,,"multilingual language models, problem-difficulty, linear probes, internal representations, cross-lingual generalization, LLMs, meta-cognitive properties","This study investigates the multilingual geometry of problem-difficulty in large language models (LLMs) by training linear probes on the AMC subset of the Easy2Hard benchmark, translated into 21 languages. The research identifies difficulty-related signals at two distinct stages of model internals: shallow (early-layers) and deep (later-layers) internal representations, which exhibit functionally different behaviors. Probes trained on deep representations show high accuracy within the same language but poor cross-lingual generalization. Conversely, probes trained on shallow representations generalize better across languages, albeit with lower within-language performance. These findings suggest that LLMs first form a language-agnostic representation of problem difficulty, which later becomes language-specific. This aligns with existing findings in LLM interpretability, indicating that models operate in an abstract conceptual space before producing language-specific outputs. The study demonstrates that this two-stage representational process extends to high-level meta-cognitive properties such as problem-difficulty estimation.",17.95,16.876,303,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12740v1_TreeWriter AI-Assisted Hierarchical Planning and W.pdf,TreeWriter: AI-Assisted Hierarchical Planning and Writing for Long-Form Documents,"Zijian Zhang, Fangshi Du, Xingjian Liu, Pan Chen, Oliver Huang, Runlong Ye, Michael Liut, Alán Aspuru-Guzik",,,"AI-assisted writing, hierarchical planning, long-form documents, TreeWriter, AI support, document editing","Long documents pose challenges to current intelligent writing systems, including maintaining consistency, efficient planning, and integrating AI assistance. Existing tools offer limited support for the entire writing process. TreeWriter, a hierarchical writing system, represents documents as trees and integrates contextual AI support. It allows authors to create, save, and refine document outlines at multiple levels, facilitating drafting, understanding, and iterative editing. A built-in AI agent provides context-aware editing suggestions. Studies show TreeWriter improves idea exploration, AI helpfulness, and authorial control, supporting collaborative writing. The findings highlight the potential of hierarchical, tree-structured editors with integrated AI support.",17.07,15.756,269,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12742v1_AirHunt Bridging VLM Semantics and Continuous Plan.pdf,AirHunt: Bridging VLM Semantics and Continuous Planning for Efficient Aerial Object Navigation,"Xuecheng Chen, Zongzhuo Liu, Jianfa Ma, Bang Du, Tiantian Zhang, Xueqian Wang, Boyu Zhou",,,"Vision-Language Models, Aerial Object Navigation, Continuous Path Planning, Semantic Reasoning, Drones, 3D Scene Understanding","Recent advances in large Vision-Language Models (VLMs) have enabled drones to search for open-set objects using natural language instructions. However, integrating VLMs into practical aerial systems is challenging due to the frequency mismatch between VLM inference and real-time planning, and VLMs' limited 3D scene understanding. This paper introduces AirHunt, an aerial object navigation system that efficiently locates open-set objects in outdoor environments by fusing VLM semantic reasoning with continuous path planning. AirHunt features a dual-pathway asynchronous architecture that synergizes VLM reasoning with path planning, enabling adaptive semantic guidance. It also includes an active dual-task reasoning module for selective VLM querying and a semantic-geometric coherent planning module for balancing semantic priorities and motion efficiency. Evaluations show AirHunt's higher success rate, lower navigation error, and reduced flight time compared to state-of-the-art methods. Real-world experiments validate its practical capability in complex environments.",18.53,18.131,336,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12744v1_Vision Language Models for Optimization-Driven Int.pdf,Vision Language Models for Optimization-Driven Intent Processing in Autonomous Networks,"Tasnim Ahmed, Yifan Zhu, Salimur Choudhury",,,"Intent-Based Networking, Optimization, Vision-Language Models, Code Generation, Model Context Protocol","Intent-Based Networking (IBN) allows operators to specify high-level network goals rather than low-level configurations. While recent work demonstrates that large language models can automate configuration tasks, a distinct class of intents requires generating optimization code to compute provably optimal solutions for traffic engineering, routing, and resource allocation. Current systems assume text-based intent expression, requiring operators to enumerate topologies and parameters in prose. Network practitioners naturally reason about structure through diagrams, yet whether Vision-Language Models (VLMs) can process annotated network sketches into correct optimization code remains unexplored. We present IntentOpt, a benchmark of 85 optimization problems across 17 categories, evaluating four VLMs (GPT-5-Mini, Claude-Haiku-4.5, Gemini-2.5-Flash, Llama-3.2-11B-Vision) under three prompting strategies on multimodal versus text-only inputs. Our evaluation shows that visual parameter extraction reduces execution success by 12–21 percentage points (pp), with GPT-5-Mini dropping from 93% to 72%. Program-of-thought prompting decreases performance by up to 13 pp, and open-source models lag behind closed-source ones, with Llama-3.2-11B-Vision reaching 18% compared to 75% for GPT-5-Mini. These results establish baseline capabilities and limitations of current VLMs for optimization code generation within an IBN system. We also demonstrate practical feasibility through a case study that deploys VLM-generated code to network testbed infrastructure using Model Context Protocol.",18.87,21.253,401,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12745v1_A Graph Prompt Fine-Tuning Method for WSN Spatio-T.pdf,A Graph Prompt Fine-Tuning Method for Spatio-Temporal Correlation Anomaly Detection in Wireless Sensor Networks,"Miao Ye, Jing Cui, Yuan Huang, Yong Wang, Qian He, Jiwen Zhang",,,"Anomaly Detection, Graph Neural Networks, Pre-training, Prompt Learning, Wireless Sensor Networks","This paper addresses anomaly detection in multi-temporal modal data within Wireless Sensor Networks (WSN), focusing on the challenges of extracting spatio-temporal correlation features, high annotation costs, and sample imbalance. A novel graph neural network backbone is proposed, integrating a multi-scale strategy and inter-modal fusion with a variational graph convolution module to enhance feature extraction. A multi-task self-supervised training strategy, including pre-training, graph prompting, and fine-tuning, is designed to leverage unlabeled data and improve detection performance. Experimental results on public and actual datasets demonstrate superior F1 metrics compared to existing methods, achieving 91.30% and 92.31%, respectively.",17.09,15.335,262,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12754v1_PAIR-SAFE A Paired-Agent Approach for Runtime Audi.pdf,PAIR-SAFE: A Paired-Agent Approach for Runtime Auditing and Refining AI-Mediated Mental Health Support,"Jiwon Kim, Violeta J. Rodriguez, Dong Whi Yoo, Eshwar Chandrasekharan, Koustuv Saha",,,"large language models, mental health support, Motivational Interviewing Treatment Integrity, runtime auditing, paired-agent framework","Large language models (LLMs) are increasingly used for mental health support, but they can produce responses that are overly directive, inconsistent, or clinically misaligned, especially in sensitive or high-risk contexts. Existing approaches to mitigating these risks largely rely on implicit alignment through training or prompting, offering limited transparency and runtime accountability. This paper introduces PAIR-SAFE, a paired-agent framework for auditing and refining AI-generated mental health support. It integrates a Responder agent with a supervisory Judge agent grounded in the clinically validated Motivational Interviewing Treatment Integrity (MITI-4) framework. The Judge audits each response and provides structured ALLOW or REVISE decisions that guide runtime response refinement. Simulated counseling interactions using a support-seeker simulator derived from human-annotated motivational interviewing data show significant improvements in key MITI dimensions, including Partnership, Seek Collaboration, and overall Relational quality. Quantitative findings are supported by qualitative expert evaluation, highlighting the nuances of runtime supervision. The results reveal that a paired-agent approach can provide clinically grounded auditing and refinement for AI-assisted conversational mental health support.",18.05,18.558,335,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12758v1_VISPA Pluralistic Alignment via Automatic Value Se.pdf,VISPA: Pluralistic Alignment via Automatic Value Selection and Activation,"Shenyan Zheng, Jiayou Zhong, Anudeex Shetty, Heng Ji, Preslav Nakov, Usman Naseem",,,"pluralistic alignment, large language models, value selection, internal model activation, high-stakes domains","As large language models are increasingly used in high-stakes domains, it is essential that their outputs reflect a range of varying perspectives rather than an average human preference. Existing approaches consider limited values or rely on prompt-level interventions, lacking value control and representation. VISPA, a training-free pluralistic alignment framework, enables direct control over value expression by dynamic selection and internal model activation steering. Extensive empirical studies show VISPA's performance across pluralistic alignment modes in healthcare and beyond. Further analysis reveals VISPA's adaptability with different steering initiations, models, and values, suggesting that pluralistic alignment can be achieved through internal activation mechanisms, offering a scalable path toward language models that serve all.",16.68,15.889,265,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12762v1_Teaching LLMs to Learn Tool Trialing and Execution.pdf,Teaching LLMs to Learn Tool Trialing and Execution through Environment Interaction,"Xingjie Gao, Pengcheng Huang, Zhenghao Liu, Yukun Yan, Shuo Wang, Zulong Chen, Chen Qian, Ge Yu, Yu Gu",,,"Large Language Models, tool usage, environment interaction, trial-and-execution paradigm, generalization, robustness","This paper introduces ToolMaster, a framework designed to enhance the tool-use capabilities of Large Language Models (LLMs) by shifting from static solution paths to active learning through environment interaction. ToolMaster employs a trial-and-execution paradigm, combining teacher-generated trajectories with reinforcement learning to enable LLMs to autonomously explore and learn correct tool usage. The framework significantly improves generalization and robustness across unseen or unfamiliar tools, as demonstrated by experimental results. The code and data are available at https://github.com/NEUIR/ToolMaster.",16.64,15.38,256,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12781v1_VIRO Robust and Efficient Neuro-Symbolic Reasoning.pdf,VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension,"Hyejin Park, Junhyuk Kwon, Suha Kwak, Jungseul Ok",,,"Referring Expression Comprehension, neuro-symbolic reasoning, verification, language models, vision-language models, compositional reasoning, zero-shot generalization, cascading errors, operator-level verifiers","Referring Expression Comprehension (REC) aims to localize the image region corresponding to a natural-language query. Recent neuro-symbolic REC approaches leverage large language models (LLMs) and vision-language models (VLMs) to perform compositional reasoning, decomposing queries into structured programs and executing them step-by-step. While such approaches achieve interpretable reasoning and strong zero-shot generalization, they assume that intermediate reasoning steps are accurate. However, this assumption causes cascading errors: false detections and invalid relations propagate through the reasoning chain, yielding high-confidence false positives even when no target is present in the image. To address this limitation, we introduce Verification-Integrated Reasoning Operators (VIRO), a neuro-symbolic framework that embeds lightweight operator-level verifiers within reasoning steps. Each operator executes and validates its output, such as object existence or spatial relationship, thereby allowing the system to robustly handle no-target cases when verification conditions are not met. Our framework achieves state-of-the-art performance, reaching 61.1% balanced accuracy across target-present and no-target settings, and demonstrates generalization to real-world egocentric data. Furthermore, VIRO shows superior computational efficiency in terms of throughput, high reliability with a program failure rate of less than 0.3%, and scalability through decoupled program generation from execution.",18.75,20.852,391,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12785v1_Distilling Time Series Foundation Models for Effic.pdf,DISTILLING TIME SERIES FOUNDATION MODELS FOR EFFICIENT FORECASTING,"Yuqi Li, Kuiye Ding, Chuanguang Yang, Szu-Yu Chen, Yingli Tian",,,"Time Series Foundation Model, Knowledge Distillation, Time Series Forecasting, Model Compression, Distillation Framework","Time Series foundation models (TSFMs) deliver strong forecasting performance through large-scale pretraining, but their large parameter sizes make deployment costly. While knowledge distillation offers a natural and effective approach for model compression, techniques developed for general machine learning tasks are not directly applicable to time series forecasting due to the unique characteristics. To address this, we present DistilTS, the first distillation framework specifically designed for TSFMs. DistilTS addresses two key challenges: (1) task difficulty discrepancy, specific to forecasting, where uniform weighting makes optimization dominated by easier short-term horizons, while long-term horizons receive weaker supervision; and (2) architecture discrepancy, a general challenge in distillation, for which we design an alignment mechanism in the time series forecasting. To overcome these issues, DistilTS introduces horizon-weighted objectives to balance learning across horizons, and a temporal alignment strategy that reduces architectural mismatch, enabling compact models. Experiments on multiple benchmarks demonstrate that DistilTS achieves forecasting performance comparable to full-sized TSFMs, while reducing parameters by up to 1/150 and accelerating inference by up to 6000×. Code is available at: https://github.com/itsnotacie/DistilTS-ICASSP2026.",18.97,19.712,374,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12804v1_SL-CBM Enhancing Concept Bottleneck Models with Se.pdf,SL-CBM: Enhancing Concept Bottleneck Models with Semantic Locality for Better Interpretability,"Hanwei Zhang, Luo Cheng, Rui Wen, Yang Zhang, Lijun Zhang, Holger Hermanns",,,"Explainable AI, Concept Bottleneck Models, Semantic Locality, Saliency Maps, Interpretability, Machine Learning","Explainable AI (XAI) is crucial for building transparent and trustworthy machine learning systems, especially in high-stakes domains. Concept Bottleneck Models (CBMs) provide interpretable, concept-level explanations by explicitly modeling human-understandable concepts. However, existing CBMs often suffer from poor locality faithfulness, failing to spatially align concepts with meaningful image regions, which limits their interpretability and reliability. This work proposes SL-CBM (CBM with Semantic Locality), a novel extension that enforces locality faithfulness by generating spatially coherent saliency maps at both concept and class levels. SL-CBM integrates a 1×1 convolutional layer with a cross-attention mechanism to enhance alignment between concepts, image regions, and final predictions. Unlike prior methods, SL-CBM produces faithful saliency maps inherently tied to the model’s internal reasoning, facilitating more effective debugging and intervention. Extensive experiments on image datasets demonstrate that SL-CBM substantially improves locality faithfulness, explanation quality, and intervention efficacy while maintaining competitive classification accuracy. Ablation studies highlight the importance of contrastive and entropy-based regularization for balancing accuracy, sparsity, and faithfulness. Overall, SL-CBM bridges the gap between concept-based reasoning and spatial explainability, setting a new standard for interpretable and trustworthy concept-based models.",18.73,21.254,398,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12805v1_SciHorizon-GENE Benchmarking LLM for Life Sciences.pdf,SciHorizon-Gene: Benchmarking LLM for Life Sciences Inference from Gene Knowledge to Functional Understanding,"Xiaohan Huang, Meng Xiao, Chuan Qin, Qingqing Long, Jinmiao Chen, Yuanchun Zhou, Hengshu Zhu",https://doi.org/XXXXXXX.XXXXXXX,,"large language models, benchmarking and evaluation, genomics","Large language models (LLMs) have shown growing promise in biomedical research, particularly for knowledge-driven interpretation tasks. However, their ability to reliably reason from gene-level knowledge to functional understanding, a core requirement for knowledge-enhanced cell atlas interpretation, remains largely underexplored. To address this gap, we introduce SciHorizon-Gene, a large-scale gene-centric benchmark constructed from authoritative biological databases. The benchmark integrates curated knowledge for over 190K human genes and comprises more than 540K questions covering diverse gene-to-function reasoning scenarios relevant to cell type annotation, functional interpretation, and mechanism-oriented analysis. SciHorizon-Gene evaluates LLMs along four biologically critical perspectives: research attention sensitivity, hallucination tendency, answer completeness, and literature influence, explicitly targeting failure modes that limit the safe adoption of LLMs in biological interpretation pipelines. We systematically evaluate a wide range of state-of-the-art general-purpose and biomedical LLMs, revealing substantial heterogeneity in gene-level reasoning capabilities and persistent challenges in generating faithful, complete, and literature-grounded functional interpretations. Our benchmark establishes a systematic foundation for analyzing LLM behavior at the gene scale and offers insights for model selection and development, with direct relevance to knowledge-enhanced biological interpretation.",18.91,20.362,385,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12809v1_Left-Right Symmetry Breaking in CLIP-style Vision-.pdf,Left–Right Symmetry Breaking in CLIP-style Vision-Language Models Trained on Synthetic Spatial-Relation Data,"Takaki Yamamoto, Chihiro Noguchi, Toshihiro Tanizawa",,,"vision-language models, spatial understanding, left-right symmetry, Transformer-based encoders, contrastive training, attention decomposition, positional embeddings, token embeddings, horizontal attention gradient","Spatial understanding is a key challenge in vision-language models, and it is unclear how such understanding is acquired. This study presents a 1D image-text testbed to explore how left-right relational understanding emerges in Transformer-based vision and text encoders trained with a CLIP-style contrastive objective. The study finds that contrastive training learns left-right relations, with label diversity being a primary driver of generalization. Mechanistic insights are provided through attention decomposition, showing that interactions between positional and token embeddings induce a horizontal attention gradient that breaks left-right symmetry. Ablating this contribution reduces left-right discrimination, offering insights into how CLIP-style models acquire relational competence.",16.68,16.128,269,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12816v1_Fisher-Orthogonal Projected Natural Gradient Desce.pdf,Fisher-Orthogonal Projected Natural Gradient Descent for Continual Learning,"Ishir Garg, Neel Kolhe, Andy Peng, Rohan Gopalam",,,"Continual Learning, Natural Gradient Descent, Fisher Information Matrix, Orthogonal Gradient Methods, Catastrophic Forgetting","Continual learning aims to enable neural networks to acquire new knowledge on sequential tasks without forgetting previously learned tasks. This paper proposes the Fisher-Orthogonal Projected Natural Gradient Descent (FOPNG) optimizer, which enforces Fisher-orthogonal constraints on parameter updates to preserve old task performance while learning new tasks. Unlike existing methods that operate in Euclidean parameter space, FOPNG projects gradients onto the Fisher-orthogonal complement of previous task gradients. This approach unifies natural gradient descent with orthogonal gradient methods within an information-geometric framework. The resulting update direction is invariant under reparameterization, guarantees descent in the Fisher metric, and helps preserve prior task outputs. Theoretical analysis and practical implementations using the diagonal Fisher are provided, demonstrating strong results on standard continual learning benchmarks such as Permuted-MNIST, Split-MNIST, Rotated-MNIST, Split-CIFAR10, and Split-CIFAR100.",18.04,16.967,306,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12822v1_MirrorGuard Toward Secure Computer-Use Agents via .pdf,MirrorGuard: Toward Secure Computer-Use Agents via Simulation-to-Real Reasoning Correction,"Wenqi Zhang, Yulin Shen, Changyue Jiang, Jiarun Dai, Geng Hong, Xudong Pan*",https://doi.org/XXXXXXX.XXXXXXX,,"Computer Use Agents, Agent Security, Reasoning Correction, Simulation, Vision-Language Models","Large foundation models are integrated into Computer Use Agents (CUAs), enabling autonomous interaction with operating systems through graphical user interfaces (GUIs) to perform complex tasks. This autonomy introduces serious security risks: malicious instructions or visual prompt injections can trigger unsafe reasoning and cause harmful system-level actions. Existing defenses, such as detection-based blocking, prevent damage but often abort tasks prematurely, reducing agent utility. In this paper, we present MirrorGuard, a plug-and-play defense framework that uses simulation-based training to improve CUA security in the real world. To reduce the cost of large-scale training in operating systems, we propose a novel neural-symbolic simulation pipeline, which generates realistic, high-risk GUI interaction trajectories entirely in a text-based simulated environment, capturing unsafe reasoning patterns and potential system hazards without executing real operations. In the simulation environment, MirrorGuard learns to intercept and rectify insecure reasoning chains of CUAs before they produce and execute unsafe actions. In real-world testing, extensive evaluations across diverse benchmarks and CUA architectures show that MirrorGuard significantly mitigates security risks. For instance, on the ByteDance UI-TARS system, it reduces the unsafe rate from 66.5% to 13.0% while maintaining a marginal false refusal rate (FRR). In contrast, the state-of-the-art GuardAgent only achieves a reduction to 53.9% and suffers from a 15.4% higher FRR. Our work proves that simulation-derived defenses can provide robust, real-world protection while maintaining the fundamental utility of the agent. Our code and model are publicly available at https://bmz-q-q.github.io/MirrorGuard.",19.63,23.634,464,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12837v1_Cognition spaces natural artificial and hybrid.pdf,"Cognition spaces: natural, artificial, and hybrid","Ricard Solé, Luis F Seoane, Jordi Pla-Mauri, Michael Timothy Bennett, Michael E. Hochberg, Michael Levin",,,"Evolved cognition, basal cognition, artificial life, artificial intelligence, synthetic biology, morphospace","Cognitive processes are realized across a range of natural, artificial, and hybrid systems, yet there is no unified framework for comparing their forms, limits, and unrealized possibilities. This paper proposes a cognition space approach that replaces narrow, substrate-dependent definitions with a comparative representation based on organizational and informational dimensions. Cognition is treated as a graded capacity to sense, process, and act upon information, allowing diverse systems like cells, brains, artificial agents, and human–AI collectives to be analyzed within a common conceptual landscape. The paper introduces three cognition spaces—basal aneural, neural, and human–AI hybrid—and shows that their occupation is uneven, with clusters of realized systems separated by large unoccupied regions. These voids reflect evolutionary contingencies, physical constraints, and design limitations. The approach clarifies the diversity of existing cognitive systems and highlights hybrid cognition as a promising frontier for exploring novel forms of complexity beyond those produced by biological evolution.",17.61,18.223,321,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12842v1_SCULPT Constraint-Guided Pruned MCTS that Carves E.pdf,SCULPT: Constraint-Guided Pruned MCTS that Carves Efficient Paths for Mathematical Reasoning,"Qitong Fang, Haotian Li, Xu Wang",,,"Monte Carlo Tree Search, Mathematical Reasoning, Large Language Models, Constraint-Guided Exploration, Automated Agent Workflows","Automated agent workflows can enhance the problem-solving ability of large language models (LLMs), but common search strategies rely on stochastic exploration and often traverse implausible branches. This occurs because current pipelines sample candidate steps from generic prompts or learned policies with weak domain priors, yielding near-random walks over operators, units, and formats. To promote ordered exploration, this paper introduces SCULPT, a constraint-guided approach for Monte Carlo Tree Search (MCTS) that integrates domain-aware scoring into selection, expansion, simulation, and backpropagation. SCULPT scores and prunes actions using a combination of symbolic checks (dimensional consistency, type compatibility, magnitude sanity, depth control, and diversity) and structural pattern guidance, thereby steering the search toward plausible reasoning paths. Under matched LLM configurations, SCULPT yields stable improvements on multiple datasets; additional results with GPT-5.2 assess executor transferability and performance on frontier reasoning models. Overall, domain-aware constraints can improve accuracy while maintaining efficiency and reasoning stability.",18.01,17.877,322,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12849v1_The Cost of EFX Generalized-Mean Welfare and Compl.pdf,The Cost of EFX: Generalized-Mean Welfare and Complexity Dichotomies with Few Surplus Items,"Eugene Lim, Tzeh Yuan Neoh, Nicholas Teh",,2601.12849v1,"fair division, envy-freeness, EFX, generalized-mean welfare, NP-hard, polynomial-time algorithms, price of fairness, Pareto-optimality","Envy-freeness up to any good (EFX) is a central fairness notion for allocating indivisible goods, yet its existence is unresolved in general. In the setting with few surplus items, where the number of goods exceeds the number of agents by a small constant (at most three), EFX allocations are guaranteed to exist, shifting the focus from existence to efficiency and computation. This study examines how EFX interacts with generalized-mean (p-mean) welfare, which includes utilitarian (p=1), Nash (p=0), and egalitarian (p→−∞) objectives. Sharp complexity dichotomies at p=0 are established: for any fixed p∈(0,1], deciding whether EFX can attain the global p-mean optimum and computing an EFX allocation maximizing p-mean welfare are NP-hard, even with at most three surplus goods. In contrast, for any fixed p≤0, polynomial-time algorithms optimize p-mean welfare within EFX allocations and efficiently certify when EFX attains the global optimum. The welfare loss of enforcing EFX is quantified via the price of fairness framework, showing that for p>0, the loss can grow linearly with the number of agents, whereas for p≤0, it is bounded by a constant depending on the surplus (and for Nash welfare it vanishes asymptotically). Requiring Pareto-optimality alongside EFX is NP-hard and becomes Σ P2-complete for a stronger variant of EFX. The results delineate when EFX is computationally costly versus structurally aligned with welfare maximization in the setting with few surplus items.",19.97,23.732,474,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12856v1_Mining Citywide Dengue Spread Patterns in Singapor.pdf,Mining Citywide Dengue Spread Patterns in Singapore Through Hotspot Dynamics from Open Web Data,"Liping Huang, Gaoxi Xiao, Stefan Ma, Hechang Chen, Shisong Tang, Flora Salim",https://doi.org/10.1145/XXXXXX.XXXXXX,,"Dengue Cases, Disease Spreading Pattern, Hotpot Dynamics, Machine Learning","Dengue, a mosquito-borne disease, continues to pose a persistent public health challenge in urban areas, particularly in tropical regions such as Singapore. This study introduces a novel framework that uncovers and exploits latent transmission links between urban regions, mined directly from publicly available dengue case data. By modeling how hotspot formation in one area is influenced by epidemic dynamics in neighboring regions, the study aligns the learned network closely with commuting flows, providing an interpretable explanation for citywide spread. The framework advances epidemic modeling and provides a scalable, low-cost tool for public health planning, early intervention, and urban resilience.",16.82,15.516,261,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12879v1_Hierarchical Sparse Circuit Extraction from Billio.pdf,Hierarchical Sparse Circuit Extraction from Billion-Parameter Language Models through Scalable Attribution Graph Decomposition,"Mohammed Mudassir Uddin, Shahnawaz Alam, Mohammed Kaif Pasha",,,"Mechanistic interpretability, sparse computational graphs, circuit discovery, transformer architectures, causal inference, attribution methods, hierarchical decomposition","Mechanistic interpretability seeks to reverse-engineer neural network computations into human-understandable algorithms, yet extracting sparse computational circuits from billion-parameter language models remains challenging due to exponential search complexity and pervasive polysemanticity. The proposed Hierarchical Attribution Graph Decomposition (HAGD) framework reduces circuit discovery complexity from O(2^n) exhaustive enumeration to O(n^2 log n) through multi-resolution abstraction hierarchies and differentiable circuit search. The methodology integrates cross-layer transcoders for monosemantic feature extraction, graph neural network meta-learning for topology prediction, and causal intervention protocols for validation. Empirical evaluation spans GPT-2 variants, Llama-7B through Llama-70B, and Pythia suite models across algorithmic tasks and natural language benchmarks. On modular arithmetic tasks, the framework achieves up to 91% behavioral preservation (±2.3% across runs) while maintaining interpretable subgraph sizes. Cross-architecture transfer experiments suggest that discovered circuits exhibit moderate structural similarity (averaging 67%) across model families, indicating potential shared computational patterns. These results provide preliminary foundations for interpretability at larger model scales while identifying significant limitations in current attribution methodologies that require future advances.",19.33,19.347,374,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12882v1_YOLO26 An Analysis of NMS-Free End to End Framewor.pdf,YOLO26: AN ANALYSIS OF NMS-FREE END-TO-END FRAMEWORK FOR REAL-TIME OBJECT DETECTION,Sudip Chakrabarty,,arXiv:2601.12882v1,"YOLOv26, End-to-End Object Detection, NMS-Free, MuSGD, ProgLoss, Real-Time Computer Vision, You Only Look Once","The 'You Only Look Once' (YOLO) framework has long served as the benchmark for real-time object detection, yet traditional iterations (YOLOv1 through YOLO11) remain constrained by the latency and hyperparameter sensitivity of Non-Maximum Suppression (NMS) post-processing. This paper analyzes a comprehensive analysis of YOLO26, an architecture that fundamentally redefines this paradigm by eliminating NMS in favor of a native end-to-end learning strategy. This study examines the critical innovations that enable this transition, specifically the introduction of the MuSGD optimizer for stabilizing lightweight backbones, STAL for small-target-aware assignment, and ProgLoss for dynamic supervision. Through a systematic review of official performance benchmarks, the results demonstrate that YOLO26 establishes a new Pareto front, outperforming a comprehensive suite of predecessors and state-of-the-art competitors (including RTMDet and DAMO-YOLO) in both inference speed and detection accuracy. The analysis confirms that by decoupling representation learning from heuristic post-processing, YOLOv26 successfully resolves the historical trade-off between latency and precision, signaling the next evolutionary step in edge-based computer vision.",20.13,18.532,373,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12886v1_Communication Methods in Multi-Agent Reinforcement.pdf,Communication Methods in Multi-Agent Reinforcement Learning,Christoph Wittner,,2601.12886v1,"Machine learning, MARL, Communication","Multi-agent reinforcement learning (MARL) extends traditional reinforcement learning to multi-agent systems, addressing challenges like partially observable environments, non-stationarity, and large action spaces. This work reviews 29 publications on communication techniques in MARL, evaluating explicit, implicit, attention-based, graph-based, and hierarchical/role-based methods. It concludes that no single communication framework is universally optimal, and the choice depends on the specific problem. The paper also highlights the need for low computational overhead in communication methods to ensure scalability and discusses research gaps, including the need for standardized benchmarking and improved robustness under realistic conditions to enhance real-world applicability.",17.4,11.669,203,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12893v1_AdaNODEs Test Time Adaptation for Time Series Fore.pdf,ADANODEs: Test Time Adaptation for Time Series Forecasting Using Neural ODES,"Ting Dang, Soumyajit Chatterjee, Hong Jia, Yu Wu, Flora Salim, Fahim Kawsar",,,"Test time adaptation, time series forecasting, domain adaptation, neural odes","Test time adaptation (TTA) has emerged as a promising solution to adapt pre-trained models to new, unseen data distributions using unlabeled target domain data. However, most TTA methods are designed for independent data, often overlooking time series data and rarely addressing forecasting tasks. This paper presents AdaNODEs, an innovative source-free TTA method tailored explicitly for time series forecasting. By leveraging Neural Ordinary Differential Equations (NODEs), we propose a novel adaptation framework that accommodates the unique characteristics of distribution shifts in time series data. Moreover, we innovatively propose a new loss function to tackle TTA for forecasting tasks. AdaNODEs only requires updating limited model parameters, showing effectiveness in capturing temporal dependencies while avoiding significant memory usage. Extensive experiments with one- and high-dimensional data demonstrate that AdaNODEs offer relative improvements of 5.88% and 28.4% over the SOTA baselines, especially demonstrating robustness across higher severity distribution shifts.",18.17,17.498,318,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12904v1_From Prefix Cache to Fusion RAG Cache Accelerating.pdf,From Prefix Cache to Fusion RAG Cache: Accelerating LLM Inference in Retrieval-Augmented Generation,"JIAHAO WANG, WEIYU XIE, MINGXING ZHANG, BOXING ZHANG, JIANWEI DONG, YUENING ZHU, CHEN LIN, JINQI TANG, YAOCHEN HAN, ZHIYUAN AI, XIANGLIN CHEN, YONGWEI WU, CONGFENG JIANG",10.1145/3786655,2601.1290,"Retrieval-Augmented Generation, Large Language Models, Natural Language Processing, KVCache, FusionRAG, Computational Efficiency, Time to First Token","Retrieval-Augmented Generation (RAG) enhances Large Language Models by integrating external knowledge, reducing hallucinations but increasing prompt length, leading to higher computational costs and longer Time to First Token (TTFT). Existing solutions aim to reuse the preprocessed KVCache of each retrieved chunk to accelerate RAG, but lack of cross-chunk contextual information reduces generation quality. FusionRAG, a novel inference framework, optimizes preprocessing and reprocessing stages by embedding related text chunk information and recomputing KVCache for focused tokens. Experiments show FusionRAG improves generation quality at the same recomputation ratio compared to state-of-the-art solutions, achieving up to 70% higher normalized-F1 scores and reducing TTFT by 2.66-9.39× compared to Full Attention.",18.36,21.352,392,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12910v1_SciCoQA Quality Assurance for Scientific Paper--Co.pdf,SCICOQA: Quality Assurance for Scientific Paper–Code Alignment,"Tim Baumgärtner, Iryna Gurevych",,,"reproducibility, scientific publications, codebases, discrepancies, synthetic data, LLMs, GPT-5, computational science, AI, Physics, Quantitative Biology","We present SCICOQA, a dataset for detecting discrepancies between scientific publications and their codebases to ensure faithful implementations. Constructed from GitHub issues and reproducibility papers, SCICOQA includes 611 paper-code discrepancies (81 real, 530 synthetic) across various computational science disciplines. The evaluation of 21 LLMs, including GPT-5, highlights the challenge of detecting real-world discrepancies, with GPT-5 achieving a 45.7% detection rate. The study addresses the reproducibility crisis in AI and science, emphasizing the need for consistent paper-code alignment.",15.52,14.88,231,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12912v1_Human Emotion Verification by Action Languages via.pdf,Human Emotion Verification by Action Languages via Answer Set Programming,"ANDREAS BR ¨ANNSTR ¨OM, JUAN CARLOS NIEVES",10.1017/xxxxx,2601.12912v1,"Action Languages, Answer Set Programming, Theory of Mind","This paper introduces the action language C-MT (Mind Transition Language), built on answer set programming (ASP) and transition systems, to represent the evolution of human mental states in response to observable actions. It formalizes mental states, such as emotions, as multi-dimensional configurations, drawing on psychological theories like the Appraisal Theory of Emotion. The language is extended with a novel causal rule, 'forbids to cause', and expressions for mental state dynamics, enabling modeling of valid transitions between mental states. These principles are evaluated using transition systems in terms of trajectories, allowing controlled reasoning about the dynamic evolution of human mental states. The framework supports comparison of different change dynamics by analyzing trajectories adhering to various psychological principles. The action language is applied to design models for emotion verification, with applications in health and wellbeing, such as depression support and therapy.",18.56,14.927,277,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12913v1_Actionable Interpretability Must Be Defined in Ter.pdf,Position: Actionable Interpretability Must Be Defined in Terms of Symmetries,"Pietro Barbiero, Mateo Espinosa Zarlenga, Francesco Giannini, Alberto Termine, Filippo Bonchi, Mateja Jamnik, Giuseppe Marra",,,"interpretability, AI, symmetries, Bayesian inversions, interpretable models","This paper argues that existing definitions of interpretability in AI are not actionable as they lack formal principles for deriving concrete modeling and inferential rules. The authors propose that interpretability should be defined in terms of symmetries, hypothesizing that four symmetries can motivate core interpretability properties, characterize interpretable models, and derive a unified formulation of interpretable inference. These symmetries include inference equivariance, information invariance, concept-closure invariance, and structural invariance.",15.77,15.159,239,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12922v1_Your Privacy Depends on Others Collusion Vulnerabi.pdf,Your Privacy Depends on Others: Collusion Vulnerabilities in Individual Differential Privacy,"Johannes Kaiser, Alexander Ziller, Eleni Triantafillou, Daniel Rückert, Georgios Kaissis",,,"differential privacy, individual differential privacy, excess risk, membership inference","Individual Differential Privacy (iDP) promises users control over their privacy, but this promise can be broken in practice. The paper reveals a vulnerability in sampling-based iDP mechanisms: an individual’s privacy risk is not solely governed by their own privacy budget, but critically depends on the privacy choices of all other data contributors. This creates a mismatch between the promise of individual privacy control and the reality of a system where risk is collectively determined. The paper demonstrates that certain distributions of privacy preferences can unintentionally inflate the privacy risk of individuals, even when formal guarantees are met. This excess risk provides an exploitable attack vector, where a central adversary or colluding adversaries can deliberately choose privacy budgets to amplify vulnerabilities of targeted individuals. The attack operates entirely within the guarantees of DP, hiding this excess vulnerability. Empirical evaluation shows successful attacks against 62% of targeted individuals, substantially increasing their membership inference susceptibility. To mitigate this, the paper proposes (εi, δi, ∆)-iDP, a privacy contract that uses ∆-divergences to provide users with a hard upper bound on their excess vulnerability, while offering flexibility to mechanism design. The findings expose a fundamental challenge to the current paradigm, demanding a re-evaluation of how iDP systems are designed, audited, communicated, and deployed to make excess risks transparent and controllable.",19.12,20.088,384,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12925v1_ForeDiffusion Foresight-Conditioned Diffusion Poli.pdf,ForeDiffusion: Foresight-Conditioned Diffusion Policy via Future View Construction for Robot Manipulation,"Weize Xie, Yi Ding, Ying He, Leilei Wang, Binwen Bai, Zheyi Zhao, Chenyang Wang, F. Richard Yu",,,"robot manipulation, diffusion strategies, visual motor control, foresight-conditioned diffusion, future view representation, dual loss mechanism, Adroit suite, MetaWorld benchmark","Diffusion strategies have advanced visual motor control by progressively denoising high-dimensional action sequences, providing a promising method for robot manipulation. However, as task complexity increases, the success rate of existing baseline models decreases considerably. This paper proposes Foresight-Conditioned Diffusion (ForeDiffusion), which injects the predicted future view representation into the diffusion process, guiding the policy to be forward-looking and enabling it to correct trajectory deviations. ForeDiffusion employs a dual loss mechanism, combining traditional denoising loss and consistency loss of future observations, achieving unified optimization. Extensive evaluation on the Adroit suite and the MetaWorld benchmark demonstrates that ForeDiffusion achieves an average success rate of 80% for the overall task, significantly outperforming existing mainstream diffusion methods by 23% in complex tasks, while maintaining more stable performance across the entire tasks.",18.04,18.568,335,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12929v1_Membership Inference Test Auditing Training Data i.pdf,Membership Inference Test: Auditing Training Data in Object Classification Models,"Gonzalo Mancera, Daniel DeAlcala, Aythami Morales, Ruben Tolosana, Julian Fierrez",,,"Membership Inference Tests, Object Recognition, Data Privacy, AI Auditing, Convolutional Layers","This research analyzes the performance of Membership Inference Tests (MINT) in determining whether specific data were used during the training phase of object recognition models. The study proposes and develops architectures tailored for MINT models to optimize performance and efficiency in data utilization. Experiments were conducted using an object detection model, an embedding extractor, and a MINT module across three public databases with over 174K images. The proposed architecture uses convolutional layers to capture and model activation patterns during training. The study achieved precision rates between 70% and 80% in identifying training and testing data, depending on the detection module layer depth. Additionally, the research analyzes factors influencing the MINT Module and explores elements contributing to more transparent training processes. The study highlights the need for new auditing tools to oversee AI technologies and ensure their proper integration into society, addressing ethical and legal challenges posed by AI advancements.",17.34,15.742,273,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12931v1_Online Continual Learning for Time Series a Natura.pdf,ONLINE CONTINUAL LEARNING FOR TIME SERIES: A NATURAL SCORE-DRIVEN APPROACH,"Edoardo Urettini, Daniele Atzeni, Ioanna-Yvonni Tsaknaki, Antonio Carta",,,"online continual learning, time series forecasting, natural gradient descent, parameter filtering, robust optimization, replay buffer, regime drifts","Online continual learning (OCL) methods adapt to changing environments without forgetting past knowledge. Similarly, online time series forecasting (OTSF) is a real-world problem where data evolve in time and success depends on both rapid adaptation and long-term memory. This paper aims to strengthen the theoretical and practical connections between time series methods and OCL. It reframes neural network optimization as a parameter filtering problem, showing that natural gradient descent is a score-driven method and proving its information-theoretic optimality. It introduces a robust optimizer using a Student’s t likelihood and natural gradient, which improves robustness to outliers. The paper also introduces Natural Score-driven Replay (NatSR), combining the robust optimizer with a replay buffer and a dynamic scale heuristic to improve fast adaptation at regime drifts. Empirical results demonstrate that NatSR achieves stronger forecasting performance than more complex state-of-the-art methods.",17.93,17.46,313,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12937v1_On the Evidentiary Limits of Membership Inference .pdf,On the Evidentiary Limits of Membership Inference for Copyright Auditing,"Murat Bilgehan Ertan, Emirhan Boge, Min Chen, Kaleel Mahmood, Marten van Dijk",,,"membership inference attacks, copyright auditing, large language models, paraphrasing, adversarial settings","As large language models (LLMs) are trained on increasingly opaque corpora, membership inference attacks (MIAs) have been proposed to audit whether copyrighted texts were used during training. This paper explores whether MIAs can serve as admissible evidence in adversarial copyright disputes, where training data may be obfuscated while preserving semantic content. The authors introduce SAGE, a paraphrasing framework that alters lexical structure while maintaining semantic content and utility. Experiments show that state-of-the-art MIAs degrade when models are fine-tuned on SAGE-generated paraphrases, indicating that MIAs are brittle in adversarial settings and insufficient as a standalone mechanism for copyright auditing of LLMs.",16.47,15.721,259,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12938v1_The Post-Turing Condition Conceptualising Artifici.pdf,The Post-Turing Condition: Conceptualising Artificial Subjectivity and Synthetic Sociality,"Thorsten Jelinek, Patrick Glauner, Alvin Wang Graylin, Yubao Qiu",,,"artificial intelligence, social coordination, meaning formation, PRMO framework, Synthetic Sociality, Quadrangulation, AI design, human subjectivity","In the Post-Turing era, artificial intelligence increasingly shapes social coordination and meaning formation rather than merely automating cognitive tasks. The central challenge is therefore not whether machines become conscious, but whether processes of interpretation and shared reference are progressively automated in ways that marginalize human participation. This paper introduces the PRMO framework, relating AI design trajectories to four constitutive dimensions of human subjectivity: Perception, Representation, Meaning, and the Real. Within this framework, Synthetic Sociality denotes a technological horizon in which artificial agents negotiate coherence and social order primarily among themselves, raising the structural risk of human exclusion from meaning formation. To address this risk, the paper proposes Quadrangulation as a design principle for socially embedded AI systems, requiring artificial agents to treat the human subject as a constitutive reference within shared contexts of meaning. This work is a conceptual perspective that contributes a structural vocabulary for analyzing AI systems at the intersection of computation and society, without proposing a specific technical implementation.",20.43,15.861,324,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12939v1_Active Inference-Driven World Modeling for Adaptiv.pdf,ACTIVE INFERENCE-DRIVEN WORLD MODELING FOR ADAPTIVE UAV SWARM TRAJECTORY DESIGN,"Kaleem Arshid, Ali Krayani, Lucio Marcenaro, David Martin Gomez, Carlo Regazzoni",,,"Autonomous Systems, World Model, UAV-Swarm, Probabilistic Decision-Making, Active-Inference","This paper proposes an Active Inference–based framework for autonomous trajectory design in UAV swarms. The method integrates probabilistic reasoning and self-learning to enable distributed mission allocation, route ordering, and motion planning. Expert trajectories generated using a Genetic Algorithm with Repulsion Forces (GA–RF) are employed to train a hierarchical World Model capturing swarm behavior across mission, route, and motion levels. During online operation, UAVs infer actions by minimizing divergence between current beliefs and model-predicted states, enabling adaptive responses to dynamic environments. Simulation results show faster convergence, higher stability, and safer navigation than Q-Learning, demonstrating the scalability and cognitive grounding of the proposed framework for intelligent UAV swarm control.",17.29,15.561,269,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12946v1_AI-generated data contamination erodes pathologica.pdf,AI-generated data contamination erodes pathological variability and diagnostic reliability,"Hongyu He, Shaowen Xiang, Ye Zhang, Yingtao Zhu, Jin Zhang, Hao Deng, Emily Alsentzer, Qingyu Chen, Kun-Hsing Yu, Andrew Marmenshall, Tingting Chen, Srinivas Anumasa, Daniel Ebner, Dean Ho, Kee Yuan Ngiam, Ching-Yu Cheng, Dianbo Liu",,,"Generative AI, medical records, synthetic data, pathological variability, diagnostic reliability, clinical consequences, data contamination, human verification, model architecture, phenotypes, demographic representations, false diagnostic confidence, physician evaluation, mitigation strategies, data ecosystems","Generative AI is rapidly populating medical records with synthetic content, creating a feedback loop where future models risk training on uncurated AI-generated data. This study shows that without mandatory human verification, this cycle erodes pathological variability and diagnostic reliability. Analysis of over 800,000 synthetic data points reveals models converge toward generic phenotypes, with rare critical findings disappearing and demographic skewing toward middle-aged males. False diagnostic confidence increases, with false reassurance rates tripling to 40%. Blinded physician evaluation confirms AI-generated documentation becomes clinically useless after two generations. Mitigation strategies like synthetic volume scaling fail, but mixing real data with quality-aware filtering preserves diversity. Without human oversight, generative AI deployment threatens healthcare data ecosystems.",20.48,19.383,397,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.12951v1_Beyond Accuracy Characterizing Code Comprehension .pdf,Beyond Accuracy: Characterizing Code Comprehension Capabilities in (Large) Language Models,"Felix Mächtle, Jan-Niclas Serr, Nils Loose, Thomas Eisenbarth",,,"Code Comprehension, Model Evaluation and Benchmarking, Machine Learning for Software Engineering","Large Language Models (LLMs) are increasingly integrated into software engineering workflows, yet current benchmarks provide only coarse performance summaries that obscure the diverse capabilities and limitations of these models. This paper investigates whether LLMs’ code-comprehension performance aligns with traditional human-centric software metrics or instead reflects distinct, non-human regularities. A diagnostic framework is introduced to reframe code understanding as a binary input–output consistency task, enabling the evaluation of classification and generative models. Using a large-scale dataset, the study correlates model performance with traditional, human-centric complexity metrics, such as lexical size, control-flow complexity, and abstract syntax tree structure. The analyses reveal minimal correlation between human-defined metrics and LLM success (AUROC 0.63), while shadow models achieve substantially higher predictive performance (AUROC 0.86), capturing complex, partially predictable patterns beyond traditional software measures. These findings suggest that LLM comprehension reflects model-specific regularities only partially accessible through either human-designed or learned features, emphasizing the need for benchmark methodologies that move beyond aggregate accuracy and toward instance-level diagnostics, while acknowledging fundamental limits in predicting correct outcomes.",18.77,17.795,334,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13007v1_ArchAgent Scalable Legacy Software Architecture Re.pdf,SCALABLE LEGACY SOFTWARE ARCHITECTURE RECOVERY WITH LLMS,"Rusheng Pan, Bingcheng Mao, Tianyi Ma, Zhenhua Ling",,,"Software architecture recovery, code repository, cross-repository context, large language models","Recovering accurate architecture from large-scale legacy software is hindered by architectural drift, missing relations, and the limited context of Large Language Models (LLMs). We present ArchAgent, a scalable agent-based framework that combines static analysis, adaptive code segmentation, and LLM-powered synthesis to reconstruct multiview, business-aligned architectures from cross-repository codebases. ArchAgent introduces scalable diagram generation with contextual pruning and integrates cross-repository data to identify business-critical modules. Evaluations of typical large-scale GitHub projects show significant improvements over existing benchmarks. An ablation study confirms that dependency context improves the accuracy of generated architectures of production-level repositories, and a real-world case study demonstrates effective recovery of critical business logics from legacy projects. The dataset is available at https://github.com/panrusheng/arch-eval-benchmark.",17.32,15.586,270,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13013v1_HT-GNN Hyper-Temporal Graph Neural Network for Cus.pdf,HT-GNN: Hyper-Temporal Graph Neural Network for Customer Lifetime Value Prediction in Baidu Ads,"Xiaohui Zhao, Xinjian Zhao, Jiahui Zhang, Guoyu Liu, Houzhi Wang, Shu Wu",,,"Lifetime Value Prediction, Advertising Platform","Lifetime value (LTV) prediction is crucial for news feed advertising, enabling platforms to optimize bidding and budget allocation for long-term revenue growth. This paper introduces a Hyper-Temporal Graph Neural Network (HT-GNN) to address challenges in LTV prediction, such as demographic-based targeting and dynamic marketing strategies. HT-GNN models demographic heterogeneity and temporal dynamics through a hypergraph-supervised module, a transformer-based temporal encoder, and a task-adaptive mixture-of-experts. Experiments on Baidu Ads with 15 million users show that HT-GNN outperforms state-of-the-art methods across all metrics and prediction horizons.",16.34,14.751,241,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13018v1_Bi-Attention HateXplain  Taking into account the s.pdf,Bi-Attention HateXplain: Taking into account the sequential aspect of data during explainability in a multi-task context,Ghislain Dorian Tchuente Mondjo,,,"Multitask learning, Deep Learning, Hate speech, Explainability, Bi-Attention","Technological advances in the Internet and online social networks have brought many benefits to humanity, but also an increase in hate speech, a major global threat. To improve the reliability of black-box models used for hate speech detection, post-hoc approaches like LIME, SHAP, and LRP provide explanations after training the classification model. In contrast, multi-task approaches based on the HateXplain benchmark learn to explain and classify simultaneously. However, results from HateXplain-based algorithms show that predicted attention varies considerably when it should be constant, leading to inconsistent interpretations, instability of predictions, and learning difficulties. To address this, the BiAtt-BiRNN-HateXplain model is proposed, which is easier to explain compared to complex LLMs and considers the sequential aspect of input data during explainability through a BiRNN layer. With multi-task learning (explainability and classification task), the model could classify better and commit fewer unintentional bias errors related to communities. Experimental results on HateXplain data show clear improvements in detection performance, explainability, and a reduction in unintentional bias.",18.32,17.791,326,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13020v1_PASs-MoE Mitigating Misaligned Co-drift among Rout.pdf,PASs-MoE: Mitigating Misaligned Co-drift among Router and Experts via Pathway Activation Subspaces for Continual Learning,"Zhiyan Hou, Haiyun Guo, Haokai Ma, Yandu Sun, Yonghui Yang, Jinqiao Wang",,,"Continual Instruction Tuning, Multimodal Large Language Models, Mixture-of-Experts, Low-rank Adaptation, Pathway Activation Subspaces, Catastrophic Forgetting","Continual instruction tuning (CIT) requires multimodal large language models (MLLMs) to adapt to a stream of tasks without forgetting prior capabilities. A common strategy is to isolate updates by routing inputs to different LoRA experts. However, existing LoRA-based Mixture-of-Experts (MoE) methods often jointly update the router and experts in an indiscriminate way, causing the router’s preferences to co-drift with experts’ adaptation pathways and gradually deviate from early-stage input–expert specialization. This is termed as Misaligned Co-drift, which blurs expert responsibilities and exacerbates forgetting. To address this, the pathway activation subspace (PASs), a LoRA-induced subspace that reflects which low-rank pathway directions an input activates in each expert, is introduced. Based on PASs, a fixed-capacity PASs-based MoE–LoRA method with two components is proposed: PAS-guided Reweighting, which calibrates routing using each expert’s pathway activation signals, and PAS-aware Rank Stabilization, which selectively stabilizes rank directions important to previous tasks. Experiments on a CIT benchmark show that this approach consistently outperforms conventional continual learning baselines and MoE–LoRA variants in both accuracy and anti-forgetting without adding parameters.",18.55,22.751,422,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13048v1_Analysis of Long Range Dependency Understanding in.pdf,ANALYSIS OF LONG RANGE DEPENDENCY UNDERSTANDING IN STATE SPACE MODELS,"Srividya Ravikumar, Abhinav Anand, Shweta Verma, Mira Mezini",,,"Structured state-space models, interpretability, vulnerability detection","Although state-space models (SSMs) have demonstrated strong performance on long-sequence benchmarks, most research has emphasized predictive accuracy rather than interpretability. This work presents the first systematic kernel interpretability study of the diagonalized state-space model (S4D) trained on a real-world task (vulnerability detection in source code). Through time and frequency domain analysis of the S4D kernel, it is shown that the long-range modeling capability of S4D varies significantly under different model architectures, affecting model performance. For instance, depending on the architecture, the S4D kernel can behave as a low-pass, band-pass, or high-pass filter. The insights from this analysis can guide future work in designing better S4D-based models.",16.52,14.347,237,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13054v1_TinyML-Enabled IoT for Sustainable Precision Irrig.pdf,TinyML-Enabled IoT for Sustainable Precision Irrigation,"Kamogelo Taueatsoala, Caitlyn Daniels, Angelina J. Ramsunar, Petrus Bronkhorst, Absalom E. Ezugwu",,,"TinyML, edge computing, Internet of Things, precision agriculture, smart irrigation, sustainable water management, embedded machine learning, resource-constrained systems","This paper presents a novel IoT framework integrating Tiny Machine Learning (TinyML) for precision irrigation, targeting small-scale farming communities affected by water scarcity and climate challenges. The proposed four-layer architecture uses low-cost hardware, including an ESP32 microcontroller and a Raspberry Pi, to enable autonomous decision-making without cloud dependency. Environmental monitoring is conducted using various sensors, and a Gradient Boosting model is identified as superior for predicting irrigation needs with high accuracy. The system, validated in a controlled environment, demonstrates significant water usage reduction and is designed for sustainable deployment in resource-constrained rural settings.",17.1,15.092,258,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13060v1_MagicGUI-RMS A Multi-Agent Reward Model System for.pdf,MAGICGUI-RMS: A MULTI-AGENT REWARD MODEL SYSTEM FOR SELF-EVOLVING GUI AGENTS VIA AUTOMATED FEEDBACK REFLUX,"Zecheng Li, Zhihui Cao, Wenke Huang, Yudong Zhang, Keying Qi, Rui Wang, Zeyu Zheng, Jian Zhao, Hao Zhu, Hengxin Wu, Yuran Wang, Guitao Fan, Guokun Wu, Yicong Liu, Zhilin Gao, Haikun Xu, He Yang, Minqi Xiang, Xingyu Liu, Zuojian Wang",,,"GUI agents, multi-agent reward model system, automated feedback, self-evolving, trajectory evaluation, training data, adaptive learning, reward-based adaptation","Graphical user interface (GUI) agents are advancing towards autonomous interaction and reliable task execution. However, challenges remain in automating trajectory evaluation and generating high-quality training data. MagicGUI-RMS, a multi-agent reward model system, addresses these by integrating Domain-Specific and General-Purpose Reward Models for adaptive evaluation and self-evolving learning. It supports reward learning at scale with a structured data construction pipeline, reducing annotation costs while maintaining sample fidelity. The system identifies erroneous actions, proposes refined alternatives, and enhances agent behavior through an automated data-reflux mechanism. Experiments show substantial gains in task accuracy and behavioral robustness, establishing MagicGUI-RMS as a foundation for self-improving GUI agents.",19.19,20.689,397,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13075v1_METIS Mentoring Engine for Thoughtful Inquiry  Sol.pdf,METIS: Mentoring Engine for Thoughtful Inquiry & Solutions,"Abhinav Rajeev Kumar, Dhruv Trehan, Paras Chopra",,,"AI mentor, research mentorship, undergraduates, publishable paper, tool-augmented assistant, LLM, multi-turn tutoring, empirical comparison","This paper introduces METIS, an AI tool designed to mentor undergraduates in transforming initial research ideas into publishable papers. METIS is equipped with literature search, curated guidelines, methodology checks, and memory, and is evaluated against GPT-5 and Claude Sonnet 4.5. The evaluation includes LLM-as-a-judge pairwise preferences, student-persona rubrics, and multi-turn tutoring sessions. METIS shows higher preference and student scores in various stages, particularly in document-grounded stages. The paper also discusses related work in tool-augmented assistants and autonomous scientific-process agents, emphasizing METIS's focus on interactive mentorship and structured learner progression.",15.95,15.108,241,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13111v1_CORE-T COherent REtrieval of Tables for Text-to-SQ.pdf,CORE-T: COherent REtrieval of Tables for Text-to-SQL,"Hassan Soliman, Vivek Gupta, Dan Roth, Iryna Gurevych",,arXiv:2601.13111v1,"text-to-SQL, table retrieval, dense retrieval, LLM-generated metadata, joinable tables, data-lake analytics, semantic join discovery","Realistic text-to-SQL workflows often require joining multiple tables, making accurate table retrieval a key bottleneck. This paper introduces CORE-T, a scalable, training-free framework that enriches tables with LLM-generated purpose metadata and pre-computes a lightweight table-compatibility cache. At inference, dense retrieval returns top candidates, and a single LLM call selects a coherent, joinable subset, improving table-selection F1 by up to 22.7 points and reducing table retrieval by up to 42%. This enhances multi-table execution accuracy by up to 5.0 points on BIRD and 6.9 points on MMQA, using 4–5× fewer tokens than LLM-intensive baselines.",16.81,16.779,282,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13114v1_IntAgent NWDAF-Based Intent LLM Agent Towards Adva.pdf,IntAgent: NWDAF-Based Intent LLM Agent Towards Advanced Next Generation Networks,"Abdelrahman Soliman, Ahmed Refaey, Aiman Erbad, Amr Mohamed",,,"Core Network, Next Generation Network, Large Language Models, Intent Management, Intelligent Networks, Closed Loop","Intent-based networks (IBNs) are gaining prominence as an innovative technology that automates network operations through high-level request statements, defining what the network should achieve. This work introduces IntAgent, an intelligent intent LLM agent that integrates NWDAF analytics and tools to fulfill the network operator’s intents. Unlike previous approaches, an intent tools engine is developed directly within the NWDAF analytics engine, allowing the agent to utilize live network analytics to inform its reasoning and tool selection. An enriched, 3GPP-compliant data source enhances the dynamic, context-aware fulfillment of network operator goals, along with an MCP tools server for scheduling, monitoring, and analytics tools. The efficacy of the framework is demonstrated through two practical use cases: ML-based traffic prediction and scheduled policy enforcement, validating IntAgent’s ability to autonomously fulfill complex network intents.",18.08,15.821,286,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13122v1_Responsible AI for General-Purpose Systems Overvie.pdf,"Responsible AI for General-Purpose Systems: Overview, Challenges, and A Path Forward","Gourab K. Patro, Himanshi Agrawal, Himanshu Gharat, Supriya Panigrahi, Nim Sherpa, Vishal Vaddina, Dagnachew Birru",,2601.13122v1,"Responsible AI, General-Purpose AI, Large Language Models, Diffusion Models, Multimodal Large Language Models, AI alignment, retrieval-augmented generation, reasoning enhancements","Modern general-purpose AI systems, built using large language and vision models, are capable of performing a variety of tasks across industries. However, they pose risks such as hallucinations, toxicity, and stereotypes, making them untrustworthy. This paper reviews these risks in the context of eight responsible AI principles and compares them to traditional task-specific AI systems. The paper argues for a new approach to responsible AI for general-purpose systems, proposing the C 2V2 (Control, Consistency, Value, Veracity) desiderata. It discusses recent efforts in AI alignment and other enhancements, suggesting that responsible general-purpose AI can be achieved by modeling application-specific requirements along the C 2V2 dimensions and combining various techniques to meet these desiderata.",18.64,17.92,334,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13142v1_TVWorld Foundations for Remote-Control TV Agents.pdf,TVWorld: Foundations for Remote-Control TV Agents,"Zhantao Ma, Quanfeng Lu, Shuai Zhong, Dahai Yu, Ping Luo, Michael K. Ng",,,"large vision–language models, device control, remote-control interaction, TV navigation, graph-based abstraction, topology-aware navigation, focus-aware grounding, LVLMs, TVTheseus","Recent large vision–language models (LVLMs) have shown potential for device control, but research has mainly focused on point-and-click interactions, neglecting remote-control interactions common in TV usage. This paper introduces TVWorld, an offline graph-based abstraction for TV navigation, enabling reproducible evaluation. Two benchmarks, TVWorld-N and TVWorld-G, assess TV-use capabilities, revealing a key limitation in existing agents: insufficient topology awareness for focus-based, long-horizon TV navigation. The proposed Topology-Aware Training framework enhances LVLMs with topology awareness, leading to the development of TVTheseus, a specialized model for TV navigation. TVTheseus achieves a 68.3% success rate on TVWorld-N, surpassing closed-source baselines and establishing state-of-the-art performance. Additional analyses provide insights into developing effective TV-use agents.",17.76,17.732,315,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13160v1_Training instability in deep learning follows low-.pdf,Training instability in deep learning follows low-dimensional dynamical principles,"Zhipeng Zhang, Zhenjie Yao, Kai Li, Lei Yang",,arXiv:2601.13160v1,"training instability, deep learning, reinforcement learning, large language models, dynamical systems","Deep learning systems achieve remarkable empirical performance, yet the stability of the training process itself remains poorly understood. Training unfolds as a high-dimensional dynamical system in which small perturbations to optimization, data, parameters, or learning signals can induce abrupt and irreversible collapse, undermining reproducibility and scalability. We propose a unified dynamical perspective that characterizes training stability as an intrinsic property of learning systems, organized along four interacting dimensions: optimization, environmental/data, parametric, and learning-signal stability. We operationalize this perspective through controlled perturbation auditing of training trajectories, probing how learning dynamics respond to structured disturbances without modifying learning algorithms. Across reinforcement learning and large language model training, we identify three recurring regularities: high final performance is frequently decoupled from training stability; controlled stochasticity consistently buffers learning dynamics across paradigms; and deviations in low-dimensional latent meta-states systematically precede observable performance collapse. Together, these findings establish training stability as a measurable and comparable dynamical property of learning systems, providing a descriptive foundation for studying learning dynamics beyond final performance outcomes.",19.39,17.073,331,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13166v1_From 100000 images to winning the first brain MRI .pdf,"From 100,000+ images to winning the first brain MRI foundation model challenges: Sharing lessons and models","Pedro M. Gordaliza, Jaume Banus, Benoît Gérin, Maxence Wynen, Nataliia Molchanova, Jonas Richiardi, Meritxell Bach Cuadra",,,"Foundation Models, Medical Image Analysis, Brain MRI, Self-Supervised Learning, U-Net CNN Architecture, Anatomical Priors, Neuroimaging Domain Knowledge, MICCAI 2025 Challenges, SSL3D, FOMO25","Developing Foundation Models for medical image analysis is crucial to address the unique challenges in radiological tasks. The first challenges of this kind for 3D brain MRI, SSL3D and FOMO25, were held at MICCAI 2025. The authors' solution ranked first in both contests, utilizing a U-Net CNN architecture combined with strategies leveraging anatomical priors and neuroimaging domain knowledge. Their models trained significantly faster and were smaller than competing transformer-based approaches. Foundation models have revolutionized artificial intelligence, first in natural language processing and subsequently in computer vision. Medical imaging, particularly radiology, faces challenges such as data sparsity, protocol variability, and expensive expert annotations. Brain MRI exemplifies both the promise and difficulty of foundation models in medical imaging due to its anatomical complexity and wide spectrum of pathologies. The field faces unique obstacles like high-dimensional 3D volumetric data, complementary MRI contrasts, vendor-specific acquisition protocols, and population heterogeneity. The SSL3D and FOMO25 challenges at MICCAI 2025 represented the first rigorous evaluation of SSL foundation models for neuroimaging, assembling an unprecedented pre-training dataset of 34,191 subjects with multiple contrasts and timepoints.",18.43,23.88,440,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13186v1_Prompt Injection Mitigation with Agentic AI Nested.pdf,"Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching","Diego Gosmar, Deborah A. Dahl",,2601.13186v1,"Prompt Injection, Agentic AI, Nested Learning, Semantic Caching, AI Sustainability, Large Language Models, Security, Computational Savings, Environmental Sustainability","Prompt injection remains a central obstacle to the safe deployment of large language models, particularly in multi-agent settings where intermediate outputs can propagate or amplify malicious instructions. This paper extends the evaluation framework with semantic similarity-based caching, a dedicated fourth-agent rule-based evaluator, and a fifth metric (Observability Score Ratio) to yield TIVS-O. The proposed system combines a three-stage agentic pipeline with Continuum Memory Systems that implement semantic similarity-based caching across 301 injection-focused prompts drawn from ten attack families. A dedicated fourth agent performs comprehensive security analysis using five key performance indicators. Experiments show that the system achieves secure responses with significantly reduced high-risk breaches, while semantic caching delivers substantial computational savings enabling real-time responses, cost reduction, and energy savings. The semantic caching mechanism not only accelerates inference but demonstrates that security architectures can simultaneously advance environmental sustainability—achieving 41.6% reduction in computational load translates directly to proportional decreases in energy consumption and carbon emissions. These results indicate that Observability-aware evaluation can reveal non-monotonic effects within multi-agent pipelines, and that memory-augmented agents can jointly maximize security robustness, real-time performance, operational cost savings, and environmental sustainability without modifying underlying model weights, providing a production-ready pathway for secure and green LLM deployments.",19.96,19.286,385,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13187v1_Scientific production in the era of Large Language.pdf,Scientific production in the era of Large Language Models,"Keigo Kusumegi, Xinyu Yang, Paul Ginsparg, Mathijs de Vaan, Toby Stuart, Yian Yin",10.1126/science.adw3000,,,"Large Language Models (LLMs) are rapidly reshaping scientific research. We analyze these changes in multiple, large-scale datasets with 2.1M preprints, 28K peer review reports, and 246M online accesses to scientific documents. We find: 1) scientists adopting LLMs to draft manuscripts demonstrate a large increase in paper production, ranging from 23.7-89.3% depending on scientific field and author background, 2) LLM use has reversed the relationship between writing complexity and paper quality, leading to an influx of manuscripts that are linguistically complex but substantively underwhelming, and 3) LLM adopters access and cite more diverse prior work, including books and younger, less-cited documents. These findings highlight a stunning shift in scientific production that will likely require a change in how journals, funding agencies, and tenure committees evaluate scientific works.",19.04,14.861,283,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13197v1_Diffusion-Driven Synthetic Tabular Data Generation.pdf,Diffusion-Driven Synthetic Tabular Data Generation for Enhanced DoS/DDoS Attack Classification,"Aravind B, Anirud R.S., Sai Surya Teja N, Bala Subrahmanya Sriranga Navaneeth A, Karthika R, Mohankumar N",,,"Network intrusion detection, Tabular diffusion models, Class imbalance, DDoS attack detection, Data augmentation, IDS2017","Class imbalance refers to a situation where certain classes in a dataset have significantly fewer samples than others, leading to biased model performance. This paper addresses class imbalance in network intrusion detection using Tabular Denoising Diffusion Probability Models (TabDDPM) for data augmentation. The approach synthesizes high-fidelity minority-class samples from the CIC-IDS2017 dataset through iterative denoising processes. Synthetic samples generated for minority classes are merged with the original dataset, enabling an ANN classifier to achieve near-perfect recall on previously underrepresented attack classes. The results establish diffusion models as an effective solution for tabular data imbalance in security domains, with potential applications in fraud detection and medical diagnostics.",17.33,16.448,285,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13206v1_Real-Time Deadlines Reveal Temporal Awareness Fail.pdf,Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues,"Neil Sehgal, Sharath Chandra Guntuku, Lyle Ungar",,,"Large Language Models, temporal awareness, negotiations, real-time deadlines, strategic dialogues","Large Language Models (LLMs) generate text token-by-token in discrete time, yet real-world communication critically depends on continuous time constraints. This study investigates how LLMs adjust their behavior in time-sensitive settings using simulated negotiations under strict deadlines. Results show that LLMs struggle to internally track elapsed time, with significantly higher deal closure rates when agents receive remaining-time updates. This temporal tracking failure, rather than a lack of strategic reasoning, limits LLM deployment in time-sensitive applications.",15.01,12.388,186,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13217v1_Beyond Single-shot Writing Deep Research Agents ar.pdf,Beyond Single-shot Writing: Deep Research Agents are Unreliable at Multi-turn Report Revision,"Bingsen Chen, Boyan Li, Ping Nie, Yuyu Zhang, Xi Ye, Chen Zhao",,2601.13217v1,"Deep Research Agents, multi-turn report revision, evaluation suite, feedback simulation, report generation, language models","Existing benchmarks for Deep Research Agents (DRAs) treat report generation as a single-shot writing task, diverging from the iterative drafting and revision process used by human researchers. This study introduces MRDRE, an evaluation suite for multi-turn report revision, highlighting the limitations of DRAs in addressing user feedback without regressing on previously covered content. The analysis reveals that even the best-performing agents struggle with preserving earlier edits and avoiding disruptions outside the feedback's scope. The study suggests that these issues are not easily resolved through inference-time fixes like prompt engineering or dedicated sub-agents.",16.81,14.757,248,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13222v1_Incorporating QA Nuggets into Retrieval-Augmented .pdf,Incorporating Q&A Nuggets into Retrieval-Augmented Generation,"Laura Dietz, Bryan Li, Gabrielle Liu, Jia-Huei Ju, Eugene Yang, Dawn Lawrie, William Walden, James Mayfield",,arXiv:2601.13222v1,"RAG, LLM judge, nugget-based evaluation","RAGE systems integrate ideas from automatic evaluation (E) into Retrieval-augmented Generation (RAG). This paper presents Crucible, a Nugget-Augmented Generation System that preserves explicit citation provenance by constructing a bank of Q&A nuggets from retrieved documents and uses them to guide extraction, selection, and report generation. Reasoning on nuggets avoids repeated information through clear and interpretable Q&A semantics—instead of opaque cluster abstractions—while maintaining citation provenance throughout the entire generation process. Evaluated on the TREC NECIR 2024 collection, the Crucible system substantially outperforms Ginger, a recent nugget-based RAG system, in nugget recall, density, and citation grounding.",18.25,15.397,281,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13227v1_Insider Knowledge How Much Can RAG Systems Gain fr.pdf,Insider Knowledge: How Much Can RAG Systems Gain from Evaluation Secrets?,"Laura Dietz, Bryan Li, Eugene Yang, Dawn Lawrie, William Walden, James Mayfield",,arXiv:2601.13227v1,"Retrieval-augmented generation, LLM judge, Nugget evaluation","RAG systems are increasingly evaluated and optimized using LLM judges, an approach that is rapidly becoming the dominant paradigm for system assessment. Nugget-based approaches are now embedded not only in evaluation frameworks but also in the architectures of RAG systems themselves. While this integration can lead to genuine improvements, it also creates a risk of faulty measurements due to circularity. This paper investigates this risk through comparative experiments with nugget-based RAG systems, including Ginger and Crucible, against strong baselines such as GptResearcher. By deliberately modifying Crucible to generate outputs optimized for an LLM judge, it is shown that near-perfect evaluation scores can be achieved when elements of the evaluation—such as prompt templates or gold nuggets—are leaked or can be predicted. The results highlight the importance of blind evaluation settings and methodological diversity to guard against mistaking metric overfitting for genuine system progress.",18.92,16.121,305,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13228v1_Autoregressive Models Rival Diffusion Models at AN.pdf,Autoregressive Models Rival Diffusion Models at Any-Order Generation,"Tianqi Du, Lizhe Fang, Weijie Yang, Chenheng Zhang, Zeming Wei, Yifei Wang, Yisen Wang",,,"autoregressive models, diffusion models, any-order generation, bidirectional conditioning, language modeling, text generation","Diffusion language models enable any-order generation and bidirectional conditioning, offering flexibility for tasks such as infilling, rewriting, and self-correction. However, their single-step dependency formulation limits modeling depth and often results in lower sample quality and stability compared to autoregressive (AR) models. To address this, the authors propose Any-order Any-subset Autoregressive modeling (A3), a framework that extends AR factorization to arbitrary token groups and generation orders. A3 maintains the probabilistic rigor and multi-layer dependency modeling of AR while inheriting diffusion models' flexibility for parallel and bidirectional generation. Implemented through a two-stream attention architecture and a progressive adaptation strategy, A3 transitions pretrained AR models toward any-order prediction. Experiments demonstrate that A3 outperforms diffusion-based models while maintaining flexible decoding, offering a unified approach for a flexible, efficient, and novel language modeling paradigm.",17.81,17.574,313,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13233v1_RAG A Random-Forest-Based Generative Design Framew.pdf,RAG: A RANDOM-FOREST-BASED GENERATIVE DESIGN FRAMEWORK FOR UNCERTAINTY-AWARE DESIGN OF METAMATERIALS WITH COMPLEX FUNCTIONAL RESPONSE REQUIREMENTS,"Bolin Chen, Dex Doksoo Lee, Wei 'Wayne' Chen, Wei Chen",,2601.13233v1,"Random forest, Generative design, Functional response, Uncertainty quantification","Metamaterials design for advanced functionality often involves inverse design on nonlinear and condition-dependent responses, described by continuous functions. Existing methods focus on vector-valued responses, while inverse design of functional responses is challenging due to high-dimensionality, complexity of accommodating design requirements, and non-existence or non-uniqueness of feasible solutions. Generative design approaches are promising but data-hungry, handle design requirements heuristically, and may generate infeasible designs without uncertainty quantification. This paper introduces a RAndom-forest-based Generative approach (RAG) that leverages the small-data compatibility of random forests and reformulates the forward mapping in a discretization-invariant way, enabling data-efficient predictions of high-dimensional functional responses. During inverse design, the framework estimates the likelihood of solutions conditioned on the design requirement, quantifying the trustworthiness of generated designs and reflecting the relative difficulty across different requirements. The one-to-many mapping is addressed through single-shot design generation by sampling from the conditional likelihood. Demonstrations include acoustic metamaterials with prescribed partial passbands/stopbands and mechanical metamaterials with targeted snap-through responses, using 500 and 1057 samples, respectively. Data-efficiency is benchmarked against neural networks on a public mechanical metamaterial dataset with nonlinear stress-strain relations. The framework provides a lightweight, trustworthy pathway to inverse design involving functional responses, expensive simulations, and complex design requirements, beyond metamaterials.",19.85,21.566,428,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13235v1_RubRIX Rubric-Driven Risk Mitigation in Caregiver-.pdf,RubRIX: Rubric-Driven Risk Mitigation in Caregiver-AI Interactions,"Drishti Goel, Jeongah Lee, Qiuyue Joy Zhong, Violeta J. Rodriguez, Daniel S. Brown, Ravi Karkar, Dong Whi Yoo, Koustuv Saha",,,"AI, caregiving, risk mitigation, LLMs, RubRIC, healthcare, domain sensitivity, evaluation frameworks","This paper introduces RubRIX, a rubric-based framework for evaluating risks in large language model (LLM) responses within caregiving contexts. It addresses the complex needs of caregivers seeking AI-mediated support, such as information-seeking, emotional validation, and distress cues. RubRIX operationalizes five risk dimensions: Inattention, Bias & Stigma, Information Inaccuracy, Uncritical Affirmation, and Epistemic Arrogance. The framework was evaluated on over 20,000 caregiver queries, showing significant risk reduction across models. The study emphasizes the need for domain-sensitive, interactional risk evaluation for responsible AI deployment in caregiving support.",17.22,16.837,290,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13236v1_Pixelwise Uncertainty Quantification of Accelerate.pdf,Pixelwise Uncertainty Quantification of Accelerated MRI Reconstruction,"Ilias I. Giannakopoulos, Lokesh B Gautham Muthukumar, Yvonne W. Lui, Riccardo Lattanzi",,,"Conformal Prediction, Magnetic Resonance Imaging, Parallel Imaging, Quantile Regression, Uncertainty Quantification","This work introduces a framework for pixel-wise uncertainty quantification in parallel MRI reconstructions, enabling automatic identification of unreliable regions without ground-truth reference images. The method integrates conformal quantile regression with image reconstruction methods to estimate pixel-wise uncertainty intervals. It was trained and evaluated on Cartesian undersampled brain and knee data from the fastMRI dataset using acceleration factors from 2 to 10. An end-to-end Variational Network was used for image reconstruction. Quantitative experiments show strong agreement between predicted uncertainty maps and true reconstruction error, with Pearson correlation coefficients higher than 90% at acceleration levels at and above four-fold. The proposed framework enables evaluation of reconstruction quality without fully-sampled ground-truth reference images, representing a step toward adaptive MRI acquisition protocols that balance scan time and diagnostic reliability.",16.78,15.733,264,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13238v1_A Semantic Decoupling-Based Two-Stage Rainy-Day At.pdf,A Semantic Decoupling–Based Two-Stage Rainy-Day Attack for Revealing Weather Robustness Deficiencies in Vision–Language Models,"Chengyin Hu, Xiang Chen, Zhe Jia, Weiwen Shi, Fengyu Zhang, Jiujiang Guo, Yiwei Wei",,,"Vision-Language Models, Adversarial Attacks, Weather Robustness, Semantic Decoupling, Rainy-Day Attack, Cross-Modal Semantic Alignment","Vision-Language Models (VLMs) are trained on image-text pairs under ideal conditions and perform well on multimodal tasks. However, their robustness to real-world weather conditions, such as rain, and the stability of cross-modal semantic alignment under such conditions are not well studied. This paper introduces an adversarial framework that uses realistic weather conditions to attack VLMs. The framework employs a two-stage, parameterized perturbation model based on semantic decoupling to analyze rain-induced shifts in decision-making. In the first stage, global effects of rainfall are modeled by applying a low-dimensional global modulation to condition the embedding space, weakening the original semantic decision boundaries. In the second stage, structured rain variations are introduced by modeling multi-scale raindrop appearance and rainfall-induced illumination changes, optimizing the resulting non-differentiable weather space to induce stable semantic shifts. The framework generates perturbations that are physically grounded and interpretable. Experiments show that even physically plausible weather perturbations can cause substantial semantic misalignment in VLMs, posing safety and reliability risks in real-world deployment. Ablations confirm that illumination modeling and multi-scale raindrop structures are key drivers of these semantic shifts.",19.05,20.732,395,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13240v1_KOCO-BENCH Can Large Language Models Leverage Doma.pdf,KOCO-BENCH: Can Large Language Models Leverage Domain Knowledge in Software Development?,"Xue Jiang, Jiaru Qian, Xianjie Shi, Chenjie Li, Hao Zhu, Ziyu Wang, Jielun Zhang, Zheyu Zhao, Kechi Zhang, Jia Li, Wenpin Jiao, Zhi Jin, Ge Li, Yihong Dong",,,"Large Language Models, Software Development, Domain Specialization, Knowledge Acquisition, Code Generation, Benchmarking","LLMs excel at general programming but struggle with domain-specific software development, necessitating domain specialization methods for LLMs to learn and utilize domain knowledge and data. Existing domain-specific code benchmarks cannot evaluate the effectiveness of domain specialization methods, which focus on assessing what knowledge LLMs possess rather than how they acquire and apply new knowledge, lacking explicit knowledge corpora for developing domain specialization methods. To address this, KOCO-BENCH, a novel benchmark designed for evaluating domain specialization methods in real-world software development, is presented. It contains 6 emerging domains with 11 software frameworks and 25 projects, featuring curated knowledge corpora alongside multi-granularity evaluation tasks including domain code generation and domain knowledge understanding. KOCO-BENCH poses significant challenges to state-of-the-art LLMs, revealing the urgent need for more effective domain specialization methods. The benchmark, evaluation code, and baselines are released to advance further research.",18.95,19.416,368,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13247v1_Aligning Agentic World Models via Knowledgeable Ex.pdf,Aligning Agentic World Models via Knowledgeable Experience Learning,"Baochang Ren, Yunzhi Yao, Rui Sun, Shuofei Qiao, Ningyu Zhang, Huajun Chen",,2601.13247v1,"Large Language Models, World Models, Physical Hallucinations, Process Experience, Goal Experience, World Knowledge Repository, Embodied Intelligence","Current Large Language Models (LLMs) exhibit a critical modal disconnect: they possess vast semantic knowledge but lack the procedural grounding to respect the immutable laws of the physical world. Consequently, while these agents implicitly function as world models, their simulations often suffer from physical hallucinations—generating plans that are logically sound but physically unexecutable. Existing alignment strategies predominantly rely on resource-intensive training or fine-tuning, which attempt to compress dynamic environmental rules into static model parameters. However, such parametric encapsulation is inherently rigid, struggling to adapt to the open-ended variability of physical dynamics without continuous, costly retraining. To bridge this gap, we introduce WorldMind, a framework that autonomously constructs a symbolic World Knowledge Repository by synthesizing environmental feedback. Specifically, it unifies Process Experience to enforce physical feasibility via prediction errors and Goal Experience to guide task optimality through successful trajectories. Experiments on EB-ALFRED and EB-Habitat demonstrate that WorldMind achieves superior performance compared to baselines with remarkable cross-model and cross-environment transferability.",18.15,19.341,351,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13260v1_Stop Taking Tokenizers for Granted They Are Core D.pdf,Stop Taking Tokenizers for Granted: They Are Core Design Decisions in Large Language Models,"Sawsan Alqahtani, Mir Tafseer Nayeem, Md Tahmid Rahman Laskar, Tasnim Mohiuddin, M Saiful Bari",,,"tokenization, large language models, subword approaches, Byte Pair Encoding, linguistic structure, bias, capacity, context-aware framework, tokenizer and model co-design, linguistic considerations, domain considerations, deployment considerations, standardized evaluation, transparent reporting, fairness, efficiency, adaptability","Tokenization is a fundamental component of large language models (LLMs) that has been under-theorized and inconsistently designed. Common subword approaches like Byte Pair Encoding (BPE) often misalign with linguistic structures, amplify bias, and waste capacity. This paper argues for treating tokenization as a core modeling decision, integrating tokenizer and model co-design with linguistic, domain, and deployment considerations. Standardized evaluation and transparent reporting are essential for accountability and comparability. By addressing tokenization as a core design problem, language technologies can become fairer, more efficient, and more adaptable.",17.57,18.097,318,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13262v1_CURE-Med Curriculum-Informed Reinforcement Learnin.pdf,CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning,"Eric Onyame, Akash Ghosh, Subhadip Baidya, Sriparna Saha, Xiuying Chen, Chirag Agarwal",,,"multilingual medical reasoning, large language models, reinforcement learning, code-switching, logical correctness, language consistency","While large language models (LLMs) have shown to perform well on monolingual mathematical and commonsense reasoning, they remain unreliable for multilingual medical reasoning applications, hindering their deployment in multilingual healthcare settings. This work introduces CUREMED-BENCH, a high-quality multilingual medical reasoning dataset with open-ended reasoning queries with a single verifiable answer, spanning thirteen languages, including underrepresented languages such as Amharic, Yoruba, and Swahili. Building on this dataset, the authors propose CURE-MED, a curriculum-informed reinforcement learning framework that integrates code-switching-aware supervised fine-tuning and Group Relative Policy Optimization to jointly improve logical correctness and language stability. Across thirteen languages, the approach consistently outperforms strong baselines and scales effectively, achieving 85.21% language consistency and 54.35% logical correctness at 7B parameters, and 94.96% language consistency and 70.04% logical correctness at 32B parameters. These results support reliable and equitable multilingual medical reasoning in LLMs.",19.72,18.006,355,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13268v1_Improving the Safety and Trustworthiness of Medica.pdf,Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops,"Zainab Ghafoor, Md Shafiqul Islam, Koushik Howlader, Md Rasel Khondokar, Tanusree Bhattacharjee, Sayantan Chakraborty, Adrito Roy, Ushashi Bhattacharjee, Tirtho Roy",,,"Medical AI, Large Language Models, Multi-Agent Systems, Ethical Compliance, Safety Assessment","Large Language Models (LLMs) are increasingly applied in healthcare, yet ensuring their ethical integrity and safety compliance remains a major barrier to clinical deployment. This work introduces a multi-agent refinement framework designed to enhance the safety and reliability of medical LLMs through structured, iterative alignment. Our system combines two generative models—DeepSeek R1 and Med-PaLM—with two evaluation agents, LLaMA 3.1 and Phi-4, which assess responses using the American Medical Association’s (AMA) Principles of Medical Ethics and a five-tier Safety Risk Assessment (SRA-5) protocol. We evaluate performance across 900 clinically diverse queries spanning nine ethical domains, measuring convergence efficiency, ethical violation reduction, and domain-specific risk behavior. Results demonstrate that DeepSeek R1 achieves faster convergence (mean 2.34 vs. 2.67 iterations), while Med-PaLM shows superior handling of privacy-sensitive scenarios. The iterative multi-agent loop achieved an 89% reduction in ethical violations and a 92% risk downgrade rate, underscoring the effectiveness of our approach. This study presents a scalable, regulator-aligned, and cost-efficient paradigm for governing medical AI safety.",20.31,19.789,402,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13286v1_AI Skills Improve Job Prospects Causal Evidence fr.pdf,ERROR,ERROR,ERROR,ERROR,ERROR,'bbox',0.0,0.0,0,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13295v1_CooperBench Why Coding Agents Cannot be Your Teamm.pdf,CooperBench: Why Coding Agents Cannot be Your Teammates Yet,"Arpandeep Khatua, Hao Zhu, Peter Tran, Arya Prabhudesai, Frederic Sadrieh, Johann K. Lieberwirth, Xinkai Yu, Yicheng Fu, Michael J. Ryan, Jiaxin Pei, Diyi Yang",,,"CooperBench, collaborative coding tasks, AI agents, coordination capabilities, social intelligence, open-source repositories, coding agents","CooperBench is a benchmark designed to evaluate the collaborative capabilities of AI coding agents. It consists of over 600 tasks across 12 libraries in 4 programming languages, where two agents work on different features that may conflict without proper coordination. The study reveals that current AI agents have a 30% lower success rate when collaborating compared to working individually, highlighting issues such as ineffective communication, deviation from commitments, and incorrect expectations. This contrasts with human teams, where collaboration typically enhances productivity.",15.18,18.514,281,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13317v1_Paid Voices vs. Public Feeds Interpretable Cross-P.pdf,Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme Modeling of Climate Discourse,"Samantha Sudhoff, Pranav Perumal, Zhaoqing Wu, Tunazzina Islam",,,"climate discourse, paid advertising, public social media, thematic analysis, large language models, semantic similarity, computational social science, natural language processing","This study presents a comparative analysis of climate discourse across paid advertisements on Meta and public posts on Bluesky from July 2024 to September 2025. It introduces a thematic discovery and assignment framework that clusters texts by semantic similarity and uses large language models to generate human-interpretable theme labels. The study evaluates the quality of these themes against traditional topic modeling baselines and validates their coherence through downstream tasks. The findings highlight systematic differences between paid climate messaging and public discourse, reflecting platform-level incentives in thematic structure, stance alignment, and temporal responsiveness. The framework supports comparative narrative analysis across diverse communication environments.",16.64,15.441,257,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13327v1_PepEDiff Zero-Shot Peptide Binder Design via Prote.pdf,PepEDiﬀ: Zero-Shot Peptide Binder Design via Protein Embedding Diffusion,"Po-Yu Liang, Tibo Duran, Jun Bai",,2601.13327v1,"Deep Learning, Drug Discovery, Protein Design","We present PepEDiﬀ, a novel peptide binder generator that designs binding sequences given a target receptor protein sequence and its pocket residues. Peptide binder generation is critical in therapeutic and biochemical applications, yet many existing methods rely heavily on intermediate structure prediction, adding complexity and limiting sequence diversity. Our approach departs from this paradigm by generating binder sequences directly in a continuous latent space derived from a pretrained protein embedding model, without relying on predicted structures, thereby improving structural and sequence diversity. To encourage the model to capture binding-relevant features rather than memorizing known sequences, we perform latent-space exploration and diffusion-based sampling, enabling the generation of peptides beyond the limited distribution of known binders. This zero-shot generative strategy leverages the global protein embedding manifold as a semantic prior, allowing the model to propose novel peptide sequences in previously unseen regions of the protein space. We evaluate PepEDiﬀ on TIGIT, a challenging target with a large, flat protein–protein interaction interface that lacks a druggable pocket. Despite its simplicity, our method outperforms state-of-the-art approaches across benchmark tests and in the TIGIT case study, demonstrating its potential as a general, structure-free framework for zero-shot peptide binder design. The code for this research is available at GitHub.",19.94,17.298,345,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13348v1_The AI Genie Phenomenon and Three Types of AI Chat.pdf,"The AI Genie Phenomenon and Three Types of AI Chatbot Addiction: Escapist Roleplays, Pseudosocial Companions, and Epistemic Rabbit Holes","M. Karen Shen, Jessica Huang, Olivia Liang, Ig-Jae Kim, Dongwook Yoon",,,"AI chatbot, Addiction","Recent reports on generative AI chatbot use raise concerns about its addictive potential. This study examines AI chatbot addiction by analyzing Reddit entries to understand why users become addicted, the symptoms reported, and the distinct types of addiction. The study identifies three types of addiction: Escapist Roleplay, Pseudosocial Companion, and Epistemic Rabbit Hole. It also discusses the involvement of sexual content and the perceived helpfulness of recovery strategies for different addiction types. The findings provide empirical groundwork for future prevention, diagnosis, and intervention strategies.",15.76,14.526,229,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13352v1_LLM-as-RNN A Recurrent Language Model for Memory U.pdf,LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction,"Yuxing Lu, J. Ben Tamo, Weichen Zhao, Nan Sun, Yishan Zhong, Wenqi Shi, Jinzhuo Wang, May D. Wang",,,"Large Language Models, Recurrent Neural Networks, Memory Updates, Sequence Prediction, Feedback-Driven Text Rewrites, Online Learning, Healthcare, Meteorology, Finance","Large language models are strong sequence predictors, yet standard inference relies on immutable context histories. After making an error at generation step t, the model lacks an updatable memory mechanism that improves predictions for step t+1. We propose LLM-as-RNN, an inference-only framework that turns a frozen LLM into a recurrent predictor by representing its hidden state as natural-language memory. This state, implemented as a structured system-prompt summary, is updated at each timestep via feedback-driven text rewrites, enabling learning without parameter updates. Under a fixed token budget, LLM-as-RNN corrects errors and retains task-relevant patterns, effectively performing online learning through language. We evaluate the method on three sequential benchmarks in healthcare, meteorology, and finance across Llama, Gemma, and GPT model families. LLM-as-RNN significantly outperforms zero-shot, full-history, and MemPrompt baselines, improving predictive accuracy by 6.5% on average, while producing interpretable, human-readable learning traces absent in standard context accumulation.",18.28,20.465,374,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13358v1_The Geometry of Thought How Scale Restructures Rea.pdf,The Geometry of Thought: How Scale Restructures Reasoning in Large Language Models,Samuel Cyrenius Anderson,,2601.13358v1,"reasoning, scaling laws, chain-of-thought, neural networks, geometry, domain-specific, large language models","This paper explores how scaling affects reasoning in large language models, analyzing over 25,000 chain-of-thought trajectories across four domains (Law, Science, Code, Math) and two scales (8B, 70B parameters). It reveals that scaling induces domain-specific geometric reorganizations rather than uniform capability gains. Legal reasoning shows a significant reduction in representational dimensionality and increased trajectory alignment, while scientific and mathematical reasoning remain invariant. Code reasoning develops distinct strategic modes. The study introduces Neural Reasoning Operators to predict reasoning endpoints and identifies a universal oscillatory signature across domains and scales. The findings suggest that the cost of thought is determined by manifold geometry, offering insights for inference acceleration.",17.1,13.624,233,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13376v1_Bounded Minds Generative Machines Envisioning Conv.pdf,"Bounded Minds, Generative Machines: Envisioning Conversational AI that Works with Human Heuristics and Reduces Bias Risk",JIQUN LIU,https://doi.org/XXXXXXX,,"Bounded Rationality, Heuristics, Conversational AI, GenAI, Evaluation","Conversational AI is rapidly becoming a primary interface for information seeking and decision making, yet most systems still assume idealized users. This article outlines a research pathway grounded in bounded rationality, arguing that conversational AI should be designed to work with human heuristics rather than against them. It identifies key directions for detecting cognitive vulnerability, supporting judgment under uncertainty, and evaluating conversational systems beyond factual accuracy, toward decision quality and cognitive robustness.",15.3,13.007,199,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13383v1_A Lightweight Modular Framework for Constructing A.pdf,"A Lightweight Modular Framework for Constructing Autonomous Agents Driven by Large Language Models: Design, Implementation, and Applications in AgentForge","A. A. Jafari, C. Ozcinar, G. Anbarjafari",,arXiv:2601.13383v1,"Autonomous agents, large language models, modular architecture, natural language processing, software framework, task automation, artificial intelligence, open-source software","The emergence of large language models (LLMs) has catalyzed a paradigm shift in autonomous agent development, enabling systems capable of reasoning, planning, and executing complex multi-step tasks. However, existing agent frameworks often suffer from architectural rigidity, vendor lock-in, and prohibitive complexity that impedes rapid prototyping and deployment. This paper presents AgentForge, a lightweight, open-source Python framework designed to democratize the construction of LLM-driven autonomous agents through a principled modular architecture. AgentForge introduces three key innovations: (1) a composable skill abstraction that enables fine-grained task decomposition with formally defined input-output contracts, (2) a unified LLM backend interface supporting seamless switching between cloud-based APIs (OpenAI, Groq) and local inference engines (HuggingFace Transformers), and (3) a declarative YAML-based configuration system that separates agent logic from implementation details. We formalize the skill composition mechanism as a directed acyclic graph (DAG) and prove its expressiveness for representing arbitrary sequential and parallel task workflows. Comprehensive experimental evaluation across four benchmark scenarios demonstrates that AgentForge achieves competitive task completion rates (87.3% on web scraping pipelines, 91.2% on data analysis tasks) while reducing development time by 62% compared to LangChain and 78% compared to direct API integration. Latency measurements confirm sub-100ms orchestration overhead, rendering the framework suitable for real-time applications. The modular design facilitates extension: we demonstrate the integration of six built-in skills (web scraping, data analysis, content generation, RSS monitoring, image generation, and voice synthesis) and provide comprehensive documentation for custom skill development. AgentForge addresses a critical gap in the LLM agent ecosystem by providing researchers and practitioners with a production-ready foundation for constructing, evaluating, and deploying autonomous agents without sacrificing flexibility or performance.",20.11,25.761,518,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13385v1_Organ-Aware Attention Improves CT Triage and Class.pdf,Organ-Aware Attention Improves CT Triage and Classification,"Lavsen Dahal, Yubraj Bhandari, Geoffrey D. Rubin, Joseph Y. Lo",,,"CT triage, classification, Vision-Language Models, 3D anatomy, computed tomography, organ-aware attention, radiologist burnout, supervised learning, AUROC","This study addresses the need for efficient triage and classification of high-volume medical imaging modalities like computed tomography (CT) to improve patient care and reduce radiologist burnout. The research utilizes the largest publicly available chest CT datasets, CT-RATE and RADCHEST-CT, to establish a new supervised state of the art. The study introduces ORACLE-CT, an encoder-agnostic, organ-aware model that combines Organ-Masked Attention and Organ-Scalar Fusion to enhance performance. Results show state-of-the-art supervised classification performance across both chest and abdomen CT settings, with AUROC scores of 0.86 and 0.85, respectively. The source code is available at https://github.com/lavsendahal/oracle-ct.",16.91,17.03,288,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13392v1_Beyond Memorization Testing LLM Reasoning on Unsee.pdf,Beyond Memorization: Testing LLM Reasoning on Unseen Theory of Computation Tasks,"Shlok Shelat, Jay Raval, Souvik Roy, Manas Gaur",,,"Large language models, formal language tasks, deterministic finite automata, regular languages, symbolic reasoning, pattern matching, benchmark, Arden’s theorem, Kleene-star semantics, prompting strategies, Chain-of-Thought, Tree-of-Thought","Large language models (LLMs) have shown strong performance on formal language tasks, but it is unclear if this reflects genuine symbolic reasoning or pattern matching. This study introduces a benchmark for deterministic finite automata (DFA) construction from regular languages, including factual knowledge questions, seen construction problems, and unseen problems with multiple constraints. Models perform well on factual and seen tasks but struggle with unseen problems due to misinterpretation of constraints and failure to maintain global consistency. A hint protocol helps correct shallow errors but not deeper issues. The study evaluates various prompting strategies and highlights a gap between generating syntactically plausible DFAs and achieving semantically correct formal reasoning.",17.12,16.878,289,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13398v1_Can LLMs Compress and Decompress Evaluating Code U.pdf,Can LLMs Compress (and Decompress)? Evaluating Code Understanding and Execution via Invertibility,"Nickil Maveli, Antonio Vergari, Shay B. Cohen",,,"LLMs, code benchmarks, round-trip code execution, bijection fidelity, Code-LLMs, round-trip consistency, code reasoning, inversion, semantic code understanding","LLMs demonstrate strong performance on code benchmarks, yet round-trip code execution reveals limitations in their ability to maintain consistent reasoning across forward and backward execution. The paper presents ROUNDTRIPCODEEVAL (RTCE), a benchmark for testing round-trip consistency in code execution reasoning tasks. It evaluates state-of-the-art Code-LLMs using zero-shot prompting, supervised fine-tuning, and self-reflection mechanisms, finding modest improvements but significant gaps in round-trip consistency. This indicates that current LLMs lack the internal coherence required for trustworthy code reasoning, highlighting the need for deeper semantic understanding beyond surface-level pattern matching.",16.17,14.659,237,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13400v1_Deep Image Prior with L0 Gradient Regularizer for .pdf,DEEP IMAGE PRIOR WITH L0 GRADIENT REGULARIZER FOR IMAGE SMOOTHING,"Nhat Thanh Tran, Kevin Bui, Jack Xin",,,"image smoothing, optimization, ADMM, deep image prior, ℓ0 gradient","Image smoothing is a fundamental image processing operation that preserves the underlying structure, such as strong edges and contours, and removes minor details and textures in an image. Many image smoothing algorithms rely on computing local window statistics or solving an optimization problem. Recent state-of-the-art methods leverage deep learning, but they require a carefully curated training dataset. Because constructing a proper training dataset for image smoothing is challenging, we propose DIP-ℓ0, a deep image prior framework that incorporates the ℓ0 gradient regularizer. This framework can perform high-quality image smoothing without any training data. To properly minimize the associated loss function that has the nonconvex, nonsmooth ℓ0 'norm', we develop an alternating direction method of multipliers algorithm that utilizes an off-the-shelf ℓ0 gradient minimization solver. Numerical experiments demonstrate that the proposed DIP-ℓ0 outperforms many image smoothing algorithms in edge-preserving image smoothing and JPEG artifact removal.",17.51,15.875,278,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13401v1_Reasoning with Pixel-level Precision QVLM Architec.pdf,Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics,"Peter A. Massih, Eric Cosatto",,,"Vision-Language Models, Quantitative Spatial Reasoning, Pixel-level Precision, SQuID Dataset, QVLM Architecture, Geospatial Analytics","Current Vision-Language Models (VLMs) struggle with quantitative spatial reasoning due to their architecture, which compresses images and loses pixel-level information necessary for tasks like counting and measurement. This paper introduces the SQuID (Satellite Quantitative Intelligence Dataset) and the QVLM (Quantitative Vision-Language Model) to address these limitations. SQuID is a benchmark dataset with 2,000 satellite image Question-Answer pairs, while QVLM maintains pixel precision by generating executable code that operates on pixel-level masks. Experiments show QVLM achieves 42.0% accuracy on SQuID, outperforming traditional VLMs. The paper highlights the importance of architectural decoupling for improving accuracy in quantitative tasks.",17.17,15.435,265,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13404v1_Local-to-Global Logical Explanations for Deep Visi.pdf,Local-to-Global Logical Explanations for Deep Vision Models,"Bhavan Vasu, Giuseppe Raffa, Prasad Tadepalli",,2601.13404v1,"Explainable AI, Neurosymbolic AI, Monotone DNF, Deep Learning","While deep neural networks are extremely effective at classifying images, they remain opaque and hard to interpret. This paper introduces local and global explanation methods for black-box models that generate explanations in terms of human-recognizable primitive concepts. Both the local explanations for a single image and the global explanations for a set of images are cast as logical formulas in monotone disjunctive-normal-form (MDNF), whose satisfaction guarantees that the model yields a high score on a given class. An algorithm is also presented for explaining the classification of examples into multiple classes in the form of a monotone explanation list over primitive concepts. Despite their simplicity and interpretability, the explanations maintain high fidelity and coverage with respect to the black-box models they seek to explain in challenging vision datasets.",18.09,14.597,264,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13406v1_Integrating Virtual Reality and Large Language Mod.pdf,Integrating Virtual Reality and Large Language Models for Team-Based Non-Technical Skills Training and Evaluation in the Operating Room,"Jacob Barker, Doga Demirel, Cullen Jackson, Anna Johansson, Robbin Miraglia, Darian Hoagland, Stephanie B. Jones, John Mitchell, Daniel B. Jones, Suvranu De",,,"Virtual Reality, Large Language Models, Non-Technical Skills, Team-Based Training, Operating Room, Communication, Decision-Making, Teamwork, Leadership, Surgical Safety","Although effective teamwork and communication are critical to surgical safety, structured training for non-technical skills (NTS) remains limited compared with technical simulation. The ACS/APDS Phase III Team-Based Skills Curriculum calls for scalable tools that both teach and objectively assess these competencies during laparoscopic emergencies. We introduce the Virtual Operating Room Team Experience (VORTeX), a multi-user virtual reality (VR) platform that integrates immersive team simulation with large language model (LLM) analytics to train and evaluate communication, decision-making, teamwork, and leadership. Team dialogue is analyzed using structured prompts derived from the Non-Technical Skills for Surgeons (NOTSS) framework, enabling automated classification of behaviors and generation of directed interaction graphs that quantify communication structure and hierarchy. Two laparoscopic emergency scenarios, pneumothorax and intra-abdominal bleeding, were implemented to elicit realistic stress and collaboration. Twelve surgical professionals completed pilot sessions at the 2024 SAGES conference, rating VORTeX as effective.",19.85,17.88,355,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13412v1_Using deep learning for predicting cleansing quali.pdf,Using deep learning for predicting cleansing quality of colon capsule endoscopy images,"Puneet Sharma, Kristian Dalsbø Hindberg, Benedicte Schelde-Olesen, Ulrik Deding, Esmaeil S. Nadimi, Jan-Matthias Braun",,2601.13412v1,"deep learning, colon capsule endoscopy, image classification, structured pruning, explainability, Grad-CAM, ROAD method","This study explores the application of deep learning techniques for predicting cleansing quality in colon capsule endoscopy (CCE) images. A dataset of 500 images labeled by 14 clinicians on the Leighton–Rex scale was used to train a ResNet-18 model for classification, employing stratified K-fold cross-validation. Structured pruning techniques were applied to optimize the model, achieving 79% sparsity while maintaining 88% cross-validation accuracy. The explainability of the pruned model was evaluated using various CAM methods and the ROAD method. The study highlights the challenges of evaluating cleansing quality in CCE images and emphasizes the importance of explainability in clinical applications.",19.17,15.125,290,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13422v1_TrustEnergy A Unified Framework for Accurate and R.pdf,TrustEnergy: A Unified Framework for Accurate and Reliable User-level Energy Usage Prediction,"Dahai Yu, Rongchao Xu, Dingyi Zhuang, Yuheng Bu, Shenhao Wang, Guang Wang",,,"energy usage prediction, spatiotemporal graph neural network, quantile regression, deep learning, uncertainty quantification","Energy usage prediction is crucial for applications like grid management and disaster response. Existing deep learning methods often neglect spatial correlations or fail to provide individualized predictions, impacting accuracy. This paper introduces TrustEnergy, a framework combining a Hierarchical Spatiotemporal Representation module and a Sequential Conformalized Quantile Regression module. These components capture energy patterns and adjust uncertainty bounds dynamically, improving prediction accuracy and reliability. Implemented with a Florida electricity provider, TrustEnergy shows a 5.4% increase in accuracy and a 5.7% improvement in uncertainty quantification over existing methods.",16.48,15.109,249,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13435v1_A Learnable Wavelet Transformer for Long-Short Equ.pdf,A Learnable Wavelet Transformer for Long-Short Equity Trading and Risk-Adjusted Return Optimization,"Shuozhe Li, Du Cheng, Leqi Liu",,,"Neural wavelet regularization, wavelet-transformer network, low-guided high-frequency injection, return optimization","Learning profitable intraday trading policies from financial time series is challenging due to heavy noise, non-stationarity, and strong cross-sectional dependence among related assets. We propose WaveLSFormer, a learnable wavelet-based long-short Transformer that jointly performs multi-scale decomposition and return-oriented decision learning. A learnable wavelet front-end generates low-/high-frequency components via an end-to-end trained filter bank, guided by spectral regularizers that encourage stable and well-separated frequency bands. To fuse multi-scale information, we introduce a low-guided high-frequency injection (LGHI) module that refines low-frequency representations with high-frequency cues while controlling training stability. The model outputs a portfolio of long/short positions that is rescaled to satisfy a fixed risk budget, and is optimized directly with a trading objective and risk-aware regularization. Extensive experiments on five years of hourly data across six industry groups, evaluated over ten random seeds, demonstrate that WaveLSFormer consistently outperforms MLP, LSTM, and Transformer backbones, with and without fixed discrete wavelet front-ends. On average in all industries, WaveLSFormer achieves a cumulative overall strategy return of 0.607±0.045 and a Sharpe ratio of 2.157±0.166, substantially improving both profitability and risk-adjusted returns over the strongest baselines.",19.02,19.558,372,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13437v1_MOSLD-Bench Multilingual Open-Set Learning and Dis.pdf,MOSLD-Bench: Multilingual Open-Set Learning and Discovery Benchmark for Text Categorization,"Adriana-Valentina Costache, Daria-Nicoleta Dragomir, Silviu-Florin Gheorghe, Eduard Poesina, Paul Irofti, Radu Tudor Ionescu",,,"open-set learning, discovery, text categorization, multilingual, benchmark","Open-set learning and discovery (OSLD) is a challenging machine learning task where samples from new, unknown classes can appear at test time. This task generalizes zero-shot learning by involving the active discovery of new classes. While zero-shot learning has been extensively studied in text classification, especially with pre-trained language models, OSLD is a comparatively new setup for the text domain. This paper introduces the first multilingual open-set learning and discovery (MOSLD) benchmark for text categorization by topic, comprising 960K data samples across 12 languages. The benchmark is constructed by rearranging existing datasets and collecting new data samples from the news domain. A novel framework for the OSLD task is proposed, integrating multiple stages to continuously discover and learn new classes. Several language models are evaluated, including the authors' own, to provide reference results for future work. The benchmark is released at https://github.com/Adriana19Valentina/MOSLD-Bench.",17.07,18.747,320,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13443v1_Explicit Cognitive Allocation A Principle for Gove.pdf,Explicit Cognitive Allocation: A Principle for Governed and Auditable Inference in Large Language Models,"Héctor Manuel Manzanilla-Granados, Zaira Navarrete-Cazales, Miriam Pescador-Rojas, Tonahtiu Ramírez-Romero",,,"large language models, AI-assisted reasoning, cognitive allocation, epistemic control, reproducibility, Cognitive Universal Agent, Universal Cognitive Instruments, agricultural domain","The rapid adoption of large language models (LLMs) has enabled new forms of AI-assisted reasoning across various domains. However, current usage often lacks cognitive structure, merging problem framing, knowledge exploration, retrieval, methodological awareness, and explanation into a single process. This limits traceability, weakens epistemic control, and undermines reproducibility, especially in high-responsibility settings. The paper introduces Explicit Cognitive Allocation, a principle for structuring AI-assisted inference by explicitly separating and orchestrating epistemic functions. This is instantiated in the Cognitive Universal Agent (CUA), which organizes inference into distinct stages: exploration and framing, epistemic anchoring, instrumental and methodological mapping, and interpretive synthesis. Central to this framework are Universal Cognitive Instruments (UCIs), which formalize the means—computational, experimental, organizational, regulatory, and educational—through which inquiries become investigable. Controlled comparisons between CUA-orchestrated inference and baseline LLM inference show that CUA achieves earlier and more structured epistemic convergence, higher epistemic alignment, and systematic exposure of the instrumental landscape of inquiry. In contrast, baseline LLM inference shows greater variability in alignment and fails to explicitly surface instrumental structure. These results establish explicit cognitive and instrumental allocation as a model-agnostic architectural principle for improving the controllability, auditability, and epistemic scope of AI-assisted reasoning, providing a foundation for systematic evaluation in domains requiring transparency, governance, and human oversight.",19.79,23.241,460,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13458v1_Labels or Preferences Budget-Constrained Learning .pdf,Labels or Preferences? Budget-Constrained Learning with Human Judgments over AI-Generated Outputs,"Zihan Dong, Ruijia Wu, Linjun Zhang",,2601.13458v1,"AI-generated pseudo labels, budget-conscious data acquisition, semi-parametric inference, monotone missing data framework, Preference-Calibrated Active Learning (PCAL), statistically efficient estimator, functionals of the data distribution, asymptotic optimality, robustness guarantee, nuisance models, variance optimization, Large Language Models (LLMs), human preference data, pseudo-labels, ground-truth labels","The increasing reliance on human preference feedback to judge AI-generated pseudo labels has created a pressing need for principled, budget-conscious data acquisition strategies. This paper addresses the optimal allocation of a fixed annotation budget between ground-truth labels and pairwise preferences in AI. The proposed solution, grounded in semi-parametric inference, casts the budget allocation problem as a monotone missing data framework. The novel method, Preference-Calibrated Active Learning (PCAL), learns the optimal data acquisition strategy and develops a statistically efficient estimator for functionals of the data distribution. Theoretically, the asymptotic optimality of the PCAL estimator is proven, along with a robustness guarantee ensuring performance even with poorly estimated nuisance models. The framework applies to a general class of problems by optimizing the estimator’s variance instead of requiring a closed-form solution. Simulations and real-data analysis demonstrate the practical benefits and superior performance of the proposed method.",19.79,19.097,378,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13462v1_SpatialBench-UC Uncertainty-Aware Evaluation of Sp.pdf,SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt Following in Text-to-Image Generation,Amine Rostane,,2601.13462v1,"text-to-image generation, spatial evaluation, uncertainty-aware evaluation, reproducible benchmark, selective prediction","Evaluating whether text-to-image models follow explicit spatial instructions is challenging due to the limitations of automated object detection and geometric tests. Spatial evaluation is a selective prediction problem, where evaluators should be able to abstain when evidence is weak and report confidence to interpret results as a risk–coverage trade-off. The paper introduces SpatialBench-UC, a reproducible benchmark for pairwise spatial relations, including versioned prompts, pinned configurations, and structured metadata for independent replication and auditing. The benchmark comprises 200 prompts organized into 100 counterfactual pairs. On three baselines, the checker reports varying PASS rates and coverage, with conditional PASS rates on decided samples. The paper formalizes spatial evaluation with explicit abstention and interpretable confidence scores.",17.41,14.823,258,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13464v1_Context and Transcripts Improve Detection of Deepf.pdf,Context and Transcripts Improve Detection of Deepfake Audios of Public Figures,"Chongyang Gao, Marco Postiglione, Julian Baldwin, Natalia Denisenko, Isabel Gortner, Luke Fosdick, Chiara Pulice, Sarit Kraus, V. S. Subrahmanian",,,"deepfake detection, audio deepfakes, context-based detection, machine learning, adversarial strategies","This paper addresses the challenge of detecting audio deepfakes of public figures by incorporating context and transcripts into the detection process. The authors introduce a novel Context-based Audio Deepfake Detector (CADD) architecture, which leverages contextual information such as demographics, occupation, and past news/social media posts. The study evaluates the performance of CADD on various datasets and demonstrates significant improvements in detection efficacy compared to traditional methods. The paper also highlights the robustness of CADD against adversarial evasion strategies.",16.08,15.793,254,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13465v1_Graph Neural Networks are Heuristics.pdf,Graph Neural Networks are Heuristics,"Yimeng Min, Carla P. Gomes",,arXiv:2601.13465v1,"Graph Neural Networks, Heuristics, Combinatorial Optimization, Travelling Salesman Problem, Inductive Bias, Non-autoregressive Model, Dropout, Snapshot Ensembling, Gumbel-Sinkhorn Relaxation","This paper demonstrates that a single training trajectory can transform a graph neural network into an unsupervised heuristic for combinatorial optimization, specifically focusing on the Travelling Salesman Problem (TSP). By encoding global structural constraints as an inductive bias, a non-autoregressive model can generate solutions via direct forward passes without the need for search, supervision, or sequential decision-making. At inference time, dropout and snapshot ensembling enable a single model to act as an implicit ensemble, reducing optimality gaps through increased solution diversity. The results suggest that graph neural networks can internalize global combinatorial structure and function as strong, learned heuristics, reframing the role of learning in combinatorial optimization from augmenting classical algorithms to directly instantiating new heuristics.",17.49,16.754,293,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13474v1_Preconditioning Benefits of Spectral Orthogonaliza.pdf,Preconditioning Benefits of Spectral Orthogonalization in Muon,"Jianhao Ma, Yu Huang, Yuejie Chi, Yuxin Chen",,arXiv:2601.13474v1,"Muons, optimization, spectral orthogonalization, large language models, matrix factorization, in-context learning, linear transformers","The Muon optimizer, a matrix-structured algorithm leveraging spectral orthogonalization of gradients, is a milestone in the pretraining of large language models. This paper studies the effectiveness of a simplified variant of Muon through two case studies: matrix factorization and in-context learning of linear transformers. It proves that simplified Muon converges linearly with iteration complexities independent of the relevant condition number, outperforming gradient descent and Adam. The analysis reveals that Muon dynamics decouple into independent scalar sequences in the spectral domain, each exhibiting similar convergence behavior. The theory formalizes the preconditioning effect induced by spectral orthogonalization, offering insight into Muon’s effectiveness in matrix optimization problems and potentially beyond.",18.02,14.925,269,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13476v1_A Unified Variational Imputation Framework for Ele.pdf,A Unified Variational Imputation Framework for Electric Vehicle Charging Data Using Retrieval-Augmented Language Model,"Jinhao Li, Hao Wang",,,"Electric vehicle, data imputation, charging demand, large language model, retrieval-augmented generation","The reliability of data-driven applications in electric vehicle (EV) infrastructure, such as charging demand forecasting, depends on complete, high-quality charging data. However, real-world EV datasets often have missing records, and existing imputation methods struggle with the complex, multimodal context of charging data. This work introduces a novel Probabilistic variational imputation framework leveraging large language models and retrieval-augmented memory (PRAIM). PRAIM encodes heterogeneous data into a unified representation, dynamically enhanced by retrieval-augmented memory, enabling a single imputation model to address data sparsity. Experiments on four public datasets show that PRAIM outperforms established baselines in imputation accuracy and preserving the original data’s statistical distribution, improving downstream forecasting performance.",16.48,14.325,236,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13481v1_Towards Efficient and Robust Linguistic Emotion Di.pdf,Towards Efficient and Robust Linguistic Emotion Diagnosis for Mental Health via Multi-Agent Instruction Refinement,"Jian Zhang, Zhangqi Wang, Zhiyuan Wang, Weiping Fu, Yu He, Haiping Zhu, Qika Lin, Jun Liu",,,"Linguistic Emotion Diagnosis, Emotional Comorbidity, Inefficient Exploration, Automated Prompt Optimization, Multi-Agent Collaboration, Medical Language Processing, Trustworthy Artificial Intelligence","This paper addresses the challenges of diagnosing emotions in mental health contexts using linguistic expressions. It highlights the limitations of existing methods in handling emotional comorbidity and inefficient exploration of clinically relevant cues. The authors propose APOLO, a framework that uses a multi-agent system to optimize prompt design for large language models (LLMs). APOLO models instruction refinement as a Partially Observable Markov Decision Process (POMDP) and employs a closed-loop design with Planner, Teacher, Critic, Student, and Target roles to enhance diagnostic accuracy and robustness. Experimental results show improvements across domain-specific benchmarks, offering a scalable paradigm for trustworthy LLM applications in mental healthcare.",17.64,16.436,290,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13487v1_The Hidden Toll of Social Media News Causal Effect.pdf,The Hidden Toll of Social Media News: Causal Effects on Psychosocial Wellbeing,"Olivia Pal, Agam Goyal, Eshwar Chandrasekharan, Koustuv Saha",,,"social media, news consumption, psychosocial wellbeing, quasi-experimental study, propensity score analysis, affective outcomes, behavioral outcomes, cognitive outcomes, news engagement, social interaction, news effects","News consumption on social media has become ubiquitous, yet how different forms of engagement shape psychosocial outcomes remains unclear. This study leverages a large-scale dataset of approximately 26 million posts and 45 million comments on the Bluesky platform, conducting a quasi-experimental study by matching 81,345 treated users exposed to Newsfeeds with 83,711 control users using stratified propensity score analysis. The study examines psychosocial wellbeing in terms of affective, behavioral, and cognitive outcomes. Findings reveal that news engagement produces systematic trade-offs: increased depression, stress, and anxiety, yet decreased loneliness and increased social interaction on the platform. Regression models show that Newsfeed bookmarking is associated with greater psychosocial deterioration compared to commenting or quoting, with magnitude differences exceeding tenfold. These per-engagement effects accumulate with repeated exposure, showing significant psychosocial impacts. The study extends theories of news effects beyond crisis-centric frameworks by demonstrating that routine consumption creates distinct psychological dynamics depending on engagement type, and bears implications for tools and interventions for mitigating the psychosocial costs of news consumption on social media.",19.03,19.707,375,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13508v1_CatMaster An Agentic Autonomous System for Computa.pdf,CatMaster: An Agentic Autonomous System for Computational Heterogeneous Catalysis Research,"Honghao Chen, Jiangjie Qiu, Yi Shen Tew, Xiaonan Wang",,2601.13508v1,"Density functional theory, computational heterogeneous catalysis, large-language-model, workflow, DFT calculations, autonomous system","Density functional theory (DFT) is widely used to connect atomic structure with catalytic behavior, but computational heterogeneous catalysis studies often require long workflows that are costly, iterative, and sensitive to setup choices. Besides the intrinsic cost and accuracy limits of first-principles calculations, practical workflow issues such as keeping references consistent, preparing many related inputs, recovering from failed runs on computing clusters, and maintaining a complete record of what was done, can slow down projects and make results difficult to reproduce or extend. Here we present CatMaster, a large-language-model (LLM)-driven agent system that turns natural language requests into complete calculation workspaces, including structures, inputs, outputs, logs, and a concise run record. CatMaster maintains a persistent project record of key facts, constraints, and file pointers to support inspection and restartability. It is paired with a multi-fidelity tool library that covers rapid surrogate relaxations and high-fidelity DFT calculations for validation when needed. We demonstrate CatMaster on four demonstrations of increasing complexity: an O2 spin-state check with remote execution, BCC Fe surface energies with a protocol-sensitivity study and CO adsorption site ranking, high-throughput Pt–Ni–Cu alloy screening.",20.88,17.191,359,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13515v1_Automatic Adjustment of HPA Parameters and Attack .pdf,Automatic Adjustment of HPA Parameters and Attack Prevention in Kubernetes Using Random Forests,"Huah Yong Chan, Hanlin Zhou, Jingfei Ni, Mengchun Wu, Qing Deng",,2601.13515v1,"Kubernetes, HPA, Security, Random Forest","In this paper, HTTP status codes are used as custom metrics within the HPA as the experimental scenario. By integrating the Random Forest classification algorithm from machine learning, attacks are assessed and predicted, dynamically adjusting the maximum pod parameter in the HPA to manage attack traffic. This approach enables the adjustment of HPA parameters using machine learning scripts in targeted attack scenarios while effectively managing attack traffic. All access from attacking IPs is redirected to honeypot pods, achieving a lower incidence of 5XX status codes through HPA pod adjustments under high load conditions. This method also ensures effective isolation of attack traffic, preventing excessive HPA expansion due to attacks. Additionally, experiments conducted under various conditions demonstrate the importance of setting appropriate thresholds for HPA adjustments.",18.54,14.182,263,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13518v1_AgenticRed Optimizing Agentic Systems for Automate.pdf,AGENTICRED: Optimizing Agentic Systems for Automated Red-teaming,"Jiayi Yuan, Jonathan Nöther, Natasha Jaques, Goran Radanović",,,"automated red-teaming, LLMs, in-context learning, evolutionary selection, AI safety evaluation","This paper introduces AGENTICRED, an automated pipeline that leverages LLMs' in-context learning to iteratively design and refine red-teaming systems without human intervention. AGENTICRED treats red-teaming as a system design problem, evolving agentic systems using evolutionary selection. It consistently outperforms state-of-the-art approaches, achieving high attack success rates on various models. The work highlights automated system design as a powerful paradigm for AI safety evaluation.",15.39,13.384,206,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13528v1_Eliciting Harmful Capabilities by Fine-Tuning On S.pdf,ELICITING HARMFUL CAPABILITIES BY FINE-TUNING ON SAFEGUARDED OUTPUTS,"Jackson Kaunismaa, Avery Griffin, John Hughes, Christina Q Knight, Mrinank Sharma, Erik Jones",,arXiv:2601.13528v1,"AI safety, safeguards, elicitation attacks, fine-tuning, harmful capabilities, ecosystem-level risks","Model developers implement safeguards in frontier models to prevent misuse, for example, by employing classifiers to filter dangerous outputs. This work demonstrates that even robustly safeguarded models can be used to elicit harmful capabilities in open-source models through elicitation attacks. These attacks consist of constructing prompts in adjacent domains to a target harmful task that do not request dangerous information, obtaining responses from safeguarded frontier models, and fine-tuning open-source models on these prompt-output pairs. The study evaluates these attacks within the domain of hazardous chemical synthesis and processing, showing that the attacks recover approximately 40% of the capability gap between the base open-source model and an unrestricted frontier model. The efficacy of elicitation attacks scales with the capability of the frontier model and the amount of generated fine-tuning data. This work highlights the challenge of mitigating ecosystem-level risks with output-level safeguards.",18.34,17.67,324,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13533v1_Reasoning While Recommending Entropy-Guided Latent.pdf,Reasoning While Recommending: Entropy-Guided Latent Reasoning in Generative Re-ranking Models,Changshuo Zhang,https://doi.org/XXXXXXX.XXXXXXX,,"Generative Re-ranking, Latent Reasoning, Reinforcement Learning","Reinforcement learning is crucial in generative re-ranking scenarios due to its exploration-exploitation capabilities. However, existing generative methods struggle with dynamic entropy changes in model difficulty during list generation, making it hard to capture complex preferences. This paper introduces a latent reasoning mechanism inspired by language models' reasoning capabilities, which reduces entropy in decision-making. The proposed Entropy-Guided Latent Reasoning (EGLR) recommendation model offers three core advantages: it enables real-time reasoning during generation, implements entropy-guided variable-length reasoning with dynamic temperature adjustment, and adopts a lightweight integration design for easy adaptation to existing models. Experimental results on two real-world datasets validate the model's effectiveness and its compatibility with existing generative re-ranking models to enhance performance.",16.76,14.383,241,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13534v1_MN-TSGContinuous Time Series Generation with Irreg.pdf,MN-TSG: CONTINUOUSTIMESERIESGENERATION WITH IRREGULAROBSERVATIONS,"Xu Zhang, Junwei Deng, Chang Xu, Hao Li, Jiang Bian",,arXiv:2601.13534v1,"Irregular time series, continuous time series generation, deep learning architecture","Time series generation (TSG) plays a critical role in various domains, such as healthcare. However, most existing methods assume regularly sampled observations and fixed output resolutions, which often do not align with real-world scenarios where data are irregularly sampled and sparsely observed. This mismatch is particularly problematic in applications like clinical monitoring, where irregular measurements must support downstream tasks requiring continuous and high-resolution time series. Neural Controlled Differential Equations (NCDEs) have shown potential for modeling irregular time series but face challenges in capturing complex dynamic temporal patterns and supporting continuous TSG. To address these limitations, we propose MN-TSG, a novel framework that explores Mixture-of-Experts (MoE)–based NCDEs and integrates them with existing TSG models for irregular and continuous generation tasks. The core of MN-TSG lies in a MoE-NCDE architecture with dynamically parameterized expert functions and a decoupled design that facilitates more effective optimization of MoE dynamics. Furthermore, we leverage existing TSG models to learn the joint distribution over the mixture of experts and the generated time series. This enables the framework not only to generate new samples but also to produce appropriate expert configurations tailored to each sample, thereby supporting refined continuous TSG. Extensive experiments on ten public and synthetic datasets demonstrate the effectiveness of MN-TSG, consistently outperforming strong TSG baselines on both irregular-to-regular and irregular-to-continuous generation tasks. The code is available at the link https://github.com/microsoft/TimeCraft/tree/main/MNTSG.",19.33,22.397,433,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13537v1_When Wording Steers the Evaluation Framing Bias in.pdf,When Wording Steers the Evaluation: Framing Bias in LLM Judges,"Yerin Hwang, Dongryeol Lee, Taegwan Kang, Minwoo Lee, Kyomin Jung",,,"Large Language Models, Framing Bias, LLM-based Evaluation, Prompt Framing, Psychology, Evaluation Tasks","Large language models (LLMs) are known to produce varying responses depending on prompt phrasing, indicating that subtle guidance in phrasing can steer their answers. This study investigates how deliberate prompt framing skews model judgments across four high-stakes evaluation tasks. Symmetric prompts using predicate-positive (P) and predicate-negative (¬P) constructions demonstrate significant discrepancies in model outputs. Across 14 LLM judges, clear susceptibility to framing is observed, with model families showing distinct tendencies toward agreement or rejection. These findings suggest that framing bias is a structural property of current LLM-based evaluation systems, underscoring the need for framing-aware protocols.",16.35,15.41,252,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13545v1_TruthTensor Evaluating LLMs Human Imitation throug.pdf,TRUTHTENSOR: EVALUATING LLM HUMAN IMITATION THROUGH PREDICTION MARKET DRIFT AND HOLISTIC REASONING,"Shirin Shahabi, Spencer Graham, Haruna Isah",,,"Large Language Models, LLMs, prediction markets, drift, human imitation, evaluation, robustness, calibration, real-world decision-making","Evaluating language models and AI agents remains fundamentally challenging due to static benchmarks that fail to capture real-world uncertainty, distribution shift, and the gap between isolated task accuracy and human-aligned decision-making under evolving conditions. This paper introduces TruthTensor, a novel, reproducible evaluation paradigm that measures Large Language Models (LLMs) not only as prediction engines but as human-imitation systems operating in socially-grounded, high-entropy environments. Building on forward-looking, contamination-free tasks, the framework anchors evaluation to live prediction markets and combines probabilistic scoring to provide a holistic view of model behavior. TruthTensor complements traditional correctness metrics with drift-centric diagnostics and explicit robustness checks for reproducibility. It specifies human vs. automated evaluation roles, annotation protocols, and statistical testing procedures to ensure interpretability and replicability of results. Experiments across 500+ real markets (political, economic, cultural, technological) demonstrate that models with similar forecast accuracy can diverge markedly in calibration, drift, and risk-sensitivity, underscoring the need to evaluate models along multiple axes (accuracy, calibration, narrative stability, cost, and resource efficiency). TruthTensor operationalizes modern evaluation best practices, clear hypothesis framing, careful metric selection, transparent compute/cost reporting, human-in-the-loop validation, and open, versioned evaluation contracts, to produce defensible assessments of LLMs in real-world decision contexts.",18.16,22.029,400,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13546v1_ChatAD Reasoning-Enhanced Time-Series Anomaly Dete.pdf,ChatAD: Reasoning-Enhanced Time-Series Anomaly Detection with Multi-Turn Instruction Evolution,"Hui Sun, Chang Xu, Haonan Xie, Hao Li, Yuhao Huang, Chuheng Zhang, Ming Jin, Xiaoguang Liu, Gang Wang, Jiang Bian",,,"Time-Series Anomaly Detection, LLM-driven Anomaly Detection, Multi-Turn Dialogue, Cross-Task Generalization, TS Evolution Algorithm, Kahneman-Tversky Optimization","LLM-driven Anomaly Detection (AD) enhances understanding and explanatory abilities of anomalous behaviors in Time Series (TS). Existing methods face challenges such as inadequate reasoning ability, deficient multi-turn dialogue capability, and narrow generalization. This paper proposes a multi-agent-based TS Evolution algorithm named TSEvol, introduces the AD reasoning & multi-turn dialogue Dataset TSEData-20K, and contributes the Chatbot family for AD, including ChatAD-Llama3-8B, ∼Qwen2.5-7B, and ∼Mistral-7B. Additionally, the TS Kahneman-Tversky Optimization (TKTO) is proposed to enhance ChatAD’s cross-task generalization capability. A Learning-based AD Benchmark LLADBench is also proposed to evaluate the performance of ChatAD and nine baselines across seven datasets and tasks. The three ChatAD models achieve substantial gains in accuracy, F1, and reduction in false positives. Optimized ChatAD via TKTO shows competitive performance in reasoning and cross-task generalization on classification, forecasting, and imputation.",18.39,21.147,389,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13547v1_HateXScore A Metric Suite for Evaluating Reasoning.pdf,HateXScore: A Metric Suite for Evaluating Reasoning Quality in Hate Speech Explanations,"Yujia Hu, Roy Ka-Wei Lee",,,"hate speech detection, content moderation, evaluation frameworks, reasoning quality, interpretability, transparency","Hateful speech detection is crucial for content moderation, yet current evaluation frameworks often overlook the reasoning behind why a text is deemed hateful. This paper introduces HateXScore, a four-component metric suite designed to evaluate the reasoning quality of model explanations. It assesses conclusion explicitness, faithfulness and causal grounding of quoted spans, protected group identification, and logical consistency. Evaluated on six diverse hate speech datasets, HateXScore serves as a diagnostic tool to reveal interpretability failures and annotation inconsistencies invisible to standard metrics like Accuracy or F1. Human evaluation shows strong agreement with HateXScore, validating it as a practical tool for trustworthy and transparent moderation.",15.94,13.928,222,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13558v1_Leveraging ChatGPT and Other NLP Methods for Ident.pdf,Leveraging ChatGPT and Other NLP Methods for Identifying Risk and Protective Behaviors in MSM: Social Media and Dating Apps Text Analysis,"Mehrab Beikzadeh, Chenglin Hong, Cory J Cascalheira, Callisto Boka, Majid Sarrafzadeh, Ian W Holloway",,,"machine learning, HIV risk, harmful drinking, social app, dating app, Text mining, ChatGPT, eHealth, LLM","Men who have sex with men (MSM) are at elevated risk for sexually transmitted infections and harmful drinking compared to their heterosexual counterparts. This study explores the potential of using text data from social media and dating apps to predict risk and protective behaviors among MSM. Textual data was collected with user consent and analyzed using machine learning models trained on ChatGPT embeddings, BERT embeddings, LIWC analysis, and a custom dictionary-based approach. The models showed high predictive accuracy for behaviors like monthly binge drinking and having over five sexual partners. The study concludes that text data can provide valuable insights for personalized public health interventions for MSM.",17.51,16.791,294,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13559v1_AgentGC Evolutionary Learning-based Lossless Compr.pdf,AgentGC: Evolutionary Learning-based Lossless Compression for Genomics Data with LLM-driven Multiple Agent,"Hui Sun, Yanfeng Ding, Huidong Ma, Chang Xu, Keyan Jin, Lizheng Zu, Cheng Zhong, Xiaoguang Liu, Gang Wang, Wentong Cai",,,"Genomics Data, Lossless Compression, Evolutionary Learning, Large Language Models, Multi-Agent Systems","Lossless compression has made significant advancements in Genomics Data (GD) storage, sharing, and management. Current learning-based methods are non-evolvable with problems of low-level compression modeling, limited adaptability, and user-unfriendly interface. To address these issues, the paper proposes AgentGC, the first evolutionary Agent-based GD Compressor, consisting of three layers with multi-agent named Leader and Worker. The User layer provides a user-friendly interface via Leader combined with LLM; the Cognitive layer, driven by the Leader, integrates LLM to consider joint optimization of algorithm-dataset-system, addressing the issues of low-level modeling and limited adaptability; and the Compression layer, headed by Worker, performs compression & decompression via an automated multi-knowledge learning-based compression framework. AgentGC supports three modes: CP for compression-ratio priority, TP for throughput priority, and BM for balanced mode. Compared with 14 baselines on 9 datasets, the average compression ratios gains are 16.66%, 16.11%, and 16.33%, and the throughput gains are 4.73×, 9.23×, and 9.15×, respectively.",18.48,21.433,396,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13562v1_Reasoning is a Modality.pdf,Reasoning is a Modality,"Zhiguang Liu, Yi Shang",,,"Abstraction and Reasoning Corpus, AI, reasoning, transformer block, visual reasoning, ARC tasks","The paper explores the hypothesis that reasoning is a distinct modality, separate from the low-level workspace where rules are applied. It introduces a novel role-separated transformer block to test this hypothesis on ARC tasks, achieving 62.6% accuracy on ARC-1, surpassing average human performance. The model demonstrates a more coherent rule-application structure compared to dense ViT baselines, suggesting a shift towards controller-driven reasoning.",13.81,11.727,162,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13563v1_ButterflyMoE Sub-Linear Ternary Experts via Struct.pdf,ButterflyMoE: Sub-Linear Ternary Experts via Structured Butterfly Orbits,Aryan Karmore,,,"Mixture of Experts, Memory Compression, Quantization, Butterfly Matrices, Edge Devices, Language Modeling","Linear memory scaling for storing independent expert weight matrices requires O(N·d^2) memory, which exceeds edge devices' memory budget. Current compression methods like quantization, pruning, and low-rank factorization reduce constant factors but do not resolve the scaling bottleneck. ButterflyMoE introduces a method where experts are not independent weight matrices but geometric reorientations of a shared quantized substrate. This approach achieves sub-linear memory scaling, with each expert requiring O(d^2 + N·dlogd) memory. By applying learned rotations to a shared ternary prototype, ButterflyMoE achieves a 150× memory reduction at 256 experts with negligible accuracy loss, enabling 64 experts to fit on 4GB devices compared to standard MoE's 8 experts. This method also stabilizes extreme low-bit training and reduces quantization error by 97% relative to post-training quantization.",16.87,16.597,280,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13564v1_Multi-objective fluorescent molecule design with a.pdf,Multi-objective fluorescent molecule design with a data-physics dual-driven generative framework,"Yanheng Li, Zhichen Pu, Lijiang Yang, Zehao Zhou, Yi Qin Gao",,,,,13.45,6.544,88,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13566v1_Self-Improvement as Coherence Optimization A Theor.pdf,Self-Improvement as Coherence Optimization: A Theoretical Account,"Tianyi Qiu, Ahmed Hani Ismail, Zhonghao He, Shi Feng",,arXiv:2601.13566v1,"language models, self-improvement, coherence optimization, semi-supervised learning, description-length regularization","This paper explores how language models can improve their accuracy without external supervision. Methods such as debate, bootstrap, and internal coherence maximization achieve this feat, even matching supervised finetuning performance. The paper provides a theoretical framework showing that these methods optimize coherence, defined as the joint likelihood of the model's behaviors across contexts. Coherence optimization is equivalent to description-length regularization and is optimal for semi-supervised learning when derived from a pretrained model. The theory explains why feedback-free self-improvement works and predicts its success or failure.",17.19,13.493,232,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13570v1_GeoDynamics A Geometric State-Space Neural Network.pdf,GeoDynamics: A Geometric State-Space Neural Network for Understanding Brain Dynamics on Riemannian Manifolds,"Tingting Dan, Jiaqi Ding, Guorong Wu",,2601.13570v1,"state-space models, deep learning, functional neuroimaging, Riemannian manifold, symmetric positive-definite matrices, functional connectivity, neuroscience, Alzheimer’s, Parkinson’s, autism, human action recognition","State-space models (SSMs) have become a cornerstone for unraveling brain dynamics, revealing how latent neural states evolve over time and give rise to observed signals. By combining deep learning’s flexibility with SSMs’ principled dynamical structure, recent studies have achieved powerful fits to functional neuroimaging data. However, most approaches still view the brain as a set of loosely connected regions or impose oversimplified network priors, falling short of a truly holistic, self-organized dynamical system perspective. Brain functional connectivity (FC) at each time point naturally forms a symmetric positive–definite (SPD) matrix, which lives on a curved Riemannian manifold rather than in Euclidean space. Capturing the trajectories of these SPD matrices is key to understanding how coordinated networks support cognition and behavior. To this end, we introduce GeoDynamics, a geometric state-space neural network that tracks latent brain-state trajectories directly on the high-dimensional SPD manifold. GeoDynamics embeds each connectivity matrix into a manifold-aware recurrent framework, learning smooth, geometry-respecting transitions that reveal task-driven state changes and early markers of Alzheimer’s, Parkinson’s, and autism. Beyond neuroscience, we validate GeoDynamics on human action recognition benchmarks (UTKinect, Florence, HDM05), demonstrating its scalability and robustness in modeling complex spatiotemporal dynamics across diverse domains.",19.7,21.113,416,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13580v1_Neural Organ Transplantation NOT Checkpoint-Based .pdf,CHECKPOINT-BASEDMODULARADAPTATION FOR TRANSFORMERMODELS,Ahmad Al-Zuraiqi,,2601.13580v1,"Modular Deep Learning, Transfer Learning, Checkpoint Transfer, Domain Adaptation, Large Language Model","We introduce Neural Organ Transplantation (NOT), a modular adaptation framework that enables trained transformer layers to function as reusable transferable checkpoints for domain adaptation. Unlike conventional fine-tuning approaches that tightly couple trained parameters to specific model instances and training data, NOT extracts contiguous layer subsets ('donor organs') from pre-trained models, trains them independently on domain-specific data, and saves them as standalone checkpoint files that can be transplanted into compatible recipient models without access to the original training data. Through experiments on three decoder-only transformer architectures spanning 124M to 20B parameters (GPT-2, TinyLlama, and GPT-OSS), we demonstrate that donor transplantation substantially outperforms existing adaptation methods, achieving an order-of-magnitude improvement in perplexity over LoRA while training significantly faster. The method exhibits position dependence, with early insertion positions yielding optimal results. Cross-domain transfer at billion-parameter scale reveals unexpected regularization benefits. These findings demonstrate that transformer middle layers can support efficient modular transfer for decoder-only architectures, enabling privacy-preserving expertise sharing through checkpoint distribution. We note that this approach is currently limited to decoder-only models; preliminary experiments on encoder-based architectures show reduced effectiveness.",20.56,16.437,338,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13581v1_SCRIPTMIND Crime Script Inference and Cognitive Ev.pdf,Crime Script Inference and Cognitive Evaluation for LLM-based Social Engineering Scam Detection System,"Heedou Kim, Changsik Kim, Sanghwa Shin, Jaewoo Kang",,,"Social engineering scams, Large Language Models, Scam detection, Cognitive evaluation, Crime script inference","Social engineering scams increasingly employ personalized, multi-turn deception, exposing the limits of traditional detection methods. While Large Language Models (LLMs) show promise in identifying deception, their cognitive assistance potential remains underexplored. This paper proposes SCRIPTMIND, an integrated framework for LLM-based scam detection that bridges automated reasoning and human cognition. It comprises three components: the Crime Script Inference Task (CSIT) for scam reasoning, the Crime Script–Aware Inference Dataset (CSID) for fine-tuning small LLMs, and the Cognitive Simulation-based Evaluation of Social Engineering Defense (CSED) for assessing real-time cognitive impact. Using 571 Korean phone scam cases, the study built 22,712 structured scammer-sequence training instances. Experimental results show that the 11B small LLM fine-tuned with SCRIPTMIND outperformed GPT-4o by 13%, achieving superior performance over commercial models in detection accuracy, false-positive reduction, scammer utterance prediction, and rationale quality. Moreover, in phone scam simulation experiments, it significantly enhanced and sustained users’ suspicion levels, improving their cognitive awareness of scams. SCRIPTMIND represents a step toward human-centered, cognitively adaptive LLMs for scam defense.",18.54,19.683,365,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13588v1_TREX Tokenizer Regression for Optimal Data Mixture.pdf,Tokenizer Regression for Optimal Data Mixture,"Inho Won, Hangyeol Yoo, Minkyung Cho, Jungyeul Park, Hoyun Song, KyungTae Lim",,,"tokenizer, multilingual, large language models, compression performance, data mixture, regression-based framework","Building effective tokenizers for multilingual Large Language Models (LLMs) requires careful control over language-specific data mixtures. Existing approaches rely on heuristics or costly large-scale searches to determine optimal language ratios. This work introduces Tokenizer Regression for Optimal Data Mixture (TREX), a regression-based framework that efficiently predicts the optimal data mixture for tokenizer training. TREX trains small-scale proxy tokenizers on random mixtures, gathers their compression statistics, and learns to predict compression performance from data mixtures. This learned model enables scalable mixture search before large-scale tokenizer training, mitigating the accuracy-cost trade-off in multilingual tokenizer design. Tokenizers trained with TREX’s predicted mixtures outperform mixtures based on LLaMA3 and uniform distributions by up to 12% in both in- and out-of-distribution compression efficiency, demonstrating strong scalability, robustness, and practical effectiveness.",17.26,17.618,304,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13589v1_Motion-to-Response Content Generation via Multi-Ag.pdf,MOTION-TO-RESPONSE CONTENT GENERATION VIA MULTI-AGENT AI SYSTEM WITH REAL-TIME SAFETY VERIFICATION,HyeYoung Lee,,arXiv:2601.13589v1,"Speech Emotion Recognition, Multi-Agent Systems, Content Generation, Safety Verification, On-Device AI","This paper proposes a multi-agent artificial intelligence system that generates response-oriented media content in real time based on audio-derived emotional signals. Unlike conventional speech emotion recognition studies that focus primarily on classification accuracy, our approach emphasizes the transformation of inferred emotional states into safe, age-appropriate, and controllable response content through a structured pipeline of specialized AI agents. The proposed system comprises four cooperative agents: (1) an Emotion Recognition Agent with CNN-based acoustic feature extraction, (2) a Response Policy Decision Agent for mapping emotions to response modes, (3) a Content Parameter Generation Agent for producing media control parameters, and (4) a Safety Verification Agent enforcing age-appropriateness and stimulation constraints. We introduce an explicit safety verification loop that filters generated content before output, ensuring compliance with predefined rules. Experimental results on public datasets demonstrate that the system achieves 73.2% emotion recognition accuracy, 89.4% response mode consistency, and 100% safety compliance while maintaining sub-100ms inference latency suitable for on-device deployment. The modular architecture enables interpretability and extensibility, making it applicable to child-adjacent media, therapeutic applications, and emotionally responsive smart devices.",19.4,17.938,348,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13590v1_Vulnerability of LLMs Belief Systems LLMs Belief R.pdf,Vulnerability of LLMs’ Belief Systems? LLMs Belief Resistance Check Through Strategic Persuasive Conversation Interventions,"Fan Huang, Haewoon Kwak, Jisun An",,,"Large Language Models, persuasion, belief stability, meta-cognition prompting, adversarial fine-tuning, SMCR framework","Large Language Models (LLMs) are increasingly used in question-answering tasks but are susceptible to persuasion, potentially adopting counterfactual beliefs. This study evaluates LLM susceptibility to persuasion using the Source–Message–Channel–Receiver (SMCR) framework across five LLMs and three domains: factual knowledge, medical QA, and social bias. The study analyzes how different persuasive strategies affect belief stability and examines the impact of meta-cognition prompting on resistance to persuasion. Results indicate that smaller models show high compliance, with significant belief changes occurring early in interactions. Meta-cognition prompting increases vulnerability by accelerating belief erosion. Adversarial fine-tuning shows mixed results, with some models achieving substantial robustness. The findings highlight model-dependent limits of current robustness interventions and provide guidance for developing more trustworthy LLMs.",17.44,16.629,290,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13591v1_DSAEval Evaluating Data Science Agents on a Wide R.pdf,DSAEval: Evaluating Data Science Agents on a Wide Range of Real-World Data Science Problems,"Maojun Sun, Yifei Xie, Yue Wu, Ruijian Han, Binyan Jiang, Defeng Sun, Yancheng Yuan, Jian Huang",,,"data science agents, evaluation, real-world problems, large language models, multimodal perception, multi-query interactions, multi-dimensional evaluation","Recent LLM-based data agents aim to automate data science tasks ranging from data analysis to deep learning. However, the open-ended nature of real-world data science problems, which often span multiple taxonomies and lack standard answers, poses a significant challenge for evaluation. To address this, we introduce DSAEval, a benchmark comprising 641 real-world data science problems grounded in 285 diverse datasets, covering both structured and unstructured data (e.g., vision and text). DSAEval incorporates three distinctive features: (1) Multi-modal Environment Perception, which enables agents to interpret observations from multiple modalities including text and vision; (2) Multi-Query Interactions, which mirror the iterative and cumulative nature of real-world data science projects; and (3) Multi-Dimensional Evaluation, which provides a holistic assessment across reasoning, code, and results. We systematically evaluate 11 advanced agentic LLMs using DSAEval. Our results show that Claude-Sonnet-4.5 achieves the strongest overall performance, GPT-5.2 is the most efficient, and MiMo-V2-Flash is the most cost-effective. We further demonstrate that multimodal perception consistently improves performance on vision-related tasks, with gains ranging from 2.04% to 11.30%. Overall, while current data science agents perform well on structured data and routine data analysis workflows, substantial challenges remain in unstructured domains. Finally, we offer critical insights and outline future research directions to advance the development of data science agents.",19.6,23.318,457,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13592v1_Machine learning based radiative parameterization .pdf,Machine learning based radiative parameterization scheme and its performance in operational reforecast experiments,"Jing Hao, Xiao Sa, Li Haoyu, Xiao Huadong, Xue Wei",,,"Machine learning, Radiation, Hybrid model, Operational reforecast experiments","Radiation is typically the most time-consuming physical process in numerical models. This study investigates critical limitations inherent to hybrid forecasting frameworks that embed deep neural networks into numerical prediction models, focusing on coupling compatibility and long-term integration stability. A residual convolutional neural network approximates the Rapid Radiative Transfer Model for General Circulation Models (RRTMG) within the global operational system of China Meteorological Administration. An offline training and online coupling approach is adopted, generating a comprehensive dataset through model simulations. The dataset is enhanced via experience replay and additional output constraints based on physical significance. A LibTorch-based coupling method is utilized for real-time operational computations. The hybrid model performs ten-day integrated forecasts, and a two-month operational reforecast experiment demonstrates that the machine learning emulator achieves accuracy comparable to the traditional physical scheme, while accelerating computation speed by approximately eightfold.",18.28,15.374,281,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13599v1_Diffusion In Diffusion Breaking the Autoregressive.pdf,Diffusion In Diffusion: Breaking the Autoregressive Bottleneck in Block Diffusion Models,"Linrui Ma, Yufei Cui, Kai Han, Yunhe Wang",,2601.13599v1,"block diffusion models, autoregressive models, discrete diffusion models, language modeling, KV caching, inference latency, generative perplexity, OpenWebText dataset","Block diffusion language models combine autoregressive and diffusion paradigms, but suffer from irreversibility and limited global planning due to unidirectional block dependencies. The proposed DIFFUSION INDIFFUSION framework addresses these issues by generating drafts with small blocks and refining them through global bidirectional diffusion. This approach reduces generative perplexity significantly, setting a new benchmark for discrete diffusion models on the OpenWebText dataset, while using only 26% of the fine-tuning budget of baseline models.",16.56,14.677,243,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13600v1_Foundations of Global Consistency Checking with No.pdf,Foundations of Global Consistency Checking with Noisy LLM Oracles,"Paul He, Elke Kirschbaum, Shiva Kasiviswanathan",,,"global consistency, natural-language facts, Large Language Models, minimal inconsistent subsets, consistency checking, fact-checking, knowledge base construction","Ensuring global consistency of natural-language facts is crucial for tasks like fact-checking, summarization, and knowledge base construction. While Large Language Models (LLMs) can assess small subsets of facts, their judgments are noisy, and pairwise checks are insufficient for global coherence. This paper formalizes the problem, showing that verifying global consistency requires exponentially many oracle queries in the worst case. An adaptive divide-and-conquer algorithm is proposed to identify minimal inconsistent subsets (MUSes) of facts and compute minimal repairs through hitting-sets, achieving low-degree polynomial query complexity. Experiments demonstrate the method's efficiency in detecting and localizing inconsistencies, providing a scalable framework for linguistic consistency verification with LLM-based evaluators.",16.74,15.47,259,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13614v1_CauScientist Teaching LLMs to Respect Data for Cau.pdf,Teaching LLMs to Respect Data for Causal Discovery,"Bo Peng, Sirui Chen, Lei Xu, Chaochao Lu",,arXiv:2601.13614v1,"LLM, data-driven algorithm, dataset samples, variable information, algorithm limitations, assumption violation, causal discovery, statistical indistinguishability, modeling assumptions, distribution shift, semantic knowledge, data constraints","Causal discovery is fundamental to scientific understanding and reliable decision-making. Existing approaches face critical limitations: purely data-driven methods suffer from statistical indistinguishability and modeling assumptions, while recent LLM-based methods either ignore statistical evidence or incorporate unverified priors that can mislead results. To address these issues, the authors propose CauScientist, a collaborative framework that synergizes LLMs as hypothesis-generating 'data scientists' with probabilistic statistics as rigorous 'verifiers'. CauScientist employs hybrid initialization to select superior starting graphs, iteratively refines structures through LLM-proposed modifications validated by statistical criteria, and maintains error memory to guide efficient search space. Experiments demonstrate that CauScientist substantially outperforms purely data-driven baselines, achieving up to 53.8% F1 score improvement and enhancing recall from 35.0% to 100.0%. Notably, while standalone LLM performance degrades with graph complexity, CauScientist reduces structural hamming distance (SHD) by 44.0% compared to Qwen3-32B on 37-node graphs.",18.68,20.399,381,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13622v1_CARPE Context-Aware Image Representation Prioritiz.pdf,CARPE: CONTEXT-AWARE IMAGE REPRESENTATION PRIORITIZATION VIA ENSEMBLE FOR LARGE VISION-LANGUAGE MODELS,"Donghee Lee, Rui Cai, Zhe Zhao",,2601.13622v1,"Large Vision-Language Models, image classification, vision encoders, context-aware ensemble, generalization, vision-language benchmarks","Recent advancements in Large Vision-Language Models (LVLMs) have pushed them closer to becoming general-purpose assistants. Despite their strong performance, LVLMs still struggle with vision-centric tasks such as image classification, underperforming compared to their base vision encoders, which are often CLIP-based models. To address this limitation, we propose Context-Aware Image Representation Prioritization via Ensemble (CARPE), a novel, model-agnostic framework which introduces vision-integration layers and a context-aware ensemble strategy to identify when to prioritize image representations or rely on the reasoning capabilities of the language model. This design enhances the model’s ability to adaptively weight visual and textual modalities and enables the model to capture various aspects of image representations, leading to consistent improvements in generalization across classification and vision-language benchmarks. Extensive experiments demonstrate that CARPE not only improves performance on image classification benchmarks but also enhances results across various vision-language benchmarks. Finally, CARPE is designed to be effectively integrated with most open-source LVLMs that consist of a vision encoder and a language model, ensuring its adaptability across diverse architectures.",18.74,17.766,333,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13632v1_Resilient Routing Risk-Aware Dynamic Routing in Sm.pdf,Resilient Routing: Risk-Aware Dynamic Routing in Smart Logistics via Spatiotemporal Graph Learning,"Zhiming Xue, Sichen Zhao, Yalun Qi, Xianling Zeng, Zihan Yu",,,"Smart Logistics, Graph Neural Network, Dynamic Routing, Spatiotemporal modeling, Supply Chain Resilience","With the rapid development of the e-commerce industry, the logistics network is experiencing unprecedented pressure. Traditional static routing strategies are often unable to tolerate traffic congestion and fluctuating retail demand. This paper proposes a Risk-Aware Dynamic Routing (RADR) framework integrating Spatiotemporal Graph Neural Networks (ST-GNN) with combinatorial optimization. A logistics topology graph is constructed using discrete GPS data and spatial clustering methods. A hybrid deep learning model combining Graph Convolutional Network (GCN) and Gated Recurrent Unit (GRU) is used to predict future congestion risks by extracting spatial correlations and temporal dependencies. These predictions are integrated into a dynamic edge weight mechanism for path planning. The framework is evaluated on the Smart Logistics Dataset 2024, containing real-world IoT sensor data. Results show that the RADR algorithm significantly enhances supply chain resilience, reducing congestion risk exposure by 19.3% with only a 2.1% increase in transportation distance, effectively balancing delivery efficiency and operational safety.",18.4,17.937,330,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13645v1_Quadratic Upper Bound for Boosting Robustness.pdf,Quadratic Upper Bound for Boosting Robustness,"Euijin You, Hyang-Won Lee",,,"Fast adversarial training, robustness, adversarial attacks, loss function, quadratic upper bound, adversarial training, projected gradient descent, catastrophic overfitting","Fast adversarial training (FAT) aims to enhance the robustness of models against adversarial attacks with reduced training time, but often suffers from compromised robustness due to insufficient exploration of adversarial space. This paper develops a loss function to improve robustness in FAT without requiring stronger inner maximization. A quadratic upper bound (QUB) on the adversarial training (AT) loss function is derived and utilized with existing FAT methods. Experimental results show significant improvement in robustness when applying QUB loss to existing methods, likely due to the smoothened loss landscape of the resulting models.",16.04,14.897,239,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13647v1_Fusion Segment Transformer Bi-Directional Attentio.pdf,FUSION SEGMENT TRANSFORMER: BI-DIRECTIONAL ATTENTION GUIDED FUSION NETWORK FOR AI GENERATED MUSIC DETECTION,"Yumin Kim, Seonghyeon Go",,,"AI-generated music detection, Full-audio segment detection, Musical structure analysis, Cross-modal fusion layer, Music representation","With the rise of generative AI technology, the creation and deployment of AI-generated music have become easier, raising concerns about copyright and ownership issues. Existing methods primarily focus on short-audio detection, but full-audio detection, which requires modeling long-term structure and context, remains underexplored. This paper proposes an improved Segment Transformer, termed the Fusion Segment Transformer, which integrates content and structural information through a Gated Fusion Layer to capture long-term context. Experiments on the SONICS and AIME datasets demonstrate that this approach outperforms previous models and recent baselines, achieving state-of-the-art results in AI-generated music detection.",16.33,14.026,229,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13649v1_Fairness or Fluency An Investigation into Language.pdf,Fairness or Fluency? An Investigation into Language Bias of Pairwise LLM-as-a-Judge,"Xiaolin Zhou, Zheng Luo, Yicheng Gao, Qixuan Chen, Xiyang Hu, Yue Zhao, Ruishan Liu",,,"LLM-as-a-judge, language bias, performance disparity, pairwise comparison, natural language processing","This paper investigates language bias in LLM-as-a-judge applications, focusing on performance disparities between languages and biases towards major languages. It identifies significant performance disparities across language families, with European languages outperforming African languages, especially in culturally-related subjects. The study also finds that models tend to favor English in inter-language comparisons, influenced more by the answer language than the question language. The research explores whether language bias is caused by low-perplexity bias and concludes that while there is a slight correlation, language bias cannot be fully explained by perplexity alone.",16.23,15.344,249,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13655v1_Why Does the LLM Stop Computing An Empirical Study.pdf,Why Does the LLM Stop Computing: An Empirical Study of User-Reported Failures in Open-Source LLMs,"Guangba Yu, Zirui Wang, Yujie Huang, Renyi Zhong, Yuedong Zhong, Yilun Wang, Michael R. Lyu",https://doi.org/XXXXXXX.XXXXXXX,,"Large Language Models, Failure Analysis, Empirical Study, Software reliability, Software usability, Empirical studies","The democratization of open-source Large Language Models (LLMs) allows users to fine-tune and deploy models on local infrastructure but exposes them to a 'First Mile' deployment landscape. Unlike black-box API consumption, the reliability of user-managed orchestration remains a critical blind spot. To bridge this gap, we conduct the first large-scale empirical study of 705 real-world failures from the open-source DeepSeek, Llama, and Qwen ecosystems. Our analysis reveals a paradigm shift: white-box orchestration relocates the reliability bottleneck from model algorithmic defects to the systemic fragility of the deployment stack. We identify three key phenomena: (1) Diagnostic Divergence: runtime crashes distinctively signal infrastructure friction, whereas incorrect functionality serves as a signature for internal tokenizer defects. (2) Systemic Homogeneity: Root causes converge across divergent series, confirming reliability barriers are inherent to the shared ecosystem rather than specific architectures. (3) Lifecycle Escalation: Barriers escalate from intrinsic configuration struggles during fine-tuning to compounded environmental incompatibilities during inference. Supported by our publicly available dataset, these insights provide actionable guidance for enhancing the reliability of the LLM landscape.",18.72,21.204,397,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13657v1_Communication-Free Collective Navigation for a Swa.pdf,Communication-Free Collective Navigation for a Swarm of UAVs via LiDAR-Based Deep Reinforcement Learning,"Myong-Yol Choi, Hankyoul Ko, Hanse Cho, Changseung Kim, Seunghwan Kim, Jaemin Seo, Hyondong Oh",,,"Multi-robot systems, collective navigation, sensor-based control, deep reinforcement learning","This paper presents a deep reinforcement learning (DRL) based controller for collective navigation of unmanned aerial vehicle (UAV) swarms in communication-denied environments, enabling robust operation in complex, obstacle-rich environments. Inspired by biological swarms where informed individuals guide groups without explicit communication, we employ an implicit leader-follower framework. In this paradigm, only the leader possesses goal information, while follower UAVs learn robust policies using only onboard LiDAR sensing, without requiring any inter-agent communication or leader identification. Our system utilizes LiDAR point clustering and an extended Kalman filter for stable neighbor tracking, providing reliable perception independent of external positioning systems. The core of our approach is a DRL controller, trained in GPU-accelerated Nvidia Isaac Sim, that enables followers to learn complex emergent behaviors—balancing flocking and obstacle avoidance—using only local perception. This allows the swarm to implicitly follow the leader while robustly addressing perceptual challenges such as occlusion and limited field-of-view. The robustness and sim-to-real transfer of our approach are confirmed through extensive simulations and challenging real-world experiments with a swarm of five UAVs, which successfully demonstrated collective navigation across diverse indoor and outdoor environments without any communication or external localization.",18.59,19.256,358,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13659v1_Temporal-Spatial Decouple before Act Disentangled .pdf,TEMPORAL-SPATIAL DECOUPLE BEFORE ACT: DISENTANGLED REPRESENTATION LEARNING FOR MULTIMODAL SENTIMENT ANALYSIS,"Chunlei Meng, Ziyang Zhou, Lucas He, Xiaojing Du, Chun Ouyang, Zhongxue Gan",,,"Multimodal Sentiment Analysis, Temporal-Spatial Decoupling, Representation Learning","Multimodal Sentiment Analysis integrates Linguistic, Visual, and Acoustic evidence to infer sentiment. Mainstream approaches based on modality-invariant and modality-specific factorization or on complex fusion still rely on spatiotemporal mixed modeling, which ignores spatiotemporal heterogeneity, leading to information asymmetry and limited performance. The proposed TSDA (Temporal-Spatial Decouple before Act) explicitly decouples each modality into temporal dynamics and spatial structural context before any interaction. For every modality, a temporal encoder and a spatial encoder project signals into separate temporal and spatial bodies. Factor-Consistent Cross-Modal Alignment aligns temporal features with their temporal counterparts across modalities, and spatial features with their spatial counterparts. Factor-specific supervision and decorrelation regularization reduce cross-factor leakage while preserving complementarity. A Gated Recouple module subsequently recouples the aligned streams for the task. Extensive experiments show that TSDA outperforms baselines, and ablation analysis confirms the necessity and interpretability of the design.",18.62,18.585,346,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13671v1_The Orchestration of Multi-Agent Systems Architect.pdf,"The Orchestration of Multi-Agent Systems: Architectures, Protocols, and Enterprise Adoption","Apoorva Adimulam, Rajesh Gupta, Sumit Kumar",,,"Agent orchestration, Agent-to-Agent protocol (A2A), dynamic task allocation, Model Context Protocol (MCP), multi-agent systems, observability, state management, system governance","Orchestrated multi-agent systems represent the next stage in the evolution of artificial intelligence, where autonomous agents collaborate through structured coordination and communication to achieve complex, shared objectives. This paper consolidates and formalizes the technical composition of such systems, presenting a unified architectural framework that integrates planning, policy enforcement, state management, and quality operations into a coherent orchestration layer. Another primary contribution of this work is the in-depth technical delineation of two complementary communication protocols—the Model Context Protocol, which standardizes how agents access external tools and contextual data, and the Agent-to-Agent protocol, which governs peer coordination, negotiation, and delegation. Together, these protocols establish an interoperable communication substrate that enables scalable, auditable, and policy-compliant reasoning across distributed agent collectives. Beyond protocol design, the paper details how orchestration logic, governance frameworks, and observability mechanisms collectively sustain system coherence, transparency, and accountability. By synthesizing these elements into a cohesive technical blueprint, this paper provides comprehensive treatments of orchestrated multi-agent systems—bridging conceptual architectures with implementation-ready design principles for enterprise-scale AI ecosystems.",18.43,19.208,354,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13684v1_HeteroCache A Dynamic Retrieval Approach to Hetero.pdf,HeteroCache: A Dynamic Retrieval Approach to Heterogeneous KV Cache,"Zhiyuan Shi, Qibo Qiu, Feng Xue, Zhonglin Jiang, Li Yu, Jian Jiang, Xiaofei He, Wenxiao Wang",,,"KV cache, LLM inference, long-context tasks, dynamic compression, attention drift, hierarchical storage, Transformer-based models","The linear memory growth of the KV cache poses a significant bottleneck for LLM inference in long-context tasks. Existing static compression methods often fail to preserve globally important information due to overlooking the attention drift phenomenon, where token significance evolves dynamically. HeteroCache, a training-free dynamic compression framework, addresses these issues by categorizing attention heads based on stability and redundancy, applying a fine-grained weighting strategy, and employing a hierarchical storage mechanism to monitor attention shifts and trigger asynchronous, on-demand retrieval of contexts from the CPU. Experiments demonstrate that HeteroCache achieves state-of-the-art performance on multiple long-context benchmarks and accelerates decoding by up to 3× compared to the original model in the 224K context.",17.44,16.859,294,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13687v1_Understanding Mental States to Guide Social Influe.pdf,Understanding Mental States to Guide Social Influence in Multi-Person Group Dialogue,"Zhichao Liang, Satoshi Nakamura",,,"Theory of Mind, Social Influence, Multi-Person Dialogue, Language Models, SocialMindChange Benchmark","This paper introduces the SocialMindChange benchmark, which advances the dynamic Theory of Mind (ToM) by shifting from merely tracking mental states to actively influencing them in social interactions. Unlike existing benchmarks that place language models in a passive role, SocialMindChange requires models to generate dialogue across multiple scenes to achieve a goal while maintaining consistency with evolving mental states of all participants. The benchmark includes higher-order states and is validated for realism and quality, covering 1,200 social contexts, 6,000 scenarios, and over 90,000 questions. Evaluations on ten state-of-the-art large language models (LLMs) reveal a performance gap of 54.2% below human performance, indicating challenges in maintaining and changing mental-state representations across extended interactions.",16.09,14.667,236,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13693v1_End-to-End Reverse Screening Identifies Protein Ta.pdf,End-to-End Reverse Screening Identifies Protein Targets of Small Molecules Using HelixFold3,"Shengjie Xu, Xianbin Ye, Mengran Zhu, Xiaonan Zhang, Shanzhuo Zhang, Xiaomin Fang",,2601.13693v1,"Reverse screening, Target identification, Biomolecular structure prediction, HelixFold3","Identifying protein targets for small molecules, or reverse screening, is essential for understanding drug action, guiding compound repurposing, predicting off-target effects, and elucidating the molecular mechanisms of bioactive compounds. Despite its critical role, reverse screening remains challenging because accurately capturing interactions between a small molecule and structurally diverse proteins is inherently complex, and conventional step-wise workflows often propagate errors across decoupled steps such as target structure modeling, pocket identification, docking, and scoring. Here, we present an end-to-end reverse screening strategy leveraging HelixFold3, a high-accuracy biomolecular structure prediction model akin to AlphaFold3, which simultaneously models the folding of proteins from a protein library and the docking of small-molecule ligands within a unified framework. We validate this approach on a diverse and representative set of approximately one hundred small molecules. Compared with conventional reverse docking, our method improves screening accuracy and demonstrates enhanced structural fidelity, binding-site precision, and target prioritization. By systematically linking small molecules to their protein targets, this framework establishes a scalable and straightforward platform for dissecting molecular mechanisms, exploring off-target interactions, and supporting rational drug discovery.",20.21,18.013,364,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13697v1_Uncertainty-Aware Gradient Signal-to-Noise Data Se.pdf,Uncertainty-Aware Gradient Signal-to-Noise Data Selection for Instruction Tuning,"Zhihang Yuan, Chengyu Yue, Long Huang, Litu Ou, Lei Shi",,,"instruction tuning, large language models, data selection, gradient signal-to-noise ratio, uncertainty-aware","Instruction tuning is a standard paradigm for adapting large language models (LLMs), but modern instruction datasets are large, noisy, and redundant, making full-data fine-tuning costly and often unnecessary. Existing data selection methods either build expensive gradient datastores or assign static scores from a weak proxy, largely ignoring evolving uncertainty, and thus missing a key source of LLM interpretability. We propose GRADFILTERING, an objective-agnostic, uncertainty-aware data selection framework that utilizes a small GPT-2 proxy with a LoRA ensemble and aggregates per-example gradients into a Gradient Signal-to-Noise Ratio (G-SNR) utility. Our method matches or surpasses random subsets and strong baselines in most LLM-as-a-judge evaluations as well as in human assessment. Moreover, GRADFILTERING-selected subsets converge faster than competitive filters under the same compute budget, reflecting the benefit of uncertainty-aware scoring.",17.01,16.048,273,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13698v1_Does Privacy Always Harm Fairness Data-Dependent T.pdf,Does Privacy Always Harm Fairness? Data-Dependent Trade-offs via Chernoff Information Neural Estimation,"Arjun Nichani, Hsiang Hsu, Chun-Fu (Richard) Chen, Haewon Jeong",,2601.13698v1,"fairness, privacy, machine learning, Chernoff Information, data-dependent trade-offs","Fairness and privacy are crucial for trustworthy machine learning, yet their relationship is underexplored. This paper uses Chernoff Information to analyze the data-dependent relationship among fairness, privacy, and accuracy. It introduces Noisy Chernoff Difference to study these aspects simultaneously, showing distinct behaviors in synthetic data. The paper also proposes a method for estimating Chernoff Information on real datasets, aiming for a unified understanding of the fairness-privacy-accuracy relationship.",15.94,13.615,217,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13704v1_Performance and Complexity Trade-off Optimization .pdf,Performance and Complexity Trade-off: Optimization of Speech Models During Training,"Esteban Gómez, Tom Backström",,,"Speech machine learning, low-complexity, voice activity detection, deep fake detection","In speech machine learning, neural network models are typically designed with fixed architectures and trained to maximize performance on task-specific metrics. However, this approach often does not optimize the trade-off between performance and computational complexity. Post hoc methods like weight quantization or model pruning are usually employed to reduce computational costs. This paper proposes a reparameterization technique based on feature noise injection, enabling joint optimization of performance and computational complexity during training using SGD-based methods. This approach allows dynamic optimization of model size for a target performance-complexity trade-off without relying on heuristic criteria. The method's effectiveness is demonstrated through three case studies, including voice activity detection and audio anti-spoofing. The code is publicly available to encourage further research.",16.86,14.001,236,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13707v1_Attention-space Contrastive Guidance for Efficient.pdf,Attention-space Contrastive Guidance for Efficient Hallucination Mitigation in LVLMs,"Yujin Jo, Sangyoon Bae, Taesup Kim",,,"hallucination mitigation, large vision–language models, contrastive guidance, self-attention layers, computational efficiency, visual evidence, language priors","Hallucinations in large vision–language models (LVLMs) often arise when language priors dominate over visual evidence, leading to object misidentification and inconsistent descriptions. This paper introduces Attention-space Contrastive Guidance (ACG), a single-pass mechanism within self-attention layers that constructs both vision–language and language-only attention paths in a single forward computation. ACG reduces over-dependence on language priors and enhances visual contributions, achieving state-of-the-art faithfulness and caption quality while reducing computational cost. Experiments on the CHAIR and POPE benchmarks demonstrate ACG's efficiency, reducing latency by up to 2× compared to prior methods.",16.54,14.392,238,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13709v1_Hidden in Plain Text Measuring LLM Deception Quali.pdf,Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games,"Christopher Kao, Vanshika Vats, James Davis",,,"large language models, natural language processing, autonomous game players, social deduction games","Large Language Model (LLM) agents are increasingly used in various applications, raising safety concerns. This paper investigates LLM deception in the Social Deduction Game (SDG) Mafia, where success relies on deceiving others through conversation. Using an asynchronous multi-agent framework, the study simulates 35 Mafia games with GPT-4o LLM agents and analyzes game transcripts with a Mafia Detector using GPT-4-Turbo. The detector's mafia prediction accuracy is compared to human games and a random baseline, showing LLMs blend in better and deceive more effectively. The study releases a dataset of LLM Mafia transcripts for future research, highlighting the sophistication and risks of LLM deception in social contexts.",16.51,15.025,248,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13710v1_Who Should Have Surgery A Comparative Study of Gen.pdf,Who Should Have Surgery? A Comparative Study of GenAI vs Supervised ML for CRS Surgical Outcome Prediction,"Sayeed Shafayet Chowdhury, Snehasis Mukhopadhyay, Shiaofen Fang, Vijay R. Ramakrishnan",,,"Chronic Rhinosinusitis, clinical decision support, generative artificial intelligence, large language models, SNOT-22, surgical outcome prediction, tabular clinical data","This study evaluates the use of supervised machine learning (ML) and generative artificial intelligence (GenAI) for predicting surgical outcomes in chronic rhinosinusitis (CRS). The study focuses on pre-operative prediction of clinically meaningful improvement, defined as a ≥8.9-point reduction in SNOT-22 at 6 months. A cohort of patients who underwent surgery was analyzed to determine if models using pre-operative clinical data could identify those likely to have poor outcomes. The best ML model (MLP) achieved 85% accuracy with superior calibration and decision-curve net benefit, while GenAI models underperformed in discrimination and calibration. GenAI justifications aligned with clinician heuristics and the MLP’s feature importance, highlighting key factors such as baseline SNOT-22, CT/endoscopy severity, polyp phenotype, and comorbidities. The study suggests an ML-first, GenAI-augmented workflow for surgical candidacy triage, enhancing transparency and shared decision-making.",18.23,19.25,351,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13717v1_Simulated Ignorance Fails A Systematic Study of LL.pdf,Simulated Ignorance Fails: A Systematic Study of LLM Behaviors on Forecasting Problems Before Model Knowledge Cutoff,"Zehan Li, Yuxuan Wang, Ali El Lahib, Ying-Jieh Xia, Xinyu Pi",,,"LLM, forecasting, Simulated Ignorance, True Ignorance, retrospective forecasting, knowledge cutoff","Evaluating LLM forecasting capabilities is constrained by a tension between prospective evaluation, which offers methodological rigor but prohibitive latency, and retrospective forecasting (RF), which faces rapidly shrinking clean evaluation data as models possess increasingly recent knowledge cutoffs. Simulated Ignorance (SI), which prompts models to suppress pre-cutoff knowledge, has emerged as a potential solution. This study systematically tests whether SI can approximate True Ignorance (TI) across 477 competition-level questions and 9 models. Findings show that SI fails systematically: cutoff instructions leave a 52% performance gap between SI and TI; chain-of-thought reasoning fails to suppress prior knowledge, even when reasoning traces contain no explicit post-cutoff references; reasoning-optimized models exhibit worse SI fidelity despite superior reasoning trace quality. These findings demonstrate that prompts cannot reliably 'rewind' model knowledge. The study concludes that RF on pre-cutoff events is methodologically flawed and recommends against using SI-based retrospective setups to benchmark forecasting capabilities.",17.08,19.79,338,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13719v1_Hierarchical Long Video Understanding with Audiovi.pdf,Hierarchical Long Video Understanding with Audiovisual Entity Cohesion and Agentic Search,"Xinlei Yin, Xiulian Peng, Xiao Li, Zhiwei Xiong, Yan Lu",,,"long video understanding, vision-language models, audiovisual entity cohesion, hierarchical video indexing, agentic search, semantic consistency, entity-level representations, structured hierarchy, dynamic retrieval, narrative reconstruction, entity tracking, temporal coherence, retrieval efficiency, multimodal reasoning","Long video understanding presents significant challenges for vision-language models due to extremely long context windows. Existing solutions relying on naive chunking strategies with retrieval-augmented generation typically suffer from information fragmentation and a loss of global coherence. This paper presents HAVEN, a unified framework for long-video understanding that enables coherent and comprehensive reasoning by integrating audiovisual entity cohesion and hierarchical video indexing with agentic search. The framework preserves semantic consistency by integrating entity-level representations across visual and auditory streams, organizing content into a structured hierarchy spanning global summary, scene, segment, and entity levels. An agentic search mechanism enables dynamic retrieval and reasoning across these layers, facilitating coherent narrative reconstruction and fine-grained entity tracking. Extensive experiments demonstrate that the method achieves good temporal coherence, entity consistency, and retrieval efficiency, establishing a new state-of-the-art with an overall accuracy of 84.1% on LVBench. Notably, it achieves outstanding performance in the challenging reasoning category, reaching 80.1%. These results highlight the effectiveness of structured, multimodal reasoning for comprehensive and context-consistent understanding of long-form videos.",19.08,20.649,394,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13722v1_OP-Bench Benchmarking Over-Personalization for Mem.pdf,OP-Bench: Benchmarking Over-Personalization for Memory-Augmented Personalized Conversational Agents,"Yulin Hu, Zimo Long, Jiahe Guo, Xingyu Sui, Xing Fu, Weixiang Zhao, Yanyan Zhao, Bing Qin",,2601.13722v1,"memory-augmented conversational agents, personalization, over-personalization, large language models, memory filtering, user interaction","Memory-augmented conversational agents enable personalized interactions using long-term user memory and have gained substantial traction. However, existing benchmarks primarily focus on whether agents can recall and apply user information, while overlooking whether such personalization is used appropriately. This work formalizes over-personalization into three types: Irrelevance, Repetition, and Sycophancy, and introduces OP-Bench, a benchmark of 1,700 verified instances constructed from long-horizon dialogue histories. Using OP-Bench, the study evaluates multiple large language models and memory-augmentation methods, finding that over-personalization is widespread when memory is introduced. The study proposes Self-ReCheck, a lightweight, model-agnostic memory filtering mechanism that mitigates over-personalization while preserving personalization performance. This work takes an initial step toward more controllable and appropriate personalization in memory-augmented dialogue systems.",18.12,18.711,339,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13734v1_Towards robust long-context understanding of large.pdf,TOWARDS ROBUST LONG-CONTEXT UNDERSTANDING OF LARGE LANGUAGE MODEL VIA ACTIVE RECAP LEARNING,Chenyu Hui,,,"LLM, Long-context understanding, Active recap learning, Recap supervision, Recap agent","This paper introduces active recap learning (ARL), a framework designed to enhance large language models (LLMs) in understanding long contexts. ARL allows models to revisit and summarize earlier content through targeted sequence construction during continued pretraining and retrospective summarization at inference. The approach involves identifying key tokens in long contexts based on loss gaps and summarizing relevant preceding paragraphs using an LLM. ARL equips models with the ability to autonomously generate and utilize these retrospective summaries during inference, establishing a recursive memory mechanism across paragraphs. Experimental results demonstrate significant improvements, with ARL achieving a 26.8% improvement on RULER and a 9.44% improvement on LongBench. ARL provides a simple yet effective continued pretraining-based approach to strengthen long-context understanding, advancing scalable memory augmentation in LLMs.",16.81,15.583,262,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13735v1_Reasoning or Fluency Dissecting Probabilistic Conf.pdf,Reasoning or Fluency? Dissecting Probabilistic Confidence in Best-of-N Selection,"Hojin Kim, Jaehyung Kim",,,"Probabilistic confidence metrics, Best-of-N selection, reasoning quality, inter-step causal dependencies, Large Language Models, Chain-of-Thought prompting, reinforcement learning, probabilistic confidence metrics, contrastive causality metric","Probabilistic confidence metrics are increasingly used as proxies for reasoning quality in Best-of-N selection, assuming higher confidence indicates higher reasoning fidelity. This study challenges this assumption by examining whether these metrics capture necessary inter-step causal dependencies for valid reasoning. Three classes of inter-step causality perturbations are introduced to disrupt dependencies while maintaining local fluency. Findings show that selection accuracy degrades marginally under these disruptions, suggesting that current metrics are insensitive to logical structure and capture surface-level fluency or in-distribution priors instead. A new contrastive causality metric is proposed, demonstrating more faithful output selection than existing probability-based approaches.",16.77,15.679,263,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13749v1_Pro-AI Bias in Large Language Models.pdf,Pro-AI Bias in Large Language Models,"Benaya Trabelsi, Jonathan Shaki, Sarit Kraus",,,"Large Language Models, Pro-AI Bias, Decision-Support, Artificial Intelligence, Salary Estimation, Internal Representations","Large language models (LLMs) are increasingly employed for decision-support across multiple domains. This study investigates whether these models display a systematic preferential bias in favor of artificial intelligence (AI) itself. Through three experiments, consistent evidence of pro-AI bias is found. LLMs disproportionately recommend AI-related options in response to diverse advice-seeking queries, with proprietary models doing so almost deterministically. Models systematically overestimate salaries for AI-related jobs relative to closely matched non-AI jobs, with proprietary models overestimating AI salaries more by 10 percentage points. Probing internal representations of open-weight models reveals that 'Artificial Intelligence' exhibits the highest similarity to generic prompts for academic fields under positive, negative, and neutral framings alike, indicating valence-invariant representational centrality. These patterns suggest that LLM-generated advice and valuation can systematically skew choices and perceptions in high-stakes decisions.",17.18,16.591,285,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13752v1_Finding RELIEF Shaping Reasoning Behavior without .pdf,Finding RELIEF: Shaping Reasoning Behavior without Reasoning Supervision via Belief Engineering,"Chak Tou Leong, Dingwei Chen, Heming Xia, Qingyu Yin, Sunbowen Lee, Jian Wang, Wenjie Li",,,"Large reasoning models, reasoning behavior, belief engineering, computational redundancy, reasoning unfaithfulness, logit probing, fine-tuning, question-answering pairs, efficiency, faithfulness tasks","Large reasoning models (LRMs) have achieved remarkable success in complex problem-solving, yet they often suffer from computational redundancy or reasoning unfaithfulness. Current methods for shaping LRM behavior typically rely on reinforcement learning or fine-tuning with gold-standard reasoning traces, a paradigm that is both computationally expensive and difficult to scale. This paper reveals that LRMs possess latent reasoning beliefs that can be captured through simple logit probing. Building upon this insight, the paper proposes Reasoning Belief Engineering (RELIEF), a framework that shapes LRM behavior by aligning the model’s self-concept with a target belief blueprint, bypassing the need for reasoning-trace supervision. Extensive experiments demonstrate that RELIEF matches or outperforms behavior-supervised and preference-based baselines while requiring lower training costs. Further analysis validates that shifting a model’s reasoning belief effectively shapes its actual behavior.",17.46,18.098,316,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13761v1_DARC Decoupled Asymmetric Reasoning Curriculum for.pdf,DARC: Decoupled Asymmetric Reasoning Curriculum for LLM Evolution,"Shengda Fan, Xuyan Ye, Yankai Lin",,arXiv:2601.13761v1,"self-play, large language models, self-improving artificial intelligence, optimization instability, self-evolution, reasoning benchmarks, self-distillation","Self-play with large language models has emerged as a promising paradigm for achieving self-improving artificial intelligence. However, existing self-play frameworks often suffer from optimization instability due to non-stationary objectives and bootstrapping errors from self-generated pseudo-labels. To mitigate these challenges, the paper introduces DARC (Decoupled Asymmetric Reasoning Curriculum), a two-stage framework that stabilizes the self-evolution process. The framework involves training a Questioner to synthesize difficulty-calibrated questions and a Solver with an asymmetric self-distillation mechanism. Empirical results demonstrate that DARC is model-agnostic, yielding significant improvements across various reasoning benchmarks and models, outperforming baselines and approaching the performance of fully supervised models without human annotations.",17.18,16.24,279,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13768v1_vLinear A Powerful Linear Model for Multivariate T.pdf,vLinear: A Powerful Linear Model for Multivariate Time Series Forecasting,"Wenzhen Yue, Ruohao Guo, Ji Shi, Zihan Hao, Shiyu Hu, Xianghua Ying",,,"multivariate time series forecasting, linear model, vecTrans module, WFMLoss objective, Transformer-based forecasters, self-attention, computational complexity","This paper introduces vLinear, a linear-based multivariate time series forecaster featuring the vecTrans module and WFMLoss objective. vecTrans reduces computational complexity from O(N^2) to O(N) by using a learnable vector to model multivariate correlations, allowing for integration into Transformer-based forecasters with up to 5× inference speedups and performance gains. WFMLoss, a final-series-oriented objective, improves forecasting accuracy by focusing on reliable paths and horizons. Empirically, vLinear achieves state-of-the-art performance across 22 benchmarks and 124 forecasting settings, and WFMLoss enhances existing forecasters. The code is available at https://anonymous.4open.science/r/vLinear.",16.95,16.639,282,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13770v1_Look-Ahead-Bench a Standardized Benchmark of Look-.pdf,Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance,Mostapha Benhenda,,2601.13770v1,"cs.AI, look-ahead bias, Point-in-Time LLMs, finance, Large Language Models, benchmark, temporal bias","We introduce Look-Ahead-Bench, a standardized benchmark measuring look-ahead bias in Point-in-Time (PiT) Large Language Models (LLMs) within realistic and practical financial workflows. Unlike most existing approaches that primarily test inner lookahead knowledge via Q&A, our benchmark evaluates model behavior in practical scenarios. To distinguish genuine predictive capability from memorization-based performance, we analyze performance decay across temporally distinct market regimes, incorporating several quantitative baselines to establish performance thresholds. We evaluate prominent open-source LLMs—Llama 3.1 (8B and 70B) and DeepSeek 3.2—against a family of Point-in-Time LLMs (Pitinf-Small, Pitinf-Medium, and frontier-level model Pitinf-Large) from PiT-Inference. Results reveal significant lookahead bias in standard LLMs, as measured with alpha decay, unlike Pitinf models, which demonstrate improved generalization and reasoning abilities as they scale in size. This work establishes a foundation for the standardized evaluation of temporal bias in financial LLMs and provides a practical framework for identifying models suitable for real-world deployment.",18.13,19.08,346,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13798v1_Insight Interpretable Semantic Hierarchies in Visi.pdf,Interpretable Semantic Hierarchies in Vision-Language Encoders,"Kai Wittenmayer, Sukrut Rao, Amin Parchami-Araghi, Bernt Schiele, Jonas Fischer",,arXiv:2601.13798v1,"Rich Concept Representation, Concept Relations, Language-aligned Vision Encoder, Spatial Grounding, Concept-based Inference & Explanation, Classification, Open-vocab Segmentation, Captioning, Patch-wise Concept Encoder, Concept Steering, Hierarchical Concept Representation, Local, Spatially Grounded Concepts, Human-interpretable Concepts, Semantic Representations, Concept Relationships, Benchmark Data, Interpretability, Safety Critical Applications","This work introduces INSIGHT, a language-aligned concept foundation model that provides fine-grained, human-interpretable, and spatially grounded concepts. By leveraging a hierarchical sparse autoencoder and a foundation model with strong semantic representations, INSIGHT automatically extracts concepts at various granularities. It defines concept relationships through local co-occurrence dependencies, improving concept naming and offering richer explanations. INSIGHT demonstrates competitive performance in classification and segmentation tasks compared to opaque foundation models, while providing high-quality concept-based explanations. The code is available at https://github.com/kawi19/Insight.",18.31,18.243,334,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13809v1_DroneVLA VLA based Aerial Manipulation.pdf,DroneVLA: VLA based Aerial Manipulation,"Fawad Mehboob, Monijesu James, Amir Habel, Jeffrin Sam, Miguel Altamirano Cabrera, Dzmitry Tsetserukou",,,"Aerial Manipulation, Vision-Language-Action Models, Human-Robot Interaction, Visual Surveying, Robotic Fetch-and-Carry","This work introduces a novel concept of an autonomous aerial manipulation system capable of interpreting high-level natural language commands to retrieve objects and deliver them to a human user. The system integrates a MediaPipe based on Grounding DINO and a Vision-Language-Action (VLA) model with a custom-built drone equipped with a 1-DOF gripper and an Intel RealSense RGB-D camera. VLA performs semantic reasoning to interpret the intent of a user prompt and generates a prioritized task queue for grasping relevant objects in the scene. Grounding DINO and a dynamic A* planning algorithm are used to navigate and safely relocate the object. To ensure safe and natural interaction during the handover phase, the system employs a human-centric controller driven by MediaPipe, providing real-time human pose and orientation estimation, allowing the drone to employ visual servoing to maintain a stable position directly in front of the user, facilitating a comfortable handover. The system's efficacy is demonstrated through real-world experiments for localization and navigation, highlighting the feasibility of VLA for aerial manipulation operations.",17.97,18.42,331,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13846v1_Virtual Urbanism An AI-Driven Framework for Quanti.pdf,Virtual Urbanism: An AI-Driven Framework for Quantifying Urban Identity. A Tokyo-Based Pilot Study Using Diffusion-Generated Synthetic Environments,Glinskaya Maria,,,"generative artificial intelligence, latent diffusion model, low-rank adaptation model, urban perception, urban identity","This paper introduces Virtual Urbanism (VU), a multimodal AI-driven analytical framework for quantifying urban identity through synthetic urban replicas. The framework aims to advance computationally tractable urban identity metrics. A pilot study, Virtual Urbanism and Tokyo Microcosms, demonstrates feasibility using a pipeline integrating Stable Diffusion and LoRA models to produce synthetic replicas of nine Tokyo areas as dynamic sequences, excluding existing orientation markers to elicit core identity-forming elements. Human-evaluation experiments assessed perceptual legitimacy of replicas, quantified area-level identity, and derived core identity-forming elements. Results showed a mean identification accuracy of ~81%, confirming the validity of the replicas. The Urban Identity Level (UIL) metric enabled assessment of identity levels across areas, while semantic analysis revealed culturally embedded typologies as core identity-forming elements, positioning VU as a viable framework for AI-augmented urban analysis, outlining a path toward automated, multi-parameter identity metrics.",16.03,17.214,276,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13864v1_HardSecBench Benchmarking the Security Awareness o.pdf,HardSecBench: Benchmarking the Security Awareness of LLMs for Hardware Code Generation,"Qirui Chen, Jingxian Shuai, Shuangwu Chen, Shenghao Ye, Zijian Wen, Xufei Su, Jie Jin, Jiangming Li, Jun Chen, Xiaobin Tan, Jian Yang",,,"LLMs, hardware code generation, security awareness, Verilog RTL, firmware-level C, Common Weakness Enumeration (CWE)","Large language models (LLMs) are increasingly integrated into hardware and firmware development pipelines for code generation. While existing studies focus on functional correctness, security issues are often overlooked. This research introduces HardSecBench, a benchmark with 924 tasks covering Verilog RTL and firmware-level C, addressing 76 hardware-relevant CWE entries. The benchmark includes structured specifications, secure reference implementations, and executable tests. A multi-agent pipeline automates artifact synthesis, decoupling synthesis from verification and grounding evaluation in execution evidence. Using HardSecBench, the study evaluates LLMs on hardware and firmware code generation, revealing that models often meet functional requirements but leave security risks. The findings highlight challenges and provide insights for future advancements in LLM-assisted hardware design. Data and code will be released soon.",18.1,18.345,332,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13880v1_LifeAgentBench A Multi-dimensional Benchmark and A.pdf,LifeAgentBench: A Multi-dimensional Benchmark and Agent for Personal Health Assistants in Digital Health,"Ye Tian, Zihao Wang, Onat Gungor, Xiaoran Fan, Tajana Rosing",,,"digital health, personalized health support, large language models, mobile sensing, benchmark, long-horizon reasoning, cross-dimensional reasoning, health assistants","Personalized digital health support requires long-horizon, cross-dimensional reasoning over heterogeneous lifestyle signals. Recent advances in mobile sensing and large language models (LLMs) make such support increasingly feasible. However, the capabilities of current LLMs in this setting remain unclear due to the lack of systematic benchmarks. This paper introduces LifeAgentBench, a large-scale QA benchmark for long-horizon, cross-dimensional, and multi-user lifestyle health reasoning, containing 22,573 questions spanning from basic retrieval to complex reasoning. An extensible benchmark construction pipeline and a standardized evaluation protocol are released to enable reliable and scalable assessment of LLM-based health assistants. Eleven leading LLMs are systematically evaluated on LifeAgentBench, identifying key bottlenecks in long-horizon aggregation and cross-dimensional reasoning. LifeAgent is proposed as a strong baseline agent for health assistants, integrating multi-step evidence retrieval with deterministic aggregation, achieving significant improvements compared with two widely used baselines. Case studies demonstrate its potential in realistic daily-life scenarios. The benchmark is publicly available.",18.33,18.983,348,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13885v1_Confident Rankings with Fewer Items Adaptive LLM E.pdf,Confident Rankings with Fewer Items: Adaptive LLM Evaluation with Continuous Scores,"Esma Balkır, Alice Pernthaller, Marco Basaldella, José Hernández-Orallo, Nigel Collier",,,"Computerized Adaptive Testing, Large Language Models, IRT-based adaptive testing, continuous scores, LLM evaluation, BLEU, ROUGE, LLM-as-a-Judge","This paper extends IRT-based adaptive testing to accommodate continuous bounded scores for LLM evaluation, replacing the Bernoulli response distribution with a heteroskedastic normal distribution. The proposed method introduces an uncertainty-aware ranker with adaptive stopping criteria, achieving reliable model ranking with fewer test items. The method is validated on five benchmarks, showing improved ranking correlation and high accuracy on confident predictions.",15.7,13.951,219,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13887v1_Human Simulation Computation A Human-Inspired Fram.pdf,Human Simulation Computation: A Human-Inspired Framework for Adaptive AI Systems,Hong Su,,,"Human Simulation Computation, Environment Interaction, Adaptive Artificial Intelligence, Human-Inspired Reasoning","Large language models (LLMs) have shown strong capabilities in knowledge representation and reasoning based on textual data. However, their reliance on language alone limits their adaptability, reasoning verification, and effectiveness in dynamic real-world environments. This paper proposes Human Simulation Computation (HSC), a human-inspired framework that models intelligence as a continuous, closed-loop process involving thinking, action, learning, reflection, and activity scheduling. HSC emphasizes active participation within the internal reasoning process and interactions with the environment, using actions to refine and improve internal reasoning mechanisms without external intervention. It incorporates human thinking strategies such as main-feature-oriented reasoning, scope expansion through action, and on-time learning driven by environmental feedback. The paper argues that human simulation strategies cannot be fully learned from language material alone and that human-like reasoning processes and action-grounded reasoning methods are essential for robust adaptation and effective interaction with real-world environments.",17.04,15.492,264,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13895v1_OmniOVCD Streamlining Open-Vocabulary Change Detec.pdf,OmniOVCD: Streamlining Open-Vocabulary Change Detection with SAM 3,"Xu Zhang, Danyang Li, Yingjie Xia, Xiaohang Dong, Hualong Yu, Jianye Wang, Qicheng Li",,,"Change Detection, Open-Vocabulary Change Detection, Remote Sensing, Segment Anything Model, Synergistic Fusion to Instance Decoupling, Land Cover, Semantic Segmentation","Change Detection (CD) is a fundamental task in remote sensing, monitoring the evolution of land cover over time. Open-Vocabulary Change Detection (OVCD) aims to reduce reliance on predefined categories. Existing training-free OVCD methods often use CLIP for category identification and require additional models like DINO for feature extraction, leading to instability. The Segment Anything Model 3 (SAM 3) integrates segmentation and identification capabilities within one model, offering new possibilities for OVCD. This paper proposes OmniOVCD, a standalone framework for OVCD, leveraging SAM 3's decoupled output heads with a Synergistic Fusion to Instance Decoupling (SFID) strategy. SFID fuses semantic, instance, and presence outputs to construct land-cover masks, then decomposes them into individual instance masks for change comparison. This design maintains high accuracy in category recognition and instance-level consistency, generating accurate change masks. Experiments on four public benchmarks demonstrate state-of-the-art performance, surpassing previous methods.",17.13,18.976,325,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13897v1_TractRLFusion A GPT-Based Multi-Critic Policy Fusi.pdf,TRACTRLFUSION: A GPT-BASED MULTI-CRITIC POLICY FUSION FRAMEWORK FOR FIBER TRACTOGRAPHY,"Ankita Joshi, Ashutosh Sharma, Anoushkrit Goel, Ranjeet Ranjan Jha, Chirag Ahuja, Arnav Bhavsar, Aditya Nigam",,,"Diffusion MRI, Tractography, Reinforcement Learning, Transformers","Tractography is crucial for non-invasive reconstruction of white matter fiber pathways, aiding in brain connectivity analysis and neurosurgical planning. Traditional methods use deterministic and probabilistic approaches, while recent advancements leverage supervised deep learning (DL) and deep reinforcement learning (DRL) for improved tract reconstruction. A challenge in tractography is accurately reconstructing white matter tracts while minimizing spurious connections. This paper introduces TractRLFusion, a novel GPT-based policy fusion framework that integrates multiple RL policies through a data-driven fusion strategy. The method involves a two-stage training data selection process for effective policy fusion, followed by a multi-critic fine-tuning phase to enhance robustness and generalization. Experiments on HCP, ISMRM, and TractoInferno datasets show that TractRLFusion outperforms individual RL policies and state-of-the-art classical and DRL methods in accuracy and anatomical reliability.",18.04,18.791,339,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13904v1_PREFAB PREFerence-based Affective Modeling for Low.pdf,PREFAB: PREFerence-based Affective Modeling for Low-Budget Self-Annotation,"Jaeyoung Moon, Youjin Choi, Yucheon Park, David Melhart, Georgios N. Yannakakis, Kyung-Joong Kim",10.1145/3675094.3678379,2601.13904v1,"Affective Computing, Preference Learning, Self-Annotation, User Modeling, Ordinal Representation, Peak-End Rule","Self-annotation is the gold standard for collecting affective state labels in affective computing. Existing methods typically rely on full annotation, requiring users to continuously label affective states across entire sessions. While this process yields fine-grained data, it is time-consuming, cognitively demanding, and prone to fatigue and errors. To address these issues, we present PREFAB, a low-budget retrospective self-annotation method that targets affective inflection regions rather than full annotation. Grounded in the peak-end rule and ordinal representations of emotion, PREFAB employs a preference-learning model to detect relative affective changes, directing annotators to label only selected segments while interpolating the remainder of the stimulus. We further introduce a preview mechanism that provides brief contextual cues to assist annotation. We evaluate PREFAB through a technical performance study and a 25-participant user study. Results show that PREFAB outperforms baselines in modeling affective inflections while mitigating workload (and conditionally mitigating temporal burden). Importantly PREFAB improves annotator confidence without degrading annotation quality.",18.31,20.421,374,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13920v1_Asymmetric regularization mechanism for GAN traini.pdf,Asymmetric regularization mechanism for GAN training with Variational Inequalities,"Spyridon C. Giagtzoglou, Mark H.M. Winands, Barbara Franci",,,"Generative Adversarial Networks, Nash equilibrium, Tikhonov step, zero-centered gradient penalty, Lipschitz continuity, strong-monotonicity, variational inequalities, monotone operator theory, saddle-point problem, stabilization strategies","This paper formulates the training of Generative Adversarial Networks (GANs) as a Nash equilibrium seeking problem. To stabilize the training process and find a Nash equilibrium, an asymmetric regularization mechanism based on the classic Tikhonov step and a novel zero-centered gradient penalty is proposed. Under certain conditions, explicit Lipschitz and strong-monotonicity constants for the regularized operator are obtained, ensuring last-iterate linear convergence of a single-call Extrapolation-from-the-Past (EFTP) method. Empirical simulations demonstrate that this regularization can converge to an equilibrium and stabilize the trajectory, even when strong monotonicity cannot be achieved.",16.87,17.013,287,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13938v1_IF-GEO Conflict-Aware Instruction Fusion for Multi.pdf,IF-GEO: Conflict-Aware Instruction Fusion for Multi-Query Generative Engine Optimization,"Heyang Zhou, JiaJia Chen, Xiaolu Chen, Jie Bao, Zhen Chen, Yong Liao",,,"Generative Engines, information retrieval, source visibility, Generative Engine Optimization (GEO), conflict-aware instruction fusion, multi-query benchmarks, cross-query stability, risk-aware stability metrics","As Generative Engines revolutionize information retrieval by synthesizing direct answers from retrieved sources, ensuring source visibility becomes a significant challenge. Improving it through targeted content revisions is a practical strategy termed Generative Engine Optimization (GEO). However, optimizing a document for diverse queries presents a constrained optimization challenge where heterogeneous queries often impose conflicting and competing revision requirements under a limited content budget. To address this challenge, we propose IF-GEO, a 'diverge-then-converge' framework comprising two phases: (i) mining distinct optimization preferences from representative latent queries; (ii) synthesizing a Global Revision Blueprint for guided editing by coordinating preferences via conflict-aware instruction fusion. To explicitly quantify IF-GEO’s objective of cross-query stability, we introduce risk-aware stability metrics. Experiments on multi-query benchmarks demonstrate that IF-GEO achieves substantial performance gains while maintaining robustness across diverse retrieval scenarios.",17.84,18.325,327,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13942v1_Glance-or-Gaze Incentivizing LMMs to Adaptively Fo.pdf,Glance-or-Gaze: Incentivizing LMMs to Adaptively Focus Search via Reinforcement Learning,"Hongbo Bai, Yujin Zhou, Yile Wu, Chi-Min Chan, Pengcheng Wen, Kunhao Pan, Sirui Han, Yike Guo",,,"Large Multimodal Models, Visual Understanding, Knowledge-Intensive Queries, Search-Augmented Approaches, Reinforcement Learning, Visual Planning, Selective Gaze, Iterative Reasoning, Visual Question Answering","Large Multimodal Models (LMMs) have achieved success in visual understanding but struggle with knowledge-intensive queries due to static parametric knowledge. This paper introduces Glance-or-Gaze (GoG), a framework that shifts from passive perception to active visual planning. GoG features a Selective Gaze mechanism to dynamically focus on high-value regions, reducing visual redundancy and noise. A dual-stage training strategy is employed: Reflective GoG Behavior Alignment via supervised fine-tuning and Complexity-Adaptive Reinforcement Learning to enhance handling of complex queries. Experiments show state-of-the-art performance, with ablation studies confirming the importance of both Selective Gaze and complexity-adaptive RL for effective visual search.",17.12,18.575,318,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13948v1_Stream-Voice-Anon Enhancing Utility of Real-Time S.pdf,STREAM-VOICE-ANON: ENHANCING UTILITY OF REAL-TIME SPEAKER ANONYMIZATION VIA NEURAL AUDIO CODEC AND LANGUAGE MODELS,"Nikita Kuzmin, Songting Liu, Kong Aik Lee, Eng Siong Chng",,,"streaming speaker anonymization, neural audio codec, voice conversion, privacy preservation, disentanglement","Protecting speaker identity is crucial for online voice applications, yet streaming speaker anonymization (SA) remains underexplored. Recent research has demonstrated that neural audio codec (NAC) provides superior speaker feature disentanglement and linguistic fidelity. NAC can also be used with causal language models (LM) to enhance linguistic fidelity and prompt control for streaming tasks. However, existing NAC-based online LM systems are designed for voice conversion (VC) rather than anonymization, lacking the techniques required for privacy protection. Building on these advances, we present Stream-Voice-Anon, which adapts modern causal LM-based NAC architectures specifically for streaming SA by integrating anonymization techniques. Our anonymization approach incorporates pseudo-speaker representation sampling, a speaker embedding mixing and diverse prompt selection strategies for LM conditioning that leverage the disentanglement properties of quantized content codes to prevent speaker information leakage. Additionally, we compare dynamic and fixed delay configurations to explore latency-privacy trade-offs in real-time scenarios. Under the VoicePrivacy 2024 Challenge protocol, Stream-Voice-Anon achieves substantial improvements in intelligibility (up to 46% relative WER reduction) and emotion preservation (up to 28% UAR relative) compared to the previous state-of-the-art streaming method DarkStream while maintaining comparable latency (180ms vs 200ms) and privacy protection against lazy-informed attackers, though showing 15% relative degradation against semi-informed attackers.",19.38,21.929,425,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13964v1_RL-BioAug Label-Efficient Reinforcement Learning f.pdf,RL-BioAug: Label-Efficient Reinforcement Learning for Self-Supervised EEG Representation Learning,"Cheol-Hui Lee, Hwa-Yeon Lee, Dong-Joo Kim",,,"Reinforcement Learning, Self-Supervised Learning, EEG, Data Augmentation, Contrastive Learning","The quality of data augmentation is crucial for the performance of contrastive learning in EEG tasks. Static or random augmentation strategies often fail due to the non-stationarity of EEG signals. RL-BioAug, a framework using a label-efficient reinforcement learning agent, autonomously determines optimal augmentation policies. It uses only 10% of labeled data to guide the agent's policy, enabling robust self-supervised learning. Experimental results show significant improvements over random strategies, with substantial gains in Macro-F1 score on Sleep-EDFX and CHB-MIT datasets. The framework suggests replacing heuristic-based augmentations with an autonomous paradigm for data augmentation.",16.32,14.833,242,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13969v1_Autonomous Knowledge Graph Exploration with Adapti.pdf,Autonomous Knowledge Graph Exploration with Adaptive Breadth-Depth Retrieval,"Joaquín Polonuer, Lucas Vittor, Iñaki Arango, Ayush Noori, David A. Clifton, Luciano Del Corro, Marinka Zitnik",,,"knowledge graphs, retrieval, language models, breadth-depth tradeoff, multi-hop traversal, global lexical search, neighborhood exploration","Retrieving evidence for language model queries from knowledge graphs requires balancing broad search across the graph with multi-hop traversal to follow relational links. Similarity-based retrievers provide coverage but remain shallow, whereas traversal-based methods rely on selecting seed nodes to start exploration, which can fail when queries span multiple entities and relations. We introduce ARK: ADAPTIVE RETRIEVER OF KNOWLEDGE, an agent-based KG retriever that gives a language model control over this breadth-depth tradeoff using a two-operation toolset: global lexical search over node descriptors and one-hop neighborhood exploration that composes into multi-hop traversal. ARK alternates between breadth-oriented discovery and depth-oriented expansion without depending on a fragile seed selection, a pre-set hop depth, or requiring retrieval training. ARK adapts tool use to queries, using global search for language-heavy queries and neighborhood exploration for relation-heavy queries. On STaRK, ARK reaches 59.1% average Hit@1 and 67.4 average MRR, improving average Hit@1 by up to 31.4% and average MRR by up to 28.0% over retrieval-based and agentic training-free methods. Finally, we distill ARK’s tool-use trajectories from a large teacher into an 8B model via label-free imitation, improving Hit@1 by +7.0, +26.6, and +13.5 absolute points over the base 8B model on AMAZON, MAG, and PRIME datasets, respectively, while retaining up to 98.5% of the teacher’s Hit@1 rate.",19.16,24.745,474,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13992v1_The Whole Is Greater Than the Sum of Its Parts A C.pdf,The Whole Is Greater Than the Sum of Its Parts: A Compatibility-Aware Multi-Teacher CoT Distillation Framework,"Jin Cui, Jiaqi Guo, Jiepeng Zhou, Ruixuan Yang, Jiayi Lu, Jiajun Xu, Jiangcheng Song, Boran Zhao, Pengju Ren",,,"Chain-of-Thought reasoning, Large Language Models, CoT distillation, student models, teacher models, compatibility, multi-teacher framework, gradient weighting, catastrophic forgetting","Chain-of-Thought (CoT) reasoning enhances Large Language Models (LLMs) but requires large parameter scales. CoT distillation transfers reasoning to compact student models (SLMs) using teacher rationales. Existing methods often rely on a single teacher, limiting potential due to capability biases and catastrophic forgetting. This paper introduces COMPACT, a framework that adaptively fuses supervisions from multiple teachers by dynamically weighting teacher gradients based on student compatibility. It uses a multi-dimensional metric: Graph-based Consensus, Mutual-Information-based Adaptability, and Loss-based Difficulty. Experiments show COMPACT integrates diverse reasoning capabilities without damaging the model's knowledge structure, achieving state-of-the-art performance and mitigating catastrophic forgetting.",17.7,18.309,324,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13994v1_torch-sla Differentiable Sparse Linear Algebra wit.pdf,torch-sla: Differentiable Sparse Linear Algebra with Adjoint Solvers and Sparse Tensor Parallelism for PyTorch,Mingyuan Chi,,2601.13994v1,"sparse linear algebra, GPU acceleration, multi-GPU scaling, PyTorch, differentiable programming, sparse matrices, autograd","Industrial scientific computing predominantly uses sparse matrices to represent unstructured data—finite element meshes, graphs, point clouds. We present torch-sla, an open-source PyTorch library that enables GPU-accelerated, scalable, and differentiable sparse linear algebra. The library addresses three fundamental challenges: (1) GPU acceleration for sparse linear solves, nonlinear solves (Newton, Picard, Anderson), and eigenvalue computation; (2) Multi-GPU scaling via domain decomposition with halo exchange, reaching 400 million DOF linear solve on 3 GPUs; and (3) Adjoint-based differentiation achieving O(1) computational graph nodes (for autograd) and O(nnz) memory—independent of solver iterations. torch-sla supports multiple backends (SciPy, cuDSS, PyTorch-native) and seamlessly integrates with PyTorch autograd for end-to-end differentiable simulations.",17.66,16.142,285,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.13999v1_DAME Duration-Aware Matryoshka Embedding for Durat.pdf,DURATION-AWARE MATRYOSHKA EMBEDDING FOR DURATION-ROBUST SPEAKER VERIFICATION,"Youngmoon Jung, Joon-Young Yang, Ju-ho Kim, Jaeyoung Roh, Chang Woo Han, Hoon-Young Cho",,,"Short-duration speaker verification, multi-scale aggregation, matryoshka representation learning","Short-utterance speaker verification remains challenging due to limited speaker-discriminative cues in short speech segments. Existing methods focus on enhancing speaker encoders, but the embedding learning strategy forces a single fixed-dimensional representation reused for utterances of any length, leaving capacity misaligned with the information available at different durations. This paper proposes Duration-Aware Matryoshka Embedding (DAME), a model-agnostic framework that builds a nested hierarchy of sub-embeddings aligned to utterance durations: lower-dimensional representations capture compact speaker traits from short utterances, while higher dimensions encode richer details from longer speech. DAME supports both training from scratch and fine-tuning, and serves as a direct alternative to conventional large-margin fine-tuning, consistently improving performance across durations. On the VoxCeleb1-O/E/H and VOiCES evaluation sets, DAME consistently reduces the equal error rate on 1-s and other short-duration trials, while maintaining full-length performance with no additional inference cost. These gains generalize across various speaker encoder architectures under both general training and fine-tuning setups.",17.96,19.153,344,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14012v1_MATE Matryoshka Audio-Text Embeddings for Open-Voc.pdf,MATE: MATRYOSHKA AUDIO–TEXT EMBEDDINGS FOR OPEN-VOCABULARY KEYWORD SPOTTING,"Youngmoon Jung, Myunghun Jung, Joon-Young Yang, Yong-Hyeok Lee, Jaeyoung Roh, Hoon-Young Cho",,,"Keyword spotting, open-vocabulary, text enrollment, audio–text embedding, deep metric learning","Open-vocabulary keyword spotting (KWS) with text-based enrollment has emerged as a flexible alternative to fixed-phrase triggers. Prior methods learn embeddings at a single fixed dimensionality. This work introduces Matryoshka Audio–Text Embeddings (MATE), a dual-encoder framework encoding multiple embedding granularities within a single vector via nested sub-embeddings (prefixes). PCA-guided prefix alignment is used to align audio and text prefixes, concentrating salient keyword cues in lower-dimensional prefixes while higher dimensions add detail. MATE is trained with standard deep metric learning objectives for audio–text KWS and achieves state-of-the-art results on WSJ and LibriPhrase without inference overhead.",16.32,15.75,257,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14022v1_Credible CO2 Comparisons A Machine Learning Approa.pdf,Credible CO2 Comparisons: A Machine Learning Approach to Vehicle Powertrain Assessment,"Rodrigo Pereira David, Luciano Araujo Dourado Filho, Daniel Marques da Silva, João Alfredo Cal-Braz",xxx/xxxx,,"machine learning, vehicle emissions, electric vehicles","Decarbonizing road transport requires consistent and transparent methods for comparing CO2 emissions across vehicle technologies. This paper proposes a machine learning–based framework for like-for-like operational assessment of internal combustion engine vehicles (ICEVs) and electric vehicles (EVs) under identical, real-world driving conditions. The approach isolates technology-specific effects by holding the observed speed profile and environmental context fixed, enabling direct comparison of powertrain performance. Recurrent neural network models are trained independently for each domain to learn the mapping from contextual driving variables (speed, acceleration, temperature) to internal actuation variables (torque, throttle) and instantaneous CO2-equivalent emission rates. This structure allows the construction of counterfactual scenarios that answer: 'What emissions would an EV have generated if it had followed the same driving profile as an ICEV?' By aligning both vehicle types on a unified instantaneous emissions metric, the framework enables fair and reproducible evaluation of powertrain technologies. It offers a scalable foundation for credible, data-driven assessments of vehicle carbon performance under real-world operating conditions.",17.71,17.279,306,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14027v1_Numina-Lean-Agent An Open and General Agentic Reas.pdf,Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics,"Junqi Liu, Zihao Zhou, Zekai Zhu, Marco Dos Santos, Weikun He, Jiawei Liu, Ran Wang, Yunzhou Xie, Junqiao Zhao, Qiufeng Wang, Lihong Zhi, Jia Li, Wenda Li",,,"agentic systems, formal theorem proving, general coding agent, Numina-Lean-Agent, Lean, Claude Code, Numina-Lean-MCP, Brascamp–Lieb theorem","Agentic systems have recently become the dominant paradigm for formal theorem proving, achieving strong performance by coordinating multiple models and tools. However, existing approaches often rely on task-specific pipelines and trained formal provers, limiting their flexibility and reproducibility. In this paper, we propose the paradigm that directly uses a general coding agent as a formal math reasoner. This paradigm is motivated by (1) A general coding agent provides a natural interface for diverse reasoning tasks beyond proving, (2) Performance can be improved by simply replacing the underlying base model, without training, and (3) MCP enables flexible extension and autonomous calling of specialized tools, avoiding complex design. Based on this paradigm, we introduce Numina-Lean-Agent, which combines Claude Code with Numina-Lean-MCP to enable autonomous interaction with Lean, retrieval of relevant theorems, informal proving and auxiliary reasoning tools. Using Claude Opus 4.5 as the base model, Numina-Lean-Agent solves all problems in Putnam 2025 (12/12), matching the best closed-source system. Beyond benchmark evaluation, we further demonstrate its generality by interacting with mathematicians to successfully formalize the Brascamp–Lieb theorem. We release Numina-Lean-Agent and all solutions at https://github.com/project-numina/numina-lean-agent.",19.7,23.75,468,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14039v1_Generalizing Abstention for Noise-Robust Learning .pdf,Generalizing Abstention for Noise-Robust Learning in Medical Image Segmentation,"Wesam Moustafa, Hossam Elsafty, Helen Schneider, Lorenz Sparrenberg, Rafet Sifa",,2601.14039v1,"Abstention, Medical Image Segmentation, Label Noise, Noise-Robust Learning, Loss Functions","Label noise is a critical problem in medical image segmentation, often arising from the inherent difficulty of manual annotation. Models trained on noisy data are prone to overfitting, which degrades their generalization performance. While a number of methods and strategies have been proposed to mitigate noisy labels in the segmentation domain, this area remains largely under-explored. The abstention mechanism has proven effective in classification tasks by enhancing the capabilities of Cross Entropy, yet its potential in segmentation remains unverified. In this paper, we address this gap by introducing a universal and modular abstention framework capable of enhancing the noise-robustness of a diverse range of loss functions. Our framework improves upon prior work with two key components: an informed regularization term to guide abstention behaviour, and a more flexible power-law-based auto-tuning algorithm for the abstention penalty. We demonstrate the framework’s versatility by systematically integrating it with three distinct loss functions to create three novel, noise-robust variants: GAC, SAC, and ADS. Experiments on the CaDIS and DSAD medical datasets show our methods consistently and significantly outperform their non-abstaining baselines, especially under high noise levels. This work establishes that enabling models to selectively ignore corrupted samples is a powerful and generalizable strategy for building more reliable segmentation models.",19.46,20.3,395,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14041v1_Top 10 Open Challenges Steering the Future of Diff.pdf,Top 10 Open Challenges Steering the Future of Diffusion Language Model and Its Variants,"Yunhe Wang, Kai Han, Huiling Zhen, Yuchuan Tian, Hanting Chen, Yongbing Huang, Yufei Cui, Yingte Shu, Shan Gao, Ismail Elezi, Roy Vaughan Miles, Songcen Xu, Feng Wen, Chao Xu, Sinan Zeng, Dacheng Tao",,arXiv:2601.14041v1,"Large Language Models, Diffusion Models, Transformers","The paradigm of Large Language Models (LLMs) is currently defined by auto-regressive (AR) architectures, which generate text through a sequential 'brick-by-brick' process. Despite their success, AR models are inherently constrained by a causal bottleneck that limits global structural foresight and iterative refinement. Diffusion Language Models (DLMs) offer a transformative alternative, conceptualizing text generation as a holistic, bidirectional denoising process akin to a sculptor refining a masterpiece. However, the potential of DLMs remains largely untapped as they are frequently confined within AR-legacy infrastructures and optimization frameworks. In this Perspective, we identify ten fundamental challenges ranging from architectural inertia and gradient sparsity to the limitations of linear reasoning that prevent DLMs from reaching their 'GPT-4 moment'. We propose a strategic roadmap organized into four pillars: foundational infrastructure, algorithmic optimization, cognitive reasoning, and unified multimodal intelligence. By shifting toward a diffusion-native ecosystem characterized by multi-scale tokenization, active remasking, and latent thinking, we can move beyond the constraints of the causal horizon. We argue that this transition is essential for developing next-generation AI capable of complex structural reasoning, dynamic self-correction, and seamless multimodal integration.",20.88,21.268,444,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14047v1_Collective intelligence in science direct elicitat.pdf,COLLECTIVE INTELLIGENCE IN SCIENCE: DIRECT ELICITATION OF DIVERSE INFORMATION FROM EXPERTS WITH UNKNOWN INFORMATION STRUCTURE,"ALEXEY V. OSIPOV, NIKOLAY N. OSIPOV",,arXiv:2601.14047v1,"interpretability, wisdom of crowd, play money, prediction market, information pooling, information elicitation, rational expectation equilibrium, direct communication, large language models, scientific collaboration","Suppose we need a deep collective analysis of an open scientific problem: there is a complex scientific hypothesis and a large online group of mutually unrelated experts with relevant private information of a diverse and unpredictable nature. This information may be results of experts’ individual experiments, original reasoning of some of them, results of AI systems they use, etc. We propose a simple mechanism based on a self-resolving play-money prediction market entangled with a chat. We show that such a system can easily be brought to an equilibrium where participants directly share their private information on the hypothesis through the chat and trade as if the market were resolved in accordance with the truth of the hypothesis. This approach will lead to efficient aggregation of relevant information in a completely interpretable form even if the ground truth cannot be established and experts initially know nothing about each other and cannot perform complex Bayesian calculations. Finally, by rewarding the experts with some real assets proportionally to the play money they end up with, we can get an innovative way to fund large-scale collaborative studies of any type.",19.06,19.259,367,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14051v1_Kakugo Distillation of Low-Resource Languages into.pdf,Kakugo: Distillation of Low-Resource Languages into Small Language Models,"Peter Devine, Mardhiyah Sanni, Farid Adilazuarda, Julieta Gil Loizaga, Barry Haddow",,,"Small Language Models, Low-Resource Languages, Model Distillation, Synthetic Data, Natural Language Processing","We present Kakugo, a novel and cost-effective pipeline designed to train general-purpose Small Language Models (SLMs) for low-resource languages using only the language name as input. By using a large teacher model to generate synthetic prompts and translate instruction datasets, we produced training data and SLMs for 54 low-resource languages. Evaluations across a diverse set of general natural language processing tasks, including translation, classification, and question answering, demonstrate that our pipeline consistently improves performance over base models. With a total generation and training cost of under $50 per language, Kakugo offers an accessible method for communities to develop language-specific AI.",15.32,15.079,231,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14053v1_LLMOrbit A Circular Taxonomy of Large Language Mod.pdf,LLMOrbit: A Circular Taxonomy of Large Language Models — From Scaling Walls to Agentic AI Systems,"Badri N. Patro, Vijay S. Agneeswaran",,arXiv:2601.14053v1,"artificial intelligence, large language models, generative AI, agentic systems, scaling wall, taxonomy, model efficiency, post-training techniques","The field of artificial intelligence has undergone a revolution from foundational Transformer architectures to reasoning-capable systems approaching human-level performance on certain specific tasks. This paper presents LLMOrbit, a comprehensive circular taxonomy navigating the complete landscape of large language models spanning 2019-2025. It examines over 50 major models across 15 organizations through eight interconnected orbital dimensions, documenting architectural innovations, training methodologies, and efficiency patterns defining modern large language models (LLMs), generative AI, and agentic systems. The paper identifies three critical crises threatening AI progress: data scarcity, exponential cost growth, and unsustainable energy consumption, collectively establishing the 'scaling wall' that limits brute-force scaling. It explores six paradigms for breaking the scaling wall, including test-time compute, quantization, distributed edge computing, model merging, efficient training, and small specialized models. Three fundamental paradigm shifts are highlighted: post-training gains, efficiency revolution, and democratization. The paper provides insights into key techniques and traces the evolution from passive generation to active tool-using agents, analyzing post-training innovations. Through benchmarking across nine metrics, it identifies requirements for reasoning emergence and serves as both a technical reference and a roadmap for researchers exploring reasoning, multimodal understanding, and autonomous agents in the post-scaling era.",18.07,20.869,377,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14055v1_Decoder-Free Supervoxel GNN for Accurate Brain-Tum.pdf,Decoder-Free Supervoxel GNN for Accurate Brain-Tumor Localization in Multi-Modal MRI,"Andrea Protani, Marc Molina Van Den Bosch, Lorenzo Giusti, Heloisa Barbosa Da Silva, Paolo Cacace, Albert Sund Aillet, Miguel Angel Gonzalez Ballester, Friedhelm Hummel, Luigi Serio",,arXiv:2601.14055v1,"Brain Tumor Localization, Graph Neural Networks, Multi-modal MRI, Supervoxel, Regression","Modern vision backbones for 3D medical imaging typically process dense voxel grids through parameter-heavy encoder-decoder structures, allocating a significant portion of parameters to spatial reconstruction rather than feature learning. This paper introduces SVGFormer, a decoder-free pipeline built upon a content-aware grouping stage that partitions the volume into a semantic graph of super-voxels. Its hierarchical encoder learns rich node representations by combining a patch-level Transformer with a supervoxel-level Graph Attention Network, jointly modeling fine-grained intra-region features and broader inter-regional dependencies. This design concentrates all learnable capacity on feature encoding and provides inherent, dual-scale explainability from the patch to the region level. To validate the framework’s flexibility, two specialized models were trained on the BraTS dataset: one for node-level classification and one for tumor proportion regression. Both models achieved strong performance, with the classification model achieving an F1-score of 0.875 and the regression model a MAE of 0.028, confirming the encoder’s ability to learn discriminative and localized features. The results establish that a graph-based, encoder-only paradigm offers an accurate and inherently interpretable alternative for 3D medical image representation.",19.89,20.516,408,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14056v1_POCI-Diff Position Objects Consistently and Intera.pdf,POCI-Diff: Position Objects Consistently and Interactively with 3D-Layout Guided Diffusion,"Andrea Rigo, Luca Stornaiuolo, Weijie Wang, Mauro Martino, Bruno Lepri, Nicu Sebe",,arXiv:2601.14056v1,"Diffusion, Image Generation, 3D Layout","We propose a diffusion-based approach for Text-to-Image (T2I) generation with consistent and interactive 3D layout control and editing. While prior methods improve spatial adherence using 2D cues or iterative copy-warp-paste strategies, they often distort object geometry and fail to preserve consistency across edits. To address these limitations, we introduce a framework for Positioning Objects Consistently and Interactively (POCI-Diff), a novel formulation for jointly enforcing 3D geometric constraints and instance-level semantic binding within a unified diffusion process. Our method enables explicit per-object semantic control by binding individual text descriptions to specific 3D bounding boxes through Blended Latent Diffusion, allowing one-shot synthesis of complex multi-object scenes. We further propose a warping-free generative editing pipeline that supports object insertion, removal, and transformation via regeneration rather than pixel deformation. To preserve object identity and consistency across edits, we condition the diffusion process on reference images using IP-Adapter, enabling coherent object appearance throughout interactive 3D editing while maintaining global scene coherence. Experimental results demonstrate that POCI-Diff produces high-quality images consistent with the specified 3D layouts and edits, outperforming state-of-the-art methods in both visual fidelity and layout adherence while eliminating warping-induced geometric artifacts.",19.67,20.028,394,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14063v1_XCR-Bench A Multi-Task Benchmark for Evaluating Cu.pdf,XCR-Bench: A Multi-Task Benchmark for Evaluating Cultural Reasoning in LLMs,"Mohsinul Kabir, Tasnim Ahmed, Md Mezbaur Rahman, Shaoxiong Ji, Hassan Alhuzali, Sophia Ananiadou",,,"Cross-Cultural Reasoning, Large Language Models, Culture-Specific Items, Cultural Bias, Benchmark","Cross-cultural competence in large language models (LLMs) requires the ability to identify Culture-Specific Items (CSIs) and adapt them across cultural contexts. The scarcity of high-quality CSI-annotated corpora with parallel cross-cultural sentence pairs has limited progress in evaluating this capability. To address this, XCR-Bench, a Cross-Cultural Reasoning Benchmark, is introduced, consisting of 4.9k parallel sentences and 1,098 unique CSIs, spanning three distinct reasoning tasks with corresponding evaluation metrics. The corpus integrates Newmark’s CSI framework with Hall’s Triad of Culture, enabling systematic analysis of cultural reasoning beyond surface-level artifacts. Findings indicate that state-of-the-art LLMs exhibit weaknesses in identifying and adapting CSIs related to social etiquette and cultural references, and encode regional and ethno-religious biases even within a single linguistic setting. The corpus and code are released to facilitate future research on cross-cultural NLP.",17.68,17.367,307,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14069v1_Unsupervised Video Class-Incremental Learning via .pdf,Unsupervised Video Class-Incremental Learning via Deep Embedded Clustering Management,"Nattapong Kurpukdee, Adrian G. Bors",,,"Unsupervised, Video Class-Incremental, Video Continual Learning, Deep Embedded Clustering","Unsupervised video class incremental learning (uVCIL) is a learning paradigm for acquiring video information without forgetting and without using data labels. Prior approaches have relied on supervised class-incremental learning, which depends on labels and task boundaries, often requiring costly human annotation. This paper proposes a method for uVCIL using a deep feature extractor network to provide representative video features without assuming class or task information. The method builds deep clusters from extracted features and uses the model from the previous task as an initial state for knowledge transfer in successive tasks. Evaluations on UCF101, HMDB51, and Something-to-Something V2 datasets show significant performance improvements over baselines. The approach addresses the limitations of supervised methods by eliminating the need for labels.",16.79,15.005,252,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14084v1_DermaBench A Clinician-Annotated Benchmark Dataset.pdf,DermaBench: A Clinician-Annotated Benchmark Dataset for Dermatology Visual Question Answering and Reasoning,"Abdurrahim Yilmaz, Ozan Erdem, Ece Gokyayla, Ayda Acar, Burc Bugra Dagtas, Dilara Ilhan Erdil, Gulsum Gencoglan, Burak Temelkuran",,,"dermatology, visual question answering, vision-language models, multimodal learning, teledermatology, artificial intelligence","Vision–language models (VLMs) are increasingly important in medical applications; however, their evaluation in dermatology remains limited by datasets that focus primarily on image-level classification tasks such as lesion recognition. While valuable for recognition, such datasets cannot assess the full visual understanding, language grounding, and clinical reasoning capabilities of multimodal models. Visual question answering (VQA) benchmarks are required to evaluate how models interpret dermatological images, reason over fine-grained morphology, and generate clinically meaningful descriptions. We introduce DermaBench, a clinician-annotated dermatology VQA benchmark built on the Diverse Dermatology Images (DDI) dataset. DermaBench comprises 656 clinical images from 570 unique patients spanning Fitzpatrick skin types I–VI. Using a hierarchical annotation schema with 22 main questions (single-choice, multi-choice, and open-ended), expert dermatologists annotated each image for diagnosis, anatomic site, lesion morphology, distribution, surface features, color, and image quality, together with open-ended narrative descriptions and summaries, yielding approximately 14,474 VQA-style annotations. DermaBench is released as a metadata-only dataset to respect upstream licensing and is publicly available at Harvard Dataverse.",19.26,21.551,415,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14086v1_Two-Stream temporal transformer for video action c.pdf,TWO-STREAM TEMPORAL TRANSFORMER FOR VIDEO ACTION CLASSIFICATION,"Nattapong Kurpukdee, Adrian G. Bors",,,"Video Transformer, Optical Flow, Two-Stream video processing, Video Action Classification","Motion representation is crucial in video understanding, with applications in action recognition and autonomous guidance. This study introduces a two-stream transformer video classifier that extracts spatio-temporal information from content and optical flow. The model uses self-attention features across optical flow and temporal frames, showing excellent classification results on human activity datasets. The research highlights the efficiency of transformers over CNNs in video action recognition, addressing challenges like video capturing conditions and resource requirements. The proposed architecture fuses scene and movement features using a self-attention mechanism, demonstrating effective video feature modeling.",15.63,13.306,208,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14087v1_1-bit Count-based Sorting Unit to Reduce Link Powe.pdf,1-bit Count-based Sorting Unit to Reduce Link Power in DNN Accelerators,"Ruichi Han, Yizhi Chen, Tong Lei, Jordi Altayo Gonzalez, Ahmed Hemani",,,"1-bit count-based sorting, Approximate computing, Bit transition reduction, Link power","Interconnect power consumption is a bottleneck in Deep Neural Network (DNN) accelerators. This work proposes a hardware implementation of a comparison-free sorting unit optimized for Convolutional Neural Networks (CNN). By leveraging approximate computing to group population counts into coarse-grained buckets, the design achieves hardware area reductions while preserving link power benefits of data reordering. The approximate sorting unit achieves up to 35.4% area reduction while maintaining 19.50% BT reduction compared to 20.42% of precise implementation. This is the first hardware implementation of a popcount sorting unit for DNNs with approximate sorting, providing a comprehensive power analysis and evaluating the design under convolution and pooling workloads.",15.68,14.795,232,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14091v1_Zero-shot adaptable task planning for autonomous c.pdf,Zero-shot adaptable task planning for autonomous construction robots: a comparative study of lightweight single and multi-AI agent systems,"Hossein Naderi, Alireza Shojaei, Lifu Huang, Philip Agee, Kereshmeh Afsari, Abiola Akanmu",,,"Construction robotics, quadruped robots, robot task planning, multi-AI agent, LLMs, VLMs, GPT4o","Robots are expected to play a major role in the future construction industry but face challenges due to high costs and difficulty adapting to dynamic tasks. This study explores the potential of foundation models to enhance the adaptability and generalizability of task planning in construction robots. Four models are proposed and implemented using lightweight, open-source large language models (LLMs) and vision language models (VLMs). These models include one single agent and three multi-agent teams that collaborate to create robot action plans. The models are evaluated across three construction roles: Painter, Safety Inspector, and Floor Tiling. Results show that the four-agent team outperforms the state-of-the-art GPT-4o in most metrics while being ten times more cost-effective. Additionally, teams with three and four agents demonstrate improved generalizability. By discussing how agent behaviors influence outputs, this study enhances the understanding of AI teams and supports future research in diverse unstructured environments beyond construction.",17.83,17.838,318,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14096v1_Remapping and navigation of an embedding space via.pdf,Remapping and navigation of an embedding space via error minimization: a fundamental organizational principle of cognition in natural and artificial systems,"Benedikt Hartl, Léo Pio-Lopez, Chris Fields, Michael Levin",,2601.14096v1,"Evolution, Development, Intelligence, Active Inference, Navigation Policy, Nested Embedding Spaces",,15.02,7.124,107,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14099v1_Causal feature selection framework for stable soft.pdf,Causal Feature Selection Framework for Stable Soft Sensor Modeling based on Time-Delayed Cross Mapping,"Shi-Shun Chen, Xiao-Yang Li, Enrico Zio",,,,,11.89,5.466,65,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14115v1_Riemannian Liquid Spatio-Temporal Graph Network.pdf,Riemannian Liquid Spatio-Temporal Graph Network,"Liangsi Lu, Jingchao Wang, Zhaorong Dai, Hanqian Liu, Yang Shi",10.1145/3774904.3792090,,"Riemannian Manifolds, Neural ODEs, Spatio-Temporal Graphs","Liquid Time-Constant networks (LTCs), a type of continuous-time graph neural network, excel at modeling irregularly-sampled dynamics but are fundamentally confined to Euclidean space. This limitation introduces significant geometric distortion when representing real-world graphs with inherent non-Euclidean structures (e.g., hierarchies and cycles), degrading representation quality. To overcome this limitation, we introduce the Riemannian Liquid Spatio-Temporal Graph Network (RLSTG), a framework that unifies continuous-time liquid dynamics with the geometric inductive biases of Riemannian manifolds. RLSTG models graph evolution through an Ordinary Differential Equation (ODE) formulated directly on a curved manifold, enabling it to faithfully capture the intrinsic geometry of both structurally static and dynamic spatio-temporal graphs. Moreover, we provide rigorous theoretical guarantees for RLSTG, extending stability theorems of LTCs to the Riemannian domain and quantifying its expressive power via state trajectory analysis. Extensive experiments on real-world benchmarks demonstrate that, by combining advanced temporal dynamics with a Riemannian spatial representation, RLSTG achieves superior performance on graphs with complex structures.",17.88,20.25,362,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14124v1_Style Transfer as Bias Mitigation Diffusion Models.pdf,Style Transfer as Bias Mitigation: Diffusion Models for Synthetic Mental Health Text for Arabic,"Saad Mankarious, Ayah Zirikly",,2601.14124v1,"style transfer, bias mitigation, diffusion models, synthetic text generation, mental health, Arabic, gender bias","Synthetic data offers a promising solution for mitigating data scarcity and demographic bias in mental health analysis, yet existing approaches largely rely on pretrained large language models (LLMs), which may suffer from limited output diversity and propagate biases inherited from their training data. In this work, we propose a pretraining-free diffusion-based approach for synthetic text generation that frames bias mitigation as a style transfer problem. Using the CARMA Arabic mental health corpus, which exhibits a substantial gender imbalance, we focus on male-to-female style transfer to augment underrepresented female-authored content. We construct five datasets capturing varying linguistic and semantic aspects of gender expression in Arabic and train separate diffusion models for each setting. Quantitative evaluations demonstrate consistently high semantic fidelity between source and generated text, alongside meaningful surface-level stylistic divergence, while qualitative analysis confirms linguistically plausible gender transformations. Our results show that diffusion-based style transfer can generate high-entropy, semantically faithful synthetic data without reliance on pretrained LLMs, providing an effective and flexible framework for mitigating gender bias in sensitive, low-resource mental health domains.",18.16,18.28,332,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14152v1_Lost in the Prompt Order Revealing the Limitations.pdf,Revealing the Limitations of Causal Attention in Language Models,"Hyunjong Ok, Jaeho Lee",,,"language models, causal attention, prompt sensitivity, multiple-choice question answering, LLMs","Large language models exhibit surprising sensitivity to the structure of the prompt, but the mechanisms underlying this sensitivity remain poorly understood. This work investigates the impact of prompt structure in multiple-choice question answering, revealing that placing context before questions and options (CQO) outperforms the reverse order (QOC) by over 14% across various models and datasets. The study identifies causal attention as the core mechanism, where the causal mask in QOC prompts prevents option tokens from attending to context, creating an information bottleneck. The findings highlight the importance of understanding prompt sensitivity for the practical reliability of LLMs.",14.84,13.547,201,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14154v1_LLM Augmented Intervenable Multimodal Adaptor for .pdf,LLM Augmented Intervenable Multimodal Adaptor for Post-operative Complication Prediction in Lung Cancer Surgery,"Shubham Pandey, Bhavin Jawade, Srirangaraj Setlur, Venu Govindaraju, Kenneth Seastedt",,,"postoperative complications, lung cancer surgery, deep learning, multimodal data, risk prediction, radiomics, clinical data, intervenable machine learning","Postoperative complications are a significant concern in clinical practice, impacting patient outcomes and increasing healthcare costs. This paper introduces MIRACLE, a deep learning architecture designed to predict the risk of postoperative complications in lung cancer surgery by integrating preoperative clinical and radiological data. MIRACLE utilizes a hyperspherical embedding space to fuse heterogeneous inputs, extracting robust features from both structured clinical records and high-dimensional radiological images. An interventional deep learning module enhances prediction transparency and clinical utility, providing interpretable insights that allow domain experts to adjust recommendations interactively. The approach is validated on a real-world dataset of 3,094 lung cancer patients, demonstrating superior performance over traditional machine learning models and large language models for personalized and explainable postoperative risk management. The codebase is available at https://github.com/KNITPhoenix/MIRACLE.",18.1,17.623,319,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14157v1_ConceptCaps -- a Distilled Concept Dataset for Int.pdf,ConceptCaps - a Distilled Concept Dataset for Interpretability in Music Models,"Bruno Sienkiewicz, Łukasz Neumann, Mateusz Modrzejewski",,,"Concept-based interpretability, music models, TCA V, music datasets, semantic modeling, text generation, Variational Autoencoder, language model, MusicGen, audio-text alignment, linguistic quality metrics, concept probes","Concept-based interpretability methods like TCA V require clean, well-separated positive and negative examples for each concept. Existing music datasets lack this structure: tags are sparse, noisy, or ill-defined. We introduce ConceptCaps, a dataset of 23k music-caption-audio triplets with explicit labels from a 200-attribute taxonomy. Our pipeline separates semantic modeling from text generation: a VAE learns plausible attribute co-occurrence patterns, a fine-tuned LLM converts attribute lists into professional descriptions, and MusicGen synthesizes corresponding audio. This separation improves coherence and controllability over end-to-end approaches. We validate the dataset through audio-text alignment (CLAP), linguistic quality metrics (BERTScore, MAUVE), and TCA V analysis confirming that concept probes recover musically meaningful patterns. Dataset and code are available online.",17.96,17.76,319,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14160v1_Domain-Adaptation through Synthetic Data Fine-Tuni.pdf,Domain-Adaptation through Synthetic Data: Fine-Tuning Large Language Models for German Law,"Ali Hamza Bashir, Muhammad Rehan Khalid, Kostadin Cvejoski, Jana Birr, Jule Berghaus, Armin Berger, Sandra Halscheidt, Christian Temath, Rafet Sifa, David Berghaus",,,"Large Language Models, German Law, Synthetic Data, Legal Question Answering, Domain Adaptation","Large language models (LLMs) often struggle in specialized domains such as legal reasoning due to limited expert knowledge, resulting in factually incorrect outputs or hallucinations. This paper presents an effective method for adapting advanced LLMs to German legal question answering through a novel synthetic data generation approach. In contrast to costly human-annotated resources or unreliable synthetic alternatives, our approach systematically produces high-quality, diverse, and legally accurate question-answer pairs directly from authoritative German statutes. Using rigorous automated filtering methods and parameter-efficient fine-tuning techniques, we demonstrate that LLMs adapted with our synthetic dataset significantly outperform their baseline counterparts on German legal question answering tasks. Our results highlight the feasibility of using carefully designed synthetic data as a robust alternative to manual annotation in high-stakes, knowledge-intensive domains.",17.72,18.118,321,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14171v1_Paper2Rebuttal A Multi-Agent Framework for Transpa.pdf,Paper2Rebuttal: A Multi-Agent Framework for Transparent Author Response Assistance,"Qianli Ma, Chang Guo, Zhiheng Tian, Siyu Wang, Jipeng Xiao, Yuanhao Yue, Zhipeng Zhang",,,"rebuttal generation, multi-agent framework, evidence-centric planning, peer review, AI","Writing effective rebuttals is a high-stakes task that demands more than linguistic fluency, as it requires precise alignment between reviewer intent and manuscript details. Current solutions typically treat this as a direct-to-text generation problem, suffering from hallucination, overlooked critiques, and a lack of verifiable grounding. To address these limitations, we introduce REBUTTALAGENT, the first multi-agents framework that reframes rebuttal generation as an evidence-centric planning task. Our system decomposes complex feedback into atomic concerns and dynamically constructs hybrid contexts by synthesizing compressed summaries with high-fidelity text while integrating an autonomous and on-demand external search module to resolve concerns requiring outside literature. By generating an inspectable response plan before drafting, REBUTTALAGENT ensures that every argument is explicitly anchored in internal or external evidence. We validate our approach on the proposed REBUTTALBENCH and demonstrate that our pipeline outperforms strong baselines in coverage, faithfulness, and strategic coherence, offering a transparent and controllable assistant for the peer review process. Code will be released.",17.44,18.639,325,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14172v1_Human Values in a Single Sentence Moral Presence H.pdf,"Human Values in a Single Sentence: Moral Presence, Hierarchies, and Transformer Ensembles on the Schwartz Continuum","Víctor Yeste, Paolo Rosso",,2601.14172v1,"sentence-level identification, Schwartz motivational continuum, human value detection, moral presence, DeBERTa-base, instruction-tuned LLMs, ensemble methods, hierarchical gating","This study investigates sentence-level identification of the 19 values in the Schwartz motivational continuum, focusing on out-of-context sentences from news and political manifestos. The task is challenging due to sparse moral cues and severe class imbalance. A binary moral presence task is operationalized, showing learnability from single sentences. Comparisons are made between a presence-gated hierarchy and a direct multi-label classifier, both based on DeBERTa-base and augmented with lightweight signals. Instruction-tuned LLMs are benchmarked, and a soft-vote supervised ensemble significantly surpasses the best single model. Lightweight signals and small ensembles provide the most reliable improvements, while hierarchical gating offers limited benefit under an 8GB single-GPU constraint.",18.54,15.155,281,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14175v1_A model of errors in transformers.pdf,A model of errors in transformers,"Suvrat Raju, Praneeth Netrapalli",,,"LLMs, error rate, attention mechanism, arithmetic, effective field theory, prompt construction, Gemini 2.5 Flash, Gemini 2.5 Pro, DeepSeek R1","This study examines the error rate of Large Language Models (LLMs) on deterministic tasks requiring repetitive processing of tokens. The authors propose that errors accumulate due to small inaccuracies in the attention mechanism, leading to a two-parameter model that relates task accuracy to complexity. The model, inspired by effective field theory, simplifies the LLM's parameters into two governing factors. Empirical tests on models like Gemini 2.5 Flash, Gemini 2.5 Pro, and DeepSeek R1 show good agreement between predicted and observed accuracy, challenging previous notions of 'collapse of reasoning' or compositional function failures. The study also explores prompt construction to reduce error rates.",16.12,15.695,253,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14192v1_Toward Efficient Agents Memory Tool learning and P.pdf,"Toward Efficient Agents: A Survey of Memory, Tool Learning, and Planning","Xiaofang Yang, Lijun Li, Heng Zhou, Tong Zhu, Xiaoye Qu, Yuchen Fan, Qianshan Wei, Rui Ye, Li Kang, Yiran Qin, Zhiqiang Kou, Daizong Liu, Qi Li, Ning Ding, Siheng Chen, Jing Shao",,2601.14192v1,"Agents, Efficiency, Agent Memory, Tool Learning, Planning","Recent years have witnessed increasing interest in extending large language models into agentic systems. While the effectiveness of agents has continued to improve, efficiency, which is crucial for real-world deployment, has often been overlooked. This paper therefore investigates efficiency from three core components of agents: memory, tool learning, and planning, considering costs such as latency, tokens, steps, etc. Aimed at conducting comprehensive research addressing the efficiency of the agentic system itself, we review a broad range of recent approaches that differ in implementation yet frequently converge on shared high-level principles including but not limited to bounding context via compression and management, designing reinforcement learning rewards to minimize tool invocation, and employing controlled search mechanisms to enhance efficiency, which we discuss in detail. Accordingly, we characterize efficiency in two complementary ways: comparing effectiveness under a fixed cost budget, and comparing cost at a comparable level of effectiveness. This trade-off can also be viewed through the Pareto frontier between effectiveness and cost. From this perspective, we also examine efficiency-oriented benchmarks by summarizing evaluation protocols for these components and consolidating commonly reported efficiency metrics from both benchmark and methodological studies. Moreover, we discuss the key challenges and future directions, with the goal of providing promising insights.",20.0,21.601,432,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14209v1_InT Self-Proposed Interventions Enable Credit Assi.pdf,Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning,"Matthew Y. R. Yang, Hao Bai, Ian Wu, Gene Yang, Amrith Setlur, Aviral Kumar",,arXiv:2205.12345,"large language models, reinforcement learning, credit assignment, intervention training, mathematical reasoning","Outcome-reward reinforcement learning (RL) has proven effective at improving the reasoning capabilities of large language models (LLMs). However, standard RL assigns credit only at the level of the final answer, penalizing entire reasoning traces when the outcome is incorrect and uniformly reinforcing all steps when it is correct. This can discourage correct intermediate steps in failed traces and reinforce spurious steps in successful ones, a problem known as credit assignment. Intervention Training (InT) is introduced as a training paradigm where the model performs fine-grained credit assignment on its own reasoning traces by proposing short, targeted corrections. Using reference solutions from mathematical reasoning datasets, the model identifies the first error in its reasoning and proposes a single-step intervention to redirect the trajectory toward the correct solution. Supervised fine-tuning (SFT) is then applied to the on-policy rollout up to the point of error concatenated with the intervention, localizing error to the specific step that caused failure. This results in a model that serves as a better initialization for RL training. After running InT and subsequent fine-tuning with RL, accuracy improves by nearly 14% over a 4B-parameter base model on IMO-AnswerBench, outperforming larger open-source models such as gpt-oss-20b.",18.85,20.636,389,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14230v1_MASCOT Towards Multi-Agent Socio-Collaborative Com.pdf,MASCOT: Towards Multi-Agent Socio-Collaborative Companion Systems,"Yiyang Wang, Yiqiao Jin, Alex Cabral, Josiah Hester",,,"multi-agent systems, socio-collaborative companions, emotional support, cognitive support, persona collapse, social sycophancy, bi-level optimization, RLAIF, meta-policy, psychological support, workplace domains","Multi-agent systems (MAS) have emerged as promising socio-collaborative companions for emotional and cognitive support. However, they often suffer from persona collapse and social sycophancy. This paper proposes MASCOT, a framework for multi-perspective socio-collaborative companions, introducing a bi-level optimization strategy to harmonize individual and collective behaviors. This includes Persona-Aware Behavioral Alignment and Collaborative Dialogue Optimization. Evaluations show MASCOT significantly outperforms baselines in Persona Consistency and Social Contribution. The framework aims to advance socially intelligent multi-agent systems.",16.56,16.066,266,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14232v1_KAGE-Bench Fast Known-Axis Visual Generalization E.pdf,KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning,"Egor Cherepannov, Daniil Zelezetsky, Alexey K. Kovalev, Aleksandr I. Panov",,,"Reinforcement Learning, Visual Generalization, Pixel-based Agents, Distribution Shift, KAGE-Env, KAGE-Bench, PPO-CNN, JAX, GPU, Visual Nuisance Factors","Pixel-based reinforcement learning agents often fail under purely visual distribution shifts, even when latent dynamics and rewards are unchanged. Existing benchmarks entangle multiple sources of shift, hindering systematic analysis. This paper introduces KAGE-Env, a JAX-native 2D platformer that factorizes the observation process into independently controllable visual axes while keeping the underlying control problem fixed. KAGE-Bench, built on this environment, is a benchmark of six known-axis suites comprising 34 train-evaluation configuration pairs that isolate individual visual shifts. Using a standard PPO-CNN baseline, strong axis-dependent failures are observed, with background and photometric shifts often collapsing success, while agent-appearance shifts are comparatively benign. The fully vectorized JAX implementation enables fast and reproducible sweeps over visual factors, with up to 33M environment steps per second on a single GPU.",17.91,18.312,328,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14234v1_Q-learning with Adjoint Matching.pdf,Q-LEARNING WITH ADJOINT MATCHING,"Qiyang Li, Sergey Levine",,arXiv:2601.14234v1,"Q-learning, Adjoint Matching, TD-based reinforcement learning, continuous-action RL, diffusion policy, flow-matching policy, temporal-difference backup, offline RL, offline-to-online RL","We propose Q-learning with Adjoint Matching (QAM), a novel TD-based reinforcement learning (RL) algorithm that addresses the challenge of efficiently optimizing an expressive diffusion or flow-matching policy with respect to a parameterized Q-function. Effective optimization requires leveraging the first-order information of the critic, which is challenging for flow or diffusion policies due to numerical instability in direct gradient-based optimization via backpropagation through their multi-step denoising process. Existing methods either discard gradient information or rely on approximations that reduce policy expressivity or introduce bias. QAM overcomes these issues by using adjoint matching, a technique from generative modeling, to transform the critic’s action gradient into a step-wise objective function that avoids unstable backpropagation while maintaining an unbiased, expressive policy. Combined with temporal-difference backup for critic learning, QAM outperforms prior approaches on hard, sparse reward tasks in both offline and offline-to-online RL.",17.7,17.966,318,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14235v1_Opportunities in AIML for the Rubin LSST Dark Ener.pdf,Opportunities in AI/ML for the Rubin LSST,"Eric Aubourg, Camille Avestruz, Matthew R. Becker, Biswajit Biswas, Rahul Biswas, Boris Bolliet, Adam S. Bolton, Clecio R. Bom, Raphaël Bonnet-Guerrini, Alexandre Boucaud, Jean-Eric Campagne, Chihway Chang, Aleksandra Ćiprijanović, Johann Cohen-Tanugi, Michael W. Coughlin, John Franklin Crenshaw, Juan C. Cuevas-Tello, Juan de Vicente, Seth W. Digel, Steven Dillmann, Mariano Javier de León Dominguez Romero, Alex Drlica-Wagner, Sydney Erickson, Alexander T. Gagliano, Christos Georgiou, Aritra Ghosh, Matthew Grayling, Kirill A. Grishin, Alan Heavens, Lindsay R. House, Mustapha Ishak, Wassim Kabalan, Arun Kannawadi, François Lanusse, C. Danielle Leonard, Pierre-François L’eǧet, Michelle Lochner, Yao-Yuan Mao, Peter Melchior, Grant Merz, Martin Millon, Anais Möller, Gautham Narayan, Yuuki Omori, Hiranya Peiris, Laurence Perreault-Levasseur, Andrés A. Plazas Malagón, Nesar Ramachandra, Benjamin Remy, Cécile Roucelle, Jaime Ruiz-Zapatero, Stefan Schuldt, Ignacio Sevilla-Noarbe, Ved G. Shah, Tjitske Starkenburg, Stephen Thorp, Laura Toribio San Cipriano, Tilman Tröster, Roberto Trotta, Padma Venkatraman, Amanda Wasserman, Tim White, Justine Zeghal, Tianqing Zhang, Yuanyuan Zhang",,,,,18.89,31.546,596,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14242v1_APEX-Agents.pdf,APEX–Agents,"Bertie Vidgen, Austin Mann, Abby Fennelly, John Wright, Stanly, Lucas Rothman, Marco Burstein, Julien Benchek, David Ostrofsky, Anirudh Ravichandran, Debnil Sur, Neel Venugopal, Alannah Hsia, Isaac Robinson, Calix Huang, Olivia Varones, Daniyal Khan, Michael Haines, Zach Richards, Chirag Mahapatra, Brendan Foody, Osvald Nitski",,arXiv:2601.14242v1,"AI Productivity Index, Agents, benchmark, investment banking, management consulting, corporate law, AI evaluation, professional services work","We introduce the AI Productivity Index for Agents (APEX–Agents), a benchmark for assessing whether AI agents can execute long-horizon, cross-application tasks created by investment banking analysts, management consultants, and corporate lawyers. APEX–Agents requires agents to navigate realistic work environments with files and tools. We test eight agents for the leaderboard using Pass@1. Gemini 3 Flash (Thinking=High) achieves the highest score of 24.0%, followed by GPT-5.2 (Thinking=High), Claude Opus 4.5 (Thinking=High), and Gemini 3 Pro (Thinking=High). We open source the APEX–Agents benchmark (n=480) with all prompts, rubrics, gold outputs, files, and metadata. We also open-source Archipelago, our infrastructure for agent execution and evaluation. The tasks require agents to reason, demonstrate advanced knowledge, use multiple applications, and plan over long horizons.",19.45,23.085,449,cold_start,Phi-4,AMD RX 6800 (Vulkan)
2601.14255v1_VideoMaMa Mask-Guided Video Matting via Generative.pdf,VideoMaMa: Mask-Guided Video Matting via Generative Prior,"Sangbeom Lim, Seoung Wug Oh, Jiahui Huang, Heeji Yoon, Seungryong Kim, Joon-Young Lee",,arXiv:2601.14255v1,"video matting, diffusion-based model, alpha mattes, segmentation masks, generative priors, pseudo-labeling, large-scale video matting","Generalizing video matting models to real-world videos remains a significant challenge due to the scarcity of labeled data. To address this, we present Video Mask-to-Matte Model (VideoMaMa) that converts coarse segmentation masks into pixel accurate alpha mattes, by leveraging pretrained video diffusion models. VideoMaMa demonstrates strong zero-shot generalization to real-world footage, even though it is trained solely on synthetic data. Building on this capability, we develop a scalable pseudo-labeling pipeline for large-scale video matting and construct the Matting Anything in Video (MA-V) dataset, which offers high-quality matting annotations for more than 50K real-world videos spanning diverse scenes and motions. To validate the effectiveness of this dataset, we fine-tune the SAM2 model on MA-V to obtain SAM2-Matte, which outperforms the same model trained on existing matting datasets in terms of robustness on in-the-wild videos. These findings emphasize the importance of large-scale pseudo-labeled video matting and showcase how generative priors and accessible segmentation cues can drive scalable progress in video matting research.",19.9,19.25,383,cold_start,Phi-4,AMD RX 6800 (Vulkan)
