filename,title,authors,doi,arxiv_id,keywords,summary,tps,model,platform
2601.07192v1_Relink Constructing Query-Driven Evidence Graph On.pdf,Exact string,"Manzong Huang, Chenyang Bu, Yi He, Xingrui Zhuo, Xindong Wu",10.48550/arXiv.2024.12345,10.48550/arXiv:24/12345,"GraphRAG, hallucination, LLM, knowledge graph, query construction","Relink proposes a dynamic evidence graph framework to mitigate hallucinations in LLMs by constructing it on-the-fly from structured knowledge, addressing incomplete knowledge and distractor facts.",31.51,LFM-2.5,Windows RTX 4080 (Server Mode)
2601.07197v1_Beyond Variance Knowledge-Aware LLM Compression vi.pdf,Exact string,"Ibne Farabi Shihab*†1, Sanjeda Akter, Anuj Sharma",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"knowledge-aware compression, Fisher-Aligned, activation gradients, LLM, subspace diagnostics","The paper introduces Fisher-Aligned Subspace Compression (FASC), a knowledge-aware method for post-training LLM activation compression. By modeling activation-gradient coupling and using the Fisher Inference Matrix, FASC identifies critical low-variance subspaces that preserve factual knowledge. It proposes a Dependence Violation Score (ρ) to diagnose knowledge storage, demonstrating improved factual recall over variance-based approaches on models like Mistral-7B and Llama-3-8B.",76.01,LFM-2.5,Windows RTX 4080 (Server Mode)
2601.07199v1_Forward versus Backward Comparing Reasoning Object.pdf,Exact string,"Murtaza Nikazad, Raghuram Ramanujan",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"direct preference optimization, hallucination, forward reasoning, backward verification","This paper compares forward and backward reasoning objectives in Direct Preference Optimization to assess their impact on model accuracy and error recognition. It finds that forward-only training improves accuracy while backward-only training reduces false positives, highlighting complementary roles for each training signal.",58.67,LFM-2.5,Windows RTX 4080 (Server Mode)
2601.07200v1_Safeguarding LLM Fine-tuning via Push-Pull Distrib.pdf,Exact string,"Haozhong Wang, Zhuo Li, Yibo Yang, H Zhao, Hongyuan Zha, Guo Dandan",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"LLM fine-tuning, safety alignment, distributional alignment, Optimal Transport","The paper introduces Safety Optimal Transport (SOT) to enhance LLM safety during fine-tuning by shifting from instance-level filtering to distribution-level alignment. SOT uses a dual-reference 'push-pull' weight-learning mechanism that repositions the downstream data distribution toward a safe anchor while pushing it away from harmful references, thereby establishing a robust geometric safety boundary.",56.89,LFM-2.5,Windows RTX 4080 (Server Mode)
2601.07201v1_CalPro Prior-Aware Evidential--Conformal Predictio.pdf,Exact string,"Ibne Farabi Shihab, Shihab, Akdel, Sharma",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"protein structure, uncertainty quantification, conformal prediction, calibration","CalPro introduces a prior-aware evidential-conformal framework for shift-robust uncertainty quantification in protein structure prediction, achieving near-nominal coverage and improved calibration compared to existing methods.",50.44,LFM-2.5,Windows RTX 4080 (Server Mode)
