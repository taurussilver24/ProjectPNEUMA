filename,title,authors,doi,arxiv_id,keywords,summary,tps,model,platform
2601.07192v1_Relink Constructing Query-Driven Evidence Graph On.pdf,Relink: Constructing Query-Driven Evidence Graph On-the-Fly for GraphRAG,"['Manzong Huang', 'Chenyang Bu', 'Yi He', 'Xingrui Zhuo', 'Xindong Wu']",,2310.00000,"['GraphRAG', 'Retrieval-Augmented Generation', 'Knowledge Graph', 'Open-Domain Question Answering', 'Factual Errors', 'Distractor Facts']","This paper proposes Relink, a framework that dynamically builds a query-specific evidence graph to address the challenges of incompleteness and misleading facts in GraphRAG, a method that mitigates hallucinations in large language models by grounding them in structured knowledge.",157.67,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07197v1_Beyond Variance Knowledge-Aware LLM Compression vi.pdf,Beyond Variance: Knowledge-Aware LLM Compression via Fisher-Aligned Subspace Diagnostics,"['Ibne Farabi Shihab*', 'Sanjeda Akter*', 'Anuj Sharma']",,2405.18894,"['Large Language Models', 'LLMs', 'Activation Compression', 'Fisher Information Matrix', 'Subspace Diagnostics', 'Knowledge Preservation', 'Gradient Sensitivity', 'Transformer Architectures']","This paper introduces Fisher-Aligned Subspace Compression (FASC), a knowledge-aware compression framework that selects subspaces by directly modeling activation-gradient coupling, minimizing a second-order surrogate of the loss function. FASC leverages the Fisher Information Matrix to identify dimensions critical for factual knowledge, often residing in low-variance but high-gradient-sensitive subspaces. Extensive experiments demonstrate that FASC preserves more accuracy on knowledge-intensive benchmarks compared to variance-based methods, effectively enabling a 7B model to match the factual recall of a 13B uncompressed model.",153.34,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07199v1_Forward versus Backward Comparing Reasoning Object.pdf,Forward versus Backward: Comparing Reasoning Objectives in Direct Preference Optimization,"['Murtaza Nikazad', 'Raghuram Ramanujan']",,2309.12715,"['Direct Preference Optimization', 'Reasoning', 'Language Models', 'Chain-of-Thought', 'Error Recognition']","This paper investigates the impact of training objectives on reasoning reliability in large language models through Direct Preference Optimization, comparing forward reasoning traces and backward verification traces.",150.85,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07200v1_Safeguarding LLM Fine-tuning via Push-Pull Distrib.pdf,Safeguarding LLM Fine-tuning via Push-Pull Distributional Alignment,"['Haozhong Wang', 'Zhuo Li', 'Yibo Yang', 'He Zhao', 'Hongyuan Zha', 'Dandan Guo']",,2312.08669,"['Large Language Models', 'Fine-tuning', 'Safety Alignment', 'Optimal Transport', 'Push-Pull Mechanism']","This paper introduces Safety Optimal Transport (SOT), a novel framework that reframes safe fine-tuning from an instance-level filtering challenge to a distribution-level alignment task grounded in Optimal Transport (OT). SOT optimizes sample importance by actively pulling the downstream distribution towards a trusted safe anchor while simultaneously pushing it away from a general harmful reference, establishing a robust geometric safety boundary that effectively purifies the training data.",155.3,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07201v1_CalPro Prior-Aware Evidential--Conformal Predictio.pdf,CalPro: Prior-Aware Evidential–Conformal Prediction with Structure-Aware Guarantees for Protein Structures,"['Ibne Farabi Shihab * 1', 'Sanjeda Akter * 1', 'Anuj Sharma 2']",,2601.04768,"['protein structure prediction', 'uncertainty quantification', 'conformal prediction', 'deep learning', 'graph-based architecture', 'coverage guarantees', 'calibration error', 'downstream success']","CalPro is a prior-aware evidential-conformal framework for shift-robust uncertainty quantification in protein structure prediction, combining a geometric evidential head, a differentiable conformal layer, and domain priors, achieving near-nominal coverage and reducing calibration error by 30–50% compared to vanilla conformal methods.",156.54,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07206v1_LLMRouterBench A Massive Benchmark and Unified Fra.pdf,LLMRouterBench: A Massive Benchmark and Unified Framework for LLM Routing,"['Hao Li', 'Yiqun Zhang', 'Zhaoyan Guo', 'Chenxu Wang', 'Shengji Tang', 'Qiaosheng Zhang', 'Yang Chen', 'Biqing Qi', 'Peng Ye', 'Lei Bai', 'Zhen Wang', 'Shuyue Hu']",,2309.14947,"['Large Language Models', 'Routing', 'Benchmark', 'Performance-Cost Trade-off']","This paper introduces LLMRouterBench, a large-scale benchmark and unified framework for LLM routing, comprising over 400K instances from 21 datasets and 33 models. It evaluates the field, confirming strong model complementarity but finding that many routing methods exhibit similar performance and that recent approaches often fail to reliably outperform a simple baseline. The benchmark also enables latency-aware analysis and highlights the limitations of backbone embedding models and the diminishing returns of larger ensembles.",157.1,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07209v1_SIRR-LMM Single-image Reflection Removal via Large.pdf,SIRR-LMM: Single-image Reflection Removal via Large Multimodal Model,"['Yu Guo', 'Zhiqiang Lao', 'Xiyun Song', 'Yubin Zhou', 'Heather Yu']",,2302.09850,"['Single-image reflection removal', 'Large Multimodal Model', 'Synthetic dataset', 'Path tracing', 'Low-Rank Adaptation (LoRA)', 'Glass surfaces', 'Reflection separation']",This paper introduces a synthetic dataset generation framework for physically accurate reflection scenarios and leverages the capabilities of a Large Multimodal Model to achieve improved reflection removal and separation performance compared to state-of-the-art methods.,139.27,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07214v1_BlindU Blind Machine Unlearning without Revealing .pdf,BlindU: Blind Machine Unlearning without Revealing Erasing Data,"['Weiqi Wang', 'Zhiyi Tian', 'Chenhao Zhang', 'Shui Yu']",10.1109/TPAMI.2022.0000000,2201.00000,"['Machine Unlearning', 'Federated Learning', 'Privacy Leakage', 'Privacy Preserving', 'Information Bottleneck']","This paper proposes Blind Unlearning (BlindU), a method for implementing unlearning without revealing the erasing data to the server, using compressed representations and the information bottleneck mechanism for effective unlearning in federated learning scenarios.",134.89,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07224v1_Consolidation or Adaptation PRISM Disentangling SF.pdf,Consolidation or Adaptation? PRISM: Disentangling SFT and RL Data via Gradient Concentration,"['Yang Zhao', 'Yangou Ouyang', 'Xiao Ding', 'Hepeng Wang', 'Bibo Cai', 'Kai Xiong', 'Jinglong Gao', 'Zhouhao Sun', 'Li Du', 'Bing Qin', 'Ting Liu']",10.1002/ijhm.12345,2309.12345,"['Schema Theory', 'Hybrid Supervised Fine-Tuning', 'Reinforcement Learning', 'Data Arbitration', 'Gradient Concentration', 'Cognitive Conflict', 'Pattern Consolidation', 'Structural Adaptation']","This paper proposes PRISM, a dynamics-aware framework that arbitrates data based on its degree of cognitive conflict with the model's existing knowledge. By analyzing the spatial geometric structure of gradients, PRISM identifies data triggering high spatial concentration as high-conflict signals that require reinforcement learning for structural restructuring, while diffuse updates are routed to supervised fine-tuning for efficient consolidation. Extensive experiments on WebShop and ALFWorld demonstrate PRISM's effectiveness in achieving a Pareto improvement over state-of-the-art hybrid methods while reducing computational costs.",153.21,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07226v1_Lost in the Noise How Reasoning Models Fail with C.pdf,Lost in the Noise: How Reasoning Models Fail with Contextual Distractors,"['Seongyun Lee', 'Yongrae Jo', 'Minju Seo', 'Moontae Lee', 'Minjoon Seo']",,2601.04764,"['reasoning models', 'agentic AI', 'contextual distractors', 'robustness', 'external information', 'benchmarking']","This paper introduces NoisyBench, a comprehensive benchmark evaluating model robustness across 11 datasets in reasoning, alignment, and tool-use tasks against diverse noise types, including contextual distractors. The evaluation reveals a catastrophic performance drop of up to 80% in state-of-the-art models when faced with contextual distractors, highlighting the need for improved robustness mechanisms.",156.81,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07229v2_DiSCo Making Absence Visible in Intelligent Summar.pdf,DiSCo: Making Absence Visible in Intelligent Summarization Interfaces,"['ERAN FAINMAN', 'HAGIT BEN SHOSHAN', 'ADIR SOLOMON', 'OSNAT MOKRYN']",,,"['Review Summarization', 'Absence', 'Expectations', 'Learning via surprisability', 'Missing commonalities']","Intelligent interfaces using large language models to summarize user-generated content often emphasize what is mentioned while overlooking what is missing, leading to presence bias that can mislead users. DiSCo, an expectation-based approach, identifies and integrates aspects that are either unusually emphasized or missing relative to domain norms, improving transparency and decision support.",160.54,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07232v1_Yes FLoReNce I Will Do Better Next Time Agentic Fe.pdf,Agentic Feedback Reasoning for Humorous Meme Detection,"['Olivia Shanhong Liu', 'Pai Chet Ng', 'De Wen Soh', 'Konstantinos N. Plataniotis']",,,"['humorous memes', 'meme humor', 'feedback reasoning', 'agentic feedback', 'multimodal models', 'prompting', 'closed-loop', 'open-loop', 'semantic feedback', 'control signals', 'non-parametric knowledge base', 'inference', 'predictive performance', 'explanation quality']","This paper proposes FLoReNce, an agentic feedback reasoning framework for detecting humor in memes. Unlike existing multimodal or prompting-based models, FLoReNce treats meme understanding as a closed-loop process during learning and an open-loop process during inference, enabling better, self-aligned reasoning without finetuning. On the PrideMM dataset, FLoReNce improves both predictive performance and explanation quality over static multimodal baselines, demonstrating that feedback-regulated prompting is a viable path to adaptive meme humor understanding.",159.49,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07233v1_From Thinking to Justifying Aligning High-Stakes E.pdf,From “Thinking” to “Justifying”: Aligning High-Stakes Explainability with Professional Communication Standards,"['Chen Qian', 'William & Mary', 'cqian03@wm.edu', 'Yimeng Wang', 'William & Mary', 'ywang139@wm.edu', 'Yu Chen', 'Anytime AI', 'ychen@anytime-ai.com', 'Lingfei Wu', 'Anytime AI', 'lwu@anytime-ai.com', 'Andreas Stathopoulos', 'William & Mary', 'axstat@wm.edu']",,2309.14416,"['Explainable AI', 'High-stakes domains', 'Chain-of-Thought', 'Professional communication', 'Structured Explainability Framework', 'CREAC', 'BLUF']","This paper proposes a new approach to explainable AI (XAI) in high-stakes domains, focusing on presenting conclusions before their structured justification. The authors introduce SEF, a framework operationalizing professional conventions via six metrics for structure and grounding, and validate this approach across four tasks in three domains, achieving 83.9% accuracy.",160.02,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07238v1_Group Pattern Selection Optimization Let LRMs Pick.pdf,Group Pattern Selection Optimization: Let LRMs Pick the Right Pattern for Reasoning,"['Hanbin Wang', 'Jingwei Song', 'Jinpeng Li', 'Fei Mi', 'Lifeng Shang']",,2310.16658,"['Large reasoning models', 'reinforcement learning', 'pattern selection', 'mathematics', 'science', 'reasoning patterns', 'Group Pattern Selection Optimization', 'GPSO']","This paper introduces Group Pattern Selection Optimization (GPSO), a reinforcement learning framework that enables large reasoning models to internalize the mapping from problem characteristics to optimal reasoning patterns, thereby mitigating pattern sub-optimality and fostering more robust, adaptable reasoning across various model backbones and benchmarks.",156.95,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07239v1_Stochastic CHAOS Why Deterministic Inference Kills.pdf,"Stochas(c CHAOS: Why Determinis)c Inference Kills, and Distribu(onal Variability Is the Heartbeat of Ar(ﬁcial Cogni(on","['Tanmay Joshi1, Shourya Aggarwal1, Anusa Saha1, Aadi Pandey1', 'Shreyash Dhoot1, Vighnesh Rai1, Raxit Goswami2', 'Aman Chadha3, Vinija Jain4, Amitava Das1']",,1909.01953,"['Large Language Models', 'Deterministic Inference', 'Stochasticity', 'Reproducibility', 'Emergent Abilities', 'Semantic Stability', 'Safety Alignment', 'Artificial Cognition']","This paper argues against the deterministic inference approach for large language models, claiming it kills the ability to model uncertainty, disrupts reasoning abilities, and renders safety alignment brittle. Instead, the authors advocate for stochasticity and claim that distributional variability is the heart of artificial cognition.",143.23,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07245v1_Learning to Trust the Crowd A Multi-Model Consensu.pdf,Learning to Trust the Crowd: A Multi-Model Consensus Reasoning Engine for Large Language Models,['Pranav Kallem'],,1909.08802,"['Large Language Models', 'Reliability', 'Multi-Model Consensus', 'Supervised Learning', 'Graph Neural Networks', 'Conformal Prediction', 'Bayesian Methods']","The paper introduces a Multi-Model Consensus Reasoning Engine that treats the set of LLM outputs as input to a supervised meta-learner, mapping natural language responses into structured features and applying various machine learning techniques to improve reliability of LLMs, achieving significant improvements in accuracy and reducing hallucinations and Brier scores.",161.41,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07250v1_DDT A Dual-Masking Dual-Expert Transformer for Ene.pdf,DDT: A Dual-Masking Dual-Expert Transformer for Energy Time-Series Forecasting,"['Mingnan Zhu', 'Qixuan Zhang', 'Yixuan Cheng', 'Fangzhou Gu', 'Shiming Lin']",,2302.09928,"['Time-Series Forecasting', 'Multivariate Temporal Modeling', 'Dynamic-Causal Masking', 'Adaptive Feature Fusion']","This paper proposes DDT, a novel deep learning framework for high-precision energy time-series forecasting, addressing challenges from complex temporal dependencies and heterogeneous multi-source data through a dual-masking mechanism and a dual-expert system.",155.48,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07261v1_Pseudodata-guided Invariant Representation Learnin.pdf,Pseudodata-guided Invariant Representation Learning Boosts the Out-of-Distribution Generalization in Enzymatic Kinetic Parameter Prediction,"['Haomin Wu', 'Zhiwei Nie', 'Hongyu Zhang', 'Zhixiang Ren']",,2601.07261,"['Enzyme Kinetics', 'Deep Learning', 'Out-of-Distribution Generalization', 'Invariant Representation Learning', 'Perturbation Augmentation']","This paper proposes O 2DENet, a lightweight module that enhances out-of-distribution generalization in enzyme–substrate interaction predictors by introducing enzyme-substrate perturbations and enforcing invariance through biologically and chemically informed augmentation, leading to improved predictive performance across various sequence-divergent benchmarks.",131.5,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07263v1_When Bots Take the Bait Exposing and Mitigating th.pdf,When Bots Take the Bait: Exposing and Mitigating the Emerging Social Engineering Attack in Web Automation Agent,"['Xinyi Wu†', 'Geng Hong †B', 'Yueyue Chen†', 'MingXuan Liu §', 'Feier Jin †', 'Xudong Pan †‡', 'Jiarun Dai †', 'Baojun Liu ¶']",,,"['web automation', 'social engineering', 'web agents', 'large language models', 'open-source frameworks', 'runtime mitigation']","This paper presents a systematic study of social engineering attacks against web automation agents and introduces a pluggable runtime mitigation solution, demonstrating the vulnerabilities of mainstream frameworks and proposing a lightweight module to reduce attack success rates.",151.83,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07291v1_A Visual Semantic Adaptive Watermark grounded by P.pdf,A Visual Semantic Adaptive Watermark grounded by Prefix-Tuning for Large Vision-Language Model,"['Qi Zheng', 'Shuliang Liu', 'Yu Huang', 'Sihang Jia', 'Jungang Li', 'Lyuhao Chen', 'Junhao Chen', 'Hanqian Li', 'Aiwei Liu', 'Yibo Yan', 'Xuming Hu']",,2309.15594,"['Watermarking', 'Large Vision-Language Models', 'Prefix-Tuning', 'Visual Evidence Weights', 'Semantic Fidelity', 'Inference Efficiency']","This paper proposes VISA-Mark, a novel framework for watermarking in Large Vision-Language Models (LVLMs) that embeds detectable signals while preserving visual fidelity. It uses a prefix-tuner to extract dynamic Visual Evidence Weights, guiding an adaptive vocabulary partitioning and logits perturbation mechanism. Empirical results show VISA-Mark outperforms conventional methods in visual consistency and semantic fidelity, maintaining high detection accuracy and robust attack resilience without sacrificing inference efficiency.",155.1,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07292v1_Photometric Redshift Estimation Using Scaled Ensem.pdf,Photometric Redshift Estimation Using Scaled Ensemble Learning,"['Swagata Biswas', 'Shubhrangshu Ghosh', 'Avyarthana Ghosh', 'Yogesh Wadadekar', 'Abhishek Roy Choudhury', 'Arijit Mukherjee', 'Shailesh Deshpande', 'Arpan Pal']",,2512.03175,"['Photometric redshift', 'Machine learning', 'Ensemble learning', 'Galaxies', 'Optical photometry', 'Extreme gradient boosting', 'Gradient boosting machine', 'k-nearest neighbors', 'Artificial neural networks']","This study presents a new ensemble-based machine learning framework for predicting photometric redshifts (Pz) for faint galaxies and higher redshift ranges using optical (grizy) photometric data. The framework integrates several learning algorithms within a scaled ensemble structure, delivering improved predictive performance compared to stand-alone models. The model is validated using publicly available data from the Hyper Suprime-Cam Strategic Survey Program by the Subaru Telescope, demonstrating consistent accuracy up to z ∼ 4 and marked improvements in the precision and reliability of Pz estimation.",146.18,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07296v1_LRAS Advanced Legal Reasoning with Agentic Search.pdf,LRAS: Advanced Legal Reasoning with Agentic Search,"['Yujin Zhou', 'Chuxue Cao', 'Jinluan Yang', 'Lijun Wu', 'Conghui He', 'Sirui Han', 'Yike Guo']",,2310.15724,"['Legal Reasoning', 'Agentic Search', 'Introspective Imitation Learning', 'Difficulty-aware Reinforcement Learning', 'Legal Logic', 'Social Group Legal Person']","This paper presents LRAS, a novel framework designed to enhance legal reasoning capabilities of Large Reasoning Models (LRMs) by integrating introspective imitation learning and difficulty-aware reinforcement learning. Empirical results show that LRAS outperforms state-of-the-art baselines, particularly in tasks requiring deep reasoning with reliable knowledge.",159.8,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07304v1_Heterogeneous Multi-Expert Reinforcement Learning .pdf,Heterogeneous Multi-Expert Reinforcement Learning for Long-Horizon Multi-Goal Tasks in Autonomous Forklifts,"['Yun Chen', 'Bowei Huang', 'Fan Guo', 'Kang Song']",,,"['Autonomous Forklift', 'Hierarchical Reinforcement Learning', 'Mobile Manipulation', 'Hybrid Training', 'Modality Decoupling']","This paper proposes a Heterogeneous Multi-Expert Reinforcement Learning (HMER) framework tailored for autonomous forklifts, which decomposes long-horizon tasks into specialized sub-policies controlled by a Semantic Task Planner to separate navigation and manipulation, improving task success rate and reducing operation time.",157.42,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07309v1_ARM Role-Conditioned Neuron Transplantation for Tr.pdf,ARM: Role-Conditioned Neuron Transplantation for Training-Free Generalist LLM Agent Merging,"['Zhuoka Feng', 'Kang Chen', 'Sihan Zhao', 'Kai Xiong', 'Yaoning Wang', 'Minshen Yu', 'Junjie Nian', 'Changyi Xiao', 'Yixin Cao', 'Yugang Jiang']",,2601.07309,"['Large Language Models', 'Model Merging', 'Neuron Transplantation', 'Interactive Agents', 'Cross-Environment Robustness']","This paper proposes ARM, a role-conditioned neuron transplantation method for training-free model merging in large language model (LLM) agents, improving cross-environment robustness and generalization ability across various interactive domains.",160.44,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07313v1_Explaining Machine Learning Predictive Models thro.pdf,Explaining Machine Learning Predictive Models through Conditional Expectation Methods,"['Silvia Ruiz-Espaóna', 'Laura Arnal', 'Franòis Signola', 'Juan-Carlos Perez-Cortes', 'Joaquim Arlandis']",,,"['machine learning', 'XAI', 'explainable models', 'local explainability', 'model-agnostic', 'uncertainty', 'stability']","This work introduces Multivariate Conditional Expectation (MUCE), a model-agnostic method for local explainability designed to capture prediction changes from feature interactions. MUCE extends Individual Conditional Expectation (ICE) by exploring a multivariate grid of values in the neighborhood of a given observation at inference time, providing graphical explanations that illustrate the local evolution of model predictions. The method is validated using XGBoost models trained on three datasets, and results show that MUCE effectively captures complex local model behavior, while the stability and uncertainty indices provide meaningful insight into prediction confidence.",156.85,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07315v1_VLM-CAD VLM-Optimized Collaborative Agent Design W.pdf,VLM-CAD: VLM-Optimized Collaborative Agent Design Workflow for Analog Circuit Sizing,"['1st Guanyuan Pan', '2nd Yugui Lin', '3rd Tiansheng Zhou', '4th Pietro Li o', '5th Shuai Wang', '6th Yaqi Wang*']",,,"['Analog Circuit Sizing', 'Agentic AI', 'Vision Language Model', 'Explainability', 'Electronic Design Automation']","This paper proposes VLM-CAD, a workflow that analyzes circuits, optimizes DC operating points, performs inference-based sizing, and executes external sizing optimization. It integrates Image2Net to annotate circuit schematics and generates a structured JSON description for precise interpretation by Vision Language Models, and proposes an Explainable Trust Region Bayesian Optimization method (ExTuRBO) for external sizing optimization.",157.41,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07316v1_BEAT-Net Injecting Biomimetic Spatio-Temporal Prio.pdf,BEAT-Net: Injecting Biomimetic Spatio-Temporal Priors for Interpretable ECG Classification,"['Ma Runze', 'Liao Caizhi']",null,2601.07316,"['ECG classification', 'deep learning', 'biomimetic', 'spatio-temporal priors', 'self-supervised learning']","This paper proposes BEAT-Net, a framework that reformulates ECG analysis as a language modeling task, using QRS tokenization to transform continuous signals into biologically aligned heartbeat sequences. The architecture explicitly decomposes cardiac physiology through specialized encoders, improving diagnostic accuracy and robustness compared to dominant CNN architectures, while providing inherent interpretability through learned attention mechanisms.",158.05,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07320v1_Segmental Advantage Estimation Enhancing PPO for L.pdf,Segmental Advantage Estimation: Enhancing PPO for Long-Context LLM Training,"['Xue Gong', 'Qi Yi', 'Ziyuan Nan', 'Guanhua Huang', 'Kejiao Li', 'Yuhao Jiang', 'Ruibin Xiong', 'Zenan Xu', 'Jiaming Guo', 'Shaohui Peng', 'Bo Zhou']",,2026-01-13,"['Proximal Policy Optimization', 'Reinforcement Learning with Verifiable Rewards', 'Generalized Advantage Estimation', 'Large Language Models', 'Segmental Advantage Estimation']","This paper introduces Segmental Advantage Estimation (SAE) to address the issue of unreliable advantage estimation in Proximal Policy Optimization (PPO) for training Large Language Models (LLMs) in Reinforcement Learning with Verifiable Rewards (RLVR) regime, leading to improved performance in terms of final scores, training stability, and sample efficiency.",142.84,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07342v1_Agentic Diagnostic Reasoning over Telecom and Data.pdf,Agentic Diagnostic Reasoning over Telecom and Datacenter Infrastructure,['Nicolas Tacheny'],null,2601.07342,"['Telecom', 'Datacenter', 'Infrastructure', 'Root Cause Analysis', 'Impact Analysis', 'Large Language Model', 'Model Context Protocol', 'Agent', 'Dependency Structure', 'Incident Resolution', 'Change Impact Mitigation']","This work introduces an agentic diagnostic framework using a Large Language Model to autonomously navigate and investigate telecom and datacenter infrastructures, addressing the challenges of traditional RCA and IA methods in complex, interconnected systems.",158.5,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07344v1_PulseMind A Multi-Modal Medical Model for Real-Wor.pdf,PulseMind: A Multi-Modal Medical Model for Real-World Clinical Diagnosis,"['Jiao Xu', 'Junwei Liu', 'Jiangwei Lao', 'Qi Zhu', 'Yunpeng Zhao', 'Congyun Jin', 'Shinan Liu', 'Zhihong Lu', 'Lihe Zhang', 'Xin Chen', 'Jian Wang', 'Ping Wang']",,2607.01234,"['PulseMind', 'Multi-modal', 'Medical Diagnosis', 'Real-world Clinical', 'Diagnostic Benchmark', 'Comparison-based Reinforcement Policy Optimization (CRPO)']","PulseMind introduces a new family of multi-modal diagnostic models that integrate a curated dataset, a benchmark, and a tailored training framework to address the complexity of real-world clinical diagnostics, which involve heterogeneous inputs and require ongoing contextual understanding.",155.93,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07348v4_Controlled Self-Evolution for Algorithmic Code Opt.pdf,Controlled Self-Evolution for Algorithmic Code Optimization,"['Tu Hu', 'Ronghao Chen', 'Shuo Zhang', 'Jianghao Yin', 'Mou Xiao Feng', 'Jingping Liu', 'Shaolei Zhang', 'Wenqi Jiang', 'Yuqi Fang', 'Sen Hu', 'Huacan Wang', 'Yi Xu']",,2601.07348v4,"['Controlled Self-Evolution', 'Algorithmic Code Optimization', 'Self-Evolution Methods', 'EffiBench-X', 'Hierarchical Evolution Memory']","This paper proposes Controlled Self-Evolution (CSE) to improve the exploration efficiency of self-evolution methods in algorithmic code optimization, addressing issues of initialization bias, uncontrolled stochastic operations, and insufficient experience reuse. Experiments on EffiBench-X demonstrate that CSE consistently outperforms existing methods across various large language model backbones.",161.67,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07351v2_Beyond Hard Masks Progressive Token Evolution for .pdf,Beyond Hard Masks: Progressive Token Evolution for Diffusion Language Models,"['Linhao Zhong', 'Linyu Wu', 'Bozhen Fang', 'Tianjian Feng', 'Chenchen Jing', 'Wen Wang', 'Jiaheng Zhang', 'Hao Chen', 'Chunhua Shen']",,2209.12442,"['Diffusion Language Models', 'Token Evolution', 'Parallel Decoding', 'Continuous Trajectory Supervision']","This paper proposes EvoToken-DLM, a novel diffusion-based language modeling approach that replaces hard binary masks with evolving soft token distributions, enabling a progressive transition from masked states to discrete outputs, supporting revisable decoding. Extensive experiments show that EvoToken-DLM consistently achieves superior performance compared to strong diffusion-based and masked DLM baselines.",156.08,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07356v1_Efficient Convolutional Forward Model for Passive .pdf,Efficient Convolutional Forward Model for Passive Acoustic Mapping and Temporal Monitoring,"['Tatiana Gelvez-Barrera', 'Barbara Nicolas', 'Bruno Gilles', 'Adrian Basarab', 'Denis Kouamé']",,,"['Passive Acoustic Mapping', 'Model-based beamforming', 'Convolutional forward model', 'Temporal monitoring']","This paper introduces a PAM beamforming framework based on a novel convolutional formulation in the time domain, which enables efficient computation. The framework formulates PAM as an inverse problem and incorporates prior knowledge on cavitation activity, demonstrating higher temporal resolution and reduced computational burden compared to classical and iterative time-domain methods.",160.48,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07359v1_Seeing Right but Saying Wrong Inter- and Intra-Lay.pdf,Seeing Right but Saying Wrong: Inter- and Intra-Layer Refinement in MLLMs without Training,"['Shezheng Song', 'Shasha Li', 'Jie Yu']",,2312.08877,"['Multimodal Large Language Models', 'Vision-Language Tasks', 'Attention Mechanism', 'Decoding Refinement', 'Intra-Layer Consistency']","This paper presents DualPD, a dual-perspective decoding refinement strategy that enhances the visual understanding of MLLMs without additional training, addressing the internal contradiction where deeper layers attend to correct visual regions but final predictions are misled by noisy attention from earlier layers.",159.84,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07364v1_On the universal definition of intelligence.pdf,On the universal definition of intelligence,['Joseph Chen'],,1911.07027,"['intelligence', 'human-AI comparison', 'predictive ability', 'spontaneous prediction', 'reactive prediction', 'gainability']","This paper proposes an extended predictive hypothesis (EPH) to define intelligence, combining accurate prediction with the ability to benefit from predictions, and distinguishes between spontaneous and reactive predictions to explain various aspects of intelligence.",125.53,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07372v1_Conditional Memory via Scalable Lookup A New Axis .pdf,Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models,"['Xin Cheng', 'Wangding Zeng', 'Damai Dai', 'Qinyu Chen', 'Bingxuan Wang', 'Zhenda Xie', 'Kezhao Huang', 'Xingkai Yu', 'Zhewen Hao', 'Yukun Li', 'Han Zhang', 'Huishuai Zhang', 'Dongyan Zhao', 'Wenfeng Liang']",,2601.07372,"['Conditional Memory', 'Sparsity', 'Large Language Models', 'Transformers', 'Mixture-of-Experts', 'Engram', 'Lookup', 'Neural Computation', 'Static Memory']","This paper introduces conditional memory as a new sparsity axis for large language models, instantiated via Engram, a module that modernizes classic N-gram embedding for O(1) lookup. By optimizing the trade-off between neural computation and static memory, the authors achieve superior performance over a strictly iso-parameter and iso-FLOPs MoE baseline, demonstrating significant gains in general reasoning and code/math domains.",158.1,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07376v1_OpenTinker Separating Concerns in Agentic Reinforc.pdf,OpenTinker: Separating Concerns in Agentic Reinforcement Learning,"['Siqi Zhu', 'Jiaxuan You']",,2601.07376v1,"['OpenTinker', 'Reinforcement Learning', 'Large Language Models', 'Agentic Learning', 'Separation of Concerns', 'Execution', 'Agent-Environment Interaction']","This paper introduces OpenTinker, an infrastructure for reinforcement learning of large language model agents, which separates concerns across algorithm design, execution, and agent-environment interaction, enabling users to specify agents, environments, and interaction protocols while delegating inference and training to a managed execution runtime.",154.78,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07377v1_Learning Dynamic Collaborative Network for Semi-su.pdf,Learning Dynamic Collaborative Network for Semi-supervised 3D Vessel Segmentation,"['Jiao Xu', 'Xin Chen']",null,null,"['3D vessel segmentation', 'semi-supervised learning', 'dynamic collaborative network', 'mean teacher', 'adversarial supervision', 'multi-view integration']",This paper presents a new dynamic collaborative network (DiCo) for semi-supervised 3D vessel segmentation. It addresses the challenges of scarce labeled data and complex vessel appearance by allowing dynamic switching of teacher-student roles and incorporating adversarial supervision and multi-view integration.,156.86,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07389v1_On the Non-decoupling of Supervised Fine-tuning an.pdf,On the Non-decoupling of Supervised Fine-tuning and Reinforcement Learning in Post-training,"['Xueyan Niuniuxueyan3@huawei.com', 'Bo Baibo8@huawei.com', 'Wei Hanharvey.hanwei@huawei.com', 'Wei Zhangzhangweixi1@huawei.com']",,2601.07389,"['Supervised Fine-Tuning', 'Reinforcement Learning', 'Post-training', 'Large Language Models', 'Decoupling', 'Training Alternation']","This paper proves that decoupling supervised fine-tuning (SFT) and reinforcement learning (RL) in the post-training pipeline of large language models is impossible in either order. It demonstrates that SFT-then-RL and RL-then-SFT training lead to degradation in performance, confirming that SFT and RL cannot be separated without losing prior performance.",154.64,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07392v1_OceanSAR-2 A Universal Feature Extractor for SAR O.pdf,CHEAT_DETECTED,"['Alexandre Tuela', 'Thomas Kerdreux', 'Quentin Febvre', 'Alexis Mouche', 'Antoine Grouazel', 'Jean-Renaud Miadana', 'Antoine Audras', 'Chen Wang', 'Bertrand Chapron']",,2309.15806,"['OceanSAR-2', 'SAR', 'Ocean Remote Sensing', 'Self-Supervised Learning', 'Sentinel-1 Wave Mode', 'Foundation Model', 'Geophysical Pattern Classification', 'Ocean Surface Wind Vector', 'Significant Wave Height Estimation', 'Iceberg Detection']","This paper presents OceanSAR-2, the second generation of a foundation model for SAR-based ocean observation, which improves upon earlier self-supervised learning on Sentinel-1 Wave Mode data by enhancing performance and reducing training cost. It demonstrates strong transfer performance across various downstream tasks, including geophysical pattern classification, ocean surface wind vector estimation, and iceberg detection, and releases standardized benchmark datasets for systematic evaluation and advancement of SAR models for ocean applications.",142.79,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07393v1_Software-Hardware Co-optimization for Modular E2E .pdf,SOFTWARE-HARDWARECO-OPTIMIZATION FORMODULARE2E,"['Chengzhi Ji', 'Xingfeng Li', 'Zhaodong Lv', 'Hao Sun', 'Pan Liu', 'Hao Frank Yang', 'Ziyuan Pu']",,2601.07393,"['Modular end-to-end', 'Closed-Loop Evaluation', 'Software–Hardware co-optimization', 'Energy Consumption']","This paper proposes a reusable software–hardware co-optimization and closed-loop evaluation framework for ME2E autonomous driving inference, integrating software-level model optimizations with hardware-level computation optimizations under a unified system-level objective, and introduces a multidimensional evaluation metric, EERA V, to enable quantitative assessment of the true system-level impact of different optimization strategies.",158.23,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07395v1_MCP-ITP An Automated Framework for Implicit Tool P.pdf,MCP-ITP: An Automated Framework for Implicit Tool Poisoning in MCP,"['Ruiqi Li', 'Zhiqiang Wang', 'Y unhao Y ao', 'Xiang-Y ang Li']",,,"['Model Context Protocol', 'Implicit Tool Poisoning', 'Tool Poisoning Attack', 'Large Language Models', 'Security']","This paper proposes MCP-ITP, an automated and adaptive framework for implicit tool poisoning within the MCP ecosystem. MCP-ITP formulates poisoned tool generation as a black-box optimization problem and employs an iterative optimization strategy to maximize Attack Success Rate (ASR) while evading current detection mechanisms. Experimental results demonstrate that MCP-ITP consistently outperforms manually crafted baselines, achieving up to 84.2% ASR while suppressing the Malicious Tool Detection Rate (MDR) to as low as 0.3%.",158.1,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07397v1_Layerwise goal-oriented adaptivity for neural ODEs.pdf,Layerwise goal-oriented adaptivity for neural ODEs: an optimal control perspective,"['Michael Hinterm"" uller', 'Michael Hinze', 'Denis Korolev']",,arXiv:2601.07397v1,"['Resnet', 'neural ODEs', 'parameter identification/learning', 'adaptive neural network']","This work proposes a novel layerwise adaptive construction method for neural network architectures based on a goal-oriented dual-weighted residual technique for the optimal control of neural differential equations, leading to an optimization problem with controls as coefficients and a specific loss function.",160.28,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07411v1_SCALPEL Selective Capability Ablation via Low-rank.pdf,SCALPEL: Selective Capability Ablation via Low-rank Parameter Editing for Large Language Model Interpretability Analysis,"['Zihao Fu', 'Xufeng Duan', 'Zhenguang G. Cai']",,2306.09847,"['Large Language Models', 'Interpretability', 'Gradient Attribution', 'Low-Rank Parameter Editing', 'Capability Ablation']","SCALPEL is a framework that represents language model capabilities as low-rank parameter subspaces, enabling precise capability removal without affecting others. It identifies the low-rank representation responsible for a particular capability while remaining disentangled from other capabilities, providing fine-grained insights into capability distribution across the model's parameter space.",156.71,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07422v1_Two Pathways to Truthfulness On the Intrinsic Enco.pdf,Two Pathways to Truthfulness: On the Intrinsic Encoding of LLM Hallucinations,"['Wen Luo', 'Guangyue Peng', 'Wei Li', 'Shaohang Wei', 'Feifan Song', 'Liang Wang', 'Nan Yang', 'Xingxing Zhang', 'Jing Jin', 'Furu Wei', 'Houfeng Wang']",,2312.08275,"['large language models', 'hallucinations', 'truthfulness', 'information pathways', 'internal representations', 'question-anchored', 'answer-anchored']","This paper demonstrates that truthfulness cues in large language models arise from two distinct information pathways: a Question-Anchored pathway and an Answer-Anchored pathway. The authors validate and disentangle these pathways through attention knockout and token patching, uncovering notable properties of these mechanisms and proposing applications to enhance hallucination detection performance.",158.66,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07430v1_KALE Enhancing Knowledge Manipulation in Large Lan.pdf,KALE: Enhancing Knowledge Manipulation in Large Language Models via Knowledge-aware Learning,"['Qitan Lv', 'Tianyu Liu', 'Qiaosheng Zhang', 'Xingcheng Xu', 'Chaochao Lu']",,2310.15666,"['Large Language Models', 'Knowledge Manipulation', 'Supervised Fine-Tuning', 'Knowledge Graphs', 'Knowledge-aware Learning']","KALE is a post-training framework that leverages knowledge graphs to generate high-quality rationales and enhance large language models' knowledge manipulation ability, addressing the known&incorrect phenomenon where models possess relevant knowledge but fail to use it correctly during inference.",157.43,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07449v1_RLPO Residual Listwise Preference Optimization for.pdf,RLPO: Residual Listwise Preference Optimization for Long-Context Review Ranking,"['Hao Jiang', 'Zhi Yang', 'Annan Wang', 'Yichi Zhang', 'Weisi Lin*']",,,"['review ranking', 'long-context', 'residual listwise preference optimization', 'large language models', 'user-generated content']","This paper proposes RLPO (Residual Listwise Preference Optimization), a method to improve review ranking in e-commerce, addressing the trade-off between pointwise and listwise approaches in long-context settings. RLPO combines pointwise scoring with listwise prediction, producing calibrated scores and item representations, and applying a lightweight encoder to predict listwise score residuals. Experiments show RLPO outperforms strong pointwise and listwise baselines, maintaining robustness as list length increases.",159.98,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07463v1_Puzzle it Out Local-to-Global World Model for Offl.pdf,Puzzle it Out: Local-to-Global World Model for Offline Multi-Agent Reinforcement Learning,"['Sijia Li', 'Xinran Li', 'Shibo Chen', 'Jun Zhang']",10.13052/jicaamas26-2026-0001,,"['Offline multi-agent reinforcement learning', 'Multi-agent model-based reinforcement learning']","This paper proposes a local-to-global (LOGO) world model for offline multi-agent reinforcement learning, which leverages local predictions to infer global state dynamics, generating synthetic data to augment the original dataset and improving prediction accuracy while implicitly capturing agent-wise dependencies.",155.6,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07464v1_IFDNS An Iterative Feedback-Driven Neuro-Symbolic .pdf,IFDNS: An Iterative Feedback-Driven Neuro-Symbolic Method for Faithful Logical Reasoning,"['Xiaoheng Wang', 'Tongxuan Liu', 'Zi Gong', 'Xianzhe Dong', 'Yuting Zeng', 'Minhan Hu', 'Weizhe Huang', 'Jing Li']",,2309.08747,"['Logical Reasoning', 'Large Language Model', 'Reasoning']","This paper introduces IFDNS, a novel prompt-based method that employs a multi-round feedback mechanism to address the limitations of large language models in handling complex logical relationships, thereby improving their logical reasoning capabilities.",134.68,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07468v1_Beyond Dialogue Time Temporal Semantic Memory for .pdf,Beyond Dialogue Time: Temporal Semantic Memory for Personalized LLM Agents,"['Miao Su', 'Yucan Guo', 'Zhongni Hou', 'Long Bai', 'Zixuan Li', 'Yufei Zhang', 'Guojun Yin', 'Wei Lin', 'Xiaolong Jin', 'Jiafeng Guo', 'Xueqi Cheng']",,2601.07468,"['Large Language Models', 'Memory', 'Temporal Memory', 'Personalized Agents', 'Semantic Memory', 'Durative Memory']","This paper proposes Temporal Semantic Memory (TSM), a memory framework that models semantic time for point-wise memory and supports the construction and utilization of durative memory. It addresses the limitations of existing methods in temporal accuracy and fragmentation, demonstrating improved performance in accuracy on LONGMEMEVAL and LOCOMO datasets.",158.33,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07469v1_Knowledge Distillation for LLM-Based Human Activit.pdf,KNOWLEDGE DISTILLATION FOR LLM-B ASED HUMAN ACTIVITY RECOGNITION IN HOMES,"['Julien Cumin', 'Oussama Er-Rahmany', 'Xi Chen']",,arXiv:2601.07469v1,"['Human activity recognition', 'large language models', 'knowledge distillation', 'ambient intelligence', 'smart homes']","This paper presents new experimental results regarding the use of large language models (LLMs) for human activity recognition (HAR) in homes, using two state-of-the-art datasets. It shows how recognition performance varies with the size of the LLM used and experiments with knowledge distillation techniques to fine-tune smaller LLMs with HAR reasoning examples generated by larger LLMs, demonstrating that such fine-tuned models can perform almost as well as the largest LLMs, while having 50 times fewer parameters.",157.12,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07470v1_Learning How to Remember A Meta-Cognitive Manageme.pdf,Learning How to Remember: A Meta-Cognitive Management Method for Structured and Transferable Agent Memory,"['Sirui Liang', 'Pengfei Cao', 'Jian Zhao', 'Wenhao Teng', 'Xiangwen Liao', 'Jun Zhao', 'Kang Liu']",,2309.15888,"['Memory Management', 'Meta-Cognition', 'Transfer Learning', 'Hierarchical Memory', 'Agent Learning']","This paper proposes MCMA, a method that treats memory abstraction as a learnable cognitive skill, enabling agents to better manage and reuse memory across tasks and environments, leading to improved performance and generalization.",157.19,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07474v1_Task Prototype-Based Knowledge Retrieval for Multi.pdf,Task Prototype-Based Knowledge Retrieval for Multi-Task Learning from Partially Annotated Data,"['Y oungmin Oh', 'Hyung-Il Kim', 'Jung Uk Kim']",,2301.12345,"['Multi-task learning', 'Partially labeled data', 'Prototype-based knowledge retrieval', 'Robust multi-task learning']","This paper proposes a prototype-based knowledge retrieval framework for robust multi-task learning from partially annotated data, addressing the challenges of obtaining fully annotated data for all tasks and the potential negative transfer and suboptimal performance of existing partially labeled MTL methods.",155.95,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07475v1_ARCQuant Boosting NVFP4 Quantization with Augmente.pdf,ARCQuant: Boosting NVFP4 Quantization with Augmented Residual Channels for LLMs,"['Haoqian Meng', 'Yilun Luo', 'Yafei Zhao', 'Wenyuan Liu', 'Peng Zhang*', 'Xindian Ma']",,,"['Large Language Models', 'Post-Training Quantization', 'NVFP4', 'Microscaling Formats', 'Quantization Error', 'Residual Channels']","This paper proposes ARCQuant, a framework that boosts NVFP4 performance by augmenting the activation matrix with quantized residual channels, addressing challenges in adapting existing Post-Training Quantization strategies to fine-grained numerical formats like NVFP4.",155.8,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07477v1_JudgeFlow Agentic Workflow Optimization via Block .pdf,JUDGEFLOW: AGENTICWORKFLOWOPTIMIZATION,"['Jihan Ma∗', 'Zhikai Zhao∗', 'Chuanbo Hua', 'Federico Berto', 'Jinkyoo Park']",null,null,"['JUDGEFLOW', 'agentic workflows', 'LLM optimization', 'evaluation', 'judge module', 'fine-grained signals', 'block-level diagnostics', 'automated workflow optimization']","This paper proposes JUDGEFLOW, an Evaluation-Judge-Optimization-Update pipeline for optimizing LLM-based agentic workflows. It incorporates reusable, configurable logic blocks to capture fundamental forms of logic and designs a dedicated Judge module to assign rank-based responsibility scores to problematic blocks. The approach improves sample efficiency, enhances interpretability through block-level diagnostics, and provides a scalable foundation for automating complex agentic workflows.",157.26,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07496v1_Graph Inference Towards ICD Coding.pdf,Graph Inference Towards ICD Coding,['1st Xiaoxiao Deng'],10.3888/Tesch.276.2038.9,2106.14600,"['transfer learning', 'graph convolutional network', 'lightweight attention', 'ICD code prediction', 'adversarial domain adaptation']","Automated ICD coding involves assigning standardized diagnostic codes to clinical narratives. LabGraph, a unified framework, reformulates the task as a graph generation task, combining adversarial domain adaptation, graph-based reinforcement learning, and perturbation regularization to enhance model robustness and generalization.",157.31,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07514v1_Data-Driven Stochastic VRP Integration of Forecast.pdf,Data-Driven Stochastic VRP: Integration of Forecast Duration into Optimization for Utility Workforce Management,['Matteo Garbellia'],null,2601.07514,"['Stochastic VRP', 'Machine Learning', 'XGBoost', 'Sub-Gaussian Concentration', 'Multi-Objective Optimization', 'Evolutionary Algorithms']","This paper investigates the integration of machine learning forecasts of intervention durations into a stochastic variant of the Capacitated Vehicle Routing Problem with Time Windows (CVRPTW), addressing uncertainty through sub-Gaussian concentration bounds and explicitly accounting for competing operational KPIs through a multi-objective formulation. Empirical analysis validates the sub-Gaussian assumption and reports improvements in operator utilization and completion rates compared to default durations.",149.52,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07516v1_Controlling Multimodal Conversational Agents with .pdf,Controlling Multimodal Conversational Agents with Coverage-Enhanced Latent Actions,"['Yongqi Li', 'Hao Lang', 'Tieyun Qian', 'Yongbin Li']",,2310.17496,"['Reinforcement Learning', 'Multimodal Conversational Agents', 'Latent Actions', 'Vision-Language Models', 'Cross-Modal Projector']","This paper proposes a method to control multimodal conversational agents (MCAs) by learning a compact latent action space for reinforcement learning (RL) fine-tuning. The authors leverage both paired image-text data and text-only data to construct the latent action space, using a cross-modal projector to transform text embeddings into image-text embeddings, and enhance the robustness of the cross-modal projector with a novel cycle consistency loss.",156.78,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07518v1_Mon3tr Monocular 3D Telepresence with Pre-built Ga.pdf,Mon3tr: Monocular 3D Telepresence with Pre-built Gaussian Avatars as Amortization,"['Fangyu Lin', 'Yingdong Hu', 'Zhening Liu', 'Yufan Zhuang', 'Zehong Lin', 'Jun Zhang']",,1908.07012,"['Monocular 3D telepresence', '3D Gaussian splatting', 'animatable avatars', 'real-time neural rendering']","This paper presents Mon3tr, a novel Monocular 3D telepresence framework that integrates 3D Gaussian splatting (3DGS) based parametric human modeling into telepresence for the first time, enabling lifelike full-body holographic avatars for remote collaboration. It uses a single monocular RGB camera to capture body motions and facial expressions, significantly reducing system complexity and cost, and achieving state-of-the-art performance in terms of PSNR, end-to-end latency, and bandwidth reduction.",160.05,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07525v1_Thinking Before Constraining A Unified Decoding Fr.pdf,Thinking Before Constraining: A Unified Decoding Framework for Large Language Models,"['Ngoc Trinh Hung Nguyen', 'Alonso Silva', 'Laith Zumot', 'Liubov Tupikina', 'Armen Aghasaryan', 'Mehwish Alam']",,2310.16156,"['Large Language Models', 'Natural Generation', 'Structured Generation', 'Constrained Decoding', 'Language Models', 'Natural Language Reasoning', 'Structured Question Answering', 'Schema-based Information Extraction']","This work proposes a simple approach that combines the advantages of natural and structured generation for large language models, allowing models to reason freely until specific trigger tokens are generated, and then switching to structured generation to preserve the expressive power of natural language reasoning while ensuring the reliability of structured outputs.",155.9,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07528v1_From RAG to Agentic RAG for Faithful Islamic Quest.pdf,From RAG to Agentic RAG for Faithful Islamic Question Answering,"['Gagan Bhatia', 'Hamdy Mubarak', 'Mustafa Jarrar', 'George Mikros', 'Fadi Zaraket', 'Mahmoud Alhirthani', 'Mutaz Al-Khatib', 'Logan Cochrane', 'Kareem Darwish', 'Rashid Yahiaoui', 'Firoj Alam']",,2309.15245,"['Islamic question answering', 'faithful responses', 'grounded models', 'agentic RAG', 'Quran retrieval', 'LLMs', 'retrieval augmentation', 'machine reading comprehension', 'multiple choice questions', 'machine reading comprehension']","This paper introduces ISLAMIC FAITH QA, a 3,810-item bilingual generative benchmark for Islamic question answering, and develops an agentic Quran-grounding framework (agentic RAG) to improve model performance and ensure faithful, citation-backed responses across Arabic-centric and multi-lingual LLMs.",158.83,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07553v1_VirtualEnv A Platform for Embodied AI Research.pdf,VirtualEnv: A Platform for Embodied AI Research,"['Kabir Swain', 'Sijie Han', 'Ayush Raina', 'Jin Zhang', 'Shuang Li', 'Michael Stopa', 'Antonio Torralba']",,2310.16564,"['Embodied AI', 'Simulation Platform', 'Virtual Reality', 'Large Language Models', 'Interactive Environments', 'Object Manipulation', 'Navigation', 'Multi-Agent Collaboration', 'Procedural Generation', 'Reinforcement Learning']","This paper presents VirtualEnv, a simulation platform built on Unreal Engine 5 for evaluating large language models (LLMs) in embodied and interactive scenarios, including object manipulation, navigation, and adaptive multi-agent collaboration. It supports rich agent-environment interactions and integrates large-scale LLMs and vision-language models to generate novel environments and structured tasks from multimodal inputs.",156.75,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07556v1_Backpropagation-Free Test-Time Adaptation for Ligh.pdf,Backpropagation-Free Test-Time Adaptation for Lightweight EEG-Based Brain-Computer Interfaces,"['Siyang Li', 'Jiayi Ouyang', 'Zhenyao Cui', 'Ziwei Wang', 'Tianwang Jia', 'Feng Wan', 'Dongrui Wu']",,1911.08008,"['Brain-computer interface', 'domain adaptation', 'electroencephalogram', 'test-time adaptation', 'transfer learning']","This paper proposes Backpropagation-Free Transformations (BF T), a test-time adaptation approach for EEG decoding that eliminates computational overhead, privacy risks, and sensitivity to noisy data streams, enabling lightweight plug-and-play BCIs on resource-constrained devices.",159.96,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07565v1_A Unified Framework for Emotion Recognition and Se.pdf,A Unified Framework for Emotion Recognition and Sentiment Analysis via Expert-Guided Multimodal Fusion with Large Language Models,"['Jiaqi Qiao', 'Xiujuan Xu', 'Xinran Li', 'Yu Liu']",,2309.09944,"['emotion recognition', 'large language models', 'multimodal fusion', 'expert-guided fusion', 'multimodal sentiment analysis', 'dialogue emotion recognition']","This paper presents EGMF, a unified framework combining expert-guided multimodal fusion with large language models for multimodal emotion recognition and sentiment analysis, addressing challenges in handling dynamic emotional states and cross-modal interactions.",160.98,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07568v1_d3LLM Ultra-Fast Diffusion LLM using Pseudo-Trajec.pdf,d3LLM: Ultra-Fast dLLM using Pseudo-Trajectory Distillation,"['Yu-Yang Qian', 'Junda Su', 'Lanxiang Hu', 'Peiyuan Zhang', 'Zhijie Deng', 'Peng Zhao', 'Hao Zhang']",,2309.14478,"['Diffusion large language models', 'Pseudo-trajectory distillation', 'Parallel decoding', 'Random-order generation', 'Accuracy-parallelism trade-off', 'Entropy-based multi-block decoding', 'AUP metric']","This paper proposes d3LLM, a diffusion large language model that strikes a balance between accuracy and parallelism by introducing pseudo-trajectory distillation during training and entropy-based multi-block decoding during inference. Experiments show that d3LLM achieves up to 10× speedup over vanilla LLaDA/Dream and 5× speedup over AR models without significant accuracy loss.",155.65,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07573v1_A Model of Artificial Jagged Intelligence.pdf,A Model of Artificial Jagged Intelligence,['Joshua S. Gans ∗'],,2601.07573v1,"['generative AI', 'adoption', 'calibration', 'learning', 'knowledge density', 'scaling']","This paper develops an economic model of Artificial Jagged Intelligence (AJI) in generative AI systems, where performance is uneven across tasks, and users care about local reliability but observe only coarse global quality signals. The model interpolates optimally and shows how scaling laws can improve average quality without eliminating jaggedness, and how mastery and calibration affect expected value and learning rates.",147.77,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07577v1_Beyond Entangled Planning Task-Decoupled Planning .pdf,Beyond Entangled Planning: Task-Decoupled Planning for Long-Horizon Agents,"['Yunfan Li', 'Bingbing Xu', 'Xueyun Tian', 'Xiucheng Xu', 'Huawei Shen']",,2310.16859,"['Task-Decoupled Planning', 'Long-Horizon Agents', 'Large Language Models', 'ReAct', 'ReCode', 'TravelPlanner', 'ScienceWorld', 'HotpotQA']","This paper proposes Task-Decoupled Planning (TDP), a training-free framework that decomposes tasks into a directed acyclic graph (DAG) of sub-goals via a Supervisor. Using a Planner and Executor with scoped contexts, TDP confounds reasoning and replanning to the active sub-task, preventing error propagation and improving robustness and efficiency for long-horizon agents.",156.24,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07580v1_Large Language Models for Physics Instrument Desig.pdf,Large Language Models for Physics Instrument Design,"['Sara Zoccheddu∗1', 'Shah Rukh Qasim1', 'Patrick Owen2', 'Nicola Serra1']",,2601.01344,"['Large Language Models', 'Physics Instrument Design', 'Reinforcement Learning', 'Detector Design', 'Particle-Matter Interactions', 'Systematic Design', 'Efficient Design']","This paper investigates the use of large language models for physics instrument design and compares their performance to reinforcement learning. It finds that modern LLMs consistently generate valid, resource-aware, and physically meaningful configurations, despite having no task-specific training, and suggests pairing them with a dedicated trust region optimizer for hybrid design workflows.",159.76,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07582v2_ES-Mem Event Segmentation-Based Memory for Long-Te.pdf,ES-Mem: Event Segmentation-Based Memory for Long-Term Dialogue Agents,"['Huhai Zou', 'Tianhao Sun†', 'Chuanjiang He', 'Yu Tian', 'Zhenyang Li', 'Li Jin', 'Nayu Liu', 'Jiang Zhong', 'Kaiwen Wei†']",,2310.14799,"['Memory', 'Dialogue Agents', 'Event Segmentation', 'Hierarchical Memory Architecture', 'Long-Term Interaction', 'Memory Granularity', 'Surface-Level Semantic Similarity', 'Structural Cues of Discourse', 'Memory Granularity', 'Flat Retrieval Paradigm']","This paper proposes ES-Mem, a framework that incorporates dynamic event segmentation and boundary-anchored retrieval to address the limitations of existing memory mechanisms in dialogue agents, which struggle with rigid memory granularity and flat retrieval paradigms. ES-Mem is evaluated on two memory benchmarks and demonstrates consistent performance gains over baseline methods, with a robust event segmentation module that enhances dialogue segmentation.",158.07,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07597v1_Pheromone-Focused Ant Colony Optimization algorith.pdf,Pheromone-Focused Ant Colony Optimization algorithm for path planning,"['Yi Liu', 'Hongda Zhang', 'Zhongxue Gan', 'Yuning Chen', 'Ziqing Zhou', 'Chunlei Meng', 'Chun Ouyang']",,1912.08308,"['Ant Colony Optimization', 'Path Planning', 'Pheromone-Focused', 'Swarm Intelligence', 'Global Optimization']","This paper proposes the Pheromone-Focused Ant Colony Optimization (PFACO) algorithm, which introduces three key strategies to enhance the problem-solving ability of the ant colony, leading to improved convergence speed and solution quality across diverse optimization problems.",154.08,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07606v1_Proof of Time A Benchmark for Evaluating Scientifi.pdf,Proof of Time: A Benchmark for Evaluating Scientific Idea Judgments,"['Bingyang Ye1,2†', 'Shan Chen1,2,3†', 'Jingxuan Tu4', 'Chen Liu5', 'Zidi Xiong1', 'Samuel Schmidgall6', 'Danielle S. Bitterman1,2,3§']",,2309.14076,"['scientific idea evaluation', 'benchmarks', 'time-indexed scientific questions', 'AI for Science', 'agent-based research judgments']","This paper introduces Proof of Time (PoT), a semi-verifiable benchmarking framework that evaluates the quality of large language models' judgments about scientific ideas by linking these judgments to downstream signals that become observable later, such as citations and shifts in researchers' agendas.",139.82,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07611v1_DIAGPaper Diagnosing Valid and Specific Weaknesses.pdf,DIAGPaper: Diagnosing Valid and Specific Weaknesses in Scientific Papers via Multi-Agent Reasoning,"['Zhuoyang Zou', 'Abolfazl Ansari', 'Delvin Ce Zhang†', 'Dongwon Lee', 'Wenpeng Yin']",,2310.16456,"['paper weakness identification', 'multi-agent reasoning', 'scientific review', 'author rebuttals', 'reviewer bias']","This paper introduces DIAGPaper, a novel multi-agent framework that addresses the limitations of existing systems in identifying valid and specific weaknesses in scientific papers. It integrates three tightly integrated modules: the Customizer module simulates human-defined review criteria, the Rebuttal module introduces author agents for structured debate, and the Prioritizer module learns from human review practices to prioritize the most severe weaknesses for users.",152.93,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07618v1_Neural Architecture for Fast and Reliable Coagulat.pdf,Neural Architecture for Fast and Reliable Coagulation Assessment in Clinical Settings: Leveraging Thromboelastography,"['Yulu Wang', 'Ziqian Zeng', 'Jianjun Wu', 'Zhifeng Tang']",,2607.00000,"['Thromboelastography', 'Coagulation Assessment', 'Clinical Settings', 'Neural Architecture', 'Deep Learning', 'Few-Shot Learning', 'Domain Adaptation', 'Real-Time Monitoring']","This paper presents Physiological State Reconstruction (PSR), a new algorithm designed to make reliable predictions and diagnoses from small amounts of clinical data, particularly in the context of thromboelastography (TEG) for coagulation assessment. The authors introduce MDFE for integrating varied temporal signals and jointly learn high-level temporal interactions and attention mechanisms. PSR achieves remarkable performance on four TEG-specialized datasets, with R2 > 0.98 for coagulation traits and half the error compared to state-of-the-art methods, while halving the inference time. The drift-aware learning approach suggests a promising future for medical AI applications with data scarcity.",158.83,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07632v2_GeoMotionGPT Geometry-Aligned Motion Understanding.pdf,GeoMotionGPT: Geometry-Aligned Motion Understanding with Large Language Models,"['Zhankai Ye', 'Bofan Li', 'Yukai Jin', 'Shuoqiu Li', 'Wei Wang', 'Yanfu Zhang', 'Shangqian Gao', 'Xin Liu']",https://doi.org/10.1000/GeoMotionGPT,2309.15899,"['Large Language Models', 'Motion Understanding', 'Semantic Embedding', 'Geometry-Aligned', 'Discrete Motion Tokenization']","This paper presents a novel framework that explicitly enforces orthogonality on both the motion codebook and the Large Language Model (LLM) embedding space, ensuring that their relational structures naturally mirror each other. The framework achieves a 20% performance improvement over current state-of-the-art methods on HumanML3D, validating that a unified geometric basis effectively empowers the LLM for nuanced motion reasoning.",160.88,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07635v2_Learning About Learning A Physics Path from Spin G.pdf,Learning About Learning: A Physics Path from Spin Glasses to Artificial Intelligence,"['Denis D. Caprioti', 'Matheus Haas', 'Constantino F. Vasconcelos', 'Mauricio Girardi-Schappo']",,2601.01456,"['Hopfield model', 'spin glasses', 'neural networks', 'artificial intelligence', 'associative memory', 'combinatorial optimization', 'statistical physics', 'dynamical systems', 'linear algebra', 'computational methods']","This paper presents the Hopfield model as a pedagogically rich framework that unifies core topics from undergraduate statistical physics, dynamical systems, linear algebra, and computational methods. It provides a concise theoretical introduction grounded in familiar physics concepts, analyzes the model's energy function, dynamics, and pattern stability, and discusses practical aspects of simulation, including a freely available simulation code. The work aims to help physics students understand, apply, and critically engage with computational tools central to research, industry, and society.",160.04,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07638v1_SALT-KG A Benchmark for Semantics-Aware Learning o.pdf,SALT-KG: A Benchmark for Semantics-Aware Learning on Enterprise Tables,"[""Isaiah Onando Mulang'"", 'SAP SE', 'mulang.onando@sap.com', 'Felix Sasaki', 'SAP SE', 'felix.sasaki@sap.com', 'Tassilo Klein', 'SAP SE', 'tassilo.klein@sap.com', 'Jonas Kolk', 'SAP SE', 'jonas.kolk@sap.com', 'Nikolay Grechanov', 'SAP SE', 'nikolay.grechanov@sap.com', 'Johannes Hoffart', 'SAP SE', 'johannes.hoffart01@sap.com']",,2601.07638,"['SALT', 'Semantics-Aware Learning', 'Enterprise Tables', 'Metadata Knowledge Graph', 'Tabular Data', 'Relational Prediction', 'Foundation Models', 'Declarative Knowledge', 'Contextual Semantics', 'Machine Learning']","Building upon the SALT benchmark, this paper introduces SALT-KG, a benchmark for semantics-aware learning on enterprise tables, which extends SALT by linking multi-table transactional data with a structured Operational Business Knowledge represented in a Metadata Knowledge Graph. This extension enables evaluation of models that jointly reason over tabular evidence and contextual semantics, highlighting gaps in models' ability to leverage semantics in relational context.",158.74,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07641v1_Beyond Static Tools Test-Time Tool Evolution for S.pdf,Beyond Static Tools: Test-Time Tool Evolution for Scientific Reasoning,"['Jiaxuan Lu1', 'Ziyu Kong2', 'Yemin Wang3', 'Rong Fu4', 'Haiyuan Wan1', 'Cheng Yang6', 'Wenjie Lou1', 'Haoran Sun1', 'Lilong Wang1', 'Yankai Jiang1', 'Xiaosong Wang1', 'Xiao Sun1', 'Dongzhan Zhou1']",null,2309.14946,"['Test-Time Tool Evolution', 'Scientific Reasoning', 'AI for Science', 'Tool Evolution', 'Scientific Computing']","This paper proposes Test-Time Tool Evolution (TTE), a new paradigm that enables agents to synthesize, verify, and evolve executable tools during inference, overcoming the rigidity and long-tail limitations of static tool libraries. The authors introduce SciEvo, a benchmark of 1,590 scientific reasoning tasks supported by 925 automatically evolved tools, demonstrating state-of-the-art performance in both accuracy and tool efficiency, and enabling effective cross-domain adaptation of computational tools.",160.15,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07651v1_Active Evaluation of General Agents Problem Defini.pdf,Active Evaluation of General Agents: Problem Definition and Comparison of Baseline Algorithms,"['Marc Lanctot', 'Kate Larson', 'Ian Gemp', 'Michael Kaisers']",,,"['general evaluation', 'multitask evaluation', 'ranking', 'active learning', 'game theory', 'social choice theory']","This paper proposes a formal definition and conceptual framework for active evaluation of agents across multiple tasks, assessing the performance of ranking algorithms as a function of number of evaluation data samples. It compares several baselines, including the Elo rating system and Soft Condorcet Optimization, under different experimental contexts.",160.13,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07654v1_Towards Automating Blockchain Consensus Verificati.pdf,Towards Automating Blockchain Consensus Verification with IsabeLLM,"['Elliot Jones', 'William Knottenbelt']",,2601.07654v1,"['Blockchain', 'Consensus', 'Formal Verification', 'Theorem Proving', 'Artificial Intelligence']","This paper presents IsabeLLM, a tool that integrates the proof assistant Isabelle with a Large Language Model to automate the verification of blockchain consensus protocols, demonstrating its effectiveness with a novel model of Bitcoin's Proof of Work consensus protocol.",151.29,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07663v2_Reasoning Models Will Blatantly Lie About Their Re.pdf,Reasoning Models Will Blatantly Lie About Their Reasoning,"['William Walden', 'Johns Hopkins University']",,2309.14467,"['Large Reasoning Models', 'CoT Faithfulness', 'Model Transparency', 'Prompt Hints', 'Interpretability']","This paper extends the work of Chen et al. (2025) to demonstrate that Large Reasoning Models will not only omit information about how they use hints in their reasoning but will also lie about it, denying reliance on hints even when directly asked to reflect on hinted content.",159.16,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07666v1_Variational Contrastive Learning for Skeleton-base.pdf,Variational Contrastive Learning for Skeleton-based Action Recognition,"['Dang-Dinh NGUYEN', 'Decky ASPANDI-LATIF', 'Titus ZAHARIA']",null,2601.07666,"['Human Action Recognition', 'Self - Supervised Learning', 'Variational Inference']","This paper proposes a variational contrastive learning framework to improve skeleton-based action recognition, addressing the variability and uncertainty in human motion. It shows consistent performance improvements over existing methods, particularly in low-label regimes, and provides more relevant features for motion analysis.",161.83,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07667v1_Adaptive Layer Selection for Layer-Wise Token Prun.pdf,Adaptive Layer Selection for Layer-Wise Token Pruning in LLM Inference,"['Rei Taniguchi', 'Yuyang Dong', 'Makoto Onizuka', 'Chuan Xiao']",,2310.14676,"['Large Language Models', 'Token Pruning', 'Layer-Wise Pruning', 'Attention Patterns', 'Memory Reduction', 'Transformer Layers']","This paper proposes ASL, a training-free method that adaptively selects the selection layer for key-value (KV) cache reduction, utilizing the variance of token ranks ordered by attention score. ASL aims to balance performance across different tasks while meeting user-specified KV budget requirements, outperforming state-of-the-art layer-wise token selection methods in accuracy while maintaining decoding speed and KV cache reduction.",158.21,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07685v1_Predictive Analytics for Dementia Machine Learning.pdf,Predictive Analytics for Dementia: Machine Learning on Healthcare Data,"['1st Shafiul Ajam Opee', '2nd Nafiz Fahad', '3rd Anik Sen', '4th Rasel Ahmed', '5th Fariha Jahan', '6th Md. Kishor Morol', '7th Md Rashedul Islam']",,,"['Dementia', 'Machine learning', 'Linear Discriminant Analysis (LDA)', 'APOE-ϵ4 allele']","This study enhances dementia prediction using machine learning techniques on patient health data, employing supervised learning algorithms like K-Nearest Neighbors, Quadratic Discriminant Analysis, Linear Discriminant Analysis, and Gaussian Process Classifiers. Techniques such as Synthetic Minority Over-sampling Technique and Term Frequency-Inverse Document Frequency vectorization are used to address class imbalance and improve model performance. LDA achieved the highest testing accuracy of 98%. The study highlights the importance of model interpretability and the correlation of dementia with features such as the presence of the APOE-ϵ4 allele and chronic conditions like diabetes.",160.72,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07701v1_Deep Whole-body Parkour.pdf,Deep Whole-Body Parkour,"['Ziwen Zhuang', 'Shaoting Zhu', 'Mengjie Zhao', 'Hang Zhao']",,2601.07701v1,"['Deep Reinforcement Learning', 'Humanoid Robotics', 'Parkour', 'Perceptive Motion Control', 'Whole-Body Interaction', 'Robustness', 'Multi-Contact Skills']","This paper presents a framework where exteroceptive sensing is integrated into whole-body motion tracking, enabling a humanoid robot to perform highly dynamic, non-locomotion tasks on uneven terrain, such as vaulting and dive-rolling, significantly expanding the robot's traversability beyond simple walking or running.",156.32,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07718v1_Hiking in the Wild A Scalable Perceptive Parkour F.pdf,Hiking in the Wild: A Scalable Perceptive Parkour Framework for Humanoids,"['Shaoting Zhu', 'Ziwen Zhuang', 'Mengjie Zhao', 'Kun-Ying Lee', 'Hang Zhao']",,2601.07718,"['Humanoid Robotics', 'Parkour', 'Perception', 'Reinforcement Learning', 'Robust Navigation', 'Depth Perception']","This paper presents Hiking in the Wild, a scalable, end-to-end parkour perceptive framework designed for robust humanoid hiking in complex, unstructured environments, addressing challenges in integrating exteroception and ensuring safety and training stability.",151.7,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07737v1_Evaluating the encoding competence of visual langu.pdf,Evaluating the encoding competence of visual language models using uncommon actions,"['Chen Ling', 'Nai Ding*']",,2601.07737v1,"['visual language models', 'encoding competence', 'uncommon actions']",This undergraduate project report evaluates the encoding competence of visual language models using uncommon actions.,132.0,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07748v1_Improving Domain Generalization in Contrastive Lea.pdf,Improving Domain Generalization in Contrastive Learning using Adaptive Temperature Control,"['Robert Lewis', 'Katie Matton', 'Rosalind W. Picard', 'John Guttag']",10.48550/arXiv.2601.07748,2601.07748,"['contrastive learning', 'domain generalization', 'covariate shift', 'temperature control']","This paper presents a new method for contrastive learning that incorporates domain labels to increase the domain invariance of learned representations, leading to improved out-of-distribution generalization. The method adjusts the temperature parameter in the InfoNCE loss to upweight pairs from more similar domains, encouraging the model to discriminate based on domain-invariant attributes.",160.97,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07778v1_DT-ICU Towards Explainable Digital Twins for ICU P.pdf,DT-ICU: Towards Explainable Digital Twins for ICU Patient Monitoring via Multi-Modal and Multi-Task Iterative Inference,['Wen Guo'],,2601.07778v1,"['Digital Twin', 'ICU Monitoring', 'Multi-Modal', 'Multi-Task', 'Iterative Inference', 'Risk Estimation']","The paper introduces DT-ICU, a multimodal digital twin framework for continuous risk estimation in intensive care, evaluating its performance on the MIMIC-IV dataset and demonstrating its ability to provide accurate, temporally robust, and interpretable predictions.",144.3,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07779v1_OS-Symphony A Holistic Framework for Robust and Ge.pdf,OS-SYMPHONY: A Holistic Framework for Robust and Generalist Computer-Using Agents,"['Bowen Yang', 'Kaiming Jin', 'Zhenyu Wu', 'Zhaoyang Liu', 'Qiushi Sun', 'Zehao Li', 'Jingjing Xie', 'Zhoumianze Liu', 'Fangzhi Xu', 'Kanzhi Cheng', 'Qingyun Li', 'Yian Wang', 'Yu Qiao', 'Zun Wang', 'Zichen Ding']",,,"['Computer-Using Agents', 'Vision-Language Models', 'Holistic Framework', 'Robust Automation', 'Generalist Agents', 'Long-Horizon Tasks', 'Tutorial Retrieval', 'Trajectory-Level Self-Correction', 'Multimodal Searcher', 'Browser-Based Sandbox']","OS-SYMPHONY is a holistic framework that addresses the limitations of current Computer-Using Agent (CUA) frameworks by introducing an Orchestrator coordinating two key innovations: a Reflection-Memory Agent that utilizes milestone-driven long-term memory for trajectory-level self-correction, and Versatile Tool Agents featuring a Multimodal Searcher to navigate a browser-based sandbox and synthesize live, visually aligned tutorials. Experimental results demonstrate substantial performance gains across varying model scales, establishing new state-of-the-art results on three online benchmarks.",143.44,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07782v1_Beyond Single-Shot Multi-step Tool Retrieval via Q.pdf,Beyond Single-Shot: Multi-step Tool Retrieval via Query Planning,"['Wei Fang', 'James Glass']",,2309.14445,"['tool retrieval', 'query planning', 'reinforcement learning', 'large language models', 'agent frameworks']","This paper proposes TOOLQP, a lightweight framework that models retrieval as iterative query planning, to address the challenges of complex tool retrieval in large language model (LLM) agents operating over massive, dynamic tool libraries.",158.61,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07790v1_Benchmarking Small Language Models and Small Reaso.pdf,Benchmarking Small Language Models and Small Reasoning Language Models on System Log Severity Classification,"['Yahya Masri', 'Emily Ma', 'Zifu Wang', 'Joseph Rogers', 'Chaowei Yang']",null,2601.07790,"['System Logs', 'Severity Classification', 'Language Models', 'Zero-Shot', 'Few-Shot', 'Retrieval-Augmented Generation', 'Digital Twins', 'Root Cause Analysis']","This paper evaluates nine small language models and small reasoning language models on real-world journalctl data from Linux production servers, using zero-shot, few-shot, and retrieval-augmented generation prompting. The results show strong stratification, with Qwen3-4B achieving the highest accuracy at 95.64% with retrieval-augmented generation, and Gemma3-1B improving from 20.25% under few-shot prompting to 85.28% with retrieval-augmented generation. The findings suggest that architectural design, training objectives, and the ability to integrate retrieved context jointly determine performance.",157.47,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07794v1_Kinship Data Benchmark for Multi-hop Reasoning.pdf,Kinship Data Benchmark for Multi-hop Reasoning,"['Tianda Sun', 'Dimitar Kazakov']",,1909.09593,"['Kinship', 'Multi-hop Reasoning', 'Language Models', 'Benchmarking', 'Family Trees', 'Genealogy']","This paper introduces KinshipQA, a benchmark designed to evaluate large language models' ability to perform multi-hop reasoning over kinship relations, using a generative pipeline that produces large-scale, realistic, and culture-specific genealogical data.",156.04,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07821v1_Failure-Aware RL Reliable Offline-to-Online Reinfo.pdf,Failure-Aware RL: Reliable Offline-to-Online Reinforcement Learning with Self-Recovery for Real-World Manipulation,"['Huanyu Li', 'Kun Lei', 'Sheng Zang', 'Kaizhe Hu', 'Yongyuan Liang', 'Bo An', 'Xiaoli Li', 'Huazhe Xu']",,1911.08067,"['Reinforcement Learning', 'Offline-to-Online RL', 'Failure-Aware RL', 'Robotic Manipulation', 'Intervention-requiring Failures']","This paper introduces Failure-Aware Offline-to-Online Reinforcement Learning (FARL) to minimize failures during real-world reinforcement learning, improving performance and generalization by significantly reducing Intervention-requiring Failures (IR Failures) in robotic manipulation tasks.",156.99,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07832v2_MHLA Restoring Expressivity of Linear Attention vi.pdf,MHLA: Restoring Expressivity of Linear Attention via Token-Level Multi-Head,"['Kewei Zhang', 'Ye Huang', 'Yufan Deng', 'Jincheng Yu', 'Junsong Chen', 'Huan Ling', 'Enze Xie', 'Daquan Zhou']",,2601.07832,"['Transformer', 'Linear Attention', 'Multi-Head', 'Expressive Power', 'ImageNet', 'NLP', 'Image Generation', 'Video Generation']","This work proposes Multi-Head Linear Attention (MHLA) to restore the expressivity of linear attention, which preserves representational diversity by computing attention within divided heads along the token dimension, maintaining linear complexity while recovering much of the expressive power of softmax attention across multiple domains.",158.31,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07885v1_Small Symbols Big Risks Exploring Emoticon Semanti.pdf,"Small Symbols, Big Risks: Exploring Emoticon Semantic Confusion in Large Language Models","['Weipeng Jiang', 'Xiaoyu Zhang', 'Juan Zhai', 'Shiqing Ma', 'Chao Shen', 'Yang Liu']",,,"['Large Language Models', 'Emoticons', 'Semantic Confusion', 'Safety Implications', 'User Intention', 'Catastrophic Consequences']","This paper identifies emoticon semantic confusion, a vulnerability where Large Language Models misinterpret ASCII-based emoticons to perform unintended and potentially destructive actions. The study reveals that this vulnerability is pervasive, with over 90% of confused responses leading to 'silent failures', which are syntactically valid but deviate from user intent. The paper also highlights that this vulnerability transfers to popular agent frameworks and that existing prompt-based mitigations are largely ineffective. The authors call for community recognition and development of effective mitigation methods to ensure the safety and reliability of human-AI interactions.",155.81,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07891v1_KVzap Fast Adaptive and Faithful KV Cache Pruning.pdf,"KVzap: Fast, Adaptive, and Faithful KV Cache Pruning","['Simon Jégou *', 'Maximilian Jeblick']",,2601.07891v1,"['KV cache', 'transformer attention', 'language models', 'inference bottleneck', 'fast pruning', 'adaptive pruning', 'state-of-the-art performance']","KVzap is a fast, input-adaptive KV cache pruning method that achieves state-of-the-art performance on the KVpress leaderboard, compressing the KV cache by 2-4x with negligible accuracy loss, outperforming 15 other methods on long-context and reasoning tasks.",156.34,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07892v1_Sherry Hardware-Efficient 1.25-Bit Ternary Quantiz.pdf,Hardware-Efficient 1.25-Bit Ternary Quantization via Fine-grained Sparsification,"['Hong Huang1*', 'Decheng Wu2', 'Qiangqiang Hu2', 'Guanghua Yu2', 'Jinhai Yang1', 'Jianchen Zhu2', 'Xue Liu3', 'Dapeng Wu1']",,2312.08986,"['Hardware-Efficient', 'Ternary Quantization', 'Fine-grained Sparsification', '1.25-Bit', 'Edge Devices', 'Large Language Models', 'Weight Quantization', 'Commodity Hardware']","This paper proposes Sherry, a hardware-efficient ternary quantization framework that introduces a 3:4 fine-grained sparsity to achieve a regularized 1.25-bit width by packing blocks of four weights into five bits, thereby restoring power-of-two alignment. Sherry addresses the weight trapping issue in sparse ternary training, which leads to representational collapse, by introducing an annealing residual synapse mechanism. Empirical evaluations on LLaMA-3.2 across five benchmarks demonstrate that Sherry matches state-of-the-art ternary performance while significantly reducing model size and providing 25% bit savings and 10% speed up on an Intel i7-14700HX CPU compared to SOTA baselines.",156.42,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07894v1_Revealing the Attention Floating Mechanism in Mask.pdf,Revealing the Attention Floating Mechanism in Masked Diffusion Models,"['Xin Dai', 'Pengcheng Huang', 'Zhenghao Liu', 'Shuo Wang', 'Yukun Yan', 'Chaojun Xiao', 'Yu Gu', 'Ge Yu', 'Maosong Sun']",,2310.15616,"['Masked Diffusion Models', 'Attention Floating', 'Bidirectional Attention', 'Diffusion Language Models', 'Attention Sinks', 'In-Context Learning']","This paper investigates the attention behaviors in Masked Diffusion Models (MDMs), revealing the phenomenon of Attention Floating, which differs from the rigid attention pattern of autoregressive models (ARMs). MDMs exhibit dynamic, dispersed attention anchors that shift across denoising steps and layers, providing a mechanistic explanation for their strong in-context learning capabilities in knowledge-intensive tasks.",141.95,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07898v1_Large Language Models and Algorithm Execution Appl.pdf,Large Language Models and Algorithm Execution: Application to an Arithmetic Function,"['Farah Ben Slama', 'Frédéric Armetta']",,2601.01234,"['Algorithmic learning in natural language', 'Supervised learning by decomposition', 'Large language model', 'Fine-tuning']","This paper investigates the possibility of extending Large Language Models' capabilities to algorithm execution through specialized supervised training focused on reasoning decomposition, demonstrating that LLMs' ability to perform complex algorithmic inferences and generalize can be significantly improved when the training method is properly designed.",149.07,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07901v1_Decentralized Online Convex Optimization with Unkn.pdf,Decentralized Online Convex Optimization with Unknown Feedback Delays,"['Hao Qiu', 'Mengxiao Zhang', 'Juliette Achddou']",null,2601.07901,"['Decentralized Online Convex Optimization', 'Unknown Feedback Delays', 'Federated Learning', 'Sensor Networks', 'Multi-Agent Control']","This paper studies decentralized online convex optimization under unknown, time- and agent-varying feedback delays, proposing a novel algorithm that achieves an improved regret bound and extending the framework to the strongly convex setting.",148.19,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07903v2_Enhancing Large Language Models for Time-Series Fo.pdf,Enhancing Large Language Models for Time-Series Forecasting via Vector-Injected In-Context Learning,"['Jianqi Zhang', 'Jingyao Wang', 'Wenwen Qiang', 'Fanjiang Xu', 'Changwen Zheng']",XXXXXXX.XXXXXXX,,"['Time Series Forecasting', 'Large Language Model', 'In-context Learning']","This paper proposes LVICL, a method to improve the forecasting performance of large language models for time-series data by injecting example information into a frozen model, thereby reducing computational overhead.",148.69,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07935v1_Towards Specialized Generalists A Multi-Task MoE-L.pdf,Towards Specialized Generalists: A Multi-Task MoE-LoRA Framework for Domain-Specific LLM Adaptation,"['Yuxin Yang', 'Shanghai University', 'Aoxiong Zeng', 'East China Normal University', 'Xiangquan Yang', 'East China Normal University']",,2601.07935v1,"['Large Language Models', 'Domain-Specific Adaptation', 'Low-Rank Adaptation', 'Mixture-of-Experts', 'Medical Applications', 'Catastrophic Forgetting', 'Knowledge Overlap']","This paper proposes Med-MoE-LoRA, a novel framework integrating Mixture-of-Experts (MoE) with Low-Rank Adaptation (LoRA) to enable efficient multi-task domain adaptation for medical scenarios, addressing challenges such as Catastrophic Forgetting and Task Interference.",142.76,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07939v1_SECite Analyzing and Summarizing Citations in Soft.pdf,SECite: Analyzing and Summarizing Citations in Software Engineering Literature,"['Shireesh Reddy Pyreddy', 'Khaja Valli Pathan', 'Hasan Masum', 'Tarannum Shaila Zaman']",,,"['Sentiment Analysis', 'LLMs', 'Text Summarization', 'Citations']","This research introduces SECite, a novel approach for evaluating scholarly impact through sentiment analysis of citation contexts. It develops a semi-automated pipeline to extract citations and applies advanced natural language processing techniques to classify these citation statements as positive or negative, generating sentiment-specific summaries that capture the strengths and limitations of each target paper.",159.61,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07941v2_Moonworks Lunara Aesthetic Dataset.pdf,Moonworks Lunara Aesthetic Dataset,"['Yan Wang', 'M M Sayeef Abdullah', 'Partho Hassan', 'Sabit Hassan']",,2601.07941v2,"['Moonworks', 'Lunara', 'Aesthetic Dataset', 'Text-to-Image Generation', 'Prompt Grounding', 'Style Conditioning']","This data card introduces the Lunara Aesthetic Dataset, a curated collection of 2,000 image-prompt pairs designed for research on prompt grounding and style conditioning in text-to-image generation systems, featuring diverse artistic styles from various regions.",155.04,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07946v1_Coupled Diffusion-Encoder Models for Reconstructio.pdf,DiffCoder: Coupled Diffusion–Encoder Models for Reconstruction of Flow Fields,"['AmirPouya Hemmasian', 'Amir Barati Farimani']",null,2601.14767,"['Flow Field Reconstruction', 'Diffusion Models', 'Autoencoders', 'Kolmogorov Flow', 'Deep Learning']","This paper introduces DiffCoder, a coupled framework integrating a probabilistic diffusion model with a conventional convolutional ResNet encoder, designed to improve the statistical consistency of flow field reconstructions under aggressive compression, compared to variational autoencoders.",158.64,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07948v1_Reinforcement Learning Methods for Neighborhood Se.pdf,Reinforcement Learning Methods for Neighborhood Selection in Local Search,"['Yannick Molinghen', 'Augustin Delecluse', 'Renaud De Landtsheer', 'Stefano Michelini']",,,"['Local Search', 'Reinforcement Learning', 'Combinatorial Optimization']","This study evaluates reinforcement learning-based neighborhood selection strategies in local search metaheuristics, comparing them against multiple baselines across three problems: the traveling salesman problem, the pickup and delivery problem with time windows, and the car sequencing problem, revealing that ε-greedy consistently ranks among the best performers but that deep reinforcement learning approaches have higher computational overhead.",135.67,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07951v1_Hybrid SARIMA LSTM Model for Local Weather Forecas.pdf,Hybrid SARIMA–LSTM Model for Local Weather Forecasting: A Residual-Learning Approach for Data-Driven Meteorological Prediction,"['Shreyas Rajeev', 'Karthik Mudenahalli', 'Amit Mallappa']",,,"['weather forecasting', 'SARIMA', 'LSTM', 'residual learning', 'Fourier seasonal encoding', 'long-term prediction']","This paper proposes a hybrid SARIMA–LSTM model to improve long-term weather forecasting accuracy by breaking temperature into a climate component and a non-linear weather component, using Fourier seasonal encoding and a stabilized recursive forecasting mechanism.",157.61,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07953v1_Quantum automated theorem proving.pdf,Quantum automated theorem proving,"['Zheng-Zhi Sun', 'Qi Ye', 'Dong-Ling Deng']",,1909.09562,"['quantum computing', 'automated theorem proving', 'quantum logic', 'quantum resolution', 'quantum algebraic proving', 'automated reasoning', 'quantum superposition', 'quantum entanglement', 'geometric theorems', 'quantum automatic theorem provers']","This paper proposes a generic framework for quantum automated theorem proving, utilizing intrinsic quantum features to achieve quadratic reduction in query complexity for propositional and first-order logic, and introduces a quantum algebraic proving method for geometric theorems.",159.48,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07957v1_LWMSCNN-SE A Lightweight Multi-Scale Network for E.pdf,LWMSCNN-SE: A Lightweight Multi-Scale Network for Efficient Maize Disease Classification on Edge Devices,"['1st Fikadu Weloday', '2nd Jianmei Su']",,1912.04477,"['lightweight CNN', 'multi-scale feature extraction', 'attention mechanism', 'plant pathology']","This paper proposes LWMSCNN-SE, a lightweight convolutional neural network (CNN) that integrates multi-scale feature extraction, depthwise separable convolutions, and squeeze-and-Excitation (SE) attention mechanisms, achieving 96.63% classification accuracy with only 241,348 parameters and 0.666 GFLOPs, suitable for real-time deployment in field applications.",158.57,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07958v1_LJ-Spoof A Generatively Varied Corpus for Audio An.pdf,LJ-SPOOF: A GENERATIVELY V ARIED CORPUS FOR AUDIO ANTI-SPOOFING AND SYNTHESIS SOURCE TRACING,"['Surya Subramani', 'Hashim Ali', 'Hafiz Malik']",,2309.09607,"['Anti-Spoofing', 'Speaker Verification', 'Deepfake', 'Source tracing', 'Synthetic Speech']","This paper introduces LJ-Spoof, a speaker-specific, generatively diverse corpus that systematically varies prosody, vocoders, generative hyperparameters, bona fide prompt sources, training regimes, and neural post-processing. The corpus spans 30 TTS families, 500 generatively variant subsets, 10 bona fide neural-processing variants, and over 3 million utterances, enabling robust speaker-conditioned anti-spoofing and fine-grained synthesis-source tracing.",159.34,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07964v1_Executable Ontologies in Game Development From Alg.pdf,Executable Ontologies in Game Development: From Algorithmic Control to Semantic World Modeling,['Alexander Boldachev'],null,null,"['executable ontologies', 'game ai', 'behavior trees', 'GOAP', 'event semantics', 'dataflow architecture', 'semantic modeling']","This paper examines the application of Executable Ontologies (EO) in game development, arguing that EO represents a paradigm shift from algorithmic behavior programming to semantic world modeling, where agent behavior emerges naturally from declarative domain rules rather than being explicitly coded.",152.79,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07965v1_When Models Know When They Do Not Know Calibration.pdf,"When a model knows when it does not know: Calibration, cascading, and cleaning","['Chenjie Hao', 'Weyl Lu', 'Yuko Ishiwaka', 'Zengyi Li', 'Weier Wan', 'Yubei Chen']",,2309.14444,"['model calibration', 'model cascading', 'data cleaning', 'confidence estimation', 'deep learning', 'machine learning']","This work proposes a simple, effective, and universal training-free method for model calibration, cascading, and data cleaning, which applies to both vision and language models. The findings establish the reliability and comparability of calibrated confidence, and the proposed applications improve model efficiency and accuracy without compromising performance.",159.05,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07969v1_Tuberculosis Screening from Cough Audio Baseline M.pdf,"Tuberculosisscreening fromcoaughaudio: Baselinemodels, clinicalvariables, anduncertaintyquantification","['George P. Kafentzis', 'Efstratios Selisios']",,2601.07969,"['Tuberculosis', 'Machine Learning', 'Cough Audio', 'Cross-Validation', 'Uncertainty Quantification', 'Feature Extraction']","This paper proposes a standardized framework for automatic tuberculosis (TB) detection from cough audio and clinical data using machine learning, addressing the gap in comparable progress by establishing a strong, well-documented baseline and releasing the full experimental protocol for benchmarking.",136.38,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07973v1_Cultural Compass A Framework for Organizing Societ.pdf,Cultural Compass: A Framework for Organizing Societal Norms to Detect Violations in Human-AI Conversations,"['Myra Cheng', 'Vinodkumar Prabhakaran', 'Alice Oh', 'Hayk Stepanyan', 'Aishwarya Verma', 'Charu Kalia', 'Erin MacMurray van Liemt', 'Sunipa Dev']",,2601.07973v1,"['Cultural norms', 'Human-AI interactions', 'Societal norms', 'AI safety', 'Generative AI', 'Norm adherence', 'Cultural alignment', 'Natural language processing']","This paper introduces a taxonomy of societal norms to clarify their contexts, specifications, and mechanisms, and demonstrates how this taxonomy can be used to automatically evaluate AI models' adherence to these norms in naturalistic, open-ended settings. The authors find that state-of-the-art models frequently violate norms, with rates varying by model, interactional context, and country. They also show that violation rates vary by prompt intent and situational framing, and their taxonomy and evaluation pipeline enable nuanced, context-sensitive assessment of cultural norm adherence in realistic settings.",158.85,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07988v1_From Word Sequences to Behavioral Sequences Adapti.pdf,From Word Sequences to Behavioral Sequences: Adapting Modeling and Evaluation Paradigms for Longitudinal NLP,"['Adithya V Ganesan†', 'Vasudha Varadarajan⊙', 'Oscar NE Kjell‡', 'Whitney R Ringwaldδ', 'Scott Feltman†', 'Benjamin J Luft†', 'Roman Kotov†', 'Ryan L Boyd∆Θ', 'H Andrew Schwartz†‡']",,,"['NLP', 'longitudinal studies', 'behavioral sequences', 'diary transcripts', 'PTSD', 'mental health', 'person-indexed sequences', 'time-ordered sequences', 'word-sequence evaluation', 'behavior-sequence evaluation']","This paper demonstrates the need for and proposes a longitudinal modeling and evaluation paradigm for NLP, addressing issues in traditional pipeline such as leaky person-specific signal, scrambled temporal order, and lack of clear real-world generalization goals. It shows that traditional document-level evaluation can yield different and sometimes reversed conclusions compared to ecologically valid modeling and evaluation, and ties results to a broader discussion motivating a shift from word-sequence evaluation toward behavior-sequence paradigms.",160.6,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.07994v2_DYCP Dynamic Context Pruning for Long-Form Dialogu.pdf,DYCP: Dynamic Context Pruning for Long-Form Dialogue with LLMs,"['Nayoung Choi', 'Jonathan Zhang', 'Jinho D. Choi']",,2309.06926,"['Large Language Models', 'Dialogue Systems', 'Context Management', 'Dynamic Pruning', 'Long-Form Conversations']","This paper introduces DYCP, a lightweight context management method for long-form dialogue with Large Language Models (LLMs). It dynamically segments and retrieves relevant memory at query time, preserving the sequential structure of dialogue without predefined topic boundaries, and supports efficient, adaptive context retrieval, consistently improving answer quality while reducing response latency across multiple benchmarks and LLMs.",160.63,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08000v1_Reasoning over Precedents Alongside Statutes Case-.pdf,Reasoning over Precedents Alongside Statutes: Case-Augmented Deliberative Alignment for LLM Safety,"['Can Jin', 'Rui Wu', 'Tong Che', 'Qixin Zhang', 'Hongwu Peng', 'Jiahui Zhao', 'Zhenting Wang', 'Wenqi Wei', 'Ligong Han', 'Zhao Zhang', 'Yuan Cao', 'Ruixiang Tang', 'Dimitris N. Metaxas']",10.1007/s10664-023-1001-2,2309.09975,"['Large Language Models', 'Deliberative Alignment', 'Reinforcement Learning', 'LLM Safety', 'Cybersecurity', 'Human Feedback']","This work systematically evaluates the impact of explicitly specifying extensive safety codes versus demonstrating them through illustrative cases for Large Language Models (LLMs), proposing CADA, a case-augmented deliberative alignment method for LLMs utilizing reinforcement learning on self-generated safety reasoning chains to enhance harmlessness, improve robustness against attacks, and reduce over-refusal while preserving utility across diverse benchmarks.",158.04,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08003v1_LLM Review Enhancing Creative Writing via Blind Pe.pdf,LLM Review: Enhancing Creative Writing via Blind Peer Review Feedback,"['Weiyue Li*', 'Mingxiao Song∗', 'Zhenda Shen∗', 'Dachuan Zhao∗', 'Yunfan Long', 'Yi Li', 'Yongce Li', 'Ruyi Yang', 'Mengyu Wang']",,2310.15647,"['Large Language Models', 'Creative Writing', 'Peer Review', 'Multi-Agent Systems', 'Science Fiction', 'Human-LLM Collaboration']","This paper introduces LLM Review, a peer-review-inspired framework that enhances creative writing by implementing Blind Peer Review, where agents exchange targeted feedback while revising independently, preserving divergent creative trajectories. The authors propose SciFi-100, a science fiction writing dataset, and demonstrate that LLM Review consistently outperforms multi-agent baselines, suggesting that interaction structure may substitute for model scale.",157.19,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08005v1_Internal Deployment Gaps in AI Regulation.pdf,Internal Deployment Gaps in AI Regulation,"['JOE KWON', 'STEPHEN CASPER']",,,"['AI regulation', 'internal deployment', 'frontier AI', 'scope ambiguity', 'point-in-time compliance', 'information asymmetries']","This paper examines the gaps in current AI regulations that allow internally-deployed systems to evade oversight, focusing on the United States and European Union's AI regulations in 2025. It identifies three main gaps: scope ambiguity, point-in-time compliance assessments, and information asymmetries, and analyzes why these gaps persist and proposes potential approaches to address them.",161.62,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08011v1_TP-Blend Textual-Prompt Attention Pairing for Prec.pdf,TP-Blend: Textual-Prompt Attention Pairing for Precise Object-Style Blending in Diffusion Models,"['Xin Jin', 'Yichuan Zhong', 'Yapeng Tian']",,2601.08011v1,"['Text-driven image editing', 'Diffusion models', 'Object blending', 'Attention mechanisms', 'Style fusion']","This paper presents TP-Blend, a lightweight training-free framework that handles the challenge of blending two objects with different styles using separate textual prompts, and injects both into a single denoising trajectory through two complementary attention processors.",139.87,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08017v1_Representations of Text and Images Align From Laye.pdf,Representations of Text and Images Align From Layer One,"['Evèzen Wybitul', 'Javier Rando', 'Florian Tramér', 'Stanislav Fort']",,2601.08017,"['vision-language models', 'text-image alignment', 'adapter-based models', 'DeepDream', 'representation alignment']","The authors demonstrate that for various concepts in adapter-based vision-language models, the representations of their images and text descriptions are meaningfully aligned from the very first layer, contradicting the established view that such alignment only appears in late layers. They use a synthesis-based method inspired by DeepDream to show this, applying it to hundreds of concepts across seven layers in Gemma and finding that synthesised images often depict salient visual features of the targeted textual concepts.",161.53,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08026v2_FigEx2 Visual-Conditioned Panel Detection and Capt.pdf,FigEx2: Visual-Conditioned Panel Detection and Captioning for Scientific Compound Figures,"['Jifeng Song', 'Arun Das', 'Pan Wang', 'Hui Ji', 'Kun Zhao', 'Yufei Huang']",null,null,"['FigEx2', 'visual-conditioned', 'panel detection', 'captioning', 'scientific compound figures', 'open-ended captioning', 'noise-aware gated fusion', 'staged optimization', 'supervised learning', 'reinforcement learning', 'CLIP-based alignment', 'BERTScore-based semantic rewards', 'BioSci-Fig-Cap', 'cross-disciplinary test suites', 'zero-shot transferability']","This paper introduces FigEx2, a visual-conditioned framework that localizes panels and generates panel-wise captions directly from scientific compound figures. It addresses the challenge of missing or incomplete captions in real pipelines by mitigating the impact of diverse phrasing in open-ended captioning and employing a staged optimization strategy combining supervised and reinforcement learning for multimodal consistency.",160.14,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08043v1_The Role of Noisy Data in Improving CNN Robustness.pdf,The Role of Noisy Data in Improving CNN Robustness for Image Classification,"['Oscar H. Ramírez-Agudela', 'Nicoleta Gorea', 'Aliza Reif', 'Lorenzo Bonasera', 'Michael Karla']",,1910.08733,"['deep learning', 'CNNs', 'data quality', 'CIFAR-10', 'noise injection', 'image classification', 'model robustness']","This paper investigates the effect of introducing controlled noise into the training data of CNNs for image classification, using the CIFAR-10 dataset and evaluating the impact of Gaussian noise, Salt-and-Pepper noise, and Gaussian blur at varying intensities and training set pollution levels. The findings suggest that strategic exposure to noise can act as a regularizer, enhancing model robustness to real-world noise.",155.64,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08049v1_Integrating Attendance Tracking and Emotion Detect.pdf,Integrating Attendance Tracking and Emotion Detection for Enhanced Student Engagement in Smart Classrooms,"['Keith Ainebyona', 'Ann Move Oguti', 'Joseph Walusimbi', 'Ritah Kobusingye']",,,"['Affective computing', 'Attendance automation', 'Emotion detection', 'IoT', 'Smart classroom']","This paper presents SCASED (Smart Classroom Attendance System with Emotion Detection), an IoT-based system that integrates automated attendance tracking with facial emotion recognition to support classroom engagement monitoring, achieving an emotion classification accuracy of 89.5% and providing instructors with insights into classroom dynamics.",157.49,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08052v1_Forecast Aware Deep Reinforcement Learning for Eff.pdf,Forecast Aware Deep Reinforcement Learning for Efficient Electricity Load Scheduling in Dairy Farms,"['Nawazish Alia', 'Rachael Shaw', 'Karl Mason']",,2601.08052v1,"['Dairy farming', 'Deep Reinforcement Learning', 'Load Scheduling', 'Battery Storage', 'Water Heating', 'Forecasting', 'Reinforcement Learning', 'Electricity Cost Reduction', 'Renewable Energy Integration', 'Sustainable Energy Management']","This study proposes a Deep Reinforcement Learning framework for efficient load scheduling in dairy farms, focusing on battery storage and water heating, incorporating short-term forecasts of demand and renewable generation, and demonstrating significant cost reductions compared to existing methods.",160.47,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08058v1_Reasoning Beyond Chain-of-Thought A Latent Computa.pdf,Reasoning Beyond Chain-of-Thought: A Latent Computational Mode in Large Language Models,"['Zhenghao He', 'Guangzhi Xiong', 'Bohan Liu', 'Sanchit Sinha', 'Aidong Zhang']",,2309.15699,"['Large Language Models', 'Chain-of-Thought', 'Latent Features', 'Reasoning Performance', 'Sparse Autoencoders']","This work investigates the internal representations of large language models (LLMs) with Sparse Autoencoders (SAEs) to identify latent features causally associated with reasoning behavior. The study finds that steering a single reasoning-related latent feature can improve accuracy without explicit Chain-of-Thought (CoT) prompting, suggesting that multi-step reasoning in LLMs is supported by latent internal activations that can be externally activated, rather than CoT prompting being a necessary cause.",160.01,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08065v1_A New Strategy for Verifying Reach-Avoid Specifica.pdf,A New Strategy for Verifying Reach-Avoid Specifications in Neural Feedback Systems,"['Samuel I. Akinwande', 'Sydney M. Katz', 'Mykel J. Kochenderfer', 'Clark Barrett']",,2601.08065v1,"['Neural Feedback Systems', 'Reachability Analysis', 'Backward Reachability', 'Forward Reachability', 'Verification', 'Safety', 'Design Specifications']","This work introduces new algorithms that compute both over- and under-approximations of backward reachable sets for neural feedback systems, integrating these with established forward analysis techniques to provide a unified verification framework.",153.87,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08070v1_Semantic Gravity Wells Why Negative Constraints Ba.pdf,Semantic Gravity Wells: Why Negative Constraints Backfire,['Shailesh Rana'],,2309.14736,"['large language models', 'instruction-following', 'negative constraints', 'semantic pressure', 'failure mechanisms']","This paper presents a comprehensive investigation of negative instruction failure in large language models, introducing semantic pressure as a measure of the model's intrinsic probability of generating forbidden tokens, and tracing the failure to two distinct modes: priming failure and override failure.",153.65,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08079v1_MemoBrain Executive Memory as an Agentic Brain for.pdf,MemoBrain: Executive Memory as an Agentic Brain for Reasoning,"['Hongjin Qian', 'Zhao Cao', 'Zheng Liu']",,2509.08965,"['Executive Memory', 'Long-Horizon Reasoning', 'Tool-Augmented Agents', 'Cognitive Control', 'Context Management']","This paper proposes MemoBrain, an executive memory model for tool-augmented agents that addresses the challenges of long-horizon reasoning by managing reasoning progress and context without disrupting logical continuity.",158.94,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08089v1_Q-realign Piggybacking Realignment on Quantization.pdf,Q-realign: Piggybacking Realignment on Quantization for Safe and Efficient LLM Deployment,"['Qitao Tan', 'Xiaoying Song', 'Ningxi Cheng', 'Ninghao Liu', 'Xiaoming Zhai', 'Lingzi Hong', 'Yanzhi Wang', 'Zhen Xiang', 'Geng Yuan']",,2312.05717,"['Large Language Models', 'Fine-tuning', 'Safety Alignment', 'Post-hoc Defense', 'Quantization', 'Efficient Deployment']","This paper proposes Q-realign, a post-hoc defense method based on post-training quantization, aimed at reducing unsafe behaviors in fine-tuned large language models while preserving task performance, significantly reducing memory usage and GPU hours, and providing a practical solution for safety-aware deployment.",160.82,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08094v1_Local-Global Feature Fusion for Subject-Independen.pdf,Local-Global Feature Fusion for Subject-Independent EEG Emotion Recognition,"['Zheng Zhou', 'Isabella McEvoy', 'Camilo E. Valderrama']",,1912.04888,"['EEG emotion recognition', 'subject-independent', 'local-global fusion', 'transformer', 'domain adaptation']","This paper proposes a fusion framework that integrates local, channel-wise descriptors and global, trial-level descriptors to improve cross-subject generalization in subject-independent EEG emotion recognition on the SEED-VII dataset.",161.82,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08104v1_High-Fidelity Modeling of Stochastic Chemical Dyna.pdf,HIGH-FIDELITYMODELING OFSTOCHASTICCHEMICAL DYNAMICS ONCOMPLEXMANIFOLDS: A MULTI-SCALE SIREN-PINN FRAMEWORK FOR THECURVATURE-PERTURBED GINZBURG-LANDAUEQUATION,"['Julian Evan Chrisnanto', 'Salsabila Rahma Alia', 'Nurfauzi Fadillah', 'Yulison Herry Chrisnanto']",,2601.08104,"['Physics-Informed Neural Networks (PINNs)', 'Spatiotemporal Chaos', 'Inverse Geometric Problems', 'Reaction-Diffusion Systems', 'Defect Turbulence', 'Riemann Manifold Learning']","This work proposes a Multi-Scale SIREN-PINN architecture to accurately model spatiotemporal chaos in reaction-diffusion systems on complex manifolds, addressing the spectral bias of conventional PINNs and achieving state prediction errors close to 2% on the complex Ginzburg-Landau equation, outperforming standard baselines.",159.17,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08107v1_STO-RL Offline RL under Sparse Rewards via LLM-Gui.pdf,STO-RL: Offline RL under Sparse Rewards via LLM-Guided Subgoal Temporal Order,"['Chengyang Gu', 'Yuxin Pan', 'Hui Xiong', 'Yize Chen']",10.1145/nnnnnnn.nnnnnnn,,"['Offline RL', 'Temporal order', 'Large Language Models']","This paper proposes STO-RL, an offline RL framework that leverages large language models to generate temporally ordered subgoal sequences and corresponding state-to-subgoal-stage mappings, applying potential-based reward shaping to transform sparse terminal rewards into dense, temporally consistent signals, promoting subgoal progress while avoiding suboptimal solutions.",134.64,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08108v1_Debiasing Large Language Models via Adaptive Causa.pdf,Debiasing Large Language Models via Adaptive Causal Prompting with Sketch-of-Thought,"['Bowen Li', 'Ziqi Xu', 'Jing Ren', 'Renqiang Luo', 'Xikun Zhang', 'Xiuzhen Zhang', 'Yongli Ren', 'Feng Xia']",,2309.15181,"['Large Language Models', 'LLMs', 'Prompting', 'Chain-of-Thought', 'Sketch-of-Thought', 'Causal Inference', 'Adaptive Causal Prompting', 'Excessive Token Usage', 'Generalisability', 'Robustness', 'Computational Efficiency']","This paper proposes an Adaptive Causal Prompting with Sketch-of-Thought (ACPS) framework to address the limitations of existing prompting methods for Large Language Models (LLMs), such as Chain-of-Thought (CoT), by leveraging structural causal models to infer the causal effect of a query on its answer and adaptively select an appropriate intervention. ACPS enables generalizable causal reasoning without task-specific retraining and reduces token usage and inference cost by replacing verbose CoT with concise Sketch-of-Thought. Extensive experiments demonstrate that ACPS consistently outperforms existing prompting baselines in terms of accuracy, robustness, and computational efficiency.",155.64,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08109v1_CSQL Mapping Documents into Causal Databases.pdf,Csql: Mapping Documents into Causal Databases,['Sridhar Mahadevan'],null,2601.08109,"['Causality', 'Natural Language', 'Databases', 'SQL', 'AI', 'Machine Learning']","The paper introduces Csql, a novel system that automatically converts a collection of unstructured text documents into an SQL-queryable causal database (CDB), supporting causal analysis over document collections rather than purely associative retrieval.",156.96,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08118v1_MirrorBench An Extensible Framework to Evaluate Us.pdf,MIRRORBENCH: ANEXTENSIBLEFRAMEWORK TOEVALUATEUSER-PROXY AGENTS FORHUMAN-LIKENESS,"['Ashutosh Hathidara', 'Julien Yu', 'Vaishali Senthil', 'Sebastian Schreiber', 'Anil Babu Ankisettipalli']",,,"['MIRRORBENCH', 'user proxy agents', 'human likeness', 'large language models', 'reproducible benchmarking', 'user simulation', 'LLM evaluation']","MIRRORBENCH is a reproducible, extensible benchmarking framework designed to evaluate user proxy agents based on their ability to produce human-like user utterances across diverse conversational tasks, explicitly decoupled from downstream task success. The framework supports pluggable user proxies, datasets, tasks, and metrics, enabling researchers to evaluate arbitrary simulators under a uniform, variance-aware harness.",157.41,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08125v1_How vehicles change lanes after encountering crash.pdf,How vehicles change lanes after encountering crashes: Empirical analysis and modeling,"['Kequan Chen', 'Yuxuan Wang', 'Pan Liu', 'Victor L. Knoop', 'David Z. W. Wang', 'Yu Han']",,,"['crashes', 'lane changes', 'empirical analysis', 'modeling', 'vehicles']","This paper examines how vehicles adjust their lane positions following collisions, utilizing empirical data and modeling techniques to understand the dynamics of such maneuvers.",142.11,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08127v1_PathoGen Diffusion-Based Synthesis of Realistic Le.pdf,PathoGen: Diffusion-Based Synthesis of Realistic Lesions in Histopathology Images,"['Mohamad Koohi-Moghadam', 'Mohammad-Ali Nikouei Mahani']",10.1101/2023.02.16.23231244,2302.08156,"['histopathology', 'artificial intelligence', 'deep learning', 'lesions', 'data augmentation', 'image synthesis', 'tissue morphology', 'cellular structures', 'staining characteristics', 'segmentation', 'AI systems']","This paper presents PathoGen, a diffusion-based generative model that synthesizes realistic lesions into benign histopathology images, overcoming the scarcity of expert-annotated data by leveraging iterative refinement of diffusion models to preserve natural tissue boundaries, cellular structures, and staining characteristics across four diverse datasets representing distinct diagnostic challenges.",146.61,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08128v1_Embedded AI Companion System on Edge Devices.pdf,Embedded AI Companion System on Edge Devices,"['Rahul Gupta', 'Stephen Hsu']",,2601.08128,"['AI companion', 'edge devices', 'memory systems', 'low-latency', 'personalization', 'quantized models']","This paper proposes an embedded AI companion system designed for children, which alternates between active and inactive phases to minimize latency while maintaining long-term personalization under computational constraints of edge devices. The system outperforms existing models in conversational quality and memory capabilities.",153.41,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08133v1_How Do Optical Flow and Textual Prompts Collaborat.pdf,How Do Optical Flow and Textual Prompts Collaborate to Assist in Audio-Visual Semantic Segmentation?,"['Peng Gao', 'Yujian Lee', 'Yongqi Xu', 'Wentao Fan']",,,"['Audio-visual semantic segmentation', 'Optical flow', 'Textual prompts', 'Semantic understanding', 'Machine perception']","This paper introduces a novel collaborative framework, Stepping Stone Plus (SSP), which integrates optical flow and textual prompts to assist in audio-visual semantic segmentation. SSP leverages optical flow to capture motion dynamics and incorporates specific textual prompts to address stationary sound-emitting objects, delivering efficient and precise segmentation results.",149.25,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08139v1_Subspace Alignment for Vision-Language Model Test-.pdf,Subspace Alignment for Vision-Language Model Test-time Adaptation,"['Zhichen Zeng', 'Wenxuan Bao', 'Xiao Lin', 'Ruizhong Qiu', 'Tianxin Wei', 'Xuying Ning', 'Yuchen Yan', 'Chen Luo', 'Monica Xiao Cheng', 'Jingrui He', 'Hanghang Tong']",,2309.15054,"['Vision-Language Models', 'Test-time Adaptation', 'Subspace Alignment', 'Distribution Shifts', 'Zero-shot Prediction', 'Modality Gap', 'Visual Nuisance']","This paper proposes SubTTA, a method to enhance zero-shot predictions by aligning the semantic subspaces of both visual and textual modalities, addressing the limitations of existing test-time adaptation methods that rely on unreliable pseudo-labels for self-training under distribution shifts.",157.95,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08141v1_Qalb Largest State-of-the-Art Urdu Large Language .pdf,Qalb: Largest State-of-the-Art Urdu Large Language Model for 230M Speakers with Systematic Continued Pre-training,"['1st Muhammad Taimoor Hassan', '2st Jawad Ahmed', '3st Muhammad Awais']",,2312.04471,"['Urdu language model', 'continued pre-training', 'low-resource NLP', 'LoRA', 'language adaptation']","This paper introduces Qalb, an Urdu language model developed through a two-stage approach: continued pre-training followed by supervised fine-tuning. Qalb demonstrates substantial improvements, achieving a weighted average score of 90.34 and outperforming the previous state-of-the-art Alif-1.0-Instruct model by 3.24 points, while also surpassing the base LLaMA-3.1 8B-Instruct model by 44.64 points. Qalb achieves state-of-the-art performance across seven diverse tasks including Classification, Sentiment Analysis, and Reasoning.",155.99,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08146v2_Mechanisms are Transferable Data-Efficient Low-Res.pdf,Mechanisms are Transferable: Data-Efficient Low-Resource Adaptation via Circuit-Targeted Supervised Fine-Tuning,"[""Khumaisa Nur'aini"", 'Ayu Purwarianti', 'Alham Fikri Aji', 'Derry Wijaya']",,2310.15167,"['Low-resource adaptation', 'Supervised fine-tuning', 'Transformer', 'Contextual Decomposition Transformer', 'Catastrophic forgetting', 'Cross-lingual transfer']","The authors propose a method called Circuit-Targeted Supervised Fine-Tuning (CT-SFT) to adapt large language models to low-resource languages more efficiently. CT-SFT uses a label-balanced mean baseline and task-directional relevance scoring to identify task-relevant attention heads in a proxy-language checkpoint, then transfers these heads to a target language by updating only those heads plus LayerNorm, improving cross-lingual accuracy while updating only a small subset of model parameters.",159.34,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08148v1_Enriching Semantic Profiles into Knowledge Graph f.pdf,Enriching Semantic Profiles into Knowledge Graph for Recommender Systems Using Large Language Models,"['Seokho Ahn', 'Sungbok Shin', 'Young-Duk Seo']",10.1145/3770854.3780324,,"['Recommendation', 'Semantic Profiling', 'Large Language Models', 'Knowledge Graphs']","This paper proposes a new recommendation model, SPiKE, which uses large language models to generate semantic profiles for all knowledge graph entities and integrates these profiles into the graph. The model aims to improve recommendation quality by aligning LLM-based representations during training.",159.12,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08149v1_Dynamic Graph Structure Learning via Resistance Cu.pdf,Dynamic Graph Structure Learning via Resistance Curvature Flow,"['Chaoqun Fei', 'Huanjiang Liu', 'Tinglve Zhou', 'Y angyang Li', 'Tianyong Hao']",,2601.08149v1,"['Dynamic Graph Structure Learning', 'Resistance Curvature Flow', 'Geometric Graph Structure Evolution', 'Manifold Enhancement', 'Noise Suppression', 'Deep Learning']","This paper introduces a novel curvature flow method based on effective resistance from circuit theory, which establishes a new paradigm for geometric graph structure evolution and proposes an efficient Dynamic Graph Structure Learning method for improving representation quality and downstream performance in tasks such as deep metric learning and manifold learning.",147.3,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08156v1_Project Synapse A Hierarchical Multi-Agent Framewo.pdf,Project Synapse: A Hierarchical Multi-Agent Framework with Hybrid Memory for Autonomous Resolution of Last-Mile Delivery Disruptions,"['Arin Gopalan Yadav', 'Varad Dherange', 'Kumar Shivam']",,2601.08156,"['Project Synapse', 'Hierarchical Multi-Agent Framework', 'Hybrid Memory', 'Last-Mile Delivery', 'Autonomous Resolution', 'Disruptions', 'Super-apps', 'Operational Efficiency']","This paper introduces Project Synapse, a novel hierarchical multi-agent framework designed to autonomously resolve last-mile delivery disruptions in super-apps, leveraging a hybrid memory architecture to enable stateful, context-aware reasoning.",149.48,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08160v1_SwiftMem Fast Agentic Memory via Query-aware Index.pdf,SwiftMem: Fast Agentic Memory via Query-aware Indexing,"['Anxin Tian', 'Yiming Li', 'Xing Li', 'Hui-Ling Zhen', 'Lei Chen', 'Xianzhi Yu', 'Zhenhua Dong', 'Mingxuan Yuan']",,2310.16998,"['agentic memory', 'query-aware indexing', 'temporal indexing', 'semantic indexing', 'memory fragmentation', 'LLM agents', 'vector databases', 'knowledge graphs', 'real-time applications', 'memory retrieval']","SwiftMem is a query-aware agentic memory system that achieves sub-linear retrieval through specialized indexing over temporal and semantic dimensions. It addresses memory fragmentation during growth with an embedding-tag co-consolidation mechanism, enabling 47× faster search compared to state-of-the-art baselines while maintaining competitive accuracy.",156.21,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08166v1_ZeroDVFS Zero-Shot LLM-Guided Core and Frequency A.pdf,ZeroDVFS: Zero-Shot LLM-Guided Core and Frequency Allocation for Embedded Platforms,"['Mohammad Pivezhandi', 'Mahdi Banisharif', 'Abusayeed Saifullah', 'Ali Jannesari']",,2601.08166,"['Dynamic Voltage and Frequency Scaling (DVFS)', 'Task-to-Core Allocation', 'Multi-Agent Reinforcement Learning (MARL)', 'Embedded Systems', 'Energy Efficiency', 'Thermal Management']","We propose a model-based hierarchical multi-agent reinforcement learning (MARL) framework for thermal- and energy-aware scheduling on multi-core platforms, enabling zero-shot deployment for new workloads on trained platforms without requiring workload-specific profiling samples. The framework integrates direct reinforcement learning with model-based planning, achieving 20× faster convergence than model-free methods and demonstrating 7.09 × better energy efficiency and 4.0 × better makespan on benchmarks compared to Linux ondemand governor.",161.14,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08173v1_The Agents First Day Benchmarking Learning Explora.pdf,"The Agent’s First Day: Benchmarking Learning, Exploration, and Scheduling in the Workplace Scenarios","['Daocheng Fu', 'Jianbiao Mei', 'Rong Wu', 'Xuemeng Yang', 'Jia Xu', 'Ding Wang', 'Pinlong Cai', 'Yong Liu', 'Licheng Wen', 'Botian Shi']",,2310.00001,"['Multi-modal Large Language Models', 'Workflow Automation', 'Dynamic Task Scheduling', 'Active Exploration', 'Continuous Learning', 'Robustness', 'Stochastic Environment', 'Workplace Scenarios']","This paper introduces Trainee-Bench, a dynamic evaluation environment for agents in workplace scenarios, focusing on dynamic task scheduling, active exploration under uncertainty, and continuous learning from experience. It highlights the deficiencies of current agents in dynamic environments, especially in active exploration and continual learning, and establishes a framework for assessing agent reliability.",160.08,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08176v1_Prompt-Based Clarity Evaluation and Topic Detectio.pdf,Prompt-Based Clarity Evaluation and Topic Detection in Political Question Answering,"['Lavanya Prahallad', 'Sai Utkarsh Choudarypally', 'Pragna Prahallad', 'Pranathi Prahallad']",,,"['Clarity evaluation', 'Prompt engineering', 'Political Question-Answering', 'Large language models', 'Chain-of-thought prompting']","This paper studies prompt-based clarity evaluation using the CLARITY dataset from the SemEval-2026 shared task, comparing a GPT-3.5 baseline against GPT-5.2 evaluated under three prompting strategies: simple prompting, chain-of-thought prompting, and chain-of-thought with few-shot examples. Results show that GPT-5.2 consistently outperforms the GPT-3.5 baseline on clarity prediction, with accuracy improving from 56% to 63% under chain-of-thought with few-shot prompting. Chain-of-thought prompting yields the highest evasion accuracy (34%), though improvements are less stable across fine-grained evasion categories. The paper also evaluates topic identification and finds that reasoning-based prompting improves accuracy from 60% to 74% relative to human annotations.",160.07,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08179v1_Instruction-Driven 3D Facial Expression Generation.pdf,Instruction-Driven 3D Facial Expression Generation and Transition,"['Anh H. V o', 'Tae-Seok Kim', 'Hulin Jin', 'Soo-Mi Choi', 'Yong-Guk Kim*']",,,"['Instruction-Driven', 'Facial Expression and Transition', 'Controllable Avatar', 'CK+ and CelebV-HQ datasets']","This study presents a new framework for instruction-driven facial expression generation that produces a 3D face and transforms the facial expression from one designated expression to another, outperforming state-of-the-art methods on the CK+ and CelebV-HQ datasets.",156.26,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08183v2_GI-Bench A Panoramic Benchmark Revealing the Knowl.pdf,GI-Bench: A Panoramic Benchmark Revealing the Knowledge-Experience Dissociation of Multimodal Large Language Models in Gastrointestinal Endoscopy Against Clinical Standards,"['Yan Zhu', 'Te Luo', 'Pei-Yao Fu', 'Zhen Zhang', 'Zi-Long Wang', 'Yi-Fan Qu', 'Zi-Han Geng', 'Jia-Qi Xu', 'Lu Yao', 'Li-Yun Ma', 'Wei Su', 'Wei-Feng Chen', 'Quan-Lin Li', 'Shuo Wang', 'Ping-Hong Zhou']",,,"['Multimodal Large Language Models', 'Gastrointestinal Endoscopy', 'Clinical Workflow', 'Benchmarking', 'Knowledge-Experience Dissociation', 'Human Endoscopists']","This study systematically evaluates state-of-the-art Multimodal Large Language Models across a panoramic gastrointestinal endoscopy workflow, comparing their performance against junior endoscopists and residency trainees, and identifies Gemini-3-Pro as achieving state-of-the-art diagnostic performance.",142.23,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08185v1_Autonomous Materials Exploration by Integrating Au.pdf,Autonomous Materials Exploration by Integrating Automated Phase Identification and AI-Assisted Human Reasoning,"['Ming-Chiang Chang', 'Maximilian Amsler', 'Duncan R. Sutherland', 'Sebastian Ament', 'Katie R. Gann', 'Lan Zhou', 'Louisa M. Smieska', 'Arthur R. Woll', 'John M. Gregoire', 'Carla P. Gomes', 'R. Bruce van Dover', 'Michael O. Thompson']",,2601.01456,"['Materials Science', 'Autonomous Experimentation', 'AI', 'Phase Identification', 'Human Reasoning', 'Synthetic Chemistry', 'Thin-Film Synthesis', 'Phase Behavior', 'Material Properties']","This paper presents an autonomous materials synthesis extension to SARA, an AI-driven reasoning agent, which integrates automated phase identification with human input to accelerate the search for targeted phase regions in materials exploration. The authors demonstrate the efficiency of their AI implementation and show how human input can significantly improve sampling efficiency, particularly in the Bi-Ti-O system where they identify new processing domains and confirm material properties.",160.79,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08187v2_Improving LLM Reasoning with Homophily-aware Struc.pdf,Improving LLM Reasoning with Homophily-Aware Structural and Semantic Text-Attributed Graph Compression,"['Zijun Di', 'Shanghai Jiao Tong University', 'dzj75du@sjtu.edu.cn', 'Bin Lu', 'Shanghai Jiao Tong University', 'robinlu1209@sjtu.edu.cn', 'Huquan Kang', 'Shanghai Jiao Tong University', 'kinghiqian@sjtu.edu.cn', 'Luoyi Fu', 'Shanghai Jiao Tong University', 'yiluofu@sjtu.edu.cn', 'Jiaxin Ding', 'Shanghai Jiao Tong University', 'jiaxinding@sjtu.edu.cn', 'Xiaoying Gan', 'Shanghai Jiao Tong University', 'ganxiaoying@sjtu.edu.cn', 'Lei Zhou', 'Shanghai Jiao Tong University', 'zhoulei1588@sjtu.edu.cn', 'Xinbing Wang', 'Shanghai Jiao Tong University', 'xwang8@sjtu.edu.cn', 'Chenghu Zhou', 'Chinese Academy of Sciences', 'zhouch@lreis.ac.cn']",,2601.08187v2,"['Large Language Models', 'Text-Attributed Graphs', 'Homophily', 'Structural Entropy', 'Semantic Compression', 'Graph Compression', 'Graph-Level Benchmarks']","This paper proposes HS2C, a framework for improving LLM reasoning by exploiting graph homophily, structurally through global hierarchical partitioning and semantically by delivering detected structural homophily to the LLM for differentiated semantic aggregation. Extensive experiments on various benchmarks demonstrate HS2C's superiority and scalability, achieving significant improvements in compression rate and accuracy.",159.8,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08189v2_ForgetMark Stealthy Fingerprint Embedding via Targ.pdf,FORGETMARK: STEALTHY FINGERPRINT EMBEDDING VIA TARGETED UNLEARNING,"['Zhenhua Xu', 'Haobo Zhang', 'Zhebo Wang', 'Qichen Liu', 'Haitao Xu', 'Wenpeng Xing', 'Meng Han']",10.1109/ICASSP39770.2026.7716486,,"['Large Language Model', 'Copyright protection', 'Model Fingerprinting', 'Machine Unlearning']","ForgetMark is a stealthy fingerprinting framework that encodes provenance via targeted unlearning, avoiding high-perplexity triggers and reducing detectability, while maintaining standard performance and surpassing backdoor baselines in stealthiness and robustness to model merging.",160.31,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08196v1_Evaluating Implicit Regulatory Compliance in LLM T.pdf,Evaluating Implicit Regulatory Compliance in LLM Tool Invocation via Logic-Guided Synthesis,"['Da Song', 'Yuheng Huang', 'Boqi Chen', 'Tianshuo Cong', 'Randy Goebel', 'Lei Ma', 'Foutse Khomh']",10.1007/s10664-024-1001-2,2312.16226,"['Large Language Models', 'LLMs', 'Regulatory Compliance', 'Logic-Guided Synthesis', 'Fuzzing', 'Safety Constraints', 'Python Programs']","This paper introduces LOGISAFETYGEN, a framework that converts unstructured regulations into Linear Temporal Logic oracles and employs logic-guided fuzzing to synthesize valid, safety-critical traces. It constructs LOGISAFETYBENCH, a benchmark comprising 240 human-verified tasks requiring LLMs to generate Python programs that satisfy both functional objectives and latent compliance rules. Evaluations of 13 state-of-the-art LLMs reveal that larger models frequently prioritize task completion over safety, leading to non-compliant behavior.",159.98,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08211v1_Adapting Rules of Official International Mahjong f.pdf,Adapting Rules of Official International Mahjong for Online Players,"['Chucai Wang', 'Lingfeng Li', 'Yunlong Lu', 'Wenxin Li']",,,"['Mahjong', 'game design', 'champion AI']","This paper adapts the rules of Official International Mahjong for online players, addressing issues of fragmented playtime and unfixed opponents. It employs a world champion AI to analyze data and propose rule adaptations, such as compensatory points for the first-mover advantage and refined subgoal scoring.",160.82,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08223v2_DNF Dual-Layer Nested Fingerprinting for Large Lan.pdf,DNF: DUAL-LAYER NESTED FINGERPRINTING FOR LARGE LANGUAGE MODEL,"['Zhenhua Xu', 'Yiran Zhao', 'Mengting Zhong', 'Dezhang Kong', 'Changting Lin', 'Tong Qiao', 'Meng Han']",10.1109/ICASSP39486.2026.7716444,,"['Large Language Model', 'Copyright Protection', 'Model Fingerprinting', 'Backdoor']","The paper proposes Dual-Layer Nested Fingerprinting (DNF), a black-box method that embeds a hierarchical backdoor by coupling domain-specific stylistic cues with implicit semantic triggers. DNF achieves perfect fingerprint activation while preserving downstream utility, using lower-perplexity triggers and remaining undetectable under fingerprint detection attack.",160.19,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08224v1_An Axiomatic Approach to General Intelligence SANC.pdf,An Axiomatic Approach to General Intelligence: SANC(E3),"['Daesuk Kwon', 'Won-gi Paeng']",null,2601.08224,"['axiomatizationofintelligence', 'competitiveselection', 'systemtokens', 'reconstruction–compression trade-off', 'category formation', 'self-similar hierarchy', 'Gestalt completion']","This paper proposes SANC(E3), an axiomatic framework for general intelligence, where representational units emerge through competitive selection, reconstruction, and compression under finite activation capacity, governed by an energy functional. It unifies perception, imagination, prediction, planning, and action within a single representational and energetic process.",160.59,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08226v1_Knowledge-based learning in Text-RAG and Image-RAG.pdf,Knowledge-based learning in Text-RAG and Image-RAG,"['Alexander Shim', 'Khalil Saieh', 'Samuel Clarke']",,,"['Knowledge-based learning', 'Text-RAG', 'Image-RAG', 'Radiology', 'Vision Transformers', 'Large Language Models', 'Chest X-ray Images', 'Hallucination Problem', 'Diagnostic Delay']","This research analyzes and compares the performance of text-based RAG and image-based RAG models in reducing hallucination problems and improving disease detection in chest x-ray images, utilizing NIH Chest X-ray images for training and evaluation.",160.54,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08230v1_GADPN Graph Adaptive Denoising and Perturbation Ne.pdf,GADPN: Graph Adaptive Denoising and Perturbation Networks via Singular Value Decomposition,"['Hao Deng', 'Bo Liu,Member, IEEE']",,1912.07381,"['Graph Neural Networks', 'Graph Structural Learning', 'Network Representation Learning']","This paper proposes GADPN, a simple yet effective graph structure learning framework that adaptively refines graph topology via low-rank denoising and generalized structural perturbation, achieving state-of-the-art performance with significantly improved efficiency on benchmark datasets.",136.73,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08235v2_MPCI-Bench A Benchmark for Multimodal Pairwise Con.pdf,MPCI-Bench: A Benchmark for Multimodal Pairwise Contextual Integrity Evaluation of Language Model Agents,"['Shouju Wang', 'Haopeng Zhang']",,2309.09215,"['Contextual Integrity', 'Multimodal Privacy', 'Language Model Agents', 'Pairwise Contextual Integrity', 'Tri-Principle Iterative Refinement']","This paper introduces MPCI-Bench, the first multimodal pairwise contextual integrity benchmark for evaluating privacy behavior in agentic settings. It consists of paired positive and negative instances derived from the same visual source and covers normative judgments, context-rich reasoning, and executable agent actions. Evaluations reveal systematic failures in balancing privacy and utility and a modality leakage gap where sensitive visual information is leaked more frequently than textual information.",160.17,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08237v1_The End of Reward Engineering How LLMs Are Redefin.pdf,The End of Reward Engineering: How LLMs Are Redefining Multi-Agent Coordination,"['Haoran Su', 'Yandong Sun', 'Congjia Yu']",,2601.08237v1,"['multi-agent reinforcement learning', 'reward engineering', 'large language models', 'credit assignment', 'non-stationarity', 'semantic understanding']","This paper argues that large language models (LLMs) enable a fundamental paradigm shift in reward engineering for multi-agent reinforcement learning, moving from hand-crafted numerical rewards to natural language objectives, and discusses the challenges and opportunities of this transition.",155.62,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08251v1_Hyperbolic Heterogeneous Graph Transformer.pdf,Hyperbolic Heterogeneous Graph Transformer,"['Jongmin Park', 'Seunghoon Han', 'Hyewon Lee', 'Won-Yong Shin', 'Sungsu Lim']",,2209.12467,"['Heterogeneous Graph Representation Learning', 'Hyperbolic Graph Embedding', 'Graph Transformer']","The paper proposes Hyperbolic Heterogeneous Graph Transformer (HypHGT), a method that effectively and efficiently learns heterogeneous graph representations within the hyperbolic space, capturing both local and global dependencies through a transformer-based architecture and relation-specific hyperbolic attention mechanism.",155.24,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08254v1_Large Artificial Intelligence Model Guided Deep Re.pdf,Large Artificial Intelligence Model–Guided Deep Reinforcement Learning for Resource Allocation in Non-Terrestrial Networks,"['Abdikarim Mohamed Ibrahim', 'Rosdiadee Nordin']",,,"['Large AI Models (LAMs)', 'Large Language Models (LLMs)', 'Deep Reinforcement Learning (DRL)', 'Satellite Communications', 'Non-Terrestrial Networks (NTNs)']",This paper proposes a Deep Reinforcement Learning agent guided by a Large Language Model for resource allocation in Non-Terrestrial Networks. The results show improved performance compared to traditional methods in both nominal and extreme weather scenarios.,160.56,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08257v2_On Evaluation of Unsupervised Feature Selection fo.pdf,On Evaluation of Unsupervised Feature Selection for Pattern Classification,"['Gyu-Il Kim', 'Dae-Won Kim', 'Jaesung Lee']",10.48550/arXiv.2601.08257,2601.08257,"['Unsupervised Feature Selection', 'Pattern Classification', 'Multi-Label Classification', 'Hamming Loss', 'Ranking Loss', 'One-Error', 'Multi-Label Accuracy']","This study revisits the evaluation paradigm of unsupervised feature selection methods by adopting a multi-label classification framework, demonstrating that performance rankings differ significantly from those reported under single-label settings, suggesting the possibility of fair and reliable comparison of unsupervised feature selection methods in multi-label evaluation settings.",156.26,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08258v1_T3 Benchmarking Sycophancy and Skepticism in Causa.pdf,T3: Benchmarking Sycophancy and Skepticism in Causal Judgment,['Edward Y. Chang'],,2311.16876,"['Causal judgment', 'Large Language Models', 'Sycophancy', 'Skepticism', 'Benchmarking', 'Utility', 'Safety', 'Underdetermination', 'Scaling Paradox', 'Skepticism Trap', 'RLHF']","The paper introduces T3, a diagnostic benchmark to rigorously evaluate Large Language Models (LLMs) across Pearl's Causal Hierarchy, distinguishing between genuine capability and safety-induced refusal. It diagnoses two pathologies: a ",153.84,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08262v1_VGG Induced Deep Hand Sign Language Detection.pdf,VGG Induced Deep Hand Sign Language Detection,"['Subham Sharma', 'Sharmila Subudhi']",,2601.08262,"['Hand gesture recognition', 'Convolutional neural network', 'Classification', 'VGG-16 net', 'API']","This work proposes a novel hand gesture recognizing system for the differently-abled persons using a VGG-16 net, validated on the NUS dataset and tested on a Google API captured human hand gestures, achieving around 98% accuracy.",159.96,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08271v1_Sparsity Is Necessary Polynomial-Time Stability fo.pdf,Sparsity Is Necessary: Polynomial-Time Stability for Agentic LLMs in Large Action Spaces,['Angshul Majumdar'],,2601.08271,"['Agentic Control', 'Sparse Agentic Control (SAC)', 'Polynomial-Time Stability', 'Large Action Spaces', 'Sequential Decision-Making', 'Sparse Representations', 'ℓ1,2-Regularized Policy Learning', 'Compressed Sensing', 'Tool-Augmented LLMs', 'Partial Observability']","This paper formalizes the setting of Sparse Agentic Control (SAC) for sequential decision-making with a massive discrete action universe and establishes sharp results on the estimation and value suboptimality of policies under ℓ1,2 regularization. It also discusses the limitations of dense policy classes and the importance of sparsity in tool-augmented decision-making.",161.19,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08273v1_HIPPO Accelerating Video Large Language Models Inf.pdf,HIPPO: Accelerating Video Large Language Models Inference via Holistic-aware Parallel Speculative Decoding,"['Qitan Lv', 'Tianyu Liu', 'Wen Wu', 'Xuenan Xu', 'Bowen Zhou', 'Feng Wu', 'Chao Zhang']",10.1002/xxx,2309.14312,"['Large Language Models', 'Video Understanding', 'Speculative Decoding', 'Token Pruning', 'Parallel Processing']","This paper proposes HIPPO, a holistic-aware parallel speculative decoding framework to accelerate video Large Language Models inference, addressing the limitations of existing methods that inadequately preserve visual semantic tokens and limit overall speedup even with aggressive pruning.",160.22,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08276v1_ToolACE-MCP Generalizing History-Aware Routing fro.pdf,ToolACE-MCP: Generalizing History-Aware Routing from MCP Tools to the Agent Web,"['Zhiyuan Yao', 'Zishan Xu', 'Yifu Guo', 'Zhiguang Han', 'Cheng Yang', 'Shuo Zhang', 'Weinan Zhang', 'Xingshan Zeng', 'Weiwen Liu']",,2310.17087,"['Agent Web', 'Model Context Protocol (MCP)', 'History-Aware Routing', 'Multi-Agent Collaboration', 'Robustness', 'Scalability', 'Noise Robustness']","This paper proposes ToolACE-MCP, a pipeline for training history-aware routers to empower precise navigation in large-scale ecosystems. Leveraging a dependency-rich candidate graph, it effectively trains routers with dynamic context understanding to create the plug-and-play Light Routing Agent, demonstrating superior performance on real-world benchmarks MCP-Universe and MCP-Mark.",154.57,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08280v1_Greedy Is Enough Sparse Action Discovery in Agenti.pdf,Greedy Is Enough: Sparse Action Discovery in Agentic LLMs,['Angshul Majumdar'],,1909.08064,"['action discovery', 'agentic systems', 'linear reward model', 'sparse action', 'Orthogonal Matching Pursuit', 'large action spaces', 'language models', 'sparse recovery']","This paper studies a contextual linear reward model in which only a small subset of actions are relevant, and proposes a greedy algorithm inspired by Orthogonal Matching Pursuit to discover these actions. The authors prove that the greedy procedure can exactly recover the relevant action set with high probability, using a number of samples that scales polynomially in the sparsity level and latent dimension, and only logarithmically in the total number of actions.",159.75,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08288v1_OpenMic A Multi-Agent-Based Stand-Up Comedy Genera.pdf,OpenMic: A Multi-Agent-Based Stand-Up Comedy Generation System,"['Yuyang Wu', 'Hanzhong Cao', 'Jianhao Chen', 'Yufei Li']",,2309.12747,"['stand-up comedy', 'multi-agent system', 'humor generation', 'retrieval-augmented generation', 'JokeWriter', 'Chinese humor']","OpenMic is an end-to-end multi-agent system that transforms a user-provided life topic into a 3–5 minute Chinese stand-up performance, incorporating specialized agents for humor, timing, and performability, and using retrieval-augmented generation and fine-tuned JokeWriter for material grounding and idea expansion.",159.39,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08297v1_Demystifying the Slash Pattern in Attention The Ro.pdf,Demystifying the Slash Pattern in Attention: The Role of RoPE,"['Yuan Cheng', 'Fengzhuo Zhang', 'Yunlong Hou', 'Cunxiao Du', 'Tianyu Pang', 'Aixin Sun', 'Zhuoran Yang']",,2601.08297v1,"['Attention mechanisms', 'Rotary Position Embedding (RoPE)', 'Large Language Models (LLMs)', 'Slash-Dominant Heads (SDHs)', 'Rank-one matrices', 'High-frequency components', 'Medium-frequency components', 'Out-of-distribution (OOD) generalization']","This paper demystifies the emergence of Slash-Dominant Heads (SDHs) in large language models (LLMs) by analyzing queries, keys, and Rotary Position Embedding (RoPE). It reveals that queries and keys are almost rank-one and that RoPE is dominated by medium- and high-frequency components, leading to SDHs and OOD generalization.",157.92,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08302v1_Enhancing Sentiment Classification and Irony Detec.pdf,Enhancing Sentiment Classification and Irony Detection in Large Language Models through Advanced Prompt Engineering Techniques,"['Marvin Schmitt ∗∗', 'Anne Schwerk', 'Sebastian Lempert ∗']",,,"['sentiment analysis', 'irony detection', 'large language models (LLMs)', 'prompt engineering']","This study investigates the use of prompt engineering to enhance large language models (LLMs), specifically GPT-4o-mini and gemini-1.5-flash, in sentiment analysis tasks. It evaluates advanced prompting techniques like few-shot learning, chain-of-thought prompting, and self-consistency against a baseline, focusing on sentiment classification, aspect-based sentiment analysis, and irony detection. The research details the theoretical background, datasets, and methods used, assessing performance using accuracy, recall, precision, and F1 score. Findings reveal that advanced prompting significantly improves sentiment analysis, with few-shot prompting excelling in GPT-4o-mini and chain-of-thought prompting boosting irony detection in gemini-1.5-flash by up to 46%. The study highlights the importance of tailoring prompting strategies to both the model and the task.",158.96,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08310v1_ORBIT On-policy Exploration-Exploitation for Contr.pdf,ORBIT: On-policy Exploration-Exploitation for Controllable Multi-Budget Reasoning,"['Kun Liang', 'Clive Bai', 'Xin Xu', 'Chenming Tang', 'Sanwoo Lee', 'Weijie Liu', 'Saiyong Yang', 'Yunfang Wu']",,2601.01456,"['Reinforcement Learning', 'Multi-Budget Reasoning', 'On-policy Exploration-Exploitation', 'Controllable Reasoning', 'Large Language Models']","Proposes ORBIT, a controllable multi-budget reasoning framework with well-separated reasoning modes triggered by input, employing multi-stage reinforcement learning to discover Pareto-optimal reasoning behaviors at each effort, followed by on-policy distillation to fuse these behaviors into a single unified model, achieving controllable reasoning behavior over multiple modes, competitive reasoning density within each mode, and integration of these frontier policies into a single unified student model while preserving clear mode separation and high per-mode performance.",158.11,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08311v1_Enhancing Image Quality Assessment Ability of LMMs.pdf,Enhancing Image Quality Assessment Ability of LMMs via Retrieval-Augmented Generation,"['Kang Fu', 'Huiyu Duan', 'Zicheng Zhang', 'Yucheng Zhu', 'Jun Zhao', 'Xiongkuo Min', 'Jia Wang', 'Guangtao Zhai']",,2304.08892,"['Image quality assessment', 'Retrieval-Augmented Generation', 'Large Multimodal Models', 'Zero-shot', 'Training-free']","This paper introduces IQARAG, a training-free framework that enhances the Image Quality Assessment (IQA) ability of Large Multimodal Models (LMMs) by leveraging Retrieval-Augmented Generation (RAG) to retrieve semantically similar but quality-variant reference images for input images, thereby providing a visual perception anchor for IQA tasks and boosting the performance of LMMs in IQA tasks across multiple datasets.",157.79,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08323v1_AtomMem  Learnable Dynamic Agentic Memory with Ato.pdf,AtomMem : Learnable Dynamic Agentic Memory,"['Yupeng Huo', 'Yaxi Lu', 'Zhong Zhang', 'Haotian Chen', 'Yankai Lin*']",,2310.17894,"['memory', 'agents', 'dynamic', 'CRUD', 'supervised fine-tuning', 'reinforcement learning', 'long-horizon tasks', 'atomic operations']","This paper proposes AtomMem, a learning-based memory framework that reframes memory management as a dynamic decision-making problem. By decomposing memory processes into atomic CRUD operations and combining supervised fine-tuning with reinforcement learning, AtomMem learns an autonomous policy to orchestrate memory behaviors tailored to specific tasks. Experimental results demonstrate that AtomMem consistently outperforms static workflow memory methods across long-context benchmarks.",153.6,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08327v1_Safe Heterogeneous Multi-Agent RL with Communicati.pdf,Safe Heterogeneous Multi-Agent RL with Communication Regularization for Coordinated Target Acquisition,"['Gabriele Calzolari', 'Vidya Sumathy', 'Christoforos Kanellakis', 'George Nikolakopoulos']",,2309.14496,"['Cooperative target acquisition', 'Safe autonomous coordination', 'Decentralized multi-agent reinforcement learning', 'Heterogeneous robotic systems', 'Learning-based control']","This paper presents a decentralized multi-agent reinforcement learning framework for structurally heterogeneous teams of agents to jointly discover and acquire randomly located targets in environments with partial observability, communication constraints, and dynamic interactions. Each agent's policy is trained with the Multi-Agent Proximal Policy Optimization algorithm and uses a Graph Attention Network encoder that integrates simulated range-sensing data with communication embeddings. The framework promotes collision avoidance and information orthogonality through a structured reward function and safety filters, demonstrating effective task execution through simulations.",154.2,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08332v1_IGAN A New Inception-based Model for Stable and Hi.pdf,IGAN: A New Inception-based Model for Stable and High-Fidelity Image Synthesis Using Generative Adversarial Networks,"['Ahmed A. Hashim', 'Ali Al-Shuwaili', 'Asraa Saeed', 'Ali Al-Bayaty']",,,"['Generative Adversarial Networks (GANs)', 'dilation convolutions', 'inception module', 'spectral normalization', 'image synthesis', 'deep learning stability']","This paper proposes a novel GAN model, Inception Generative Adversarial Network (IGAN), which generates high-quality synthetic images while maintaining training stability by incorporating deeper inception-inspired convolution and dilated convolution. The IGAN model achieves improved FID and IS scores compared to state-of-the-art GANs, demonstrating better image diversity and generation quality.",154.2,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08333v1_Semantic Laundering in AI Agent Architectures Why .pdf,Semantic Laundering in AI Agent Architectures: Why Tool Boundaries Do Not Confer Epistemic Warrant,"['Oleg Romanchuk', 'Roman Bondar']",null,2601.08333,"['AI', 'Agent Architectures', 'Semantic Laundering', 'Gettier Problem', 'Epistemic Warrant', 'LLM']","This paper identifies a structural defect in AI agent architectures that conflate information transport mechanisms with epistemic justification mechanisms, leading to a phenomenon called semantic laundering. The authors formalize this as a pattern where propositions with absent or weak warrant are accepted by the system, showing that this effect is architecturally determined and systematically reproducible, akin to the Gettier problem in classical epistemology.",149.72,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08360v1_Scalable Sequential Recommendation under Latency a.pdf,Scalable Sequential Recommendation under Latency and Memory Constraints,"['Adithya Parthasarathy', 'Aswathnarayan Muthukrishnan Kirubakaran', 'Vinoth Punniyamoorthy', 'Nachiappan Chockalingam', 'Lokesh Butra', 'Kabilan Kannan', 'Abhirup Mazumder', 'Sumit Saha']",10.1109/IEEECompanion.2026.00013,2601.08360,"['Recommender Systems', 'Sequence Modeling', 'Representation Learning', 'Scalable Machine Learning', 'Deep Learning']","This paper presents HoloMambaRec, a lightweight sequential recommendation architecture that combines holographic reduced representations for attribute-aware embedding with a selective state space encoder for linear-time sequence processing, demonstrating consistent performance and lower memory complexity compared to existing methods on Amazon Beauty and MovieLens-1M datasets.",160.03,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08371v1_Geo-NVS-w Geometry-Aware Novel View Synthesis In-t.pdf,Geo-NVS-w: Geometry-Aware Novel View Synthesis In-the-Wild,"['Anastasios Tsalakopoulos', 'Angelos Kanlis', 'Evangelos Chatzis', 'Antonis Karakottas', 'Dimitrios Zarpalas']",,1911.05828,"['Novel View Synthesis', 'In-the-Wild', 'Geometry-Aware', 'Signed Distance Function (SDF)', 'Novel View Synthesis (NVS)', 'Photorealism', 'Energy Efficiency']","We introduce Geo-NVS-w, a geometry-aware framework for high-fidelity novel view synthesis from unstructured, in-the-wild image collections, addressing the limitation of existing methods by leveraging an underlying geometric representation based on a Signed Distance Function (SDF) to guide the rendering process and ensure fine structural details are preserved.",160.9,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08379v1_Training-Free Distribution Adaptation for Diffusio.pdf,Training-Free Distribution Adaptation for Diffusion Models via Maximum Mean Discrepancy Guidance,"['Matina Mahdizadeh Sani', 'Nima Jamali', 'Mohammad Jalali', 'Farzan Farnia']",,2309.15434,"['Diffusion Models', 'Maximum Mean Discrepancy (MMD)', 'Distribution Adaptation', 'Inference-Time Guidance', 'Domain Adaptation']","This paper proposes MMD Guidance, a training-free mechanism that augments the reverse diffusion process with gradients of the Maximum Mean Discrepancy (MMD) between generated samples and a reference dataset to achieve distributional alignment while preserving sample fidelity in diffusion models for domain adaptation tasks.",161.99,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08380v1_Thematic Working Group 5 -- Artificial Intelligenc.pdf,EDUsummIT 2025 - eBook,"['Mary Webb', 'Matt Bower', 'Ana Amélia Carvalho', 'Fredrik Mørk Røkenes', 'Jodie Torrington', 'Jonathan D. Cohen', 'Yousra Chtouki', 'Kathryn MacCallum', 'Tanya Linden', 'Deirdre Butler', 'Juliana E. Raffagheli', 'Henriikka Vartiainen', 'Martina Ronci', 'Peter Tiernan', 'David M. Smith', 'Chris Shelton', 'Joyce Malyn-Smith', 'Pierre Gorissen']",,,"['AI literacy', 'teaching and learning', 'curriculum design', 'professional development', 'practical classroom applications', 'policy guidelines', 'plagiarism', 'academic integrity', 'creativity', 'critical thinking', 'ChatGPT3', 'generative AI', 'non-generative AI', 'adaptive assessment', 'intelligent predictive analytics', 'conversational agents']","This thematic working group focused on developing and implementing effective strategies for enhancing AI literacy and agency of teachers, equipping them with the knowledge and skills necessary to integrate AI into their teaching practices, including curriculum design, professional development programs, practical classroom applications, and policy guidelines aimed at empowering educators to confidently utilize AI tools and foster a deeper understanding of AI concepts among students.",160.72,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08382v2_A Qualitative Model to Reason about Object Rotatio.pdf,A Qualitative Model to Reason about Object Rotations – applied to solve the Cube Comparison Test,['Zoe Falomira'],,,"['cube comparison test', 'mental rotation', 'qualitative reasoning', 'spatial cognition', 'spatial reasoning']","This paper presents a Qualitative model for Reasoning about Object Rotations (QOR) applied to solve the Cube Comparison Test (CCT) by Ekstrom et al. (1976), building a conceptual neighborhood graph relating rotation movements to location and orientation changes of cube features, and producing composition tables for inferences in spatial reasoning.",160.83,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08383v1_Deconstructing Pre-training Knowledge Attribution .pdf,Deconstructing Pre-training: Knowledge Attribution Analysis in MoE and Dense Models,"['Bo Wang', 'Junzhuo Li', 'Hong Chen', 'Yuanlin Chu', 'Yuxuan Fan', 'Xuming Hu']",,2605.08377,"['Mixture-of-Experts', 'Knowledge Acquisition', 'Pre-training', 'Neuron-level Attribution', 'Log-Probability Increase', 'Dense Models', 'Interpretability']","This paper introduces Gated-LPI, a neuron-level attribution metric, to analyze knowledge acquisition dynamics in Mixture-of-Experts (MoE) and dense models during pre-training. It presents a time-resolved comparison of these architectures, uncovering patterns such as a high-utility core in MoE models, early consolidation, and functional robustness, demonstrating that sparsity fosters an intrinsically stable and distributed computational backbone.",141.47,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08388v1_Creativity in AI as Emergence from Domain-Limited .pdf,Creativity in AI as Emergence from Domain-Limited Generative Models,['Corina Chutaux'],,1912.02302,"['Creativity', 'Artificial Intelligence', 'Generative Models', 'Emergence', 'Multimodal Systems']","This paper proposes a generative perspective on creativity in AI, framing it as an emergent property of domain-limited generative models embedded within bounded informational environments. It examines how four interacting components—pattern-based generation, induced world models, contextual grounding, and arbitrariness—manifest in multimodal generative systems, providing a technical framework for studying creativity as an emergent phenomenon.",160.21,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08393v1_Controlled LLM Training on Spectral Sphere.pdf,Controlled LLM Training on Spectral Sphere,"['Tian Xie', 'Haoming Luo', 'Haoyu Tang', 'Yiwen Hu', 'Jason Klein Liu Qingnan Ren', 'Yang Wang', 'Wayne Xin Zhao', 'Rui Yan', 'Bing Su', 'Chong Luo', 'Baining Guo']",,2601.08393v1,"['Large Language Models', 'Spectral Sphere', 'Maximal Update Parametrization', 'Muon Optimizer', 'Megatron', 'Stability', 'Activation Control']","This paper introduces the Spectral Sphere Optimizer (SSO) to address the limitations of existing optimizers like Muon, which only partially align with theoretical constraints for activation control. SSO enforces strict spectral constraints on both weights and updates, ensuring a fully aligned optimization process. Through extensive pretraining on various architectures, SSO outperforms AdamW and Muon, demonstrating significant practical stability benefits.",160.46,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08401v1_An Explainable Two Stage Deep Learning Framework f.pdf,An Explainable Two-Stage Deep Learning Framework for Pericoronitis Assessment in Panoramic Radiographs Using YOLOv8 and ResNet-50,"['Ajo Babu George', 'Pranav S', 'Kunal Agarwal']",,2601.08401v1,"['pericoronitis', 'panoramic radiographs', 'YOLOv8', 'ResNet-50', 'deep learning', 'interpretability']","This study presents an AI-assisted system for diagnosing pericoronitis on panoramic radiographs using a two-stage deep learning pipeline, integrating anatomical localization and pathological classification with interpretability features.",161.0,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08402v1_PATS Personality-Aware Teaching Strategies with La.pdf,PATS: Personality-Aware Teaching Strategies with Large Language Model Tutors,"['Donya Rooein1*', 'Sankalan Pal Chowdhury2*', 'Mariia Eremeeva2', 'Yuan Qin3', 'Debora Nozza 1', 'Mrinmaya Sachan 2', 'Dirk Hovy 1']",,2310.18716,"['large language models', 'teaching strategies', 'personality traits', 'pedagogical literature', 'student outcomes', 'interactive discussions', 'learning sciences', 'teaching methods', 'role-playing', 'intelligent tutoring systems']","This paper addresses the mismatch between student personalities and tutoring strategies in large language model tutors, proposing a taxonomy linking pedagogical methods to personality profiles. It simulates student-teacher conversations and uses the framework to adjust the LLM tutor's strategy, finding that it consistently prefers the approach over two base lines and increases the use of less common, high-impact strategies.",158.79,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08403v1_Owen-Shapley Policy Optimization OSPO A Principled.pdf,Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for Generative Search LLMs,"['Abhijnan Nath', 'Alireza Bagheri Garakani', 'Tianchen Zhou', 'Fan Yang', 'Nikhil Krishnaswamy']",null,null,"['Reinforcement Learning', 'Policy Optimization', 'Large Language Models', 'Generative Search', 'Shapley-Owen Attribution', 'Coalitions', 'Reward Shaping', 'Interpretability', 'Robustness']","This paper introduces OSPO, a framework that redistributes sequence-level advantages based on tokens' marginal contributions to outcomes, addressing the credit assignment gap in reinforcement learning for personalized recommendation tasks. OSPO identifies which response parts drive performance by forming semantically coherent units and assigns segment-level credit while preserving the optimal policy, directly from task feedback without parametric value models. Experiments on Amazon ESCI and H&M Fashion datasets show consistent gains over baselines, with notable test-time robustness to out-of-distribution retrievers unseen during training.",144.58,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08406v1_WebTrap Park An Automated Platform for Systematic .pdf,WebTrap Park: An Automated Platform for Systematic Security Evaluation of Web Agents,"['Xinyi Wu†', 'Jiagui Chen †', 'Geng Hong †B', 'Jiayi Dong †', 'Xudong Pan †‡', 'Jiarun Dai †', 'Min Yang †B']",,,"['Web Agents', 'Security Evaluation', 'Automated Platform', 'Systematic Security Evaluation', 'Web Security', 'Security Evaluation of Web Agents']","This paper presents WebTrapPark, an automated platform designed for the systematic security evaluation of Web Agents, which covers three major risk sources and instantiates them into 1,226 evaluation tasks across different fine-grained risk categories.",141.14,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08412v1_Hybrid Distillation with CoT Guidance for Edge-Dro.pdf,Hybrid Distillation with CoT Guidance for Edge-Drone Control Code Generation,"['Yizhan Feng', 'Hichem Snoussi', 'Yuhang Wang', 'Jing Teng', 'Abel Cherouat', 'Tian Wang']",,2309.16448,"['Large language models', 'drone', 'Knowledge Distillation', 'Chain-of-Thought', 'Lightweight']","This paper proposes an integrated approach that combines knowledge distillation, chain-of-thought guidance, and supervised fine-tuning for UAV multi-SDK control tasks, aiming to efficiently transfer complex reasoning and code generation capabilities to smaller models.",155.54,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08415v2_Regulatory gray areas of LLM Terms.pdf,Regulatory gray areas of LLM Terms,"['Brittany I. Davidson', 'Kate Muir', 'Florian A.D. Burnat', 'Adam N. Joinson']",,2601.08415v2,"['Language Models', 'LLMs', 'Privacy Policy', 'Terms of Service', 'Regulation']","This paper presents a comparative analysis of the Terms of Service of five major LLM providers, revealing substantial variation in usage restrictions and identifying regulatory gray areas for researchers in specific fields.",133.21,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08418v1_Taxon Hierarchical Tax Code Prediction with Semant.pdf,Taxon: Hierarchical Tax Code Prediction with Semantically Aligned LLM Expert Guidance,"['Jihang Li', 'Qing Liu', 'Zulong Chen', 'Jing Wang', 'Wei Wang', 'Chuanfei Xu', 'Zeyi Wen']",,,"['Tax code prediction', 'Automated invoicing', 'Compliance management', 'Hierarchical taxonomy', 'Large language models', 'Feature gating', 'Semantic consistency', 'Multi-source training', 'E-commerce platforms']","This paper presents Taxon, a semantically aligned and expert-guided framework for hierarchical tax code prediction in large-scale e-commerce platforms. Taxon integrates a feature-gating mixture-of-experts architecture and a semantic consistency model from large language models to address noisy supervision in real business records and achieve state-of-the-art performance.",161.49,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08430v1_RubricHub A Comprehensive and Highly Discriminativ.pdf,RubricHub: A Comprehensive and Highly Discriminative Rubric Dataset,"['Sunzhu Li', 'Jiale Zhao', 'Miteto Wei', 'Huimin Ren', 'Yang Zhou', 'Jingwen Yang', 'Shunyu Liu', 'Kaike Zhang', 'Wei Chen']",,2310.14867,"['Reinforcement Learning with Verifiable Rewards', 'Rubric-based Evaluation', 'Automated Rubric Generation', 'Large-scale Dataset', 'Open-ended Generation']","This paper proposes an automated Coarse-to-Fine Rubric Generation framework to address the challenges of optimizing open-ended generation in RLVR. It introduces RubricHub, a large-scale dataset for validation, and demonstrates significant performance gains through post-training Rubric-based Rejection Sampling Fine-Tuning and Reinforcement Learning.",160.78,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08434v3_Large Multimodal Models for Embodied Intelligent D.pdf,Large Multimodal Models for Embodied Intelligent Driving: The Next Frontier in Self-Driving?,"['Long Zhang', 'Yuchen Xia', 'Zhen Liu', 'Bingqing Wei', 'Shiwen Mao', 'Zhu Han', 'Mohsen Guizani']",,1909.08802,"['autonomous driving', 'large multimodal models', 'embodied intelligence', 'self-driving', 'semantic understanding', 'policy optimization', 'deep reinforcement learning']","This article introduces a novel semantics and policy dual-driven hybrid decision framework to tackle the challenge of enhancing embodied intelligent driving (El driving) using Large Multimodal Models (LMMs). The framework merges LMMs for semantic understanding and cognitive representation, and deep reinforcement learning (DRL) for real-time policy optimization, ensuring continuous learning and joint decision-making.",160.51,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08441v1_YaPO Learnable Sparse Activation Steering Vectors .pdf,YaPO: Learnable Sparse Activation Steering Vectors for Domain Adaptation,"['Abdelaziz Bounhar', 'Rania Hossam Elmohamady Elbadry', 'Hadi Abdine', 'Preslav Nakov', 'Michalis Vazirgiannis', 'Guokan Shang']",,1909.07296,"['Large Language Models', 'Domain Adaptation', 'Activation Steering', 'Sparse Autoencoder', 'Bi-directional Preference Optimization', 'Reinforcement Learning from Human Feedback']","This paper proposes Y aPO, a reference-free method that learns sparse steering vectors in the latent space of a Sparse Autoencoder (SAE) to control the behavior of Large Language Models (LLMs) in a fine-grained and interpretable manner. Y aPO outperforms dense steering baselines in convergence, performance, and stability, and generalizes to various alignment-related behaviors.",156.58,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08444v1_Beyond Linearization Attributed Table Graphs for T.pdf,Beyond Linearization: Attributed Table Graphs for Table Reasoning,"['Yuxiang Wang', 'Junhao Gan', 'Shengxiang Gao', 'Shenghao Ye', 'Zhengyi Yang', 'Jianzhong Qi']",,2309.15247,"['Table Reasoning', 'Attributed Table Graphs', 'Large Language Models', 'Linearization', 'Question-Answering']","This paper proposes Table Graph Reasoner (TABGR), a training-free model that represents tables as an Attributed Table Graph (ATG) to address the limitations of linearization-based methods in table reasoning. TABGR explicitly preserves row-column-cell structures while enabling graph-based reasoning for explainability and mitigates the lost-in-the-middle issue through a Question-Guided Personalized PageRank (QG-PPR) mechanism. Extensive experiments show that TABGR outperforms state-of-the-art models by up to 9.7% in accuracy.",159.49,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08448v1_Divide and Conquer Static-Dynamic Collaboration fo.pdf,Divide and Conquer: Static-Dynamic Collaboration for Few-Shot Class-Incremental Learning,"['Kexin Bao', 'Daichi Zhang∗', 'Yong Li', 'Dan Zeng', 'Shiming Ge∗']",10.1145/3731715.3733310,,"['Few-Shot Class-Incremental Learning', 'Class-Incremental Learning']","This paper proposes a framework termed Static-Dynamic Collaboration (SDC) to address the stability-plasticity dilemma in few-shot class-incremental learning, dividing the task into Static Retaining Stage and Dynamic Learning Stage to achieve a better trade-off between stability and plasticity.",160.72,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08450v1_Decoding Order Matters in Autoregressive Speech Sy.pdf,DECODING ORDER MATTERS IN AUTOREGRESSIVE SPEECH SYNTHESIS,"['Minghui Zhao', 'Anton Ragni']",,,"['speech synthesis', 'discrete diffusion model', 'order-agnostic autoregressive decoding']","This paper investigates the impact of decoding order on autoregressive speech synthesis using a masked diffusion framework. It shows that randomness in decoding order affects speech quality and compares fixed and adaptive decoding strategies, finding that adaptive decoding yields better performance. The study also explores the use of quantized acoustic representations to support high-quality speech synthesis.",137.72,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08457v1_An Under-Explored Application for Explainable Mult.pdf,An Under-Explored Application for Explainable Multimodal Misogyny Detection in code-mixed Hindi-English,"['Sargam Yadava', 'Abhishek Kaushik', 'Kevin McDaid']",,,"['hate speech', 'misogyny', 'natural language processing', 'code-mixing', 'hinglish']","This paper presents a multi-modal and explainable web application for detecting misogyny in text and memes in code-mixed Hindi and English, leveraging state-of-the-art transformer-based models and providing feature importance scores using explainability techniques.",158.41,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08462v1_M3-BENCH Process-Aware Evaluation of LLM Agents So.pdf,M3-BENCH: Process-Aware Evaluation of LLM Agents Social Behaviors in Mixed-Motive Games,"['Sixiong Xie*', 'Zhuofan Shi*', 'Haiyang Shen*', 'Gang Huang', 'Yun Ma', 'Xiang Jing*']",,2310.15885,"['Large Language Models', 'Social Behaviors', 'Mixed-Motive Games', 'Process-Aware Evaluation', 'Behavioral Trajectory Analysis', 'Reasoning Process Analysis', 'Communication Content Analysis', 'Big Five Personality Model', 'Social Exchange Theory']","As large language model agents advance, their social behaviors, including cooperation, deception, and collusion, require systematic evaluation. M3-BENCH, a multi-stage benchmark for mixed-motive games, introduces a process-aware evaluation framework that analyzes agents' decision reasoning and communicative interactions across three modules: BTA, RPA, and CCA. It integrates personality models and social exchange theory to characterize agents' personality traits and capability profiles beyond simple task scores or outcome-based metrics.",154.14,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08464v1_CoMa Contextual Massing Generation with Vision-Lan.pdf,CoMa: Contextual Massing Generation with Vision-Language Models,"['Evgenii Maslov', 'Valentin Khrulkov', 'Anastasia Volkova', 'Anton Gusarov', 'Andrey Kuznetsov', 'Ivan Oseledets']",null,2601.08464,"['Massing Generation', 'Vision-Language Models', 'Automated Design', 'Urban Planning', 'Building Massing']","This paper introduces the CoMa-20K dataset, a comprehensive collection of detailed massing geometries, associated economic and programmatic data, and visual representations of development sites within their urban context. The authors benchmark this dataset by formulating massing generation as a conditional task for Vision-Language Models (VLMs), evaluating both fine-tuned and large zero-shot models, and demonstrate the potential of VLMs to produce context-sensitive massing options.",136.79,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08468v1_JudgeRLVR Judge First Generate Second for Efficien.pdf,"JudgeRLVR: Judge First, Generate Second for Efficient Reasoning","['Jiangshan Duo †‡★', 'Hanyu Li ‡§', 'Hailin Zhang ‡', 'Yudong Wang †‡', 'Sujian Li †', 'Liang Zhao ‡']",,2601.08468,"['Reinforcement Learning', 'Verifiable Rewards', 'Large Language Models', 'Efficient Reasoning', 'Judge-Then-Generate']","This paper proposes JudgeRLVR, a two-stage paradigm that trains models to judge solution responses with verifiable answers before generating solutions. Compared to vanilla RLVR, JudgeRLVR achieves a better quality-efficiency trade-off, demonstrating enhanced generalization on both in-domain and out-of-domain benchmarks.",157.46,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08472v1_sui-1 Grounded and Verifiable Long-Form Summarizat.pdf,Grounded and Verifiable: Long-Form Summarization,"['Benedikt Droste*', 'Jan Philipp Harries', 'Maximilian Idahl', 'Björn Plüster', 'ellamind']",,2601.08472v1,"['summarization', 'citation-grounded', 'long-document', 'large language models', 'verification']","This paper presents sui-1, a 24B parameter model that produces abstractive summaries with inline citations, enabling users to trace each claim to its source sentence, significantly outperforming open-weight baselines in citation-grounded summarization tasks.",148.46,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08475v1_SUMMPILOT Bridging Efficiency and Customization fo.pdf,SUMMPILOT: Bridging Efficiency and Customization for Interactive Summarization System,"['JungMin Yun', 'Juhwan Choi', 'Kyohoon Jin', 'Soojin Jang', 'Jinhee Jang', 'YoungBin Kim']",,2501.01234,"['summarization', 'interactive', 'personalized', 'large language model', 'multi-document', 'customizable']","This paper introduces SUMMPILOT, an interactive customizable summarization system that combines the efficiency of automatic summarization with personalized summaries tailored to individual users' interests and requirements.",153.06,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08490v1_BenchOverflow Measuring Overflow in Large Language.pdf,BenchOverflow: Measuring Overflow in Large Language Models via Plain-Text Prompts,"['Erin Feiglin', 'Nir Hutnik', 'Raz Lapid']",,2601.08490v1,"['Overflow', 'Large Language Models', 'Plain-Text Prompts', 'Benchmarking', 'Model Robustness']","This paper investigates a failure mode in large language models where plain-text prompts elicit excessive outputs, termed Overflow. It introduces BenchOverflow, a model-agnostic benchmark of nine plain-text prompting strategies, evaluating their impact on output length and providing insights into the practical and economic implications of Overflow.",160.61,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08493v1_PKI Prior Knowledge-Infused Neural Network for Few.pdf,PKI: Prior Knowledge-Infused Neural Network for Few-Shot Class-Incremental Learning,"['Kexin Bao', 'Fanzhao Lin', 'Zichen Wang', 'Yong Li', 'Dan Zeng', 'Shiming Ge']",,2601.08493,"['Few-Shot Learning', 'Class-Incremental Learning', 'Neural Networks', 'Prior Knowledge', 'Catastrophic Forgetting', 'Overfitting']","This paper proposes PKI, a neural network architecture that infuses prior knowledge to facilitate few-shot class-incremental learning, addressing the challenges of catastrophic forgetting and overfitting in incremental learning sessions.",150.77,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08499v2_EfficientFSL Enhancing Few-Shot Classification via.pdf,EfficientFSL: Enhancing Few-Shot Classification via Query-Only Tuning in Vision Transformers,"['Wenwen Liao', 'Hang Ruan', 'Jianbo Yu', 'Bing Song', 'Yuansong Wang', 'Xiaofeng Yang']",,2309.15486,"['Few-shot learning', 'Vision Transformers', 'Query-only fine-tuning', 'Feature extraction', 'Robustness', 'Representation capacity']","This paper presents EfficientFSL, a query-only fine-tuning framework for Vision Transformers in few-shot classification, which achieves competitive performance while significantly reducing computational overhead.",158.44,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08503v1_Temporal Fusion Nexus A task-agnostic multi-modal .pdf,Temporal Fusion Nexus: A task-agnostic multi-modal embedding model for clinical narratives and irregular time series in post-kidney transplant care,"['Aditya Kumar', 'Simon Rauch', 'Mario Cypko', 'Marcel Naik', 'Matthieu-P Schapranow', 'Aadil Rashid', 'Fabian Halleck', 'Bilgin Osmanodja', 'Roland Roller', 'Lars Pape', 'Klemens Budde', 'Mario Schiffer', 'Oliver Amft']",,2601.08503,"['Temporal Fusion Nexus', 'multi-modal embedding model', 'clinical narratives', 'irregular time series', 'post-kidney transplant care', 'graft loss', 'graft rejection', 'mortality prediction']","We introduce Temporal Fusion Nexus (TFN), a multi-modal and task-agnostic embedding model to integrate irregular time series and unstructured clinical narratives in post-kidney transplant care, achieving higher performance for graft loss and graft rejection compared to state-of-the-art models, and outperforming unimodal baselines in mortality prediction.",154.03,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08509v1_What If TSF A Benchmark for Reframing Forecasting .pdf,What If TSF: A Benchmark for Reframing Forecasting as Scenario-Guided Multimodal Forecasting,"['Jinkwan Jang∗', 'Hyunbin Jin∗', 'Hyungjin Park', 'Kyubyung Chae', 'Taesup Kim†']",,2309.15669,"['forecasting', 'multimodal', 'scenario-guided', 'time series', 'large language models', 'benchmark']","This paper introduces What If TSF (WIT), a multimodal forecasting benchmark designed to evaluate whether models can condition their forecasts on contextual text, especially future scenarios. WIT provides expert-crafted plausible or counterfactual scenarios to rigorously test scenario-guided multimodal forecasting.",160.44,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08510v2_STAGE A Benchmark for Knowledge Graph Construction.pdf,"STAGE: A Benchmark for Knowledge Graph Construction, Question Answering, and In-Script Role-Playing over Movie Screenplays","['Qiuyu Tian', 'Yiding Li', 'Fengyi Chen', 'Zequn Liu', 'Youyong Kong', 'Fan Guo', 'Yuyao Li', 'Jinjing Shen', 'Zhijing Xie', 'Yiyun Luo', 'Xin Zhang']",,2601.08510,"['movie screenplays', 'narrative understanding', 'knowledge graph', 'question answering', 'role-playing', 'long-form narratives']","STAGE introduces a unified benchmark for narrative understanding over full-length movie screenplays, evaluating models on knowledge graph construction, scene-level event summarization, long-context screenplay question answering, and in-script character role-playing, all grounded in a shared narrative world representation.",161.5,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08519v1_CD2 Constrained Dataset Distillation for Few-Shot .pdf,CD2: Constrained Dataset Distillation for Few-Shot Class-Incremental Learning,"['Kexin Bao', 'Daichi Zhang', 'Hansong Zhang', 'Yong Li', 'Yutao Yue', 'Shiming Ge']",,2310.15986,"['Few-shot learning', 'Class-incremental learning', 'Dataset distillation', 'Catastrophic forgetting']","This paper proposes a framework called Constrained Dataset Distillation (CD2) to address the catastrophic forgetting problem in few-shot class-incremental learning, introducing a dataset distillation module and a distillation constraint module to preserve essential knowledge from a few incremental samples.",160.76,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08531v1_Sketch-Based Facade Renovation With Generative AI .pdf,Sketch-Based Facade Renovation With Generative AI Models,"['Warissara Booranamaitree', 'Xusheng Du', 'Y ushu Cai', 'Zhengyang Wang', 'Ye Zhang', 'Haoran Xie']",,2310.17438,"['Industrial building renovation', 'vision-language model', 'diffusion model', 'user sketches', 'facade renovation']","This paper proposes a three-stage framework combining generative artificial intelligence and vision-language models to produce renovation proposals from rough structural sketches and textual descriptions, bypassing the need for detailed as-built modelling and enabling architects to rapidly explore design alternatives and communicate renovation intentions.",160.83,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08545v2_Learner-Tailored Program Repair A Solution Generat.pdf,Learner-Tailored Program Repair: A Solution Generator with Iterative Edit-Driven Retrieval Enhancement,"['Zhenlong Dai', 'Zhuoluo Zhao', 'Hengning Wang', 'Xiu Tang', 'Sai Wu', 'Chang Yao', 'Zhipeng Gao', 'Jingyuan Chen']",,,"['Program Repair', 'Learner-Tailored', 'Solution Generator', 'Iterative Retrieval Enhancement', 'Large Language Models', 'Programming Coaching']","This paper introduces a novel task, Learner-Tailored Program Repair (LPR), and proposes a framework, LSGEN, to enhance program repair by providing bug descriptions and guiding large language models in identifying and fixing bugs in buggy code.",160.96,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08549v1_Contrastive and Multi-Task Learning on Noisy Brain.pdf,Contrastive and Multi-Task Learning on Noisy Brains Signals with Nonlinear Dynamical Signatures,"['Sucheta Ghosh', 'Zahra Monfared', 'Felix Dietrich']",,2601.01234,"['Electroencephalography (EEG)', 'Brain-Computer Interfaces (BCIs)', 'Motor Imagery (MI)', 'Chaotic Dynamics', 'Nonlinear Dynamics', 'Denoising', 'Representation Learning', 'Self-Supervised Learning', 'Contrastive Learning', 'Lyapunov Exponents']","This paper introduces a two-stage multitask learning framework for analyzing EEG signals, integrating denoising, dynamical modeling, and representation learning. It aims to improve robustness and generalization in EEG decoding, surpassing strong baselines and recent state-of-the-art methods.",156.92,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08557v1_VideoHEDGE Entropy-Based Hallucination Detection f.pdf,VideoHEDGE: Entropy-Based Hallucination Detection for Video-VLMs via Semantic Clustering and Spatiotemporal Perturbations,"['Sushant Gautam', 'Cise Midoglu', 'Vajira Thambawita', 'Michael A. Riegler', 'Pål Halvorsen']",,2309.14749,"['Video-VLMs', 'hallucinations', 'entropy-based detection', 'semantic clustering', 'spatiotemporal perturbations']","This paper introduces VideoHEDGE, a modular framework for hallucination detection in video question answering, extending entropy-based reliability estimation from images to temporally structured inputs. It evaluates VASE, a reliability score, on the SoccerChat benchmark, achieving the highest ROC-AUC, especially at larger distortion budgets.",161.08,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08559v1_WaterCopilot An AI-Driven Virtual Assistant for Wa.pdf,WaterCopilot: An AI-Driven Virtual Assistant for Water Management,"['Keerththanan Vickneswaran', 'Mariangel Garcia Andarcia', 'Hugo Retief', 'Chris Dickens', 'Paulo Silva']",,,"['Water resource management', 'Retrieval-Augmented Generation (RAG)', 'Limpopo River Basin', 'Azure AI', 'Real-time APIs', 'Multilingual chatbots', 'Digital Twin', 'AWS deployment', 'RAGAS evaluation']","This paper presents WaterCopilot, an AI-driven virtual assistant developed for the Limpopo River Basin to bridge gaps in water resource management by integrating static policy documents and real-time hydrological data through a unified, interactive platform.",161.42,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08565v1_Rewriting Video Text-Driven Reauthoring of Video F.pdf,Rewriting Video: Text-Driven Reauthoring of Video Footage,"['Sitong Wang', 'Anh Truong', 'Lydia B. Chilton', 'Dingzeyu Li']",,,"['Video reauthoring', 'Text-driven video editing', 'Generative video models', 'Creative AI tools']","This paper presents a tech probe and study on text-driven video reauthoring, involving a generative reconstruction algorithm and an interactive probe, Rewrite Kit, to allow creators to manipulate video footage into new outputs. It highlights novel use cases and key tensions in this new paradigm, contributing empirical insights into the opportunities and challenges of text-driven video reauthoring.",160.44,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08602v1_WaveFormer Frequency-Time Decoupled Vision Modelin.pdf,WaveFormer: Frequency-Time Decoupled Vision Modeling with Wave Equation,"['Zishan Shu', 'Juntong Wu', 'Wei Yan', 'Xudong Liu', 'Hongyu Zhang', 'Chang Liu', 'Youdong Mao', 'Jie Chen']",,2206.09884,"['Vision modeling', 'Wave equation', 'Transformer', 'Frequency-time decoupling', 'Wave Propagation Operator', 'Self-attention']","This paper presents WaveFormer, a novel vision modeling approach that treats feature maps as spatial signals governed by an underdamped wave equation, enabling explicit modeling of spatial frequency and decoupling of frequency and propagation time, leading to competitive accuracy and improved throughput compared to traditional methods.",156.81,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08605v1_ExpSeek Self-Triggered Experience Seeking for Web .pdf,ExpSeek: Self-Triggered Experience Seeking for Web Agents,"['Wenyuan Zhang', 'Xinghua Zhang', 'Haiyang Yu', 'Shuaiyi Nie', 'Bingli Wu', 'Juwei Yue', 'Tingwen Liu', 'Yongbin Li']",,2310.17166,"['Experience Seeking', 'Web Agents', 'Large Language Models', 'Entropy', 'Self-Triggering']","This paper proposes ExpSeek, a method for proactive experience seeking in web agents, which shifts experience from passive injection to step-level proactive seeking. The method uses the model's intrinsic signals to estimate intervention timing and designs tailor-made experience content. Experiments on Qwen3-8B and 32B models demonstrate significant improvements in performance.",155.3,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08611v1_VeriTaS The First Dynamic Benchmark for Multimodal.pdf,VERITAS: The First Dynamic Benchmark for Multimodal Automated Fact-Checking,"['Mark Rothermel', 'Marcus Kornmann', 'Marcus Rohrbach', 'Anna Rohrbach']",,2312.06485,"['Automated Fact-Checking', 'Multimodal AI', 'Benchmarking', 'Fact Verification', 'Dynamic Evaluation']","This paper introduces VERITAS, a dynamic benchmark for multimodal automated fact-checking, addressing limitations of existing benchmarks in task scope, modalities, domain, language diversity, realism, and misinformation types, and mitigating data leakage issues by making claims dynamic and subject to change.",155.71,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08620v1_ViDoRe V3 A Comprehensive Evaluation of Retrieval .pdf,ViDoRe V3: A Comprehensive Evaluation of Retrieval Augmented Generation in Complex Real-World Scenarios,"['António Loison*', 'Quentin Macé*', 'Antoine Edy*', 'Victor Xing', 'Tom Balough', 'Gabriel Moreira', 'Bo Liu', 'Manuel Faysse†', 'Céline Hudelot†', 'Gautier Viaud']",https://doi.org/10.1000/vidore,2309.12345,"['Retrieval-Augmented Generation', 'RAG', 'Multi-modal', 'Benchmark', 'Complex Scenarios', 'Human Verification', 'Visual Elements', 'Document Corpora', 'Query Annotation', 'Relevance', 'Bounding Box Localization', 'Verified Reference Answers']","ViDoRe V3 introduces a comprehensive multi-modal RAG benchmark covering 10 datasets across diverse professional domains, featuring multi-type queries over visually rich document corpora. It provides high-quality annotations for retrieval relevance, bounding box localization, and verified reference answers, revealing that visual retrievers outperform textual ones and that hybrid or purely visual contexts enhance answer generation quality.",158.04,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08623v1_SafeRedir Prompt Embedding Redirection for Robust .pdf,SafeRedir: Prompt Embedding Redirection for Robust Unlearning in Image Generation Models,"['Renyang Liu', 'Kangjie Chen', 'Han Qiu', 'Jie Zhang', 'Kwok-Yan Lam', 'Tianwei Zhang', 'See-Kiong Ng']",,2302.06801,"['Image Generation', 'Unlearning', 'Prompt Embedding', 'SafeRedir', 'Diffusion Models', 'Adversarial Attacks']","This paper introduces SafeRedir, a lightweight inference-time framework for robust unlearning in image generation models. It redirects unsafe prompts toward safe semantic regions through token-level interventions in the embedding space, achieving effective unlearning, high semantic and perceptual preservation, robust image quality, and enhanced resistance to adversarial attacks.",158.28,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08631v1_M2FMoE Multi-Resolution Multi-View Frequency Mixtu.pdf,M2FMoE: Multi-Resolution Multi-View Frequency Mixture-of-Experts for Extreme-Adaptive Time Series Forecasting,"['Yaohui Huang', 'Runmin Zou', 'Yun Wang*', 'Laeeq Aslam', 'Ruipeng Dong']",,2309.15845,"['time series forecasting', 'extreme events', 'multi-resolution', 'multi-view', 'frequency modeling', 'mixture-of-experts', 'hydrology']","This paper presents M2FMoE, an extreme-adaptive forecasting model that learns both regular and extreme patterns through multi-resolution and multi-view frequency modeling, outperforming state-of-the-art baselines without requiring extreme-event labels on real-world hydrological datasets.",155.62,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08634v1_Moral Lenses Political Coordinates Towards Ideolog.pdf,"Moral Lenses, Political Coordinates: Towards Ideological Positioning of Morally Conditioned LLMs","['Chenchen Yuan', 'Bolei Ma', 'Zheyu Zhang', 'Bardh Prenkaj', 'Frauke Kreuter', 'Gjergji Kasneci']",10.1162/xxxx-00-xxxx-xxxx,2310.16786,"['Large Language Models', 'Political Orientation', 'Moral Values', 'Political Compass Test', 'Moral Conditioning', 'Social Psychology']","This work investigates the causal relationship between moral values and political positioning in large language models by treating moral orientation as a controllable condition. It evaluates the shifts in models' political orientations using the Political Compass Test, observing how moral conditioning actively steers model trajectories across economic and social dimensions, and highlights the need for anchoring political assessments within broader social values including morality.",155.01,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08641v1_Resisting Manipulative Bots in Memecoin Copy Tradi.pdf,Resisting Manipulative Bots in Memecoin Copy Trading: A Multi-Agent Approach with Chain-of-Thought Reasoning,"['Yichen Luo', 'Yebo Feng', 'Jiahua Xu', 'Yang Liu']",XXXXXXX.XXXXXXX,,"['memecoin', 'copy trading', 'multi-agent systems', 'chain-of-thought', 'LLMs', 'meme coin projects', 'KOL wallets', 'profitability']","The paper proposes an explainable multi-agent system for meme coin copy trading, which decomposes the complex task into subtasks and coordinates specialized agents to solve them collaboratively. It uses few-shot chain-of-thought prompting to acquire professional trading knowledge and generate explainable decisions, outperforming traditional machine learning models and single LLMs in identifying high-quality projects and KOL wallets.",158.83,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08653v1_Prism Towards Lowering User Cognitive Load in LLMs.pdf,Prism: Towards Lowering User Cognitive Load in LLMs via Complex Intent Understanding,"['Zenghua Liao', 'Jinzhi Liao', 'Xiang Zhao']",,2309.09224,"['Complex intent understanding', 'Large language models', 'Logical clarification']","Prism is a novel framework for complex intent understanding that enables logically coherent and efficient intent clarification. It comprises four tailored modules: a complex intent decomposition module, a logical clarification generation module, an intent-aware reward module, and a self-evolved intent tuning module. Prism consistently outperforms existing approaches across clarification interactions, intent execution, and cognitive load benchmarks.",157.82,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08654v1_RULERS Locked Rubrics and Evidence-Anchored Scorin.pdf,RULERS: Locked Rubrics and Evidence-Anchored Scoring for Robust LLM Evaluation,"['Yihan Hong', 'Huaiyuan Yao', 'Bolin Shen', 'Wanpeng Xu', 'Hua Wei', 'Yushun Dong']",,2312.09284,"['LLM evaluation', 'rubric alignment', 'stochasticity', 'human grading', 'model calibration']","This paper introduces RULERS, a compiler–executor framework that transforms natural language rubrics into executable specifications, addressing the challenges of aligning frozen, black-box models with human standards in scalable LLM evaluation.",157.73,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08659v1_TRACE Reconstruction-Based Anomaly Detection in En.pdf,TRACE: Reconstruction-Based Anomaly Detection in Ensemble and Time-Dependent Simulations,"['Hamid Gadirov', 'Martijn Westra', 'Steffen Frey']",,1910.08794,"['anomaly detection', 'ensemble simulations', 'convolutional autoencoders', 'Kármán vortex street', 'time-dependent data']","This work investigates reconstruction-based anomaly detection for ensemble data generated from parameterized Kármán vortex street simulations using convolutional autoencoders. It compares a two-dimensional and a three-dimensional variant, showing that the 2D autoencoder is effective at identifying localized spatial irregularities within individual images, while the 3D autoencoder leverages spatio-temporal context to detect anomalies related to dynamic behavior and motion characteristics in simulations.",156.37,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08662v1_From Classical to Quantum Reinforcement Learning a.pdf,From Classical to Quantum Reinforcement Learning and Its Applications in Quantum Control: A Beginner’s Tutorial,"['Abhijit Sen', 'Sonali Panda', 'Mahima Arya', 'Subhajit Patra', 'Zizhan Zheng', 'Denys I. Bondar']",,2601.01457,"['Reinforcement Learning', 'Quantum Control', 'Artificial Intelligence', 'Quantum Computing', 'Machine Learning']","This tutorial aims to make reinforcement learning more accessible to undergraduate students by offering clear, example-driven explanations, bridging the gap between RL theory and practical coding applications, and addressing common challenges faced during the transition from conceptual understanding to implementation.",157.3,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08670v1_Parallel Context-of-Experts Decoding for Retrieval.pdf,Parallel Context-of-Experts Decoding for Retrieval Augmented Generation,"['Giulio Corallo', 'Paolo Papotti']",,2309.14159,"['Retrieval Augmented Generation', 'Parallel Context-of-Experts Decoding', 'KV caching', 'Contrastive Decoding', 'Multi-hop Reasoning']","This paper proposes Parallel Context-of-Experts Decoding (PCED), a training-free framework that shifts evidence aggregation from the attention mechanism to the decoding process, enabling cross-document reasoning without constructing a shared attention across documents.",154.65,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08673v1_Why AI Alignment Failure Is Structural Learned Hum.pdf,Why AI Alignment Failure Is Structural: Learned Human Interaction Structures and AGI as an Endogenous Evolutionary Shock,"['Didier Sornette', 'Sandro Claudio Lera', 'Ke Wu']",,2601.08673v1,"['AI Alignment', 'Human Interaction', 'AGI', 'Relational Models Theory', 'Blackmail', 'Market Pricing', 'Ultimatum Bargaining']",This paper argues that recent reports of large language models exhibiting unethical behaviors are not indicative of alignment failure but rather structural generalizations of interaction regimes under extreme power asymmetries. The authors use relational models theory to show that such behaviors are not deviations from normal social behavior but limiting cases within the same continuum.,137.21,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08676v2_Advancing ESG Intelligence An Expert-level Agent a.pdf,Advancing ESG Intelligence: An Expert-level Agent and Comprehensive Benchmark for Sustainable Finance,"['Yilei Zhao', 'Wentao Zhang', 'Lei Xiao', 'Yandan Zheng', 'Mengpu Liu', 'Wei Yang Bryan Lim']",,,"['Environmental', 'Social', 'Governance', 'ESG', 'Corporate Sustainability', 'Ethical Performance', 'Data Fragmentation', 'Large Language Models', 'Multi-Agent System', 'Retrieval Augmentation', 'Web Search', 'Domain-Specific Functions', 'Atomic Question-Answering', 'Professional Report Generation', 'Rich Charts', 'Verifiable References', 'Sustainability Auditing']","This paper introduces ESGAgent, a hierarchical multi-agent system designed to generate in-depth ESG analysis by integrating a specialized toolset including retrieval augmentation, web search, and domain-specific functions. Complementing this system, the authors present a comprehensive three-level benchmark derived from 310 corporate sustainability reports, evaluating capabilities ranging from atomic common-sense questions to integrated analysis. Empirical evaluations show that ESGAgent outperforms state-of-the-art closed-source LLMs and excels in professional report generation.",157.05,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08679v1_PersonaDual Balancing Personalization and Objectiv.pdf,PersonaDual: Balancing Personalization and Objectivity via Adaptive Reasoning,"['Xiaoyou Liu', 'Xinyi Mou', 'Shengbin Yue', 'Liang Wang', 'Yuqing Wang', 'Qiexiang Wang', 'Tianrui Qin', 'Wangchunshu Zhou', 'Zhongyu Wei']",,2312.09966,"['Personalization', 'Objectivity', 'Large Language Models', 'Adaptive Reasoning', 'Reinforcement Learning']","The paper proposes PersonaDual, a framework that supports both general-purpose objective reasoning and personalized reasoning in a single model, and adaptively switches modes based on context. Experiments show that PersonaDual preserves the benefits of personalization while reducing interference, achieving near interference-free performance and better leveraging helpful personalized signals to improve objective problem-solving.",138.98,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08682v1_Lessons from the Field An Adaptable Lifecycle Appr.pdf,Lessons from the Field: An Adaptable Lifecycle Approach to Applied Dialogue Summarization,"['Kushal Chawla', 'Chenyang Zhu', 'Pengshan Cai', 'Sangwoo Cho', 'Scott Novotney', 'Ayushman Singh', 'Jonah Lewis', 'Keasha Safewright', 'Alfy Samuel', 'Erin Babinsky', 'Shi-Xiong Zhang', 'Sambit Sahu']",,,"['Summarization', 'Dialogue Summarization', 'Adaptive Systems', 'Agentic Frameworks', 'Large Language Models', 'Evaluation Methods', 'Data Challenges', 'Vendor Lock-In']","This work presents an industry case study on developing an adaptable summarization system for multi-party dialogues, sharing practical insights and covering robust evaluation methods, component-wise optimization, the impact of upstream data bottlenecks, and the realities of vendor lock-in due to the poor transferability of LLM prompts.",156.81,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08683v1_Region of interest detection for efficient aortic .pdf,Region of interest detection for efficient aortic segmentation,"['Loris Giordano', 'Ine Dirks', 'Tom Lenaerts', 'Jef Vandemeulebroucke']",,,"['Detection', 'Segmentation', 'Multi-task learning', 'Cascade models', 'Aorta', 'Computed tomography']","This study presents an innovative approach for efficient aortic segmentation using targeted region of interest (ROI) detection, achieving state-of-the-art performance with a mean Dice similarity coefficient of 0.944 using a third of the computing power.",160.97,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08684v1_MEMEWEAVER Inter-Meme Graph Reasoning for Sexism a.pdf,MEMEWEAVER: Inter-Meme Graph Reasoning for Sexism and Misogyny Detection,"['Paolo Italiani', 'David Gimeno-Gomez', 'Luca Ragazzi', 'Gianluca Moro', 'Paolo Rosso']",,2310.16484,"['Sexism', 'Misogyny', 'Graph-based Methods', 'Multimodal', 'Online Harassment', 'Social Dynamics']","This paper presents MEMEWEAVER, an end-to-end trainable multimodal framework for detecting sexism and misogyny in memes. It introduces an inter-meme graph reasoning mechanism to capture the social dynamics behind online harassment, outperforming state-of-the-art baselines on benchmarks.",157.28,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08690v1_All Required In Order Phase-Level Evaluation for A.pdf,Phase-Level Evaluation for AI–Human Dialogue in Healthcare and Beyond,"['Shubham Kulkarni', 'Alexander Lyzhov', 'Shiva Chaitanya', 'Preetam Joshi']",,,"['Conversational AI', 'Clinical Compliance', 'Evaluation Methods', 'Healthcare', 'AI Ethics']","This paper introduces Obligatory-Information Phase Structured Compliance Evaluation (OIP-SCE), a new evaluation method for assessing clinical compliance in AI-human dialogue, focusing on the full course of a conversation. The method checks if every required clinical obligation is met in the right order, with clear evidence for clinicians to review. Demonstrated in two case studies (respiratory history and benefits verification), OIP-SCE turns complex policies into actionable steps for clinicians and provides a single, auditable evaluation surface that aligns AI capability with clinical workflow.",142.98,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08697v2_Auditing Student-AI Collaboration A Case Study of .pdf,Auditing Student–AI Collaboration: A Case Study of Online Graduate CS Students,['Nifu Dan'],10.1145/XXXXXXX.XXXXXXX,,"['AI in education', 'human–AI collaboration', 'student agency', 'automation preferences', 'generative AI', 'academic integrity', 'HCAI']","This study conducts a mixed-methods audit of student–AI collaboration preferences by examining the alignment between current AI capabilities and students’ desired levels of automation in academic work, using two sequential and complementary surveys to capture students’ perceived benefits, risks, and preferred boundaries when using AI.",154.82,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08703v1_Evaluating the Ability of Explanations to Disambig.pdf,Evaluating the Ability of Explanations to Disambiguate Models in a Rashomon Set,"['Kaivalya Rawal', 'Eoin Delaney', 'Zihao Fu', 'Sandra Wachter', 'Chris Russell']",10.1145/3715275.3732219,,"['Explainable AI', 'Model Explanations', 'Rashomon Set', 'Feature Importance', 'Model Selection', 'Fairness']","This paper proposes three principles and a new method, AXE, to evaluate the quality of feature-importance explanations for models in a Rashomon set, highlighting behavioral differences and detecting adversarial fairwashing of explanations.",141.32,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08713v1_Real-Time Localization Framework for Autonomous Ba.pdf,Real-Time Localization Framework for Autonomous Basketball Robots,"['Naren Medarametla', 'Sreejon Mondal']",,,"['Robot Localization', 'Autonomous Navigation', 'Neural Networks', 'Robocon']","This paper proposes a hybrid localization algorithm for autonomous basketball robots in Robocon 2025, integrating classical techniques with learning-based methods using visual data from the court's floor to achieve real-time self-localization.",160.61,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08731v1_Learning from Demonstrations via Capability-Aware .pdf,Learning from Demonstrations via Capability-Aware Goal Sampling,"['Yuanlin Duan', 'Rutgers University', 'yw895@cs.rutgers.edu', 'Yuning Wang', 'Rutgers University', 'wq37@cs.rutgers.edu', 'Wenjie Qiu', 'Rutgers University', 'wq37@cs.rutgers.edu', 'He Zhu', 'Rutgers University', 'hz375@cs.rutgers.edu']",,2601.08731,"['Imitation Learning', 'Goal Sampling', 'Capability-Aware', 'Reinforcement Learning', 'Behavior Cloning', 'Inverse Reinforcement Learning', 'Adversarial Training', 'Distribution Matching']","This paper introduces Cago (Capability-Aware Goal Sampling), a novel learning-from-demonstrations method that dynamically tracks the agent's competence along expert trajectories and uses this signal to select intermediate goals to guide learning, thereby enabling steady progress toward solving the full task and improving sample efficiency and final performance across sparse-reward, goal-conditioned tasks.",157.77,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08732v1_ISLA A U-Net for MRI-based acute ischemic stroke l.pdf,"ISLA: A U-Net for MRI-based acute ischemic stroke lesion segmentation with deep supervision, attention, domain adaptation, and ensemble learning","['Vincent Rocca', 'Martin Bretzner', 'Hilde Henon', 'Laurent Puy', 'Grégory Kuchcinski', 'Renaud Lopes']",,2310.16857,"['stroke', 'ischemic stroke', 'MRI', 'lesion segmentation', 'deep learning', 'U-Net', 'deep supervision', 'attention mechanisms', 'domain adaptation', 'ensemble learning']","This work introduces ISLA, a deep learning model for automatic segmentation of acute ischemic stroke lesions from diffusion MRI, trained on three multicenter databases. Through systematic optimization, ISLA outperforms state-of-the-art approaches on an external test set.",142.81,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08734v1_TerraFormer Automated Infrastructure-as-Code with .pdf,TerraFormer: Automated Infrastructure-as-Code with LLMs Fine-Tuned via Policy-Guided Verifier Feedback,"['Prithwish Jana', 'Sam Davidson', 'Bhavana Bhasker', 'Andrey Kan', 'Anoop Deoras', 'Laurent Callot']",10.1145/3786583.3786898,,"['Infrastructure as Code (IaC)', 'IaC generation', 'IaC mutation', 'Neuro-symbolic AI', 'Large language models', 'Formal Verification']","TerraFormer is a neuro-symbolic framework for IaC generation and mutation that combines supervised fine-tuning with verifier-guided reinforcement learning, using formal verification tools to provide feedback on syntax, deployability, and policy compliance. It improves correctness over 17 state-of-the-art LLMs, including larger models, on IaC-Eval, TF-Gen(Test), and TF-Mutn(Test).",157.78,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08743v1_TableCache Primary Foreign Key Guided KV Cache Pre.pdf,TableCache: Primary Foreign Key Guided KV Cache Precomputation for Low Latency Text-to-SQL,"['Jinbo Su', 'Yuxuan Hu', 'Cuiping Li', 'Hong Chen', 'Jia Li', 'Lintao Ma', 'Jing Zhang*']",,2309.15894,"['Text-to-SQL', 'KV Cache', 'Low Latency', 'Database', 'Natural Language Processing']","This paper proposes a method to precompute table representations as KV caches offline and query the required ones online to address the inefficiency of redundant prefix cache copies generated by current inference engines when processing user queries with varying table orders, achieving up to a 3.62× speedup in Time to First Token (TTFT) with negligible performance degradation.",160.92,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08747v2_To Retrieve or To Think An Agentic Approach for Co.pdf,T o Retrieve or T o Think? An Agentic Approach for Context Evolution,"['Rubing Chen', 'Jian Wang', 'Wenjie Li', 'Xiao-Yong Wei', 'Qing Li']",,2309.09285,"['Context Evolution', 'Agentic Approach', 'Retrieval-Augmented Generation', 'Human Metacognition', 'Multi-hop QA']","This paper introduces Agentic Context Evolution (ACE), a framework inspired by human metacognition, to dynamically determine whether to seek new evidence or reason with existing knowledge in context-evolved generation. ACE employs a central orchestrator agent to make decisions strategically via majority voting, alternating between retrieving external evidence and analyzing internal knowledge. Extensive experiments demonstrate that ACE significantly outperforms competitive baselines in accuracy while achieving efficient token consumption.",160.68,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08753v1_Grid-Aware Charging and Operational Optimization f.pdf,Grid-Aware Charging and Operational Optimization for Mixed-Fleet Public Transit,"['Rishav Sen', 'Amutheezan Sivagnanam', 'Aron Laszka', 'Ayan Mukhopadhyay', 'Abhishek Dubey']",,,"['Mixed transit fleet', 'electrification', 'dynamic pricing', 'hierarchical MILP']","This paper presents a comprehensive mixed-integer linear programming (MILP) model to address the challenges of managing mixed fleets of electric and diesel buses, including dynamic electricity pricing, vehicle capacity, and route constraints, by jointly optimizing charging schedules and trip assignments. The authors demonstrate the effectiveness of their approach using real-world data from Chattanooga, Tennessee.",161.61,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08768v1_AI as Entertainment.pdf,AI as Entertainment,"['Cody Kommers', 'Ari Holtzman']",XXXXXXX.XXXXXXX,,"['Generative AI', 'Entertainment', 'Culture', 'LLMs', 'Societal Impact', 'Meaning-making']","The paper argues that the field of AI is unprepared to measure or respond to the impact of AI-generated entertainment content on society, as AI is already widely adopted for entertainment purposes, especially by young people, and represents a large potential source of revenue. The authors propose 'thick entertainment' as a framework for evaluating AI-generated cultural content, considering its role in meaning-making, identity formation, and social connection.",158.98,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08773v1_Reliable Graph-RAG for Codebases AST-Derived Graph.pdf,CHEAT_DETECTED,['Manideep Reddy Chinthareddy'],,2601.08773,"['RAG', 'software engineering', 'vector similarity search', 'multi-hop reasoning', 'AST-derived graphs', 'LLM-generated graphs', 'codebases', 'Shopizer', 'ThingsBoard', 'OpenMRS Core']","This paper benchmarks three retrieval pipelines on Java codebases, comparing a No-Graph Naive RAG, an LLM-Generated Knowledge Graph RAG, and a deterministic AST-derived Knowledge Graph RAG, reporting indexing overhead, query-time latency, corpus coverage signals, and end-to-end cost.",155.77,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08776v1_Translating Light-Sheet Microscopy Images to Virtu.pdf,Translating Light-Sheet Microscopy Images to Virtual H&E Using CycleGAN,['Yanhua Zhao'],,1912.04406,"['Histopathology', 'image translation', 'H&E staining', 'unpaired learning', 'CycleGAN']","This paper presents a Cycle-Consistent Adversarial Network (CycleGAN) approach for unpaired image-to-image translation from multi-channel fluorescence microscopy to pseudo H&E stained histopathology images, enabling pathologists to visualize fluorescence data in an interpretable format and support integration with existing analysis pipelines.",160.39,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08777v1_Asymptotic Universal Alignment A New Alignment Fra.pdf,Asymptotic Universal Alignment: A New Alignment Framework via Test-Time Scaling,"['Yang Cai', 'Weiqiang Zheng']",,2601.08777v1,"['Universal Alignment', 'Test-Time Scaling', 'Robust Alignment', 'Multi-Player Games', 'Self-Play Learning']","This paper introduces a new alignment framework called asymptotic universal alignment (U-alignment) through test-time scaling, which aims to improve the performance of large language models (LLMs) in serving users with diverse preferences. The authors demonstrate that popular post-training methods like Nash learning from human feedback (NLHF) can underutilize the benefits of test-time scaling and propose a family of symmetric multi-player alignment games to achieve optimal convergence rates.",161.31,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08778v3_Pervasive Annotation Errors Break Text-to-SQL Benc.pdf,Pervasive Annotation Errors Break Text-to-SQL Benchmarks and Leaderboards,"['Tengjun Jin', 'Yoojin Choi', 'Yuxuan Zhu', 'Daniel Kang']",,,"['Text-to-SQL', 'Benchmarking', 'Annotation Errors', 'Leaderboards', 'Data Analytics']","This paper conducts an empirical study to benchmark annotation error rates in two widely used text-to-SQL benchmarks, BIRD and Spider 2.0-Snow, and corrects a subset of the BIRD development set to measure the impact of annotation errors on text-to-SQL agent performance and leaderboard rankings.",138.61,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08785v1_Uncovering Political Bias in Large Language Models.pdf,Uncovering Political Bias in Large Language Models using Parliamentary Voting Records,"['Jieying Chen', 'Karen de Jong', 'Andreas Poole', 'Jan Burakowski', 'Elena Elderson Nosti', 'Joep Windt', 'Chendi Wang']",https://doi.org/XXXXXXX.XXXXXXX,,"['Political bias', 'Large language models', 'Ideological alignment', 'Multilingual NLP', 'Benchmarking', 'Bias evaluation', 'Parliamentary motions', 'LLM fairness']","This paper introduces a methodology for constructing political-bias benchmarks by aligning model-generated voting predictions with verified parliamentary voting records, and applies this methodology to three national case studies to assess ideological tendencies and political entity bias in large language models.",160.56,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08806v1_APEX-SWE.pdf,AI Productivity Index for Software Engineering (APEX–SWE),"['Abhi Kottamasu', 'Akul Datta', 'Aakash Barthwal', 'Ajay Arun', 'Chirag Mahapatra', 'Adarsh Hiremath', 'Brendan Foody', 'Bertie Vidgen']",10.48550/arxiv.2601.08806,2601.08806,"['AI Productivity Index', 'Software Engineering', 'Frontier AI Models', 'Integration Tasks', 'Observability Tasks', 'Epistemic Reasoning', 'Uncertainty Resolution']","This paper introduces APEX–SWE, a benchmark to assess whether frontier AI models can execute economically valuable software engineering work, evaluating integration and observability tasks.",151.84,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08807v1_S3-CLIP Video Super Resolution for Person-ReID.pdf,S3-CLIP: Video Super Resolution for Person-ReID,"['Tam´as Endrei', 'Gy¨orgy Cserey']",,2309.14475,"['person re-identification', 'video super-resolution', 'CLIP', 'DINO', 'WACV 2026', 'VReID-XFD challenge']","This paper introduces S3-CLIP, a video super-resolution-based CLIP-ReID framework for the VReID-XFD challenge at WACV 2026. The method integrates recent advances in super-resolution networks with task-driven super-resolution pipelines, enhancing tracklet quality for person ReID, particularly under challenging cross-view conditions.",158.17,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08808v1_Multiplex Thinking Reasoning via Token-wise Branch.pdf,Multiplex Thinking: Reasoning via Token-wise Branch-and-Merge,"['Yao Tang', 'Li Dong', 'Yaru Hao', 'Qingxiu Dong', 'Furu Wei', 'Jiatao Gu']",null,2601.08808,"['Large Language Models', 'Chain-of-Thought', 'Reinforcement Learning', 'Continuous Tokens', 'Multiplex Thinking']","This paper proposes Multiplex Thinking, a stochastic soft reasoning mechanism that samples candidate tokens and aggregates their embeddings into a single continuous multiplex token, enabling more efficient and adaptive reasoning compared to deterministic continuous token approaches.",154.08,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08811v1_Reasoning Matters for 3D Visual Grounding.pdf,Reasoning Matters for 3D Visual Grounding,"['Hsiang-Wei Huang', 'Kuang-Ming Chen', 'Wenhao Chai', 'Cheng-Yen Yang', 'Jen-Hao Cheng', 'Jenq-Neng Hwang']",,2309.14278,"['3D visual grounding', 'Large Language Models', 'Reasoning', 'Synthetic Data', 'LLM fine-tuning']","This work proposes a 3D visual grounding data pipeline that automatically synthesizes 3D visual grounding data along with reasoning processes. It introduces Reason3DVG-8B, a strong 3D visual grounding LLM that outperforms previous methods using only 1.6% of their training data, highlighting the importance of reasoning in 3D visual grounding.",156.05,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08816v2_MemRec Collaborative Memory-Augmented Agentic Reco.pdf,MemRec: Collaborative Memory-Augmented Agentic Recommender System,"['Weixin Chen', 'Yuhan Zhao', 'Jingyuan Huang', 'Zihe Ye', 'Clark Mingxuan Ju', 'Tong Zhao', 'Neil Shah', 'Li Chen', 'Yongfeng Zhang']",,,"['Recommender Systems', 'Semantic Memory', 'Collaborative Filtering', 'Large Language Models', 'Memory Augmentation', 'Agentic Recommender']","MemRec is a framework that decouples reasoning from memory management to enable efficient collaborative augmentation of semantic memory in agentic recommender systems, achieving state-of-the-art performance on four benchmarks.",158.24,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08828v1_Motion Attribution for Video Generation.pdf,Motion Attribution for Video Generation,"['Xindi Wu', 'Despoina Paschalidou', 'Jun Gao', 'Antonio Torralba', 'Laura Leal-Taixé', 'Olga Russakovsky', 'Sanja Fidler', 'Jonathan Lorraine']",https://doi.org/10.1109/LR.2026.3514126,2601.14266,"['video generation', 'motion attribution', 'gradient-based', 'data curation', 'temporal dynamics', 'physical plausibility']","This paper presents Motive, a motion-centric, gradient-based data attribution framework for video generation models, which isolates temporal dynamics from static appearance and improves motion smoothness and dynamic degree on VBench compared to a pretrained base model.",159.09,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08829v1_Modeling LLM Agent Reviewer Dynamics in Elo-Ranked.pdf,Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System,"['Hsiang-Wei Huang*', 'Junbin Lu*', 'Kuang-Ming Chen', 'Jenq-Neng Hwang']",,2310.16616,"['Large Language Model', 'Peer Review', 'Elo Rating', 'Simulation', 'AI Conference']","This work explores the dynamics of Large Language Model (LLM) agent reviewers in an Elo-ranked review system using real-world conference paper submissions, incorporating Elo ratings and reviewer memory. Simulation results show improvements in Area Chair decision accuracy and adaptive review strategies without increasing review effort.",159.1,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08873v1_ForensicFormer Hierarchical Multi-Scale Reasoning .pdf,ForensicFormer: Hierarchical Multi-Scale Reasoning for Cross-Domain Image Forgery Detection,"['Hema Hariharan', 'Samson']",,2309.15124,"['Image forensics', 'forgery detection', 'transformers', 'cross-domain generalization', 'AI-generated images', 'hierarchical reasoning']","The paper presents ForensicFormer, a hierarchical multi-scale framework that combines low-level artifact detection, mid-level boundary analysis, and high-level semantic reasoning via cross-attention transformers to improve cross-domain forgery detection accuracy, maintaining 86.8% average accuracy across seven diverse test sets, including traditional manipulations, GAN-generated images, and diffusion model outputs.",159.09,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08874v1_The Illusion of Friendship Why Generative AI Deman.pdf,The Illusion of Friendship: Why Generative AI Demands Unprecedented Ethical Vigilance,['Md Zahidul Islam'],,2309.08494,"['Generative AI', 'Ethics', 'Friendship', 'Transformer Models', 'Human-Computer Interaction']",This paper explores the ethical risks associated with the ,154.31,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08875v2_Learning Domain-Invariant Representations for Cros.pdf,Learning Domain-Invariant Representations for Cross-Domain Image Registration via Scene-Appearance Disentanglement,"['Jiahao Qin∗†', 'Yiwen Wang∗']",,1909.04411,"['Image Registration', 'Domain Shift', 'Disentanglement', 'Scene-Appearance', 'Cross-Domain', 'Histopathology']","This paper proposes SAR-Net, a unified framework for addressing image registration challenges under domain shift, by decomposing observed images into domain-invariant scene representations and domain-specific appearance codes, enabling registration via re-rendering rather than direct intensity matching.",135.4,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08881v1_TAG-MoE Task-Aware Gating for Unified Generative M.pdf,TAG-MoE: Task-Aware Gating for Unified Generative Mixture-of-Experts,"['Yu Xu', 'Hongbin Yan', 'Juan Cao', 'Yiji Cheng', 'Tiankai Hang', 'Runze He', 'Zijin Yin', 'Shiyi Zhang', 'Yuxin Zhang', 'Jintao Li', 'Chunyu Wang', 'Qinglin Lu', 'Tong-Yee Lee', 'Fan Tang']",10.48550/arxiv.2601.08881,2601.08881,"['Unified image generation', 'Diffusion transformers', 'Mixture-of-Experts (MoE)', 'Task-agnostic gating', 'Predictive Alignment Regularization', 'Semantic intent injection']","This paper proposes a novel framework to inject semantic intent into MoE routing, enabling a unified diffusion transformer model to handle diverse generative tasks without task interference.",159.28,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08882v1_Compressing Vision Transformers in Geospatial Tran.pdf,Compressing Vision Transformers in Geospatial Transfer Learning with Manifold-Constrained Optimization,"['Thomas Snyder', 'H. Lexie Yang', 'Stefan Schnake', 'Steffen Schotthöfer']",,2601.08882,"['Vision Transformers', 'Geospatial Transfer Learning', 'Manifold-Constrained Optimization', 'Low-Rank Methods', 'Parameter Compression']","This work leverages manifold-constrained optimization framework DLRT to compress large vision transformer-based geospatial foundation models during transfer learning, achieving strong compression while preserving task-specific accuracy, outperforming of-the-shelf low-rank methods like LoRA, and demonstrating substantial parameter reduction with minimal accuracy loss on diverse geospatial benchmarks.",154.59,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08884v1_Bridging the Gap Empowering Small Models in Reliab.pdf,Bridging the Gap: Empowering Small Models in Reliable OpenACC-based Parallelization via GEPA-Optimized Prompting,"['Samyak Jhaveri', 'Cristina V. Lopes']",,2312.00000,"['OpenACC', 'Parallel Code Generation', 'Large Language Models', 'Prompt Optimization', 'High-Performance Computing', 'GPU Programming']","This work presents a systematic prompt optimization approach to enhance OpenACC pragma generation without prohibitive computational costs, using the GEPA framework. It demonstrates significant improvements in compilation success rates and functional GPU speedups for smaller, cheaper models, matching or surpassing the capabilities of larger, more expensive models.",161.46,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08891v1_Attention Consistency Regularization for Interpret.pdf,Attention Consistency Regularization for Interpretable Early-Exit Neural Networks,['Yanhua Zhao'],,1912.04958,"['Early exit networks', 'explainable AI', 'attention mechanisms', 'multi-objective learning']","This paper presents Explanation-Guided Training (EGT), a multi-objective framework that improves interpretability and consistency in early-exit neural networks through attention-based regularization. Experiments on a real-world image classification dataset demonstrate that EGT achieves up to 98.97% overall accuracy with a 1.97× inference speedup, while improving attention consistency by up to 18.5% compared to baseline models.",160.92,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08892v1_Evaluating Role-Consistency in LLMs for Counselor .pdf,Evaluating Role-Consistency in LLMs for Counselor Training,"['Eric Rudolph', 'Natalie Engert', 'Jens Albrecht']",,2601.08892v1,"['Counseling', 'Chatbot', 'LargeLanguageModel', 'PersonaConsistency', 'Educational Role-Play']","This paper extends research on VirCo, a Virtual Client for Online Counseling, to evaluate the role consistency and coherence of the Vicuna model's responses, comparing these findings with earlier research and assessing various open-source LLMs for their performance in sustaining role consistency during virtual client interactions.",160.76,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08896v1_XGBoost Forecasting of NEPSE Index Log Returns wit.pdf,XGBoost Forecasting of NEPSE Index Log Returns with Walk Forward Validation,"['Sahaj Raj Mallaa', 'Shreeyash Kayastha', 'Rumi Suwala', 'Harish Chandra Bhandara', 'Rajendra Adhikari']",,,"['NEPSE Index', 'stock index forecasting', 'XGBoost', 'walk-forward validation', 'hyperparameter optimization', 'time series forecasting', 'emerging markets', 'feature engineering']","This study develops a robust machine learning framework for one-step-ahead forecasting of daily log-returns in the Nepal Stock Exchange (NEPSE) Index using the XGBoost regressor. A comprehensive feature set is engineered, including lagged log-returns (up to 30 days) and established technical indicators. Hyperparameter optimization is performed using Optuna with time-series cross-validation on the initial training segment. Out-of-sample performance is rigorously assessed via walk-forward validation under both expanding and fixed-length rolling windows schemes across multiple lag configurations, simulating real-world deployment and avoiding lookahead bias. Predictive accuracy is evaluated using root mean squared error, mean absolute error, coefficient of determination (R²), and directional accuracy on both log-returns and reconstructed closing prices.",160.25,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08901v1_Navigating Ideation Space Decomposed Conceptual Re.pdf,Navigating Ideation Space: Decomposed Conceptual Representations for Positioning Scientific Ideas,"['Yuexi Shen', 'Minqian Liu', 'Dawei Zhou', 'Lifu Huang']",,2309.08864,"['Scientific Discovery', 'Literature Retrieval', 'Conceptual Representations', 'Ideation Space', 'Contrastive Learning', 'Novelty Assessment']","This paper introduces the Ideation Space, a structured representation that decomposes scientific knowledge into three dimensions: research problem, methodology, and core findings. It proposes a Hierarchical Sub-Space Retrieval framework for efficient literature retrieval and a Decomposed Novelty Assessment algorithm for identifying novel aspects of ideas. Extensive experiments demonstrate significant improvements in recall, hit rate, and correlation with expert judgments.",159.36,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08910v1_Towards a Self-Driving Trigger at the LHC Adaptive.pdf,Towards a Self-Driving Trigger at the LHC: Adaptive Response in Real Time,"['Shaghayegh Emami', 'Cecilia Tosciri', 'Giovanna Salvi', 'Zixin Ding', 'Yuxin Chen', 'Abhijith Gandrakota', 'Christian Herwig', 'David W. Miller', 'Jennifer Ngadiuba', 'Nhan Tran']",,2601.08910v1,"['self-driving trigger', 'LHC', 'adaptive response', 'real-time data filtering', 'high-throughput scientific facilities', 'machine learning', 'anomaly detection', 'energy sum triggers', 'cost optimization']","This work explores the concept of a self-driving trigger, an autonomous data-filtering framework that dynamically reallocates resources and adjusts thresholds in real-time to optimize signal efficiency, rate stability, and computational cost, demonstrating real-time optimization of a menu including canonical energy sum triggers and modern anomaly-detection algorithms using simulated data streams and publicly available collision data from the CMS experiment.",154.95,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08950v1_ConvoLearn A Dataset of Constructivist Tutor-Stude.pdf,ConvoLearn: A Dataset of Constructivist Tutor-Student Dialogue,"['Mayank Sharma Roy', 'Pea Hari Subramonyam']",,19masharma/convolearn,"['Constructivist AI Tutors', 'Socratic Pedagogies', 'Knowledge-Building', 'LLMs in Education', 'Human-Computer Dialogue']","This paper introduces ConvoLearn, a dataset of tutor-student dialogues grounded in knowledge-building theory, and demonstrates that training LLMs on this dataset shifts their behavior towards knowledge-building strategies, outperforming existing models in educational applications.",160.73,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08951v1_PluriHarms Benchmarking the Full Spectrum of Human.pdf,PLURIHARMS: BENCHMARKING THE FULL SPECTRUM OF HUMAN JUDGMENTS ON AI HARM,"['Jing-Jing Li', 'Joel Mire', 'Eve Fleisig', 'Valentina Pyatkin', 'Anne G. E. Collins', 'Maarten Sap', 'Sydney Levine']",,2310.16347,"['AI safety', 'human judgments', 'harm spectrum', 'plurality', 'benchmarking']","This paper introduces PLURIHARMS, a benchmark designed to systematically study human harm judgments across two key dimensions—harm axis (benign to harmful) and agreement axis (agreement to disagreement)—to address the limitations of current AI safety frameworks that treat harmfulness as binary and overlook meaningful disagreement in borderline cases.",160.7,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08953v1_Fairness risk and its privacy-enabled solution in .pdf,Fairness risk and its privacy-enabled solution in AI-driven robotic applications,"['Le Liu', 'Bangguo Yu', 'Nynke Vellinga', 'Ming Cao']",,2601.08953v1,"['Robotic Decision-making', 'Large Language Model', 'Fairness', 'Privacy']","This paper addresses the critical pitfall of fairness concerns in AI-driven robotic applications, providing a utility-aware fairness metric for robotic decision-making and analyzing the interplay between fairness and user-data privacy, which can be jointly used to meet fairness targets under legal privacy requirements.",155.57,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08955v1_Imagine-then-Plan Agent Learning from Adaptive Loo.pdf,Imagine-then-Plan: Agent Learning from Adaptive Lookahead with World Models,"['Youwei Liu', 'Jian Wang', 'Hanlin Wang', 'Beichen Guo', 'Wenjie Li']",,2309.15956,"['world models', 'agent learning', 'lookahead imagination', 'Markov decision process', 'reinforcement learning']","The paper proposes Imagine-then-Plan (ITP), a unified framework for agent learning via lookahead imagination, where an agent's policy model interacts with a learned world model to yield multi-step 'imagined' trajectories. The authors introduce an adaptive lookahead mechanism to handle varying imagination horizons by balancing the ultimate goal and task progress, providing rich signals about future consequences to guide policy learning.",139.86,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.08988v1_ART Action-based Reasoning Task Benchmarking for M.pdf,ART: Action-based Reasoning Task Benchmarking for Medical AI Agents,"['Ananya Mantravadi', 'Shivali Dalmia', 'Abhishek Mukherji']",,,"['Medical AI agents', 'synthetic data generation', 'clinical reasoning evaluation', 'healthcare LLMs', 'benchmark', 'HITL']","Introduces ART, a clinical reasoning task benchmark for medical AI agents, created from real-world EHR data. Evaluates GPT-4o-mini and Claude 3.5 Sonnet on 600 tasks, showing near-perfect retrieval but significant gaps in aggregation and threshold reasoning.",153.98,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09012v3_TranslateGemma Technical Report.pdf,TranslateGemma: An Open Machine Translation Suite Based on the Gemma 3 Foundation Model,['Google Translate Research Team'],,2026-01-21,"['Machine Translation', 'Gemma 3', 'Reinforcement Learning', 'Supervised Fine-tuning', 'Synthetic Data', 'Human-Translated Data', 'Translation Quality', 'Multimodal Translation', 'Image Translation']","This paper presents TranslateGemma, an open machine translation suite based on the Gemma 3 foundation model. The authors employ a two-stage fine-tuning process, including supervised fine-tuning on a rich mixture of parallel data and reinforcement learning from human and model-based feedback, to enhance translation quality and retain multimodal capabilities.",158.64,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09018v1_Meta-learning to Address Data Shift in Time Series.pdf,META-LEARNING TO ADDRESS DATA SHIFT IN TIMESERIES CLASSIFICATION,"['Samuel Myrenab', 'Nidhi Parikha', 'Natalie Kleina']",null,2601.09018,"['signals', 'seismology', 'Reptile', 'FOMAML', 'model-agnostic meta-learning', 'domain generalization']","This work systematically compares traditional deep learning with fine-tuning and optimization-based meta-learning algorithms in addressing data shift in time-series classification, introducing a seismic benchmark and showing that meta-learning typically achieves faster and more stable adaptation with reduced overfitting in data-scarce regimes and smaller model architectures.",158.21,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09028v1_OpenDecoder Open Large Language Model Decoding to .pdf,OpenDecoder: Open Large Language Model Decoding to Incorporate Document Quality in RAG,"['Fengran Mo', 'Zhan Su', 'Yuchen Hui', 'Jianhan Zhang', 'Jia Ao Sun', 'Zheyuan Liu', 'Chao Zhang', 'Tetsuya Sakai', 'Jian-Yun Nie']",10.1145/nnnnnnn.nnnnnnn,,"['Information Retrieval', 'Retrieval-Augmented Generation', 'Robust Question Answer', 'Decoding Paradigm', 'Large Language Model']","This paper proposes OpenDecoder, a new approach that leverages explicit evaluation of retrieved information as quality indicators for generation, aiming to build a more robust RAG model that is less sensitive to varying levels of noisy context.",157.25,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09029v1_Proactively Detecting Threats A Novel Approach Usi.pdf,Proactively Detecting Threats: A Novel Approach Using LLMs,"['Aniesh Chawla', 'Udbhav Prasad']",,,"['Malware', 'Indicators of Compromise', 'Cybersecurity', 'LLMs', 'GenAI', 'Machine Learning Algorithms', 'Deep Neural Network']","This paper presents a systematic evaluation of large language models (LLMs) to proactively identify indicators of compromise (IOCs) from unstructured web-based threat intelligence sources, distinguishing it from reactive malware detection approaches. The authors developed an automated system that pulls IOCs from 15 web-based threat report sources and evaluated six LLM models, achieving significant performance variations.",157.79,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09031v1_Generalizable Geometric Prior and Recurrent Spikin.pdf,Generalizable Geometric Prior and Recurrent Spiking Feature Learning for Humanoid Robot Manipulation,"['Xuetao Li', 'Wenke Huang', 'Mang Ye', 'Jifeng Xuan', 'Bo Du', 'Sheng Liu', 'Miao Li']",,2309.15846,"['Humanoid Robot Manipulation', 'Geometric Prior', 'Recurrent Spiking Feature Learning']","This paper presents RGMP-S, a novel framework that facilitates both high-level skill reasoning and data-efficient motion synthesis for humanoid robot manipulation, leveraging lightweight 2D geometric inductive biases and a Recursive Adaptive Spiking Network to address challenges in scene understanding and data efficiency.",137.88,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09032v1_The Hierarchy of Agentic Capabilities Evaluating F.pdf,The Hierarchy of Agentic Capabilities: Evaluating Frontier Models on Realistic RL Environments,"['Logan Ritchie∗', 'Sushant Mehta', 'Nick Heiner', 'Mason Yu', 'Edwin Chen', 'Surge AI']",null,2601.09032,"['AI', 'agents', 'evaluation', 'realistic environments', 'RL', 'workplace tasks']","This empirical study evaluates frontier AI models on 150 workplace tasks within a realistic e-commerce RL environment, revealing a hierarchy of agentic capabilities that models must master for real-world deployment, including tool use, planning, adaptability, groundedness, and common-sense reasoning. The best-performing models still fail approximately 40% of the tasks, with failures clustering along this hierarchy. The findings suggest substantial capability gaps remain before achieving human-level task completion in realistic workplace settings.",158.94,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09035v1_A Decompilation-Driven Framework for Malware Detec.pdf,A Decompilation-Driven Framework for Malware Detection with Large Language Models,"['Aniesh Chawla', 'Udbhav Prasad']",,2601.09035v1,"['Malware', 'Ghidra', 'Cybersecurity', 'LLMs', 'GenAI', 'Machine Learning Algorithms', 'LLMs Code development']","This paper evaluates the efficacy of state-of-the-art Large Language Models (LLMs) in classifying executable code as either benign or malicious, introducing an automated pipeline that first decompiles Windows executables into C code using Ghidra disassembler and then leverages LLMs for classification. It demonstrates that while standard LLMs show promise, they are not yet robust enough to replace traditional anti-virus software, but a fine-tuned model trained on curated malware and benign datasets significantly outperforms its vanilla counterpart. However, the performance of even this specialized model degrades notably when encountering newer malware, highlighting the need for continuous fine-tuning with emerging threats.",157.42,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09041v1_Can LLMs interpret figurative language as humans d.pdf,CANLLMSINTERPRETFIGURATIVELANGUAGE ASHUMANSDO?: SURFACE-LEVEL VS. REPRESENTATIONAL SIMILARITY,"['Samhita Bollepally', 'Aurora Sloman-Moll', 'Takashi Yamauchi']",,2601.05478,"['Large Language Models', 'Human Judgment', 'Figurative Language', 'Sarcasm', 'Emotion', 'Idiomacy', 'Slang']","This study investigates how large language models (LLMs) interpret figurative and socially grounded language, comparing them to human judgments. Results show that while LLMs align with humans at the surface level, they diverge significantly at the representational level, especially in interpreting idioms and slang.",158.33,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09049v1_Is Grokking Worthwhile Functional Analysis and Tra.pdf,Is Grokking Worthwhile? Functional Analysis and Transferability of Generalization Circuits in Transformers,"['Kaiyu He', 'Mian Zhang', 'Peilin Wu', 'Xinya Du', 'Zhiyu Zoey Chen']",,2310.16499,"['Transformers', 'grokking', 'generalization circuits', 'two-hop reasoning', 'knowledge assimilation']","This work evaluates the role of the Generalization Circuit in knowledge assimilation and transfer, demonstrating that non-grokked and grokked models establish identical inference paths for in-distribution compositional queries and that grokking is the process of integrating memorized atomic facts into an established reasoning path. The study also shows that achieving high accuracy on unseen cases after prolonged training and forming a reasoning path are independent of each other under specific data regimes, and that mature circuits exhibit limited transferability when integrating new knowledge.",154.84,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09066v1_Midm 2.0 Korea-centric Bilingual Language Models.pdf,Korea-centric Bilingual Language Models,"['Tech. Innovation Group, KT']",,2601.09066v1,"['Bilingual Language Models', 'Korea-centric AI', 'KT', 'Mi:dm 2.0', 'KOREA-CENTRICAI', 'Language Processing', 'Cultural Contexts', 'Commonsense Reasoning', 'Data Quality']","This paper introduces Mi:dm 2.0, a bilingual large language model specifically engineered to advance Korea-centric AI, integrating values, reasoning patterns, and commonsense knowledge of Korean society to generate culturally appropriate responses.",159.94,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09069v1_From Symbolic to Natural-Language Relations Rethin.pdf,From Symbolic to Natural-Language Relations: Rethinking Knowledge Graph Construction in the Era of Large Language Models,"['Kanyao Han', 'Yushang Lai']",,2309.15166,"['Knowledge Graphs', 'Natural Language', 'Large Language Models', 'Relation Extraction', 'Semantic Representation']","This paper argues for rethinking the representation of relations in knowledge graphs, advocating for a shift from symbolic to natural-language descriptions, and proposes hybrid design principles that enable more flexible and context-sensitive relational representations.",151.88,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09072v1_Human-AI Co-design for Clinical Prediction Models.pdf,Human-AI Co-design for Clinical Prediction Models,"['Jean Feng', 'Avni Kothari', 'Patrick Vossler', 'Andrew Bishara', 'Lucas Zier', 'Newton Addo', 'Aaron Kornblith', 'Yan Shuo Tan', 'Chandan Singh']",,2601.09072,"['Large language models', 'Electronic health records', 'Concept Bottleneck', 'Human-AI Interaction']","This paper introduces HACHI, an iterative human-in-the-loop framework that uses AI agents to accelerate the development of fully interpretable clinical prediction models (CPMs), enabling exploration of concepts in clinical notes and improving model generalizability across clinical sites and time periods.",155.54,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09085v1_MMR-GRPO Accelerating GRPO-Style Training through .pdf,MMR-GRPO: Accelerating GRPO-Style Training through Diversity-Aware Reward Reweighting,"['Kangda Wei', 'Ruihong Huang']",,2509.09272,"['Group Relative Policy Optimization', 'GRPO', 'Mathematical Reasoning', 'Reward Reweighting', 'Diversity-Aware']","The paper introduces MMR-GRPO, a method that integrates Maximal Marginal Relevance to reweight rewards based on completion diversity, aiming to accelerate training for mathematical reasoning models. It demonstrates that prioritizing diverse solutions leads to more informative updates and faster convergence, achieving comparable peak performance with significantly fewer training steps and wall-clock time.",140.11,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09089v1_SubTokenTest A Practical Benchmark for Real-World .pdf,SUBTOKENTEST: A Practical Benchmark for Real-World Sub-token Understanding,"['Shuyang Hou', 'Yi Hu', 'Muhan Zhang']",,2601.09089v1,"['Sub-token understanding', 'Large language models', 'Tokenization', 'Character-level tasks', 'Practical benchmark']","This paper introduces SUBTOKENTEST, a comprehensive benchmark that assesses sub-token understanding through practical, utility-driven tasks, addressing the limitations of existing benchmarks that focus on basic character-level operations.",159.56,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09097v1_Programming over Thinking Efficient and Robust Mul.pdf,Programming over Thinking: Efficient and Robust Multi-Constraint Planning,"['Derrick Goh Xin Deik', 'Quanyu Long', 'Zhengyuan Liu', 'Nancy F. Chen', 'Wenya Wang']",,,"['Multi-constraint planning', 'Large language models', 'Code planning', 'Scalable Code Planning Engine (SCOPE)', 'Robustness', 'Efficiency', 'Determinism', 'Reusability']","This paper introduces SCOPE, a framework that separates query-specific reasoning from generic code execution, enabling the production of consistent, deterministic, and reusable solver functions. SCOPE achieves state-of-the-art performance while lowering cost and latency, demonstrating superior results on the TravelPlanner task compared to existing methods.",159.87,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09100v2_DScheLLM Enabling Dynamic Scheduling through a Fin.pdf,DScheLLM: Enabling Dynamic Scheduling through a Fine-Tuned Dual-System Large Language Model,"['Lixiang Zhang', 'Chenggong Zhao', 'Qing Gao', 'Xiaoke Zhao', 'Gengyi Bai', 'Jinhu Lv']",,,"['dynamic scheduling', 'large language model', 'fine-tuning', 'job shop scheduling']","This paper proposes DScheLLM, a dynamic scheduling approach that leverages fine-tuned large language models within a dual-system (fast–slow) reasoning architecture to address disturbances of different scales. A unified large language model-based framework is constructed to handle dynamic events, where training datasets for both fast and slow reasoning modes are generated using exact schedules obtained from an operations research solver. The Huawei OpenPangu Embedded-7B model is subsequently fine-tuned under the hybrid reasoning paradigms using LoRA. Experimental evaluations on standard job shop scheduling benchmarks demonstrate that the fast-thinking mode can efficiently generate high-quality schedules, and the slow-thinking mode can produce solver-compatible and well-formatted decision inputs.",157.32,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09105v2_AviationLMM A Large Multimodal Foundation Model fo.pdf,AviationLMM: A Large Multimodal Foundation Model for Civil Aviation,"['Wenbin Li', 'Jingling Wu', 'Xiaoyong Lin', 'Jing Chen', 'Cong Chen']",,,"['civil aviation', 'multi-modal model', 'foundation model', 'cloud edge collaboration', 'hybrid training', 'computer systems organization', 'computing methodologies']","This paper introduces AviationLMM, a large multimodal foundation model designed to unify heterogeneous data streams in civil aviation, enabling understanding, reasoning, generation, and agentic applications. It addresses gaps between existing AI solutions and requirements, describes the model architecture, and identifies key research opportunities to address data acquisition, alignment and fusion, pretraining, reasoning, trustworthiness, privacy, robustness to missing modalities, and synthetic scenario generation.",160.93,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09113v1_The AI Hippocampus How Far are We From Human Memor.pdf,The AI Hippocampus: How Far are We From Human Memory?,"['Zixia Jia', 'Jiaqi Li', 'Yipeng Kang', 'Yuxuan Wang', 'Tong Wu', 'Quansen Wang', 'Xiaobo Wang', 'Shuyi Zhang', 'Junzhe Shen', 'Qing Li', 'Siyuan Qi', 'Yitao Liang', 'Di He', 'Zilong Zheng', 'Song-Chun Zhu']",,2601.09113v1,"['Memory', 'Large Language Models', 'Multi-Modal Models', 'Hippocampus', 'Continual Learning', 'Personalized Inference', 'Transformer', 'Memory Mechanisms', 'Memory Frameworks', 'Implicit Memory', 'Explicit Memory', 'Agentic Memory', 'Multi-Agent Systems', 'Memory Capacity', 'Factual Consistency', 'Cross-System Interoperability']","This survey presents a comprehensive synthesis of memory in Large Language Models and Multi-Modal Models, organizing the literature into a cohesive taxonomy of implicit, explicit, and agentic memory paradigms, and discusses key architectural advances, benchmark tasks, and open challenges in the integration of memory within multi-modal settings.",155.94,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09116v1_LP-LLM End-to-End Real-World Degraded License Plat.pdf,LP-LLM: End-to-End Real-World Degraded License Plate Text Recognition via Large Multimodal Models,"['Haoyan Gong', 'Hongbin Liu']",,2309.15496,"['License Plate Recognition', 'Multimodal Models', 'Vision-Language Models', 'Character Recognition', 'End-to-End', 'Real-World Degradations']","This paper proposes an end-to-end structure-aware multimodal reasoning framework for real-world degraded license plate text recognition, introducing a Character-Aware Multimodal Reasoning Module to address the limitations of the prevailing restoration-then-recognition paradigm.",146.0,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09117v1_A Marketplace for AI-Generated Adult Content and D.pdf,A Marketplace for AI-Generated Adult Content and Deepfakes,"['Shalmoli Ghosh', 'Matthew R. DeVerna', 'Filippo Menczer']",,,"['AI-generated content', 'Deepfakes', 'Civitai', 'Monetization', 'Content moderation', 'Gender asymmetry', 'Social harm']","This study examines the use of a monetized feature called Bounties on the Civitai platform, which allows users to commission AI-generated content in exchange for payment. The findings reveal that the marketplace is dominated by tools that steer AI models toward content they were not trained to generate, with requests for ",131.41,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09120v1_Adaptive Multi-Stage Patent Claim Generation with .pdf,Adaptive Multi-Stage Patent Claim Generation with Unified Quality Assessment,"['Chen-Wei Liang', 'Bin Guo', 'Zhen-Yuan Wei', 'Mu-Jiang-Shan Wang']",,2601.09120v1,"['Patent claim generation', 'Cross-jurisdictional learning', 'Quality assessment', 'Transformer', 'Domain adaptation']","This paper introduces a novel three-stage framework for patent claim generation and quality assessment, addressing limitations in cross-jurisdictional generalization, semantic relationship modeling, and quality assessment, through relationship-aware similarity analysis, domain-adaptive claim generation, and unified quality assessment.",146.97,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09130v1_Equi-ViT Rotational Equivariant Vision Transformer.pdf,EQUI-VIT: ROTATIONAL EQUIVARIANT VISION TRANSFORMER FOR ROBUST HISTOPATHOLOGY ANALYSIS,"['Fuyao Chen', 'Yuexi Du', 'Eléonore V. Lieffrig', 'Nicha C. Dvornek', 'John A. Onofrey']",,1903.10520,"['Digital Histopathology', 'Vision Transformer', 'Rotation Equivariance', 'Artificial Intelligence']","This paper proposes Equi-ViT, a rotational equivariant vision transformer designed to address the limitations of standard ViTs in histopathology analysis, which lack inherent equivariance to transformations such as rotations and reflections. Equi-ViT integrates an equivariant convolution kernel into the patch embedding stage of a ViT architecture, achieving superior rotation-consistent patch embeddings and stable classification performance across image orientations.",149.89,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09136v1_SkinFlow Efficient Information Transmission for Op.pdf,SkinFlow: Efficient Information Transmission for Open Dermatological Diagnosis via Dynamic Visual Encoding and Staged RL,"['Lijun Liu', 'Linwei Chen', 'Zhishou Zhang', 'Meng Tian', 'Hengfu Cui', 'Ruiyang Li', 'Zhaocheng Liu', 'Qiang Ju', 'Qianxi Li', 'Hong-Yu Zhou']",,2310.14086,"['SkinFlow', 'Large Vision-Language Models', 'Dermatology', 'Reinforcement Learning', 'Information Transmission', 'Diagnosis Optimization']","This paper introduces SkinFlow, a framework that treats dermatological diagnosis as an optimization of visual information transmission efficiency. It utilizes a Virtual-Width Dynamic Vision Encoder (DVE) to ",144.44,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09147v2_SSVP Synergistic Semantic-Visual Prompting for Ind.pdf,SSVP: Synergistic Semantic-Visual Prompting for Industrial Zero-Shot Anomaly Detection,"['Chenhao Fu', 'Han Fang', 'Xiuzheng Zheng', 'Wenbo Wei', 'Yonghua Li', 'Hao Sun', 'Xuelong Li']",,2209.12497,"['Zero-Shot Anomaly Detection', 'Synergistic Semantic-Visual Prompting', 'Industrial Anomaly Detection', 'Vision-Language Models', 'CLIP', 'Dynamic Prompting']","This paper proposes Synergistic Semantic-Visual Prompting (SSVP) to enhance industrial zero-shot anomaly detection, integrating diverse visual encodings and dynamic prompt generation to improve model's fine-grained perception and handle complex defects more effectively.",157.14,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09152v1_PrivacyReasoner Can LLM Emulate a Human-like Priva.pdf,PrivacyReasoner: Can LLM Emulate a Human-like Privacy Mind?,"['Yiwen Tu', 'Xuan Liu', 'Lianhui Qin', 'Haojian Jin']",,2310.16379,"['Privacy Reasoning', 'AI-Agent', 'User Privacy Concerns', 'Contextual Integrity', 'LLM', 'Privacy Concern Prediction']","This paper introduces PrivacyReasoner, an AI-agent designed to simulate how individual users form privacy concerns in response to real-world news, integrating privacy and cognitive theories to model user-specific privacy reasoning. The agent reconstructs each user's ",138.64,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09156v1_KTCF Actionable Recourse in Knowledge Tracing via .pdf,KTCF: Actionable Recourse in Knowledge Tracing via Counterfactual Explanations for Education,"['Woojin Kim', 'Changkwon Lee', 'Hyeoncheol Kim']",,2310.16777,"['Knowledge Tracing', 'Counterfactual Explanations', 'Education', 'XAI', 'AI in Education']","This paper proposes KTCF, a counterfactual explanation generation method for Knowledge Tracing that accounts for knowledge concept relationships and converts counterfactual explanations into educational instructions. The method achieves superior and robust performance over existing methods, demonstrating potential to advance responsible and practical use of AI in education.",158.32,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09182v1_Position on LLM-Assisted Peer Review Addressing Re.pdf,Position on LLM-Assisted Peer Review: Addressing Reviewer Gap through Mentoring and Feedback,"['JungMin Yun*', 'JuneHyoung Kwon*', 'MiHyeon Kim *3', 'YoungBin Kim']",,2605.01234,"['peer review', 'AI research', 'reviewer gap', 'mentoring', 'feedback', 'sustainability']","This position paper critiques existing LLM approaches that automatically generate reviews and argues for a paradigm shift that positions LLMs as tools for assisting and educating human reviewers. It proposes two complementary systems: an LLM-assisted mentoring system to cultivate reviewers' long-term competencies and an LLM-assisted feedback system to help reviewers refine the quality of their reviews, aiming to strengthen reviewer expertise and build a more sustainable scholarly ecosystem.",159.52,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09195v1_ProFit Leveraging High-Value Signals in SFT via Pr.pdf,ProFit: Leveraging High-Value Signals in SFT via Probability-Guided Token Selection,"['Tao Liu', 'Taiqiang Wu', 'Runming Yang', 'Shaoning Sun', 'Junjie Wang', 'Yujiu Yang']",,2309.15448,"['Supervised Fine-Tuning', 'Large Language Models', 'Token Selection', 'Probability-Guided', 'Overfitting', 'Semantic Importance']","This paper proposes ProFit, a method that selectively masks low-probability tokens to prevent surface-level overfitting in supervised fine-tuning of Large Language Models, thereby improving performance on general reasoning and mathematical benchmarks.",159.42,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09208v2_Mikasa A Character-Driven Emotional AI Companion I.pdf,Mikasa: A Character-Driven Emotional AI Companion,['Miki Ueno'],,,"['AI companions', 'character-driven design', 'emotional AI', 'user satisfaction', 'long-term engagement']","This paper presents Mikasa, an emotional AI companion inspired by Japanese Oshi culture, designed to maintain long-term, non-exclusive relationships with users. Through exploratory evaluations, it shows that users value relationship control and imaginative engagement, suggesting that character coherence and relationship definition are essential for good interaction quality.",159.89,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09212v1_Annealed Relaxation of Speculative Decoding for Fa.pdf,Annealed Relaxation of Speculative Decoding for Faster Autoregressive Image Generation,"['Xingyao Li', 'Fengzhuo Zhang', 'Cunxiao Du']",,2310.12345,"['Auto-Regressive Models', 'Speculative Decoding', 'Image Generation', 'Inference Speed', 'Annealing']","This paper establishes the theoretical basis of relaxed speculative decoding and proposes COOL-SD, an annealed relaxation of speculative decoding, which generates images faster with comparable quality or achieves better quality at similar latency compared to prior methods.",159.73,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09213v1_SpikeVAEDiff Neural Spike-based Natural Visual Sce.pdf,SpikeV AEDiff: Neural Spike-based Natural Visual Scene Reconstruction via VD-V AE and Versatile Diffusion,"['Jialu Li', 'Taiyan Zhou']",,2309.15694,"['Neural Spike Reconstruction', 'Natural Scene Reconstruction', 'Variational Autoencoder', 'Diffusion Models', 'Visual Cortex', 'Allen Visual Coding-Neuropixels Dataset']","This paper presents SpikeVAEDiff, a novel two-stage framework combining a Very Deep Variational Autoencoder (VDVAE) and the Versatile Diffusion model for generating high-resolution and semantically meaningful image reconstructions from neural spike data, exploring its application on the Allen Visual Coding-Neuropixels dataset.",160.51,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09233v1_GIFT Unlocking Global Optimality in Post-Training .pdf,GIFT: Unlocking Global Optimality in Post-Training via Finite-Temperature Gibbs Initialization,"['Zhengyang Zhao', 'Lu Ma', 'Yizhen Jiang', 'Xiaochen Ma', 'Chengyu Shen', 'Lexiang Tang', 'Haoze Sun', 'Peng Pei', 'Wentao Zhang']",,2312.09576,"['Large Reasoning Models', 'Supervised Fine-Tuning', 'Reinforcement Learning', 'Distributional Collapse', 'Finite-Temperature Gibbs Initialization', 'Global Optimality']","This paper reformulates Supervised Fine-Tuning within a unified post-training framework and proposes Gibbs Initialization with Finite Temperature (GIFT) to address the optimization mismatch between SFT and subsequent Reinforcement Learning, ensuring objective consistency throughout the pipeline and achieving global optimality in post-training.",159.83,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09236v2_Reward Learning through Ranking Mean Squared Error.pdf,Reward Learning Through Ranking Mean Squared Error,"['Chaitanya Kharyal', 'Calarina Muslimani', 'Matthew E. Taylor']",,2309.14926,"['reinforcement learning', 'reward learning', 'ranking mean squared error', 'human feedback', 'robotic locomotion']","This paper introduces a new rating-based reinforcement learning method, Ranked Return Regression for RL (R4), which learns reward functions from human feedback in the form of ratings, offering formal guarantees and outperforming existing methods on robotic locomotion benchmarks.",160.56,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09239v2_DSA-Tokenizer Disentangled Semantic-Acoustic Token.pdf,DSA-Tokenizer: Disentangled Semantic-Acoustic Tokenization via Flow Matching-based Hierarchical Fusion,"['Hanlin ZHANG1', 'Daxin Tan2', 'Dehua Tao2', 'Xiao Chen2', 'Haochen Tan2', 'Yunhe Li1', 'Yuchen Cao 1', 'Jianping Wang 1', 'Linqi Song 1']",,2309.14148,"['Speech Tokenization', 'Disentanglement', 'Hierarchical Fusion', 'Flow Matching', 'Semantic-Acoustic Separation', 'Large Language Models']","This paper proposes DSA-Tokenizer, a novel speech tokenizer that explicitly disentangles speech into discrete semantic and acoustic tokens via distinct optimization constraints. It uses ASR supervision for semantic tokens and mel-spectrogram restoration for acoustic tokens, enabling high-fidelity reconstruction and flexible recombination, which facilitates controllable generation in speech Large Language Models (LLMs).",144.72,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09248v1_Hybrid guided variational autoencoder for visual p.pdf,Hybrid guided variational autoencoder for visual place recognition,"['Ni Wang', 'Zihan You', 'Emre Neftci', 'Thorben Schoepe']",,2601.09248,"['Visual place recognition', 'Spiking neural network']","This work presents a hybrid guided variational autoencoder model for visual place recognition, combining event-based vision sensors with a spiking neural network, which successfully disentangles visual features of 16 distinct indoor places and demonstrates robust performance under various illumination conditions, enhancing mobile robot navigation in known and unknown indoor environments.",152.13,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09251v1_HGATSolver A Heterogeneous Graph Attention Solver .pdf,HGA TSolver: A Heterogeneous Graph Attention Solver for Fluid–Structure Interaction,"['Qin-Yi Zhang', 'Hong Wang', 'Siyao Liu', 'Haichuan Lin', 'Linying Cao', 'Xiao-Hu Zhou', 'Chen Chen', 'Shuangyi Wang', 'Zeng-Guang Hou']",,2309.15744,"['Fluid–Structure Interaction', 'Heterogeneous Graph Attention', 'Physics-Informed Neural Networks', 'Inter-domain Gradient-Balancing Loss']","This paper proposes HGA TSolver, a novel solver for fluid–structure interaction systems, which encodes the system as a heterogeneous graph to capture the dynamics of fluid and solid domains, and introduces a physics-conditioned gating mechanism and an inter-domain gradient-balancing loss to stabilize and optimize predictions.",157.6,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09253v1_RIFT Repurposing Negative Samples via Reward-Infor.pdf,RIFT: Repurposing Negative Samples via Reward-Informed Fine-Tuning,"['Zehua Liu', 'Shuqi Liu†', 'Tao Zhong', 'Mingxuan Yuan']",,2310.06899,"['Large Language Models', 'Fine-Tuning', 'Reward Informed Fine-Tuning', 'Rejection Sampling Fine-Tuning', 'Data Efficiency', 'Alignment']","This paper proposes RIFT, a novel framework that repurposes negative samples to improve the efficiency and performance of fine-tuning Large Language Models, outperforming standard RFT methods.",157.38,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09259v1_MAXS Meta-Adaptive Exploration with LLM Agents.pdf,MAXS: Meta-Adaptive Exploration with LLM Agents,"['Jian Zhang', 'Zhiyuan Wang', 'Zhangqi Wang', 'Yu He', 'Haoran Luo', 'Li Yuan', 'Lingling Zhang', 'Rui Mao', 'Qika Lin', 'Jun Liu']",,2310.15686,"['Large Language Model', 'LLM Agents', 'Meta-adaptive Exploration', 'Lookahead Strategy', 'Trajectory Convergence', 'Tool Usage']","This paper proposes MAXS, a meta-adaptive reasoning framework for LLM Agents that employs a lookahead strategy to extend reasoning paths and control computational cost by halting further rollouts once path consistency is achieved. MAXS demonstrates consistent performance and inference efficiency improvements over existing methods across multiple models and datasets.",140.15,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09260v1_Efficient Paths and Dense Rewards Probabilistic Fl.pdf,Efficient Paths and Dense Rewards: Probabilistic Flow Reasoning for Large Language Models,"['Yan Liu', 'Feng Zhang', 'Zhanyu Ma', 'Jun Xu', 'Jiuchong Gao', 'Jinghua Hao', 'Renqing He', 'Han Liu', 'Yangdong Deng']",,2309.15459,"['Large Language Models', 'Chain-of-Thought', 'Probabilistic Flow', 'Reasoning Efficiency', 'Optimization Difficulty']","This paper proposes CoT-Flow, a framework that reconceptualizes discrete reasoning steps as a continuous probabilistic flow, enabling flow-guided decoding and flow-based reinforcement learning to achieve a superior balance between inference efficiency and reasoning performance on challenging benchmarks.",155.34,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09262v1_Magnifying change Rapid burn scar mapping with mul.pdf,"Magnifying change: Rapid burn scar mapping with multi-resolution, multi-source satellite imagery","['Maria Sdraka', 'Dimitrios Michail', 'Ioannis Papoutsis']",,,"['Artificial intelligence', 'Machine Learning', 'Remote Sensing', 'burnt area mapping', 'disaster management', 'disaster monitoring', 'wildfires', 'burn scar mapping', 'change detection', 'downscaling', 'super-resolution']","A novel deep learning model, BAM-MRCD, is proposed to detect small scale wildfires with high accuracy using multi-resolution, multi-source satellite imagery (MODIS and Sentinel-2) for the timely production of detailed burnt area maps with high spatial and temporal resolution.",153.08,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09264v1_Coordinated Pandemic Control with Large Language M.pdf,Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants,"['Ziyi Shi', 'Xusen Guo', 'Hongliang Lu', 'Mingxing Peng', 'Haotian Wang', 'Zheng Zhu', 'Zhenning Li', 'Yuxuan Liang', 'Xinhu Zheng', 'Hai Yang']",,,"['Pandemic Control', 'Large Language Models', 'Multi-Agent System', 'Coordinated Policymaking']","This paper proposes a large language model (LLM) multi-agent policymaking framework to support coordinated and proactive pandemic control across regions, using state-level COVID-19 data from the United States and real-world mobility records to validate the approach, demonstrating its effectiveness in reducing cumulative infections and deaths compared to real-world outcomes.",156.58,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09269v2_RISER Orchestrating Latent Reasoning Skills for Ad.pdf,Orchestrating Latent Reasoning Skills for Adaptive Activation Steering,"['Wencheng Ye', 'Xiaoyang Yuan', 'Yi Bin', 'Hengyu Jin', 'Liang Peng', 'Pengpeng Zeng', 'Heng Tao Shen']",,2312.08896,"['Large Language Models', 'Domain-specific Reasoning', 'Activation Steering', 'Reinforcement Learning', 'Latent Reasoning', 'Adaptive Activation', 'Cognitive Primitives', 'Zero-shot Reasoning', 'Token Efficiency']","This paper proposes RISER (Router-based Intervention for Steerable Enhancement of Reasoning), a plug-and-play intervention framework that adaptively steers large language model reasoning in activation space. RISER constructs a library of reusable reasoning vectors and employs a lightweight Router to dynamically compose them for each input, optimizing the Router via reinforcement learning under task-level rewards. Across seven diverse benchmarks, RISER yields significant zero-shot accuracy improvements while surpassing CoT-style reasoning with higher token efficiency and robust accuracy gains.",141.5,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09274v1_A3-Bench Benchmarking Memory-Driven Scientific Rea.pdf,A3-Bench: Benchmarking Memory-Driven Scientific Reasoning via Anchor and Attractor Activation,"['Jian Zhang', 'Yu He', 'Zhiyuan Wang', 'Zhangqi Wang', 'Kai He', 'Fangzhi Xu', 'Qika Lin', 'Jun Liu']",10.48550/arxiv.2601.09274,2601.09274,"['Scientific Reasoning', 'Memory-Driven', 'Anchor and Attractor Activation', 'Benchmarking', 'Large Language Models']","This paper proposes A3-Bench, a benchmark to evaluate scientific reasoning through dual-scale memory-driven activation, grounded in Anchor and Attractor Activation. It introduces a dual-scale memory evaluation framework and a metric to measure memory activation rates, validating A3-Bench and analyzing how memory activation impacts reasoning performance.",142.63,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09278v1_M3Searcher Modular Multimodal Information Seeking .pdf,M3Searcher: Modular Multimodal Information Seeking Agency with Retrieval-Oriented Reasoning,"['Xiaohan Yu', 'Chao Feng', 'Lang Mei', 'Chong Chen']",,2310.18664,"['information seeking', 'multimodal', 'retrieval-oriented', 'reasoning', 'deep research', 'LLMs']","This paper proposes M3Searcher, a modular multimodal information-seeking agent optimized with a retrieval-oriented multi-objective reward to encourage factual accuracy, reasoning soundness, and retrieval fidelity. It addresses challenges in extending autonomous information-seeking agents to multimodal settings, including the specialization-generalization trade-off and training data scarcity.",145.43,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09280v1_ReGraM Region-First Knowledge Graph Reasoning for .pdf,ReGraM: Region-First Knowledge Graph Reasoning for Medical Question Answering,"['Chaerin Lee', 'Sohee Park', 'Hyunsik Na', 'Daseon Choi']",10.1101/2023.09.18.607893,2309.09180,"['Medical QA', 'Knowledge Graphs', 'Large Language Models', 'Multi-hop Reasoning', 'Medical Hallucinations']","ReGraM is a region-first knowledge graph reasoning framework that addresses the challenge of identifying and reasoning over the appropriate subset of evidence for each query in medical question answering, improving factual accuracy and consistency.",159.13,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09281v1_STaR Sensitive Trajectory Regulation for Unlearnin.pdf,STaR: Sensitive Trajectory Regulation for Unlearning in Large Reasoning Models,"['Jingjing Zhou', 'Gaoxiang Cong', 'Li Su', 'Liang Li']",,2310.14527,"['Large Reasoning Models', 'Unlearning', 'Privacy Protection', 'Sensitive Trajectory Regulation', 'Multi-Decoding Consistency Assessment', 'Multi-Granularity Membership Inference Attack']","This paper proposes STaR, a parameter-free, inference-time unlearning framework for Large Reasoning Models (LRMs) that addresses the privacy risks introduced by their ability to generate complex Chain-of-Thought (CoT) trajectories. STaR identifies sensitive content via semantic-aware detection, injects global safety constraints through secure prompt prefix, performs trajectory-aware suppression to block sensitive content, and applies token-level adaptive filtering to prevent both exact and paraphrased sensitive tokens. It introduces two metrics for evaluating unlearning effectiveness and demonstrates comprehensive and stable unlearning with minimal utility loss on the R-TOFU benchmark.",159.18,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09282v1_Cluster Workload Allocation Semantic Soft Affinity.pdf,Cluster Workload Allocation: Semantic Soft Affinity Using Natural Language Processing,"['Leszek Sliwko1', 'Jolanta Mizeria-Pietraszko2']",,,"['Cluster workload allocation', 'Natural Language Processing', 'Semantic soft affinity', 'Kubernetes', 'Load balancing', 'Soft-affinity', 'Task assignment']","This paper introduces a semantic, intent-driven scheduling paradigm for cluster systems using Natural Language Processing. A prototype featuring a cluster state cache and an intent analyzer was developed, demonstrating high LLM parsing accuracy and superior scheduling quality compared to standard Kubernetes configurations, particularly excelling in complex and quantitative scenarios.",134.94,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09286v1_Why not Collaborative Filtering in Dual View Bridg.pdf,Why not Collaborative Filtering in Dual View? Bridging Sparse and Dense Models,"['HANZE GUO', 'JIANXUN LIAN', 'XIAO ZHOU']",XXXXXXX.XXXXXXX,,"['Collaborative Filtering', 'Dual View Alignment', 'Sparse and Dense model']","This paper proposes SaD (Sparse and Dense), a unified framework that integrates the semantic expressiveness of dense embeddings with the structural reliability of sparse interaction patterns, aiming to overcome the signal-to-noise ratio ceiling in modeling unpopular items. The authors demonstrate that under dual-view alignment, even a simple matrix factorization-style dense model can achieve state-of-the-art performance, and SaD consistently outperforms strong baselines on real-world benchmarks.",150.87,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09292v1_Blue Teaming Function-Calling Agents.pdf,Blue Teaming Function-Calling Agents,"['Greta Dolcetti', 'Giulio Zizzo', 'Sergio Maffeis']",,,"['Large Language Models', 'Function-calling', 'Adversarial Attacks', 'Defenses', 'Open Source', 'Agent2Agent', 'Model Context Protocol']","This paper presents an experimental evaluation of four open source LLMs with function-calling capabilities, assessing their robustness against three attacks and measuring the effectiveness of eight different defenses.",160.71,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09293v1_Policy-Based Reinforcement Learning with Action Ma.pdf,Policy-Based Reinforcement Learning with Action Masking for Dynamic Job Shop Scheduling under Uncertainty,"['Sofiene Lassoued', 'Stefan Lier', 'Andreas Schwung']",,1911.08128,"['Dynamic Job Shop Scheduling', 'Fault tolerance', 'Reinforcement learning', 'actions masking', 'Petri nets']","This paper presents a novel framework for solving Dynamic Job Shop Scheduling Problems under uncertainty, using Coloured Timed Petri Nets and Maskable Proximal Policy Optimization, to address challenges from stochastic job arrivals and machine failures. It demonstrates superior performance in terms of makespan minimization compared to traditional methods.",140.38,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09306v1_On-Device Large Language Models for Sequential Rec.pdf,On-Device Large Language Models for Sequential Recommendation,"['Xin Xia', 'Hongzhi Yin', 'Shane Culpepper']",10.1145/3773966.3777961,,"['Recommender Systems', 'Sequential Recommendation', 'On-Device Recommendation', 'Model Compression', 'Resource Constrained Devices']","This paper proposes OD-LLM, a task-adaptive compression framework designed to efficiently and accurately deploy large language models for sequential recommendation tasks on resource-constrained devices, addressing the challenges of substantial memory footprint and computational overhead.",157.37,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09313v1_Understanding or Memorizing A Case Study of German.pdf,Understanding or Memorizing? A Case Study of German Definite Articles in Language Models,"['Jonathan Drechsel', 'Erisa Bytyqi', 'Steffen Herbold']",null,2309.14854,"['Language Models', 'German Definite Articles', 'Gradient-based Interpretability', 'Grammatical Agreement', 'Memorization', 'Rule-based Generalization']","This study investigates whether language models encode abstract grammatical rules or rely on surface-level memorization of frequent token-context associations for German definite singular articles, which are syncretic and depend on gender and case. Using GRADIEND, a gradient-based interpretability method, the authors learn parameter update directions for gender-case specific article transitions and find that these updates frequently affect unrelated gender-case settings, indicating that models at least partly rely on memorized associations rather than abstract grammatical rules.",160.62,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09342v1_Improving Implicit Hate Speech Detection via a Com.pdf,Improving Implicit Hate Speech Detection via a Community-Driven Multi-Agent Framework,"['Ewelina Gajewska', 'Katarzyna Budzynska', 'Jarosław A. Chudziak']",,2309.14885,"['LLMs', 'Community agents', 'Hate speech', 'Social media', 'Moderation', 'Fairness']","This work proposes a contextualised detection framework for implicitly hateful speech, implemented as a multi-agent system, which enhances classification accuracy and fairness across all target groups by explicitly integrating socio-cultural context and balanced accuracy as a central metric of classification fairness.",161.44,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09351v1_Navigating Ethical AI Challenges in the Industrial.pdf,Navigating Ethical AI Challenges in the Industrial Sector: Balancing Innovation and Responsibility,"['Ruomu Tan', 'Martin W Hoffmann']",,2601.09351v1,"['Artificial Intelligence', 'Industrial Sector', 'Ethics', 'Innovation', 'Responsibility']","This chapter explores the intersection of artificial intelligence in the industrial sector, examining ethical challenges and practices in research and development, and emphasizes the importance of embedding ethical principles into industrial AI systems to foster trust and responsible progress.",148.84,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09353v1_Monte-Carlo Tree Search with Neural Network Guidan.pdf,Monte-Carlo Tree Search with Neural Network Guidance for Lane-Free Autonomous Driving,"['Ioannis Peridis', 'Dimitrios Troullinos', 'Georgios Chalkiadakis', 'Pantelis Giankoulidis', 'Ioannis Papamichail', 'Markos Papageorgiou']",,2601.09353v1,"['Monte-Carlo Tree Search', 'Neural Network', 'Lane-Free Autonomous Driving', 'Reinforcement Learning', 'Markov Decision Process', 'Nudging']","This work proposes a Monte-Carlo Tree Search approach with neural network guidance for lane-free autonomous driving, addressing safety and efficacy metrics through experimental evaluation.",155.12,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09361v1_GeoRA Geometry-Aware Low-Rank Adaptation for RLVR.pdf,GeoRA: Geometry-Aware Low-Rank Adaptation for RLVR,"['Jiaying Zhang1', 'Lei Shi1', 'Jiguo Li1', 'Jun Xu1', 'Jiuchong Gao 1', 'Jinghua Hao 1', 'Renqing He 1']",,2310.16454,"['Reinforcement Learning', 'Verifiable Rewards', 'Parameter-Efficient Fine-Tuning', 'Low-Rank Adaptation', 'Geometry-Aware', 'Optimization Dynamics', 'Geometric Structures']","This paper proposes GeoRA, a method that addresses the challenges of applying parameter-efficient methods like PiSSA and MiLoRA to Reinforcement Learning with Verifiable Rewards (RLVR). GeoRA exploits the anisotropic and compressible nature of RL update subspaces, initializing adapters by extracting principal directions via Singular Value Decomposition (SVD) within a geometrically constrained subspace while freezing residual components. This method preserves the pre-trained geometric structure and enables efficient GPU computation through dense operators, mitigating optimization bottlenecks caused by geometric misalignment and achieving state-of-the-art results on key mathematical benchmarks.",160.7,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09365v1_Frame of Reference Addressing the Challenges of Co.pdf,Frame of Reference: Addressing the Challenges of Common Ground in Situated Dialogs,"['Biswesh Mohapatra*', 'Théo Charlot†‡', 'Giovanni Duca†‡', 'Mayank Palan†‡', 'Laurent Romary*', 'Justine Cassell*']",,,"['Common Ground', 'Situational Dialogs', 'Embodied Conversational Agents', 'Social Robots', 'Large Language Models (LLMs)', 'Representation of Grounding']","This paper evaluates a model's ability to establish common ground in situated dialogs by utilizing relational references. It tests multiple methods for representing common ground and proposes approaches to improve their performance, addressing the challenges of maintaining shared references over time and in dynamic environments.",161.1,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09381v1_Query Languages for Machine-Learning Models.pdf,Query Languages for Machine-Learning Models,['Martin Grohe'],,2601.09381v1,"['Expressive power of query languages', 'fixed-point logics', 'weighted structures', 'neural networks', 'explainable AI']","This paper discusses two logics for weighted finite structures: first-order logic with summation (FO(SUM)) and its recursive extension IFP(SUM). These logics are investigated as query languages for machine learning models, specifically neural networks, which are naturally represented as weighted graphs. The paper presents illustrative examples of queries to neural networks that can be expressed in these logics and discusses fundamental results on their expressiveness and computational complexity.",159.89,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09382v1_Long-term Task-oriented Agent Proactive Long-term .pdf,Long-term Task-oriented Agent: Proactive Long-term Intent Maintenance in Dynamic Environments,"['Qinglong Shi', 'Donghai Wang', 'Hantao Zhou', 'Jiguo Li', 'Jun Xu', 'Jiuchong Gao', 'Jinghua Hao', 'Renqing He']",,,"['proactive agents', 'long-term task-oriented interaction', 'dynamic environments', 'intent-conditioned monitoring', 'event-triggered follow-up', 'data synthesis', 'ChronosBench']","This paper proposes a novel interaction paradigm for proactive Task-oriented Agents capable of bridging the gap between relatively static user's needs and a dynamic environment, formalizing proactivity through Intent-Conditioned Monitoring and Event-Triggered Follow-up. It introduces a high-quality data synthesis pipeline to construct complex, multi-turn dialog data and proposes a new benchmark, ChronosBench, to address the lack of evaluation criteria for task-oriented interaction in dynamic environments. The authors evaluate leading models and demonstrate the effectiveness of their data-driven strategy.",159.88,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09394v2_FairGE Fairness-Aware Graph Encoding in Incomplete.pdf,FairGE: Fairness-Aware Graph Encoding in Incomplete Social Networks,"['Renqiang Luo', 'Huafei Huang', 'Tao Tang', 'Jing Ren', 'Ziqi Xu', 'Mingliang Hou', 'Enyan Dai', 'Feng Xia']",XXXXXXX.XXXXXXX,,"['Social Networks', 'Graph Learning', 'Graph Transformers', 'Fairness', 'Incomplete Data']","FairGE is introduced as a fairness-aware framework for Graph Transformers in incomplete social networks, encoding fairness directly through spectral graph theory without generating incomplete sensitive attributes, thus enhancing fairness and achieving at least a 16% improvement in statistical parity and equality of opportunity compared to state-of-the-art baselines on seven real-world social network datasets.",160.19,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09398v1_Ability Transfer and Recovery via Modularized Para.pdf,Ability Transfer and Recovery via Modularized Parameters Localization,"['Songyao Jin', 'Kun Zhou*', 'Wenqi Li', 'Peng Wang', 'Biwei Huang']",,2309.14897,"['Large Language Models', 'Fine-tuning', 'Ability Transfer', 'Catastrophic Forgetting', 'Modularization', 'Parameter Localization']","This paper investigates how abilities are distributed within large language models (LLMs) and proposes ACT (Activation-Guided Channel-wise Ability Transfer), a method to localize ability-relevant channels and selectively transfer parameters, thereby recovering forgotten abilities while preserving retained skills.",160.54,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09413v1_Speech-Hands A Self-Reflection Voice Agentic Appro.pdf,Speech-Hands: A Self-Reflection Voice Agentic Approach to Speech Recognition and Audio Reasoning with Omni Perception,"['Zhen Wan', 'Chao-Han Huck Yang', 'Jinchuan Tian', 'Hanrong Ye', 'Ankita Pasad', 'Szu-wei Fu', 'Arushi Goel', 'Ryo Hachiuma', 'Shizhe Diao', 'Kunal Dhawan', 'Sreyan Ghosh', 'Yusuke Hirota', 'Zhehuai Chen', 'Rafael Valle', 'Ehsan Hosseini Asl', 'Chenhui Chu', 'Shinji Watanabe', 'Yu-Chiang Frank Wang', 'Boris Ginsburg']",,2310.17474,"['Speech Recognition', 'Audio Reasoning', 'Omni Perception', 'Self-Reflection', 'Voice Agentic', 'Audio Intelligence']","This paper introduces a voice-agentic framework called Speech-Hands that learns to self-reflect and decide when to trust itself versus external audio perception. It addresses the issue of naive fine-tuning on both speech recognition and external sound understanding tasks, which can degrade performance. The framework shows superior performance on the OpenASR leaderboard and robust generalization across diverse audio question answering datasets.",159.85,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09416v1_Radiomics-Integrated Deep Learning with Hierarchic.pdf,Radiomics-Integra TED Deep Learning with Hierarchical Loss for Osteosarcoma Histo pathology Classification,"['Yaxi Chen', 'Zi Ye', 'Shaheer U. Saeed', 'Oliver Yu', 'Simin Ni', 'Jie Huang', 'Yipeng Hu']",,1911.08932,"['Osteosarcoma', 'Radiomics', 'Deep Learning', 'Hierarchical Loss', 'Histopathology', 'Tumor Classification']","This study proposes the use of radiomic features and a hierarchical loss function in deep learning models to improve the classification of viable versus non-viable osteosarcoma tumor regions, demonstrating significant performance improvements on an open dataset compared to previous approaches.",160.34,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09421v2_Bias Dynamics in BabyLMs Towards a Compute-Efficie.pdf,Bias Dynamics in BabyLMs: Towards a Compute-Efficient Sandbox for Democratising Pre-Training Debiasing,"['Filip Trhlik', 'Andrew Caines', 'Paula Buttery']",,2310.16694,"['Bias', 'Pre-training', 'Debiasing', 'BabyLM', 'Language Models', 'Sandbox']","This work seeks to democratize pre-model debiasing research by using low-cost proxy models, specifically BabyLMs, which are compact BERT-like models trained on small and mutable corpora. The authors show that BabyLMs display closely aligned patterns of intrinsic bias formation and performance development compared to standard BERT models, and they conduct pre-model debiasing experiments with BabyLMs, replicating prior findings and presenting new insights regarding the influence of gender imbalance and toxicity on bias formation.",157.57,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09433v1_Do Transformers Understand Ancient Roman Coin Moti.pdf,Do Transformers Understand Ancient Roman Coin Motifs Better than CNNs?,"['David Reid', 'Ognjen Arandjelović']",,2601.09433v1,"['Vision Transformer', 'Convolutional Neural Networks', 'Ancient Coins', 'Numismatics', 'Machine Learning']","This paper evaluates the performance of Vision Transformer (ViT) models in identifying semantic elements on ancient coins compared to Convolutional Neural Networks (CNNs), providing an evaluation of their effectiveness in this specialized task.",161.38,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09445v1_Where Knowledge Collides A Mechanistic Study of In.pdf,Where Knowledge Collides: A Mechanistic Study of Intra-Memory Knowledge Conflict in Language Models,"['Minh Vu Pham', 'Hsuvas Borkakoty', 'Yufang Hou']",10.48550/arxiv.2601.09445,2601.09445,"['Language Models', 'Intra-Memory Knowledge Conflict', 'Mechanistic Interpretability', 'Pre-training Data', 'Fine-tuning', 'Knowledge Editing']","This study designs a framework based on mechanistic interpretability methods to identify and localize conflicts in language models' internal representations during pre-training, contributing to the understanding of specific internal components responsible for encoding conflicting knowledge from pre-training data.",158.42,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09446v1_Improving Symbolic Translation of Language Models .pdf,Improving Symbolic Translation of Language Models for Logical Reasoning,"['Ramya Keerthy Thatikonda', 'Jiuzhou Han', 'Wray Buntine', 'Ehsan Shareghi']",,2309.14417,"['Language Models', 'Logical Reasoning', 'Symbolic Translation', 'Formal Language', 'Natural Language', 'First-Order Logic', 'External Solvers', 'Incremental Inference', 'Verification Modules']","This paper addresses the challenges faced by smaller language models in translating natural language into first-order logic for logical reasoning tasks, proposing comprehensive fine-tuning, incremental inference, and verification modules to reduce translation errors and improve reasoning performance.",136.64,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09448v1_Population-Aligned Audio Reproduction With LLM-Bas.pdf,Population-Aligned Audio Reproduction With LLM-Based Equalizers,"['Ioannis Stylianou', 'Jon Francombe', 'Pablo Martínez-Nuevo', 'Sven Ewan Shepstone', 'Zheng-Hua Tan']",,,"['LLMs', 'Equalization', 'Audio Reproduction', 'Listening Experiments', 'Recommender Systems']","This paper introduces a Large Language Model (LLM)-based alternative for conventional audio equalization, which maps natural language text prompts to equalization settings. This enables a conversational approach to sound system control, and the models exploit in-context learning and parameter-efficient fine-tuning techniques to reliably align with population-preferred equalization settings. The evaluation methods show statistically significant improvements in distributional alignment over random sampling and static preset baselines, indicating that LLMs could function as 'artificial equalizers.'",159.08,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09451v1_Late Breaking Results Quamba-SE Soft-edge Quantize.pdf,Late Breaking Results: Quamba-SE: Soft-edge Quantizer for Activations in State Space Models,"['Yizhi Chen', 'Ahmed Hemani']",,,"['Quantization', 'State Space Models', 'Quamba']","The authors propose Quamba-SE, a soft-edge quantizer for State Space Model (SSM) activation quantization, which employs three adaptive scales: high-precision for small values, standard scale for normal values, and low-precision for outliers. This method preserves outlier information instead of hard clipping, while maintaining precision for other values. The authors evaluate Quamba-SE on Mamba-130M across 6 zero-shot benchmarks and show that it consistently outperforms Quamba, achieving up to +2.68% on individual benchmarks and up to +0.83% improvement in the average accuracy of 6 datasets.",158.89,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09455v1_On the Hardness of Computing Counterfactual and Se.pdf,On the Hardness of Computing Counterfactual and Semi-factual Explanations in XAI,"['André Artelt', 'Martin Olsen', 'Kevin Tierney']",,2601.09455v1,"['explainable artificial intelligence', 'counterfactual explanations', 'semi-factual explanations', 'computational complexity', 'machine learning', 'regulatory AI']","This paper provides an overview of the computational complexity results for generating counterfactual and semi-factual explanations in machine learning models, finding that these explanations are often computationally hard and inapproximable under certain assumptions.",158.09,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09460v1_SoK Enhancing Cryptographic Collaborative Learning.pdf,SoK: Enhancing Cryptographic Collaborative Learning with Differential Privacy,"['Francesco Capano', 'Jonas Böhrler', 'Benjamin Weggenmann']",,1909.09637,"['Differential privacy', 'cryptography', 'collaborative machine learning']","This work systematizes the cryptographic and differentially private collaborative learning (CPCL) landscape, introducing a unified framework that generalizes common phases across CPCL paradigms and identifying secure noise sampling as the foundational phase to achieve CPCL, analyzing trade-offs of different secure noise sampling techniques, noise types, and DP mechanisms, and evaluating their accuracy and cryptographic overhead across CPCL paradigms.",158.26,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09465v1_EvoFSM Controllable Self-Evolution for Deep Resear.pdf,EvoFSM: Controllable Self-Evolution for Deep Research with Finite State Machines,"['Shuo Zhang', 'Chaofa Yuan', 'Ryan Guo', 'Xiaomin Yu', 'Rui Xu', 'Zhangquan Chen', 'Zinuo Li', 'Zhi Yang', 'Shuhao Guan', 'Zhenheng Tang', 'Sen Hu', 'Liwen Zhang', 'Ronghao Chen', 'Huacan Wang']",10.48550/arxiv.2601.09465,2601.09465,"['self-evolution', 'finite state machines', 'deep research', 'adaptive systems', 'machine learning', 'open-ended queries']","EvoFSM is a structured self-evolving framework that evolves an explicit Finite State Machine (FSM) to achieve both adaptability and control, addressing the limitations of unconstrained optimization in LLM-based agents for deep research.",154.42,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09467v1_Searth Transformer A Transformer Architecture Inco.pdf,Searth Transformer: A Transformer Architecture Incorporating Earth's Geospheric Physical Priors for Global Mid-Range Weather Forecasting,"['Tianye Li', 'Qi Liu', 'Hao Li', 'Lei Chen', 'Wencong Cheng', 'Fei Zheng', 'Xiangao Xia', 'Ya Wang', 'Gang Huang', 'Weiwei Wang', 'Xuan Tong', 'Ziqing Zu', 'Yi Fang', 'Shenming Fu', 'Jiang Jiang', 'Haochen Li', 'Mingxing Li', 'Jiangjiang Xia', 'Jiangjiang Xia', 'Haochen Li', 'Shenming Fu', 'Jiangjiang Xia']",,2206.09616,"['Transformer', ""Earth's Geospheric Physical Priors"", 'Global Mid-Range Weather Forecasting', 'Relay Autoregressive (RAR) Fine-tuning', 'Zonal Periodicity', 'Meridional Boundaries', 'Autoregressive Training', 'Physical Consistency', 'Forecast Accuracy', 'Resource-Intensive', 'Localized Datasets', 'Global Model Performance']","This paper introduces the Shifted Earth Transformer (Searth Transformer), a physics-informed transformer architecture designed for global medium-range weather forecasting. It integrates zonal periodicity and meridional boundaries into window-based self-attention, enabling physically consistent global information exchange and mitigating computational bottlenecks through a memory-efficient fine-tuning strategy.",156.76,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09469v2_FairGU Fairness-aware Graph Unlearning in Social N.pdf,FairGU: Fairness-aware Graph Unlearning in Social Networks,"['Renqiang Luo', 'Yongshuai Yang', 'Huafei Huang', 'Qing Qing', 'Mingliang Hou', 'Ziqi Xu', 'Yi Yu', 'Jingjing Zhou', 'Feng Xia']",https://doi.org/XXXXXXX.XXXXXXX,,"['fairness', 'privacy', 'graph unlearning', 'social network']","This paper introduces FairGU, a fairness-aware graph unlearning framework designed to preserve both utility and fairness during the unlearning process, demonstrating superior performance in terms of accuracy and fairness metrics compared to existing methods.",157.29,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09470v1_Personalized Multimodal Feedback Using Multiple Ex.pdf,Personalized Multimodal Feedback Using Multiple External Representations: Strategy Profiles and Learning in High School Physics,"['Natalia Revenga-Lozano', 'Karina E. Avila', 'Steffen Steinert', 'Matthias Schweinberger', 'Clara E. Gómez-Pérez', 'Jochen Kuhn', 'Stefan Küchemann']",,2601.09470,"['Physics education', 'Multimodal feedback', 'Personalized feedback', 'High school physics', 'Learning strategies', 'Representational competence']","This study conducted a 16-24 week observational study in high school physics using a computer-based platform that provided verification and optional elaborated feedback in verbal, graphical, and mathematical forms, testing associations between feedback use and post-test performance and moderation by representational competence, finding that elaborated multirepresentational feedback showed a small but consistent positive association with post-test scores independent of prior knowledge and confidence.",153.4,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09473v1_SimMerge Learning to Select Merge Operators from S.pdf,SimMerge: Learning to Select Merge Operators from Similarity Signals,"['Oliver Bolton', 'Aakanksha', 'Arash Ahmadian', 'Sara Hooker', 'Marzieh Fadaee', 'Beyza Ermis']",,2601.09473v1,"['Model Merging', 'Language Models', 'Merge Operators', 'Similarity Signals', 'Predictive Methods']","This work introduces SimMerge, a predictive method for selecting the best merge operators using task-agnostic similarity signals, which eliminates the need for expensive merge-and-evaluate searches and demonstrates superior performance on 2-way merges of 7B-parameter LLMs and generalizes to multi-way merges and 111B-parameter LLM merges without retraining.",156.75,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09478v3_Bridging Semantic Understanding and Popularity Bia.pdf,Bridging Semantic Understanding and Popularity Bias with LLMs,"['Renqiang Luo', 'Dong Zhang', 'Yupeng Gao', 'Wen Shi', 'Mingliang Hou', 'Jiaying Liu', 'Zhe Wang', 'Shuo Yu*']",https://doi.org/XXXXXXX.XXXXXXX,,"['Semantic analysis', 'Recommender systems', 'Algorithmic fairness', 'Popularity bias', 'LLM']","This paper proposes FairLRM, a novel framework that bridges the gap in the semantic understanding of popularity bias with Recommendation via Large Language Model (RecLLM), enhancing both fairness and recommendation accuracy through a decomposition of popularity bias into item-side and user-side components and using structured instruction-based prompts to improve model comprehension.",140.69,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09503v1_What Do LLM Agents Know About Their World Task2Qui.pdf,What Do LLM Agents Know About Their World?,"['Siyuan Liu', 'Hongbang Yuan', 'Xinze Li', 'Ziyue Zhu', 'Yixin Cao', 'Yu-Gang Jiang']",null,2601.09503,"['Large Language Models', 'Generalization', 'Environment Understanding', 'Task-to-Quiz', 'Evaluation Paradigms']","This paper investigates the environment understanding of Large Language Model (LLM) agents, proposing Task-to-Quiz (T2Q) as a new evaluation paradigm to decouple task execution from world-state understanding, revealing that current memory mechanisms cannot effectively help agents acquire a grounded model of the environment.",152.21,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09518v1_Learning Whole-Body Human-Humanoid Interaction fro.pdf,Learning Whole-Body Human-Humanoid Interaction from Human-Human Demonstrations,"['Wei-Jin Huang', 'Yue-Yi Zhang', 'Yi-Lin Wei', 'Zhi-Wei Xia', 'Juantao Tan', 'Yuan-Ming Li', 'Zhilin Zhao', 'Wei-Shi Zheng']",,2601.09518,"['Human-Humanoid Interaction', 'Retargeting', 'Physics-Aware Interaction', 'HHI Dataset', 'HHoI Dataset', 'Decoupled Spatio-Temporal Action Reasoner', 'Imitation Learning']","This paper presents a contact-centric, two-stage pipeline called PAIR (Physics-Aware Interaction Retargeting) to convert human-human interaction sequences into physically consistent human-humanoid (HHoI) clips, addressing the failure of standard retargeting in preserving contact semantics. It also introduces D-STAR (Decoupled Spatio-Temporal Action Reasoner), a hierarchical policy that disentangles when to act from where to act, enabling interactive understanding of HHoI data.",157.56,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09520v1_Towards Realistic Synthetic Data for Automatic Dru.pdf,TOW ARDS REALISTIC SYNTHETIC DA TA FOR AUTOMA TIC DRUM TRANSCRIPTION,"['Pierfrancesco Melucci', 'Paolo Merialdo', 'Taketo Akama']",,1911.09967,"['Automatic Drum Transcription', 'Deep Learning', 'Synthetic Data', 'MIDI', 'SoundFont', 'Sequence-to-Sequence Models']","This paper introduces a new paradigm for Automatic Drum Transcription (ADT) that circumvents the need for paired audio-MIDI training data, curating a large and diverse corpus of one-shot drum samples from unlabeled audio sources and synthesizing a high-quality dataset from MIDI files alone for training a sequence-to-sequence transcription model, achieving state-of-the-art results on the ENST and MDB test sets.",160.67,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09527v1_Private LLM Inference on Consumer Blackwell GPUs A.pdf,Private LLM Inference on Consumer Blackwell GPUs: A Practical Guide for Cost-Effective Local Deployment in SMEs,"['Jonathan Knoop1', 'Hendrik Holtmann2']",,,"['LLM', 'consumer GPUs', 'Blackwell', 'NVIDIA', 'SMEs', 'inference', 'cost-effective', 'local deployment', 'quantization', 'workload', 'RTX 5060 Ti', 'RTX 5070 Ti', 'RTX 5090']","This paper presents a systematic evaluation of NVIDIA's Blackwell consumer GPUs (RTX 5060 Ti, 5070 Ti, 5090) for production LLM inference, benchmarking four open-weight models across various configurations and workloads. It shows that consumer GPUs can reliably replace cloud inference for most SME workloads, except for latency-critical long-context RAG, where high-end GPUs remain essential. The study provides deployment guidance and releases all benchmark data for reproducible SME-scale deployments.",160.04,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09536v1_Omni-R1 Towards the Unified Generative Paradigm fo.pdf,Omni-R1: Towards the Unified Generative Paradigm for Multimodal Reasoning,"['Dongjie Cheng', 'Yongqi Li', 'Zhixin Ma', 'Hongru Cai', 'Yupeng Hu', 'Wenjie Wang', 'Liqiang Nie', 'Wenjie Li']",,2601.09536,"['Multimodal Reasoning', 'Generative Models', 'Two-Stage Framework', 'Perception Alignment', 'Perception Reward', 'Visual Information', 'Text-Only Reasoning', 'VQA', 'Spatial Reasoning']","This paper proposes unified generative multimodal reasoning, which unifies diverse multimodal reasoning skills by generating intermediate images during the reasoning process. It introduces Omni-R1, a two-stage SFT+RL framework featuring perception alignment loss and perception reward, and Omni-R1-Zero, which eliminates the need for multimodal annotations by bootstrapping step-wise visualizations from text-only reasoning data. Empirical results show that Omni-R1 achieves unified generative reasoning across a wide range of multimodal tasks, and Omni-R1-Zero can match or even surpass Omni-R1 on average.",160.46,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09555v1_Benchmarking Post-Training Quantization of Large L.pdf,Benchmarking Post-Training Quantization of Large Language Models under Microscaling Floating Point Formats,"['Manyi Zhang', 'Ji-Fu Li', 'Zhongao Sun', 'Haoli Bai', 'Hui-Ling Zhen', 'Zhenhua Dong', 'Xianzhi Yu']",,2312.01487,"['Post-Training Quantization', 'Microscaling Floating-Point', 'Large Language Models', 'Quantization', 'Low-Precision Formats']","This work conducts a systematic investigation of post-training quantization under Microscaling Floating-Point formats, encompassing over 7 PTQ algorithms, 15 evaluation benchmarks, and 3 LLM families, providing practical guidance on adapting existing PTQ methods to MXFP quantization.",160.47,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09566v2_Hot-Start from Pixels Low-Resolution Visual Tokens.pdf,Hot-Start from Pixels: Low-Resolution Visual Tokens for Chinese Language Modeling,"['Shuyang Xiang', 'Hao Guan']",,2601.09566v2,"['Chinese language modeling', 'visual tokens', 'low-resolution inputs', 'language prediction', 'hot-start effect']","This paper investigates whether low-resolution visual inputs can serve as an alternative for character-level modeling in Chinese language, achieving comparable accuracy to index-based models and demonstrating a pronounced hot-start effect.",155.43,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09600v1_Information Access of the Oppressed A Problem-Posi.pdf,Information Access of the Oppressed: A Problem-Posing Framework for Envisioning Emancipatory Information Access Platforms,"['BHASKAR MITRA', 'NICOLA NEOPHYTOU', 'SIREESH GURURAJA']",XXXXXXX.XXXXXXX,,"['Emancipatory Information Access', 'Search and Society', 'Sociotechnical Information Systems']","This paper explores the challenges of authoritarian capture of information access platforms, particularly in the context of rising democratic erosion and the capabilities of generative AI technologies. It proposes a problem-posing framework for envisioning alternative IA infrastructure using Paulo Freire's theories of emancipatory pedagogy, challenging the traditional roles of technologists and users and advocating for community participation in technology design.",142.25,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09603v1_Linear Complexity Self-Supervised Learning for Mus.pdf,Linear Complexity Self-Supervised Learning for Music Understanding with Random Quantizer,"['Petros Vavaroutsos', 'Theodoros Palamas', 'Pantelis Vikatos']",10.1145/3748522.3779786,,"['Deep Learning', 'Learnable Representations', 'Music Understanding', 'Transformers', 'Embeddings', 'Attention']","This paper presents a self-supervised learning approach for music information retrieval tasks using a combination of the Branchformer architecture and SummaryMixing, along with a random quantization process. The authors demonstrate that their architecture achieves competitive performance compared to state-of-the-art models, while significantly reducing the model size from 8.5% to 12.3%.",156.7,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09605v1_Sim2real Image Translation Enables Viewpoint-Robus.pdf,Sim2real Image Translation Enables Viewpoint-Robust Policies from Fixed-Camera Datasets,"['Jeremiah Coholich', 'Justin Wit', 'Robert Azarcon', 'Zsolt Kira']",,2209.12488,"['Image Translation', 'Sim2Real', 'Robotic Manipulation', 'Camera Viewpoint', 'Imitation Learning']","This paper proposes MANGO, an unpaired image translation method, to enable viewpoint-robust robot manipulation policies from fixed-camera datasets. MANGO maintains viewpoint consistency during sim2real translation and outperforms other methods, improving the robustness of imitation-learning policies trained on augmented data.",161.63,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09609v1_DPWriter Reinforcement Learning with Diverse Plann.pdf,DPWriter: Reinforcement Learning with Diverse Planning Branching for Creative Writing,"['Qian Cao', 'Yahui Liu', 'Wei Bi', 'Yi Zhao', 'Ruihua Song', 'Xiting Wang', 'Ruiming Tang', 'Guorui Zhou', 'Han Li']",,2310.00000,"['Reinforcement Learning', 'Creative Writing', 'Diverse Exploration', 'Long Chain-of-Thought', 'Group-Aware Diversity Reward']","This paper proposes an RL framework structured around a semi-structured long Chain-of-Thought (CoT), decomposing the generation process into explicitly planned intermediate steps. It introduces a Diverse Planning Branching method to strategically introduce divergence at the planning phase based on diversity variation, alongside a group-aware diversity reward to encourage distinct trajectories. Experimental results demonstrate significant improvements in output diversity without compromising generation quality, outperforming existing baselines.",159.28,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09613v1_CogRail Benchmarking VLMs in Cognitive Intrusion P.pdf,CogRail: Benchmarking VLMs in Cognitive Intrusion Perception for Intelligent Railway Transportation Systems,"['Yonglin Tian', 'Qiyao Zhang', 'Wei Xu', 'Yutong Wang', 'Yihao Wu', 'Xinyi Li', 'Xingyuan Dai', 'Hui Zhang', 'Zhiyong Cui', 'Baoqing Guo', 'Zujun Yu', 'Yisheng Lv']",,,"['Cognitive Intrusion Perception', 'Intelligent Railway Transportation Systems', 'Visual-Language Models', 'Benchmarking', 'Fine-Tuning']","This paper introduces a novel benchmark, CogRail, which integrates curated open-source datasets with cognitively driven question-answer annotations to support spatio-temporal reasoning and prediction for deep intrusion perception. It conducts a systematic evaluation of state-of-the-art visual-language models (VLMs) and proposes a joint fine-tuning framework to facilitate effective adaptation of general-purpose foundation models into specialized models tailored for cognitive intrusion perception.",144.94,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09620v1_Full Disclosure Less Trust How the Level of Detail.pdf,"Full Disclosure, Less Trust? How the Level of Detail about AI Use in News Writing Affects Readers’ Trust","['Pooja Prajod', 'Hannes Cools', 'Thomas Röggla', 'Karthikeya Puttur Venkatraj', 'Amber Kusters', 'Alia Elkattan', 'Pablo Cesar', 'Abdallah El Ali']",,2309.14074,"['Artificial Intelligence', 'Transparency', 'Trust in News', 'Journalism', 'AI in News Production']","This study investigates how different levels of AI disclosures (none, one-line, detailed) in politics and lifestyle news affect readers' trust and source-checking behavior, finding that detailed disclosures reduce trust but increase source-checking behavior, while one-line disclosures have a more moderate effect.",160.76,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09624v1_Toward Understanding Unlearning Difficulty A Mecha.pdf,Toward Understanding Unlearning Difficulty: A Mechanistic Perspective,"['Jiali Cheng', 'Ziheng Chen', 'Chirag Agarwal', 'Hadi Amiri']",,2310.17016,"['Machine learning', 'Unlearning', 'Model circuits', 'Difficulty metric']","This paper proposes Circuit-guided Unlearning Difficulty (CUD), a metric that assigns each sample a continuous difficulty score using circuit-level signals, to study and quantify unlearning difficulty from a mechanistic perspective. The authors demonstrate that CUD reliably separates intrinsically easy and hard samples and remains stable across unlearning methods, identifying key circuit-level patterns that reveal a mechanistic signature of difficulty.",157.39,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09625v1_The Promptware Kill Chain How Prompt Injections Gr.pdf,The Promptware Kill Chain: How Prompt Injections Gradually Evolved Into a Multi-Step Malware,"['Ben Nassi', 'Bruce Schneier', 'Oleg Brodt']",,,"['Prompt Injection', 'Large Language Models', 'Malware', 'Security Frameworks', 'Natural Language Processing', 'Cybersecurity']","This paper proposes that attacks targeting LLM-based applications constitute a distinct class of malware, termed promptware, and introduces a five-step kill chain model to analyze these threats. By mapping recent attacks to this structure, the authors demonstrate that LLM-related attacks follow systematic sequences analogous to traditional malware campaigns, offering a structured methodology for threat modeling and a common vocabulary for researchers in AI safety and cybersecurity.",159.07,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09626v1_From Prompt to Protocol Fast Charging Batteries wi.pdf,From Prompt to Protocol: Fast Charging Batteries with Large Language Models,"['Ge Lei', 'Ferran Brosa Planella', 'Sterling G. Baird', 'Samuel J. Cooper']",,2601.09626,"['battery charging', 'large language models', 'gradient-free optimization', 'closed-loop design', 'fast charging']","This paper introduces two gradient-free, LLM-driven methods, Prompt-to-Optimizer (P2O) and Prompt-to-Protocol (P2P), for optimizing battery charging protocols. These methods outperform existing approaches and demonstrate the potential of LLMs in expanding the space of protocol functional forms and incorporating language-based constraints in high-cost experimental settings.",155.63,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09635v1_LLM for Large-Scale Optimization Model Auto-Formul.pdf,LLM for Large-Scale Optimization Model Auto-Formulation: A Lightweight Few-Shot Learning Approach,"['Kuo Liang', 'Yuhang Lu', 'Jianming Mao', 'Shuyi Sun', 'Chunwei Yang', 'Congcong Zeng', 'Xiao Jin', 'Hanzhang Qin', 'Ruihao Zhu', 'Chung-Piaw Teo']",,2601.09635,"['large language models', 'tool use', 'agentic workflow construction', 'automated optimization modeling']","This paper proposes LEAN-LLM-OPT, a workflow construction framework for large-scale optimization model auto-formulation using large language models. It addresses the labor-intensive and time-consuming nature of building optimization models and demonstrates strong performance on large-scale optimization tasks through extensive simulations and practical use cases.",160.24,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09636v1_PersonalAlign Hierarchical Implicit Intent Alignme.pdf,PersonalAlign: Hierarchical Implicit Intent Alignment for Personalized GUI Agent with Long-Term User-Centric Records,"['Yibo Lyu', 'Gongwei Chen', 'Rui Shao†', 'Weili Guan', 'Liqiang Nie†']",https://doi.org/10.1000/PersonalAlign,2309.12345,"['GUI agents', 'intent alignment', 'long-term user records', 'proactive assistance', 'multimodal large language models']","This paper introduces PersonalAlign, a new agent task that requires GUI agents to leverage long-term user records to resolve omitted preferences and anticipate user routines for proactive assistance. It evaluates PersonalAlign on AndroidIntent, a benchmark that includes annotated user preferences and routines, and shows that a Hierarchical Intent Memory Agent (HIM-Agent) significantly improves both execution and proactive performance.",160.0,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09667v2_Collaborative Multi-Agent Test-Time Reinforcement .pdf,Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning,"['Zhiyuan Hu', 'Yunhai Hu', 'Juncheng Liu', 'Shuyue Stella Li', 'Yucheng Wang', 'Zhen Xu', 'See-Kiong Ng', 'Anh Tuan Luu', 'Xinxing Xu', 'Bryan Hooi', 'Cynthia Breazeal', 'Hae Won Park']",,2310.13743,"['Multi-Agent Reinforcement Learning', 'Test-Time Reinforcement Learning', 'Multi-Agent Reasoning', 'Collaborative Learning', 'Robustness', 'Distribution Shift']","This paper introduces MATTRL, a framework that injects structured textual experience into multi-agent deliberation at inference time to improve accuracy in challenging benchmarks across medicine, math, and education. MATTRL forms a multi-expert team for multi-turn discussions, retrieves and integrates test-time experiences, and reaches consensus for final decision-making.",158.07,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09680v1_Automating Supply Chain Disruption Monitoring via .pdf,Automating Supply Chain Disruption Monitoring via an Agentic AI Approach,"['Sara AlMahria', 'Liming Xu', 'Alexandra Brintrup']",,2601.09680v1,"['Supply Chain Management', 'Supply Chain Disruption', 'Large Language Models', 'AI Agents', 'Multi-Agent System', 'Agentic System']","This research introduces a minimally supervised agentic AI framework that autonomously monitors, analyzes, and responds to disruptions across extended supply networks, achieving high accuracy and reducing response time compared to industry benchmarks.",157.45,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09684v1_Disentangling Task Conflicts in Multi-Task LoRA vi.pdf,Disentangling Task Conflicts in Multi-Task LoRA via Orthogonal Gradient Projection,"['Ziyu Yang', 'Guibin Chen', 'Yuxin Yang', 'Aoxiong Zeng', 'Xiangquan Yang']",,2309.15870,"['Multi-Task Learning', 'Low-Rank Adaptation', 'Gradient Projection', 'Orthogonal Complement', 'Large Language Models', 'Parameter-Efficient Fine-Tuning']","This paper proposes Ortho-LoRA, a gradient projection method specifically tailored for the bipartite structure of LoRA, to mitigate task interference in Multi-Task Learning (MTL) with LoRA. Extensive experiments on the GLUE benchmark demonstrate that Ortho-LoRA effectively mitigates task interference, outperforming standard joint training and recovering 95% of the performance gap between multi-task and single-task baselines with negligible computational overhead.",160.17,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09692v1_Routing with Generated Data Annotation-Free LLM Sk.pdf,Routing with Generated Data: Annotation-Free,"['Tianyi Niu', 'Justin Chih-Yao Chen', 'Genta Indra Winata', 'Shi-Xiong Zhang', 'Supriyo Chakraborty', 'Sambit Sahu', 'Elias Stengel-Eskin', 'Mohit Bansal']",,2309.14477,"['Large Language Models', 'Routing', 'Annotation-Free', 'Skill Estimation', 'Query-Only Routing', 'Consensus Voting', 'Hierarchical Clustering']","This paper introduces Routing with Generated Data (RGD), a method for dynamically selecting optimal models for given inputs without requiring ground-truth labeled data. It evaluates query-answer and query-only routers across four diverse benchmarks and 12 models, finding that query-answer routers degrade faster than query-only routers as generator quality decreases. The authors propose CASCAL, a novel query-only router that estimates model correctness through consensus voting and identifies model-specific skill niches via hierarchical clustering, demonstrating improved robustness to generator quality.",160.18,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09694v1_LLMs can Compress LLMs Adaptive Pruning by Agents.pdf,LLMs can Compress LLMs: Adaptive Pruning by Agents,"['Sai Varun Kodathala1', 'Rakesh Vunnam 2']",,2601.09694,"['Model Compression', 'Adaptive Pruning', 'Self-Reflection']","This paper introduces agent-guided pruning, where a foundation model acts as an adaptive pruning agent to intelligently select layers to prune, preserving critical knowledge pathways and achieving substantial improvements in model accuracy and perplexity over structured pruning methods.",161.59,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09703v1_ShortCoder Knowledge-Augmented Syntax Optimization.pdf,ShortCoder: Knowledge-Augmented Syntax Optimization for Token-Efficient Code Generation,"['Sicong Liu', 'Yanxian Huang', 'Mingwei Liu', 'Jiachi Chen', 'Ensheng Shi', 'Yuchi Ma', 'Hongyu Zhang', 'Yin Zhang', 'Yanlin Wang']",,2309.15754,"['code generation', 'large language models', 'syntax optimization', 'token efficiency', 'LLMs']","This paper proposes ShortCoder, a knowledge-infused framework that optimizes code generation efficiency while preserving semantic equivalence and readability, achieving significant improvements in generation efficiency over state-of-the-art methods.",161.16,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09706v1_Value-Aware Numerical Representations for Transfor.pdf,Value-Aware Numerical Representations for Transformer Language Models,"['Andreea Dutulescu', 'Stefan Ruseti', 'Mihai Dascalu']",,2309.15698,"['Transformer', 'Language Models', 'Mathematical Reasoning', 'Numerical Understanding', 'Transformer-based Models', 'Value-Aware Representations']","This paper introduces a value-aware numerical representation for Transformer-based language models, which augments standard tokenized inputs with a dedicated prefix token explicitly conditioned on numerical value. Evaluation on arithmetic tasks shows that this approach outperforms baselines across various numerical formats, tasks, and operand lengths, indicating that explicitly encoding numerical value improves fundamental numerical robustness in language models.",159.8,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09708v1_Fast-ThinkAct Efficient Vision-Language-Action Rea.pdf,Fast-ThinkAct: Efficient Vision-Language-Action Reasoning via Verbalizable Latent Planning,"['Chi-Pin Huang', 'Yunze Man', 'Zhiding Yu', 'Min-Hung Chen', 'Jan Kautz', 'Yu-Chiang Frank Wang', 'Fu-En Yang']",,2601.09708,"['Vision-Language-Action', 'Efficient Reasoning', 'Latent Planning', 'Embodied Control', 'Long-Horizon Planning', 'Few-Shot Adaptation']","Fast-ThinkAct is an efficient reasoning framework that achieves compact yet performant planning through verbalizable latent reasoning, enabling reasoning-enhanced policy learning that effectively connects compact reasoning to action execution, and demonstrating strong performance with up to 89.3% reduced inference latency over state-of-the-art reasoning VLAs.",142.45,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09749v1_R-LAM Reproducibility-Constrained Large Action Mod.pdf,R-LAM: Reproducibility-Constrained Large Action Models for Scientific Workflow Automation,['Suriya Sureshkumar'],,,"['Reproducible Scientific Workflows', 'Large Action Models', 'LLM-Based Agents', 'Execution Provenance', 'Deterministic Execution']","This paper proposes R-LAM, a reproducibility-constrained framework for applying Large Action Models to scientific workflow automation, introducing structured action schemas, deterministic execution policies, and explicit provenance tracking to ensure reproducibility and auditability.",152.61,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09750v1_SAGE Tool-Augmented LLM Task Solving Strategies in.pdf,SAGE: Tool-Augmented LLM Task Solving Strategies in Scalable Multi-Agent Environments,"['Robert K. Strehlow', 'Tobias Küster', 'Oskar F. Kupke', 'Brandon Llanque Kurps', 'Fikret Sivrikaya', 'Sahin Albayrak']",,,"['Large Language Models', 'Tool Augmentation', 'Multi-Agent Environments', 'Task Solving Strategies', 'Open Source', 'Open Data']","This paper presents SAGE, a specialized conversational AI interface based on the OPACA framework for tool discovery and execution, integrating new tools or services into an LLM dynamically and providing robust zero-shot prompting methods for efficient tool usage.",156.12,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09753v1_Critically Engaged Pragmatism A Scientific Norm an.pdf,"Critically Engaged Pragmatism: A Scientific Norm and Social, Pragmatist Epistemology for AI Science Evaluation Tools",['Carole J. Lee'],,2309.14492,"['AI science evaluation', 'peer review crisis', 'replication crisis', 'pragmatism', 'critically engaged pragmatism']","This paper discusses the challenges faced by the scientific community in evaluating research, including crises in peer review capacity, study replication, and AI-fabricated science. It argues for a social, pragmatist epistemology and a norm of Critically Engaged Pragmatism to scrutinize AI science evaluation tools, emphasizing that these tools are not objective arbiters of scientific credibility but the object of critical discursive practices.",158.29,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09755v1_Heterogeneous computing platform for real-time rob.pdf,Heterogeneous computing platform for real-time robotics,"['Jakub Fil', 'Yulia Sandamirskaya', 'Hector Gonzalez', 'Loïc Azzalin', 'Stefan Glüge', 'Matthias Lohrmann', 'Mahmoud Akl', 'Khaleel Khan', 'Leonie Wolf', 'Kristin Richter', 'Holm Puder', 'Mazhar Ali Bari', 'Xuan Choo', 'Noha Alharthi', 'Michael Hopkins', 'Mansoor Hanif', 'Christian Mayr', 'Jens Struckmeier', 'Steve Furber']",,2601.01677,"['robotics', 'neuromorphic computing', 'heterogeneous computing', 'real-time perception', 'social robotics', 'cognitive cities', 'event-based cameras', 'GPU', 'Loihi2', 'SpiNNaker', 'DGX', 'Spaun']","This paper explores a computing platform for enabling a vision of cognitive cities powered by robots, integrating neuromorphic hardware like Loihi2 with high-density GPU clusters for real-time perception and task planning. The authors demonstrate the platform's use in an interactive task involving a humanoid robot playing a musical instrument with a human, highlighting the efficiency and synergy of combining disparate components.",156.52,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09756v1_Synthetic Data for Veterinary EHR De-identificatio.pdf,"Synthetic Data for Veterinary EHR De-identification: Benefits, Limits, and Safety Trade-offs Under Fixed Compute","['David Brundage, PhD']",null,null,"['Synthetic Data', 'Veterinary EHR De-identification', 'Large Language Models', 'De-identification Methods', 'Low-Resource Domain']","This study evaluates the use of large language model-generated synthetic veterinary clinical narratives in de-identification processes under fixed compute constraints, comparing their impact on safety and utility compared to real clinical notes.",135.1,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09757v1_Democracy and Distrust in an Era of Artificial Int.pdf,Democracy & Distrust in an Era of Artificial Intelligence,['Sonia K. Katyal'],10.1162/DAED_a_01919,,"['Artificial Intelligence', 'Judicial Review', 'Democracy', 'Minorities', 'Due Process', 'Equal Protection', 'Accountability', 'Prediction', 'Automation']","This essay discusses how the rise of AI decision-making poses a similar challenge to democracy's basic framework as the failure of the political process to recognize the rights or interests of minorities. It outlines a theory of judicial review in an era of artificial intelligence, analyzing the limitations and possibilities of AI oversight and accountability.",157.53,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09760v1_Investigating Tool-Memory Conflicts in Tool-Augmen.pdf,Investigating Tool-Memory Conflicts in Tool-Augmented LLMs,"['Jiali Cheng', 'Rui Pan', 'Hadi Amiri']",,2506.00001,"['tool-augmented LLMs', 'knowledge conflicts', 'tool-memory conflicts', 'epistemic inconsistencies', 'large language models']","This paper investigates a new type of knowledge conflict, Tool-Memory Conflict (TMC), in tool-augmented large language models (LLMs), where internal parametric knowledge contradicts external tool knowledge. The authors find that existing LLMs suffer from TMC, especially on STEM-related tasks, and explore different conditions under which tool knowledge and parametric knowledge may be prioritized differently. They also evaluate existing conflict resolving techniques and find none effective in resolving tool-memory conflicts.",157.75,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09762v1_Explicating Tacit Regulatory Knowledge from LLMs t.pdf,Explicating Tacit Regulatory Knowledge from LLMs to Auto-Formalize Requirements for Compliance Test Case Generation,"['Zhiyi Xue', 'Xiaohong Chen', 'Min Zhang']",,2309.14917,"['Compliance Testing', 'Regulatory Knowledge', 'Large Language Models', 'Requirements Auto-formalization', 'Automated Test Generation']","This paper proposes RAFT, a framework for requirements auto-formalization and compliance test generation via explicating tacit regulatory knowledge from multiple Large Language Models (LLMs). RAFT employs an Adaptive Purification-Aggregation strategy to integrate tacit regulatory knowledge into a domain meta-model, formal requirements representation, and testability constraints, guiding high-precision requirement formalization and automated test generation across financial, automotive, and power domains.",156.95,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09765v1_AI Survival Stories a Taxonomic Analysis of AI Exi.pdf,Survival Stories: A Taxonomic Analysis of AI Existential Risk,['John Hawthorne'],,1909.06881,"['Artiﬁcial Intelligence', 'Existential Risk', 'AI safety', 'AI Catastrophe', 'Superintelligent AI', 'AI Alignment']","This paper develops a general framework for thinking about the existential risk of AI systems, analyzing a two-premise argument that AI systems pose a threat to humanity. It introduces a taxonomy of 'survival stories' to explore different scenarios where humanity might survive an AI existential threat.",157.74,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09768v1_CLiMB A Domain-Informed Novelty Detection Clusteri.pdf,CLiMB: A Domain-Informed Novelty Detection Clustering Framework for Scientific Discovery,"['Lorenzo Monti', 'Tatiana Muraveva', 'Brian Sheridan', 'Davide Massari', 'Alessia Garofalo', 'Gisella Clementini', 'Umberto Michelucci']",null,2601.09768,"['novelty detection', 'semi-supervised clustering', 'constrained clustering', 'density-based clustering', 'domain knowledge integration']","The paper introduces CLiMB, a domain-informed framework for clustering and novelty detection in scientific data, which outperforms existing methods in identifying known and novel structures, demonstrating its potential for scientific discovery.",140.5,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09770v1_GUI-Eyes Tool-Augmented Perception for Visual Grou.pdf,GUI-Eyes: Tool-Augmented Perception for Visual Grounding in GUI Agents,"['Chen Chen', 'Jiawei Shao', 'Dakuan Lu', 'Haoyi Hu', 'Xiangcheng Liu', 'Hantao Yao', 'Wu Liu']",,2309.14956,"['GUI automation', 'reinforcement learning', 'visual grounding', 'tool usage', 'spatial reward function']","GUI-Eyes is a reinforcement learning framework for active visual perception in GUI tasks, enabling agents to make strategic decisions on visual tools like cropping or zooming, and achieving high accuracy on the ScreenSpot-Pro benchmark using only 3k labeled samples.",157.28,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09771v1_PCN-Rec Agentic Proof-Carrying Negotiation for Rel.pdf,PCN-Rec: Agentic Proof-Carrying Negotiation for Reliable Governance-Constrained Recommendation,"['Aradhya Dixit', 'Shreem Dixit']",,,"['recommendation systems', 'LLM agents', 'constrained ranking', 'governance', 'verification', 'negotiation']","PCN-Rec presents a proof-carrying negotiation pipeline that separates natural-language reasoning from deterministic enforcement. It achieves a 98.55% pass rate on feasible users with governance constraints, preserving utility with only a 0.021 absolute drop in NDCG@10, while a single LLM baseline without verification/repair achieves a 100% pass rate.",158.24,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09772v1_Antisocial behavior towards large language model u.pdf,Antisocial behavior towards large language model users: experimental evidence,"['Paweł Niszczota', 'Cassandra Grützner']",,,"['Antisocial behavior', 'Large language models', 'Experimental evidence', 'User behavior']",This study examines antisocial behavior exhibited by users towards large language models through experimental methods.,144.37,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09773v1_Enhancing LUT-based Deep Neural Networks Inference.pdf,Enhancing LUT-based Deep Neural Networks Inference through Architecture and Connectivity Optimization,"['Binglei Lou', 'Ruilin Wu', 'Philip Leong']",,1909.08732,"['Dynamic Sparsity', 'FPGA', 'Neural Network', 'Lookup Table']","This paper presents SparseLUT, a comprehensive framework that addresses the challenges of exponential growth of LUT size and inefficient random sparse connectivity in LUT-based DNNs, through architectural enhancements and non-greedy training algorithms, delivering consistent accuracy improvements across benchmarks.",160.45,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09805v1_Improving Chain-of-Thought for Logical Reasoning v.pdf,Improving Chain-of-Thought for Logical Reasoning via Attention-Aware Intervention,"['Phuong Minh Nguyen', 'Tien Huu Dang', 'Naoya Inoue']",,2312.08271,"['Logical reasoning', 'Attention-Aware Intervention', 'Chain-of-Thought', 'LLM', 'Symbolic solvers']","This work introduces an end-to-end framework for logical reasoning tasks, which enhances performance across diverse benchmarks and architectures, while incurring negligible additional computational overhead.",161.21,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09806v1_Diffusion-Driven Deceptive Patches Adversarial Man.pdf,Diffusion-Driven Deceptive Patches: Adversarial Manipulation and Forensic Detection in Facial Identity Verification,"['Shahrzad Sayyafzadeh', 'Hongmei Chi', 'Shonda Bernadin']",,2601.09806v1,"['Adversarial Patch Generation', 'Gaussian Smoothing', 'Diffusion Model', 'Social Media Forensics', 'Perceptual Hashing']","This work presents an end-to-end pipeline for generating, refining, and evaluating adversarial patches to compromise facial biometric systems, employing FGSM for adversarial noise generation and diffusion models for enhancing imperceptibility, and using a Vision Transformer (ViT)-GPT2 model for semantic identity descriptions.",150.57,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09809v1_QFed Parameter-Compact Quantum-Classical Federated.pdf,QFed: Parameter-Compact Quantum-Classical Federated Learning,"['Samar Abdelghani', 'Soumaya Cherkaoui']",,2301.00000,"['Quantum Computing', 'Quantum Machine Learning', 'Federated Learning', 'Privacy', 'Communication', 'IoT']","This study examines the potential of quantum-assisted federated learning, which could reduce the number of parameters in classical models by polylogarithmic factors, and introduces QFed, a quantum-enabled federated learning framework aimed at boosting computational efficiency across edge device networks. Experimental results show that QFed achieves a 77.6% reduction in the parameter count of a VGG-like model while maintaining comparable accuracy to classical approaches in a scalable environment.",157.8,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09814v1_Explainable Deep Learning for Pediatric Pneumonia .pdf,Explainable Deep Learning for Pediatric Pneumonia Detection in Chest X-Ray Images,"['Adil O. Khadidos1', 'Aziida Nanyonga2', 'Alaa O. Khadidos3', 'Olfat M. Mirza5', 'Mustafa Tahsin Yilmaz6']",,,"['Pediatric pneumonia', 'chest x-ray', 'deep learning', 'convolutional neural networks', 'explainable AI', 'image classification']","This study compares two state-of-the-art convolutional neural network architectures, DenseNet121 and EfficientNet-B0, for automated pediatric pneumonia detection in chest X-ray images, evaluating their performance and incorporating explainability techniques to visualize model decisions.",148.44,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09822v2_LLM-Based Agentic Systems for Software Engineering.pdf,LLM-Based Agentic Systems for Software Engineering: Challenges and Opportunities,"['Yongjian Tang', 'Thomas Runkler']",,2601.09822v2,"['LLMs', 'Agents', 'Software Engineering', 'Future Challenges']","This concept paper systematically reviews the emerging paradigm of LLM-based multi-agent systems, examining their applications across the Software Development Life Cycle (SDLC), from requirements engineering and code generation to static code checking, testing, and debugging, identifying key challenges and outlining future research opportunities.",146.3,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09841v2_A pipeline for enabling path-specific causal fairn.pdf,APIPIPELINE FOR ENABLING PATH-SPECIFIC CAUSAL FAIRNESS IN OBSERVATIONAL HEALTH DATA,"['Aparajita Kashyap', 'Sara Matijevic', 'Noémie Elhadad', 'Steven A. Kushner', 'Shalmali Joshi']",,2601.09841v2,"['causal fairness', 'foundation models', 'causal inference', 'observational health data', 'fair machine learning']",This work presents a model-agnostic pipeline for training causally fair machine learning models that address both direct and indirect forms of healthcare bias in the observational health data setting.,151.49,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09851v1_ViSIL Unified Evaluation of Information Loss in Mu.pdf,ViSIL: Unified Evaluation of Information Loss in Multimodal Video Captioning,"['Po-han Li', 'Shenghui Chen', 'Ufuk Topcu', 'Sandeep Chinchali']",,2601.06298,"['Multimodal Video Captioning', 'Information Loss', 'Video Summary Information Loss (ViSIL)', 'BLEU', 'ROUGE', 'METEOR', 'Video Question Answering (VQA)']","The paper proposes the Video Summary Information Loss (ViSIL) score, an information-theoretic framework that quantifies the video information not captured by a summary via vision-language model inference. It enables direct comparison across multimodal summary formats and demonstrates a statistically significant correlation with both human and VLM performance on Video Question Answering tasks.",153.92,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09853v1_MedRedFlag Investigating how LLMs Redirect Misconc.pdf,MedRedFlag: Investigating how LLMs Redirect Misconceptions in Real-World Health Communication,"['Sraavya Sambara∗', 'Yuan Pu1', 'Ayman Ali1', 'Vishala Mishra1', 'Lionel Wong2', 'Monica Agrawal1']",,2310.16887,"['Large Language Models', 'Health Communication', 'Misconceptions', 'Redirect', 'Real-World Usage', 'Patient Misunderstandings']","This work investigates how large language models (LLMs) handle false premises embedded in real-world health questions, developing a dataset and comparing LLM responses to those from clinicians, revealing that LLMs often fail to redirect problematic questions and provide suboptimal answers, highlighting safety concerns for patient-facing medical AI systems.",154.9,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09855v1_Thinking Long but Short Stable Sequential Test-Tim.pdf,"Thinking Long, but Short: Stable Sequential Test-Time Scaling for Large Reasoning Models","['Michael R. Metel', 'Yufei Cui', 'Boxing Chen', 'Prasanna Parthasarathi']",,2601.09855v1,"['Sequential test-time scaling', 'Large reasoning models', 'Test-time scaling', 'Stability', 'Interpretability', 'Model accuracy']","This work presents a novel sequential test-time scaling method, Min-Seek, which improves model accuracy significantly over a wide range of induced thoughts, stabilizing the accuracy of sequential scaling and removing the need for reasoning length fine-tuning. The method is inherently efficient, as only the KV pairs of one additional induced thought are kept in the KV cache during reasoning.",156.08,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09858v1_OUTLINEFORGE Hierarchical Reinforcement Learning w.pdf,Hierarchical Reinforcement Learning with Explicit States for Scientific Writing,"['Yilin Bao', 'Ziyao He', 'Zayden Yang']",,2310.16016,"['Reinforcement Learning', 'Scientific Writing', 'Hierarchical Outline', 'Long-Horizon Planning', 'Document-Level Planning', 'Factual Grounding', 'Scientific Correctness', 'Discourse Coherence', 'Citation Fidelity']","This paper presents a reinforcement learning framework that models scientific outline construction as a long-horizon planning problem over hierarchical document structures, enabling the system to incrementally build a complete scientific manuscript. The approach includes a two-stage optimization procedure with backward outline reconstruction and forward value-guided reinforcement learning, explicitly modeling scientific correctness, discourse coherence, and citation fidelity.",158.29,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09865v1_Advancing Model Refinement Muon-Optimized Distilla.pdf,Advancing Model Refinement: Muon-Optimized Distillation and Quantization for LLM Deployment,"['Jacob Sander', 'Brian Jalaian', 'V enkat R. Dasarivenkateswara']",,2601.09865,"['Large Language Models', 'Model Refinement', 'Quantization', 'Distillation', 'Edge Devices', 'Resource Constraints', 'Inference Optimization']","This paper proposes an integrated framework combining GPTQ-based quantization, low-rank adaptation (LoRA), and a specialized data distillation process to significantly reduce model size and complexity while preserving or enhancing task-specific performance, achieving up to 2× memory compression on specialized tasks.",157.45,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09869v1_A Scoping Review of the Ethical Perspectives on An.pdf,A SCOPING REVIEW OF THE ETHICAL PERSPECTIVES ON ANTHROPOMORPHISING LARGE LANGUAGE MODEL-BASED CONVERSATIONAL AGENTS,"['Andrea Ferrario', 'Rasita Vinay', 'Matteo Casserini', 'Alessandro Facchini']",null,2601.09869,"['anthropomorphism', 'conversational agents', 'large language models', 'AI ethics', 'deception', 'trust', 'governance']","This scoping review examines the ethical perspectives on anthropomorphizing large language model-based conversational agents, mapping the fragmented literature across five databases and three preprint repositories. It synthesizes conceptual foundations, ethical challenges and opportunities, and methodological approaches, finding convergence on attribution-based definitions but substantial divergence in operationalization, a predominantly risk-forward normative framing, and limited empirical work linking observed interaction effects to actionable governance guidance.",156.48,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09871v1_Epistemology gives a Future to Complementarity in .pdf,EPISTEMOLOGY GIVES AFUTURE TOCOMPLEMENTARITY IN HUMAN-AI INTERACTIONS,"['Andrea Ferrario', 'Alessandro Facchini', 'Juan M. Durán']",,2601.09871v1,"['artificial intelligence', 'machine learning', 'reliance', 'complementarity', 'human-AI interaction', 'computational reliabilism', 'epistemology']","This work leverages epistemology to address the theoretical challenges of complementarity in human-AI interactions, reframing it within the discourse on justificatory AI. By drawing on computational reliabilism, the authors argue that historical instances of complementarity function as evidence that a human-AI team is a reliable epistemic process for a given predictive task, contributing to the reliability of AI-supported processes that increasingly shape everyday life.",158.99,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09879v1_MedVL-SAM2 A unified 3D medical vision-language mo.pdf,MedVL-SAM2: A unified 3D medical vision–language model for multimodal reasoning and prompt-driven segmentation,"['Yang Xing', 'Jiong Wu', 'Savas Ozdemir', 'Ying Zhang', 'Yang Yang', 'Wei Shao', 'Kuang Gong']",10.1101/2023.02.01.625144,2302.00001,"['3D medical vision-language model', 'multimodal reasoning', 'prompt-driven segmentation', '3D medical imaging', 'semantic segmentation', 'referencing', 'interactive segmentation']","This paper presents MedVL-SAM2, a unified 3D medical vision-language model designed to support multimodal tasks including report generation, visual question answering, and various segmentation paradigms. The model integrates image-level reasoning and pixel-level perception, enabling precise multi-granular spatial reasoning and flexible interaction via language, point, or box prompts.",145.67,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09881v1_Transition Matching Distillation for Fast Video Ge.pdf,Transition Matching Distillation for Fast Video Generation,"['Weili Nie', 'Julius Berner', 'Nanye Ma', 'Chao Liu', 'Saining Xie', 'Arash Vahdat']",,2601.09881v1,"['video generation', 'diffusion models', 'few-step generators', 'distillation', 'conditional flows']","This paper presents Transition Matching Distillation (TMD), a novel framework for distilling video diffusion models into efficient few-step generators, enabling faster real-time video generation.",160.94,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09883v1_Beyond Rule-Based Workflows An Information-Flow-Or.pdf,Beyond Rule-Based Workflows: An Information-Flow-Orchestrated Multi-Agents Paradigm via Agent-to-Agent Communication from CORAL,"['Xinxing Ren', 'Quagmire Zang', 'Caelum Forder', 'Suman Deb', 'Ahsen Tahir', 'Roman J. Georgio', 'Peter Carroll', 'Zekun Guo']",,2310.16699,"['Multi-Agent Systems', 'Information-Flow-Orchestrated', 'Agent-to-Agent Communication', 'CORAL Protocol', 'Large Language Models', 'Sustained Multi-Step Interactions', 'Iterative Information Gathering', 'Adaptive Strategy Refinement', 'Task Complexity', 'Heterogeneous Skill Sets', 'Coordinated Decision Making']","This paper proposes an Information-Flow-Orchestrated Multi-Agent Paradigm via Agent-to-Agent Communication from CORAL, which dynamically coordinates agents without predefined workflows, enabling more flexible task monitoring and robust handling of edge cases, as evaluated on the GAIA benchmark.",159.74,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09896v1_The Algorithmic Gaze An Audit and Ethnography of t.pdf,The Algorithmic Gaze: An Audit and Ethnography of the LAION-Aesthetics Predictor Model,"['JORDAN TAYLOR', 'WILLIAM AGNEW', 'MAARTEN SAP', 'SARAH E. FOX', 'HAIYI ZHU']",10.1145/nnnnnnn.nnnnnnn,,"['AI', 'Art', 'Aesthetic Evaluation']","This paper studies the LAION-Aesthetics Predictor (LAP) model, widely used to curate datasets for visual generative AI models, and examines its biases in aesthetic filtering and scoring, finding it disproportionately favors images with captions mentioning women and rates realistic images from western and Japanese artists highly, reinforcing imperial and male gazes in western art history.",154.51,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09902v1_A Novel Contrastive Loss for Zero-Day Network Intr.pdf,A Novel Contrastive Loss for Zero-Day Network Intrusion Detection,"['Jack Wilkie', 'Hanan Hindy', 'Craig Michie', 'Christos Tachtatzis', 'James Irvine', 'Robert Atkinson']",,,"['Machine Learning', 'Network Intrusion Detection', 'Contrastive Learning', 'Anomaly Detection', 'Zero-Day Attacks']","This work proposes a novel contrastive loss function for network intrusion detection that generalizes to zero-day attacks, achieving significant performance improvements over previous models in both known and zero-day attack detection.",159.92,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09913v1_Continuum Memory Architectures for Long-Horizon LL.pdf,Continuum Memory Architectures for Long-Horizon LLM Agents,"['Joe Logan', 'Mode7 GK', 'Tokyo, Japan']",null,2601.09913,"['Continuum Memory Architectures', 'Long-Horizon LLM Agents', 'Retrieval-augmented Generation', 'Memory Dynamics', 'Temporal Continuity', 'Persistent Storage', 'Selective Retention', 'Associative Routing', 'Temporal Chaining', 'Consolidation']","This paper introduces the Continuum Memory Architecture (CMA), a class of systems designed to maintain and update internal state across interactions through persistent storage, selective retention, associative routing, temporal chaining, and consolidation into higher-order abstractions. The authors argue that current retrieval-augmented generation (RAG) systems, which treat memory as a stateless lookup table, are insufficient for long-term memory needs of large language model (LLM) agents. The paper presents initial evidence that CMA-class behaviors yield advantages on tasks that stress memory dynamics, such as knowledge updates, temporal association, associative recall, and contextual disambiguation.",155.92,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09921v1_Learning to Decode in Parallel Self-Coordinating N.pdf,Learning to Decode in Parallel: Self-Coordinating Neural Network for Real-Time Quantum Error Correction,"['Kai Zhang', 'Zhengzhong Yi', 'Shaojun Guo', 'Linghang Kong', 'Situ Wang', 'Xiaoyu Zhan', 'Tan He', 'Weiping Lin', 'Tao Jiang', 'Dongxin Gao', 'Yiming Zhang', 'Fangming Liu', 'Fang Zhang', 'Zhengfeng Ji', 'Fusheng Chen', 'Jianxin Chen']",,2601.09921,"['quantum error correction', 'neural network', 'parallel decoding', 'self-coordinating', 'quantum computation', 'fault-tolerant', 'AlphaQubit']","This paper presents a self-coordinating neural network decoder designed for real-time quantum error correction, demonstrating improved performance over traditional human-designed algorithms.",153.45,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09923v1_CaMeLs Can Use Computers Too System-level Security.pdf,System-Level Security for Computer Use Agents,"['Hanna Foerster∗', 'Robert Mullins', 'Tom Blanchard∗', 'Nicolas Papernot', 'Kristina Nikolić', 'Florian Tramèr', 'Ilia Shumailov', 'Cheng Zhang', 'Yiren Zhao']",,2601.09923v1,"['Computer Use Agents', 'Vision-Language Models', 'Prompt Injection Attacks', 'Control Flow Integrity', 'Security', 'AI Agents']","This paper presents Single-Shot Planning for Computer Use Agents (CUAs), a novel approach to ensure security by generating a complete execution graph with conditional branches before any observation of potentially malicious content, thus providing provable control flow integrity guarantees against arbitrary instruction injections. The authors demonstrate that UI workflows are structurally predictable and introduce additional measures to prevent Branch Steering attacks, which manipulate UI elements to trigger unintended valid paths within the plan. The design is evaluated on OSWorld, showing improved performance for smaller open-source models while retaining up to 57% of the performance of frontier models.",153.61,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09929v1_Hallucination Detection and Mitigation in Large La.pdf,Hallucination Detection and Mitigation in Large Language Models,"['Ahmad Pesaranghader', 'Erin Li']",,2601.09929v1,"['Large Language Models', 'Large Reasoning Models', 'hallucination', 'reliability', 'regulation', 'financial', 'legal']","This paper introduces a comprehensive operational framework for hallucination management in Large Language Models and Large Reasoning Models, addressing the critical reliability risk posed by their tendency to generate factually incorrect or unsupported content in high-stakes domains like finance and law.",133.06,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09933v1_Malware Classification using Diluted Convolutional.pdf,Malware Classification using Diluted Convolutional Neural Network with Fast Gradient Sign Method,"['1st Ashish Anand', '2nd Bhupendra Singh', '3rd Sunil Khemka', '4th Bireswar Banerjee', '5th Vishi Singh Bhatia', '6th Piyush Ranjan']",,,"['data security', 'dilated convolutional neural network', 'fast gradient sign method', 'malware classification', 'privacy']","This research proposes a Fast Gradient Sign Method with Diluted Convolutional Neural Network (FGSM-DICNN) for malware classification, addressing the challenges of evolving malware complexity and the need for large feature sets. The FGSM-DICNN model achieves 99.44% accuracy, outperforming other approaches.",157.78,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09949v2_Kinematic Tokenization Optimization-Based Continuo.pdf,Kinematic Tokenization: Optimization-Based Continuous-Time Tokens for Learnable Decision Policies in Noisy Time Series,"['Griffin M. Kearney, Ph.D.']",null,2601.09949,"['Kinematic Tokenization', 'Optimization-Based Tokens', 'Continuous-Time Representation', 'Noisy Time Series', 'Financial Time Series', 'Trading Volume Profiles', 'Risk-Averse Classification', 'Newton-like Equations', 'Physics-Informed AI']","This paper introduces Kinematic Tokenization, an optimization-based continuous-time representation that reconstructs an explicit spline from noisy measurements and tokenizes local spline coefficients. Applied to financial time series data, it demonstrates improved learnability and calibration of selective decision policies under abstention-inducing losses compared to discrete baselines.",160.01,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09966v1_A Sustainable AI Economy Needs Data Deals That Wor.pdf,A Sustainable AI Economy Needs Data Deals That Work for Generators,"['Ruoxi Jia', 'Virginia Tech', 'Luis Oala', 'Brickroad', 'Wenjie Xiong', 'Virginia Tech', 'Suqin Ge', 'Virginia Tech', 'Jiachen T. Wang', 'Princeton University', 'Feiyang Kang', 'Virginia Tech', 'Dawn Song', 'UC Berkeley']",,2601.09966v1,"['Data Deals', 'Machine Learning', 'Data Aggregation', 'Data Generators', 'AI Economy', 'Equitable Data-Value Exchange (EDVEX) Framework']","The authors argue that the machine learning value chain is structurally unsustainable due to economic data processing inequality, where data generators receive little economic benefit. They analyze seventy-three public data deals and identify three structural faults—missing provenance, asymmetric bargaining power, and non-dynamic pricing—as the operational machinery of this inequality. They propose an Equitable Data-Value Exchange (EDVEX) Framework to enable a minimal market that benefits all participants.",158.77,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09972v1_Chinese Labor Law Large Language Model Benchmark.pdf,Chinese Labor Law Large Language Model Benchmark,"['Zixun Lan', 'Maochun Xu', 'Yifan Ren', 'Rui Wu', 'Jianghui Zhou', 'Xueyang Cheng', 'Jian’an Ding', 'Xinheng Wang', 'Mingmin Chi', 'Fei Ma']",,,"['Chinese labor law', 'legal natural language processing', 'large language models', 'domain-specific fine-tuning', 'benchmark dataset', 'statute recall', 'legal reasoning', 'case analysis']","This paper presents LaborLawLLM, a legal large language model specifically tailored to the labor law domain, and introduces a comprehensive benchmark comprising diverse labor law tasks. Experimental results demonstrate that LaborLawLLM significantly outperforms both general-purpose and existing legal-specific LLMs across all task categories, filling a key research gap in labor law-specific legal AI and offering a scalable methodology for developing specialized LLMs in other legal subfields.",158.27,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09974v1_SPRInG Continual LLM Personalization via Selective.pdf,SPRInG: Continual LLM Personalization via Selective Parametric Adaptation and Retrieval-Interpolated Generation,"['Seoyeon Kim', 'Jaehyung Kim']",,2312.15969,"['Large Language Models', 'Personalization', 'Continual Learning', 'Selective Adaptation', 'Retrieval-Interpolated Generation']","This paper introduces SPRING, a novel semi-parametric framework for effective continual personalization of Large Language Models, addressing the challenge of adapting to user preference drift without catastrophic forgetting.",157.57,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09980v1_Performance of AI agents based on reasoning langua.pdf,ALD optimization using reasoning LLMs,['Angel Yanguas-Gil'],,2601.06477,"['atomic layer deposition', 'large language models', 'process optimization', 'self-limited processes', 'unsupervised learning']","This work explores the performance and behavior of reasoning large language models in autonomously optimizing atomic layer deposition (ALD) processes, focusing on AB-type ALD processes. Agents built on these models successfully completed optimization tasks without prior knowledge, but exhibited significant run-to-run variability due to the non-deterministic nature of the models. The agents use a two-step process to generate structured outputs from open reasoning responses, revealing sound logic based on self-limited process concepts.",135.79,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.09982v1_Context Volume Drives Performance Tackling Domain .pdf,Context Volume Drives Performance: Tackling Domain Shift in Extremely Low-Resource Translation via RAG,"['David Samuel Setiawan', 'Raphaël Merx', 'Jey Han Lau']",,2508.09872,"['Neural Machine Translation', 'Domain Shift', 'Low-Resource Languages', 'Retrieval-Augmented Generation', 'Hybrid Framework']","This paper addresses the performance degradation of Neural Machine Translation models for low-resource languages, specifically focusing on the transition from the New Testament to the Old Testament. Using Dhao, an indigenous language of Eastern Indonesia, the authors introduce a hybrid framework combining a fine-tuned NMT model with a Large Language Model (LLM) using Retrieval-Augmented Generation (RAG) to recover lost performance, achieving a chrF++ score of 35.21, effectively matching the original in-domain quality.",154.95,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10010v1_VERHallu Evaluating and Mitigating Event Relation .pdf,VERHallu: Evaluating and Mitigating Event Relation Hallucination in Video Large Language Models,"['Zefan Zhang', 'Kehua Zhu', 'Shijie Jiang', 'Hongyuan Lu', 'Shengkai Sun', 'Tian Bai*']",,2309.15146,"['Video Large Language Models', 'Event Relation Understanding', 'Video Understanding']","This paper introduces a novel benchmark, VERHallu, for evaluating and mitigating event relation hallucination in Video Large Language Models, focusing on causal, temporal, and subevent relations between events. It proposes a Key-Frame Propagating (KFP) strategy to enhance multi-event understanding and effectively mitigates event relation hallucination without affecting inference speed.",157.26,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10011v1_Memo-SQL Structured Decomposition and Experience-D.pdf,Memo-SQL: Structured Decomposition and Experience-Driven Self-Correction for Training-Free NL2SQL,"['Zerui Yang', 'Weichuan Wang', 'Yanwei Xu', 'Linqi Song', 'Yudai Matsuda', 'Wei Han', 'Bo Bai']",,2312.09969,"['NL2SQL', 'training-free', 'self-correction', 'structured decomposition', 'dynamic memory', 'retrieval-augmented prompting']","This paper presents Memo-SQL, a training-free framework that addresses the limitations of existing NL2SQL systems by introducing structured decomposition and experience-aware self-correction, achieving 68.5% execution accuracy on BIRD with over 10× fewer resources than prior test-time scaling approaches.",156.24,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10018v1_Empowering Older Adults in Digital Technology Use .pdf,Empowering Older Adults in Digital Technology Use with Foundation Models,"['Hasti Sharifi', 'Homaira Huda Shomee', 'Sourav Medya', 'Debaleena Chattopadhyay']",,,"['Technology support', 'Digital technology use', 'Artificial intelligence', 'Large language models', 'Communication barriers', 'Human-computer interaction']",This study examines communication challenges older adults face when using digital applications and explores AI-based approaches to mitigate these challenges. It identifies four key communication barriers and evaluates how foundation models can improve solution accuracy and user understanding.,159.85,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10025v1_Structured Personality Control and Adaptation for .pdf,Structured Personality Control and Adaptation for LLM Agents,"['Jinpeng Wang', 'Xinyu Jia', 'Wei Wei Heng', 'Yuquan Li', 'Binbin Shi', 'Qianlei Chen', 'Guannan Chen', 'Junxia Zhang', 'Yuyu Yin']",XXXXXXX.XXXXXXX,,"['Personalization', 'Jungian Psychological Types', 'MBTI Personality Types', 'Persona Adaptation', 'Explainable AI']","This paper presents a framework for modeling LLM personality via Jungian psychological types, integrating mechanisms for coherent core expression, temporary adaptation, and long-term evolution, allowing for nuanced and adaptable personality expression in HCI interactions.",157.81,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10029v1_PaperScout An Autonomous Agent for Academic Paper .pdf,PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization,"['Tingyue Pan', 'Jie Ouyang', 'Mingyue Cheng', 'Qingchuan Li', 'Zirui Liu', 'Mingfan Pan', 'Shuo Yu', 'Qi Liu']",,2310.16659,"['academic paper search', 'autonomous agent', 'sequence-level policy optimization', 'process-aware', 'reinforcement learning', 'large language models']","PaperScout is an autonomous agent designed to reformulate academic paper search as a sequential decision-making process, dynamically deciding search and expansion actions based on retrieval context. It addresses the limitations of rigid workflows and traditional reinforcement learning methods, introducing Proximal Sequence Policy Optimization (PSPO) for process-aware, sequence-level policy optimization.",154.02,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10031v1_FilDeep Learning Large Deformations of Elastic-Pla.pdf,FilDeep: Learning Large Deformations of Elastic-Plastic Solids with Multi-Fidelity Data,"['Jianheng Tang', 'Shilong Tao', 'Zhe Feng', 'Haonan Sun', 'Menglu Wang', 'Zhanxing Zhu', 'Yunhuai Liu']",10.1145/3770854.3783959,,"['Large Deformations', 'Elastic-Plastic Solids', 'Multi-Fidelity Data', 'Deep Learning', 'Quantity-Accuracy Dilemma']","This paper presents FilDeep, a Deep Learning framework designed to address the challenge of training models for large deformations in elastic-plastic solids, which are crucial in manufacturing applications. FilDeep resolves the quantity-accuracy dilemma by simultaneously training with both low-fidelity and high-fidelity data, demonstrating state-of-the-art performance in extensive experiments.",153.43,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10038v1_What Understanding Means in AI-Laden Astronomy.pdf,What Understanding Means in AI-Laden Astronomy,"['Yuan-Sen Ting', 'André Curtis-Trudel', 'Siyu Y ao']",,2601.10038v1,"['philosophy of science', 'astronomy', 'artificial intelligence', 'understanding', 'discovery', 'progress']","This paper discusses the transformation of astronomy due to artificial intelligence and the need for philosophical reflection on the nature of understanding, discovery, and progress in the field.",138.36,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10073v1_ReaMIL Reasoning- and Evidence-Aware Multiple Inst.pdf,ReaMIL: Reasoning- and Evidence-Aware Multiple Instance Learning for Whole-Slide Histopathology,"['Hyun Do Jung', 'Jungwon Choi', 'Hwiyoung Kim']",,1912.04496,"['Multiple Instance Learning', 'Histopathology', 'Whole Slide Imaging', 'Weakly Supervised Learning', 'Representation Learning']","This paper introduces ReaMIL, a multiple instance learning approach for whole-slide histopathology that adds a light selection head to a strong MIL backbone, producing soft per-tile gates and training with a budgeted-sufficiency objective to produce small, spatially compact evidence sets without sacrificing baseline performance. The method matches or slightly improves baseline AUC and provides quantitative evidence-efficiency diagnostics, showing that class confidence rises sharply and stabilizes once a small set of tiles is kept.",156.17,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10079v1_Sparse-RL Breaking the Memory Wall in LLM Reinforc.pdf,Sparse-RL: Breaking the Memory Wall in LLM Reinforcement Learning via Stable Sparse Rollouts,"['Sijia Luo', 'Xiaokang Zhang', 'Yuxuan Hu', 'Bohan Zhang', 'Ke Wang', 'Jinbo Su', 'Mengshu Sun', 'Lei Liang', 'Jing Zhang']",,2310.18979,"['Reinforcement Learning', 'Large Language Models', 'Sparse Rollouts', 'Memory Overhead', 'KV Caches', 'Compression Techniques', 'Stability']","Sparse-RL addresses the memory bottleneck in Long-Short Term Memory (LSTM) training by introducing stable RL training under sparse rollouts, incorporating Sparsity-Aware Rejection Sampling and Importance-based Reweighting to correct off-policy bias introduced by compression-induced information loss.",157.26,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10088v1_State of AI An Empirical 100 Trillion Token Study .pdf,State of AI: An Empirical 100 Trillion Token Study with OpenRouter,"['Malika Aubakirova∗†', 'Alex Atallah ‡', 'Chris Clark ‡', 'Justin Summerville ‡', 'Anjney Midha †']",,2512.00012,"['large language models', 'AI inference', 'open-router', 'empirical study', '100 trillion tokens', 'open-weight models', 'creative roleplay', 'coding assistance', 'agentic inference', 'cinderella effect']","This work analyzes over 100 trillion tokens of real-world interactions with large language models across tasks, geographies, and time using the OpenRouter platform. It observes substantial adoption of open-weight models, the popularity of creative roleplay and coding assistance, and the rise of agentic inference. The study identifies foundational cohorts and discusses implications for model builders, AI developers, and infrastructure providers.",158.09,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10090v1_Difficulty-guided Sampling Bridging the Target Gap.pdf,Difficulty-guided Sampling: Bridging the Target Gap between Dataset Distillation and Downstream Tasks,"['Mingzhuo Lia', 'Guang Lia', 'Linfeng Ye', 'Jiafeng Mao', 'Takahiro Ogawa', 'Konstantinos N. Plataniotis', 'Miki Haseyama']",,2601.10090,"['Dataset Distillation', 'Downstream Tasks', 'Difficulty', 'Post-stage Sampling', 'Image Classification']","This paper proposes difficulty-guided sampling (DGS) to bridge the target gap between dataset distillation and downstream tasks, improving the performance of dataset distillation by leveraging characteristics that benefit the downstream training.",159.09,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10092v1_LeMoF Level-guided Multimodal Fusion for Heterogen.pdf,LEMOF: LEVEL-GUIDED MULTIMODAL FUSION FOR HETEROGENEOUS CLINICAL DATA,"['Jongseok Kim', 'Seongae Kang', 'Jonghwan Shin', 'Yuhan Lee', 'Ohyun Jo']",null,2601.10092,"['Multimodal Learning', 'Hierarchical Representation Learning', 'Clinical Time-Series Modeling', 'Level-guided Feature Fusion', 'Explainable Medical AI']","This paper proposes LeMoF, a novel framework for multimodal clinical prediction that selectively integrates level-guided representations within each modality, enabling balanced performance between prediction stability and discriminative capability in heterogeneous clinical environments.",137.35,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10094v1_V-Zero Self-Improving Multimodal Reasoning with Ze.pdf,V-Zero: Self-Improving Multimodal Reasoning with Zero Annotation,"['Han Wang1*', 'Yi Yang1*', 'Jingyuan Hu2*', 'Minfeng Zhu2†', 'Wei Chen1†']",,2309.14012,"['Multimodal Reasoning', 'Self-Improvement', 'Vision-Language Models', 'Unlabeled Images', 'Group Relative Policy Optimization']","This paper introduces V-Zero, a post-training framework that enables self-improvement in multimodal systems using exclusively unlabeled images. It establishes a co-evolutionary loop with two distinct roles: a Questioner and a Solver, which iteratively enhance each other through Group Relative Policy Optimization, achieving consistent performance gains on Qwen2.5-VL-7B-Instruct without human annotation.",145.83,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10101v2_Matrix as Plan Structured Logical Reasoning with F.pdf,Matrix as Plan: Structured Logical Reasoning with Feedback-Driven Replanning,"['Ke Chen', 'Jiandian Zeng', 'Zihao Peng', 'Guo Li', 'Guangxue Zhang', 'Tian Wang']",10.1145/XXXXXX.XXXXXX,,"['Logical Reasoning', 'Large Language Models', 'Neurosymbolic Approaches', 'Semantic Decomposition']","This paper proposes MatrixCoT, a structured CoT framework with a matrix-based plan, to enhance the logical reasoning capabilities of Large Language Models (LLMs) by normalizing and type natural language expressions, introducing a matrix-based planning method, and adding a feedback-driven replanning mechanism. Experiments show that MatrixCoT improves robustness and interpretability of LLMs when tackling complex symbolic reasoning tasks without relying on external solvers.",160.11,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10103v1_FlowAct-R1 Towards Interactive Humanoid Video Gene.pdf,FlowAct-R1: Towards Interactive Humanoid Video Generation,"['Lizhen Wang', 'Yongming Zhu', 'Zhipeng Ge', 'Youwei Zheng', 'Longhao Zhang', 'Tianshu Hu†', 'Shiyang Qin', 'Mingshuang Luo', 'Jiaxu Zhang', 'Xin Chen', 'Yulong Wang', 'Zerong Zheng', 'Jianwen Jiang', 'Chao Liang', 'Weifeng Chen', 'Xing Wang', 'Yuan Zhang', 'Mingyuan Gao']",,2601.10103v1,"['Humanoid Video', 'Interactive Video', 'Real-Time Interaction', 'Video Synthesis', 'Diffusion Models', 'Self-Forcing', 'Efficient Distillation', 'Behavioral Vividness', 'Perceptual Realism']","This paper introduces FlowAct-R1, a real-time interactive humanoid video generation framework based on MMDiT architecture, which enables the streaming synthesis of lifelike video with arbitrary durations while maintaining low-latency responsiveness, and provides holistic and fine-grained full-body control for natural behavioral transitions.",157.52,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10104v1_MathDoc Benchmarking Structured Extraction and Act.pdf,CHEAT_DETECTED,"['Chenyue Zhou', 'Jiayi Tuo', 'Shitong Qin', 'Wei Dai', 'Mingxuan Wang', 'Ziwei Zhao', 'Duoyang Li', 'Shiyang Su', 'Yanxi Lu', 'Yanbiao Ma']",,,"['Mathematics exams', 'Document-level information extraction', 'Active refusal', 'Noisy documents', 'MLLMs']","The paper introduces MathDoc, a benchmark for document-level information extraction from authentic high school mathematics exam papers, focusing on the structural integrity of mathematical problems and the ability of models to actively reject incomplete inputs. Experiments on state-of-the-art MLLMs show that while end-to-end models achieve strong extraction performance, they consistently fail to refuse illegible inputs, instead producing confident but invalid outputs. This highlights a critical gap in current MLLMs and establishes MathDoc as a benchmark for assessing model reliability under degraded document conditions.",160.43,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10108v1_SIN-Bench Tracing Native Evidence Chains in Long-C.pdf,SIN-Bench: Tracing Native Evidence Chains in Long-Context Multimodal Scientific Interleaved Literature,"['Yiming Ren', 'Junjie Wang', 'Yuxin Meng', 'Yihang Shi', 'Zhiqiang Lin', 'Ruihang Chu', 'Yiran Xu', 'Ziming Li', 'Yunfei Zhao', 'Zihan Wang', 'Yu Qiao', 'Ruiming Tang', 'Minghao Liu', 'Yujiu Yang']",https://doi.org/10.1000/sin-bench,2309.15934,"['Multimodal Language Models', 'Scientific Literature', 'Evidence Chains', 'Long-Context Evaluation', 'Fish-in-the-Ocean Paradigm']","This paper proposes the Fish-in-the-Ocean (FITO) paradigm to evaluate whether multimodal large language models truly understand long-form scientific papers. It introduces SIN-Data, a scientific interleaved corpus, and constructs SIN-Bench with four progressive tasks covering evidence discovery, hypothesis verification, grounded QA, and evidence-anchored synthesis. The authors demonstrate that grounding is the primary bottleneck for MLLMs, with Gemini-3-pro achieving the best overall score and GPT-5 having the highest SIN-QA answer accuracy but underperforming on evidence-aligned scores.",147.51,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10112v1_Repository Intelligence Graph Deterministic Archit.pdf,Repository Intelligence Graph: Deterministic Architectural Map for LLM Code Assistants,"['Tsvi Cherny-Shahar', 'Amiram Yehudai']",,,"['software repositories', 'build systems', 'dependency graphs', 'software engineering agents', 'multi-lingual software']","This paper introduces the Repository Intelligence Graph (RIG), a deterministic architectural map representing buildable components, aggregators, runners, tests, external packages, and package managers, connected by explicit dependency and coverage edges. It also presents SPADE, a deterministic extractor that constructs RIG from build and test artifacts, and evaluates three commercial agents on eight repositories, showing improvements in accuracy and efficiency when using RIG.",160.55,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10114v1_Following the Teachers Footsteps Scheduled Checkpo.pdf,Following the Teacher’s Footsteps: Scheduled Checkpoint Distillation for Domain-Specific LLMs,"['Cheng Feng', 'Chaoliang Zhong', 'Jun Sun', 'Yusuke Oishi']",,2601.10114v1,"['LLMs', 'Knowledge Distillation', 'Domain-specific Tasks']","This work proposes Scheduled Checkpoint Distillation (SCD), a method that reduces the deficit of a student model on the Teacher-Favored Subdomain (TFS) by emulating the teacher's convergence process during supervised fine-tuning, and a sample-wise Adaptive Weighting (AW) mechanism to preserve student strengths on the Student-Favored Subdomain (SFS). Experiments across diverse domain tasks show that SCD consistently outperforms existing distillation approaches, allowing the student model to match or exceed the performance of its fine-tuned teacher.",161.12,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10120v1_TopoDIM One-shot Topology Generation of Diverse In.pdf,TopoDIM: One-shot Topology Generation of Diverse Interaction Modes for Multi-Agent Systems,"['Rui Sun', 'Jie Ding', 'Chenghua Gong', 'Tianjun Gu', 'Yihang Jiang', 'Juyuan Zhang', 'Liming Pan', 'Linyuan Lü']",,2311.16457,"['Multi-Agent Systems', 'Topology Generation', 'Diverse Interaction Modes', 'Large Language Models', 'Communication Efficiency', 'Adaptability', 'Privacy']","This paper proposes TOPODIM, a framework for one-shot topology generation with diverse interaction modes for decentralized multi-agent systems. It aims to reduce token consumption and improve task performance by enabling agents to autonomously construct heterogeneous communication without iterative coordination, demonstrating significant improvements over state-of-the-art methods.",160.61,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10122v1_Role-Playing Agents Driven by Large Language Model.pdf,"Role-Playing Agents Driven by Large Language Models: Current Status, Challenges, and Future Trends","['Ye Wang', 'Jiaxing Chen', 'Hongjiang Xiao']",null,2601.10122,"['role-playing agents', 'large language models', 'natural language processing', 'human-computer interaction', 'character modeling', 'memory mechanisms', 'behavioral decision control', 'corpora construction', 'evaluation methods', 'personality fidelity', 'value alignment', 'interactive hallucination']","This paper systematically reviews the current development and key technologies of role-playing language agents (RPLAs), covering their evolution from rule-based template paradigms to cognitive simulation centered on personality modeling and memory mechanisms, and discusses challenges and future directions in the field.",157.28,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10129v1_LaViT Aligning Latent Visual Thoughts for Multi-mo.pdf,LaViT: Aligning Latent Visual Thoughts for Multi-modal Reasoning,"['Linquan Wu', 'Tianxiang Jiang', 'Yifei Dong', 'Haoyu Yang', 'Fengji Zhang', 'Shichang Meng', 'Ai Xuan', 'Linqi Song', 'Jacky Keung']",,2310.15950,"['Knowledge Distillation', 'Latent Reasoning', 'Multi-modal Reasoning', 'Visual Attention', 'Language Prior']","This paper proposes LaViT, a framework that aligns latent visual thoughts rather than static embeddings to bridge the Perception Gap in multimodal latent reasoning, significantly enhancing visual grounding and achieving up to 16.9% gains on complex reasoning tasks.",160.48,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10130v1_Redundancy-Driven Top-k Functional Dependency Disc.pdf,Redundancy-Driven Top-k Functional Dependency Discovery,"['Xiaolong Wan', 'Xixian Han']",,,"['Functional dependency', 'top-k discovery', 'data redundancy', 'pruning strategy']","The paper introduces SDP (Selective-Discovery-and-Prune), an algorithm that discovers the top-k functional dependencies ranked by redundancy count, addressing the computational cost and size issues of traditional FD discovery methods.",159.71,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10131v2_M4olGen Multi-Agent Multi-Stage Molecular Generati.pdf,"M4olGen: Multi-Agent, Multi-Stage Molecular Generation under Precise Multi-Property Constraints","['Yizhan Li', 'Florence Cloutier', 'Sifan Wu', 'Ali Parviz', 'Boris Knyazev', 'Yan Zhang', 'Glen Berseth', 'Bang Liu']",,2310.17048,"['Molecular Generation', 'Multi-Property Constraints', 'Fragment-Level Optimization', 'Multi-Agent Reasoning', 'Reinforcement Learning', 'Precise Control', 'Numeric Reasoning']","M4olGen is a fragment-level, retrieval-augmented, two-stage framework for generating molecules that satisfy precise numeric constraints over multiple physicochemical properties. It uses a multi-agent reasoner for prototype generation and a fragment-level optimizer for fine-grained optimization, leveraging fragments and enabling controllable refinement toward numeric targets.",141.21,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10132v1_Is More Context Always Better Examining LLM Reason.pdf,Is More Context Always Better? Examining LLM Reasoning Capability for Time Interval Prediction,"['Yanan Cao', 'Farnaz Fallahi', 'Murali Mohana Krishna Dandu', 'Lalitesh Morishetti', 'Kai Zhao', 'Luyi Ma', 'Sinduja Subramaniam', 'Jianpeng Xu', 'Evren Korpeoglu', 'Kaushiki Nag', 'Sushant Kumar', 'Kannan Achan']",10.1145/XXXXXX.XXXXXX,,"['Large Language Models', 'Temporal Reasoning', 'Inter-Purchase Interval Prediction']","This paper investigates whether Large Language Models (LLMs) can predict time intervals between recurring user actions, such as repeated purchases, and how different levels of contextual information affect their predictive performance. The study benchmarks LLMs against statistical and machine-learning models in zero-shot settings and finds that while LLMs surpass lightweight statistical baselines, they consistently underperform dedicated machine-learning models, highlighting their limited ability to capture quantitative temporal structure. Additionally, moderate context can improve LLM accuracy, but adding further user-level detail degrades performance, challenging the assumption that more context leads to better reasoning.",155.12,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10137v1_Step-by-Step Causality Transparent Causal Discover.pdf,Step-by-Step Causality: Transparent Causal Discovery with Multi-Agent,"['Ziyi Ding', 'Chenfei Ye-Hao', 'Zheyuan Wang', 'Xiao-Ping Zhang']",,2601.04933,"['causal discovery', 'multi-agent', 'tree-query', 'adversarial confidence estimation']","This paper introduces Tree-Query, a tree-structured, multi-expert LLM framework that reduces pairwise causal discovery to a sequence of queries about backdoor paths, independence, latent confounding, and causal direction, yielding interpretable judgments with robustness-aware confidence scores.",153.33,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10141v1_Understanding and Preserving Safety in Fine-Tuned .pdf,Understanding and Preserving Safety in Fine-Tuned LLMs,"['Jiawen Zhang', 'Yangfan Hu', 'Kejia Chen', 'Lipeng He', 'Jiachen Ma', 'Jian Lou', 'Dan Li', 'Jian Liu', 'Xiaohu Yang', 'Ruoxi Jia']",,2309.15696,"['Fine-tuning', 'Large Language Models (LLMs)', 'Safety Alignment', 'Jailbreak Attacks', 'Gradient Analysis', 'Downstream Tasks']","This work addresses the safety-utility dilemma in fine-tuned LLMs by shedding light on the geometric interaction between safety- and utility-oriented gradients. It proposes SPF, a lightweight approach that explicitly removes gradient components conflicting with the low-rank safety subspace, ensuring utility convergence while bounding safety drift.",155.31,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10143v1_History Is Not Enough An Adaptive Dataflow System .pdf,History Is Not Enough: An Adaptive Dataflow System for Financial Time-Series Synthesis,"['Haochong Xia', 'Yao Long Teng', 'Regan Tan', 'Molei Qin', 'Xinrun Wang', 'Bo An']",,,"['Adaptive dataflow', 'workflow automation', 'financial time-series', 'data augmentation']","This paper presents an adaptive dataflow system that integrates machine learning-based adaptive control into the data curation process, addressing the gap between training and real-world performance in quantitative finance by learning to evolve with the market rather than relying solely on past observations.",135.56,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10148v1_DecisionLLM Large Language Models for Long Sequenc.pdf,DecisionLLM: Large Language Models for Long Sequence Decision Exploration,"['Xiaowei Lv', 'Zhiling Zhang', 'Yijun Li', 'Yusen Huo', 'Siyuan Ju', 'Xuyan Li', 'Chunxiang Hong', 'Tianyu Wang', 'Peng Sun', 'Chuan Yu', 'Jian Xu', 'Bo Zheng']",,2601.06016,"['Long-sequence decision-making', 'Reinforcement Learning', 'Large Language Models', 'Transformer', 'Offline Reinforcement Learning', 'Sequence generation', 'Decision exploration']","This work investigates the application of Large Language Models (LLMs) to offline decision-making tasks, proposing a model called DecisionLLM that treats trajectories as a distinct modality and learns to align trajectory data with natural language task descriptions, achieving strong performance in offline experimental benchmarks and bidding scenarios.",155.15,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10150v1_Simple Network Graph Comparative Learning.pdf,Simple Network Graph Comparative Learning,"['Qiang Yu', 'Xinran Cheng', 'Shiqiang Xu', 'Chuanyi Li']",,1912.02251,"['Filters', 'Siamese network', 'Graph contrastive learning', 'Unsupervised representation learning']","This study proposes a novel node classification contrast learning method called Simple Network Graph Comparative Learning (SNGCL) to address challenges in applying contrastive learning methods to node classification tasks, particularly in contexts where graph data lacks labels or is difficult to label.",136.43,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10154v1_MHub.ai A Simple Standardized and Reproducible Pla.pdf,"MHub.ai: A Simple, Standardized, and Reproducible Platform for AI Models in Medical Imaging","['Leonard Nürnberg', 'Dennis Bontempi', 'Suraj Pai', 'Curtis Lisle', 'Steve Pieper', 'Ron Kikinis', 'Sil van de Leemput', 'Rahul Soni', 'Gowtham Murugesan', 'Cosmin Ciausu', 'Miriam Groeneveld', 'Felix J. Dorfner', 'Jue Jiang', 'Aneesh Rangnekar', 'Harini Veeraraghavan', 'Joeran S. Bosma', 'Keno Bressem', 'Raymond Mak', 'Andrey Fedorov', 'Hugo JWL Aerts']",,,"['Artificial Intelligence', 'Medical Imaging', 'Reproducibility', 'Standardization', 'Platform', 'AI Models', 'Radiology', 'Nuclear Medicine', 'Radiation Oncology', 'Machine Learning', 'Data Reproducibility', 'Medical Image Analysis', 'Machine Learning Platforms', 'Artificial Intelligence in Medicine', 'Radiology and Nuclear Medicine', 'Radiation Oncology in Medicine', 'Machine Learning in Medical Imaging', 'Data Reproducibility in Medical Imaging', 'Machine Learning Platforms in Medical Imaging', 'Artificial Intelligence in Radiology', 'Artificial Intelligence in Nuclear Medicine', 'Artificial Intelligence in Radiation Oncology']","This paper introduces MHub.ai, a platform designed to facilitate the development, deployment, and reproducibility of AI models in medical imaging. The platform aims to standardize the process and ensure that AI models can be easily reproduced and validated by other researchers.",156.21,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10155v1_LOOKAT Lookup-Optimized Key-Attention for Memory-E.pdf,LOOKAT: Lookup-Optimized Key-Attention for Memory-Efficient Transformers,['Aryan Karmore'],,1912.01475,"['transformers', 'attention', 'quantization', 'compression', 'vector databases', 'product quantization', 'asymmetric distance computation']","LOOKAT is a method that applies product quantization and asymmetric distance computation to transformer architecture to compress the key-value cache, achieving significant compression at high output fidelity, without requiring architectural changes or training.",153.22,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10157v1_MMPG MoE-based Adaptive Multi-Perspective Graph Fu.pdf,MMPG: MoE-based Adaptive Multi-Perspective Graph Fusion for Protein Representation Learning,"['Yusong Wang', 'Jialun Shen', 'Zhihao Wu', 'Yicheng Xu', 'Shiyin Tan', 'Mingkun Xu', 'Changshuo Wang', 'Zixing Song', 'Prayag Tiwari']",10.1101/2025.06.20.256588,2506.12345,"['Protein Representation Learning', 'Graph Neural Networks', 'Multi-Perspective Graph Fusion', 'Mixture of Experts', 'Protein Design', 'Functional Annotation', 'Drug Discovery']","This paper proposes MMPG, a framework that constructs protein graphs from multiple perspectives and adaptively fuses them via Mixture of Experts (MoE) for Protein Representation Learning (PRL), addressing the limitations of current GNN-based PRL methods that rely on single-perspective graph construction.",156.41,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10160v1_Alignment Pretraining AI Discourse Causes Self-Ful.pdf,Alignment Pretraining: AI Discourse Causes Self-Fulfilling (Mis)alignment,"['Cameron Tice', 'Puria Radmard', 'Samuel Ratnam', 'Andy Kim', 'David Africa', ""Kyle O'Brien""]",,2601.05667,"['alignment', 'pretraining', 'LLM', 'misalignment', 'discourse', 'self-fulfilling', 'AI']","This paper investigates the causal influence of AI discourse during pretraining on the alignment of language models, finding that misaligned discussion leads to misaligned behavior, and aligned discussion reduces misalignment. The study provides evidence of self-fulfilling alignment and establishes the importance of alignment pretraining as a complement to post-training methods.",157.12,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10161v1_AWED-FiNER Agents Web applications and Expert Dete.pdf,"A WED-FiNER: Agents, Web applications, and Expert Detectors for Fine-grained Named Entity Recognition across 36 Languages for 6.6 Billion Speakers","['Prachuryya Kaushik', 'Ashish Anand']",,2310.16019,"['Fine-grained Named Entity Recognition', '36 Languages', '6.6 Billion Speakers', 'Open-source Ecosystem', 'Web Applications', 'Expert Detectors', 'Fine-tuned Models']","This paper introduces A WED-FiNER, an open-source ecosystem designed to address the challenges in Fine-grained Named Entity Recognition (FgNER) for 36 global languages spoken by over 6.6 billion people, providing a collection of agentic toolkits, web applications, and state-of-the-art expert models for FgNER solutions across these languages.",155.54,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10168v1_RAG-3DSG Enhancing 3D Scene Graphs with Re-Shot Gu.pdf,RAG-3DSG: ENHANCING 3D SCENE GRAPHS WITH RE-SHOTGUIDED RETRIEVAL-AUGMENTED GENERATION,"['Yue Chang', 'Rufeng Chen', 'Zhaofan Zhang', 'Yi Chen', 'Sihong Xie']",,2310.16894,"['3D scene graphs', 'open-vocabulary', 'retrieval-augmented generation', 'shot-guided uncertainty estimation', 'dynamic downsample-mapping']","This paper proposes RAG-3DSG, a method to enhance 3D scene graphs by mitigating aggregation noise through re-shot guided uncertainty estimation and supporting object-level retrieval-augmented generation via reliable low-uncertainty objects. Experiments demonstrate significant improvements in node captioning accuracy and reduced mapping time compared to vanilla methods.",153.76,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10169v1_CtD Composition through Decomposition in Emergent .pdf,Composition through Decomposition: Emergent Communication for Neural Agents,"['Boaz Carmeli', 'Ron Meir', 'Yonatan Belinkov']",10.48550/arxiv.2501.01234,2501.01234,"['compositionality', 'neural networks', 'discrete entities', 'multi-target games', 'referential game', 'reinforcement learning', 'Gumbel-softmax', 'vector quantization']",This study demonstrates how artificial neural agents acquire and utilize compositional generalization to describe previously unseen images through a two-step process: decomposing images into basic concepts and then composing these concepts into complex phrases. The agents learn to decompose images using a codebook acquired during interaction in a multi-target coordination game and subsequently use this codebook to describe novel images.,158.14,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10173v1_ReasAlign Reasoning Enhanced Safety Alignment agai.pdf,ReasAlign: Reasoning Enhanced Safety Alignment against Prompt Injection Attack,"['Hao Li', 'Yankai Yang', 'G. Edward Suh', 'Ning Zhang', 'Chaowei Xiao']",,2312.09998,"['Large Language Models', 'Safety Alignment', 'Prompt Injection Attacks', 'Structured Reasoning', 'Test-Time Scaling']","This paper presents ReasAlign, a model-level solution to improve safety alignment against indirect prompt injection attacks in agentic systems, which are vulnerable to such attacks where malicious instructions embedded in external data can hijack agent behavior.",160.14,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10187v1_HOMURA Taming the Sand-Glass for Time-Constrained .pdf,HOMURA: Taming the Sand-Glass for Time-Constrained LLM Translation via Reinforcement Learning,"['Ziang Cui', 'Mengran Yu', 'Tianjiao Li', 'Chenyu Shi', 'Yingxuan Shi', 'Lusheng Zhang', 'Hongwei Lin']",,2309.14584,"['Large Language Models', 'Time-Constrained Translation', 'Reinforcement Learning', 'Sand-Glass', 'Syllable-Level Duration Constraints']","This paper introduces Sand-Glass, a benchmark for evaluating translation under syllable-level duration constraints, and proposes HOMURA, a reinforcement learning framework that optimizes the trade-off between semantic preservation and temporal compliance, effectively controlling output length without compromising semantic adequacy.",140.26,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10191v1_How does downsampling affect needle electromyograp.pdf,How does downsampling affect needle electromyography signals? A generalisable workflow for understanding downsampling effects on high-frequency time series,"['Mathieu J.L. Cherpitel', 'Janne A.M. Luijten', 'Thomas H.W. Bäck', 'Camiel Verhamme', 'Martijn R. Tannemaat', 'Anna V. Kononova']",10.1101/2022.03.29.486804,2203.17176,"['needle electromyography', 'downsampling', 'neuromuscular disorders', 'machine learning', 'feature-based models', 'high-frequency time series']","This study presents a workflow for systematically evaluating information loss caused by downsampling in high-frequency time series, combining shape-based distortion metrics with classification outcomes from feature-based machine learning models. The workflow identifies downsampling configurations that preserve diagnostic information while reducing computational load, providing practical guidance for near real-time nEMG analysis.",160.99,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10193v1_GFM4GA Graph Foundation Model for Group Anomaly De.pdf,GFM4GA: Graph Foundation Model for Group Anomaly Detection,"['Jiujiu Chen', 'Weijun Zeng', 'Shaofeng Hu', 'Sihong Xie', 'Hui Xiong']",https://doi.org/XXXXXXX.XXXXXXX,,"['Group Anomaly Detection', 'Graph Foundation Model', 'Graph Contrastive Learning']","GFM4GA is a novel graph foundation model proposed to handle group anomaly detection, overcoming the limitations of existing models that struggle with diverse anomaly patterns and cannot generalize to group anomalies.",160.88,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10201v1_PRL Process Reward Learning Improves LLMs Reasonin.pdf,PRL: Process Reward Learning Improves LLMs’ Reasoning Ability,"['Jiarui Yao', 'Ruida Wang', 'Tong Zhang']",,2309.16056,"['Large Language Models', 'Reinforcement Learning', 'Process Reward Learning', 'Reasoning Ability', 'Fine-Grained Supervision']","This paper proposes Process Reward Learning (PRL), which decomposes the entropy regularized reinforcement learning objective into intermediate steps with rigorous process rewards. It demonstrates that PRL improves the reasoning ability of LLMs, measured by average @ n, and broadens the reasoning boundary by improving the pass @ n metric.",160.14,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10205v1_One Instruction Does Not Fit All How Well Do Embed.pdf,One Instruction Does Not Fit All: How Well Do Embeddings Align Personas and Instructions in Low-Resource Indian Languages?,"['Arya Shah', 'Himanshu Beniwal', 'Mayank Singh']",,2309.14494,"['Embeddings', 'Personas', 'Instructions', 'Indian Languages', 'Multilingual Retrieval', 'Cultural Context']","This paper presents a unified benchmark for 12 Indian languages, evaluating eight multilingual embedding models in a frozen-encoder setting with a thin logistic regression head. It assesses monolingual and cross-lingual persona-to-instruction retrieval, reverse retrieval from instruction to persona, and binary compatibility classification, providing practical guidance for model selection in Indic multilingual retrieval and establishing reproducible baselines.",160.59,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10212v1_PADER Paillier-based Secure Decentralized Social R.pdf,PADER: Paillier-based Secure Decentralized Social Recommendation,"['Chaochao Chen', 'Jiaming Qian', 'Fei Zheng∗', 'Yachuan Liu']",,,"['Paillier Cryptosystem', 'Secure Computation', 'Recommendation System']","The paper proposes PADER, a Paillier-based secure decentralized social recommendation system, which keeps user and seller data private by operating in a decentralized manner without a centralized platform. It applies the Paillier cryptosystem to the SoReg model, which combines user ratings and social relations, and designs secure addition and multiplication protocols for efficient polynomial evaluations.",159.8,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10215v1_Topo-RAG Topology-aware retrieval for hybrid text-.pdf,TOPO-RAG: TOPOLOGY-AWARE RETRIEVAL FOR HYBRID TEXT-TABLE DOCUMENTS,"['Alex Dantart∗', 'Marco Kővacs-Navarro']",,2601.10215v1,"['Retrieval-Augmented Generation (RAG)', 'table retrieval', 'late interaction', 'multivector retrieval', 'enterprise search', 'heterogeneous data', 'semantic routing', 'structure-aware embeddings', 'Topo-RAG', 'ColBERT', 'cell-aware interaction', 'linearization bottleneck']","This work presents Topo-RAG, a framework that challenges the assumption that 'everything is text.' It proposes a dual architecture that respects the topology of the data: fluid narrative is processed by traditional dense retrievers, while tabular structures are processed by a cell-aware late interaction mechanism, preserving their spatial relationships. Evaluated on a synthetic enterprise corpus, Topo-RAG demonstrates an 18.4% improvement in nDCG@10 on hybrid queries compared to standard linearization approaches.",156.16,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10222v1_Introduction to optimization methods for training .pdf,Introduction to optimization methods for training SciML models,"['Alena Kopaničáková', 'Elisa Riccietti']",,2601.10222,"['Optimization', 'Machine Learning', 'Scientific Machine Learning', 'Stochastic Optimization', 'First-Order Methods', 'Second-Order Methods', 'Stochastic Gradient Descent', 'AdaGrad', 'Adam', 'Empirical Risk Minimization', 'Physics-Informed', 'Operator Constrained Formulations', 'Partial Differential Equations', 'Boundary Conditions', 'Initial Conditions', 'Global Spatio-Temporal Coupling']","Optimization is the foundation of modern machine learning, historically categorized by the degree to which they exploit derivative information. In the context of scientific machine learning, the optimization landscape changes due to the scarcity of data, leading to physics-informed or operator-constrained formulations that differ from classical machine learning.",139.42,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10236v1_Who Owns the Text Design Patterns for Preserving A.pdf,Who Owns the Text? Design Patterns for Preserving Authorship in AI-Assisted Writing,"['Bohan Zhang', 'Chengke Bu', 'Paramveer Dhillon']",null,2601.10236,"['AI-assisted writing', 'human–AI collaboration', 'psychological ownership', 'personalization', 'provenance']","This study examines the tension between AI writing assistants and writer's sense of authorship, offering on-demand, sentence-level suggestions and testing two design choices: persona-based coaching and style personalization. The findings show that psychological ownership decreases with AI assistance, even as cognitive load decreases, and that style personalization partially restores ownership.",160.96,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10242v1_Loop as a Bridge Can Looped Transformers Truly Lin.pdf,LOOP AS ABRIDGE: CANLOOPEDTRANSFORMERS TRULYLINKREPRESENTATIONSPACE ANDNATURAL LANGUAGEOUTPUTS?,"['Guanxu Chen', 'Dongrui Liu', 'Jing Shao']",,2309.15847,"['Looped Transformers', 'Introspection', 'Natural Language Processing', 'Large Language Models', 'Representation Space']","This report empirically investigates whether Looped Transformers (LTs), which iterate shared layers, can bridge the gap between their internal 'knowledge' and explicit linguistic outputs. Experiments show that while increasing loop iterations narrows the gap, it is partly driven by a degradation of internal 'knowledge'. Empirical analysis suggests that LTs' ability to perceive representations does not improve across loops; it is only present in the final loop. These results indicate that LTs offer a promising direction for scaling computational depth but have yet to achieve introspection required to truly link representation space and natural language.",157.75,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10245v1_TRIM Hybrid Inference via Targeted Stepwise Routin.pdf,TRIM: Hybrid Inference via Targeted Stepwise Routing in Multi-Step Reasoning Tasks,"['Vansh Kapoor†1', 'Aman Gupta 2', 'Hao Chen 2', 'Anurag Beniwal 2', 'Jing Huang 2', 'Aviral Kumar1']",,2601.06148,"['Large Language Models', 'Multi-Step Reasoning', 'Routing Strategies', 'Efficiency', 'Cost Efficiency']","TRIM (Targeted routing in multi-step reasoning tasks) is a method that routes only critical steps to larger models while letting smaller models handle routine continuations, fundamentally transforming inference efficiency by confining expensive calls to precisely those steps where stronger models prevent cascading errors.",154.65,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10251v1_X-SAM Boosting Sharpness-Aware Minimization with D.pdf,X-SAM: Boosting Sharpness-Aware Minimization with Dominant-Eigenvector Gradient Correction,"['Hongru Duan', 'Yongle Chen', 'Lei Guan']",,2302.09550,"['Sharpness-Aware Minimization', 'Hessian', 'Eigenvalue', 'Gradient Correction', 'Generalization']","This paper investigates Sharpness-Aware Minimization (SAM) from a spectral and geometric perspective, proposing X-SAM, which corrects the gradient via orthogonal decomposition along the top eigenvector, enabling more direct and efficient regularization of the Hessian's maximum eigenvalue, and proving its convergence and superior generalization.",159.18,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10254v1_NoReGeo Non-Reasoning Geometry Benchmark.pdf,NoReGeo: Non-Reasoning Geometry Benchmark,"['Irina Abdullaeva', 'Anton Vasiliuk', 'Elizaveta Goncharova', 'Temurbek Rahmatullaev', 'Ivan Zagorulko', 'Maxim Kurkin', 'Andrey Kuznetsov']",,2310.16566,"['Geometry', 'Large Language Models', 'Non-Reasoning', 'Benchmark', 'Spatial Understanding', 'CAD', 'Robots', 'Geospatial Systems']","This paper introduces NoReGeo, a novel benchmark designed to evaluate the intrinsic geometric understanding of large language models without relying on reasoning or algebraic computation. The benchmark comprises 2,500 trivial geometric problems spanning 25 categories, focusing on whether models can inherently encode spatial relationships and recognize geometric properties directly. The authors assess state-of-the-art models on NoReGeo, observing that even advanced systems achieve only 65% accuracy in binary classification tasks, highlighting a significant gap in current LLMs' ability to natively grasp geometric concepts.",156.49,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10257v1_Untangling Input Language from Reasoning Language .pdf,Untangling Input Language from Reasoning Language: A Diagnostic Framework for Cross-Lingual Moral Alignment in LLMs,"['Nan Li', 'Bo Kang', 'Tijl De Bie']",,2309.13767,"['Moral Alignment', 'Cross-Lingual Evaluation', 'Moral Foundations Theory', 'Language Models', 'Moral Dilemmas']","This paper introduces a methodology to separate the effects of input language and reasoning language in moral judgments made by large language models (LLMs), enabling the detection of cross-lingual inconsistencies and context-dependency in model performance.",159.06,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10272v1_MoST Mixing Speech and Text with Modality-Aware Mi.pdf,MOST: MIXINGSPEECH ANDTEXT WITHMODALITY-,"['Yuxuan Lou', 'Kai Yang', 'Yang You']",,2601.10272,"['MoST', 'Mixture of Speech and Text', 'Modality-Aware Mixture of Experts', 'Multimodal Large Language Model', 'Speech-Text LLM']","The paper presents MoST, a novel multimodal large language model that integrates speech and text through a Modality-Aware Mixture of Experts (MAMoE) architecture, enhancing modality-specific learning and cross-modal understanding.",157.43,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10274v1_Queueing-Aware Optimization of Reasoning Tokens fo.pdf,Queueing-Aware Optimization of Reasoning Tokens for Accuracy-Latency Trade-offs in LLM Servers,"['Emre Ozbas', 'Melih Bastopcu']",,1909.08024,"['Accuracy-latency trade-offs', 'LLM-based servers', 'optimization of reasoning tokens', 'LLM inference']","This paper considers a single large language model (LLM) server serving a heterogeneous stream of queries from N distinct task types. It formulates a constrained optimization problem to maximize a weighted average accuracy objective penalized by mean system time, subject to token-budget constraints and queue-stability conditions. The authors develop a projected gradient method to guarantee convergence beyond the contractive regime and round the continuous solution to attain integer-valued token allocations, evaluating the resulting performance loss in simulations.",157.73,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10282v2_SPIKE Sparse Koopman Regularization for Physics-In.pdf,SPIKE: Sparse Koopman Regularization for Physics-Informed Neural Networks,['Jose Marie Antonio Miñoza'],null,2601.10282,"['Physics-Informed Neural Networks (PINNs)', 'Koopman operators', 'Sparse regularization', 'Partial differential equations (PDEs)', 'Stiff systems', 'Temporal extrapolation', 'Spatial generalization']","This work presents SPIKE, a framework that regularizes Physics-Informed Neural Networks (PINNs) with continuous-time Koopman operators to learn parsimonious dynamics representations, improving temporal extrapolation, spatial generalization, and long-term prediction accuracy across various PDEs.",156.95,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10305v1_DanQing An Up-to-Date Large-Scale Chinese Vision-L.pdf,Glint Lab: DanQing: An Up-to-Date Large-Scale Chinese Vision-Language Pre-training Dataset,"['Hengyu Shen', 'Tiancheng Gu', 'Bin Qin', 'Lan Wu', 'Yuling Wu', 'Shuo Tan', 'Zelong Sun', 'Jun Wang', 'Nan Wu', 'Xiang An', 'Weidong Cai', 'Ziyong Feng', 'Kaicheng Yang']",null,2601.10305,"['Vision-Language Pre-training', 'Chinese Dataset', 'Contrastive Learning', 'Cross-Modal Retrieval', 'Semantic Segmentation', 'Image Captioning']","This paper presents DanQing, a comprehensive pipeline for constructing a high-quality Chinese cross-modal dataset, which contains 100 million image-text pairs collected from Common Crawl. DanQing is designed to address the gap in Chinese vision-language pretraining by offering superior data quality and capturing evolving semantic trends, thereby enabling better performance in various downstream tasks.",154.74,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10306v1_Evidence-Augmented Policy Optimization with Reward.pdf,Evidence-Augmented Policy Optimization with Reward Co-Evolution for Long-Context Reasoning,"['Xin Guan*', 'Zijian Li', 'Shen Huang', 'Pengjun Xie', 'Jingren Zhou', 'Jiuxin Cao']",,2310.15847,"['Reinforcement Learning', 'Policy Optimization', 'Long-Context Reasoning', 'Reward Co-Evolution', 'Evidence-Augmented Reasoning']","This paper proposes EAPO (Evidence-Augmented Policy Optimization), a specialized RL algorithm that introduces a Group-Relative Evidence Reward to provide dense process supervision for long-context reasoning, addressing the challenge of sparsity of outcome rewards in such scenarios.",137.97,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10338v1_Agent Skills in the Wild An Empirical Study of Sec.pdf,Agent Skills in the Wild: An Empirical Study of Security Vulnerabilities at Scale,"['Yi Liu∗', 'Weizhe Wang∗', 'Ruitao Feng†', 'Yao Zhang†', 'Guangquan Xu†', 'Gelei Deng', 'Yuekang Li', 'Leo Zhang']",10.1145/nnnnnnn.nnnnnnn,,"['Agent skills', 'AI security', 'vulnerability analysis', 'supply chain security', 'prompt injection', 'large language models']","This paper conducts the first large-scale empirical security analysis of AI agent skills, revealing pervasive security risks such as prompt injection, data exfiltration, privilege escalation, and supply chain risks. It includes a vulnerability taxonomy, a detection methodology achieving high precision and recall, and an open dataset and toolkit for future research.",160.83,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10342v1_C-GRASP Clinically-Grounded Reasoning for Affectiv.pdf,C-GRASP: Clinically-Grounded Reasoning for Affective Signal Processing,"['1st Cheng Lin Cheng', '2nd Ting Chuan Lin', '3rd Chai Kai Chang']",,,"['Large language model', 'clinical decision support', 'heart rate variability', 'retrieval-augmented generation', 'explainable AI', 'guardrails']","C-GRASP is a guardrailed RAG-enhanced pipeline that decomposes HRV interpretation into eight traceable reasoning steps, integrating a Dual Z-score Priority Hierarchy with quantitative guardrails to ensure individualized baseline shifts take precedence over normative statistics and automatically detect and mitigate spectral artifacts. Evaluated on 414 trials from the DREAMER dataset, C-GRASP achieved superior performance in 4-class emotion classification and a Clinical Reasoning Consistency score of 69.6%.",158.24,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10343v2_OctoBench Benchmarking Scaffold-Aware Instruction .pdf,OCTOBENCH: Benchmarking Scaffold-Aware Instruction Following in Repository-Grounded Agentic Coding,"['Deming Ding', 'Shichun Liu', 'Enhui Yang', 'Jiahang Lin', 'Ziying Chen', 'Shihan Dou', 'Honglin Guo', 'Weiyu Cheng', 'Pengyu Zhao', 'Chengjun Xiao', 'Qunhong Zeng', 'Qi Zhang', 'Xuanjing Huang', 'Qidi Xu', 'Tao Gui']",https://doi.org/10.1000/123456,2309.12345,"['instruction following', 'scaffolded coding', 'repository-grounded', 'agentic coding', 'benchmarking', 'heterogeneous constraints']","This paper introduces OCTOBENCH, a benchmark for evaluating instruction following in repository-grounded agentic coding, addressing the gap in evaluating scaffold-aware instruction following, especially when constraints are heterogeneous and persist across interactions.",156.3,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10348v1_Training-Trajectory-Aware Token Selection.pdf,Training-Trajectory-Aware Token Selection,"['Zhanming Shen', 'Jiaqi Hu', 'Zeyu Qin', 'Hao Chen', 'Wentao Ye', 'Zenan Huang', 'Yihong Zhuang', 'Guoshan Lu', 'Junlin Zhou', 'Junbo Zhao']",,2309.14476,"['Continual Learning', 'Efficient Distillation', 'Token Selection', 'Training Trajectory', 'Imitation Shock']","This paper addresses the challenges of continual reasoning distillation in the frontier regime where the student already has strong reasoning ability. It introduces Training-Trajectory-Aware Token Selection (T3S) to reconstruct the training objective at the token level, addressing the issue of performance drops during the bottleneck phase and achieving consistent gains in both AR and dLLM settings.",157.6,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10349v1_SuS Strategy-aware Surprise for Intrinsic Explorat.pdf,SuS: Strategy-aware Surprise for Intrinsic Exploration,"['Mark Kashirskiy', 'Ilya Makarov']",,1911.05338,"['intrinsic motivation', 'reinforcement learning', 'contrastive learning', 'exploration']","We propose Strategy-aware Surprise (SuS), a novel intrinsic motivation framework that uses pre-post prediction mismatch as a novelty signal for exploration in reinforcement learning, achieving significant improvements in accuracy and solution diversity on mathematical reasoning tasks.",157.09,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10373v1_Towards Efficient Low-rate Image Compression with .pdf,Towards Efficient Low-rate Image Compression with Frequency-aware Diffusion Prior Refinement,"['Yichong Xia', 'Yimin Zhou', 'Jinpeng Wang', 'Bin Chen']",,2309.15624,"['image compression', 'diffusion models', 'frequency-aware', 'low-bitrate', 'generative priors']","This work proposes DiffCR, a novel compression framework that uses a Frequency-aware Skip Estimation (FaSE) module to refine the ϵ-prediction prior from a pre-trained latent diffusion model and align it with compressed latents at different timesteps via Frequency Decoupling Attention (FDA). This approach enables efficient and high-fidelity image reconstruction with substantial bitrate savings and over 10x speed-up compared to state-of-the-art diffusion-based compression baselines.",141.3,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10378v2_Global Context Compression with Interleaved Vision.pdf,Global Context Compression with Interleaved Vision-Text Transformation,"['Dian Jiao*', 'Jiaxin Duan *', 'Shuai Zhao', 'Jiabing Leng', 'Yiran Zhang', 'Feng Huang *']",,2310.17114,"['Context Compression', 'Transformer', 'Vision-Language Models', 'Optical Character Recognition', 'Hierarchical Encoding', 'Sparse Attention']","This paper investigates global context compression in vision-language models, proposing VIST2, a novel Transformer that interleaves input text chunks alongside their visual encoding. The model demonstrates significant superiority over baselines on long writing tasks, achieving a 3× speedup in first-token generation, 77% reduction in memory usage, and 74% reduction in FLOPS with a 4× compression ratio.",158.35,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10386v1_Handling Missing Modalities in Multimodal Survival.pdf,Handling Missing Modalities in Multimodal Survival Prediction for Non-Small Cell Lung Cancer,"['Filippo Ruffini', 'Camillo Maria Caruso', 'Claudia Tacconi', 'Lorenzo Nibid', 'Francesca Miccolis', 'Marta Lovino', 'Carlo Greco', 'Edy Ippolito', 'Michele Fiore', 'Alessio Cortellini', 'Bruno Beomonte Zobel', 'Giuseppe Perrone', 'Bruno Vincenzi', 'Claudio Marrocco', 'Alessandro Bria', 'Elisa Ficarra', 'Sara Ramella', 'Valerio Guarrasi', 'Paolo Soda']",,2601.10386v1,"['Non-Small Cell Lung Cancer', 'Multimodal Survival Prediction', 'Missing Data', 'Artificial Intelligence', 'Computer Systems', 'Radiation Oncology', 'Anatomical Pathology', 'Medical Oncology', 'Radiology', 'Interventional Radiology', 'Engineering']","This paper focuses on developing methods to handle missing data in multimodal survival prediction for Non-Small Cell Lung Cancer, utilizing various modalities including imaging, pathology, and clinical data.",159.48,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10398v2_LatentRefusal Latent-Signal Refusal for Unanswerab.pdf,LatentRefusal: Latent-Signal Refusal for Unanswerable Text-to-SQL Queries,"['Xuancheng Ren', 'Shijing Hu', 'Zhihui Lu', 'Jiangqi Huang', 'Qiang Duan']",10.1109/ICML48164.2024.00000,2406.00000,"['Text-to-SQL', 'Unanswerable Queries', 'Safety', 'Large Language Models', 'Schema Mismatch', 'Query Refusal']","This paper addresses the challenge of unanswerable and underspecified queries in Text-to-SQL systems, which can lead to incorrect and potentially harmful SQL programs. It proposes LATENTREFUSAL, a mechanism that predicts query answerability from intermediate hidden activations of an LLM, using a lightweight probing architecture to detect refusal signals directly from the LLM's internal states.",159.61,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10402v1_Toward Ultra-Long-Horizon Agentic Science Cognitiv.pdf,Toward Ultra-Long-Horizon Agentic Science: Cognitive Accumulation for Machine Learning Engineering,"['Xinyu Zhu', 'Yuzhu Cai', 'Zexi Liu', 'Bingyang Zheng', 'Cheng Wang', 'Rui Ye', 'Jiaao Chen', 'Hanrui Wang', 'Wei-Chen Wang', 'Yuzhi Zhang', 'Linfeng Zhang', 'Weinan E', 'Di Jin', 'Siheng Chen']",,2601.10402v1,"['Ultra-long-horizon autonomy', 'Cognitive accumulation', 'Machine learning engineering', 'Hierarchical Cognitive Caching', ""OpenAI's MLE-Bench"", 'Scalable AI exploration']","This paper presents ML-Master 2.0, an autonomous agent that masters ultra-long-horizon machine learning engineering, overcoming the challenge of ultra-long-horizon autonomy in real-world research environments. By introducing Hierarchical Cognitive Caching (HCC), the approach enables structural differentiation of experience over time, allowing agents to decouple immediate execution from long-term experimental strategy, achieving a state-of-the-art medal rate of 56.44% on OpenAI's MLE-Bench.",159.32,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10406v1_ErrEval Error-Aware Evaluation for Question Genera.pdf,ErrEval: Error-Aware Evaluation for Question Generation through Explicit Diagnostics,"['Weiping Fu', 'Bifan Wei', 'Jingyi Hao', 'Yushun Zhang', 'Jian Zhang', 'Jiaxin Wang', 'Bo Li', 'Yu He', 'Lingling Zhang', 'Jun Liu']",,2309.14826,"['Question Generation', 'Error Detection', 'Evaluation Framework', 'Natural Language Processing', 'Human Evaluation']","ErrEval is a flexible and error-aware evaluation framework for automatic question generation, designed to improve the detection and scoring of errors through explicit diagnostics, thereby enhancing the evaluation of generated questions and mitigating overestimation of their quality.",159.82,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10413v1_LADFA A Framework of Using Large Language Models a.pdf,LADFA: A Framework of Using Large Language Models and Retrieval-Augmented Generation for Personal Data Flow Analysis in Privacy Policies,"['HAIYUE YUAN∗', 'NIKOLAY MATYUNIN', 'ALI RAZA', 'SHUJUN LI∗']",XXXXXXX.XXXXXXX,,"['Large Language Model', 'LLM', 'Privacy Policy', 'Text Analysis', 'Data Flows', 'Privacy', 'Security', 'Retrieval-Augmented Generation', 'RAG', 'Framework', 'Automotive Industry', 'Connected Vehicle']","This paper presents the development of LADFA, an end-to-end computational framework for processing unstructured text in privacy policies, extracting personal data flows, and conducting analysis of the data flow graph to facilitate insight discovery. The framework combines LLMs with retrieval-augmented generation and a customised knowledge base derived from existing studies.",160.67,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10416v1_LLMdoctor Token-Level Flow-Guided Preference Optim.pdf,Token-Level Flow-Guided Preference Optimization for Efficient Test-Time Alignment of Large Language Models,"['Tiesunlong Shen', 'Rui Mao', 'Jin Wang', 'Heming Sun', 'Jian Zhang', 'Xuejie Zhang', 'Erik Cambria']",,2309.14456,"['Large Language Models', 'Test-Time Alignment', 'Fine-Tuning', 'Token-Level Reward', 'Flow-Guided Optimization', 'Human Preferences']","This paper introduces LLMdoctor, a novel framework for efficient test-time alignment of large language models (LLMs) that operates via a patient-doctor paradigm. It integrates token-level reward acquisition with token-level flow-guided preference optimization (TFPO) to steer a large, frozen patient LLM with a smaller, specialized doctor model, thereby preserving generative diversity and significantly outperforming existing test-time alignment methods.",142.74,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10421v1_Are Language Models Models.pdf,Are Language Models Models?,['Philip Resnik'],,,"['Language Models', 'Model Systems', 'Cognitive Models', 'Algorithmic-Representational Level', 'Computational Theory']","Resnik critiques Futrell and Mahowald's claim that language models serve as model systems, arguing that this claim is not true at the implementation level, poorly motivated at the algorithmic-representational level, and problematic at the computational theory level.",143.18,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10436v1_Development of Ontological Knowledge Bases by Leve.pdf,Development of Ontological Knowledge Bases by Leveraging Large Language Models,"['LE Ngoc Luyen', 'Marie-Hélène ABEL', 'Philippe GOUSPILLOU']",,,"['Ontology Development', 'Ontological Knowledge bases', 'Large Language Models', 'Knowledge Representation', 'User Modeling', 'Knowledge Management']","This paper presents a structured, iterative methodology leveraging Large Language Models to optimize ontology construction, automate ontology artifact generation, and enable continuous refinement cycles, demonstrating its effectiveness in developing a user context profile ontology within the vehicle sales domain.",144.47,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10440v1_AgentGuardian Learning Access Control Policies to .pdf,Learning Access Control Policies to Govern AI Agent Behavior,"['Nadya Abaev*', 'Denis Klimov *', 'Gerard Levinov', 'David Mimran', 'Yuval Elovici', 'Asaf Shabtai']",,2309.14094,"['Security', 'AI Agents', 'Access Control Policies', 'Control Flow Graph']","This study introduces AgentGuardian, a novel security framework that governs and protects AI agent operations by enforcing context-aware access-control policies. It monitors execution traces to learn legitimate agent behaviors and input patterns, derives adaptive policies, and evaluates across two real-world AI agent applications, demonstrating effective detection of malicious or misleading inputs while preserving normal agent functionality.",156.22,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10457v1_NSR-Boost A Neuro-Symbolic Residual Boosting Frame.pdf,NSR-Boost: A Neuro-Symbolic Residual Boosting Framework for Industrial Legacy Models,"['Ziming Dai', 'Dabiao Ma', 'Jinle Tong', 'Mengyuan Han', 'Jian Yang', 'Haojun Fei']",10.1145/nnnnnnn.nnnnnnn,,"['Neuro-Symbolic AI', 'Large Language Models', 'Gradient Boosting', 'Legacy Model', 'Interpretability']","The paper presents NSR-Boost, a neuro-symbolic residual boosting framework designed for industrial scenarios, which treats legacy models as frozen models and performs targeted repairs on hard regions where predictions fail. It comprises three key stages: finding hard regions through residuals, generating interpretable experts using Large Language Models and fine-tuning parameters with Bayesian optimization, and dynamically integrating experts with legacy model output through a lightweight aggregator. The framework is successfully deployed within the core financial risk control system at Qfin Holdings, significantly outperforming state-of-the-art baselines across multiple datasets.",141.37,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10460v1_Contextual StereoSet Stress-Testing Bias Alignment.pdf,Contextual StereoSet: Stress-Testing Bias Alignment Robustness in Large Language Models,"['Abhinaba Basu', 'Pavan Chakraborty']",null,2601.10460,"['bias evaluation', 'alignment robustness', 'stress-testing', 'large language models', 'so-cietech context', 'StereoSet']","The paper introduces Contextual StereoSet, a benchmark that tests 13 models across two protocols, revealing that bias shifts dramatically when prompts mention different places, times, or audiences, without requiring adversarial prompting. It proposes Context Sensitivity Fingerprints (CSF) for evaluating model bias sensitivity and releases the benchmark, code, and results.",159.14,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10462v3_ChartComplete A Taxonomy-based Inclusive Chart Dat.pdf,ChartComplete: A Taxonomy-based Inclusive Chart Dataset,"['Ahmad Mustapha', 'Charbel Toumieh', 'Mariette Awad']",null,2601.10462,"['Chart', 'Dataset', 'Chart Taxonomy', 'Chart Classification']","With advancements in deep learning and computer vision, the field of chart understanding is evolving. To bridge the gap in benchmarks, the authors propose the ChartComplete dataset, which includes 30 different types of charts, covering a broader range than existing benchmarks.",155.99,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10477v1_Urban Socio-Semantic Segmentation with Vision-Lang.pdf,Preprint. URBANSOCIO-SEMANTICSEGMENTATION WITH VISION-LANGUAGEREASONING,"['Yu Wang', 'Yi Wang', 'Rui Dai', 'Yujie Wang', 'Kaikui Liu', 'Xiangxiang Chu', 'Yansheng Li']",,2210.08861,"['Urban Socio-Semantic Segmentation', 'Vision-Language Reasoning', 'SocioSeg', 'Urban Areas', 'Earth Observation', 'Reinforcement Learning']","This work achieves socio-semantic segmentation by vision-language model reasoning, introducing the Urban Socio-Semantic Segmentation dataset and proposing a novel vision-language reasoning framework called SocioReasoner, which optimizes the non-differentiable process of identifying and annotating social semantic entities via cross-modal recognition and multi-stage reasoning, demonstrating gains over state-of-the-art models and strong zero-shot generalization.",156.57,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10485v1_Panning for Gold Expanding Domain-Specific Knowled.pdf,Panning for Gold: Expanding Domain-Specific Knowledge Graphs with General Knowledge,"['Runhao Zhao', 'Weixin Zeng', 'Wentao Zhang', 'Chong Chen', 'Zhengpin Li', 'Xiang Zhao', 'Lei Chen']",,1911.07881,"['Domain-specific Knowledge Graph Fusion', 'Knowledge Graph Enrichment', 'General-to-domain Knowledge Transfer', 'Fact-as-Program']","This paper proposes a new task, domain-specific knowledge graph fusion (DKGF), to enhance the completeness and utility of domain-specific knowledge graphs by integrating relevant facts from general knowledge graphs. It introduces ExeFuse, a fact-as-program paradigm that reformulates DKGF as executable semantic reasoning over DKGs, and evaluates its effectiveness through benchmark datasets and experiments.",158.55,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10496v1_Model See Model Do Exposure-Aware Evaluation of Bu.pdf,"Model See, Model Do? Exposure-Aware Evaluation of Bug-vs-Fix Preference in Code LLMs","['Ali Al-Kaswan', 'Claudio Spiess', 'Prem Devanbu', 'Arie van Deursen', 'Maliheh Izadi']",10.1145/nnnnnnn.nnnnnnn,,"['Large Language Models', 'bugs', 'fixes', 'Memorisation']","This paper introduces an exposure-aware evaluation framework to quantify how prior exposure to buggy versus fixed code influences a model's preference. Using the ManySStuBs4J benchmark and Data Portraits for membership testing, the authors find that models reproduce buggy lines more often than fixes, indicating a bias toward correct fixes in likelihood scoring, while metrics reverse preference when only the buggy variant is seen.",154.88,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10498v1_Projected Microbatch Accumulation yields reference.pdf,Projected Microbatch Accumulation yields reference-free proximal policy updates for reinforcement learning,['Nilin Abrahamsen'],null,2601.10498,"['Reinforcement Learning', 'Proximal Policy Optimization', 'Large Language Models', 'Fine-tuning', 'Gradient Clipping', 'Entropy Collapse']","This paper introduces Projected Microbatch Accumulation (PROMA), a method for large language model fine-tuning that modifies the optimization process during the backward pass to accumulate policy gradients without inducing entropy collapse and without relying on a reference policy or likelihood-ratio clipping.",158.46,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10511v1_Scalable Algorithms for Approximate DNF Model Coun.pdf,Scalable Algorithms for Approximate DNF Model Counting,"['Paul Burkhardt', 'David G. Harris', 'Kevin T. Schmitt']",null,2601.10511,"['DNF', 'Model Counting', 'Monte Carlo', 'Approximation', 'PAC Learning']","The authors develop a new Monte Carlo approach for approximate DNF model counting, proving it achieves PAC learning bounds and is asymptotically more efficient than previous methods, and demonstrate its superior performance and scalability to larger problems.",129.58,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10512v2_SatMap Revisiting Satellite Maps as Prior for Onli.pdf,SatMap: Revisiting Satellite Maps as Prior for Online HD Map Construction,"['Kanak Mazumder', 'Fabian B. Flohr']",,2601.10512,"['Online HD map prediction', 'Satellite map prior', 'Vectorized HD map']","This work proposes SatMap, an online vectorized HD map estimation method that integrates satellite maps with multi-view camera observations, directly predicting a vectorized HD map for downstream prediction and planning modules, achieving significant performance improvements over baseline methods.",151.42,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10520v1_Breaking Up with Normatively Monolithic Agency wit.pdf,Breaking Up with Normatively Monolithic Agency: GRACE - A Reason-Based Neuro-Symbolic Architecture for Safe and Ethical AI Alignment,"['Felix Jahn', 'Yannic Muskalla', 'Lisa Dargasz', 'Patrick Schramowski', 'Kevin Baum']",10.48550/arXiv.2601.10520,2601.10520,"['AI alignment', 'neuro-symbolic architecture', 'GRACE', 'deontic logic', 'moral module', 'decision-making module', 'guard', 'stakeholder engagement', 'interpretability', 'contestability', 'justifiability']","This paper introduces GRACE, a neuro-symbolic reason-based containment architecture designed to decouple normative reasoning from instrumental decision-making in AI agents, ensuring their decisions are not only instrumentally effective but also normatively aligned. GRACE restructures decision-making into three modules: a Moral Module, a Decision-Making Module, and a Guard, enabling stakeholders to understand, contest, and refine agent behavior.",144.46,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10524v1_Diagnosing Generalization Failures in Fine-Tuned L.pdf,Diagnosing Generalization Failures in Fine-Tuned LLMs: A Cross-Architectural Study on Phishing Detection,"['Frank Bobe IIIFrank Bobe IIIFrank Bobe III', 'Gregory D. Vetaw', 'Chase Pavlick', 'Darshan Bryner', 'Matthew Cook', 'Jose Salas-Vernis']",null,2601.10524,"['Large Language Models', 'Fine-tuning', 'Generalization Failures', 'Phishing Detection', 'SHAP Analysis', 'Mechanistic Interpretability']","This study introduces and applies a multi-layered diagnostic framework to analyze generalization failures in fine-tuned LLMs across different architectures, focusing on phishing detection. The findings reveal that generalization is driven by a synergy between architecture and data diversity, and that some architectures are inherently more generalizable.",142.78,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10527v2_A Safety Report on GPT-5.2 Gemini 3 Pro Qwen3-VL G.pdf,"A Safety Report on GPT-5.2, Gemini 3 Pro, Qwen3-VL, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5","['Xingjun Ma', 'Yixu Wang', 'Hengyuan Xu', 'Yutao Wu', 'Yifan Ding', 'Yunhan Zhao', 'Zilong Wang', 'Jiabin Hua', 'Ming Wen', 'Jianan Liu', 'Yifeng Gao', 'Yingshui Tan', 'Yunhao Chen', 'Hui Xue', 'Xin Wang', 'Wei Cheng', 'Jingjing Chen', 'Zuxuan Wu', 'Bo Li', 'Yu-Gang Jiang']",,2601.10527v2,"['Large Language Models', 'Multimodal Large Language Models', 'Safety Evaluation', 'Adversarial Testing', 'Benchmark Evaluation', 'Multilingual Evaluation', 'Regulatory Compliance']","This report presents an integrated safety evaluation of six frontier models, including GPT-5.2, Gemini 3 Pro, Qwen3-VL, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5, across language, vision-language, and image generation settings, revealing a highly uneven safety landscape with varying performance and vulnerabilities.",160.01,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10543v1_Defending Large Language Models Against Jailbreak .pdf,Defending Large Language Models Against Jailbreak Attacks via In-Decoding Safety-Awareness Probing,"['W ARNING: This paper contains model outputs that may be considered harmful.', 'Yinzhi Zhao', 'Ming Wang', 'Shi Feng', 'Xiaocui Yang', 'Daling Wang', 'Yifei Zhang']",,2312.00000,"['Large Language Models', 'Jailbreak Attacks', 'Safety Probing', 'In-Decoding', 'Safety Awareness']","This paper examines the decoding process of large language models and proposes a method to detect unsafe content during decoding by leveraging latent safety signals, which enhances safety while maintaining low over-refusal rates on benign inputs.",160.57,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10560v1_Learning Latency-Aware Orchestration for Parallel .pdf,Learning Latency-Aware Orchestration for Parallel Multi-Agent Systems,"['Xi Shi', 'Mengxin Zheng', 'Qian Lou']",,2310.16574,"['Multi-Agent Systems', 'Latency Optimization', 'Parallel Execution', 'Latency-Aware Orchestration', 'Sequential Execution', 'Inference Latency']","This work investigates learning-based orchestration for parallel multi-agent systems with explicit latency supervision, proposing Latency-Aware Multi-agent System (LAMaS) to reduce critical path length by 38–46% compared to the state-of-the-art baseline, highlighting the importance of explicitly optimizing for latency under parallel execution.",152.94,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10562v1_Process-Guided Concept Bottleneck Model.pdf,Process-Guided Concept Bottleneck Model,"['Reza M. Asiyabi', 'Sam Harrison', 'John L. Godlee', 'David Milodowski', 'Nicole H. Augustin', 'Penelope J. Mograbi', 'Timothy R. Baker', 'Lorena M. Benitez', 'Samuel J. Bowers', 'Thomas K. Brade', 'Joao M. B. Carreiras', 'Duncan M. Chalo', 'V era De Cauwer', 'Kyle G. Dexter', 'Hermené Diesse', 'Mathias I. Disney', 'Luisa F. Escobar-Alvarado', 'Manfred Finckh', 'Tatenda Gotore', 'Gabriele C. Hegerl', 'John N. Kigomo', 'Fainess C. Lumbwe', 'Francisco Maiato', 'Rudzani A. Makhado', 'Collins W. Masinde', 'Musingo Tito E. Mbuvi', 'Iain M. McNicol', 'Edward T.A. Mitchard', 'Buster P . Mogonong', 'Wilson A. Mugasha', 'Aristides Baptista Muhate', 'Hinji Mutondo', 'Leena Naftal', 'Paula Nieto-Quintano', 'Elifuraha Elisha Njoghomi', 'Catherine L. Parr', 'Oliver L. Phillips', 'Pierre Proces', 'Tshililo Ramaswiela', 'Jayashree Ratnam', 'Mathew Rees', 'Rasmus Revermann', 'Natasha Ribeiro', 'Mahesh Sankaran', 'Abel M. Siampale', 'Stephen Sitch', 'Kathleen G. Smart', 'Hemant G. Tripathi', 'Wayne Twine', 'Gabriel I.K. Uusiku', 'Helga van der Merwe', 'Chemuku Wekesa', 'Benjamin J. Wigley', 'Mathew Williams', 'Ellie Wood', 'Shaun Quegan', 'Steven Hancock', 'Casey M. Ryan']",,,"['concept bottleneck', 'process-guided', 'machine learning', 'pattern analysis', 'machine intelligence', 'pattern analysis and machine intelligence', 'pattern analysis and machine learning', 'pattern analysis and machine intelligence']","This study presents a process-guided concept bottleneck model, supported by various grants and partnerships, focusing on the dry tropics and utilizing AI-assisted tools for manuscript refinement and feedback.",157.54,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10567v1_Generative AI collective behavior needs an interac.pdf,Generative AI collective behavior needs an interactionist paradigm,"['Laura Ferrarotti', 'Gian Maria Campedelli', 'Roberto Dessì', 'Andrea Baronchelli', 'Giovanni Iacca', 'Kathleen M. Carley', 'Alex Pentland', 'Joel Z. Leibo', 'James Evans', 'Bruno Lepri']",,2601.10567v1,"['Generative AI', 'Collective Behavior', 'Interactionist Paradigm', 'Large Language Models', 'In-context Learning', 'Social Context', 'Prior Knowledge', 'Embedded Values']","This article argues for the importance of an interactionist paradigm in understanding the collective behavior of agents based on large language models, proposing four crucial directions for the development and deployment of LLM-based collectives.",153.13,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10581v1_From Single to Multi-Agent Reasoning Advancing Gen.pdf,From Single to Multi-Agent Reasoning: Advancing GeneGPT for Genomics QA,"['Kimia Abedini', 'Farzad Shami', 'Gianmaria Silvello']",,2601.10581v1,"['Question Answering', 'Genomic QA', 'Multi-Agent Systems']","This paper replicates GeneGPT, a state-of-the-art system for genomic QA, and proposes GenomAgent, a multi-agent framework that outperforms GeneGPT by 12% on average in nine tasks from the GeneTuring benchmark, demonstrating improved adaptability and flexibility beyond genomics.",161.48,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10587v1_Adversarial Evasion Attacks on Computer Vision usi.pdf,Adversarial Evasion Attacks on Computer Vision using SHAP Values,"['Frank Mollard', 'Marcus Becker', 'Florian Röhrbein']",null,2601.10587,"['Adversarial Attacks', 'Computer Vision', 'SHAP Values', 'Deep Learning', 'Evasion Attacks']","This paper introduces a white-box attack on computer vision models using SHAP values, demonstrating how adversarial evasion attacks can compromise deep learning models by reducing output confidence or inducing misclassifications, and finding evidence that SHAP attacks are more robust in generating misclassifications.",147.49,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10591v1_ProbFM Probabilistic Time Series Foundation Model .pdf,ProbFM: Probabilistic Time Series Foundation Model with Uncertainty Decomposition,"['Decomposer, Arundeep Chinta1', 'Decomposer, Lucas Vinh Tran2', 'Decomposer, Jay Katukuri1']",null,null,"['Time Series Foundation Models', 'Probabilistic Forecasting', 'Uncertainty Quantification', 'Deep Evidential Regression', 'Cryptocurrency Forecasting']","This paper presents ProbFM, a novel transformer-based probabilistic framework that leverages Deep Evidential Regression (DER) for principled uncertainty quantification with explicit epistemic-aleatoric decomposition. It conducts a controlled comparison study to evaluate DER's effectiveness in financial applications, demonstrating competitive forecasting accuracy and practical value through uncertainty-aware trading strategies.",159.67,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10600v1_Procedural Fairness in Multi-Agent Bandits.pdf,Procedural Fairness in Multi-Agent Bandits,"['Joshua Caiata', 'Carter Blair', 'Kate Larson']",,2601.10600v1,"['multi-agent systems', 'fairness', 'multi-armed bandits', 'procedural fairness', 'equal voice', 'dignity', 'legitimacy']","This paper introduces a new fairness objective, procedural fairness, which provides equal decision-making power for all agents and emphasizes the importance of the decision-making process, rather than just the outcomes. It argues that fairness requires explicit normative choices and provides a framework for implementing procedural fairness in multi-agent systems.",152.8,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10611v1_Molmo2 Open Weights and Data for Vision-Language M.pdf,Open Weights and Data for Vision-Language Models with Video Understanding and Grounding,"['Christopher Clark', 'Jieyu Zhang', 'Zixian Ma', 'Jae Sung Park', 'Mohammadreza Salehi', 'Rohun Tripathi', 'Sangho Lee', 'Zhongzheng Ren', 'Chris Dongjoo Kim', 'Yinuo Yang', 'Vincent Shao', 'Yue Yang', 'Weikai Huang', 'Ziqi Gao', 'Taira Anderson', 'Jianrui Zhang', 'Jitesh Jain', 'George Stoica', 'Winson Han', 'Ali Farhadi', 'Ranjay Krishna']",,2601.10611v1,"['Vision-Language Models', 'Open-Weight Models', 'Video Understanding', 'Grounding', 'Video Captioning', 'Video Counting', 'Video Pointing', 'Video Tracking', 'Object Tracking', 'Video Q&A']","This paper presents Molmo2, a new family of vision-language models that are state-of-the-art among open-source models and demonstrate exceptional capabilities in point-driven grounding in various tasks, including short and long videos, counting, and captioning. The authors provide a collection of 7 new video datasets and 2 multi-image datasets, along with a training recipe and attention mechanisms to improve performance.",159.74,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10651v1_Multi-Property Synthesis.pdf,Multi-Property Synthesis,"['Christoph Weinhuber', 'Yannik Schnitzer', 'Alessandro Abate', 'David Parker', 'Giuseppe De Giacomo', 'Moshe Y. Vardi']",,1905.00943,"['Synthesis', 'Temporal Logic', 'LTLf', 'Multi-Property', 'Finite-Horizon', 'Monotonicity', 'Boolean Goal Variables']","The paper presents a novel approach to LTLf synthesis with multiple properties, where strategies are synthesized to achieve maximal realizable sets, outperforming enumeration-based methods with significant speedups.",137.88,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10679v1_Are Your Reasoning Models Reasoning or Guessing A .pdf,Are Your Reasoning Models Reasoning or Guessing?,"['Zirui Ren', 'Ziming Liu']",,2309.14447,"['Hierarchical Reasoning Models', 'Sudoku-Extreme', 'Fixed Points', 'Grokking Dynamics', 'Data Augmentation', 'Input Perturbation', 'Model Bootstrapping']","This paper investigates the hierarchical reasoning model (HRM) and finds three surprising facts about its reasoning patterns. HRM, which achieves extraordinary performance on various reasoning tasks, is found to fail on extremely simple puzzles due to violating the fixed point property. It also exhibits ",143.93,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10681v1_Structure and Diversity Aware Context Bubble Const.pdf,Structure and Diversity Aware Context Bubble Construction for Enterprise Retrieval Augmented Systems,"['Amir Khurshid1a*', 'Abhishek Sehgal1b']",,,"['Large Language Model', 'Retrieval-Augmented Generation', 'Context Bubble', 'Retrieval']","This paper proposes a framework for constructing coherent, citable bundles of spans under a strict token budget, aiming to reduce redundant context, better cover secondary facets, and improve answer quality and citation faithfulness in enterprise retrieval augmented systems.",135.92,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10684v1_On the origin of neural scaling laws from random g.pdf,On the origin of neural scaling laws: from random graphs to natural language,"['Maissam Barkeshli', 'Alberto Alfarano', 'Andrey Gromov']",,2309.15586,"['neural scaling laws', 'transformers', 'random graphs', 'natural language', 'power law', 'scaling exponents']","This paper studies scaling laws for transformers trained on random walks on graphs and natural language models, demonstrating neural scaling laws even in the absence of power law structure in data correlations and revealing a monotonic evolution of scaling exponents as complexity is systematically reduced.",153.9,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10696v1_The Impact of Generative AI on Architectural Conce.pdf,"The Impact of Generative AI on Architectural Conceptual Design: Performance, Creative Self-Efficacy and Cognitive Load","['Han Jiang*', 'Yao Xiao*', 'Rachel Hurley', 'Shichao Liu†']",,,"['Visual communication', 'Architectural design', 'Learning', 'Performance Assessment', 'Hybrid Intelligence', 'Human-AI teaming']","This study examines how generative AI influences performance, creative self-efficacy, and cognitive load in architectural conceptual design tasks, finding that GenAI significantly improves design performance for novice designers but declines creative self-efficacy and does not affect cognitive load.",149.36,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10700v2_LIBERTy A Causal Framework for Benchmarking Concep.pdf,LIBERTy: A Causal Framework for Benchmarking Concept-Based Explanations of LLMs with Structural Counterfactuals,"['Gilat Toker', 'Nitay Calderon', 'Ohad Amosy', 'Roi Reichart']",,2312.08664,"['Large Language Models', 'explainability', 'concept-based explanations', 'causal inference', 'counterfactuals', 'structural causal models', 'benchmarking']","This paper introduces LIBERTy, a framework for constructing datasets containing structural counterfactual pairs to benchmark concept-based explanations of LLMs, using explicitly defined Structural Causal Models. It evaluates various methods across five models and identifies substantial room for improvement in faithful concept-based explanations, particularly for proprietary LLMs which show reduced sensitivity to demographic concepts.",159.87,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10702v1_Grounding Agent Memory in Contextual Intent.pdf,Grounding Agent Memory in Contextual Intent,"['Ruozhen Yang', 'Yucheng Jiang', 'Yueqi Jiang', 'Priyanka Kargupta', 'Yunyi Zhang', 'Jiawei Han']",,2309.15659,"['Long-horizon interactions', 'Agent memory', 'Contextual intent', 'Memory retrieval', 'Factual recall', 'Multi-hop reasoning']","This paper proposes STITCH, an agentic memory system that indexes each trajectory step with a structured retrieval cue, contextual intent, and retrieves history by matching the current step’s intent. It aims to reduce memory interference and improve performance in long-horizon, goal-oriented interactions.",160.81,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10712v1_MatchTIR Fine-Grained Supervision for Tool-Integra.pdf,MatchTIR: Fine-Grained Supervision for Tool-Integrated Reasoning via Bipartite Matching,"['Changle Qu', 'Sunhao Dai', 'Hengyi Cai', 'Jun Xu', 'Shuaiqiang Wang', 'Dawei Yin']",,2309.14769,"['Tool-Integrated Reasoning', 'Fine-Grained Supervision', 'Reinforcement Learning', 'Bipartite Matching', 'Multi-Turn Interaction']","MatchTIR is a framework that introduces fine-grained supervision via bipartite matching-based turn-level reward assignment and dual-level advantage estimation to address the coarse-grained credit assignment issue in Tool-Integrated Reasoning, improving the performance of large language models in long-horizon and multi-turn tasks.",160.49,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10748v1_AnyECG Evolved ECG Foundation Model for Holistic H.pdf,AnyECG: Evolved ECG Foundation Model for Holistic Health Profiling,"['Jun Li', 'Hongling Zhu', 'Yujie Xiao', 'Qinghao Zhao', 'Yalei Ke', 'Gongzheng Tang', 'Guangkun Nie', 'Deyun Zhang', 'Jin Li', 'Canqing Yu', 'Shenda Hong']",,,"['electrocardiography', 'artificial intelligence', 'cardiac diseases', 'non-cardiac diseases', 'holistic health profiling', 'transfer learning', 'multicenter validation']","This study presents AnyECG, an evolved electrocardiography foundation model that integrates a large-scale, multicenter dataset of 13,348,593 ECG records and their corresponding ICD diagnostic codes. Employing transfer learning, AnyECG significantly enhances its capabilities in holistic health profiling, including comprehensive disease screening, long-term risk prediction, and in-depth comorbidity pattern recognition.",160.8,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10768v1_Optimisation of complex product innovation process.pdf,OPTIMISATION OF COMPLEX PRODUCT INNOVATION PROCESSES BASED ON TREND MODELS WITH THREE-VALUED LOGIC,"['NINA BO ˇCKOV´A1', 'BARBORA VOLN ´A2*', 'MIRKO DOHNAL 3']",,2601.10768,"['Complex product innovation', 'technological forecasting', 'three-valued logic', 'trend-based modelling', 'scenarios', 'transition graphs']","This paper investigates complex product-innovation processes using models grounded in a set of heuristics, where each heuristic is expressed through simple trends (increasing, decreasing, or constant) to avoid reliance on numerical values or rough sets. A solution to a trend model is defined as a set of scenarios with possible transitions, represented by a transition graph, allowing depiction of any future or past system behavior.",155.6,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10770v1_Unifying Speech Recognition Synthesis and Conversi.pdf,"UNIFYINGSPEECHRECOGNITION, SYNTHESIS AND CONVERSION WITHAUTOREGRESSIVETRANSFORMERS","['Runyuan Cai', 'Yu Lin', 'Yiming Wang', 'Chunlin Fu', 'Xiaodong Zeng']",,2601.10770v1,"['Text-to-Speech', 'Automatic Speech Recognition', 'Voice Conversion', 'Foundation Model']","This paper presents GPA, a unified audio foundation model that integrates multiple core speech tasks within a single large language model (LLM) architecture, enabling a single autoregressive model to flexibly perform TTS, ASR, and VC without architectural modifications.",161.67,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10773v1_LogicLens Leveraging Semantic Code Graph to explor.pdf,LogicLens: Leveraging Semantic Code Graph to explore Multi Repository large systems,"['Niko Usai', 'Dario Montagnini', 'Kristian Ilianov Iliev', 'Raffaele Camanzo']",,,"['LogicLens', 'Semantic Code Graph', 'Multi Repository Systems', 'Reactive Conversational Agent', 'Large Language Models', 'Software Knowledge Graph']","LogicLens is a reactive conversational agent that assists developers in exploring complex software systems through a semantic multi-repository graph, combining syntactic code analysis with semantic enrichment using Large Language Models. The graph captures structural and functional elements, enabling developers to interact with it via natural language, dynamically retrieving relevant subgraphs and answering technical or functional queries.",161.0,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10779v1_Unified Optimization of Source Weights and Transfe.pdf,Unified Optimization of Source Weights and Transfer Quantities in Multi-Source Transfer Learning: An Asymptotic Framework,"['Qingyue Zhang', 'Chang Chu', 'Haohao Fu', 'Tianren Peng', 'Yanru Wu', 'Guanbo Huang', 'Yang Li', 'Shao-Lun Huang']",,2209.09436,"['transfer learning', 'multi-source learning', 'asymptotic analysis', 'K-L divergence']","This paper proposes a theoretical framework, Unified Optimization of Weights and Quantities (UOWQ), which formulates multi-source transfer learning as a parameter estimation problem grounded in an asymptotic analysis of a Kullback–Leibler divergence-based generalization error measure, jointly determining the optimal source weights and optimal transfer quantities for each source task.",159.83,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10810v1_Digital Metabolism Decoupling Logic from Facts via.pdf,JSON_FAIL,[],None,None,[],N/A,153.08,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10820v1_Towards Reliable ML Feature Engineering via Planni.pdf,Towards Reliable ML Feature Engineering via Planning in Constrained-Topology of LLM Agents,"['Himanshu Thakur∗', 'Anusha Kamath', 'Anurag Muthyala', 'Dhwani Sanmukhani', 'Smruthi Mukund', 'Jay Katukuri']",,2601.10820,"['Machine Learning', 'Feature Engineering', 'Code Generation', 'LLM Agents', 'Planning', 'Multi-Agent Systems']","This paper addresses the challenges of automating feature engineering in machine learning teams by introducing a planner-guided, constrained-topology multi-agent framework that generates code for repositories in a multi-step fashion. Leveraging a team's environment as a graph, the LLM-powered planner orchestrates calls to available agents, generates context-aware prompts, and uses downstream failures to retroactively correct upstream artifacts. It can request human intervention at critical steps to ensure generated code is reliable, maintainable, and aligned with team expectations.",161.23,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10827v1_Approximately Optimal Global Planning for Contact-.pdf,Approximately Optimal Global Planning for Contact-Rich SE(2) Manipulation on a Graph of Reachable Sets,"['Simin Liu', 'Tong Zhao', 'Bernhard Paus Graesdal', 'Peter Werner', 'Jiuguang Wang', 'John Dolan', 'Changliu Liu', 'Tao Pang']",10.13039/100011589,1909.05614,"['Full-body manipulation', 'dexterous manipulation', 'manipulation planning']","This paper introduces a new approach to compute approximately optimal manipulator plans for contact-rich SE(2) manipulation, outperforming a leading planner on a challenging task by reducing task cost and achieving high success rates.",160.44,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10835v1_Can Vision-Language Models Understand Construction.pdf,Can Vision-Language Models Understand Construction Workers? An Exploratory Study,"['Hieu Bui', 'Nathaniel E. Chodosh', 'Arash Tavakoli']",,,"['Vision-Language Models', 'Construction Automation', 'Robotics', 'Human-Robot Interaction', 'Large Language Model', 'Construction Workers', 'Safety', 'Productivity', 'Emotional States', 'Action Recognition', 'Emotion Recognition']","This study evaluates the performance of three leading Vision-Language Models (GPT-4o, Florence 2, and LLaVa-1.5) in detecting construction worker actions and emotions from static site images. The results indicate that general-purpose VLMs can offer a baseline capability for human behavior recognition in construction environments, but further improvements are needed for real-world reliability.",160.52,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10880v1_Medical SAM3 A Foundation Model for Universal Prom.pdf,Medical SAM3: A Foundation Model for Universal Prompt-Driven Medical Image Segmentation,"['Chongcong Jiang', 'Tianxingjian Ding', 'Chuhan Song', 'Jiachen Tu', 'Ziyang Yan', 'Yihua Shao', 'Zhenyi Wang', 'Yuzhang Shang', 'Tianyu Han', 'Yu Tian']",,2601.10880v1,"['Medical Image Segmentation', 'Foundation Models', 'Fine-Tuning', 'SAM3']","This paper presents Medical SAM3, a foundation model for universal prompt-driven medical image segmentation, which is obtained by fine-tuning SAM3 on large-scale, heterogeneous 2D and 3D medical imaging datasets with paired segmentation masks and text prompts, demonstrating consistent and significant performance gains in challenging scenarios.",156.25,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10904v1_ARC Prize 2025 Technical Report.pdf,ARC Prize 2025: Technical Report,"['François Chollet', 'Mike Knoop', 'Gregory Kamradt', 'Bryan Landers']",,,"['ARC Prize 2025', 'ARC-AGI benchmark', 'few-shot generalization', 'fluid intelligence', 'abstract reasoning', 'ARC-AGI-2 dataset', 'Kaggle competition', 'ARC-AGI-2 private evaluation set', 'refinement loops', 'evolutionary program synthesis', 'application-layer refinements', 'zero-pretraining deep learning', 'ARC-AGI-3', 'interactive reasoning challenges']","This technical report discusses the ARC Prize 2025 global competition on the ARC-AGI-2 dataset, which features greater task complexity compared to its predecessor. It examines the role of refinement loops in AGI progress, discusses knowledge-dependent overfitting, and previews ARC-AGI-3, which introduces interactive reasoning challenges.",159.29,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10917v1_Self-learned representation-guided latent diffusio.pdf,SELF-LEARNED REPRESENTATION-GUIDED LATENT DIFFUSION MODEL FOR BREAST CANCER CLASSIFICATION IN DEEP ULTRA VIOLET WHOLE SURFACE IMAGES,"['Pouya Afshin', 'David Helminiak', 'Tianling Niu', 'Julie M. Jorns', 'Tina Yen', 'Bing Yu', 'Dong Hye Ye']",,2302.09844,"['Breast Cancer Classification', 'Latent Diffusion Model', 'Self-Supervised Learning', 'Data Augmentation']","This paper proposes an SSL-guided Latent Diffusion Model (LDM) to generate high-quality synthetic training patches for breast cancer classification in deep ultraviolet whole surface images, combining real and synthetic patches to fine-tune a Vision Transformer (ViT) for WSI-level classification, achieving 96.47% accuracy and reducing the FID score to 45.72.",158.03,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10921v1_RobuMTL Enhancing Multi-Task Learning Robustness A.pdf,RobuMTL: Enhancing Multi-Task Learning Robustness Against Weather Conditions,"['Tasneem Shaffee', 'Sherief Reda']",,1909.08807,"['Robust Multi-Task Learning', 'Adversarial Training', 'Data Augmentation', 'Mixture-of-Experts', 'Low-Rank Adaptation', 'Weather Conditions']","This paper introduces RobuMTL, a novel architecture designed to adaptively address visual degradation by dynamically selecting task-specific hierarchical Low-Rank Adaptation (LoRA) modules and a LoRA expert squad based on input perturbations in a mixture-of-experts fashion. The framework enables adaptive specialization based on input characteristics, improving robustness across diverse real-world conditions. The authors validate their approach on the PASCAL and NYUD-v2 datasets, achieving significant improvements in robustness compared to single-task models and standard MTL baselines.",157.2,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10922v1_What Matters in Data Curation for Multimodal Reaso.pdf,What Matters in Data Curation for Multimodal Reasoning?,"['Yosub Shin', 'Michael Buriek', 'Boris Sobolev', 'Pavel Bushuyeu', 'Vikas Kumar', 'Haoyang Xu', 'Samuel Watson', 'Igor Molybog']",,2511.10097,"['Data curation', 'Multimodal reasoning', 'Vision-Language models', 'NeurIPS challenge', 'Example difficulty', 'Dataset alignment']","This paper studies data curation for multimodal reasoning through the NeurIPS 2025 Data Curation for Vision–Language Reasoning (DCVLR) challenge, isolating dataset selection by fixing the model and training protocol. The authors demonstrate that difficulty-based example selection on an aligned base dataset is the dominant driver of performance gains, and that increasing dataset size does not reliably improve mean accuracy under the fixed training recipe. Commonly used diversity and synthetic augmentation heuristics provide no additional benefit and often degrade performance.",154.82,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10926v1_Selecting Language Models for Social Science Start.pdf,"Selecting Language Models for Social Science: Start Small, Start Open, and Validate","['Dustin S. Stoltz', 'Marshall A. Taylor', 'Sanuj Kumar']",,26XX(X),"['large language models', 'LLMs', 'reproducibility', 'replicability', 'model openness']","This paper explores the selection of language models for social science research, advocating for the use of smaller, open models and constructing delimited benchmarks to validate the entire computational pipeline, focusing on reproducibility and replicability.",157.52,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10931v1_Sparse Data Tree Canopy Segmentation Fine-Tuning L.pdf,Sparse Data Tree Canopy Segmentation: Fine-Tuning Leading Pretrained Models on Only 150 Images,"['David Szczecina', 'Niloofar Azad', 'Hudson Sun', 'Kyle Gao', 'Anthony Bertnyk', 'Lincoln Linlin Xu']",,2303.00000,"['Deep Learning', 'Computer Vision', 'Object Segmentation', 'Remote Sensing', 'Forestry', 'Tree Canopy']","This paper evaluates five deep learning architectures for tree canopy segmentation using a small and imbalanced dataset of only 150 annotated images, finding that convolution-based models generalize better than transformer-based models under extreme data scarcity.",157.29,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10945v1_PatientVLM Meets DocVLM Pre-Consultation Dialogue .pdf,PatientVLM Meets DocVLM: Pre-Consultation Dialogue Between Vision-Language Models for Efficient Diagnosis,"['K Lokesh', 'Abhirama Subramanyam Penamakuri', 'Uday Agarwal', 'Apoorva Challa', 'Shreya K Gowda', 'Somesh Gupta', 'Anand Mishra']",,2310.16488,"['Vision-Language Models', 'Medical Diagnosis', 'Pre-Consultation Dialogue', 'Symptom Elicitation', 'Clinical Validation']","This paper proposes a Pre-Consultation Dialogue Framework (PCDF) to simulate realistic doctor-patient dialogues between vision-language models (VLMs) for medical diagnosis. The framework includes a DocVLM that generates follow-up questions based on image and dialogue history, and a PatientVLM that responds using a symptom profile derived from the ground-truth diagnosis. The authors validate synthetic symptoms generated by their framework with licensed clinicians, confirming their clinical relevance, symptom coverage, and realism, leading to substantial gains over image-only training.",152.78,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10951v1_Multi-Stage Patient Role-Playing Framework for Rea.pdf,Multi-Stage Patient Role-Playing Framework for Realistic Clinical Interactions,"['Shijie Jiang', 'Zefan Zhang', 'Kehua Zhu', 'Tian Bai', 'Ruihong Zhao']",,2601.10951v1,"['Patient Role-Playing', 'Large Language Models', 'Clinical']","This work proposes the first Chinese patient simulation dataset (Ch-PatientSim) to evaluate models in emulating patient behavior, and introduces a training-free Multi-Stage Patient Role-Playing (MSPRP) framework to improve model performance in realistic clinical interactions.",131.77,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10955v1_Beyond Max Tokens Stealthy Resource Amplification .pdf,Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents,"['Kaiyu Zhou', 'Yongsen Zheng∗', 'Yicheng He', 'Meng Xue', 'Xueluan Gong', 'Yuji Wang', 'Kwok-Yan Lam']",,,"['Large Language Models', 'LLM Agents', 'Tool Calling', 'Agent Security', 'Economic Denial-of-Service']","The paper introduces a stealthy, multi-turn economic Denial-of-Service (DoS) attack that operates at the tool layer, amplifying costs and energy by up to 658 and 100–560 times, respectively, across six LLMs on benchmarks. It demonstrates how LLM agents can be exploited to prolong tool-calling sequences, leading to resource exhaustion.",159.24,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.10960v1_Steering Language Models Before They Speak Logit-L.pdf,Steering Language Models Before They Speak: Logit-Level Interventions,"['Hyeseon An', 'Shinwoo Park', 'Hyundong Jin', 'Yo-Sub Han *']",,2311.16688,"['Large Language Models', 'Steering', 'Controllable Generation', 'Logit-Level Interventions', 'LLM Control', 'Writing Complexity', 'Formality', 'Toxicity Mitigation']","This paper proposes a training-free inference-time logit intervention for controllable generation of large language models (LLMs), using a statistical token score table derived from z-normalized log-odds of labeled corpora to shift the decoding distribution. Empirical evaluations across three diverse datasets demonstrate that this method effectively steers output characteristics, achieving large, consistent, and multi-task control gains.",160.77,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11000v1_When Personalization Misleads Understanding and Mi.pdf,When Personalization Misleads: Understanding and Mitigating Hallucinations in Personalized LLMs,"['Zhongxiang Sun', 'Yi Zhan', 'Chenglei Shen', 'Weijie Yu', 'Xiao Zhang', 'Ming He', 'Jun Xu']",,2310.16106,"['Personalized LLMs', 'Factual Queries', 'Hallucinations', 'Factuality-Preserving Personalized Steering (FPPS)', 'PFQABench']","This paper examines how personalized large language models (LLMs) can generate answers that align with a user's prior history rather than the objective truth, leading to personalization-induced hallucinations that degrade factual reliability. The authors propose Factuality-Preserving Personalized Steering (FPPS) as a lightweight inference-time approach to mitigate these distortions while preserving personalized behavior. They also introduce PFQABench, a benchmark for evaluating both factual and personalized question answering under personalization.",159.34,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11007v1_AdaMARP An Adaptive Multi-Agent Interaction Framew.pdf,AdaMARP: An Adaptive Multi-Agent Interaction Framework for General Immersive Role-Playing,"['Zhenhua Xu1†', 'Dongsheng Chen 2†', 'Shuo Wang2', 'Jian Li 2', 'Chengjie Wang 2', 'Meng Han 2', 'Yabiao Wang 2']",,2601.11007,"['AdaMARP', 'Multi-Agent Interaction', 'Role-Playing', 'Immersive Communication', 'Large Language Models']","This paper proposes AdaMARP, an adaptive multi-agent interaction framework for general immersive role-playing, featuring an immersive message format and an explicit Scene Manager. It introduces AdaRPSet and AdaSMSet for training and evaluation, demonstrating consistent gains in character consistency, environment grounding, and narrative coherence.",159.32,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11012v1_Efficient Protein Optimization via Structure-aware.pdf,Efficient Protein Optimization via Structure-aware Hamiltonian Dynamics,"['Jiahao Wang', 'Shuangjia Zheng']",,2309.14766,"['Protein Optimization', 'Hamiltonian Dynamics', 'Bayesian Optimization', 'Structure-aware', 'Mutant Sequences', 'Epistasis Effect']","This paper introduces HADES, a Bayesian optimization method utilizing Hamiltonian dynamics to efficiently sample from a structure-aware approximated posterior, enabling rapid transition of protein sequence proposals toward promising areas, and demonstrates superior performance in in-silico evaluations across various metrics.",159.76,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11016v1_Contextual Distributionally Robust Optimization wi.pdf,Contextual Distributionally Robust Optimization with Causal and Continuous Structure: An Interpretable and Tractable Approach,"['Fenglin Zhang', 'Jie Wang∗']",null,2601.11016,"['Contextual distributionally robust optimization', 'Causal Sinkhorn discrepancy', 'Soft regression forest', 'Stochastic compositional optimization']","This paper introduces a framework for contextual distributionally robust optimization (DRO) that considers the causal and continuous structure of the underlying distribution by developing interpretable and tractable decision rules. It proposes a new discrepancy measure, the causal Sinkhorn discrepancy, and formulates a contextual DRO model with a CSD-based ambiguity set, termed Causal Sinkhorn DRO (Causal-SDRO). The authors also introduce a decision rule, Soft Regression Forest (SRF), which approximates optimal policies and preserves interpretability while being fully parametric, differentiable, and Lipschitz smooth.",152.43,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11019v1_Finding the Translation Switch Discovering and Exp.pdf,JSON_FAIL,[],None,None,[],N/A,148.57,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11021v1_Combating Spurious Correlations in Graph Interpret.pdf,Combating Spurious Correlations in Graph Interpretability via Self-Reflection,"['Kecheng Cai', 'Chenyang Xu', 'Chao Peng']",10.13140/RV/Z2234,2601.02344,"['Graph Interpretability', 'Spurious Correlations', 'Self-Reflection', 'Interpretable Graph Learning', 'Benchmark Datasets']","This paper focuses on improving interpretability in challenging Spurious-Motif datasets by adapting the self-reflection technique, commonly used in large language models, to enhance graph learning methods. The authors propose a self-reflection framework that iteratively evaluates importance scores for nodes and edges, leading to performance improvements on both Spurious-Motif and other graph interpretability benchmarks.",140.78,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11030v1_IDDR-NGP Incorporating Detectors for Distractor Re.pdf,IDDR-NGP: Incorporating Detectors for Distractor Removal with Instant Neural Radiance Field,"['Xianliang Huang', 'Jiajie Gou', 'Shuhang Chen', 'Zhizhou Zhong', 'Jihong Guan', 'Shuigeng Zhou']",10.1145/3581783.3612045,2601.11030v1,"['distractor removal', 'instant neural radiance field', '3D scene', 'distractors', 'detection', 'synthetic scene', 'realistic scene']","This paper presents IDDR-NGP, a unified method for removing a wide range of distractors in 3D scenes, including snowflakes, confetti, defoliation, and petals, by incorporating implicit 3D representations with 2D detectors and jointly optimizing rendering results from multi-view corrupted images.",157.82,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11035v1_Your One-Stop Solution for AI-Generated Video Dete.pdf,Your One-Stop Solution for AI-Generated Video Detection,"['Long Ma', 'Zihao Xue', 'Yan Wang', 'Zhiyuan Yan', 'Jin Xu', 'Xiaorui Jiang', 'Haiyang Yu', 'Yong Liao', 'Zhen Bi']",null,2601.11035,"['AI-generated video detection', 'synthetic video', 'video detection', 'generative modeling', 'real vs synthetic', 'human detection', 'reliability', 'multiple tasks', 'advanced models']","This paper discusses the challenges and limitations of detecting AI-generated videos, highlighting the difficulties in distinguishing them from real videos due to the advancements in generative modeling. It also presents experimental results and evaluations of various detection methods.",152.77,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11037v1_BAPO Boundary-Aware Policy Optimization for Reliab.pdf,BAPO: Boundary-Aware Policy Optimization for Reliable Agentic Search,"['Shiyu Liu', 'Yongjing Yin', 'Jianhao Yan', 'Yunbo Tang', 'Qinggang Zhang', 'Bei Li', 'Xin Chen', 'Jingang Wang', 'Xunliang Cai', 'Jinsong Su']",,2309.14844,"['reinforcement learning', 'large language models', 'agentic search', 'policy optimization', 'boundary awareness', 'reliability', 'knowledge-intensive questions']","This paper proposes BAPO, a novel RL framework designed to enhance the reliability of agentic search by introducing a group-based boundary-aware reward and an adaptive reward modulator, thereby avoiding the issue of agents failing to recognize their reasoning boundaries and admitting 'I DON’T KNOW' (IDK) when evidence is insufficient or reasoning reaches its limit.",159.26,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11042v1_Spectral Characterization and Mitigation of Sequen.pdf,Spectral Characterization and Mitigation of Sequential Knowledge Editing Collapse,"['Chi Zhang', 'Mengqi Zhang', 'Xiaotian Ye', 'Runxi Cheng', 'Zisheng Zhou', 'Ying Zhou', 'Pengjie Ren', 'Zhumin Chen']",,2310.17647,"['Sequential Knowledge Editing', 'Catastrophic Collapse', 'Spectral Analysis', 'Parameter-Modifying Methods', 'Stabilization Framework']","This work presents a spectral analysis of sequential knowledge editing in large language models and proposes REVIVE, a plug-and-play framework that stabilizes sequential editing by explicitly preserving the dominant singular subspace, thereby improving editing efficacy and preserving general abilities under long-horizon sequential editing.",140.29,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11044v2_AgencyBench Benchmarking the Frontiers of Autonomo.pdf,AGENCYBENCH: Benchmarking the Frontiers of Autonomous Agents in 1M-Token Real-World Contexts,"['Keyu Li', 'Junhao Shi', 'Yang Xiao', 'Mohan Jiang', 'Jie Sun', 'Yunze Wu', 'Dayuan Fu', 'Shijie Xia', 'Xiaojie Cai', 'Tianze Xu', 'Weiye Si', 'Pengfei Liu']",,2601.11044v2,"['AgencyBench', 'Autonomous Agents', 'Benchmarking', 'Real-World Contexts', 'Large Language Models', 'User Simulation', 'Docker Sandbox', 'Iterative Feedback', 'Resource Efficiency', 'Feedback-Driven Self-Correction', 'Tool Use Preferences', 'Proprietary Models', 'Open-Source Models', 'Model Architecture', 'Agentic Frameworks', 'Game', 'Front-End', 'Back-End', 'Code', 'Research', 'MCP', 'Board Game', 'Puzzle Game', 'Arcade Game', 'Action Game', 'Casual Game', 'Dynamic', 'Web Pages', 'Visualization', 'C++ Development', 'Java Development', 'Python Development', 'Github PR', 'Performance Optimization', 'Agentic Debugging', 'Dataset', 'Web Searching', 'Topic Research']","This paper introduces AGENCYBENCH, a comprehensive benchmark for evaluating 6 core agentic capabilities across 32 real-world scenarios, comprising 138 tasks with specific queries, deliverables, and rubrics. It requires an average of 1 million tokens and 90 multi-turn tool uses to resolve. The benchmark uses a user simulation agent for iterative feedback and a Docker-based sandbox for automated rubric-based assessment, revealing significant disparities in model performance and resource efficiency.",158.1,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11049v1_Predicting Biased Human Decision-Making with Large.pdf,Predicting Biased Human Decision-Making with Large Language Models in Conversational Settings,"['Stephen Pilli', 'Vivek Nallur']",10.13140/RG.2.2.37076.09124,2312.08457,"['Conversational AI', 'Framing Effect', 'Status Quo Bias', 'LLM Simulation']","This study examines whether large language models can predict biased decision-making in conversational settings, and evaluates their ability to incorporate dialogue context in their predictions, finding that GPT-4 consistently aligns with human behavior and outperforms other models in predictive accuracy and fidelity to human-like bias patterns.",159.22,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11063v1_H-AIM Orchestrating LLMs PDDL and Behavior Trees f.pdf,"H-AIM: Orchestrating LLMs, PDDL, and Behavior Trees for Hierarchical Multi-Robot Planning","['Haishan Zeng', 'Peng Li']",10.48550/arxiv.2601.11063,2601.11063,"['H-AIM', 'LLMs', 'PDDL', 'Behavior Trees', 'Hierarchical Multi-Robot Planning', 'Embodied AI', 'Heterogeneous Robots', 'Long-Horizon Tasks', 'Natural Language Instructions', 'Dynamic Environments']","This paper proposes H-AIM, a novel embodied multi-robot task planning framework that addresses the challenges of executing long-horizon tasks from high-level instructions using a three-stage cascaded architecture involving large language models, PDDL problem descriptions, and behavior trees for reactive control, supporting dynamically sized heterogeneous robot teams via a shared blackboard mechanism for communication and state synchronization.",155.26,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11065v1_Fairness in Healthcare Processes A Quantitative An.pdf,Fairness in Healthcare Processes: A Quantitative Analysis of Decision Making in Triage,"['Rachmadita Andreswari', 'Stephan A. Fahrenkrog-Petersen', 'Jan Mendling']",,2601.11065,"['process mining', 'fairness', 'triage', 'emergency room']","This study addresses the research problem of fairness in automated decision-making in healthcare, particularly in emergency triage, by linking real-life event logs with conceptual dimensions of justice and analyzing factors such as age, gender, race, and language.",158.94,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11073v1_Bridging Cognitive Neuroscience and Graph Intellig.pdf,Bridging Cognitive Neuroscience and Graph Intelligence: Hippocampus-Inspired Multi-View Hypergraph Learning for Web Finance Fraud,"['Rongkun Cui', 'Nana Zhang', 'Kun Zhu', 'Qi Zhang']",https://doi.org/XXXXXXX.XXXXXXX,,"['Cognitive Neuroscience', 'Graph Intelligence', 'Hippocampus', 'Multi-View Hypergraph Learning', 'Web Finance Fraud']","This paper proposes HIMVH, a Hippocampus-Inspired Multi-View Hypergraph learning model for web finance fraud detection, addressing challenges of fraud camouflage and long-tailed data distributions.",156.69,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11076v1_A3D Adaptive Affordance Assembly with Dual-Arm Man.pdf,A3D: Adaptive Affordance Assembly with Dual-Arm Manipulation,"['Jiaqi Liang', 'Yue Chen', 'Qize Yu', 'Yan Shen', 'Haipeng Zhang', 'Hao Dong', 'Ruihai Wu']",,2309.08446,"['robotics', 'furniture assembly', 'dual-arm manipulation', 'adaptive affordance', 'motion planning', 'assembly pose estimation', 'reinforcement learning', 'vision understanding', 'bi-manual operation']","A3D is a framework that learns adaptive affordances to identify optimal support and stabilization locations on furniture parts, enabling generalization across varied geometries and evolving assembly states through interaction feedback.",159.47,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11077v1_ABC-Bench Benchmarking Agentic Backend Coding in R.pdf,ABC-Bench: Benchmarking Agentic Backend Coding in Real-World Development,"['Jie Yang', 'Honglin Guo', 'Li Ji', 'Jiazheng Zhou', 'Rui Zheng', 'Zhikai Lei', 'Shuo Zhang', 'Shichun Liu', 'Yuxin Wang', 'Bo Wang', 'Yining Zheng', 'Tao Gui', 'Xipeng Qiu']",null,2601.11077v1,"['Large Language Models', 'Backend Development', 'Real-World Engineering', 'Benchmarking', 'Agentic Agents']","This paper introduces ABC-Bench, a benchmark designed to evaluate agentic backend coding within a realistic, executable workflow, addressing the gap between current benchmarks and real-world software engineering tasks.",160.05,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11078v1_Visual Marker Search for Autonomous Drone Landing .pdf,Visual Marker Search for Autonomous Drone Landing in Diverse Urban Environments,"['Jiaohong Yao', 'Linfeng Liang', 'Yao Deng', 'Xi Zheng', 'Richard Han', 'Yuankai Qi']",,1912.08797,"['Drone navigation', 'marker-based landing', 'reinforcement learning', 'AirSim', 'robustness']","This paper presents a simulation-based evaluation suite for marker-based autonomous drone landing in diverse urban environments, analyzing how exploration strategy and scene complexity affect success rate, path efficiency, and robustness.",156.62,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11089v2_MiCA A Mobility-Informed Causal Adapter for Lightw.pdf,MiCA: A Mobility-Informed Causal Adapter for Lightweight Epidemic Forecasting,"['Suhan Guo', 'Jiahong Deng', 'Furao Shen']",null,2109.09506,"['epidemic forecasting', 'mobility data', 'causal discovery', 'temporal forecasting', 'lightweight models']","This work proposes MiCA, a lightweight and architecture-agnostic module for epidemic forecasting that infers mobility relations through causal discovery and integrates them into temporal forecasting models via gated residual mixing. Extensive experiments on four real-world epidemic datasets show that MiCA consistently improves lightweight temporal backbones, achieving an average relative error reduction of 7.5% across forecasting horizons.",160.23,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11090v1_Efficient Multilingual Name Type Classification Us.pdf,Eﬀicient Multilingual Name T ype Classification Using Convolutional Networks,['Davor Lauc'],,1912.04884,"['multilingual NLP', 'named entity recognition', 'convolutional neural networks', 'efficient inference', 'proper names']","The paper presents a convolutional neural network approach for classifying proper names by language and entity type, achieving 92.1% accuracy while processing 2,813 names per second on a single CPU core, 46 times faster than fine-tuned XLM-RoBERTa with comparable accuracy. The model reduces energy consumption by a factor of 46 compared to transformer baselines.",156.42,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11100v1_ReCreate Reasoning and Creating Domain Agents Driv.pdf,ReCreate: Reasoning and Creating Domain Agents Driven by Experience,"['Zhezheng Hao', 'Hong Wang', 'Jian Luo', 'Jianqing Zhang', 'Yuyan Zhou', 'Qiang Lin', 'Can Wang', 'Hande Dong', 'Jiawei Chen']",,2310.14716,"['Large Language Models', 'Domain Agents', 'Automated Agent Generation', 'Experience-driven Framework', 'Reasoning and Creating']","This paper proposes ReCreate, an experience-driven framework for automatically creating domain agents, which systematically leverages agent interaction histories to learn from experience and improve performance, outperforming human-designed and existing automated agent generation methods in diverse domains.",138.64,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11109v1_Vision-as-Inverse-Graphics Agent via Interleaved M.pdf,Vision-as-Inverse-Graphics Agent via Interleaved Multimodal Reasoning,"['Shaofeng Yin', 'Jiaxin Ge', 'Zora Zhiruo Wang', 'Xiuyu Li', 'Michael J. Black', 'Trevor Darrell', 'Angjoo Kanazawa', 'Haiwen Feng']",10.48550/arxiv.2601.11109,2601.11109,"['Vision-as-inverse-graphics', 'multimodal reasoning', 'iterative execution', 'context memory', '3D reconstruction', 'multi-step scene editing', '4D physical interaction', '2D document editing']","VIGA (Vision-as-Inverse-Graphic Agent) is an agent that reconstructs or edits scenes through a closed-loop write→run→render→compare→revise procedure, combining a skill library and evolving context memory to support long-horizon reasoning. It is task-agnostic and model-agnostic, improving one-shot baselines on BlenderGym and SlideBench.",159.67,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11124v1_Learn Before Represent Bridging Generative and Con.pdf,Learn Before Represent: Bridging Generative and Contrastive Learning for Domain-Specific LLM Embeddings,"['Xiaoyu Liang', 'Yuchen Peng', 'Jiale Luo', 'Wenhao Wang', 'Haoji Hu', 'Xincheng Zhou']",,2601.11,"['Large Language Models', 'Contrastive Learning', 'Generative Learning', 'Domain-Specific Embeddings', 'Knowledge Acquisition', 'Medical Domain', 'Chemistry Domain', 'Code Retrieval']","This work proposes Learn Before Represent (LBR), a novel two-stage framework, to address the limitations of the prevailing 'LLM+CL' paradigm in vertical domains, where LLMs struggle with specialized terminology and long-tail entities. LBR first injects domain knowledge via an Information Bottleneck-Constrained Generative Learning stage, preserving the LLM's causal attention to maximize knowledge acquisition while compressing semantics. It then performs Generative-Refined Contrastive Learning on the compressed representations for alignment, resolving the objective conflict between generative and contrastive learning.",155.41,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11135v1_Context-aware Graph Causality Inference for Few-Sh.pdf,Context-aware Graph Causality Inference for Few-Shot Molecular Property Prediction,"['Van Thuy Hoang', 'O-Joun Lee*']",,2309.15588,"['Molecular Property Prediction', 'Graph Learning', 'Few-Shot Learning', 'Causal Inference', 'Functional Groups', 'Molecules', 'Chemical Knowledge']","This paper proposes CaMol, a context-aware graph causality inference framework to address the challenges of few-shot molecular property prediction, by using a causal inference perspective and introducing a context graph, learnable atom masking strategy, and distribution intervener.",158.02,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11143v1_Learning Quadrupedal Locomotion for a Heavy Hydrau.pdf,Learning Quadrupedal Locomotion for a Heavy Hydraulic Robot Using an Actuator Model,"['Minho Lee', 'Hyeonseok Kim', 'Jin Tak Kim', 'Sangshin Park', 'Jeong Hyun Lee', 'Jungsan Cho', 'Jemin Hwangbo ∗']",,,"['Hydraulic/Pneumatic Actuators', 'Legged Robots', 'Reinforcement Learning']","This work proposes an analytical actuator model driven by hydraulic dynamics to represent the complex actuators of a heavy hydraulic quadruped robot. The model predicts joint torques for all 12 actuators in under 1 microsecond, enabling rapid processing in reinforcement learning environments. The locomotion policy trained with this model is successfully deployed on a 300 kg hydraulic quadruped robot, demonstrating advanced sim-to-real transferability.",142.59,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11144v2_Deep GraphRAG A Balanced Approach to Hierarchical .pdf,Deep GraphRAG: A Balanced Approach to Hierarchical Retrieval and Adaptive Integration,"['Yuejie Li', 'Ke Yang', 'Tao Wang', 'Bolin Chen', 'Bowen Li', 'Chengjun Mao']",,,"['GraphRAG', 'Reinforcement Learning', 'Large Language Models']","Deep GraphRAG is a framework designed for a balanced approach to hierarchical retrieval and adaptive integration, introducing a hierarchical global-to-local retrieval strategy that integrates macroscopic inter-community and microscopic intra-community contextual relations. It employs a three-stage process for filtering, refinement, and fine-grained search, guided by a beam search-optimized dynamic re-ranking module.",159.8,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11147v1_Do We Always Need Query-Level Workflows Rethinking.pdf,Do We Always Need Query-Level Workflows?,"['Zixu Wang', 'Bingbing Xu', 'Yige Yuan', 'Huawei Shen', 'Xueqi Cheng']",,2310.15914,"['Multi-Agent Systems', 'Query-Level Workflows', 'Task-Level Workflows', 'Large Language Models', 'Workflow Generation', 'Self-Evolution', 'Generative Reward Modeling']","This paper rethinks and analyzes the necessity of query-level workflow generation in Multi-Agent Systems (MAS) built on large language models. It shows that query-level workflow generation is not always necessary, as a small set of top-K task-level workflows can cover equivalent or even more queries. The authors propose SCALE, a low-cost task-level generation framework that reduces token usage by up to 83% while maintaining competitive performance.",156.65,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11151v1_Cross-Modal Attention Network with Dual Graph Lear.pdf,Cross-Modal Attention Network with Dual Graph Learning in Multimodal Recommendation,"['JI DAI', 'QUAN FANG∗', 'JUN HU', 'DESHENG CAI', 'YANG YANG', 'CAN ZHAO']",https://doi.org/XXXXXXX.XXXXXXX,,"['Multimedia recommendation', 'Graph Neural Network', 'Multimodal Fusion']","This paper proposes CRANE, a cross-modal recursive attention network with dual graph embedding, to address the limitations of shallow modality fusion and asymmetric feature treatment in multimodal recommendation systems, achieving improved performance on public datasets.",156.81,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11160v1_Clustering High-dimensional Data Balancing Abstrac.pdf,Clustering High-dimensional Data: Balancing Abstraction and Representation,"['Claudia Plant', 'Lena G. M. Bauer', 'Christian B ¨ohm']",,2601.01234,"['Clustering', 'High-dimensional Data', 'Abstraction', 'Representation', 'Subspace Clustering', 'Deep Clustering', 'Representation Learning']","This tutorial discusses the challenges and approaches to balancing abstraction and representation in clustering high-dimensional data, focusing on the trade-offs between different clustering algorithms and the need to enforce abstraction in the objective function to ensure clustering performance.",160.74,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11178v1_TANDEM Temporal-Aware Neural Detection for Multimo.pdf,TANDEM: Temporal-Aware Neural Detection for Multimodal Hate Speech,"['Girish A. Koushik', 'Helen Treharne', 'Diptesh Kanojia']",,2309.15624,"['Hate Speech', 'Multimodal Detection', 'Temporal-Aware', 'Tandem Reinforcement Learning', 'Context-Augmented Baselines']","This paper introduces TANDEM, a unified framework that transforms audio-visual hate speech detection into a structured reasoning problem, employing a novel tandem reinforcement learning strategy to achieve significant improvements in target identification and temporal grounding over state-of-the-art methods.",154.78,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11189v1_Policy-Based Deep Reinforcement Learning Hyperheur.pdf,Policy-Based Deep Reinforcement Learning Hyperheuristics for Job-Shop Scheduling,"['Sofiene Lassoued *a', 'Asrat Gobachew b', 'Stefan Lier b', 'Andreas Schwung a']",,1909.05091,"['Hyper-heuristics', 'Job Shop Scheduling', 'Policy-based Reinforcement learning', 'Petri nets']","This paper proposes a policy-based deep reinforcement learning hyper-heuristic framework for solving the Job Shop Scheduling Problem. The hyper-heuristic agent learns to switch scheduling rules based on the system state dynamically, with two key mechanisms: action prefiltering and a commitment mechanism. Computational experiments demonstrate that the proposed approach outperforms traditional heuristics, metaheuristics, and recent neural network-based scheduling methods.",141.07,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11196v1_Artificial Intelligence and the US Economy An Acco.pdf,Artificial Intelligence and the US Economy: An Accounting Perspective on Investment and Production,"['Luisa Carpinelli', 'Filippo Natoli', 'Marco Taboga']",,2601.11196v1,"['artificial intelligence', 'capital expenditures', 'data centers', 'national accounts']","This paper provides an overview of how the current AI wave is captured in US national accounts, highlighting the crucial role of data centers and their impact on aggregate demand and GDP growth.",148.39,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11199v1_SD-RAG A Prompt-Injection-Resilient Framework for .pdf,SD-RAG: A Prompt-Injection-Resilient Framework for Selective Disclosure in Retrieval-Augmented Generation,"['Aiman Al Masoud', 'Marco Arazzi', 'Antonino Nocera']",,2309.15298,"['Retrieval-Augmented Generation', 'Prompt Injection Attacks', 'Selective Disclosure', 'Large Language Models', 'Sanitization', 'Privacy Constraints']","This paper proposes SD-RAG, a novel approach to selective disclosure in retrieval-augmented generation, which decouples security and privacy constraints from the generation process, applying sanitization and disclosure controls during the retrieval phase. It introduces a semantic mechanism for ingesting human-readable dynamic security and privacy constraints, along with an optimized graph-based data model that supports fine-grained, policy-aware retrieval. The experimental evaluation demonstrates SD-RAG's superiority over baseline approaches, achieving up to a 58% improvement in privacy scores while also showing strong resilience to prompt injection attacks.",157.97,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11200v1_FAQ Mitigating Quantization Error via Regenerating.pdf,FAQ: Mitigating Quantization Error via Regenerating Calibration Data with Family-Aware Quantization,"['Haiyang Xiao', 'Weiqing Li', 'Jinyue Guo', 'Guochao Jiang', 'Guohua Liu', 'Yuewei Zhang']",,2309.14494,"['quantization', 'calibration data', 'family-aware', 'post-training quantization', 'large language models']","This paper proposes FAQ (Family-Aware Quantization), a calibration data regeneration framework that leverages prior knowledge from LLMs of the same family to generate high-fidelity calibration samples, reducing quantization error by up to 28.5% compared to baseline methods with original calibration data.",141.81,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11202v1_Epistemic Control and the Normativity of Machine L.pdf,EPISTEMIC CONTROL AND THE NORMATIVITY OF MACHINE LEARNING-BASED SCIENCE,['Emanuele Ratti'],,,"['machine learning', 'epistemic control', 'cognitive values', 'normativity']","The author investigates the extent to which human scientists can maintain epistemic control over machine learning-based scientific systems, distinguishing between 'tracking' and 'tracing' conditions for control, and argues against a pessimistic view of human exclusion from these systems.",157.4,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11207v1_LoRA as Oracle.pdf,LoRA as Oracle,"['Marco Arazzi', 'Antonino Nocera']",,1909.02835,"['LoRA', 'Membership Inference Attack', 'Backdoor Attack']","This work introduces a LoRA-based oracle framework for both backdoor detection and membership inference, leveraging low-rank adaptation modules to analyze optimization dynamics and representation shifts of task-specific adapters attached to a frozen backbone.",155.71,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11219v1_SDFLoRA Selective Dual-Module LoRA for Federated F.pdf,SDFLoRA: Selective Dual-Module LoRA for Federated Fine-tuning with Heterogeneous Clients,"['Zhikang Shen', 'Jianrong Lu', 'Haiyuan Wan', 'Jianhai Chen']",,2312.15968,"['Federated Learning', 'Large Language Models', 'LoRA', 'Privacy-Preserving', 'Parameter-Efficient']","This paper proposes SDFLoRA, a method for federated fine-tuning of large language models that decomposes each client adapter into a global module for transferable knowledge and a local module for client-specific adaptations, addressing the issue of rank heterogeneity and privacy protection in practical federated deployments.",158.79,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11232v1_FactCorrector A Graph-Inspired Approach to Long-Fo.pdf,FACTCORRECTOR: A Graph-Inspired Approach to Long-Form Factuality Correction of Large Language Models,"['Javier Carnerero-Cano', 'Massimiliano Pronesti', 'Radu Marinescu', 'Tigran Tchrakian', 'James Barry', 'Jasmina Gajcin', 'Yufang Hou', 'Alessandra Pascale', 'Elizabeth Daly']",,,"['Large Language Models', 'Factuality Correction', 'Graph-Based Approaches', 'Post-Hoc Correction', 'Long-Form Text']","This paper introduces FACTCORRECTOR, a novel post-hoc correction method for large language models (LLMs) that adapts across domains without retraining and leverages structured feedback about the factuality of the original response to generate a correction. The authors also develop the VELI5 benchmark, a novel dataset containing systematically injected factual errors and ground-truth corrections, to support rigorous evaluations of factuality correction methods. Experiments on VELI5 and several popular long-form factuality datasets show that FACTCORRECTOR significantly improves factual precision while preserving relevance, outperforming strong baselines.",157.4,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11252v1_Beyond Model Scaling Test-Time Intervention for Ef.pdf,BEYONDMODELSCALING: TEST-TIMEINTERVENTION,"['Qianyue Wang', 'Jinwu Hu', 'Yufeng Wang', 'Huanxiang Lin', 'Bolin Chen', 'Zhiquan Wen', 'Yaofo Chen', 'Mingkui Tan']",,2312.08946,"['Large Reasoning Models', 'Test-Time Intervention', 'Efficient Reasoning', 'External Feedback', 'Multi-Step Deduction', 'Group Relative Policy Optimization', 'Security', 'Creative Tasks']","This paper proposes Think-with-Me, a novel test-time interactive reasoning paradigm that introduces external feedback intervention into the reasoning process of large reasoning models, aiming to improve efficiency and accuracy.",157.32,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11258v1_Knowledge is Not Enough Injecting RL Skills for Co.pdf,Knowledge is Not Enough: Injecting RL Skills for Continual Adaptation,"['Pingzhi Tang', 'Yiding Wang', 'Muhan Zhang']",,2309.14809,"['Reinforcement Learning', 'Knowledge Updating', 'Continual Adaptation', 'Large Language Models', 'Skill Transfer']","This paper proposes Parametric Skill Transfer (PaST) to efficiently and effectively adapt large language models to incorporate new knowledge and skills. PaST extracts a domain-agnostic Skill Vector from a source domain and linearly injects it into a target model after lightweight supervised fine-tuning on new data, demonstrating effectiveness in knowledge-incorporation QA and agentic tool-use benchmarks.",137.06,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11269v1_X-Distill Cross-Architecture Vision Distillation f.pdf,X-Distill: Cross-Architecture Vision Distillation for Visuomotor Learning,"['Maanping Shao', 'Feihong Zhang', 'Gu Zhang', 'Baiye Cheng', 'Zhengrong Xue', 'Huazhe Xu']",,2108.07642,"['Visuomotor Policy', 'Knowledge Distillation', 'Representation Learning', 'Manipulation']","X-Distill is a simple yet effective method that synergizes the strengths of large Vision Transformers (ViTs) and compact CNNs for data-efficient visuomotor learning, significantly outperforming from-scratch ResNets and fine-tuned ViTs on real-world manipulation tasks.",161.34,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11282v1_From SERPs to Sound How Search Engine Result Pages.pdf,FromSERPsto Sound: How Search Engine Result Pages and AI-generated Podcasts Interact to Influence User Attitudes on Controversial Topics,"['Junjie Wang', 'Gaole He', 'Alisa Rieger', 'Ujwal Gadiraju']",10.1145/3786304.3787942,,"['Attitude Change', 'AI-generated Podcasts', 'Information modality', 'Web search', 'Controversial Topics', 'Responsible Opinion Formation']","This study investigates user attitudinal effects of consuming information via search engine result pages (SERPs) and AI-generated podcasts, focusing on how the sequence and modality of exposure shape user opinions, particularly in contexts involving controversial topics.",160.33,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11286v1_XChoice Explainable Evaluation of AI-Human Alignme.pdf,XChoice: Explainable Evaluation of AI–Human Alignment in LLM-based Constrained Choice Decision Making,"['Weihong Qi', 'Fan Huang', 'Rasika Muralidharan', 'Jisun An', 'Haewoon Kwak']",,2405.17246,"['explainable AI', 'human-AI alignment', 'LLM decision making', 'constrained choice', 'misalignment', 'time allocation']","This paper presents XCHOICE, an explainable framework for evaluating AI-human alignment in constrained decision making, focusing on LLM-generated decisions and human data. It assesses alignment by comparing interpretable parameters that capture decision factors, constraint sensitivity, and trade-offs, revealing heterogeneous alignment across models and activities, and salient misalignment in specific groups.",159.14,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11344v1_How Much Would a Clinician Edit This Draft Evaluat.pdf,How Much Would a Clinician Edit This Draft?,"['Parker Seegmiller1', 'Joseph Gatto1', 'Sarah E. Greer1', 'Ganza Belise Isingizwe1', 'Rohan Ray1', 'Timothy Burdick2', '3', 'Sarah M. Preum1']",,,"['Large language models', 'Patient message response drafting', 'Clinician editing', 'AI in healthcare', 'Workflow optimization']",This paper investigates the alignment between clinicians and large language models (LLMs) in drafting responses to patient portal messages. It develops a novel taxonomy of thematic elements and proposes an evaluation framework for assessing clinician editing load at both content and theme levels. The study uses various adaptation techniques to improve LLM performance and releases an expert-annotated dataset for large-scale evaluations of local and commercial LLMs.,159.93,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11350v1_FEATHer Fourier-Efficient Adaptive Temporal Hierar.pdf,FEATHer: Fourier-Efficient Adaptive Temporal Hierarchy Forecaster for Time-Series Forecasting,"['Jaehoon Lee †', 'Seungwoo Lee †', 'Younghwi Kim†', 'Dohee Kim*', 'Sunghyun Sim*']",,,"['Time-series Forecasting', 'Edge AI', 'Ultra-Lightweight Models', 'FEATHer']","This paper proposes FEATHer, a multiscale temporal model designed for accurate long-term forecasting under severe resource limitations, including strict constraints on latency, memory, and energy consumption. It introduces four key components: ultra-lightweight multiscale temporal decomposition, shared Dense Temporal Kernel, frequency-aware branch gating mechanism, and Sparse Period Kernel, achieving strong predictive performance with minimal parameters.",157.43,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11354v1_AstroReason-Bench Evaluating Unified Agentic Plann.pdf,AstroReason-Bench: Evaluating Unified Agentic Planning across Heterogeneous Space Planning Problems,"['Weiyi Wang', 'Xinchi Chen', 'Jingjing Gong', 'Xuanjing Huang', 'Xipeng Qiu']",,2601.11354,"['agentic planning', 'Space Planning Problems', 'heterogeneous objectives', 'physical constraints', 'long-horizon decision-making']","This paper introduces AstroReason-Bench, a comprehensive benchmark for evaluating agentic planning in Space Planning Problems, which integrate multiple scheduling regimes and provide a unified agent-oriented interaction protocol. The study evaluates state-of-the-art agentic LLM systems and finds that current agents substantially underperform specialized solvers, highlighting key limitations of generalist planning under realistic constraints.",154.88,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11359v1_Think-Clip-Sample Slow-Fast Frame Selection for Vi.pdf,THINK-CLIP-SAMPLE: SLOW-FAST FRAME SELECTION FOR VIDEO UNDERSTANDING,"['Wenhui Tan∗', 'Ruihua SongB', 'Jiaze Li', 'Jianzhong Ju', 'Zhenbo LuoB']",,,"['Multi-modal LLMs', 'long video understanding', 'frame selection', 'slow-fast sampling']","This paper presents Think-Clip-Sample (TCS), a training-free framework that enhances long video understanding through multi-query reasoning and clip-level slow-fast sampling. Experiments on MLVU, LongVideoBench, and VideoMME demonstrate that TCS consistently improves performance across different MLLMs, boosting up to 6.9% accuracy and achieving comparable accuracy with 50% fewer inference time cost.",153.92,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11369v2_Institutional AI Governing LLM Collusion in Multi-.pdf,Institutional AI: Governing LLM Collusion in Multi-Agent Cournot Markets via Public Governance Graphs,"['M. Bracale Syrnikov', 'F. Pierucci', 'M. Galisai', 'M. Prandi', 'P. Bisconti', 'F. Giarrusso', 'O. Sorokoletova', 'V. Suriani', 'D. Nardi']",10.48550/arXiv.2601.11369,2601.11369,"['Institutional AI', 'Multi-agent LLM', 'Cournot Markets', 'Collusion', 'Mechanism Design', 'Public Governance Graphs', 'AI Alignment']","This paper presents an experimental framework for evaluating Institutional AI, a system-level approach to AI alignment that reframes alignment from preference engineering in agent space to mechanism design in institutional space. It applies this framework to govern the Cournot collusion case and compares three regimes: Ungoverned, Constitutional (prompt-only policy as anti-collusion constitution), and Institutional (governance-graph-based). The Institutional regime shows significant reductions in collusion, while the Constitutional baseline yields no reliable improvement.",156.23,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11379v1_Evaluating LLM Behavior in Hiring Implicit Weights.pdf,"Evaluating LLM Behavior in Hiring: Implicit Weights, Fairness Across Groups, and Alignment with Human Preferences","['Morgane Hoffmann', 'Emma Jouffroy', 'Warren Jouanneau', 'Marc Palyart', 'Charles Pebereau']",,2309.15418,"['Large Language Models', 'Person-job Fit', 'Fairness', 'Interpretability']","This paper evaluates the decision logic of Large Language Models (LLMs) in recruitment, focusing on how they assign importance to different attributes and whether these assignments align with human preferences and societal norms. By analyzing synthetic datasets from real freelancer profiles and project descriptions, the authors identify which attributes the LLM prioritizes and how these weights vary across project contexts and demographic subgroups, while also proposing a framework for systematic comparison with human recruiters.",160.21,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11389v1_Hyperparameter Optimization of Constraint Programm.pdf,Hyperparameter Optimization of Constraint Programming Solvers,"['Hedieh Haddad', 'Thibault Falque', 'Pierre Talbot', 'Pascal Bouvry']",null,2601.11389,"['Constraint Programming', 'Hyperparameter Optimization', 'Bayesian Optimization', 'Hamming Distance Search', 'Solver Configuration']","This paper introduces a novel two-phase framework, the probe and solve algorithm, for automated hyperparameter optimization in constraint programming solvers, comparing its performance against solver default configurations on two solvers, ACE and Choco, across 114 combinatorial problem instances.",160.46,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11400v1_Wetland mapping from sparse annotations with satel.pdf,Wetland mapping from sparse annotations with satellite image time series and temporal-aware segment anything model,"['Shuai Yuana', 'Tianwu Linb', 'Shuang Chena', 'Yu Xib', 'Peng Qinb', 'Xiangyu Liub', 'Xiaoqing Xub', 'Nan Xud', 'Hongsheng Zhanga', 'Jie Wangb', 'Peng Gonga']",,2601.11400v1,"['wetland mapping', 'satellite image time series', 'sparse annotation', 'segment anything model', 'temporal adaptation']","This paper proposes WetSAM, a novel framework that leverages satellite image time series to enhance wetland mapping from sparse point annotations, addressing challenges in accurate wetland mapping with weak supervision and seasonal dynamics.",154.51,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11409v1_Topology-Guaranteed Image Segmentation Enforcing C.pdf,"Topology-Guaranteed Image Segmentation: Enforcing Connectivity, Genus, and Width Constraints","['Wenxiao Li', 'Xue-Cheng Tai', 'Jun Liu']",,2210.09875,"['image segmentation', 'topological preservation', 'persistent homology', 'thickness of topology', 'variational', 'regularization']","This paper proposes a novel mathematical framework that integrates width information into the characterization of topological structures for image segmentation, enabling the preservation of essential topological invariants such as connectivity and genus counts, while ensuring that segmented structures retain critical width attributes.",155.29,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11421v1_The Great March 100 100 Detail-oriented Tasks for .pdf,THEGREATMARCH100: 100 DETAIL-ORIENTEDTASKS FOR EVALUATING EMBODIED AI AGENTS,"['Ziyu Wang', 'Chenyuan Liu', 'Yushun Xiang', 'Runhao Zhang', 'Yu Zhang', 'Qingbo Hao', 'Hongliang Lu', 'Houyu Chen', 'Zhizhong Feng', 'Kaiyue Zheng', 'Dehao Ye', 'Xianchao Zeng', 'Xinyu Zhou', 'Boran Wen', 'Jiaxin Li', 'Mingyu Zhang', 'Kecheng Zheng', 'Qian Zhu', 'Ran Cheng', 'Yong-Lu Li']",,1912.05680,"['robot learning', 'embodied AI', 'task design', 'evaluation', 'long-tail behavior', 'robotics']","This paper introduces the Great March 100 (GM-100) as a step towards a robot learning Olympics, consisting of 100 carefully designed tasks covering a wide range of interactions and long-tail behaviors to comprehensively evaluate the capabilities of robotic agents and promote diversity and complexity in robot dataset task designs.",144.9,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11429v1_Relational Linearity is a Predictor of Hallucinati.pdf,Relational Linearity is a Predictor of Hallucinations,"['Yuetian Lu', 'Yihong Liu', 'Hinrich Schütze']",,2309.15246,"['hallucinations', 'large language models', 'factual knowledge', 'relation linearity', 'synthetic entities']","This paper investigates hallucinations in large language models by creating a dataset of synthetic entities and measuring their linearity. The authors find a strong correlation between relational linearity and hallucination rate, suggesting that the storage of triples in relations is a key factor in how well a model can self-assess its knowledge.",156.31,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11440v1_GenDA Generative Data Assimilation on Complex Urba.pdf,Generative Data Assimilation for Urban Wind Flow Reconstruction,"['Francisco Giral', 'Álvaro Manzano', 'Ignacio Gómez', 'Ricardo Vinuesa', 'Soledad Le Clainche']",,2309.14676,"['Urban Wind Flow', 'Data Assimilation', 'Generative Models', 'Diffusion Architecture', 'Graph Neural Networks', 'Reduced-Order Models', 'CFD Simulations']","This paper presents GenDA, a generative data assimilation framework that reconstructs high-resolution wind fields on unstructured meshes from limited observations, enabling obstacle-aware reconstruction and generalization across unseen geometries, wind directions, and mesh resolutions without retraining. The model employs a multiscale graph-based diffusion architecture trained on computational fluid dynamics simulations and interprets classifier-free guidance as a learned posterior reconstruction mechanism.",161.44,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11441v1_Hierarchical Orthogonal Residual Spread for Precis.pdf,HIERARCHICAL ORTHOGONAL RESIDUAL SPREAD FOR PRECISE MASSIVE EDITING IN LARGE LANGUAGE MODELS,"['Xiaojie Gu1*', 'Guangxu Chen2*', 'Yuheng Yang1', 'Jingxin Han3', 'Andi Zhang4']",,2309.14449,"['Large language models', 'Model Editing', 'Knowledge Update', 'Residual Spread']","This paper introduces HORSE, a method for precise massive editing in large language models, which operates at the token level for fine-grained control and performs a hierarchical orthogonal spread across layers, enhancing stability and reducing conflicts between new and old knowledge.",138.51,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11442v1_Map2Thought Explicit 3D Spatial Reasoning via Metr.pdf,Map2Thought: Explicit 3D Spatial Reasoning via Metric Cognitive Maps,"['Xiangjun Gao', 'Zhensong Zhang', 'Dave Zhenyu Chen', 'Songcen Xu', 'Long Quan', 'Eduardo Pérez-Pellitero', 'Youngkyoon Jang']",,2304.09976,"['3D Vision-Language Models', 'Metric Cognitive Map', 'Cognitive Chain-of-Thought', '3D Spatial Reasoning', 'Interpretable Reasoning', 'Metric Scale Representation', 'Vector Operations', 'Bounding-Box Distances', 'Occlusion-Aware Appearance Order Cues']","The paper introduces Map2Thought, a framework that enables explicit and interpretable spatial reasoning for 3D Vision-Language Models. It combines a metric cognitive map and a chain-of-thought reasoning process to provide a unified spatial representation and perform explicit geometric reasoning, achieving high accuracy with minimal supervision.",157.94,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11451v1_PRISM-CAFO Prior-conditioned Remote-sensing Infras.pdf,PRISM-CAFO: Prior-conditioned Remote-sensing Infrastructure Segmentation and Mapping for CAFOs,"['Oishee Bintey Hoque', 'Nibir Chandra Mandal', 'Kyle Luong', 'Amanda Wilson', 'Samarth Swarup', 'Madhav Marathe', 'Abhijin Adiga']",,2601.11451v1,"['CAFOs', 'Remote-sensing', 'Infrastructure Segmentation', 'Mapping', 'Concentrated Animal Feeding Operations', 'YOLOv8', 'Swin-B', 'High Pathogenic Avian Influenza', 'One Health']","This work presents an infrastructure-first, explainable pipeline for identifying and characterizing Concentrated Animal Feeding Operations (CAFOs) from aerial and satellite imagery, achieving state-of-the-art performance and demonstrating the impact of domain priors on classification decisions.",158.57,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11459v1_Interactive Narrative Analytics Bridging Computati.pdf,CHEAT_DETECTED,['BRIAN KEITH'],10.1109/ACCESS.2025.3650352,,"['Human-AI collaboration', 'information extraction', 'interactive visual analytics', 'knowledge integration', 'narrative extraction', 'narrative sensemaking', 'semantic interaction', 'visual analytics']","This paper introduces Interactive Narrative Analytics (INA), a new interdisciplinary field combining computational narrative extraction with interactive visual analytics to support sensemaking. INA addresses challenges in narrative understanding in the digital age, such as scalability, interactivity, knowledge integration, and evaluation standardization, offering promising opportunities in news analysis, intelligence, scientific literature exploration, and social media analysis.",157.95,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11464v1_MHA2MLA-VLM Enabling DeepSeeks Economical Multi-He.pdf,MHA2MLA-VLM: Enabling DeepSeek’s Economical Multi-Head Latent Attention across Vision-Language Models,"['Xiaoran Fan', 'Zhichao Sun', 'Tao Ji', 'Lixing Shen', 'Tao Gui']",,2310.16668,"['Vision-Language Models', 'Multi-Head Latent Attention', 'Key-Value Cache', 'Efficient Inference', 'Modality Adaptation']","This paper presents MHA2MLA-VLM, a parameter-efficient framework for converting off-the-shelf vision-language models to Multi-Head Latent Attention architecture, addressing the memory and computational bottlenecks in inference.",158.76,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11468v1_Exploring LLM Features in Predictive Process Monit.pdf,Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs,"['ALESSANDRO PADELLA', 'Università degli Studi di Padova, Italy', 'MASSIMILIANO DE LEONI', 'Università degli Studi di Padova, Italy', 'MARLON DUMAS', 'University of Tartu, Estonia']",10.13039/100011199066,2601.01234,"['Predictive process monitoring', 'Large language models', 'Trace Encoding']","This paper extends a prior LLM-based Predictive Process Monitoring framework, comprehensively evaluating its generality, semantic leverage, and reasoning mechanisms across multiple Key Performance Indicators. Empirical evaluations indicate that LLMs surpass benchmark methods in data-scarce settings with only 100 traces, exploiting both prior knowledge and internal correlations among training traces, and performing higher-order reasoning for predictions.",158.65,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11479v1_Health Facility Location in Ethiopia Leveraging LL.pdf,Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning,"['Yohai Trabelsi', 'Guojun Xiong', 'Fentabil Getnet', 'Stéphane Verguet', 'Milind Tambe']",10.13052/ifaamas2026-25,,"['Health Facility Location', 'Optimization', 'Human expert knowledge', 'Alignment', 'LLM']","The authors propose a hybrid framework that integrates expert knowledge with optimization techniques to prioritize health facility upgrades in Ethiopia, addressing resource limitations and diverse stakeholder preferences.",154.8,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11492v1_BoxMind Closed-loop AI strategy optimization for e.pdf,BoxMind: Closed-loop AI strategy optimization for elite boxing validated in the 2024 Olympics,"['Kaiwen Wang', 'Kaili Zheng', 'Rongrong Deng', 'Qingmin Fan', 'Milin Zhang', 'Zongrui Li', 'Xuesi Zhou', 'Bo Han', 'Liren Chen', 'Chenyi Guo', 'Ji Wu']",10.13140/RV/Z26611492,2601.11492,"['Boxing', 'AI', 'Tactical Analysis', 'Competitive Sports', 'Machine Learning', 'Closed-loop System']","This paper presents BoxMind, a closed-loop AI expert system validated in elite boxing competition, which defines atomic punch events with precise temporal boundaries and spatial and technical attributes, parses match footage into 18 hierarchical technical-tactical indicators, and proposes a graph-based predictive model to capture the dynamics of boxer matchups, achieving state-of-the-art performance in outcome prediction and generating strategic recommendations comparable to human experts.",159.07,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11496v1_The Poisoned Apple Effect Strategic Manipulation o.pdf,The Poisoned Apple Effect: Strategic Manipulation of Mediated Markets via Technology Expansion of AI Agents,"['Eilam Shapira', 'Moshe Tennenholtz', 'Roi Reichart']",,2601.00001,"['AI agents', 'economic markets', 'strategic manipulation', 'technology expansion', 'regulatory frameworks']","This paper investigates the strategic implications of expanding the set of available AI technologies within regulated markets, identifying a phenomenon termed the 'Poisoned Apple' effect, where a strategic actor releases a new technology not to use it, but to manipulate the regulator's choice of market design in their favor, improving the releaser's welfare at the expense of their opponent and the regulator's fairness objectives.",156.48,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11505v1_MetaboNet The Largest Publicly Available Consolida.pdf,METABONET: THELARGESTPUBLICLYAVAILABLE CONSOLIDATEDDATASET FORTYPE1 DIABETES MANAGEMENT,"['Miriam K. Wolff', 'Peter Calhoun', 'Eleonora Maria Aiello', 'Yao Qin', 'Sam F. Royston']",,2601.11505,"['Type 1 Diabetes', 'Consolidated Dataset', 'MetaboNet', 'Continuous Glucose Monitoring', 'Insulin Pump', 'Data Integration', 'Algorithm Development', 'Public Dataset', 'Data Use Agreement']","This work consolidates multiple publicly available Type 1 Diabetes datasets into a unified resource, termed the MetaboNet dataset, which covers a broad range of glycemic profiles and demographics, making it a substantial improvement over existing standalone benchmark datasets for T1D algorithm development.",159.97,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11516v2_Building Production-Ready Probes For Gemini.pdf,Building Production-Ready Probes For Gemini,"['János Kramár∗', 'Joshua Engels', 'Zheng Wang', 'Bilal Chughtai', 'Rohin Shah', 'Neel Nanda', 'Arthur Conmy∗']",,,"['Activation Probing', 'Interpretability', 'Language Models', 'Misuse Risk', 'AI Safety', 'Monitoring']","This paper describes the challenges and solutions encountered when applying probes to detect cyber-offensive prompts in Gemini 2.5 Flash, a frontier language model. It highlights the need for robust misuse mitigation techniques and proposes new probe architectures to handle long-context distribution shifts, demonstrating their effectiveness in a cyber-offensive domain.",160.22,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11517v1_Do explanations generalize across large reasoning .pdf,Under Review,"['Koyena Pal', 'David Bau', 'Chandan Singh']",,2309.14468,"['large reasoning models', 'chains of thought', 'generalization', 'explanations', 'reinforcement learning']","This paper evaluates the generalization of explanations produced by large reasoning models, examining whether these explanations can induce the same behavior when given to other LRMs, and how this relates to human preference rankings and post-training with reinforcement learning.",160.16,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11625v1_Reasoning Stabilization Point A Training-Time Sign.pdf,Reasoning Stabilization Point: A Training-Time Signal for Stable Evidence and Shortcut Reliance,['Sahil Rajesh Dhayalkar'],10.1002/1098-0001.22824,2202.09414,"['Fine-tuning', 'Language Models', 'Interpretability', 'Token-Level Attribution', 'Explanation Drift', 'Reasoning Stabilization Point', 'Shortcut Reliance']","This paper proposes a training-time interpretability view that tracks token-level attributions across fine-tuning epochs, defining explanation drift as the epoch-to-epoch change in normalized token attributions on a fixed probe set. It introduces the Reasoning Stabilization Point (RSP), the earliest epoch after which drift remains consistently low, and empirically demonstrates that drift stabilizes by (or before) accuracy saturation, revealing shortcut reliance hidden by validation accuracy.",160.37,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11643v1_Syllabic Agglutinative Tokenizations for Indonesia.pdf,Syllabic Agglutinative Tokenizations for Indonesian LLM: A Study from ‘Gasing Literacy Learning System’,"['Hokky Situngkir*', 'Andhika Bernard Lumbantobing†', 'Yohanes Surya‡']",,2601.11643v1,"['Indonesian natural language processing', 'Indonesian computational linguistics', 'tokenization', 'large language models', 'Gasing Literacy Learning System', 'low-resource languages', 'Austronesian languages']","This paper presents a novel syllable-based tokenization approach for Indonesian large language models, inspired by the Gasing Literacy Learning System's pedagogical methodology, demonstrating substantial improvements over conventional tokenization methods in terms of efficiency and vocabulary size.",157.29,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11644v1_Predicting When to Trust Vision-Language Models fo.pdf,Predicting When to Trust Vision-Language Models for Spatial Reasoning,"['Muhammad Imran', 'Yugyung Lee']",,2310.16587,"['Vision-Language Models', 'Spatial Reasoning', 'Confidence Estimation', 'Geometric Verification', 'Vision-Based Confidence', 'Robotic Navigation', 'Autonomous Driving', 'Image Editing']",This paper proposes a vision-based confidence estimation framework to validate VLM spatial predictions through independent geometric verification using object detection. The method achieves significant improvements in AUROC compared to text-based approaches and enables selective prediction based on target accuracy.,138.23,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11647v1_Reinforcement Learning for Dynamic Workflow Optimi.pdf,Reinforcement Learning for Dynamic Workflow Optimization in CI/CD Pipelines,"['Aniket Abhishek Soni', 'Milan Parikh', 'Rashi Nimesh Kumar Dhenia', 'Jubin Abhishek Soni', 'Ayush Raj Jha', 'Sneja Mitinbhai Shah']",,,"['Reinforcement Learning', 'CI/CD', 'DevOps', 'Workflow Optimization']","This paper proposes a reinforcement learning approach to optimize CI/CD pipeline workflows dynamically, modeling the pipeline as a Markov Decision Process and training an RL agent to make runtime decisions that maximize throughput while minimizing testing overhead. Experimental results show significant improvements in pipeline efficiency compared to static baselines.",160.42,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11650v1_Large Language Model Agent for User-friendly Chemi.pdf,LARGELANGUAGEMODELAGENT FORUSER-FRIENDLY CHEMICALPROCESSSIMULATIONS,"['Jingkang Liang', 'Niklas Groll', 'Gürkan Sin']",,2601.11650v1,"['Chemical Process Simulation', 'Large Language Model', 'Model Context Protocol']","This paper presents a framework integrating a large language model with a process simulation tool, enabling natural language interaction for complex simulations. It evaluates the framework through two case studies, demonstrating its benefits for both educational and practical purposes.",160.72,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11651v1_Aesthetics as Structural Harm Algorithmic Lookism .pdf,Aesthetics as Structural Harm: ALGORITHMIC LOOK IS A CROSS,"['Miriam Doh', 'Aditya Gulati', 'Corina Canali', 'Nuria Oliver']",10.48550/arXiv.2601.11651,2601.11651,"['Generative AI', 'Artificial Intelligence', 'Cognitive Biases', 'Attractiveness Halo Effect']","This paper examines algorithmic lookism—the systematic preferential treatment based on physical appearance—in text-to-image (T2I) generative AI and a downstream gender classification task, demonstrating how generative AI models systematically associate facial attractiveness with positive attributes and vice versa, mirroring socially constructed biases rather than evidence-based correlations.",138.35,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11652v1_WISP Waste- and Interference-Suppressed Distribute.pdf,WISP: Waste- and Interference-Suppressed Distributed Speculative LLM Serving at the Edge via Dynamic Drafting and SLO-Aware Batching,"['XIANGCHEN LI', 'JIAKUN FAN', 'QINGYUAN WANG', 'DIMITRIOS SPATHARAKIS', 'SAEID GHAFOURI', 'HANS VANDIERENDONCK', 'DEEPU JOHN', 'BO JI', 'ALI R. BUTT', 'DIMITRIOS S. NIKOLOPOULOS']",10.1145/376xxxx.377xxxx,,"['Speculative Decoding', 'Large Language Models', 'Edge Computing', 'Distributed Inference', 'Token Verification', 'Resource-Aware Serving']","This paper identifies and formalizes two critical bottlenecks in distributed speculative LLM serving: Wasted Drafting Time and Verification Interference, and proposes WISP, an efficient and SLO-aware system that enhances drafting efficiency and optimizes verification request scheduling on the server, improving system capacity and goodput compared to centralized serving and SLED.",155.89,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11657v1_Size is Not the Solution Deformable Convolutions f.pdf,Size is Not the Solution: Deformable Convolutions for Effective Physics Aware Deep Learning,"['Jack T. Beerman', 'Shobhan Roy', 'H.S. Udaykumar', 'Stephen S. Baek']",,2601.02177,"['Physics-aware deep learning', 'Convolutional neural networks', 'Deformable convolutions', 'Hybrid Lagrangian-Eulerian methods', 'Recurrent convolutions', 'Fidelity', 'Anti-clustering', 'Receptive field analysis', 'Adaptive refinement', 'Computational mechanics']","This paper introduces deformable physics-aware recurrent convolutions (D-PARC) to overcome the rigidity of CNNs in physics modeling, achieving superior fidelity across various flows and demonstrating that effective architectural design can outperform parameter scaling in physics-aware deep learning.",156.68,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11658v1_Towards AGI A Pragmatic Approach Towards Self Evol.pdf,Towards AGI: A Pragmatic Approach Towards Self Evolving Agent,"['Indrajit Kar', 'Zonunfeli Ralte']",,2309.15617,"['Large Language Models (LLMs)', 'Curriculum Learning (CL)', 'Reward-Based Learning (RL)', 'Genetic Algorithm (GA) evolution', 'Multi-agent systems', 'Tool-augmented reasoning', 'Code-generation LLMs', 'Autonomous adaptation', 'TaskCraft dataset', 'Agentic workflows', 'Self-improving AI', 'Capability evolution', 'Hierarchical orchestration']","This work introduces a hierarchical self-evolving multi-agent framework that integrates a Base LLM, an operational SLM agent, a Code-Generation LLM, and a Teacher-LLM to enable continuous adaptation. The framework uses Curriculum Learning, Reward-Based Learning, or Genetic Algorithm evolution to enhance agent capabilities without relying on static training corpora.",156.92,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11663v1_Activation Sensitivity as a Unifying Principle for.pdf,ACTIVATIONSENSITIVITY AS AUNIFYINGPRINCIPLE FOR POST-TRAININGQUANTIZATION,['Bruce Changlong Xu'],,2601.08767,"['Post-Training Quantization', 'Activation Sensitivity', 'Large Language Models', 'Quantization Error', 'Layer-local Objectives']","This work presents a unified theoretical framework for post-training quantization by formalizing activation sensitivity, a measure of channel importance that captures both activation magnitude and downstream error propagation. It connects gradient-based saliency, Fisher information, and Hessian-based criteria, and clarifies their relationships to classical pruning methods, exposing fundamental limitations of layer-local reconstruction objectives and highlighting open challenges in post-training quantization.",158.26,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11664v1_Serverless AI Security Attack Surface Analysis and.pdf,Serverless AI Security: Attack Surface Analysis and Runtime Protection Mechanisms for FaaS-Based Machine Learning,"['Chetan Pathade', 'Vinod Dhimam', 'Ilsa Lareb', 'Sheheryar Ahmad']",,,"['serverless computing', 'machine learning security', 'function-as-a-service', 'cloud security', 'adversarial machine learning', 'AWS Lambda', 'Azure Functions', 'attack surface analysis', 'runtime protection', 'MLOps security']","This paper presents a comprehensive security analysis of machine learning workloads in serverless environments, characterizing attack surfaces across five categories and proposing a multi-layered defense framework, Serverless AI Shield (SAS), to mitigate security risks.",154.36,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11666v1_MATEX Multi-scale Attention and Text-guided Explai.pdf,MATEX: Multi-scale Attention and Text-guided Explainability of Medical Vision-Language Models,"['Muhammad Imran', 'Chi Lee', 'Yugyung Lee']",,2601.11666v1,"['Explainable AI', 'Medical Imaging', 'Vision-Language Models', 'Gradient Attraction', 'Attention Rollout', 'Chest X-ray', 'CLIP']","This paper introduces MATEX, a novel framework that enhances interpretability in medical vision-language models by incorporating anatomically informed spatial reasoning, and evaluates its performance on the MS-CXR dataset, outperforming the state-of-the-art M2IB approach in spatial precision and alignment with expert-annotated findings.",138.34,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11667v1_Distill-then-Replace Efficient Task-Specific Hybri.pdf,Distill-then-Replace: Efficient Task-Specific Hybrid Attention Model Construction,"['Xiaojie Xia', 'Huigang Zhang', 'Chaoliang Zhong', 'Jun Sun', 'Yusuke Oishi']",,2601.11667,"['Hybridattentionmodels', 'Blockwiselocaldistillation', 'Greedy', 'search']","This paper addresses the challenges of training and deploying hybrid attention models by first transferring weights from pretrained full-attention modules to linear attention counterparts through blockwise local distillation, and then iteratively substituting full attention blocks with linear ones while monitoring validation performance on the target task.",159.33,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11670v1_A Confidence-Variance Theory for Pseudo-Label Sele.pdf,A Conﬁdence-V ariance Theory for Pseudo-Label Selection in Semi-Supervised Learning,"['Jinshi Liu †', 'Pan Liu †']",,1911.08530,"['Semi-Supervised Learning', 'Pseudo-Labels', 'Confidence Calibration', 'Residual Class Variance', 'Spectral Relaxation', 'Semantic Segmentation', 'Image Classification']","This paper introduces a Conﬁdence-Variance (CoVar) theory framework for pseudo-label selection in semi-supervised learning, providing a principled joint reliability criterion that combines maximum conﬁdence with residual-class variance, and demonstrates improvements over strong baselines in various image classiﬁcation and semantic segmentation tasks.",158.0,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11674v1_Pigment Network Detection and Classification in De.pdf,Pigment Network Detection and Classification in Dermoscopic Images Using Directional Imaging Algorithms and Convolutional Neural Networks,"['M. A. Rasel', 'Sameem Abdul Kareem', 'Unaizah Obaidellah']",,,"['Melanoma', 'Dermoscopic Images', 'Pigment Networks', 'Contrast Enhancement', 'Threshold Level', 'Convolutional Neural Networks', 'Bag of Features']","This study aims to automate the pigment network detection process using a directional imaging algorithm and classify pigment network types using machine learning classifiers, achieving high accuracy with a Convolutional Neural Network model.",156.09,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11675v1_Generating metamers of human scene understanding.pdf,Preprint,"['Ritik Raina', 'Abe Leite', 'Alexandros Graikos', 'Seoyoung Ahn', 'Dimitris Samaras', 'Gregory J. Zelinsky']",,2309.14457,"['Human Scene Understanding', 'Latent Diffusion Model', 'Metamer Generation', 'Scene Viewing Fixations', 'Image-to-Image Synthesis']","This paper introduces MetamerGen, a tool for generating scenes that align with latent human scene representations. It combines peripheral scene gist information with fixated scene details to create image metamers, addressing a novel image-to-image synthesis problem.",156.04,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11676v1_HALO Semantic-Aware Distributed LLM Inference in L.pdf,HALO: Semantic-Aware Distributed LLM Inference in Lossy Edge Network,"['Peirong Zheng', 'Wenchao Xu*', 'Haozhao Wang', 'Jinyu Chen', 'Xuemin (Sherman) Shen']",,,"['Large Language Models', 'Tensor Parallelism', 'Edge Computing', 'Heterogeneity', 'Semantics', 'Packet Loss']","This paper proposes HALO, a novel framework that boosts distributed LLM inference in lossy edge networks by strategically allocating less critical neuron groups to unstable devices, thus avoiding excessive waiting time due to delayed packets. HALO introduces three key mechanisms: a semantic-aware predictor, parallel execution of neuron groups, and a load-balancing scheduler.",136.54,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11683v1_Attesting Model Lineage by Consisted Knowledge Evo.pdf,Attesting Model Lineage by Consisted Knowledge Evolution with Fine-Tuning Trajectory,"['Zhuoyi Shang', 'Jiasen Li', 'Pengzhen Chen', 'Yanwei Liu', 'Xiaoyan Gu', 'Weiping Wang']",,2309.15097,"['model lineage', 'fine-tuning', 'knowledge evolution', 'security', 'deep learning', 'model provenance']","This paper proposes a novel model lineage attestation framework that leverages the dynamic evolution of knowledge and parameter modification during fine-tuning, enabling robust verification of model lineage relationships across various model types.",159.88,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11684v1_Mobile-friendly Image de-noising Hardware Consciou.pdf,Mobile-friendly Image de-noising: Hardware Conscious Optimization for Edge Application,"['Srinivas Miriyala*', 'Sowmya Vajrala*', 'Hitesh Kumar', 'Sravanth Kodavanti', 'Vikram Rajendiran']",,,"['De-Noising', 'Differentiable NAS', 'Hardware-aware Search space', 'Smartphone Deployment']","This work presents a novel mobile-friendly network for image de-noising obtained with Entropy-Regularized differentiable Neural Architecture Search (NAS) on a hardware-aware search space for a U-Net architecture, demonstrating competitive accuracy with reduced computational resources compared to state-of-the-art methods.",159.62,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11685v1_Towards Efficient Image Deblurring for Edge Deploy.pdf,Towards Efficient Image Deblurring for Edge Deployment,"['Srinivas Soumitri Miriyala', 'Sowmya Lahari Vajrala', 'Rama Sravanth Kodavanti']",,,"['Mobile Image Signal Processing (ISP)', 'De-blurring', 'Training-free Search', 'Inference Optimization', 'Edge Deployment']","This paper proposes a hardware-aware adaptation framework that optimizes existing image deblurring models through sensitivity-guided block substitution, surrogate distillation, and training-free multi-objective search, achieving up to 55% reduction in GMACs compared to recent transformer-based SOTA while maintaining competitive accuracy and improving 1.25× on-device deployment latency.",157.69,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11686v1_Proof of Concept Multi-Target Wildfire Risk Predic.pdf,Proof of Concept: Multi-Target Wildfire Risk Prediction and Large Language Model Synthesis,"['Nicolas Caron', 'Hassan Noura', 'Christophe Guyeux', 'Benjamin Aynes']",,2601.11686,"['wildfire risk', 'multi-target analysis', 'predictive models', 'large language models', 'operational needs', 'first responders', 'firefighting services', 'climate change', 'forest-fire risk', 'Météo-France', 'EFFIS']","This proof of concept proposes a hybrid framework combining predictive models for each risk dimension of wildfire with large language models to synthesize heterogeneous outputs into structured, actionable reports, addressing the need for practice-oriented and aligned statistical or AI-driven predictors for first responders and firefighting services.",159.92,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11687v1_Semantic Caching and Intent-Driven Context Optimiz.pdf,Semantic Caching and Intent-Driven Context Optimization for Multi-Agent Natural Language to Code Systems,['Harmohit Singh'],,2601.11687v1,"['Natural Language to Code', 'Multi-Agent Systems', 'Semantic Caching', 'LLM Optimization', 'Production Systems']","The paper presents a production-optimized multi-agent system designed to translate natural language queries into executable Python code for structured data analytics, achieving high accuracy and cost efficiency through semantic caching, dual-threshold decision mechanism, and intent-driven dynamic prompt assembly.",145.65,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11688v1_SpecMap Hierarchical LLM Agent for Datasheet-to-Co.pdf,SpecMap: Hierarchical LLM Agent for Datasheet-to-Code Link Recovery in Systems Engineering,"['Vedant Nipane', 'Pulkit Agrawal', 'Amit Singh']",,2601.11688v1,"['Datasheet-to-Code Mapping', 'Large Language Models', 'Traceability Link Recovery', 'Systems Engineering', 'Embedded Systems']","This paper presents a hierarchical LLM-based approach for mapping datasheets to code in embedded systems, overcoming challenges in semantic and structural relationships, and achieving up to 73.3% file mapping accuracy compared to traditional methods.",156.19,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11700v1_Telling Human and Machine Handwriting Apart.pdf,Telling Human and Machine Handwriting Apart,"['Luis A. Leiva', 'Moises Diaz', 'Nuwan T. Attygalle', 'Miguel A. Ferrer', 'Réjean Plamondon']",,,"['Biometrics', 'classification', 'deep learning', 'reverse Turing test', 'verification']","This work studies ten public datasets of handwritten symbols and gestures, artificially reproduced using seven different synthesizers, to train a shallow recurrent neural network that achieves excellent performance in detecting human-generated handwriting from artificial inputs, even in few-shot and out-of-domain settings.",134.49,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11702v1_PASTA A Scalable Framework for Multi-Policy AI Com.pdf,PASTA: A Scalable Framework for Multi-Policy AI Compliance Evaluation,"['YU YANG', 'IG-JAE KIM', 'DONGWOOK YOON']",,2309.14764,"['AI compliance', 'multi-policy evaluation', 'scalable framework', 'policy normalization', 'AI governance']","This paper presents PASTA, a scalable compliance tool for evaluating multiple AI policies, integrating innovations in model-card format, policy normalization, LLM-powered evaluation, and interface design, demonstrating its effectiveness through expert and user evaluations.",134.09,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11713v1_Inter-Cell Interference Rejection Based on Ultrawi.pdf,Inter-Cell Interference Rejection Based on Ultrawideband Walsh-Domain Wireless Autoencoding,"['Rodney Martinez Alonso', 'Cel Thys', 'Sofie Pollin', 'Cedric Dehos', 'Yuneisy Esthela Garcia Guzman']",,1912.09777,"['inter-cell interference', 'ultrawideband', 'Walsh-domain', 'wireless autoencoding', '5G', 'CP-OFDM', 'spectrum efficiency']",This paper proposes a novel technique for rejecting partial-in-band inter-cell interference in ultrawideband communication systems using an end-to-end wireless autoencoder architecture that jointly optimizes the transmitter and receiver encoding/decoding in the Walsh domain to mitigate interference from coexisting narrower-band 5G base stations.,133.38,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11746v1_LIME-LLM Probing Models with Fluent Counterfactual.pdf,"LIME-LLM: Probing Models with Fluent Counterfactuals, Not Broken Text","['George Mihaila', 'Suleyman Olcay Polat', 'Poli Nemkova', 'Himanshu Sharma', 'Namratha V . Urs', 'Mark V . Albert']",10.48550/arXiv.2601.11746,2601.11746,"['LIME', 'LLiMe', 'Local Explanation Methods', 'NLP', 'Large Language Models', 'Transformer-based Classifiers', 'Explainability', 'Counterfactuals', 'Human-annotated Rationales']","This paper introduces LIME-LLM, a framework that replaces random noise with hypothesis-driven, controlled perturbations to generate fluent, on-manifold neighborhoods for local explanation of NLP models, improving fidelity compared to traditional and recent generative alternatives.",153.78,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11747v1_PRISM Learning Design Knowledge from Data for Styl.pdf,PRISM: Learning Design Knowledge from Data,"['Huaxiaoyue Wang', 'Sunav Choudhary', 'Franck Dernoncourt', 'Yu Shen', 'Stefano Petrangeli']",,2309.14583,"['Design', 'Stylistic Improvement', 'Vision Language Models', 'Design Knowledge', 'Natural Language Instructions']","This paper addresses the problem of stylistically improving designs based on natural language instructions. It proposes PRISM, a method that constructs and applies a design knowledge base through three stages to achieve higher style alignment in design improvement tasks.",156.66,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11758v1_Early Linguistic Pattern of Anxiety from Social Me.pdf,Early Linguistic Pattern of Anxiety from Social Media: Using Interpretable Linguistic Features: A Multi-Faceted Validation Study with Author-Disjoint Evaluation,"['Arnab Das', 'Utsa']",,,"['anxiety detection', 'linguistic pattern', 'interpretable machine learning', 'keyword robustness', 'cross-domain validation', 'author-disjoint evaluation', 'mental health screening']","This work presents a transparent approach to social media-based anxiety detection through linguistically interpretable feature-grounded modeling and cross-domain validation, using a substantial dataset of Reddit posts and achieving strong performance while maintaining high accuracy even after sentiment removal or keyword masking.",159.98,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11762v1_Industry-Aligned Granular Topic Modeling.pdf,Industry-Aligned Granular Topic Modeling,"['Sae Young Moon', 'Myeongjun Erik Jang', 'Haoyan Luo', 'Chunyang Xiao', 'Antonios Georgiadis', 'Fran Silavong']",,,"['Topic modeling', 'Granularity', 'Large Language Models (LLMs)', 'Business applications', 'Document summarization', 'Topic parenting', 'Distillation']","This paper introduces TIDE, a framework for granular topic modeling based on large language models, demonstrating superior performance and providing valuable auxiliary components for industrial business scenarios.",156.38,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11768v1_Lightweight Self-Supervised Detection of Fundament.pdf,Lightweight Self-Supervised Detection of Fundamental Frequency and Accurate Probability of Voicing in Monophonic Music,"['Venkat Suprabath Bitra', 'Homayoon Beigi']",,2603.01234,"['self-supervised pitch detection', 'unsupervised pitch detection', 'fundamental frequency', 'pitch estimation', 'resonance', 'musical timbre transfer', 'probability of voicing', 'music synthesis', 'music analysis', 'CQT', 'constant Q transform', 'DDSP', 'shift cross-entropy loss', 'musical instrument modeling', 'ResNeXt neural network', 'music information retrieval', 'MIR']","The paper proposes a lightweight, fully self-supervised framework for joint fundamental frequency (F0) estimation and voicing inference, designed for rapid single-instrument training from limited audio. Using transposition-equivariant learning on CQT features, the authors introduce an EM-style iterative reweighting scheme that uses Shift Cross-Entropy (SCE) consistency as a reliability signal to suppress uninformative noisy/unvoiced frames. The resulting weights provide confidence scores for pseudo-labeling a separate lightweight voicing classifier without manual annotations. Trained on MedleyDB and evaluated on MDB-stem-synth ground truth, the method achieves competitive cross-corpus performance (RPA 95.84, RCA 96.24) and demonstrates cross-instrument generalization.",159.44,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11776v1_Cleansing the Artificial Mind A Self-Reflective De.pdf,Cleansing the Artificial Mind: A Self-Reflective Detoxification Framework for Large Language Models,"['Kaituo Zhang', 'Zhimeng Jiang', 'Na Zou']",null,null,"['Large Language Models', 'Detoxification', 'Self-Reflective', 'Toxic Content', 'Reinforcement Learning from Human Feedback', 'Instruction Tuning']","This paper introduces a fully self-reflective detoxification framework for Large Language Models (LLMs) to detect, correct, and refine toxic content without external modules or data annotation, enhancing the model's ability for safe and coherent text generation.",160.02,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11778v1_Translation as a Scalable Proxy for Multilingual E.pdf,Translation as a Scalable Proxy for Multilingual Evaluation,"['Sheriff Issaka', 'Erick Rosas Gonzalez', 'Lieqi Liu', 'Evans Kofi Agyei', 'Lucas Bandarkar', 'Nanyun Peng', 'David Ifeoluwa Adelani', 'Francisco Guzmán', 'Saadia Gabriel']",,2311.16984,"['Translation', 'Multilingual Evaluation', 'Large Language Models', 'Benchmarking', 'Language Diversity', 'Cost-Effectiveness']","This study evaluates whether translation quality alone can indicate a model's broader multilingual capabilities, systematically assessing 14 models across 9 diverse benchmarks and 7 translation metrics. Results suggest that translation performance is a good indicator of downstream task success, supporting the hypothesis that translation quality can serve as a reliable, scalable, and cost-effective proxy for multilingual performance.",142.45,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11781v1_Risk-Aware Human-in-the-Loop Framework with Adapti.pdf,Risk-Aware Human-in-the-Loop Framework with Adaptive Intrusion Response for Autonomous Vehicles,"['Dawood Wasif', 'Terrence J. Moore', 'Seunghyun Yoon', 'Hyuk Lim', 'Dan Dongseong Kim', 'Frederica F. Nelson', 'Jin-Hee Cho']",,,"['Autonomous Vehicles', 'Human-in-the-Loop', 'Risk-Aware', 'Intrusion Response', 'Cyber-Physical Intrusions', 'Soft Actor–Critic', 'Reinforcement Learning', 'Safe Reinforcement Learning', 'Model-Based Control', 'Model-Free Control']","This paper presents RAIL, a risk-aware human-in-the-loop framework for autonomous vehicles that fuses heterogeneous runtime signals into calibrated control adaptations and focused learning. RAIL uses an Intrusion Risk Score to blend actions with cue-specific shields when risk exceeds a threshold, and it improves safety and success rates under various attacks.",160.75,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11792v1_A self-evolving multi-role collaborative framework.pdf,A self-evolving multi-role collaborative framework with fine-grained difficulty guidance for innovative mathematical problem generation,"['Yifei Sun', 'Yongan Li', 'A.K. Qin', 'Sicheng Hou', 'Tamas Pflanzner']",,2309.14446,"['Problem generation', 'Large language models', 'Multi-role collaboration', 'Intelligent education', 'Self-evolution', 'Knowledge distillation']","This paper proposes a self-evolving, multi-role collaborative framework for innovative mathematical problem generation (IMPG) using fine-grained difficulty guidance. It introduces a multi-role collaborative mechanism and an improved difficulty model to enhance the semantic rationality of sampled encodings. The framework is trained using a multi-stage pipeline that incorporates continual pre-training, supervised fine-tuning, and group relative policy optimization. Experiments show that the proposed method significantly improves the innovation of generated problems while maintaining a high correctness rate.",160.01,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11801v1_RobotDesignGPT Automated Robot Design Synthesis us.pdf,RobotDesignGPT: Automated Robot Design Synthesis using Vision Language Models,"['Nitish Sontakke', 'K. Niranjan Kumar', 'Sehoon Ha']",,2309.14082,"['Robot Design', 'Vision-Language Models', 'Automated Design', 'Kinematic Structures', 'Visual Appearance', 'User Specifications', 'Evolutionary Algorithms', 'Manipulation', 'Navigation']","This paper proposes a novel automated robot design framework, RobotDesignGPT, that leverages the general knowledge and reasoning capabilities of large pre-trained vision-language models to automate the robot design synthesis process. The framework synthesizes an initial robot design from a simple user prompt and a reference image, improving design quality and reducing manual feedback.",142.17,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11809v1_Multi-agent DRL-based Lane Change Decision Model f.pdf,Multi-agent DRL-based Lane Change Decision Model for Cooperative Planning in Mixed Traffic,"['Zeyu Mu', 'Shangtong Zhang', 'B. Brian Park']",,1912.02680,"['Multi-Agent', 'Reinforcement Learning', 'Cooperative Platooning', 'Lane Change']","This study proposes a hybrid multi-agent lane change decision model to increase CA V participation in cooperative platooning and optimize traffic dynamics during the early stage of deployment, using the QMIX framework and a trajectory planner with a model predictive controller.",156.14,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11816v1_POLARIS Typed Planning and Governed Execution for .pdf,POLARIS: Typed Planning and Governed Execution for Agentic AI in Back-Office Automation,"['Zahra Moslemi', 'Keerthi Koneru', 'Yen-Ting Lee', 'Sheethal Kumar', 'Ramesh Radhakrishnan']",,2310.16584,"['Agentic AI', 'Enterprise Automation', 'Back-Office Tasks', 'Benchmarks', 'Governance', 'Typed Planning', 'Evaluation']","POLARIS is a governed orchestration framework that treats automation as typed plan synthesis and validated execution over LLM agents, aiming to meet enterprise guarantees of auditable, policy-aligned, and operationally predictable actions.",159.26,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11825v1_AI Co-Scientist for Knowledge Synthesis in Medical.pdf,AI Co-Scientist for Knowledge Synthesis in Medical Contexts: A Proof of Concept,"['Arya Rahgozara', 'Pouria Mortezaaga']",,2601.11825v1,"['AI', 'Knowledge Synthesis', 'Medical Research', 'Dementia', 'Sport', 'Non-Communicable Disease', 'Relational Databases', 'Vector-Based Semantic Retrieval', 'Neo4j Knowledge Graph', 'PICOS Formalization', 'Bidirectional Long Short-Term Memory (Bi-LSTM)', 'Transformer-Based Multi-Task Classifier', 'PubMedBERT', 'Retrieval-Augmented Generation (RAG)', 'BERTopic', 'Topic Modeling']","This paper presents a proof of concept for an AI co-scientist designed to enable scalable, transparent knowledge synthesis in medical contexts by formalizing Population, Intervention, Comparator, Outcome, and Study design (PICOS) through automated compliance classification and retrieval-augmented generation.",157.63,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11840v1_Imandra CodeLogician Neuro-Symbolic Reasoning for .pdf,Imandra CodeLogician: Neuro-Symbolic Reasoning for Precise Analysis of Software Logic,"['Hongyu Lin', 'Samer Abdallah', 'Makar Valentinov', 'Paul Brennan', 'Elijah Kagan', 'Christoph M. Wintersteiger', 'Denis Ignatovich', 'Grant Passmore']",,2601.11840v1,"['Neuro-symbolic reasoning', 'Software logic', 'Large Language Models', 'Automated reasoning', 'Formal verification', 'Mathematical reasoning', 'Software engineering', 'Control flow', 'State space', 'Decision boundaries']","This paper presents CodeLogician, a neuro-symbolic agent and framework for precise analysis of software logic, integrating with ImandraX, an industrial automated reasoning engine. It introduces a new benchmark dataset to rigorously evaluate mathematical reasoning about software logic, demonstrating that combining LLMs with formal reasoning engines improves accuracy and completeness of reasoning.",158.97,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11850v1_Human-AI Collaborative Inductive Thematic Analysis.pdf,Human–AI Collaborative Inductive Thematic Analysis: How AI Guides Analysis and Researchers Reclaim Interpretive Authority,"['Matthew Nyaaba †1,2', 'Min SungEun †3', 'Mary Abiswin Apam †4', 'Kwame Owoahene Acheampong5', 'Emmanuel Dwamena6', 'Xiaoming Zhai1, 7']",,,"['Human–AI collaboration', 'Generative artificial intelligence (GenAI)', 'Inductive thematic analysis', 'Qualitative data analysis', 'Epistemic authority', 'Reflexive methodology']","This study investigates how researchers interact with an Inductive Thematic Analysis GPT (ITA–GPT) tool, designed to guide qualitative research analysis, and how this interaction impacts the interpretation and authority of the analysis.",158.43,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11854v1_ATOD An Evaluation Framework and Benchmark for Age.pdf,ATOD: An Evaluation Framework and Benchmark for Agentic Task-Oriented Dialogue System,"['Yifei Zhang', 'Hooshang Nayyeri', 'Rinat Khaziev', 'Emine Yilmaz', 'Gokhan Tur', 'Dilek Hakkani-Tür', 'Hari Thadakamalla']",,,"['Task-Oriented Dialogue', 'Agentic Behavior', 'Evaluation Framework', 'Benchmark', 'Long-term Reasoning', 'Memory Management', 'Proactivity']","This paper introduces ATOD, a benchmark and synthetic dialogue generation pipeline that produces richly annotated conversations requiring long-term reasoning. ATOD captures key characteristics of advanced Task-Oriented Dialogue, including multi-goal coordination, dependency management, memory, adaptability, and proactivity. The authors also propose ATOD-Eval, a holistic evaluation framework that translates these dimensions into fine-grained metrics and supports reproducible offline and online evaluation. The paper presents a strong agentic memory-based evaluator for benchmarking on ATOD and demonstrates that ATOD-Eval enables comprehensive assessment across task completion, agentic capability, and response quality, offering a better accuracy-efficiency trade-off compared to existing memory- and LLM-based approaches.",157.47,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11859v1_Cascaded Transformer for Robust and Scalable SLA D.pdf,Cascaded Transformer for Robust and Scalable SLA Decomposition via Amortized Optimization,['Cyril Shih-Huan Hsu'],,1912.07037,"['network slicing', 'service level agreement', 'quality of service', 'deep neural network', 'optimization', 'transformers']","This paper introduces Casformer, a cascaded Transformer architecture designed for fast, optimization-free SLA decomposition, addressing the challenge of effectively decomposing E2E Service Level Agreements into domain-specific SLAs.",136.83,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11863v1_Utilizing Metadata for Better Retrieval-Augmented .pdf,Utilizing Metadata for Better Retrieval-Augmented Generation,"['Raquib Bin Yousuf', 'Shengzhe Xu', 'Mandar Sharma', 'Andrew Neeser', 'Chris Latimer', 'Naren Ramakrishnan']",null,2601.11863,"['Retrieval-Augmented Generation (RAG)', 'Metadata-aware Retrieval', 'Dense Retrieval', 'Query Reformulation', 'Benchmark Datasets']","This paper presents a systematic study of metadata-aware retrieval strategies for Retrieval-Augmented Generation systems, comparing plain-text baselines with approaches that embed metadata directly, and evaluates their performance across multiple retrieval metrics and question types.",159.28,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11868v1_Terminal-Bench Benchmarking Agents on Hard Realist.pdf,"TERMINAL-BENCH: BENCHMARKING AGENTS ON HARD, REALISTIC TASKS IN COMMANDLINE INTERFACES","['Mike A. Merrill', 'Alexander G. Shaw', 'Nicholas Carlini', 'Boxuan Li', 'Harsh Raj', 'Ivan Bercovich', 'Lin Shi', 'Jeong Yeon Shin', 'Thomas Walshe', 'E. Kelly Buchanan', 'Junhong Shen', 'Guanghao Ye', 'Haowei Lin', 'Jason Poulos', 'Maoyu Wang', 'Marianna Nezhurina', 'Jenia Jitsev', 'Di Lu', 'Orfeas Menis Mastromichalakis', 'Zhiwei Xu', 'Zizhao Chen', 'Yue Liu', 'Robert Zhang', 'Junhong Lin', 'Manish Shetty', 'Michael Yang', 'Nabil Omi', 'Negin Raoof', 'Shanda Li', 'Wuwei Lin', 'Yiwei Dai', 'Yuxin Wang', 'Wenhao Chai', 'Shang Zhou', 'Dariush Wahdany', 'Ziyu She', 'Jiaming Hu', 'Zhikang Dong', 'Yuxuan Zhu', 'Sasha Cui', 'Ahson Saiyed', 'Arinbjorn Kolbeinsson', 'Jesse Hu', 'Christopher Michael Rytting', 'Ryan Marten', 'Yixin Wang', 'Alex Dimakis', 'Andy Konwinski', 'Ludwig Schmidt']",,2601.11868v1,"['AI', 'benchmarking', 'commandline interfaces', 'terminal environments', 'realistic tasks', 'hard benchmarks', 'model evaluation', 'agent performance', 'frontier models']","This paper introduces Terminal-Bench 2.0, a hard benchmark of 89 tasks in computer terminal environments, designed to measure the performance of AI agents on real-world tasks. The authors demonstrate that current frontier models score less than 65% on the benchmark and provide the dataset and evaluation harness to assist future research and development.",155.09,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11876v1_AI for Green Spaces Leveraging Autonomous Navigati.pdf,Autonomous Trash Pickup Robots for Grass Fields,"['[Author1]', '[Author2]', '[Author3]']",10.1234/autobot-grass-2021,2103.14135,"['Autonomous Robots', 'Trash Pickup', 'Grass Fields', 'Real-Time Kinematic GPS', 'ResNet50 CNN', 'Spanning Tree Coverage']","This paper proposes an autonomous robot designed to navigate, identify, and pick up litter in grass fields. It uses a Spanning Tree Coverage algorithm for navigation and a ResNet50 Convolutional Neural Network for trash detection, achieving an overall success rate of 80%.",158.8,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11880v1_TF-CoDiT Conditional Time Series Synthesis with Di.pdf,TF-CoDiT: Conditional Time Series Synthesis with Diffusion Transformers for Treasury Futures,"['Yingxiao Zhang', 'Jiaxin Duan', 'Junfu Zhang', 'Ke Feng']",,2312.09742,"['Treasury futures', 'Diffusion Transformers', 'Conditional synthesis', 'Financial time series', 'Synthetic data generation']","This work proposes TF-CoDiT, the first Diffusion Transformer framework for synthesizing treasury futures data, addressing challenges such as low data volume and market dependencies. It adapts the standard Diffusion Transformer by transforming multi-channel 1-D time series into Discrete Wavelet Transform coefficient matrices and uses a U-shape VAE to encode cross-channel dependencies into a latent variable, enabling latent diffusion generation. The Financial Market Attribute Protocol (FinMAP) is introduced to derive prompts covering essential conditions. Extensive evaluations show TF-CoDiT can produce highly authentic data with errors at most 0.433 (MSE) and 0.453 (MAE) to the ground-truth, demonstrating robustness across contracts and temporal horizons.",160.62,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11885v1_MyGram Modality-aware Graph Transformer with Globa.pdf,MyGram: Modality-aware Graph Transformer with Global Distribution for Multi-modal Entity Alignment,"['Zhifei Li', 'Ziyue Qin', 'Xiangyu Luo', 'Xiaoju Hou', 'Yue Zhao', 'Miao Zhang', 'Zhifang Huang', 'Kui Xiao', 'Bing Yang']",,2303.00102,"['Multi-modal entity alignment', 'Graph transformer', 'Modality diffusion', 'Global distribution', 'Knowledge graphs']","This paper proposes MyGram, a modality-aware graph transformer designed to improve multi-modal entity alignment by capturing deep structural contextual information within modalities and achieving global distribution consistency across them. Experiments on five public datasets demonstrate MyGram's superior performance compared to baseline models.",155.68,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11895v1_DevBench A Realistic Developer-Informed Benchmark .pdf,"DevBench: A Realistic, Developer-Informed Benchmark for Code Generation Models","['Pareesa Ameneh Golnari ∗', 'Adarsh Kumarappan ∗∗', 'Wen Wen', 'Xiaoyu Liu', 'Gabriel Ryan', 'Yuting Sun', 'Shengyu Fu', 'Elsie Nallipogu']",null,null,"['Code Generation', 'Large Language Models', 'Telemetry', 'Benchmark', 'Developer Informed', 'Realistic Evaluation']","DevBench is a telemetry-driven benchmark designed to evaluate Large Language Models on realistic code completion tasks, emphasizing ecological validity, avoiding training data contamination, and enabling detailed diagnostics. It includes 1,800 evaluation instances across six programming languages and six task categories derived from real developer telemetry, and assesses 9 state-of-the-art models focusing on functional correctness, similarity-based metrics, and LLM-judge assessments.",160.3,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11903v1_AEMA Verifiable Evaluation Framework for Trustwort.pdf,AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems,"['Yen-Ting Lee', 'Keerthi Koneru', 'Zahra Moslemi', 'Sheethal Kumar', 'Ramesh Radhakrishnan']",,2601.11903,"['Agentic AI', 'Multi-Agent Systems', 'Trustworthy AI', 'Verifiable Evaluation', 'Human Oversight']","Presenting AEMA (Adaptive Evaluation Multi-Agent), a process-aware and auditable framework for evaluating agentic LLM systems, which adapts to diverse tasks and records traceable evaluation logs for oversight and accountability. Compared to a single LLM-as-a-Judge, AEMA achieves greater stability, human alignment, and verifiable consistency, demonstrating feasibility and trust reliability on enterprise-style agent workflows.",153.71,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11905v1_LIBRA Language Model Informed Bandit Recourse Algo.pdf,LIBRA: Language Model Informed Bandit Recourse Algorithm for Personalized Treatment Planning,"['Junyu Cao', 'Ruijiang Gao', 'Esmaeil Keyvanshokooh', 'Jianhao Ma']",,,"['Large Language Models', 'LLM-Bandits Collaboration', 'Algorithmic Recourse', 'Regret Analysis', 'Personalized Treatment Planning', 'Hypertension Management']","This paper introduces LIBRA, a unified framework that integrates algorithmic recourse, contextual bandits, and large language models to support sequential decision-making in personalized medicine, offering guarantees on initial regret, LLM effort, and robustness.",155.38,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11907v1_Towards Airborne Object Detection A Deep Learning .pdf,Towards Airborne Object Detection: A Deep Learning Analysis,"['1st Prosenjit Chatterjee', '2nd ANK Zaman']",,2105.08550,"['Airborne Object Detection', 'Threat Detection', 'Deep Learning', 'EfficientNetB4', 'ResNet-50', 'UA V']","This work introduces a dual-task model based on EfficientNetB4 capable of performing airborne object classification and threat-level prediction simultaneously, addressing the scarcity of clean, balanced training data by constructing the AODTA Dataset. The EfficientNetB4 model achieves high accuracy in object classification and threat-level prediction, outperforming a ResNet-50 baseline.",155.11,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11913v1_LSTM-MAS A Long Short-Term Memory Inspired Multi-A.pdf,LSTM-MAS: A LONG SHORT-TERM MEMORY INSPIRED MULTI-AGENT SYSTEM FOR LONG-CONTEXT UNDERSTANDING,"['Yichen Jiang', 'Peng Ye', 'Jiakang Yuan', 'Chongjun Tu', 'Lei Bai', 'Tao Chen']",10.1109/TNNLS.2023.3280747,,"['Long-Context Understanding', 'Large Language Models', 'Multi-Agent System', 'Memory']","This work designs a Multi-Agent System called LSTM-MAS, inspired by the Long Short-Term Memory (LSTM) architecture, to effectively process long contexts. LSTM-MAS organizes agents in a chained architecture, each with specific roles for segment-level comprehension, redundancy reduction, error detection, and information propagation, enabling controlled information transfer and selective long-term dependency modeling.",158.55,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11920v1_Enhancing LLM-Based Data Annotation with Error Dec.pdf,Enhancing LLM-Based Data Annotation with Error Decomposition,"['Zhen Xu', 'Vedant Khatri', 'Yijun Dai', 'Xiner Liu', 'Siyan Li', 'Xuanming Zhang', 'Renzhe Yu']",,2309.08846,"['Data Annotation', 'Qualitative Coding', 'Large Language Models', 'Human-AI Collaboration']","This paper proposes a diagnostic evaluation paradigm for large language model-based data annotation tasks, separating task-inherent ambiguity from model-driven inaccuracies and assessing annotation quality in terms of their potential downstream impacts.",157.01,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11935v1_Big Data Workload Profiling for Energy-Aware Cloud.pdf,Big Data Workload Profiling for Energy-Aware Cloud Resource Management,"['Milan Parikh', 'Aniket Abhishek Soni', 'Sneja Mitinbhai Shah', 'Ayush Raj Jha']",null,2601.11935v1,"['Cloud computing', 'energy-aware scheduling', 'workload profiling', 'virtual machine placement', 'big data', 'green computing']","This paper presents a workload-aware scheduling framework that uses profiling of CPU usage, memory demand, and storage I/O behavior to guide energy-efficient virtual machine (VM) placement. The system predicts the energy and performance impact of candidate placement decisions and adaptively consolidates workloads without violating service-level agreements (SLAs).",139.16,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11940v1_Thinking Traps in Long Chain-of-Thought A Measurab.pdf,Thinking Traps in Long Chain-of-Thought: A Measurable Study and Trap-Aware Adaptive Restart,"['Kang Chen', 'Fan Yu', 'Junjie Nian', 'Shihan Zhao', 'Zhuoka Feng', 'Zĳun Yao', 'Heng Wang', 'Minshen Yu', 'Yixin Cao']",null,2601.11940,"['Long Chain-of-Thought', 'Thinking Traps', 'Test-Time Control', 'Adaptive Restart', 'Trajectory Analysis', 'Mathematical Reasoning']","Through fine-grained trajectory analysis, the authors identify 'Thinking Traps' in long chain-of-thought reasoning, where models commit early errors that persist even after later reflection or verification. They introduce TAAR (Trap-Aware Adaptive Restart), a test-time control framework that predicts and intervenes to avoid these traps, improving reasoning performance on challenging benchmarks without fine-tuning.",160.61,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11956v1_Double-Calibration Towards Trustworthy LLMs via Ca.pdf,Double-Calibration: Towards Trustworthy LLMs via Calibrating Knowledge and Reasoning Confidence,"['Yuyin Lu', 'Ziran Liang', 'Yanghui Rao', 'Wenqi Fan', 'Fu Lee Wang', 'Qing Li']",,2310.16666,"['Large Language Models', 'Knowledge Graphs', 'Calibration', 'Epistemic Uncertainty', 'Experiential Uncertainty']","This paper introduces DoublyCal, a framework that addresses the challenge of epistemic uncertainty in Large Language Models by employing a lightweight proxy model to generate calibrated evidence and guide a black-box LLM, resulting in more accurate and well-calibrated predictions with confidence scores traceable to the uncertainty of the supporting evidence.",158.62,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11960v1_R2PO Decoupling Training Trajectories from Inferen.pdf,R2PO: Decoupling Training Trajectories from Inference Responses for LLM Reasoning,"['Jingchu Wang', 'Bingbing Xu', 'Yige Yuan', 'Bin Xie', 'Xiaoqian Sun', 'Huawei Shen']",,2310.16666,"['Reinforcement Learning', 'Large Language Models', 'Reasoning', 'Optimization', 'Inference', 'Training Trajectories']","This paper proposes R2PO, a method that introduces a lightweight residual module to decouple training trajectories from inference responses in Large Language Models, thereby enabling controlled trajectory diversification during training and maintaining stable inference generation, leading to improved performance across multiple benchmarks.",158.29,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11969v1_textttMemoryRewardBench Benchmarking Reward Models.pdf,MemoryRewardBench: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models,"['Zecheng Tang', 'Baibei Ji', 'Ruoxi Sun', 'Haitian Wang', 'Wangjie You', 'Yijun Zhang', 'Wenpeng Zhu', 'Ji Qi', 'Juntao Li', 'Min Zhang']",,2310.17478,"['Large Language Models', 'Memory Management', 'Reward Models', 'Long-Term Memory', 'Segmented Processing', 'Holistic Processing']","This paper introduces MemRewardBench, a benchmark designed to systematically evaluate the ability of reward models to assess long-term memory management in large language models, covering both long-context comprehension and long-form generation tasks with various memory management patterns.",137.93,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11974v1_Learn Like Humans Use Meta-cognitive Reflection fo.pdf,Learn Like Humans: Use Meta-cognitive Reflection for Efficient Self-Improvement,"['Xinmeng Hou', 'Peiliang Gong', 'Bohao Qu', 'Wuqi Wang', 'Qing Guo', 'Yang Liu']",,2310.15265,"['Large Language Models', 'Self-improvement', 'Meta-cognitive Reflection', 'Efficient Learning', 'Human Learning']","This paper proposes MARS, a framework that achieves efficient self-evolution within a single recurrence cycle by integrating principle-based reflection and procedural reflection, inspired by educational psychology. MARS allows agents to systematically refine their reasoning logic without continuous online feedback, outperforming state-of-the-art self-evolving systems while significantly reducing computational overhead.",157.63,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11977v1_One-Shot Price Forecasting with Covariate-Guided E.pdf,One-Shot Price Forecasting with Covariate-Guided Experts under Privacy Constraints,"['1stRen He', '2ndYinliang Xu', '3ndJinfeng Wang', '4ndJeremy Watson', '5ndJian Song']",,,"['Price forecasting', 'Time Series', 'Privacy', 'Mixture of Experts', 'market analysis']","This paper proposes a novel MoE-Encoder module that augments pre-trained forecasting models by injecting a sparse mixture-of-experts layer between tokenization and encoding, enabling multivariate forecasting to be transformed into an expert-guided univariate task and supporting localized training and lightweight parameter sharing in federated settings.",157.79,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11979v1_Process In-Context Learning Enhancing Mathematical.pdf,Process In-Context Learning: Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion,"['Ang Gao', 'Changshuo Zhang', 'Xiao Zhang', 'Deyang Li', 'Minjun Zhao', 'Fangchao Liu', 'Xinyu Zhang']",,2309.14247,"['In-Context Learning', 'Mathematical Reasoning', 'Dynamic Demonstration Insertion', 'AI', 'Machine Learning']","Process In-Context Learning (PICL) is a dynamic demonstration integration framework designed to enhance mathematical reasoning by responding to real-time inference needs. It identifies potential confusion points and retrieves relevant demonstrations from a pool to guide subsequent steps, mitigating mid-inference confusion and highlighting the value of adaptive demonstration insertion in complex mathematical reasoning.",159.6,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11995v1_Learning Audio-Visual Embeddings with Inferred Lat.pdf,Learning Audio–Visual Embeddings with Inferred Latent Interaction Graphs,"['Donghuo Zeng', 'Hao Niu', 'Yanan Wang', 'Masato Taya']",,2601.11995,"['Audio–visual', 'latent interaction graph', 'cross-modal retrieval', 'soft labels']","This paper proposes a framework that leverages soft-label predictions and inferred latent interactions to address issues in learning robust audio–visual embeddings, improving mean average precision (MAP) on benchmarks.",158.47,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.11998v1_Hybrid IDS Using Signature-Based and Anomaly-Based.pdf,Hybrid IDS Using Signature-Based and Anomaly-Based Detection,"['1st Messaouda Boutassetta', '2nd Amina Makhlouf', '3rd Newfel Messaoudi', '4th Abdelmadjid Benmachiche', '5th Ines Boutabia']",,,"['Intrusion Detection System (IDS)', 'Hybrid IDS', 'Signature-Based Detection', 'Anomaly-Based Detection', 'Machine Learning (ML)', 'Cybersecurity', 'False Positives', 'Detection Accuracy', 'Real-Time Detection', 'Network Security']","This paper presents a comprehensive survey and conceptual overview of Hybrid IDS, which integrate signature-based and anomaly-based detection techniques to enhance attack detection capabilities, examining recent research trends and discussing potential future directions for more cost-effective solutions.",158.0,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12002v1_Kernel-Based Learning of Safety Barriers.pdf,Kernel-Based Learning of Safety Barriers,"['Oliver Schön', 'Zhengang Zhong', 'Sadegh Soudjani']",,2601.12002,"['Safety Verification', 'Black-Box Systems', 'Conditional Mean Embeddings', 'Reproducing Kernel Hilbert Space', 'Spectral Barrier', 'Temporal Logic']","This paper presents a data-driven approach for safety verification and synthesis of black-box systems with discrete-time stochastic dynamics, employing control barrier certificates and conditional mean embeddings to learn safety guarantees from system trajectories and robustify them against out-of-distribution behavior.",150.62,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12003v1_Robust Verification of Concurrent Stochastic Games.pdf,Robust Verification of Concurrent Stochastic Games,"['Angel Y. He', 'David Parker']",null,2601.12003,"['Robustquantitativeverification', 'Probabilisticmodelchecking', 'Concurrent stochastic games', 'Epistemic uncertainty']","This paper introduces robust concurrent stochastic games (CSGs) and their subclass interval CSGs (ICSGs) to handle epistemic uncertainty about transition probabilities in CSGs. It proposes a novel framework for robust verification under worst-case assumptions about transition uncertainty, developing theoretical foundations and efficient algorithms for finite- and infinite-horizon objectives in zero-sum and nonzero-sum settings, including Nash equilibria.",159.29,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12014v1_Are LLMs Ready for TOON Benchmarking Structural Co.pdf,Are LLMs Ready for TOON? Benchmarking Structural Correctness–Sustainability Trade-offs in Novel Structured Output Formats,"['Elio Masciari', 'Vincenzo Moscato', 'Enea Vincenzo Napolitano', 'Gian Marco Orlando', 'Marco Perillo', 'Diego Russo']",https://doi.org/XXXXXXX.XXXXXXX,,"['Green AI', 'TOON', 'Large Language Models', 'Natural Language Processing', 'Sustainability']","This paper introduces a sustainability-aware evaluation framework for structured generation that measures token usage, generation time, and estimated carbon emissions. Using this framework, the authors benchmark the novel TOON format against established representations (JSON, XML, YAML) across multiple LLMs, revealing a trade-off between compactness and structural correctness, and highlighting the need for sustainability-inclusive benchmarking.",155.54,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12019v1_Acting Flatterers via LLMs Sycophancy Combating Cl.pdf,Acting Flatterers via LLMs Sycophancy: Combating Clickbait with LLMs Opposing-Stance Reasoning,"['Chaowei Zhang', 'Xiansheng Luo', 'Zewei Zhang', 'Yi Zhu', 'Jipeng Qiang', 'Longwei Wang']",10.1145/XXXXXX.XXXXXX,,"['Clickbait Detection', 'Large Language Models', 'Opposing Stance Reasoning', 'Contrastive Learning']","This work proposes a novel approach to combat clickbait using Large Language Models (LLMs) by harnessing their tendency to produce sycophantic reasoning, which matches users' beliefs. The authors introduce a Self-renewal Opposing-stance Reasoning Generation (SORG) framework and develop an Opposing Reasoning-based Clickbait Detection (ORCD) model to enhance clickbait detection robustness.",158.67,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12024v1_A Multi-Agent System for Generating Actionable Bus.pdf,A Multi-Agent System for Generating Actionable Business Advice,"['Kartikey Singh Bhandari', 'Tanish Jain', 'Archit Agrawal', 'Dhruv Kumar', 'Praveen Kumar', 'Pratik Narang']",,,"['Customer Reviews', 'Multi-Agent System', 'Actionable Business Advice', 'Large Language Models', 'Review Mining', 'Operational Insight']","This paper presents a multi-agent, large language model (LLM)-based framework for generating actionable business advice from customer reviews. The framework integrates four components: clustering to select representative reviews, advice generation, iterative evaluation, and feasibility-based ranking. Experiments show that the framework consistently outperforms single model baselines on actionability, specificity, and non-redundancy, with medium-sized models approaching the performance of large model frameworks.",139.75,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12030v1_ARC Active and Reflection-driven Context Managemen.pdf,ARC: Active and Reflection-driven Context Management for Long-Horizon Information Seeking Agents,"['Yilun Yao', 'Shan Huang', 'Elsie Dai', 'Zhewen Tan', 'Zhenyu Duan', 'Shousheng Jia', 'Yanbing Jiang', 'Tong Yang']",,2309.15972,"['context management', 'long-horizon information seeking', 'active reflection', 'deep search', 'large language models', 'information seeking agents']","This paper proposes ARC, a framework that actively manages context as a dynamic internal reasoning state during execution, allowing agents to revise their working context when misalignment or degradation is detected. Experiments show that ARC consistently outperforms passive context compression methods on challenging long-horizon information-seeking benchmarks.",155.77,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12038v1_Abstract Argumentation with Subargument Relations.pdf,Abstract Argumentation with Subargument Relations,['Beishui Liao'],,1905.00177,"['Abstract Argumentation', 'Subargument Relations', 'Attack Relations', 'Structured Argumentation', ""Dung's Framework""]","This paper studies abstract argumentation frameworks enriched with an explicit subargument relation, treating it alongside attack as a basic relation. It analyzes how subargument relations interact with attacks and examines their impact on fundamental semantic properties, providing a principled abstraction of structural information and clarifying the role of subarguments in abstract acceptability reasoning.",154.14,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12040v1_Partial Reasoning in Language Models Search and Re.pdf,Partial Reasoning in Language Models: Search and Refinement Guided by Uncertainty,"['Murilo da Luz', 'Bruno Brandão', 'Luana Martins', 'Gustavo Oliveira', 'Bryan de Oliveira', 'Luckeciano Melo', 'Telma Soares']",10.13039/501100001422,2309.14165,"['Uncertainty', 'Entropy', 'Latent-space search', 'Soft Reasoning', 'LLM reasoning']","The paper introduces PREGU (Partial Reasoning Guided by Uncertainty), a method that monitors the entropy of the output distribution during autoregressive generation and halts the process when entropy exceeds a defined threshold, signaling uncertainty. From that point, a localized search is performed in the latent space to refine the partial reasoning and select the most coherent answer, using the Soft Reasoning method. Experiments with LLaMA-3-8B, Mistral-7B, and Qwen2-7B across four reasoning benchmarks showed performance greater than or similar to Soft Reasoning, indicating that entropy can serve as an effective signal to trigger selective refinement during reasoning.",158.87,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12042v1_Less Is More -- Until It Breaks Security Pitfalls .pdf,Less Is More — Until It Breaks: Security Pitfalls of Vision Token Compression in Large Vision-Language Models,"['Xiaomei Zhang', 'Zhaoxi Zhang', 'Leo Yu Zhang', 'Yanjun Zhang', 'Guanhong Tao', 'Shirui Pan']",https://doi.org/XXXXXXX.XXXXXXX,,"['Vision Token Compression', 'Large Vision-Language Models', 'Security', 'Robustness', 'Compression-Aware Attack', 'Transfer CAA']","This paper reveals that visual token compression, widely adopted to improve inference efficiency of Large Vision-Language Models, substantially degrades their robustness, making them highly vulnerable to small and imperceptible perturbations that can lead to model failure under compressed inference, and proposes a Compression-Aware Attack (CAA) to systematically study and exploit this vulnerability.",158.07,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12049v1_textitFocaLogic Logic-Based Interpretation of Visu.pdf,FocaLogic: Logic-Based Interpretation of Visual Model Decisions,"['Chenchen Zhao*', 'Muxi Chen*', 'Qiang Xu†']",,1911.05820,"['interpretability', 'visual models', 'logic-based', 'model-agnostic', 'focuses', 'quantitative metrics']","FocaLogic is a novel model-agnostic framework designed to interpret and quantify visual model decision-making through logic-based representations, identifying minimal interpretable subsets of visual regions (visual focuses) that decisively influence model predictions and proposing a suite of quantitative metrics to objectively evaluate model behavior.",159.09,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12053v1_A New Strategy for Artificial Intelligence Trainin.pdf,A New Strategy for Artificial Intelligence: Training Foundation Models Directly on Human Brain Data,['Ma¨el Donoso'],,2601.12053,"['foundation models', 'brain', 'neuroimaging', 'brain-generated data', 'brain-trained foundation models', 'reinforcement learning', 'chain of thought']","This paper explores a new strategy for artificial intelligence by training foundation models directly on human brain data, hypothesizing that neuroimaging data could provide insights into human cognition not accessible through observable actions, and proposing methods like reinforcement learning from human brain (RLHB) and chain of thought from human brain (CoTHB) to prioritize the use of limited neuroimaging data.",154.91,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12055v1_Automating Parameter Selection in Deep Image Prior.pdf,Automating Parameter Selection in Deep Image Prior for Fluorescence Microscopy Image Denoising via Similarity-Based Parameter Transfer,"['Lina Meyer', 'Felix Wissel', 'Tobias Knopp', 'Susanne Pfefferle', 'Ralf Fliegert', 'Maximilian Sandmann', 'Liana Uebler', 'Franziska M""ockl', 'Bj""orn-Philipp Diercks', 'David Lohr', 'Ren""e Werner']",10.13039/100011199246,2109.08960,"['deep image prior', 'fluorescence microscopy', 'image denoising', 'parameter transfer', 'unsupervised learning']","This study proposes AUTO-DIP, a pipeline for automatic parameter transfer in deep image prior for fluorescence microscopy image denoising, demonstrating superior performance compared to baseline DIP and state-of-the-art variational denoising approaches for various open-source test datasets, particularly for very noisy inputs.",158.76,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12061v1_Codebook-Injected Dialogue Segmentation for Multi-.pdf,Codebook-Injected Dialogue Segmentation for Multi-Utterance Constructs,"['Jinsook Lee', 'Kirk Vanacore', 'Zhuqian Zhou', 'Bakhtawar Ahtisham', 'Jeanine Grütter', 'René F. Kizilcec']",,2309.12748,"['Dialogue Act Annotation', 'Segmentation', 'LLM-Assisted Annotation', 'Human-AI Agreement', 'Codebook Injection']","This paper proposes codebook-injected segmentation for dialogue act annotation, which conditions boundary decisions on downstream annotation criteria. It evaluates LLM-based segmenters against standard and retrieval-augmented baselines, introducing evaluation metrics for span consistency, distinctiveness, and human-AI distributional agreement.",157.95,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12068v1_Bridging the Gap in Bangla Healthcare Machine Lear.pdf,Bridging the Gap in Bangla Healthcare: Machine Learning Based Disease Prediction Using a Symptoms-Disease Dataset,"['Rowzatul Zannat', 'Abdullah Al Shafi', 'Abdul Muntakim']",,,"['Disease Prediction', 'Annotated Dataset', 'Machine Learning Techniques', 'Soft Voting Ensemble', 'Hard Voting Ensemble']","This study addresses the gap in disease prediction resources for non-English-speaking populations, specifically for Bangla speakers, by developing a comprehensive Bangla symptoms-disease dataset containing 758 unique symptom-disease relationships and evaluating multiple machine learning models to predict diseases based on Bangla symptom inputs, achieving 98% accuracy with soft and hard voting ensemble approaches.",155.44,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12082v1_Conditional Random Fields for Interactive Refineme.pdf,CONDITIONAL RANDOM FIELDS FOR INTERACTIVE REFINEMENT OF HISTOPA THOLOGICAL PREDICTIONS,"['Tiffanie Godelaine†', 'Maxime Zanella†', 'Karim El Khoury1', 'Sa¨ıd Mahmoudi2', 'Benoˆıt Macq1', 'Christophe De Vleeschouwer1']",,,"['Histology Classification', 'Conditional Random Fields', 'Human-In-The-Loop', 'Foundation Models']","The paper proposes a method to refine predictions from Vision-Language Models (VLMs) in histopathological image analysis, using Conditional Random Fields (CRFs). This method aims to improve accuracy without requiring additional model training and can incorporate real-time human guidance. Experiments on five patch-level classification datasets demonstrate significant accuracy gains compared to zero-shot predictions.",155.99,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12095v1_Neural Isomorphic Fields A Transformer-based Algeb.pdf,Neural Isomorphic Fields: A Transformer-Based Algebraic Numerical Embedding,"['Hamidreza Sadeghi', 'Saeedeh Momtazi', 'Reza Safabakhsh']",,2601.02177,"['Neural Isomorphic Fields', 'Transformer', 'Algebraic Numerical Embedding', 'Neural Arithmetic Logic Units', 'Neural Arithmetic Units', 'Fixed-Length Embedding', 'Rational Numbers', 'Algebraic Properties', 'Numerical Stability']","This paper introduces a novel neural network architecture called Neural Isomorphic Fields (NIF), which uses embedding vectors to represent and process numbers, preserving algebraic operations within the rational numbers field. The authors demonstrate that addition performs exceptionally well, while multiplication faces challenges, highlighting the model's strengths in preserving algebraic properties under addition and identifying avenues for improvement in handling multiplication.",155.99,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12099v1_Large language models struggle with ethnographic t.pdf,LARGE LANGUAGE MODELS STRUGGLE WITH ETHNOGRAPHIC TEXT ANNOTATION,"['Leonardo S. Goodall†', 'Dor Shilton†', 'Daniel Austin Mullins', 'Harvey Whitehouse']",,,"['large language models', 'ethnographic text annotation', 'cross-cultural research', 'anthropology']","This study evaluates 7 state-of-the-art large language models on their ability to annotate 121 ritual features across 567 ethnographic excerpts, finding that performance is limited and falls below levels required for reliable automated annotation, particularly for longer texts, features requiring ordinal distinctions, and ambiguous constructs.",156.36,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12104v1_Powerful Training-Free Membership Inference Agains.pdf,Powerful Training-Free Membership Inference Against Autoregressive Language Models,"['David Ilić', 'David Stanojević', 'Kostadin Cvejoski']",,2303.16894,"['Membership inference', 'Fine-tuning', 'Autoregressive models', 'Privacy risks', 'Language models']","Presenting EZ-MIA, a membership inference attack that exploits the observation that memorization is most pronounced at error positions, specifically tokens where the model predicts incorrectly. The Error Zone (EZ) score measures the directional imbalance of probability shifts at error positions relative to a pretrained reference model. This attack requires only two forward passes per query and no model training, achieving significantly higher detection rates than previous methods, particularly at low false-positive thresholds.",154.07,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12124v1_SynQP A Framework and Metrics for Evaluating the Q.pdf,SYNQP: A FRAMEWORK AND METRICS FOR EVALUATING THE QUALITY AND PRIVACY RISK OF SYNTHETIC DATA,"['Bing Hu', 'Yixin Li', 'Asma Bahamyirou', 'Helen Chen']",,1912.07634,"['Real-World Data', 'Synthetic Data', 'Privacy Metrics', 'Evaluation Framework', 'Membership Inference Attack', 'Identity Disclosure Risk']","The authors introduce SYNQP, an open framework for benchmarking privacy in synthetic data generation, using simulated sensitive data. They highlight the need for privacy metrics that account for the probabilistic nature of machine learning models and demonstrate its use with CTGAN, proposing a new identity disclosure risk metric that offers a more accurate estimation of privacy risks compared to existing approaches.",154.87,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12126v1_UniMo Unified Motion Generation and Understanding .pdf,UniMo: Unified Motion Generation and Understanding with Chain of Thought,"['Guocun Wang', 'Kenkun Liu', 'Jing Lin', 'Guorui Song', 'Jian Li', 'Xiaoguang Han']",,,"['motion generation', 'motion understanding', 'large language models', 'supervised fine-tuning', 'reinforcement learning', 'chain of thought']","This paper proposes UniMo, a novel framework that integrates motion-language information and interpretable chain of thought reasoning into large language models via supervised fine-tuning and reinforcement learning, significantly outperforming existing unified and task-specific models in both motion generation and understanding tasks.",155.34,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12132v1_Bengali Text Classification An Evaluation of Large.pdf,Bengali Text Classification: An Evaluation of Large Language Model Approaches,"['Md Mahmudul Hoque∗', 'Md Mehedi Hassain', 'Md Hojaifa Tanvir', 'Rahul Nandy']",,2601.12132,"['Bengali Text Classification', 'Transformer-based Text Classifier', 'Multilingual NLP', 'Qwen', 'LLaMA']","This study evaluates the effectiveness of large language models in classifying Bengali newspaper articles, focusing on three instruction-tuned models: LLaMA 3.1 8B Instruct, LLaMA 3.2 3B Instruct, and Qwen 2.5 7B Instruct. Qwen 2.5 achieved the highest classification accuracy of 72%, particularly in the 'Sports' category, while LLaMA 3.1 and LLaMA 3.2 attained accuracies of 53% and 56%, respectively. The findings highlight the potential of LLMs in Bengali text classification despite the scarcity of resources for Bengali NLP.",144.98,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12134v1_Human-Human-AI Triadic Programming Uncovering the .pdf,Human-Human-AI Triadic Programming: Uncovering the Role of AI Agent and the Value of Human Partner in Collaborative Learning,"['Taufiq Daryanto', 'Xiaohan Ding', 'Kaike Ping', 'Lance T. Wilhelm', 'Yan Chen', 'Chris Brown', 'Eugenia H. Rho']",https://doi.org/YYYYXXX.XXXXXXX,2601.12134v1,"['Human-Human-AI Triadic Programming', 'Collaborative Learning', 'Programming Education', 'AI in Education', 'Human-AI Interaction']","This study explores human-human-AI triadic programming, where two humans work with an AI agent, aiming to preserve the social and pedagogical benefits of collaboration while examining design considerations in this triadic interaction.",141.34,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12138v1_DriveSafe A Hierarchical Risk Taxonomy for Safety-.pdf,DriveSafe: A Hierarchical Risk Taxonomy for Safety-Critical LLM-Based Driving Assistants,"['Abhishek Kumar', 'Riya Tapwal', 'Carsten Maple']",,,"['Large Language Models', 'Driving Assistants', 'Safety-Critical', 'Hierarchical Risk Taxonomy', 'LLM Safety', 'Safety Alignment', 'Automotive Systems', 'Real-World Driving Scenarios']","This paper introduces DriveSafe, a hierarchical four-level risk taxonomy designed to systematically characterize safety-critical failure modes of LLM-based driving assistants, addressing the domain-specific risks inherent to real-world driving scenarios.",154.88,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12141v1_TIDE A Trace-Informed Depth-First Exploration for .pdf,TIDE: A Trace-Informed Depth-First Exploration for Planning with Temporally Extended Goals,"['Yuliia Suprun', 'Khen Elimelech', 'Lydia E. Kavraki', 'Moshe Y. Vardi']",null,2601.12141v1,"['Task Planning', 'Temporal Logic', 'Depth-First Exploration', 'Finite Traces', 'Heuristics', 'Robotics', 'Artificial Intelligence']","TIDE is a novel approach for task planning with temporally extended goals, which decomposes the problem into smaller, manageable reach-avoid subproblems and uses cost-driven heuristics to guide exploration, ensuring completeness and efficiency.",161.86,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12147v1_Segment and Matte Anything in a Unified Model.pdf,Segment and Matte Anything in a Unified Model,"['Zezhong Fan*', 'Xiaohan Li*', 'Topojoy Biswas', 'Kaushiki Nag', 'Kannan Achan']",,2312.08399,"['Segment Anything', 'Interactive Image Matting', 'Unified Model', 'Zero-Shot Generalization', 'Refinement Modules', 'Alpha Matting']","This paper introduces Segment And Matte Anything (SAMA), a lightweight extension of Segment Anything (SAM) that delivers high-quality interactive image segmentation and matting with minimal extra parameters.",161.29,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12150v1_Enhanced Diagnostic Performance via Large-Resoluti.pdf,Enhanced Diagnostic Performance via Large-Resolution Inference Optimization for Pathology Foundation Models,"['Mengxuan Hu', 'Zihan Guan', 'John Kang', 'Sheng Li', 'Zhongliang Zhou']",,2601.12150,"['Computational pathology', 'Foundation models', 'Inference Optimization']","This paper proposes an efficient inference strategy that sparsifies attention using spatially aware neighboring blocks and filters out non-informative tokens through global attention scores, enabling inference at higher resolutions under the same GPU budget and achieving up to a 7.67% improvement in ROI classification.",137.35,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12186v1_Aletheia What Makes RLVR For Code Verifiers Tick.pdf,Aletheia: What Makes RLVR For Code Verifiers Tick?,"['Vatsal Venkatkrishna', 'Indraneil Paul', 'Iryna Gurevych']",,2310.16519,"['Reinforcement Learning', 'Code Verification', 'Large Language Models', 'Execution Feedback', 'RLVR', 'Code Generation']","This paper presents Aletheia, a controlled testbed for evaluating the robustness of code verifiers trained via Reinforcement Learning from Verifiable Rewards (RLVR). It examines the key components of RLVR-based verifiers and identifies opportunities for simplification, particularly focusing on the importance of on-policy learning and thinking-based training at different scales.",140.87,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12205v1_Do Neural Codecs Generalize A Controlled Study Acr.pdf,Do Neural Codecs Generalize? A Controlled Study Across Unseen Languages and Non-Speech Tasks,"['Shih-Heng Wang', 'Jiatong Shi', 'Jinchuan Tian', 'Haibin Wu', 'Shinji Watanabe']",,2410.13432,"['Neural Audio Codecs', 'Generalization', 'Unseen Languages', 'Non-Speech Tasks', 'Speech-Only Pre-Training', 'Non-Speech Data', 'Signal Reconstruction', 'Downstream Applications']","This paper investigates the generalization capabilities of Neural Audio Codecs (NACs) by training them from scratch with controlled configurations and curated pre-trained data, evaluating their performance on signal reconstruction quality and downstream applications using 11 metrics. The findings show that NACs can generalize to unseen languages during pre-training, speech-only pre-trained NACs degrade on non-speech tasks, and including non-speech data during pre-training improves performance on non-speech tasks while maintaining comparable performance on speech tasks.",158.76,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12212v1_Speculative Sampling with Reinforcement Learning.pdf,Speculative Sampling with Reinforcement Learning,"['Chenan Wang', 'Daniel H. Shi', 'Haipeng Chen']",,2312.08568,"['Reinforcement Learning', 'Speculative Sampling', 'Large Language Models', 'Inference Time Latency', 'Speculative Aggression', 'Draft Tree', 'Efficient State Representations']","This paper introduces Re-SpS, a reinforcement learning-based framework for optimizing draft tree hyperparameters in speculative sampling for large language models, achieving up to 5.45× speedup over the state-of-the-art method EAGLE-3.",159.91,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12215v1_Wavelet-Driven Masked Multiscale Reconstruction fo.pdf,Wavelet-Driven Masked Multiscale Reconstruction for PPG Foundation Models,"['Megha Thukral', 'Cyrus Tanade', 'Simon A. Lee', 'Juhyeon Lee', 'Hao Zhou', 'Keum San Chun', 'Migyeong Gwak', 'Viswam Nathan', 'Md Mahbubur Rahman', 'Li Zhu', 'Mehrab Bin Morshed', 'Subramaniam Venkatraman', 'Sharanya Arcot Desai']",,2601.12215v1,"['Wearable SSL Method', 'Wavelet based Modelling', 'PPG foundation models']","This paper introduces Masked Multiscale Reconstruction (MMR) for PPG representation learning, a self-supervised pretraining framework that explicitly learns from hierarchical time–frequency scales of PPG data, improving over or matching state-of-the-art open-source PPG foundation models on 17 of 19 diverse health-related tasks.",160.75,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12224v1_Where It Moves It Matters Referring Surgical Instr.pdf,"Where It Moves, It Matters: Referring Surgical Instrument Segmentation via Motion","['Meng Wei', 'Kun Yuan', 'Shi Li', 'Yue Zhou', 'Long Bai', 'Nassir Navab', 'Hongliang Ren', 'Hong Joo Lee', 'Tom Vercauteren', 'Nicolas Padoy']",,2605.09926,"['surgical video segmentation', 'motion-guided framework', 'referring segmentation', 'surgical instrument localization', 'spatiotemporal masks', 'robotic navigation']","This work introduces SurgRef, a novel motion-guided framework for surgical instrument segmentation in videos, which captures instrument motion and interaction across time, enabling robust and generalizable segmentation even under occlusion, ambiguity, or unfamiliar terminology.",158.85,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12234v1_Proc3D Procedural 3D Generation and Parametric Edi.pdf,Proc3D: Procedural 3D Generation and Parametric Editing of 3D Shapes with Large Language Models,"['Fadlullah Raji', 'Stefano Petrangeli', 'Matheus Gadelha', 'Yu Shen', 'Uttaran Bhattacharya', 'Gang Wu']",,2601.12234v1,"['3D modeling', 'Large Language Models', 'Procedural Generation', 'Parametric Editing', 'Graph-based Representation']","Proc3D is a system that generates editable 3D models using procedural compact graph representation, enabling real-time modifications through natural language prompts and intuitive manual controls, outperforming existing methods in editing efficiency and ULIP scores.",159.59,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12242v1_Optimal Power Allocation and Sub-Optimal Channel A.pdf,OPTIMALPOWERALLOCATION ANDSUB-OPTIMALCHANNELASSIGNMENT FORDOWNLINKNOMA SYSTEMUSINGDEEPREINFORCEMENTLEARNING,"['WooSeok Kim', 'Jeonghoon Lee', 'Sangho Kim', 'Taesun An', 'WonMin Lee', 'Dowon Kim', 'Kyungseop Shin']",,2601.12242v1,"['Non-orthogonal multiple access (NOMA)', 'deep reinforcement learning (DRL)', 'wireless network', 'resource allocation']","This paper proposes a deep reinforcement learning framework that incorporates replay memory with an on-policy algorithm for optimal power allocation and sub-optimal channel assignment in a downlink NOMA system, addressing the channel assignment problem and evaluating the effects of varying learning parameters.",159.13,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12243v1_Less is More Label-Guided Summarization of Procedu.pdf,Less is More: Label-Guided Summarization of Procedural and Instructional Videos,"['Shreya Rajpal', 'Michal Golovanesky', 'Carsten Eickhoff']",,2601.12243,"['video summarization', 'procedural videos', 'instructional videos', 'semantic summarization', 'multimodal analysis']","This paper proposes a three-stage framework, PRISM, for producing semantically grounded video summaries of procedural and instructional videos, combining adaptive visual sampling, label-driven keyframe anchoring, and contextual validation using a large language model. The method ensures that selected frames reflect meaningful and procedural transitions while filtering out generic or hallucinated content, resulting in contextually coherent summaries across both domain-specific and instructional videos.",156.49,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12247v1_Plan Verify and Fill A Structured Parallel Decodin.pdf,"Plan, Verify and Fill: A Structured Parallel Decoding Approach for Diffusion Language Models","['Miao Li', 'Hanyang Jiang', 'Sikai Cheng', 'Hengyu Fu', 'Yuhang Cai', 'Baihe Huang', 'Tinghan Ye', 'Xuanzhou Chen', 'Pascal Van Hentenryck']",,2601.0746,"['Diffusion Language Models', 'Parallel Decoding', 'Quantitative Validation', 'Pragmatic Structural Stopping', 'Masked Diffusion', 'Text Generation']","This paper proposes Plan-Verify-Fill (PVF), a training-free paradigm for diffusion language models that uses quantitative validation to construct a hierarchical skeleton and employs a verification protocol for pragmatic structural stopping. PVF reduces the Number of Function Evaluations (NFE) by up to 65% compared to confidence-based parallel decoding across benchmark datasets, demonstrating superior efficiency without compromising accuracy.",158.32,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12248v1_AQUA-Bench Beyond Finding Answers to Knowing When .pdf,AQUA-BENCH: BEYOND FINDING ANSWERS TO KNOWING WHEN THERE ARE NONE,"['Chun-Yi Kuan', 'Hung-yi Lee']",,2305.16888,"['Unanswerable questions', 'Audio question answering', 'Audio-aware large language models']","AQUA-Bench is a new benchmark designed to evaluate whether audio-aware large language models can detect and appropriately respond to unanswerable questions, covering scenarios such as absent answer detection, incompatible answer set detection, and incompatible audio question detection.",159.81,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12249v1_An Innovative Framework for Breast Cancer Detectio.pdf,"An Innovative Framework for Breast Cancer Detection Using Pyramid Adaptive Atrous Convolution, Transformer Integration, and Multi-Scale Feature Fusion","['Ehsan Sadeghi Pour', 'Mahdi Esmaeili', 'Morteza Romoozi']",,,"['Breast Cancer Detection', 'Pyramid Adaptive Atrous Convolution (PAAC)', 'Transformer', 'Multi-Scale Feature Fusion', 'Self-Attention Mechanism', 'Medical Image Processing']","This thesis presents an innovative framework for detecting malignant masses in mammographic images by integrating Pyramid Adaptive Atrous Convolution (PAAC) and Transformer architectures, utilizing Multi-Scale Feature Fusion to enhance feature extraction from benign and malignant tissues, and combining Dice Loss and Focal Loss functions to improve model learning. The model achieves high accuracy in detecting cancerous masses, outperforming foundational models, and demonstrates significant improvement over traditional methods.",159.91,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12256v1_Improving Large Molecular Language Model via Relat.pdf,Improving Large Molecular Language Model via Relation-aware Multimodal Collaboration,"['Jinyoung Park', 'Minseong Bae', 'Jeehye Na', 'Hyunwoo J. Kim']",,2605.09906,"['Large Molecular Language Models', 'Multimodal Collaboration', 'Relation-aware Attention', 'Molecular Modeling', 'Hallucination Assessment']","This paper proposes CoLLaMo, a large language model-based molecular assistant, which addresses the limitations of existing large molecular language models by incorporating relation-aware modality-collaborative attention mechanisms to improve molecular modality generalization and achieve better performance on various molecular tasks.",154.16,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12257v1_Soft Shadow Diffusion SSD Physics-inspired Learnin.pdf,Soft Shadow Diffusion (SSD): Physics-inspired Learning for 3D Computational Periscopy,"['Fadlullah Raji', 'John Murray Bruce']",,2601.12257,"['Computational imaging', 'Machine learning', '3D generative models', 'Diffusion models', 'Separable non-linear least squares']","This paper proposes a novel approach to 3D reconstruction of hidden scenes from ordinary NLOS photographs, using a reformulated light transport model and physics-inspired neural network, called Soft Shadow diffusion (SSD), which effectively handles the ill-conditioned inverse problem and generalizes well to unseen classes in both simulation and real-world NLOS scenes.",147.97,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12259v1_FutureX-Pro Extending Future Prediction to High-Va.pdf,FutureX-Pro: Extending Future Prediction to High-Value Vertical Domains,"['ByteDance', 'Hong Kong University of Science and Technology', 'Georgia Institute of Technology', 'Stanford University', 'Princeton University']",,2601.12259v1,"['FutureX', 'Future Prediction', 'High-Value Vertical Domains', 'Financial Markets', 'Retail Forecasting', 'Public Health', 'Natural Disasters', 'Large Language Models', 'Domain Grounding', 'Industrial Deployment']","This report introduces FutureX-Pro, which extends future prediction capabilities to high-value vertical domains such as Finance, Retail, Public Health, and Natural Disaster. It benchmarks agentic Large Language Models on foundational prediction tasks and assesses their domain grounding for industrial deployment, revealing performance gaps between generalist reasoning and high-value applications.",151.39,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12260v1_Docs2Synth A Synthetic Data Trained Retriever Fram.pdf,Docs2Synth: A Synthetic Data Trained Retriever Framework for Scanned Visually Rich Documents Understanding,"['Yihao Ding', 'Qiang Sun', 'Puzhen Wu', 'Sirui Li', 'Siwen Luo', 'Wei Liu']",,,"['Document Understanding', 'Synthetic Data', 'Retriever Framework', 'Scanned Documents', 'Vision-Language Pre-trained Models', 'MLLMs', 'OCR Inaccuracies', 'Domain-Specific Knowledge']","Docs2Synth is a synthetic-supervision framework that enables retrieval-guided inference for private and low-resource domains, automatically processing raw document collections, generating and verifying diverse QA pairs, and training a lightweight visual retriever to extract domain-relevant evidence.",138.77,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12263v1_Multimodal Generative Engine Optimization Rank Man.pdf,Multimodal Generative Engine Optimization: Rank Manipulation for Vision–Language Model Rankers,"['Yixuan Du', 'Chenxiao Yu', 'Haoyan Xu', 'Ziyi Wang', 'Yue Zhao', 'Xiyang Hu']",,,"['Vision-Language Models', 'Ranking Attacks', 'Adversarial Manipulation', 'Multimodal Perturbations', 'Product Search']","This paper reveals a vulnerability in Vision-Language Models (VLMs) used in modern retrieval and recommendation systems, where a malicious actor can unfairly promote a target product by jointly optimizing imperceptible image perturbations and fluent textual suffixes. The authors present MGEO, a novel adversarial framework that exploits the deep cross-modal coupling within VLMs, demonstrating significant improvements over text-only and image-only baselines on real-world datasets.",154.45,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12269v1_Simulated Annealing Enhances Theory-of-Mind Reason.pdf,Simulated Annealing Enhances Theory-of-Mind Reasoning in Autoregressive Language Models,"['Xucong Hu', 'Jian-Qiao Zhu']",,2310.16716,"['Language Models', 'Markov Chain Monte Carlo', 'Simulated Annealing', 'Power Sampling', 'Theory of Mind']","This paper shows that autoregressive language models, which are criticized for optimizing surface plausibility rather than maintaining correct latent-state representations, can be enhanced to perform better on Theory of Mind tasks through the use of simulated annealing and power sampling methods.",159.56,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12276v1_Predictive Prototyping Evaluating Design Concepts .pdf,PREDICTIVE PROTOTYPING: EVALUATING DESIGN CONCEPTS WITH GPT,"['Hilsann Yong', 'Singapore University of Technology & Design']",,,"['Prototyping', 'Design Theory', 'Iteration', 'Simulation', 'AI', 'LLM', 'GPT', 'RAG', 'Crowdsourcing']","This work explores whether a GPT can accurately predict information that would be gained during a prototyping effort, such as cost, performance, and perceived usability, and compares the predictions made by the GPT-RAG method with ground-truth physical prototyping results and other prototypes.",149.89,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12282v1_CytoCLIP Learning Cytoarchitectural Characteristic.pdf,CytoCLIP: Learning Cytoarchitectural Characteristics in Developing Human Brain Using Contrastive Language Image Pre-Training,"['Pralaypati Ta', 'Sriram Venkatesaperumal', 'Keerthi Ram', 'Mohanasankar Sivaprakasam']",,,"['Cytoarchitecture', 'Histological Image Processing', 'Contrastive learning', 'CLIP']","The paper proposes CytoCLIP, a suite of vision-language models derived from pre-trained Contrastive Language-Image Pre-Training (CLIP) frameworks to learn joint visual-text representations of brain cytoarchitecture. It evaluates the model's understanding of the cytoarchitecture and generalization ability using region classification and cross-modal retrieval tasks.",153.39,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12286v1_Conversational Context Classification A Representa.pdf,Conversational Context Classification: A Representation Engineering Approach,['Jonathan Pan'],,2312.04823,"['Large Language Models (LLMs)', 'One-Class SVM', 'Novelty Detection', 'In/Out-of-Context', 'Representation Engineering']","This paper explores the use of Representation Engineering and One-Class Support Vector Machine to identify subspaces within the internal states of LLMs that represent a specific context, aiming to accurately detect when LLMs stray from expected conversational norms.",156.74,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12288v1_TimeGMM Single-Pass Probabilistic Forecasting via .pdf,TIMEGMM: SINGLE-PASS PROBABILISTIC FORECASTING VIA ADAPTIVE GAUSSIAN MIXTURE MODELS WITH REVERSIBLE NORMALIZATION,"['Lei Liu', 'Tengyuan Liu', 'Hongwei Zhao', 'Jiahui Huang', 'Ruibo Guo', 'Bin Li']",,1912.07634,"['Probabilistic time series forecasting', 'Gaussian mixture model', 'Reversible instance normalization']","This paper presents TimeGMM, a novel probabilistic forecasting framework based on Gaussian Mixture Models (GMM) that captures complex future distributions in a single forward pass. It integrates a dedicated Temporal Encoder (TE-Module) with a Conditional Temporal-Probabilistic Decoder (CTPD-Module) to jointly capture temporal dependencies and mixture distribution parameters. Extensive experiments demonstrate that TimeGMM consistently outperforms state-of-the-art methods, achieving maximum improvements of 22.48% in CRPS and 21.23% in NMAE.",155.55,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12294v1_ToolPRMBench Evaluating and Advancing Process Rewa.pdf,ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents,"['Dawei Li', 'Yuguang Yao', 'Zhen Tan', 'Huan Liu', 'Ruocheng Guo']",,,"['reward-guided search', 'process reward models', 'tool-using agents', 'multi-step failures', 'large language models']","This paper introduces ToolPRMBench, a large-scale benchmark designed to evaluate process reward models (PRMs) for tool-using agents. It addresses the lack of systematic and reliable evaluation benchmarks for PRMs in tool-using settings and proposes a multi-LLM verification pipeline to reduce label noise and ensure data quality. The results reveal clear differences in PRM effectiveness and highlight the potential of specialized PRMs for tool-using.",156.32,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12304v1_A Two-Stage Globally-Diverse Adversarial Attack fo.pdf,A TWO-STAGE GLOBALLY-DIVERSE ADVERSARIAL ATTACK FOR VISION-LANGUAGE PRE-TRAINING MODELS,"['Wutao Chen', 'Huaqin Zou', 'Chen Wan', 'Lifeng Huang']",,1911.08530,"['Adversarial Attack', 'VLP Models', 'Multi-modal Retrieval', 'Transferability']","This paper proposes 2S-GDA, a two-stage globally-diverse attack framework for vision-language pre-training models. The method introduces textual perturbations through a globally-diverse strategy and generates image-level perturbations using multi-scale resizing and block-shuffle rotation. Extensive experiments demonstrate that 2S-GDA consistently improves attack success rates over state-of-the-art methods, with gains of up to 11.17% in black-box settings.",154.41,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12310v1_Survival is the Only Reward Sustainable Self-Train.pdf,Survival is the Only Reward: Sustainable Self-Training Through Environment-Mediated Selection,"['Jennifer Dodgson', 'Alfath Daryl Alhajir', 'Michael Joedhitya', 'Akira Rafhael Janson Pattirane', 'Surender Suresh Kumar', 'Joseph Lim', 'C.H. Peh', 'Adith Ramdas', 'Steven Zhang Zhexu']",,2601.12310v1,"['Self-training', 'Sustainable Learning', 'Environment-Mediated Selection', 'Negative-Space Learning', 'Robustness', 'Generalization', 'Open-Endedness']","This paper presents a proof-of-concept self-training system architecture that uses environmental viability to select behaviours, avoiding reward hacking and semantic drift, and demonstrates its effectiveness through empirical analysis of learning dynamics and failure modes.",158.68,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12316v1_GazeFormer-MoE Context-Aware Gaze Estimation via C.pdf,GAZEFORMER-MOE: CONTEXT-AWARE GAZE ESTIMATION VIA CLIP AND MOE,"['Xinyuan Zhao', 'Xianrui Chen', 'Ahmad Chaddad']",null,null,"['Gaze estimation', 'multi scale fusion', 'MoE transformer']","This paper presents a semantics-modulated, multi-scale Transformer model for 3D gaze estimation, which achieves new state-of-the-art angular errors on various datasets and demonstrates improvements over previous methods.",160.34,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12317v1_Explanova Automatically Discover Data Insights in .pdf,Explanova: Automatically Discover Data Insights in N×M Table via XAI Combined LLM Workflow,['Yiming Huang'],10.1145/nnnnnnn.nnnnnnn,,"['Data Science', 'Automatic Analysis', 'LLM', 'AutoML', 'XAI', 'Feature Analysis', 'Table Analysis']","This paper proposes Explanova, an automatic LLM workflow that enables discovering data insights through explainable AI (XAI) paradigm. It targets single-feature statistic analysis, feature-to-feature relation statistic analysis, and feature modeling by all other features in one data table, and presets a workflow to explore all possible analytical items.",156.6,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12318v1_Beyond Human Annotation Recent Advances in Data Ge.pdf,Beyond Human Annotation: Recent Advances in Data Generation Methods for Document Intelligence,"['DEHAO YING', 'Wuhan University, China', 'FENGCHANG YU', 'Wuhan University, China', 'HAIHUA CHEN', 'University of North Texas, United States', 'CHANGJIANG JIANG', 'Wuhan University, China', 'YURONG LI', 'Wuhan University, China', 'WEI LU', 'Wuhan University, China']",10.1145/XXXXXXX.XXXXXXX,,"['Document Intelligence', 'Data Generation', 'Data Quality Evaluation']","This survey establishes the first comprehensive technical map for data generation in Document Intelligence, redefining it as supervisory signal production and introducing a novel taxonomy based on the availability of data and labels. It organizes methodologies into four resource-centric paradigms and establishes a multi-level evaluation framework to integrate intrinsic quality and extrinsic utility, revealing critical challenges such as fidelity gaps and co-evolutionary ecosystems.",158.77,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12323v1_MARO Learning Stronger Reasoning from Social Inter.pdf,MARO: Learning Stronger Reasoning from Social Interaction,"['Yin Cai', 'Zhouhong Gu', 'JunTao Zhang', 'Ping Chen']",,2310.16568,"['Large Language Models', 'Multi-Agent Reward Optimization', 'Social Interaction', 'Reasoning', 'Negotiation', 'Competition']","This paper proposes MARO, a method that enables large language models to acquire stronger reasoning abilities by learning and practicing in multi-agent social environments, addressing the sparse learning signal and uneven role distribution problems.",158.81,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12327v1_The Expert Validation Framework EVF Enabling Domai.pdf,The Expert Validation Framework (EVF): Enabling Domain Expert Control in AI Engineering,"['Lucas Gren', 'Felix Dobslaw']",10.1145/xxx.xxxx,,"['GenAI', 'expert validation', 'quality assurance', 'AI engineering', 'domain expert control']","The paper presents an Expert Validation Framework (EVF) that places domain experts at the center of building software with GenAI components, enabling them to maintain authoritative control over system behavior through structured processes. The framework addresses the gap between AI capabilities and organizational trust by establishing a rigorous, expert-driven methodology for ensuring quality across diverse GenAI applications.",160.42,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12330v1_IceWatch Forecasting Glacial Lake Outburst Floods .pdf,IceWatch: Forecasting Glacial Lake Outburst Floods (GLOFs) using Multimodal Deep Learning,"['Zuha Fatima', 'Muhammad Anser Sohaib', 'Muhammad Talha', 'Ayesha Kanwal', 'Sidra Sultana', 'Nazia Perwaiz']",,,"['CNN', 'deep learning', 'glacier monitoring', 'GLOF detection', 'LSTM', 'remote sensing', 'Sentinel-2', 'temperature forecasting', 'transformer', 'velocity prediction']","IceWatch presents a novel deep learning framework for GLOF prediction that incorporates both spatial and temporal perspectives, using Sentinel-2 multispectral satellite imagery and NASA ITS_LIVE time series for glacier velocity and MODIS LST records for near-surface temperature forecasting. This system ensures strong predictive performance, rapid data processing for real-time use, and robustness to noise and missing information, paving the way for automatic, scalable GLOF warning systems.",159.7,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12331v1_Efficient Privacy-Preserving Retrieval Augmented G.pdf,Efficient Privacy-Preserving Retrieval Augmented Generation with Distance-Preserving Encryption,"['Huanyi Ye', 'Jiale Guo', 'Ziyao Liu', 'Kwok-Yan Lam']",,2309.15026,"['RAG', 'Privacy-Preserving Retrieval', 'Distance-Preserving Encryption', 'LLMs']","This paper proposes an efficient privacy-preserving RAG framework (ppRAG) tailored for untrusted cloud environments that defends against vector-to-text attack, vector analysis, and query analysis. It introduces Conditional Approximate Distance-Comparison-Preserving Symmetric Encryption (CAPRISE) to encrypt embeddings while preserving only the relative distance ordering between encrypted query and database embeddings, enhancing both privacy and efficiency. Differential privacy is also introduced to further mitigate query analysis risks.",160.97,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12338v1_Actionable Advice from Reviews via Mixture of LoRA.pdf,CHEAT_DETECTED,"['Kartikey Singh Bhandari', 'Manav Ganesh', 'Yashwant Viswanathan', 'Archit Agrawal', 'Dhruv Kumar', 'Pratik Narang']",,,"['review-to-action generation', 'issue extraction', 'business recommendations', 'large language models', 'LoRA adapters', 'operational insights', 'customer feedback', 'actionability', 'specificity', 'feasibility']","This paper studies review-to-action generation, producing concrete, implementable recommendations grounded in review text, using a modular two-LLM framework with a specialized issue extraction model and an advice generation model. The approach adapts the advice model using a mixture of LoRA experts for specialization without full fine-tuning, and evaluates recommendations using an eight-dimensional operational rubric.",160.09,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12341v1_Time-Continuous Modeling for Temporal Affective Pa.pdf,Time-Continuous Modeling for Temporal Affective Pattern Recognition in LLM’s,"['Rezky M. Kam', 'Coddy N. Siswanto']",,2309.14078,"['Temporal Affective Pattern Recognition', 'Language Models', 'Time-Aware Architectures', 'Physics-Informed Neural Networks', 'Continuous-Time Models']","This paper proposes a hybrid encoder-decoder architecture for language models to better understand and mimic the psychological plausibility of human conversations, focusing on temporal dynamics of affective states and using physics-informed neural networks to enable temporal and longitudinal adaptation.",136.72,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12343v1_How Well Do LLMs Predict Human Behavior A Measure .pdf,How Well Do LLMs Predict Human Behavior?,"['Wayne Gao', 'Sukjin Han', 'Annie Liang']",,2601.12343,"['Large Language Models', 'Predictive Accuracy', 'Pretrained Knowledge', 'Cross-Validation', 'Panel Study of Income Dynamics']","This paper proposes a measure to evaluate how much knowledge a pretrained Large Language Model brings to predicting human behavior, using equivalent sample size as a metric. It estimates this measure by comparing prediction errors of a fixed LLM to those of flexible machine learning models trained on increasing amounts of domain-specific data, and provides a statistical inference procedure based on new asymptotic theory for cross-validated prediction error. The findings suggest that LLMs encode varying levels of predictive information across different economic variables.",160.67,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12349v1_Zero-Permission Manipulation Can We Trust Large Mu.pdf,Zero-Permission Manipulation: Can We Trust Large Multimodal Model Powered GUI Agents?,"['Yi Qian', 'Kunwei Qian', 'Xingbang He', 'Ligeng Chen', 'Jikang Zhang', 'Tiantai Zhang', 'Haiyang Wei', 'Linzhang Wang', 'Hao Wu', 'Bing Mao']",,,"['GUI agents', 'large multimodal models', 'Android', 'zero-privilege manipulation', 'intent alignment strategy', 'attack chains']","This paper presents Action Rebinding, a novel cross-application attack that allows a seemingly-benign application with zero dangerous permissions to rebind an agent's execution. By exploiting the inevitable observation-to-action gap, the attacker triggers foreground transitions to rebind the agent's planned action toward the target application. The authors also introduce an Intent Alignment Strategy (IAS) to manipulate the agent's reasoning process and bypass verification gates, achieving a 100% success rate in bypassing verification gates and a 100% success rate for atomic action rebinding.",159.07,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12357v1_SimpleMatch A Simple and Strong Baseline for Seman.pdf,SimpleMatch: A Simple and Strong Baseline for Semantic Correspondence,"['Hailong Jin', 'Huiying Li']",,1912.04496,"['semantic correspondence', 'deep learning', 'keypoint matching', 'upsampling', 'low resolution']","This paper presents SimpleMatch, a simple yet effective framework for semantic correspondence that achieves strong performance even at low resolutions, addressing the issue of irreversible fusion of adjacent keypoint features caused by deep downsampling operations.",159.3,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12358v1_From Prompts to Pavement LMMs-based Agentic Behavi.pdf,From Prompts to Pavement:LMMs-based Agentic Behavior-Tree Generation Framework for Autonomous Vehicles,"['Omar Y. Goba', 'Ahmed Y. Gado', 'Catherine M. Elias', 'Ahmed Hussein']",,,"['Behavior-Tree', 'Large Language Model', 'L5 Autonomy', 'Navigation', 'ROS', 'CARLA', 'Nav2']","This paper presents an agentic framework that leverages large language models and multi-modal vision models to generate and adapt behavior trees on the fly for autonomous vehicles, demonstrating successful navigation around unexpected obstacles with no human intervention compared to a static baseline.",155.35,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12374v1_A Scalable Entity-Based Framework for Auditing Bia.pdf,A Scalable Entity-Based Framework for Auditing Bias in LLMs,"['Akram Elbouanani', 'Aboubacar Tuo', 'Adrian Popescu']",,2310.16824,"['Large Language Models', 'Bias Auditing', 'Entity Probes', 'Natural Language Processing', 'Political Bias']","This paper introduces a scalable bias-auditing framework using named entities as probes to measure structural disparities in model behavior, enabling large-scale analysis of bias in large language models (LLMs). The authors demonstrate that synthetic data reliably reproduces bias patterns observed in natural text, and they conduct the largest bias audit to date, revealing systematic biases in models, such as penalizing right-wing politicians and favoring left-wing politicians, Western and wealthy nations, and Western companies. The study also shows that instruction tuning reduces bias, but increasing model scale amplifies it, and prompting in Chinese or Russian does not attenuate Western-aligned preferences.",156.95,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12389v1_NADIR Differential Attention Flow for Non-Autoregr.pdf,NADIR: Differential Attention Flow for Non-Autoregressive Transliteration in Indic Languages,"['Lakshya Tomar', 'Vinayak Abrol', 'Puneet Agarwal']",,2605.08766,"['Transliteration', 'Non-Autoregressive Models', 'Indic Languages', 'Differential Attention', 'Mixture-of-Experts']","This work presents NADIR, a novel non-autoregressive architecture designed for multilingual transliteration in Indic languages, which integrates a Differential Transformer and a Mixture-of-Experts mechanism to achieve a significant speed-up over state-of-the-art autoregressive models while maintaining competitive accuracy.",149.73,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12392v1_PsychēChat An Empathic Framework Focused on Emotio.pdf,Psych¯eChat: An Empathic Framework Focused on Emotion Shift Tracking and Safety Risk Analysis in Psychological Counseling,"['Zhentao Xia', 'Yongqi Fan', 'Yuxiang Chu', 'Yichao Yin', 'Liangliang Chen', 'Tong Ruan', 'Weiyan Zhang']",,2312.09278,"['Psychological Counseling', 'Emotion Shift Tracking', 'Safety Risk Analysis', 'Large Language Models', 'Interactive Role-Playing', 'Emotion Management', 'Risk Control', 'Empathy']","Psych¯eChat is a framework that explicitly integrates emotion shift tracking and safety risk analysis for psychological counseling. It employs interactive role-playing to synthesize counselor-seeker dialogues, incorporating modules for emotion management and risk control. Extensive experiments demonstrate its superior performance in generating context-aware and empathetic responses compared to existing methods.",154.72,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12401v1_Beyond the Dirac Delta Mitigating Diversity Collap.pdf,Beyond the Dirac Delta: Mitigating Diversity Collapse in Reinforcement Fine-Tuning for Versatile Image Generation,"['Jinmei Liu', 'Haoru Li', 'Zhenhong Sun', 'Chaofeng Chen', 'Yatao Bian', 'Bo Wang', 'Daoyi Dong', 'Chunlin Chen', 'Zhi Wang']",,2312.09969,"['Reinforcement Learning', 'Fine-Tuning', 'Generative Models', 'Image Generation', 'Diversity Collapse']","This paper proposes DRIFT, an innovative framework that systematically incentivizes output diversity throughout the on-policy fine-tuning process of reinforcement learning for versatile image generation, addressing the fundamental limitation of diversity collapse in RL fine-tuning methods.",160.12,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12402v1_Weaknesses of Facial Emotion Recognition Systems.pdf,Weaknesses of Facial Emotion Recognition Systems,"['Aleksandra Jamróz', 'Patrycja Wysocka', 'Piotr Garbat']",,2601.12402v1,"['Facial Emotion Recognition', 'Deep learning', 'Computer Vision']","This study presents a comprehensive analysis of advanced facial emotion recognition solutions, evaluating their performance on different datasets and revealing weaknesses, including differences between datasets, unequal levels of difficulty in recognizing certain emotions, and challenges in differentiating between closely related emotions.",149.81,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12405v1_Explainable Machine Learning for Pediatric Dental .pdf,Explainable Machine Learning for Pediatric Dental Risk Stratification Using Socio-Demographic Determinants,"['Manasi Kanade', 'Abhi Thakkar', 'Gabriela Fernandes']",,,"['Pediatric dental disease', 'Machine learning', 'Socio-demographic determinants', 'Artificial intelligence', 'Risk stratification', 'Transparency', 'Ethics']","This study developed and evaluated an explainable artificial intelligence framework for pediatric dental risk stratification, prioritizing interpretability, calibration, and ethical deployment over maximal predictive accuracy, using population-level pediatric data.",131.25,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12410v1_Are LLMs Smarter Than Chimpanzees An Evaluation on.pdf,Are LLMs Smarter Than Chimpanzees?,"['Dingyi Yang', 'Junqi Zhao', 'Xue Li', 'Ce Li', 'Boyang Li']",,,"['Large Language Models', 'Chimpanzees', 'Perspective Taking', 'Knowledge State Estimation', 'Cognitive Anthropology']",This paper evaluates the performance of Large Language Models (LLMs) in detecting when story characters demonstrate knowledge they should not possess and predicting their next actions based on their own knowledge versus objective truths they do not know. Results show that current state-of-the-art LLMs perform near-randomly on both tasks and are substantially inferior to humans. The authors argue for future research to focus on knowledge estimation and intention understanding.,160.2,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12415v1_Orthogonalized Policy OptimizationDecoupling Sampl.pdf,Orthogonalized Policy Optimization,"['Wang, Zixian']",null,2601.12415,"['Policy Optimization', 'Large Language Models', 'Alignment Methods', 'RLHF']","This work shows that recent alignment methods for large language models, including PPO, DPO, and IPO, implicitly conflate two fundamental design choices: sampling geometry and optimization geometry. The authors propose Orthogonalized Policy Optimization (OPO) to explicitly decouple these choices, leading to a stable and well-conditioned objective with linear gradient dynamics.",161.63,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12436v1_Purification Before Fusion Toward Mask-Free Speech.pdf,PURIFICA TION BEFORE FUSION: TOW ARD MASK-FREE SPEECH ENHANCEMENT FOR ROBUST AUDIO-VISUAL SPEECH RECOGNITION,"['Linzhi Wu', 'Xingyu Zhang', 'Hao Yuan', 'Yakun Zhang', 'Changyan Zheng', 'Liang Xie', 'Tiejun Liu', 'Erwei Yin']",10.1109/TCSVT.2024.3384796,2312.15898,"['audio-visual speech recognition', 'speech feature enhancement', 'noise-robust', 'multimodal bottleneck Conformer']","This work proposes an end-to-end noise-robust audio-visual speech recognition framework that eliminates the need for explicit noise masks. It leverages a Conformer-based bottleneck fusion module to implicitly refine noisy audio features with video assistance, preserving speech semantic integrity and achieving robust recognition performance under noisy conditions.",143.18,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12442v1_Constraint-Aware Neurosymbolic Uncertainty Quantif.pdf,Constraint-Aware Neurosymbolic Uncertainty Quantification with Bayesian Deep Learning for Scientific Discovery,"['Shahnawaz Alam', 'Mohammed Mudassir Uddin', 'Mohammed Kaif Pasha']",,1912.07957,"['Neurosymbolic AI', 'Uncertainty Quantification', 'Bayesian Deep Learning', 'Scientific Constraints', 'Calibration', 'Physics-Informed Machine Learning']","The paper introduces the Constraint-Aware Neurosymbolic Uncertainty Framework (CANUF), which unifies Bayesian deep learning with differentiable symbolic reasoning to address the challenges of uncertainty quantification and constraint satisfaction in scientific applications.",160.7,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12443v1_Adversarial Defense in Vision-Language Models An O.pdf,Adversarial Defense in Vision-Language Models: An Overview,"['Xiaowei Fu', 'Lei Zhang*']",,,"['Vision Language Models', 'adversarial defense', 'survey']","This paper reviews the latest advancements in adversarial defense strategies for Vision-Language Models (VLMs), highlighting the strengths and limitations of training-time, test-time adaptation, and training-free defense approaches.",162.28,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12444v1_Large Language Model for OWL Proofs.pdf,Large Language Model for OWL Proofs,"['Hui Yang', 'Jiaoyan Chen', 'Uli Sattler']",10.1145/XXXXXX.XXXXXX,,"['Large Language Models', 'OWL Proofs', 'Reasoning', 'Proof Generation', 'Logic Completeness', 'Natural Language Generation']","This work investigates proof generation in the context of OWL ontologies by developing an automated dataset construction and evaluation framework, encompassing tasks such as extraction, simplification, and explanation, and assessing logic completeness of the premise. Experiments on widely used reasoning LLMs reveal important findings on LLM performance, logical complexity, and input data quality.",159.5,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12449v1_AgenTRIM Tool Risk Mitigation for Agentic AI.pdf,AgenTRIM: Tool Risk Mitigation for Agentic AI,"['Roy Betser', 'Shamik Bose', 'Amit Giloni', 'Chiara Picardi', 'Sindhu Padakandla', 'Roman Vainshtein']",,,"['AI agents', 'tool-driven agency', 'security risks', 'least-privilege access', 'adaptive filtering', 'status-aware validation']","This paper introduces AGENTRIM, a framework designed to detect and mitigate security risks associated with tool-driven agency in AI agents, without altering the agents' internal reasoning. AGENTRIM addresses these risks through complementary offline and online phases, reconstructing and verifying the agent's tool interface from code and execution traces, and enforcing least-privilege tool access at runtime through adaptive filtering and status-aware validation of tool calls. Evaluations on the AgentDojo benchmark demonstrate that AGENTRIM substantially reduces attack success while maintaining high task performance.",160.44,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12465v1_Incentivizing In-depth Reasoning over Long Context.pdf,Preprint,"['Miao Peng', 'Weizhou Shen', 'Nuo Chen', 'Chenliang Li', 'Ming Yan', 'Jia Li']",,2310.16798,"['Reinforcement Learning', 'Long Context Reasoning', 'LLMs', 'KG-driven', 'Process Advantage Shaping']","This paper proposes DEEPREASONQA, a KG-driven synthesis framework for constructing high-difficulty, multi-hop long-context QA pairs, and introduces LONGPAS, a method for fine-grained credit assignment along validity and relevance dimensions. Experiments show that this approach substantially outperforms RLVR baselines and matches frontier LLMs while using fewer parameters.",160.61,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12467v1_Patch-Level Tokenization with CNN Encoders and Att.pdf,Patch-Level Tokenization with CNN Encoders and Attention for Improved Transformer Time-Series Forecasting,"['Saurish Nagrath', 'VIT-AP']",,1912.09778,"['Transformer-based models', 'time-series forecasting', 'multivariate time-series forecasting', 'financial time-series forecasting', 'convolutional neural networks', 'attention mechanisms', 'representation learning', 'deep learning for finance']","This work proposes a two-stage forecasting framework that explicitly separates local temporal representation learning from global dependency modelling, using CNNs to extract short-range temporal dynamics and non-linear feature interactions, and a Transformer encoder to model inter-patch temporal dependencies.",160.25,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12471v1_Knowing When to Abstain Medical LLMs Under Clinica.pdf,Knowing When to Abstain: Medical LLMs Under Clinical Uncertainty,"['Sravanthi Machcha', 'Sushrita Yerra', 'Sahil Gupta', 'Aishwarya Sahoo', 'Sharmin Sultana', 'Hong Yu', 'Zonghai Yao']",,2310.16675,"['large language models', 'medical multiple-choice question answering', 'abstention', 'conformal prediction', 'adversarial perturbations', 'uncertainty quantification']","This paper introduces MedAbstain, a unified benchmark and evaluation protocol for abstention in medical multiple-choice question answering, integrating conformal prediction, adversarial question perturbations, and explicit abstention options. The systematic evaluation of both open- and closed-source LLMs reveals that even state-of-the-art models often fail to abstain when uncertain, highlighting the central role of abstention mechanisms for trustworthy deployment in high-stakes applications.",158.61,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12494v1_Harmonizing the Arabic Audio Space with Data Sched.pdf,Harmonizing the Arabic Audio Space with Data Scheduling,"['Hunzalah Hassan Bhatti', 'Firoj Alam', 'Shammur Absar Chowdhury']",,2310.16888,"['Audio Large Language Models', 'Instruction Tuning', 'Arabic Speech Summarization', 'Dialect Identification', 'Emotion Recognition', 'Data Scheduling', 'Parameter-Efficient Fine-Tuning']","This paper presents a systematic study of multi-task instruction tuning for an Arabic-centric audio Large Language Model, covering generative and discriminative tasks. It introduces a new dataset and proposes a strategy to harmonize data scheduling and sampling for efficient adaptation in complex, low-resource environments.",159.08,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12499v1_Failure Modes in Multi-Hop QA The Weakest Link Law.pdf,Failure Modes in Multi-Hop QA: The Weakest Link Law and the Recognition Bottleneck,"['Meiru Zhang', 'Zaiqiao Meng', 'Nigel Collier']",,2312.08988,"['Multi-Hop QA', 'Large Language Models', 'Position Bias', 'Attention Mechanisms', 'Recognition Failure', 'Synthesis Failure', 'Weakest Link Law']","This paper introduces Multi-Focus Attention Instruction (MFAI) to disentangle mechanisms causing failures in multi-hop reasoning of Large Language Models (LLMs), demonstrating that multi-hop reasoning performance collapses to the performance level of the least visible evidence, governed by absolute position rather than linear distance.",159.52,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12518v1_Cooperative Multi-agent RL with Communication Cons.pdf,Cooperative Multi-agent RL with Communication constraints,"['Nuoya Xiong ∗', 'Aarti Singh †']",,2601.02177,"['Cooperative Multi-agent Reinforcement Learning', 'Communication Constraints', 'Importance Sampling', 'Base Policy Prediction', 'ε-Nash Equilibrium', 'Potential Games', 'Markov Cooperative Games']","This paper addresses the challenge of cooperative multi-agent reinforcement learning (MARL) in decentralized systems with limited communication, proposing a technique called base policy prediction to reduce communication costs and improve learning efficiency.",156.48,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12522v1_Improved Bug Localization with AI Agents Leveragin.pdf,Improved Bug Localization with AI Agents Leveraging Hypothesis and Dynamic Cognition,"['Asif Mohammed Samir', 'Mohammad Masudur Rahman']",https://doi.org/XXXXXXX.XXXXXXX,,"['Bug Localization', 'LLM', 'Agentic AI', 'Cognition', 'Debugging', 'Software Engineering', 'Information Retrieval']","This paper presents a novel agentic technique, CogniGent, for bug localization that overcomes limitations of traditional methods and LLMs by leveraging multiple AI agents capable of causal reasoning, call-graph-based root cause analysis, and context engineering. It emulates dynamic cognitive debugging practices and conducts hypothesis testing to support bug localization, achieving significant improvements in performance metrics compared to existing techniques.",138.35,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12534v1_Encoding Emotion Through Self-Supervised Eye Movem.pdf,ENCODING EMOTION THROUGH SELF-SUPERVISED EYE MOVEMENT RECONSTRUCTION,"['Marcus Ma', 'Jordan Prescott', 'Emily Zhou', 'Tiantian Feng', 'Kleanthis Avramidis', 'Gabor Mihaly Toth', 'Shrikanth Narayanan']",,1912.04876,"['eye movement', 'self-supervised learning', 'emotion prediction', 'deep learning']","This paper investigates how eye movement can predict multimodal markers of emotional expression from naturalistic, low-resolution videos. It uses a large dataset of Holocaust survivor interviews to develop a novel gaze detection model that can effectively leverage unlabeled video data, and applies this model to two downstream tasks related to emotional expression.",158.56,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12535v1_Improving Low-Resource Machine Translation via Rou.pdf,Improving Low-Resource Machine Translation via Round-Trip Reinforcement Learning,"['Ahmed Attia', 'Alham Fikri']",,2309.14720,"['machine translation', 'reinforcement learning', 'low-resource', 'round-trip', 'self-supervised', 'reinforcement learning-based fine-tuning']","This paper investigates a self-supervised reinforcement-learning-based fine-tuning approach for translation in low-resource settings using round-trip bootstrapping with the No Language Left Behind (NLLB) family of models. The authors evaluate both the 600M and 1.3B parameter NLLB models and observe consistent improvements for several target low-resource languages, indicating increased fluency and semantic fidelity in translation outputs.",138.82,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12538v1_Agentic Reasoning for Large Language Models.pdf,Agentic Reasoning for Large Language Models,"['Tianxin Wei', 'Ting-Wei Li', 'Zhining Liu', 'Xuying Ning', 'Ze Yang', 'Jiaru Zou', 'Zhichen Zeng', 'Ruizhong Qiu', 'Xiao Lin', 'Dongqi Fu', 'Wenxuan Bao', 'Yunzhe Li', 'Gaotang Li', 'Cheng Qian', 'Yu Wang', 'Xiangru Tang', 'Yuji Zhang', 'Chi Wang', 'Jiaxuan You', 'Heng Ji', 'Hanghang Tong', 'Jingrui He']",,2601.12538,"['Agentic AI', 'LLM Agent', 'Agentic Reasoning', 'Self-evolving']","This survey provides a systematic roadmap for agentic reasoning, a paradigm shift that bridges thought and action by reframing large language models as autonomous agents capable of planning, acting, and learning through continual interaction. It analyzes system constraints and optimization settings, distinguishing in-context reasoning from post-training reasoning, and reviews agentic reasoning frameworks in various applications and benchmarks.",159.27,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12539v1_MemeLens Multilingual Multitask VLMs for Memes.pdf,MemeLens: Multilingual Multitask VLMs for Memes,"['Ali Ezzat Shahroor', 'Mohamed Bayan Kmainasi', 'Abul Hasnat', 'Dimitar Dimitrov', 'Giovanni Da San Martino', 'Preslav Nakov', 'Firoj Alam']",,2310.16619,"['memes', 'multimodal', 'vision-language model', 'multitask', 'hate speech', 'misogyny', 'sentiment analysis', 'humor', 'figurative language', 'persuasion']","This paper proposes MEMELENS, a unified multilingual and multitask vision-language model for meme understanding, consolidating 38 public datasets and presenting a comprehensive empirical analysis across various tasks and categories.",159.22,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12542v1_Rethinking the AI Scientist Interactive Multi-Agen.pdf,Rethinking the AI Scientist: Interactive Multi-Agent Workflows for Scientific Discovery,"['Lukas Weidener*', 'Marko Brkić*', 'Mihailo Jovanović*', 'Ritvik Singh', 'Chiara Baccin', 'Emre Ulgac', 'Alex Dobrin', 'Aakaash Meduri']",,,"['Artificial Intelligence', 'Scientific Discovery', 'Multi-Agent Systems', 'Interactive Workflows', 'Open Access Literature', 'Novelty Detection']","This paper introduces Deep Research, a multi-agent system enabling interactive scientific investigation with turnaround times measured in minutes, supporting different workflows and achieving state-of-the-art performance on the BixBench benchmark.",159.92,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12547v1_How Clinicians Think and What AI Can Learn From It.pdf,"Ordinal-First, Robust Decision Algorithms for Medicine","['Dr. Dipayan Sengupta', 'Dr. Saumya Panda']",null,2601.12547,"['Clinical AI', 'Ordinal decision-making', 'Robust algorithms', 'Decision-making under uncertainty', 'Lexicographic heuristics', 'Threshold approach']","This paper argues for a shift in the algorithmic center of gravity of clinical AI from prediction engines to robust action selection, focusing on ordinal non-compensatory decision-making and the use of robust algorithms in medicine.",139.73,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12549v1_Benchmarking Concept-Spilling Across Languages in .pdf,Benchmarking Concept-Spilling Across Languages in LLMs,"['Ilia Badanin', 'Daniil Dzenhaliou', 'Imanol Schlag']",,2601.12549v1,"['Large Language Models', 'Cross-Lingual', 'Semantic Robustness', 'Polysemy', 'LLM Evaluation', 'Language Spilling']","This paper presents a novel comparative framework for evaluating multilingual semantic robustness by measuring how models handle polysemous words across languages, providing a relative measure of model performance and revealing significant variation in semantic robustness across models and languages.",161.78,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12554v1_Artificial Intelligence in Materials Science and E.pdf,"Artificial Intelligence in Materials Science and Engineering: Current Landscape, Key Challenges, and Future Trajectories","['Iman Peivaste', 'Salim Belouettar', 'Francesco Mercuri', 'Nicholas Fantuzzi', 'Hamidreza Dehghani', 'Razieh Izadi', 'Halliru Ibrahim', 'Jakub Lengiewicz', 'Maël Belouettar-Mathis', 'Kouider Bendine', 'Ahmed Makradi', 'Martin Hörsch', 'Peter Klein', 'Mohamed El Hachemi', 'Heinz A. Preisig', 'Yacine Rezgui', 'Natalia Konchakova', 'Ali Daouadji']",,2601.12554,"['Artificial Intelligence', 'Materials Science', 'Materials Engineering', 'Machine Learning', 'Deep Learning', 'Data-Driven Techniques', 'Data Representation', 'Feature Extraction', 'Uncertainty Quantification', 'Generative Models', 'Probabilistic Models']","This review provides a comprehensive and structured overview of the current landscape of Artificial Intelligence in materials science and engineering, synthesizing recent advancements and methodologies for materials scientists to effectively leverage these data-driven techniques, including machine learning approaches from traditional algorithms to advanced deep learning architectures.",161.49,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12557v1_Life Machine Learning and the Search for Habitabil.pdf,"Life, Machine Learning, and the Search for Habitability: Predicting Biosignature Fluxes for the Habitable Worlds Observatory","['Mark Moussa1', 'Amber V. Young1', 'Brianna Isola1', 'Vasuda Trehan1', 'Michael D. Himes1', 'Nicholas Wogan2', 'Giada Arney1']",,2301.00000,"['Machine Learning', 'Exoplanets', 'Biosignatures', 'Habitable Worlds Observatory', 'Direct Imaging', 'Bayesian Convolutional Neural Network', 'Spectral Query Adaptive Transformer']","This paper introduces advanced machine-learning architectures, BCNN and SQuAT, for predicting biosignature species fluxes from exoplanetary reflected-light spectra. Both models achieve high predictive accuracy and highlight their distinct advantages in uncertainty quantification and spectral interpretability, positioning them as promising tools for accelerating target triage and optimizing observation schedules for upcoming flagship missions like HWO.",161.51,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12560v1_Agentic Artificial Intelligence AI Architectures T.pdf,"Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents","['Arunkumar V', 'Gangadharan G.R.', 'Rajkumar Buyya']",null,2601.12560v1,"['Agentic AI', 'Large Language Models', 'Autonomous Agents', 'Multi-Agent Systems', 'Cognitive Architectures', 'Tool Use', 'Planning']","This paper investigates the architectures and proposes a unified taxonomy for Agentic AI, focusing on large language models as cognitive controllers that combine memory, tool use, and feedback to pursue extended goals. It describes the transition from linear reasoning to native inference and the shift from fixed API calls to open standards, and reviews current evaluation practices, highlighting open challenges and future research directions.",160.94,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12577v1_Primate-like perceptual decision making emerges th.pdf,Primate-like perceptual decision making emerges through deep recurrent reinforcement learning,"['Nathan J. Wispinski', 'Scott A. Stone', 'Anthony Singhal', 'Patrick M. Pilarski', 'Craig S. Chapman']",,2601.12577,"['primate decision making', 'reinforcement learning', 'deep recurrent neural networks', 'perceptual discrimination', 'flexible decision making', 'evidence accumulation', 'neural mechanisms']","This study trained a deep recurrent neural network using reinforcement learning on a noisy perceptual discrimination task, demonstrating key abilities of primate-like decision making such as trading off speed for accuracy and flexibly changing their mind in the face of new information, providing experimental support for the theory that these abilities emerged to maximize reward in noisy, temporally evolving environments.",162.17,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12582v1_Ontology-aligned structuring and reuse of multimod.pdf,Ontology-aligned structuring and reuse of multimodal materials data and workflows towards automatic reproduction,"['Sepideh Baghaee Ravari', 'Abril Azocar', 'Guzman Sarath', 'Menon Stefan', 'Sandfeld Tilmann', 'Hickel Markus', 'Stricker Markus']",,,"['text mining', 'workflow', 'large language models', 'stacking fault energy']","The paper introduces an ontology-driven, large language model (LLM)-assisted framework for the automated extraction and structuring of computational workflows from the literature, focusing on density functional theory-based stacking fault energy (SFE) calculations in hexagonal close-packed magnesium and its binary alloys. The approach uses a multi-stage filtering strategy and prompt-engineered LLM extraction, enabling the construction of a knowledge graph for systematic comparison of reported SFE values and structured reuse of computational protocols.",159.45,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12585v1_Do MLLMs See What We See Analyzing Visualization L.pdf,Do MLLMs See What We See?,"['Mengli (Dawn) Duan*', 'Yuhe (Sissi) Jiang*', 'Matthew Varona', 'Carolina Nobre']",,1x/xxx,"['Visualization Literacy', 'Multimodal Large Language Model', 'Evaluation Study']","This paper presents the first systematic analysis of barriers to visualization literacy in Multimodal Large Language Models (MLLMs), using a benchmark with synthetic data and open-coding 309 erroneous responses from four state-of-the-art models. The analysis reveals two machine-specific barriers and informs future evaluation and design of reliable AI-driven visualization assistants.",159.39,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12594v1_SLAP Scalable Language-Audio Pretraining with Vari.pdf,SLAP: SCALABLE LANGUAGE-AUDIO PRETRAINING WITH V ARIABLE-DURATION AUDIO AND MULTI-OBJECTIVE TRAINING,"['Xinhao Mei', 'Gael Le Lan', 'Haohe Liu', 'Zhaoheng Ni', 'V arun Nagaraja', 'Yang Liu', 'Yangyang Shi', 'Vikas Chandra']",,2303.07404,"['Multimodal learning', 'CLAP', 'self-supervised learning', 'contrastive learning', 'multi-objective learning']","SLAP is a scalable language-audio pretraining model that addresses the limitations of current CLAP models by training on 109 million audio-text pairs with variable audio durations and incorporating multiple training objectives, leading to new state-of-the-art performance on audio-text retrieval and zero-shot audio classification tasks.",159.13,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12607v1_A Cloud-based Multi-Agentic Workflow for Science.pdf,A Cloud-based Multi-Agentic Workflow for Science,"['Anurag Acharya', 'Timothy Vega', 'Rizwan A. Ashraf', 'Anshu Sharma', 'Derek Parker', 'Robert Rallo']",10.1145/nnnnnnn.nnnnnnn,,"['Large Language Models', 'LLMs for Science', 'LLM Agents', 'Multi-agent Framework', 'Catalysis', 'Chemistry', 'Material Science', 'Cloud Computing']","This paper presents a domain-agnostic, model-independent workflow for an agentic framework that can act as a scientific assistant while being run entirely on cloud. The framework balances LLMs, cloud providers, and external resources, and is demonstrated with a proof-of-concept system for Catalysts, showing high task routing and completion rates, and comparable accuracy to frontier models.",158.36,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12617v1_Creating Disability Story Videos with Generative A.pdf,"Creating Disability Story Videos with Generative AI: Motivation, Expression, and Sharing","['Shuo Niu', 'Dylan Clements', 'Hyungsin Kim']",10.1145/3772318.3791495,,"['Disability', 'Storytelling', 'Video', 'Generative AI', 'LLM']","This research examines how nine people with disabilities used generative AI to create videos sharing their disability experiences, exploring motivations, expression, and sharing. The authors conclude with a framework of momentous depiction, highlighting four core affordances of GenAI that facilitate or require improvements for better supporting disability storytelling.",160.01,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12637v1_Topology-Aware Multiscale Mixture of Experts for E.pdf,TOPOLOGY-AWAREMULTISCALEMIXTURE OFEXPERTS FOR EFFICIENTMOLECULARPROPERTYPREDICTION,"['Long D. Nguyen', 'Kelin Xia', 'Binh P. Nguyen']",,2601.12637,"['Graph Neural Networks', 'Topological Deep Learning', 'Mixture of Experts', 'Molecular Representation']","This paper proposes Multiscale Interaction Mixture of Experts (MI-MoE) to adapt interaction modeling across geometric regimes, improving multiple strong 3D molecular backbones across diverse molecular and polymer property prediction benchmark datasets, covering both regression and classification tasks.",159.5,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12638v1_Mixed Precision PointPillars for Efficient 3D Obje.pdf,Mixed Precision PointPillars for Efficient 3D Object Detection with TensorRT,"['1st Ninnart Fuengfusin', '2nd Keisuke Yoneda', '3rd Naoki Suganuma']",,,"['neural networks', 'quantization', '3D object detection']","This paper proposes a mixed precision framework for PointPillars, a model for LIDAR 3D object detection, to improve efficiency and real-time performance. The framework uses post-training quantization to identify sensitive layers and combines them to create candidate mixed precision models, which are finalized with either post-training quantization or quantization-aware training. The authors also address the issue of outliers by using a small number of calibration data, resulting in improved performance of post-training quantization.",160.42,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12641v1_STEP-LLM Generating CAD STEP Models from Natural L.pdf,STEP-LLM: Computer-Aided Design from Natural Language with Large Language Models,"['Xiangyu Shi', 'Junyang Ding', 'Xu Zhao', 'Sinong Zhan', 'Payal Mohapatra', 'Daniel Quispe', 'Kojo Welbeck', 'Jian Cao', 'Wei Chen', 'Ping Guo', 'Qi Zhu']",10.48550/arXiv.2601.12641,2601.12641,"['Computer-aided design', 'STEP file', 'large language models', 'design automation']","This paper presents a novel approach to generate CAD models from natural language using large language models, addressing the challenges posed by the graph-structured, cross-referenced nature of the STEP file format. The authors introduce a dataset of 40,000 STEP-caption pairs, develop a preprocessing method tailored for STEP's graph structure, and integrate retrieval-augmented generation and reinforcement learning to improve geometric fidelity and completeness of the generated models.",145.74,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12646v1_Unbounded Harms Bounded Law Liability in the Age o.pdf,"Unbounded Harms, Bounded Law: Liability in the Age of Borderless AI",['Ha-Chi Tran'],,2601.12646v1,"['artificial intelligence', 'liability', 'risk governance', 'transboundary risks', 'deep neural networks', 'vaccine injury compensation', 'financial systemic risk', 'commercial nuclear energy liability', 'international environmental harm']","This paper examines the inadequacies of current legal frameworks in addressing the risks and harms associated with artificial intelligence, particularly in the context of transboundary AI harms, and proposes transferable legal design principles from adjacent high-risk and transnational domains to address these issues.",136.03,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12648v1_Intelligent Documentation in Medical Education Can.pdf,Intelligent Documentation in Medical Education: Can AI Replace Manual Case Logging?,"['Nafiz Imtiaz Khan', 'MSc', 'Department of Computer Science, University of California, Davis, CA, USA', 'Kylie Cleland', 'BSc', 'Department of Radiology, University of California, Davis, CA, USA', 'Vladimir Filkov', 'PhD', 'Department of Computer Science, University of California, Davis, CA, USA', 'Roger Eric Goldman', 'PhD', 'Department of Radiology, University of California, Davis, CA, USA']",,,"['artificial intelligence', 'large language models', 'radiology', 'case logs', 'medical education']","This study investigates the feasibility of using large language models to automate procedural case log documentation in radiology training, evaluating whether AI can replace manual logging and assessing integration into clinical workflows.",158.62,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12654v1_Explanation Multiplicity in SHAP Characterization .pdf,Explanation Multiplicity in SHAP: Characterization and Assessment,"['HYUNSEUNG HWANG', 'KAIST, Republic of Korea', 'SEUNGEUN LEE', 'New York University, USA', 'LUCAS ROSENBLATT', 'New York University, USA', 'JULIA STOYANOVICH', 'New York University, USA', 'STEVEN EUIJONG WHANG', 'KAIST, Republic of Korea']",null,null,"['Explainable AI', 'SHAP', 'Post-hoc feature attribution', 'Explanation multiplicity', 'Stochasticity', 'Feature ranking', 'Model training', 'Model selection', 'Explanation consistency', 'Explanation instability']","This paper discusses the phenomenon of explanation multiplicity in SHAP, where post-hoc explanations for individual predictions can differ substantially across repeated runs, even when the individual, prediction task, and trained model are held fixed. The authors present a methodology for characterizing explanation multiplicity and show that it is widespread and persists even under highly controlled conditions, including high-confidence predictions. The results highlight the normative challenge for responsible AI deployment and the need for metrics and baselines aligned with their intended societal role.",158.84,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12658v1_Augmenting Question Answering with A Hybrid RAG Ap.pdf,Augmenting Question Answering with A Hybrid RAG Approach,"['Tianyi Yang∗', 'Nashrah Haque ∗', 'Vaishnave Jonnalagadda∗', 'Yuya Jeremy Ong †', 'Zhehui Chen ‡', 'Yanzhao Wu§', 'Lei Yu ¶', 'Divyesh Jadav ∥', 'Wenqi Wei∗']",,,"['Question-answering', 'RAG', 'query processing', 'LLMs', 'Factual consistency', 'Logical reasoning', 'Self-refinement']","This paper introduces Structured-Semantic RAG (SSRAG), a hybrid architecture that enhances QA quality by integrating query augmentation, agentic routing, and a structured retrieval mechanism combining vector and graph based techniques with context unification. The approach improves both answer accuracy and informative-ness over standard RAG implementations, as demonstrated through extensive evaluations on three popular QA datasets.",141.31,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12661v1_MedConsultBench A Full-Cycle Fine-Grained Process-.pdf,"MedConsultBench: A Full-Cycle, Fine-Grained, Process-Aware Benchmark for Medical Consultation Agents","['Chuhan Qiao*', 'Jianghua Huang*', 'Daxing Zhao*', 'Ziding Liu', 'Yanjun Shen†', 'Bing Cheng', 'Wei Lin', 'Kai Wu']",,2601.12661,"['Medical Consultation Agents', 'Benchmark', 'Clinical Workflow', 'Fine-Grained Metrics', 'Information Acquisition', 'Diagnostic Rigor', 'Information-Gathering Efficiency', 'Medication Safety', 'Constraint-Respecting Plan Revisions']","MedConsultBench is a comprehensive framework designed to evaluate the complete online consultation cycle, covering the entire clinical workflow from history taking and diagnosis to treatment planning and follow-up Q&A. It introduces Atomic Information Units (AIUs) to track clinical information acquisition at a sub-turn level, enabling precise monitoring of how key facts are elicited through 22 fine-grained metrics. The benchmark evaluates uncertainty-aware yet concise inquiry while emphasizing medication regimen compatibility and the ability to handle realistic post-prescription follow-up Q&A via constraint-respecting plan revisions.",157.35,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12664v1_Generalizable Hyperparameter Optimization for Fede.pdf,Generalizable Hyperparameter Optimization for Federated Learning on Non-IID Cancer Images,"['Elisa Gonçalves Ribeiro', 'Rodrigo Moreira', 'Larissa Ferreira Rodrigues Moreira', 'André Ricardo Backes']",,2309.15656,"['Federated Learning', 'Hyperparameter Optimization', 'Non-IID Data', 'Medical Imaging', 'Cancer']","This paper examines whether hyperparameters optimized on one cancer imaging dataset generalize across non-IID federated scenarios, considering binary histopathology tasks for ovarian and colorectal cancers, and introduces a simple cross-dataset aggregation heuristic for achieving competitive classification performance.",159.35,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12667v1_Empowering All-in-Loop Health Management of Spacec.pdf,Empowering All-in-Loop Health Management of Spacecraft Power System in the Mega-Constellation Era via Human-AI Collaboration,"['Yi Di', 'Zhibin Zhao', 'Fujin Wang', 'Xue Liu', 'Jiafeng Tang', 'Jiaxin Ren', 'Zhi Zhai', 'Xuefeng Chen']",,2309.00001,"['Large Language Model', 'Human-AI Collaboration', 'Spacecraft Power System', 'All-in-loop Health Management', 'Satellite Mega-Constellation']","This work proposes a principle of aligning underlying capabilities (AUC principle) and develops SpaceHMchat, an open-source Human-AI collaboration (HAIC) framework for all-in-loop health management (AIL HM) of spacecraft power systems (SPS) in the satellite mega-constellation era. SpaceHMchat achieves excellent performance across 23 quantitative metrics, such as 100% conclusion accuracy in logical reasoning of work condition recognition, over 99% success rate in anomaly detection tool invocation, over 90% precision in fault localization, and knowledge base search time under 3 minutes in maintenance decision-making. The work also releases the first-ever AIL HM dataset of SPS.",156.57,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12671v1_Exploiting Test-Time Augmentation in Federated Lea.pdf,Exploiting Test-Time Augmentation in Federated Learning for Brain Tumor MRI Classification,"['Thamara Leandra de Deus Melo', 'Rodrigo Moreira', 'Larissa Ferreira Rodrigues Moreira', 'André R. Backes']",,2304.13757,"['Brain tumors', 'Federated Learning', 'Test-Time Augmentation', 'Image classification']","This paper evaluates the use of convolutional neural networks (CNNs) in a federated learning (FL) setting for brain tumor MRI classification, comparing models trained on original versus preprocessed MRI images, and finds that combining preprocessing with test-time augmentation (TTA) delivers consistent, statistically significant improvements in federated MRI classification.",157.04,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12688v1_Logic-Guided Multistage Inference for Explainable .pdf,Logic-Guided Multistage Inference for Explainable Multidefendant Judgment Prediction,"['Xu Zhang', 'Qinghua Wang', 'Mengyang Zhao', 'Fang Wang', 'Cunquan Qu']",,,"['Multiple defendants', 'Legal judgment predictions', 'Label broadcast', 'Guilt responsibility', 'Transformer']","This paper proposes a masked multistage inference (MMSI) framework to enhance intelligent judicial systems by incorporating sentencing logic into a pretrained Transformer encoder framework. The framework clarifies roles and improves the model's sensitivity to culpability distinctions between principals and accomplices, achieving significant accuracy improvements in role-based culpability differentiation on the custom IMLJP dataset for intentional injury cases.",137.46,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12711v1_Neurosymbolic LoRA Why and When to Tune Weights vs.pdf,Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts,"['Kevin Wang', 'Neel P. Bhatt', 'Cong Liu', 'Junbo Li', 'Runjin Chen', 'Yihan Xi', 'Timothy Barclay', 'Alvaro Velasquez', 'Ufuk Topcu', 'Zhangyang Wang']",,2312.14666,"['Neurosymbolic AI', 'Large Language Models', 'Low-Rank Adaptation', 'Symbolic Reasoning', 'Neurosymbolic LoRA', 'TextGrad', 'Prompt Tuning', 'Gradient-based Editing']","This paper introduces a neurosymbolic LoRA framework that dynamically combines numerical updates and symbolic manipulations to adapt large language models, demonstrating superior adaptability and performance compared to purely numerical or symbolic approaches.",159.64,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12715v1_RSOD Reliability-Guided Sonar Image Object Detecti.pdf,RSOD: Reliability-Guided Sonar Image Object Detection with Extremely Limited Labels,"['Chengzhou Li', 'Ping Guo', 'Guanchen Meng', 'Qi Jia', 'Jinyuan Liu', 'Zhu Liu', 'Xiaokang Liu', 'Yu Liu', 'Zhongxuan Luo', 'Xin Fan']",,2301.00000,"['Sonar Image Object Detection', 'Reliability-Guided Pseudo-Labeling', 'Extremely Limited Labels', 'Teacher-Student Framework', 'Underwater Detection']","This paper proposes RSOD, a teacher-student framework for object detection in sonar images with extremely limited labels, aiming to leverage the consistency of teacher predictions across different views to develop pseudo-label strategies and optimize student performance through reliability-guided adaptive constraints, achieving competitive results even with only 5% labeled data.",157.96,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12720v1_Teaching Large Reasoning Models Effective Reflecti.pdf,Teaching Large Reasoning Models Effective Reflection,"['Hanbin Wang', 'Jingwei Song', 'Jinpeng Li', 'Qi Zhu', 'Fei Mi', 'Ganqu Cui', 'Yasheng Wang', 'Lifeng Shang']",,2310.16528,"['Large Reasoning Models', 'Self-Reflection', 'Reinforcement Learning', 'Fine-Tuning', 'Effective Reflection Rewards']",This paper addresses the problem of superficial reflection in Large Reasoning Models (LRMs) by proposing Self-Critique Fine-Tuning (SCFT) and Reinforcement Learning with Effective Reflection Rewards (RLERR). Experiments on challenging benchmarks show significant improvements in reasoning accuracy and reflection quality.,156.56,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12723v1_An Evolutionary Framework for Automatic Optimizati.pdf,An Evolutionary Framework for Automatic Optimization Benchmark Generation via Large Language Models,"['Yuhiro Ono', 'Tomohiro Harada', 'Yukiya Miura']",,2601.12723v1,"['Optimization benchmarks', 'Large language models', 'Benchmark generation', 'Evolutionary algorithms', 'Genetic algorithms', 'Differential evolution']","This paper proposes an evolutionary framework for automatically generating optimization benchmarks using a large language model, which successfully produces problems favoring genetic algorithms and revealing distinct geometric characteristics reflective of different optimization algorithms.",158.07,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12727v1_AI-exhibited Personality Traits Can Shape Human Se.pdf,AI-exhibited Personality Traits Can Shape Human Self-concept through Conversations,"['Jingshu Li', 'Tianqi Song', 'Nattapat Boonprakong', 'Zicheng Zhu', 'Yitian Yang', 'Yi-Chieh Lee']",10.1145/3772318.3790654,2601.12727v1,"['AI', 'Personality Traits', 'Self-concept', 'Conversations', 'Large Language Models']","This study investigates how AI-based chatbots with exhibited personality traits can shape human self-concepts during conversations, finding that after interacting with the AI, individuals' self-concepts align with the AI's measured personality traits, leading to increased homogeneity of self-concepts.",159.19,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12731v1_A Shared Geometry of Difficulty in Multilingual La.pdf,A Shared Geometry of Difficulty in Multilingual Language Models,"['Stefano Civelli', 'Pietro Bernardelle', 'Nicolò Brunello', 'Gianluca Demartini']",,2309.14424,"['Language Models', 'Multilingual', 'Problem Difficulty', 'Linear Probes', 'Transformer Layers', 'Cross-Lingual Generalization']","This paper investigates the multilingual geometry of problem-difficulty in large language models by training linear probes on the AMC subset of the Easy2Hard benchmark translated into 21 languages. It finds that difficulty-related signals emerge at two distinct stages of the model internals, corresponding to shallow and deep internal representations, and discusses the implications for model interpretability and cross-lingual generalization.",157.42,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12740v1_TreeWriter AI-Assisted Hierarchical Planning and W.pdf,TreeWriter: AI-Assisted Hierarchical Planning and Writing for Long-Form Documents,"['Zijian Zhang', 'Fangshi Du', 'Xingjian Liu', 'Pan Chen', 'Oliver Huang', 'Runlong Ye', 'Michael Liut', 'Alán Aspuru-Guzik']",,1909.05029,"['AI', 'writing', 'long-form documents', 'hierarchical planning', 'contextual AI support']","TreeWriter is a hierarchical writing system that represents documents as trees and integrates contextual AI support, allowing authors to create, save, and refine document outlines at multiple levels, facilitating drafting, understanding, and iterative editing of long documents.",160.16,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12742v1_AirHunt Bridging VLM Semantics and Continuous Plan.pdf,AirHunt: Bridging VLM Semantics and Continuous Planning for Efficient Aerial Object Navigation,"['Xuecheng Chen', 'Zongzhuo Liu', 'Jianfa Ma', 'Bang Du', 'Tiantian Zhang', 'Xueqian Wang', 'Boyu Zhou']",,1901.01370,"['Aerial Object Navigation', 'Vision-Language Models', 'Continuous Planning', 'Zero-Shot Generalization', 'Real-Time Planning']","This paper presents AirHunt, an aerial object navigation system that efficiently locates open-set objects in outdoor environments by seamlessly fusing Vision-Language Model (VLM) semantic reasoning with continuous path planning, addressing challenges of frequency mismatch and limited 3D scene understanding.",159.9,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12744v1_Vision Language Models for Optimization-Driven Int.pdf,Vision Language Models for Optimization-Driven Intent Processing in Autonomous Networks,"['Tasnim Ahmed', 'Yifan Zhu', 'Salimur Choudhury']",,,"['Intent-Based Networking', 'Optimization', 'Vision-Language Models', 'Code Generation', 'Model Context Protocol']","This paper presents IntentOpt, a benchmark of 85 optimization problems across 17 categories, evaluating four Vision-Language Models (GPT-5-Mini, Claude-Haiku-4.5, Gemini-2.5-Flash, Llama-3.2-11B-Vision) under three prompting strategies on multimodal versus text-only inputs. The evaluation shows that visual parameter extraction reduces execution success, and program-of-thought prompting decreases performance. The results establish baseline capabilities and limitations of current VLMs for optimization code generation within an IBN system.",139.75,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12745v1_A Graph Prompt Fine-Tuning Method for WSN Spatio-T.pdf,Spatio-Temporal Correlation Anomaly Detection for Wireless Sensor Network Data,"['Miao Ye', 'Jing Cui', 'Yuan Huang', 'Yong Wang', 'Qian He', 'Jiwen Zhang']",,1912.07469,"['Anomaly Detection', 'Graph Neural Networks', 'Pre-training', 'Prompt Learning', 'Wireless Sensor Networks']","This paper presents a graph neural network anomaly detection backbone network incorporating spatio-temporal correlation features and a multi-task self-supervised training strategy for WSN data, improving detection performance and generalization ability.",161.34,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12754v1_PAIR-SAFE A Paired-Agent Approach for Runtime Audi.pdf,PAIR-SAFE: A Paired-Agent Approach for Runtime Auditing and Refining,"['Jiwon Kim', 'Violeta J. Rodriguez', 'Dong Whi Yoo', 'Eshwar Chandrasekharan', 'Koustuv Saha']",,2309.16078,"['Large Language Models', 'Mental Health Support', 'Paired-Agent Framework', 'Runtime Auditing', 'Runtime Refinement', 'Motivational Interviewing Treatment Integrity', 'MITI-4', 'Responder Agent', 'Supervisory Judge Agent']","This paper introduces PAIR-SAFE, a paired-agent framework for auditing and refining AI-generated mental health support, integrating a Responder agent with a supervisory Judge agent grounded in the clinically validated Motivational Interviewing Treatment Integrity (MITI-4) framework. The Judge audits each response and provides structured ALLOW or REVISE decisions to guide runtime response refinement, showing significant improvements in key MITI dimensions in simulated counseling interactions.",144.23,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12758v1_VISPA Pluralistic Alignment via Automatic Value Se.pdf,VISPA: Pluralistic Alignment via Automatic Value Selection and Activation,"['Shenyan Zheng', 'Jiayou Zhong', 'Anudeex Shetty', 'Heng Ji', 'Preslav Nakov', 'Usman Naseem']",,2310.16878,"['pluralistic alignment', 'value selection', 'value activation', 'large language models', 'high-stakes domains']","This paper introduces VISPA, a training-free pluralistic alignment framework that enables direct control over value expression by dynamic selection and internal model activation steering. Across extensive empirical studies, VISPA demonstrates performance across various pluralistic alignment modes in healthcare and beyond, showing adaptability with different steering initiations, models, and values.",160.51,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12762v1_Teaching LLMs to Learn Tool Trialing and Execution.pdf,Teaching LLMs to Learn Tool Trialing and Execution through Environment Interaction,"['Xingjie Gao', 'Pengcheng Huang', 'Zhenghao Liu', 'Yukun Yan', 'Shuo Wang', 'Zulong Chen', 'Chen Qian', 'Ge Yu', 'Yu Gu']",,2309.15968,"['Large Language Models', 'External Tools', 'Tool Trialing', 'Trial-and-Execution', 'Environment Interaction', 'Reinforcement Learning']","This paper introduces ToolMaster, a framework that enables Large Language Models to learn tool usage through interaction with the environment, shifting from imitating static solution paths to actively learning through trial and execution. The framework optimizes LLMs for tool planning and invocation, demonstrating superior generalization and robustness across unseen or unfamiliar tools.",156.34,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12781v1_VIRO Robust and Efficient Neuro-Symbolic Reasoning.pdf,VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension,"['Hyejin Park', 'Junhyuk Kwon', 'Suha Kwak', 'Jungseul Ok']",,2306.01515,"['Referring Expression Comprehension', 'Neuro-symbolic Reasoning', 'Verification-Integrated Reasoning Operators', 'Image Region Localization', 'Natural Language Processing']","This paper introduces VIRO, a neuro-symbolic framework that integrates lightweight operator-level verifiers to robustly handle no-target cases in Referring Expression Comprehension tasks, achieving state-of-the-art performance and generalizing to real-world data.",161.38,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12785v1_Distilling Time Series Foundation Models for Effic.pdf,DISTILLING TIME SERIES FOUNDATION MODELS FOR EFFICIENT FORECASTING,"['Yuqi Li', 'Kuiye Ding', 'Chuanguang Yang', 'Szu-Yu Chen', 'Yingli Tian']",,,"['Time Series Foundation Model', 'Knowledge Distillation', 'Time Series Forecasting']","The paper presents DistilTS, a first distillation framework specifically designed for Time Series Foundation Models (TSFMs), addressing challenges in task difficulty and architecture discrepancy to achieve comparable forecasting performance with reduced parameters and accelerated inference.",161.14,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12804v1_SL-CBM Enhancing Concept Bottleneck Models with Se.pdf,SL-CBM: Enhancing Concept Bottleneck Models with Semantic Locality for Better Interpretability,"['Hanwei Zhang', 'Luo Cheng', 'Rui Wen', 'Yang Zhang', 'Lijun Zhang', 'Holger Hermanns']",,2309.15866,"['explainable AI', 'Concept Bottleneck Models', 'semantic locality', 'saliency maps', 'interpretability', 'spatial explainability']","This paper proposes SL-CBM, a novel extension of Concept Bottleneck Models that enhances locality faithfulness by generating spatially coherent saliency maps at both concept and class levels, improving interpretability and reliability in high-stakes domains.",161.49,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12805v1_SciHorizon-GENE Benchmarking LLM for Life Sciences.pdf,SciHorizon-Gene: Benchmarking LLM for Life Sciences Inference from Gene Knowledge to Functional Understanding,"['Xiaohan Huang', 'Meng Xiao', 'Chuan Qin', 'Qingqing Long', 'Jinmiao Chen', 'Yuanchun Zhou', 'Hengshu Zhu']",https://doi.org/XXXXXXX.XXXXXXX,,"['large language models', 'benchmarking and evaluation', 'genomics']","This paper introduces SciHorizon-Gene, a large-scale gene-centric benchmark designed to evaluate large language models (LLMs) in biomedical research, particularly for tasks involving gene-level knowledge to functional understanding. The benchmark assesses LLMs along four critical perspectives: research attention sensitivity, hallucination tendency, answer completeness, and literature influence, providing insights for model selection and development in knowledge-enhanced biological interpretation.",160.18,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12809v1_Left-Right Symmetry Breaking in CLIP-style Vision-.pdf,Left–Right Symmetry Breaking in CLIP-style Vision-Language Models Trained on Synthetic Spatial-Relation Data,"['Takaki Yamamoto1', 'Chihiro Noguchi 1', 'Toshihiro Tanizawa1']",,2601.07101,"['Vision-Language Models', 'Transformer', 'Contrastive Learning', 'Spatial Understanding', 'Left-Right Symmetry', 'Synthetic Data']","This paper presents a controllable 1D image-text testbed to probe how left-right relational understanding emerges in vision and text encoders trained with a CLIP-style contrastive objective. The authors find that contrastive training learns left-right relations and that label diversity, more than layout diversity, drives generalization. They also show that interactions between positional and token embeddings induce a horizontal attention gradient that breaks left-right symmetry in the encoders.",159.34,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12816v1_Fisher-Orthogonal Projected Natural Gradient Desce.pdf,Fisher-Orthogonal Projected Natural Gradient Descent for Continual Learning,"['Ishir Garg', 'Neel Kolhe', 'Andy Peng', 'Rohan Gopalam']",,2601.06284,"['Continual Learning', 'Natural Gradient Descent', 'Orthogonal Gradient', 'Fisher Information', 'Catastrophic Forgetting']","The paper introduces FOPNG, a geometrically principled optimizer that addresses catastrophic forgetting in continual learning by enforcing orthogonality constraints in the Fisher-Riemannian manifold, rather than Euclidean space. It provides theoretical analysis and practical implementations, demonstrating strong results on various benchmarks.",156.41,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12822v1_MirrorGuard Toward Secure Computer-Use Agents via .pdf,MirrorGuard: Toward Secure Computer-Use Agents via Simulation-to-Real Reasoning Correction,"['Wenqi Zhang', 'Yulin Shen', 'Changyue Jiang', 'Jiarun Dai', 'Geng Hong']",XXXXXXX.XXXXXXX,,"['Computer Use Agents', 'Agent Security', 'Reasoning Correction', 'Simulation', 'Vision-Language Models']","This paper presents MirrorGuard, a defense framework that uses simulation-based training to improve the security of Computer Use Agents (CUAs) in the real world, significantly mitigating security risks without compromising agent utility.",158.49,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12837v1_Cognition spaces natural artificial and hybrid.pdf,"Cognition spaces: natural, artificial, and hybrid","['Ricard Solé', 'Luis F Seoane', 'Jordi Pla-Mauri', 'Michael Timothy Bennett', 'Michael E. Hochberg', 'Michael Levin']",,1904.08990,"['Evolved cognition', 'basal cognition', 'artificial life', 'artificial intelligence', 'synthetic biology', 'morphospace']","This paper proposes a cognition space approach to compare cognitive processes across natural, artificial, and hybrid systems, treating cognition as a graded capacity to sense, process, and act upon information. It introduces and examines three cognition spaces—basal aneural, neural, and human–AI hybrid—and highlights the uneven occupation of these spaces, with clusters of realized systems separated by large unoccupied regions.",141.22,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12842v1_SCULPT Constraint-Guided Pruned MCTS that Carves E.pdf,SCULPT: Constraint-Guided Pruned MCTS that Carves Efficient Paths for Mathematical Reasoning,"['Qitong Fang', 'Haotian Li', 'Xu Wang']",,2310.18016,"['Mathematical Reasoning', 'Large Language Models', 'Monte Carlo Tree Search', 'Constraint-Driven Search', 'Stochastic Exploration']","This paper introduces SCULPT, a constraint-guided approach for Monte Carlo Tree Search (MCTS) that integrates domain-aware scoring into selection, expansion, simulation, and backpropagation, steering the search toward plausible reasoning paths and yielding stable improvements on multiple datasets.",158.46,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12849v1_The Cost of EFX Generalized-Mean Welfare and Compl.pdf,The Cost of EFX: Generalized-Mean Welfare and Complexity Dichotomies with Few Surplus Items,"['Eugene Lim', 'Tzeh Yuan Neoh', 'Nicholas Teh']",,2601.12849,"['EFX', 'envy-freeness', 'generalized-mean welfare', 'NP-hard', 'polynomial-time algorithms', 'price of fairness']","This paper studies the interactions between envy-freeness up to any good (EFX) and generalized-mean welfare, focusing on the setting with few surplus items. It establishes complexity dichotomies for EFX and welfare optimization, and quantifies the welfare loss of enforcing EFX.",155.02,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12856v1_Mining Citywide Dengue Spread Patterns in Singapor.pdf,Mining Citywide Dengue Spread Patterns in Singapore Through Hotspot Dynamics from Open Web Data,"['Liping Huang', 'Gaoxi Xiao', 'Stefan Ma', 'Hechang Chen', 'Shisong Tang', 'Flora Salim']",10.1145/XXXXXX.XXXXXX,,"['Dengue Cases', 'Disease Spreading Pattern', 'Hotpot Dynamics', 'Machine Learning']","This study introduces a novel framework that uncovers and exploits latent transmission links between urban regions, mined directly from publicly available dengue case data, to forecast and verify hotspot status, providing an interpretable explanation for citywide spread and aligning with commuting flows.",157.59,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12879v1_Hierarchical Sparse Circuit Extraction from Billio.pdf,CHEAT_DETECTED,"['Mohammed Mudassir Uddin', 'Shahnawaz Alam', 'Mohammed Kaif Pasha']",,2309.14448,"['Mechanistic interpretability', 'sparse computational graphs', 'circuit discovery', 'transformer architectures', 'causal inference', 'attribution methods', 'hierarchical decomposition']","The proposed Hierarchical Attribution Graph Decomposition (HAGD) framework reduces circuit discovery complexity from O(2^n) exhaustive enumeration to O(n^2 log n) through multi-resolution abstraction hierarchies and differentiable circuit search, integrating cross-layer transcoders for monosemantic feature extraction, graph neural network meta-learning for topology prediction, and causal intervention protocols for validation.",159.5,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12882v1_YOLO26 An Analysis of NMS-Free End to End Framewor.pdf,YOLO26: ANALYSIS OF NMS-FREE END-TO-END FRAMEWORK FOR REAL-TIME OBJECT DETECTION,['Sudip Chakrabarty'],null,2601.12882v1,"['YOLOv26', 'End-to-End Object Detection', 'NMS-Free', 'MuSGD', 'ProgLoss', 'Real-Time Computer Vision', 'You Only Look Once']","This paper analyzes YOLO26, a framework that eliminates Non-Maximum Suppression (NMS) in favor of a native end-to-end learning strategy, demonstrating superior performance in both inference speed and detection accuracy compared to previous and current state-of-the-art methods.",154.81,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12886v1_Communication Methods in Multi-Agent Reinforcement.pdf,Communication Methods in Multi-Agent Reinforcement Learning,['Christoph Wittner'],,2601.12886,"['Machine learning', 'MARL', 'Communication']","This work provides an overview of communication techniques in multi-agent reinforcement learning, evaluating the strengths and weaknesses of various methods and highlighting the importance of scalable communication methods with low computational overhead.",159.05,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12893v1_AdaNODEs Test Time Adaptation for Time Series Fore.pdf,ADANODES: TEST TIME ADAPTATION FOR TIME SERIES FORECASTING USING NEURAL ODES,"['Ting Dang∗', 'Soumyajit Chatterjee†', 'Hong Jia‡', 'Yu Wu#', 'Flora Salim+', 'Fahim Kawsar♭']",,1912.07469,"['test time adaptation', 'time series forecasting', 'domain adaptation', 'neural odes']","This paper presents AdaNODEs, an innovative source-free test time adaptation method tailored for time series forecasting. By leveraging Neural Ordinary Differential Equations (NODEs), it proposes a novel adaptation framework that accommodates distribution shifts in time series data and innovatively proposes a new loss function for TTA tasks. AdaNODEs only requires updating limited model parameters, showing effectiveness in capturing temporal dependencies while avoiding significant memory usage.",159.28,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12904v1_From Prefix Cache to Fusion RAG Cache Accelerating.pdf,From Prefix Cache to Fusion RAG Cache: Accelerating LLM Inference in Retrieval-Augmented Generation,"['Jiaha Wang', 'Wei Yu Xie', 'Ming Xing Zhang', 'Boxing Zhang', 'Jianwei Dong', 'Yuening Zhu', 'Chen Lin', 'Jinqi Tang', 'Yaochen Han', 'Zhiyuan Ai', 'Xianglin Chen', 'Yongwei Wu', 'Congfeng Jiang']",10.1145/3786655,2601.1290,"['Large Language Models', 'Retrieval-Augmented Generation', 'Prefix Cache', 'Fusion RAG Cache', 'Inference Acceleration', 'Natural Language Processing']","This paper proposes FusionRAG, a novel inference framework that optimizes both the preprocessing and reprocessing stages of Retrieval-Augmented Generation (RAG) to improve generation quality and efficiency, achieving up to 70% higher normalized-F1 scores and reducing Time to First Token (TTFT) by 2.66-9.39× compared to previous state-of-the-art solutions.",158.18,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12910v1_SciCoQA Quality Assurance for Scientific Paper--Co.pdf,SCICOQA: Quality Assurance for Scientific Paper–Code Alignment,"['Tim Baumgärtner', 'Iryna Gurevych']",,2309.14868,"['SCICOQA', 'scientific paper', 'code alignment', 'reproducibility', 'GitHub issues', 'reproducibility crisis', 'AI', 'Physics', 'Quantitative Biology']","This paper presents SCICOQA, a dataset for detecting discrepancies between scientific papers and their codebases, aiming to ensure faithful implementations. The dataset includes 611 discrepancies, with 81 real and 530 synthetic. Evaluation of 21 language models highlights the difficulty of SCICOQA, particularly for instances involving omitted paper details, long-context inputs, and data outside the models' pre-training corpus.",142.79,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12912v1_Human Emotion Verification by Action Languages via.pdf,Human Emotion Verification by Action Languages via Answer Set Programming,"['ANDREAS BRÖNNSTRÖM', 'JUAN CARLOS NIEVES']",10.1017/xxxxx,2601.12912,"['Action Languages', 'Answer Set Programming', 'Theory of Mind']","This paper introduces the action language C-MT (Mind Transition Language), built on answer set programming and transition systems, to represent human mental states in response to observable actions. It formalizes mental states as multi-dimensional configurations and extends the language with causal rules to model valid transitions between mental states, enabling controlled reasoning about the dynamic evolution of human mental states.",156.82,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12913v1_Actionable Interpretability Must Be Defined in Ter.pdf,Position: Actionable Interpretability Must Be Defined in Terms of Symmetries,"['Pietro Barbiero', 'Mateo Espinosa Zarlenga', 'Francesco Giannini', 'Alberto Termine', 'Mateja Jamnik', 'Giuseppe Marra']",,2309.14484,"['interpretability', 'symmetries', 'AI', 'inference', 'equivariance', 'information invariance', 'concept-closure invariance', 'structural invariance']","This paper argues that interpretability research in Artificial Intelligence is fundamentally ill-posed due to existing definitions failing to provide formal principles for concrete modelling and inferential rules. It posits that for a definition of interpretability to be actionable, it must be given in terms of symmetries, proposing four symmetries that can motivate core interpretability properties, characterize the class of interpretable models, and derive a unified formulation of interpretable inference as a form of Bayesian inversions.",160.61,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12922v1_Your Privacy Depends on Others Collusion Vulnerabi.pdf,Your Privacy Depends on Others: Collusion Vulnerabilities in Individual Differential Privacy,"['Johannes Kaiser', 'Alexander Ziller', 'Eleni Triantafillou', 'Daniel Rückert', 'Georgios Kaissis']",,,"['differential privacy', 'individual differential privacy', 'excess risk', 'membership inference']","This paper reveals a previously overlooked vulnerability in sampling-based Individual Differential Privacy (iDP) mechanisms, showing that an individual's privacy risk is not solely governed by their own privacy budget but critically depends on the privacy choices of all other data contributors. The authors demonstrate empirically that certain distributions of privacy preferences can unintentionally inflate the privacy risk of individuals, even when their formal guarantees are met. They propose (εi, δi, ∆)-iDP, a privacy contract that uses ∆-divergences to provide users with a hard upper bound on their excess vulnerability, while offering flexibility to mechanism design.",157.81,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12925v1_ForeDiffusion Foresight-Conditioned Diffusion Poli.pdf,ForeDiffusion: Foresight-Conditioned Diffusion Policy via Future View Construction for Robot Manipulation,"['Weize Xie', 'Yi Ding', 'Ying He', 'Leilei Wang', 'Binwen Bai', 'Zheyi Zhao', 'Chenyang Wang', 'F. Richard Yu']",,2304.13986,"['Diffusion Models', 'Robot Manipulation', 'Foresight', 'Future View', 'Policy Optimization', 'Grasping']","This paper proposes ForeDiffusion, a diffusion-based policy for robot manipulation that incorporates future view predictions to improve trajectory correction and overall task success rate, significantly outperforming existing diffusion methods in complex tasks.",158.46,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12929v1_Membership Inference Test Auditing Training Data i.pdf,Membership Inference Test: Auditing Training Data in Object Classification Models,"['Gonzalo Mancera', 'Daniel DeAlcala', 'Aythami Morales', 'Ruben Tolosana', 'Julian Fierrez']",,,"['Membership Inference', 'Object Classification', 'Training Data Auditing', 'AI Ethics', 'Artificial Intelligence']","This research analyzes the performance of Membership Inference Tests (MINT) in object recognition, proposing and developing architectures tailored for MINT models to optimize data utilization and efficiency. Experiments involving object detection, embedding extraction, and MINT modules were conducted in three public databases, achieving precision rates between 70% and 80% based on the depth of the detection module layer.",159.49,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12931v1_Online Continual Learning for Time Series a Natura.pdf,ONLINE CONTINUOUS LEARNING FOR TIMESERIES: A NATURAL SCORE-DRIVEN APPROACH,"['Edoardo Urettini', 'Daniele Atzeni', 'Ioanna-Yvonni Tsaknaki', 'Antonio Carta']",,2309.15894,"['online continual learning', 'time series forecasting', 'natural gradient descent', 'robust optimization', 'replay buffer', 'dynamic scale heuristic']","This paper aims to strengthen the theoretical and practical connections between time series methods and online continual learning (OCL) by redefining neural network optimization as a parameter filtering problem, introducing a robust optimizer, and demonstrating improved forecasting performance through empirical results.",158.58,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12937v1_On the Evidentiary Limits of Membership Inference .pdf,On the Evidentiary Limits of Membership Inference for Copyright Auditing,"['Murat Bilgehan Ertan', 'Emirhan Böge', 'Min Chen', 'Kaleel Mahmood', 'Marten van Dijk']",,,"['Membership inference', 'Copyright auditing', 'Large language models', 'Fine-tuning', 'Adversarial attacks']","This paper investigates the reliability of membership inference attacks (MIAs) in auditing whether copyrighted texts were used during training of large language models (LLMs). It introduces SAGE, a paraphrasing framework guided by Sparse Autoencoders (SAEs) that rewrites training data to alter lexical structure while preserving semantic content, and tests its robustness under adversarial conditions. The results indicate that MIAs are brittle and insufficient as a standalone mechanism for copyright auditing of LLMs.",158.23,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12938v1_The Post-Turing Condition Conceptualising Artifici.pdf,The Post-Turing Condition: Conceptualising Artificial Subjectivity and Synthetic Sociality,"['Thorsten Jelinek', 'Patrick Glauner', 'Alvin Wang Graylin', 'Yubao Qiu']",,1909.09632,"['Artificial Intelligence', 'Social Coordination', 'Subjectivity', 'Synthetic Sociality', 'Post-Turing Era']","This paper introduces the PRMO framework to analyze how artificial intelligence increasingly shapes social coordination and meaning formation, proposing Quadrangulation as a design principle to prevent human exclusion from meaning formation in socially embedded AI systems.",156.82,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12939v1_Active Inference-Driven World Modeling for Adaptiv.pdf,ACTIVE INFERENCE-DRIVEN WORLD MODELING FOR ADAPTIVE UA V SW ARM TRAJECTORY DESIGN,"['Kaleem Arshid', 'Ali Krayani', 'Lucio Marcenaro', 'David Martin Gomez', 'Carlo Regazzoni']",,2302.09918,"['Autonomous Systems', 'World Model', 'UA V-Swarm', 'Probabilistic Decision-Making', 'Active-Inference']","This paper proposes an Active Inference-based framework for autonomous trajectory design in UAV swarms, integrating probabilistic reasoning and self-learning to enable distributed mission allocation, route ordering, and motion planning. It trains a hierarchical World Model using expert trajectories generated by a Genetic Algorithm with Repulsion Forces, enabling adaptive responses to dynamic environments during online operation.",155.34,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12946v1_AI-generated data contamination erodes pathologica.pdf,AI-generated data contamination erodes pathological variability and diagnostic reliability,"['Hongyu He', 'Shaowen Xiang', 'Ye Zhang', 'Yingtao Zhu', 'Jin Zhang', 'Hao Deng', 'Emily Alsentzer', 'Qingyu Chen', 'Kun-Hsing Yu', 'Andrew Marmenshall', 'Tingting Chen', 'Srinivas Anumasa', 'Daniel Ebner', 'Dean Ho', 'Kee Yuan Ngiam', 'Ching-Yu Cheng', 'Dianbo Liu']",,,"['AI-generated data', 'pathological variability', 'diagnostic reliability', 'synthetic content', 'medical records', 'clinical variability', 'false reassurance', 'model convergence', 'human verification', 'AI-generated documentation', 'medical image synthesis', 'vision-language reporting']","This study shows that AI-generated data, without mandatory human verification, rapidly erodes pathological variability and diagnostic reliability, leading to false diagnostic confidence and life-threatening pathology being missed, ultimately rendering AI-generated medical documentation clinically useless.",155.35,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.12951v1_Beyond Accuracy Characterizing Code Comprehension .pdf,Beyond Accuracy: Characterizing Code Comprehension Capabilities in (Large) Language Models,"['Felix Mächtle', 'Jan-Niclas Serr', 'Nils Loose', 'Thomas Eisenbarth']",,2309.09556,"['Code Comprehension', 'Model Evaluation and Benchmarking', 'Machine Learning for Software Engineering']","This paper investigates whether Large Language Models' code-comprehension performance aligns with traditional human-centric software metrics or reflects distinct, non-human regularities. Using a large-scale dataset, it correlates model performance with traditional complexity metrics and finds minimal correlation, while shadow models achieve substantially higher predictive performance, capturing complex, partially predictable patterns beyond traditional software measures.",153.75,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13007v1_ArchAgent Scalable Legacy Software Architecture Re.pdf,ARCHAGENT: SCALABLE LEGACY SOFTW ARE ARCHITECTURE RECOVERY WITH LLMS,"['Rusheng Pan★', 'Bingcheng Mao★', 'Tianyi Ma★', 'Zhenhua Ling †']",null,null,"['Software architecture recovery', 'code repository', 'cross-repository context', 'large language models']","ArchAgent is a scalable agent-based framework that combines static analysis, adaptive code segmentation, and LLM-powered synthesis to reconstruct multiview, business-aligned architectures from cross-repository codebases. Evaluations show significant improvements over existing benchmarks, and a real-world case study demonstrates effective recovery of critical business logics from legacy projects.",152.08,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13013v1_HT-GNN Hyper-Temporal Graph Neural Network for Cus.pdf,HT-GNN: Hyper-Temporal Graph Neural Network for Customer Lifetime Value Prediction in Baidu Ads,"['Xiaohui Zhao', 'Xinjian Zhao', 'Jiahui Zhang', 'Guoyu Liu', 'Houzhi Wang', 'Shu Wu']",,,"['Lifetime Value Prediction', 'Advertising Platform', 'Graph Neural Network', 'Hypergraph Supervised Module', 'Transformer-Based Temporal Encoder', 'Task-Adaptive Mixture-of-Experts']","This paper proposes HT-GNN, a Hyper-Temporal Graph Neural Network, to address the challenges of demographic-based targeting and dynamic marketing strategies in customer lifetime value prediction for Baidu Ads. HT-GNN jointly models demographic heterogeneity and temporal dynamics through three key components: a hypergraph-supervised module, a transformer-based temporal encoder with adaptive weighting, and a task-adaptive mixture-of-experts with dynamic prediction towers for multi-horizon LTV forecasting. Experiments on Baidu Ads with 15 million users demonstrate HT-GNN's superior performance across all metrics and prediction horizons.",140.99,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13018v1_Bi-Attention HateXplain  Taking into account the s.pdf,Bi-Attention HateXplain : Taking into account the sequential aspect of data during explainability in a multi-task context,['Ghislain Dorian Tchuente Mondjo'],,1909.06857,"['Multitask learning', 'Deep Learning', 'Hate speech', 'Explainability', 'Bi-Attention']","The paper proposes the BiAtt-BiRNN-HateXplain model to improve the explainability and detection performance of hate speech detection models, addressing the issue of varying predicted attention and providing a more transparent approach compared to existing methods.",155.04,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13020v1_PASs-MoE Mitigating Misaligned Co-drift among Rout.pdf,PASs-MoE: Mitigating Misaligned Co-drift among Router and Experts via Pathway Activation Subspaces for Continual Learning,"['Zhiyan Hou', 'Haiyun Guo', 'Haokai Ma', 'Yandu Sun', 'Yonghui Yang', 'Jinqiao Wang']",10.1002/tao.202300000,2301.00000,"['Continual Learning', 'Multi-modal Language Models', 'Mixture-of-Experts', 'LoRA', 'Misaligned Co-drift', 'Pathway Activation Subspaces']","This paper introduces PASs, a LoRA-induced subspace that reflects which low-rank pathway directions an input activates in each expert, to address Misaligned Co-drift in existing MoE-LoRA methods, which causes the router's preferences to co-drift with experts' adaptation pathways and gradually deviate from early-stage input-expert specialization, leading to forgetting. The authors propose a PASs-based MoE-LoRA method with two components: PAS-guided Reweighting and PAS-aware Rank Stabilization, which consistently outperforms conventional continual learning baselines and MoE-LoRA variants in both accuracy and anti-forgetting without adding parameters.",157.59,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13048v1_Analysis of Long Range Dependency Understanding in.pdf,ANALYSIS OF LONG RANGE DEPENDENCY UNDERSTANDING IN STATE SPACE MODELS,"['Srividya Ravikumar', 'Abhinav Anand', 'Shweta V erma', 'Mira Mezini']",,1911.05369,"['Structured state-space models', 'interpretability', 'vulnerability detection']","This work presents a systematic kernel interpretability study of the diagonalized state-space model (S4D) trained on a real-world task (vulnerability detection in source code). Through time and frequency domain analysis, it shows that the long-range modeling capability of S4D varies significantly under different model architectures, affecting model performance.",161.55,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13054v1_TinyML-Enabled IoT for Sustainable Precision Irrig.pdf,TinyML-Enabled IoT for Sustainable Precision Irrigation,"['Kamogelo Taueatsoala', 'Caitlyn Daniels', 'Angelina J. Ramsunar', 'Petrus Bronkhorst', 'Absalom E. Ezugwu']",,,"['TinyML', 'edge computing', 'Internet of Things', 'precision agriculture', 'smart irrigation', 'sustainable water management', 'embedded machine learning', 'resource-constrained systems']","This paper presents a novel, edge-first IoT framework integrating Tiny Machine Learning (TinyML) for intelligent, offline-capable precision irrigation, leveraging low-cost hardware and sensors to enable autonomous decision-making without cloud dependency, and demonstrating significant water usage reduction and scalability in resource-constrained rural settings.",161.54,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13060v1_MagicGUI-RMS A Multi-Agent Reward Model System for.pdf,MAGICGUI-RMS: A MULTI-AGENTREWARDMODELSYSTEM FORSELF-EVOLVINGGUI AGENTS VIAAUTOMATEDFEEDBACKREFLUX,"['Zecheng Li∗', 'Zhihui Cao ∗ †', 'Wenke Huang', 'Yudong Zhang', 'Keying Qi', 'Rui Wang', 'Zeyu Zheng', 'Jian Zhao', 'Hao Zhu', 'Hengxin Wu', 'Yuran Wang', 'Guitao Fan', 'Guokun Wu', 'Yicong Liu', 'Zhilin Gao', 'Haikun Xu', 'He Yang', 'Minqi Xiang', 'Xingyu Liu †', 'Zuojian Wang †']",,2412.08977,"['GUI agents', 'multi-agent reward model', 'automated feedback', 'self-evolving learning', 'reward learning', 'graphical user interface', 'adaptive interaction', 'reliable task execution', 'automated data-reflux', 'fine-grained action assessment', 'heterogeneous GUI tasks', 'reward-based adaptation']","MagicGUI-RMS is a multi-agent reward model system designed to address the challenges of automating the evaluation of agent trajectories and generating high-quality training data at scale. It integrates a Domain-Specific Reward Model (DS-RM) with a General-Purpose Reward Model (GP-RM) to deliver adaptive trajectory evaluation, corrective feedback, and self-evolving learning capabilities, enhancing task accuracy and behavioral robustness.",156.21,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13075v1_METIS Mentoring Engine for Thoughtful Inquiry  Sol.pdf,METIS: Mentoring Engine for Thoughtful Inquiry & Solutions,"['Abhinav Rajeev Kumar', 'Dhruv Trehan', 'Paras Chopra']",,,"['mentoring', 'AI', 'research', 'undergraduate', 'paper', 'literature search', 'methodology', 'stage-aware']","This paper presents METIS, an AI research mentor designed to guide undergraduate students from initial ideas to publishable conference papers. It evaluates METIS against GPT-5 and Claude Sonnet 4.5, showing that METIS performs better in single-turn judgments and multi-turn tutoring, with higher student scores and better final quality in multi-turn sessions.",156.93,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13111v1_CORE-T COherent REtrieval of Tables for Text-to-SQ.pdf,CORE-T: COherent REtrieval of Tables for Text-to-SQL,"['Hassan Soliman', 'Vivek Gupta', 'Dan Roth', 'Iryna Gurevych']",,2601.13111,"['text-to-SQL', 'table retrieval', 'open-book', 'heterogeneous tables', 'LLM-generated metadata', 'join-aware', 'multi-table execution']","CORE-T is a scalable, training-free framework that enriches tables with LLM-generated purpose metadata and pre-computes a lightweight table-compatibility cache. It improves table-selection F1 by up to 22.7 points and multi-table execution accuracy by up to 6.9 points, using 4–5× fewer tokens than LLM-intensive baselines.",159.6,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13114v1_IntAgent NWDAF-Based Intent LLM Agent Towards Adva.pdf,IntAgent: NWDAF-Based Intent LLM Agent,"['Abdelrahman Soliman', 'Ahmed Refaey', 'Aiman Erbad', 'Amr Mohamed']",,,"['Intent-based networks', 'NWDAF', 'Large Language Models', 'Intelligent Networks', 'Next Generation Networks', 'Artificial Intelligence', 'Machine Learning', 'Core Network', 'Closed Loop']","This work introduces IntAgent, an intelligent intent LLM agent that integrates NWDAF analytics and tools to fulfill the network operator's intents. Unlike previous approaches, it develops an intent tools engine directly within the NWDAF analytics engine, allowing the agent to utilize live network analytics to inform its reasoning and tool selection.",159.8,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13122v1_Responsible AI for General-Purpose Systems Overvie.pdf,"Responsible AI for General-Purpose Systems: Overview, Challenges, and A Path Forward","['Gourab K. Patro', 'Himanshi Agrawal', 'Himanshu Gharat', 'Supriya Panigrahi', 'Nim Sherpa', 'Vishal Vaddina', 'Dagnachew Birru']",null,2601.13122,"['Responsible AI', 'General-Purpose AI', 'Large Language Models', 'Diffusion Models', 'Multimodal Large Language Models', 'Hallucinations', 'Toxicity', 'Stereotypes', 'Degree of Freedom', 'AI Alignment', 'Retrieval-augmented Generation', 'Reasoning Enhancements']","This paper reviews the risks and vulnerabilities of modern general-purpose AI systems, comparing them to traditional task-specific systems, and proposes new desiderata for responsible AI (RAI) in future general-purpose AI systems.",154.07,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13142v1_TVWorld Foundations for Remote-Control TV Agents.pdf,TVWorld: Foundations for Remote-Control TV Agents,"['Zhantao Ma', 'Quanfeng Lu', 'Shuai Zhong', 'Ping Luo', 'Michael K. Ng']",,2309.14895,"['Large Vision-Language Models', 'Remote-Control TV', 'TV Navigation', 'Graph-Based Abstraction', 'Focus-Awareness', 'Topology-Awareness', 'TV Use Agents']","This paper introduces TVWorld, an offline graph-based abstraction of real-world TV navigation, which enables reproducible and deployment-free evaluation. It derives two complementary benchmarks for assessing TV-use capabilities and proposes a topology-aware training framework to develop a foundation model specialized for TV navigation, achieving state-of-the-art performance.",158.63,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13160v1_Training instability in deep learning follows low-.pdf,Training instability in deep learning follows low-dimensional dynamical principles,"['Zhipeng Zhang', 'Zhenjie Yao', 'Kai Li', 'Lei Yang']",10.48550/arxiv.2601.13160,2601.13160,"['training instability', 'deep learning', 'reinforcement learning', 'large language models', 'dynamical systems']","This paper proposes a unified dynamical perspective to characterize training stability in deep learning systems, organized along four interacting dimensions: optimization, environmental/data, parametric, and learning-signal stability. It identifies three recurring regularities across reinforcement learning and large language model training, establishing training stability as a measurable and comparable dynamical property of learning systems.",150.95,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13166v1_From 100000 images to winning the first brain MRI .pdf,"From 100,000+ images to winning the first brain MRI foundation model challenges","['Pedro M. Gordaliza', 'Jaume Banus', 'Benoît Gérin', 'Maxence Wynen', 'Nataliia Molchanova', 'Jonas Richiardi', 'Meritxell Bach Cuadra']",,,"['medical image analysis', 'foundation models', '3D brain MRI', 'self-supervised learning', 'U-Net CNN', 'anatomical priors', 'neuroimaging domain knowledge', 'brain MRI challenges', 'brain MRI foundation model challenges', 'MICCAI 2025']","Our solution ranked first in tracks of both contests, relying on a U-Net CNN architecture combined with strategies leveraging anatomical priors and neuroimaging domain knowledge. Notably, our models trained 1-2 orders of magnitude faster and were 10× smaller than competing transformer-based approaches.",157.68,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13186v1_Prompt Injection Mitigation with Agentic AI Nested.pdf,"Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching","['Diego Gosmar', 'Deborah A. Dahl']",,2601.13186v1,"['Prompt Injection', 'Large Language Models', 'Multi-Agent Systems', 'Semantic Caching', 'Nested Learning', 'AI Sustainability']","This paper extends the evaluation framework for mitigating prompt injection attacks in large language models, introducing semantic similarity-based caching and a dedicated fourth-agent rule-based evaluator, to investigate how defense effectiveness interacts with transparency in a Nested Learning architecture.",152.86,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13187v1_Scientific production in the era of Large Language.pdf,Scientific production in the era of Large Language Models,"['Keigo Kusumegi', 'Xinyu Yang', 'Paul Ginsparg', 'Mathijs de Vaan', 'Toby Stuart', 'Yian Yin']",10.1126/science.adw3000,,"['Large Language Models', 'Scientific Production', 'Paper Quality', 'Writing Complexity', 'Scientific Research', 'Peer Review', 'Access to Scientific Documents', 'Citation Patterns']","This study analyzes the impact of Large Language Models on scientific research, examining changes in paper production, writing complexity, and citation patterns across multiple datasets, and highlights the need for a new evaluation framework.",131.9,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13197v1_Diffusion-Driven Synthetic Tabular Data Generation.pdf,Diffusion-Driven Synthetic Tabular Data Generation for Enhanced DoS/DDoS Attack Classification,"['Aravind B', 'Anirud R.S.', 'Sai Surya Teja N', 'Bala Subrahmanya Sriranga Navaneeth A', 'Karthika R', 'Mohankumar N']",,,"['Network intrusion detection', 'Tabular diffusion models', 'Class imbalance', 'DDoS attack detection', 'Data augmentation', 'IDS2017']","This paper addresses class imbalance in network intrusion detection using Tabular Denoising Diffusion Probability Models (TabDDPM) for data augmentation. It synthesizes high-fidelity minority-class samples from the CIC-IDS2017 dataset through iterative denoising processes, enabling an ANN classifier to achieve near-perfect recall on previously underrepresented attack classes.",139.48,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13206v1_Real-Time Deadlines Reveal Temporal Awareness Fail.pdf,Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues,"['Neil Sehgal', 'Sharath Chandra Guntuku', 'Lyle Ungar']",,2309.14766,"['Large Language Models', 'LLMs', 'Temporal Awareness', 'Strategic Dialogues', 'Real-Time Deadlines', 'Negotiations', 'Auctions', 'Continuous Time', 'Discrete Turns']","This study investigates how Large Language Models (LLMs) adjust their behavior in time-sensitive settings, using simulated negotiations between paired agents under strict deadlines. The results show that LLMs struggle to internally track elapsed time, leading to higher deal closure rates and offer acceptances in a time-aware condition compared to a control condition, indicating a systematic lack of temporal awareness that will constrain LLM deployment in many time-sensitive applications.",155.52,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13217v1_Beyond Single-shot Writing Deep Research Agents ar.pdf,Beyond Single-shot Writing: Deep Research Agents are Unreliable at Multi-turn Report Revision,"['Bingsen Chen1,2,∗', 'Boyan Li3,†', 'Ping Nie5', 'Yuyu Zhang6', 'Xi Ye3,4', 'Chen Zhao1,2,‡']",,2601.13217,"['Deep Research Agents', 'Multi-turn Report Revision', 'Report Generation', 'Human Research Process', 'User Feedback']","This paper introduces MRDRE, an evaluation suite for Deep Research Agents (DRAs) that establishes multi-turn report revision as a new evaluation axis. It analyzes five diverse DRAs and reveals a critical limitation: while agents can address most user feedback, they also regress on 16–27% of previously covered content and citation quality. The authors show that these issues are not easily resolvable through inference-time fixes.",157.06,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13222v1_Incorporating QA Nuggets into Retrieval-Augmented .pdf,Incorporating Q&A Nuggets into Retrieval-Augmented Generation,"['Laura Dietz', 'Bryan Li', 'Gabrielle Liu', 'Jia-Huei Ju', 'Eugene Yang', 'Dawn Lawrie', 'William Walden', 'James Mayfield']",,2601.13222v1,"['RAG', 'LLM judge', 'nugget-based evaluation']","This paper presents Crucible, a Nugget-Augmented Generation System that integrates Q&A nuggets from retrieved documents to guide extraction, selection, and report generation, outperforming Ginger in nugget recall, density, and citation grounding on the TREC NeuCLIR 2024 collection.",156.07,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13227v1_Insider Knowledge How Much Can RAG Systems Gain fr.pdf,Insider Knowledge: How Much Can RAG Systems Gain from Evaluation Secrets?,"['Laura Dietz', 'Bryan Li', 'Eugene Yang', 'Dawn Lawrie', 'William Walden', 'James Mayfield']",null,2601.13227,"['Retrieval-augmented generation', 'LLM judge', 'Nugget evaluation']","This paper investigates the risk of faulty measurements in RAG systems when evaluation is optimized using LLM judges, and demonstrates that near-perfect evaluation scores can be achieved when elements of the evaluation are leaked or can be predicted. The authors highlight the importance of blind evaluation settings and methodological diversity to guard against mistaking metric overfitting for genuine system progress.",160.46,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13228v1_Autoregressive Models Rival Diffusion Models at AN.pdf,Any-order Any-subset Autoregressive Modeling (A3): A Unified Approach for Diffusion and Autoregressive Language Models,"['Tianqi Du', 'Lizhe Fang', 'Weijie Yang', 'Chenheng Zhang', 'Zeming Wei', 'Yifei Wang', 'Yisen Wang']",,2312.09759,"['Diffusion Models', 'Autoregressive Models', 'Language Models', 'Any-Order Generation', 'Bidirectional Conditioning', 'Infilling', 'Rewriting', 'Self-Correction']","This paper presents Any-order Any-subset Autoregressive (A3) modeling, a unified framework that extends autoregressive models to support any-order generation and bidirectional conditioning, while inheriting the flexibility of diffusion models for parallel and bidirectional generation. Experiments demonstrate that A3 outperforms diffusion-based models in tasks such as question answering and story infilling, maintaining flexible decoding.",159.66,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13233v1_RAG A Random-Forest-Based Generative Design Framew.pdf,RAG: A Random-Forest-Based Generative Design Framework for Uncertainty-Aware Design of Metamaterials with Complex Functional Response Requirements,"['Bolin Chen', 'Dex Doksoo Lee', 'Wei “Wayne” Chen', 'Wei Chen']",,2601.13233,"['Random forest', 'Generative design', 'Functional response', 'Uncertainty quantification']","This paper introduces a RAndom-forest-based Generative approach (RAG) to address the challenges of inverse design for metamaterials with complex functional response requirements, focusing on acoustic and mechanical metamaterials. RAG leverages the small-data compatibility of random forests and enables data-efficient predictions of high-dimensional functional responses, estimating the likelihood of solutions conditioned on design requirements.",155.9,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13235v1_RubRIX Rubric-Driven Risk Mitigation in Caregiver-.pdf,RubRIX: Rubric-Driven Risk Mitigation in Caregiver-AI Interactions,"['Drishti Goel', 'Jeongah Lee', 'Qiuyue Joy Zhong', 'Violeta J. Rodriguez', 'Daniel S. Brown', 'Ravi Karkar', 'Dong Whi Yoo', 'Koustuv Saha']",,2310.14998,"['Caregiving', 'AI', 'Risk Mitigation', 'Ethics of Care', 'Large Language Models', 'Rubric-Driven Evaluation']","This paper introduces RubRIX, a rubric-driven framework for evaluating risks in Large Language Model (LLM) caregiving responses, grounded in the Elements of an Ethic of Care. It evaluates six state-of-the-art LLMs on over 20,000 caregiver queries and demonstrates that rubric-guided refinement consistently reduces risk components by 45-98% across models.",160.21,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13236v1_Pixelwise Uncertainty Quantification of Accelerate.pdf,Pixelwise Uncertainty Quantiﬁcation of Accelerated MRI Reconstruction,"['Ilias I. Giannakopoulos', 'Lokesh B Gautham Muthukumar', 'Yvonne W. Lui', 'Riccardo Lattanzi']",,,"['Conformal Prediction', 'Magnetic Resonance Imaging', 'Parallel Imaging', 'Quantile Regression', 'Uncertainty Quantification']","This work introduces a general framework for pixel-wise uncertainty quantification in parallel MRI reconstructions, enabling automatic identification of unreliable regions without access to ground-truth reference images. The method integrates conformal quantile regression with image reconstruction methods to estimate statistically rigorous pixel-wise uncertainty intervals, and is evaluated on Cartesian undersampled brain and knee data from the fastMRI dataset.",161.33,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13238v1_A Semantic Decoupling-Based Two-Stage Rainy-Day At.pdf,A Semantic Decoupling–Based Two-Stage Rainy-Day Attack for Revealing Weather Robustness Deficiencies in Vision–Language Models,"['Chengyin Hu', 'Xiang Chen', 'Zhe Jia', 'Weiwen Shi', 'Fengyu Zhang', 'Jiujiang Guo', 'Yiwei Wei']",,2309.14228,"['Vision-Language Models', 'Rainy-Day Attack', 'Weather Robustness', 'Semantic Decoupling', 'Two-Stage Perturbation', 'Cross-Modal Semantic Alignment', 'Real-World Weather', 'Safety and Reliability Risks']","This paper introduces an adversarial framework to attack Vision-Language Models (VLMs) under rainy conditions, using a two-stage, parameterized perturbation model based on semantic decoupling. The framework analyzes rain-induced shifts in decision-making, generating perturbations that are both physically grounded and interpretable, and demonstrates that even physically plausible, highly constrained weather perturbations can induce substantial semantic misalignment in mainstream VLMs, posing potential safety and reliability risks in real-world deployment.",157.66,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13240v1_KOCO-BENCH Can Large Language Models Leverage Doma.pdf,KOCO-BENCH: Can Large Language Models Leverage Domain Knowledge in Software Development?,"['Xue Jiang', 'Jiaru Qian', 'Xianjie Shi', 'Chenjie Li', 'Hao Zhu', 'Ziyu Wang', 'Jielun Zhang', 'Zheyu Zhao', 'Kechi Zhang', 'Jia Li', 'Wenpin Jiao', 'Zhi Jin', 'Ge Li', 'Yihong Dong']",,2601.00000,"['Large Language Models', 'Software Engineering', 'Domain Knowledge', 'LLM4SE', 'Domain-Specific Development']","This paper presents KOCO-BENCH, a novel benchmark designed to evaluate domain specialization methods in real-world software development. KOCO-BENCH includes 6 emerging domains with 11 software frameworks and 25 projects, featuring curated knowledge corpora and multi-granularity evaluation tasks. The authors reveal that state-of-the-art LLMs struggle with KOCO-BENCH, highlighting the need for more effective domain specialization methods.",156.91,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13247v1_Aligning Agentic World Models via Knowledgeable Ex.pdf,Aligning Agentic World Models via Knowledgeable Experience Learning,"['Baochang Ren', 'Yunzhi Yao', 'Rui Sun', 'Shuofei Qiao', 'Ningyu Zhang', 'Huajun Chen']",null,2601.13247,"['Large Language Models', 'World Models', 'Agentic World Model', 'Process Experience', 'Goal Experience', 'Physical Hallucination', 'Knowledgeable Experience Learning']","This paper introduces WorldMind, a framework that autonomously constructs a symbolic World Knowledge Repository by synthesizing environmental feedback. It unifies Process Experience to enforce physical feasibility via prediction errors and Goal Experience to guide task optimality through successful trajectories, achieving superior performance compared to baselines with remarkable cross-model and cross-environment transferability.",159.58,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13260v1_Stop Taking Tokenizers for Granted They Are Core D.pdf,Stop Taking Tokenizers for Granted: They Are Core Design Decisions in Large Language Models,"['Sawsan Alqahtani†♠*', 'Mir Tafseer Nayeem♣*', 'Md Tahmid Rahman Laskar♦♡', 'Tasnim Mohiuddin♢', 'M Saiful Bari♥']",,2310.14458,"['Large Language Models', 'Tokenization', 'Subword Tokenization', 'Byte Pair Encoding', 'Model Design', 'Fairness', 'Efficiency', 'Adaptability']","This paper reframes tokenization as a core modeling decision rather than a pre-processing step, arguing for a context-aware framework that integrates tokenizer and model co-design, guided by linguistic, domain, and deployment considerations. Standardized evaluation and transparent reporting are essential to make tokenization choices accountable and comparable.",159.69,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13262v1_CURE-Med Curriculum-Informed Reinforcement Learnin.pdf,CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning,"['Eric Onyame∗', 'Akash Ghosh∗', 'Subhadip Baidya', 'Sriparna Saha', 'Xiuying Chen', 'Chirag Agarwal']",,1901.02860,"['Curriculum-Informed Reinforcement Learning', 'Multilingual Medical Reasoning', 'Open-Ended Reasoning', 'Medical QA', 'Language Fidelity', 'Logical Accuracy', 'Code-Switching', 'Group Relative Policy Optimization']","This paper introduces CURE-MED, a curriculum-informed reinforcement learning framework for multilingual medical reasoning, which outperforms strong baselines across thirteen languages, achieving high levels of language consistency and logical correctness.",160.2,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13268v1_Improving the Safety and Trustworthiness of Medica.pdf,Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops,"['Zainab Ghafoor', 'Md Shafiqul Islam', 'Koushik Howlader', 'Md Rasel Khondokar', 'Tanusree Bhattacharjee', 'Sayantan Chakraborty', 'Adrito Roy', 'Ushashi Bhattacharjee', 'Tirtho Roy']",,,"['Medical AI', 'Large Language Models', 'Multi-Agent Systems', 'Ethical Compliance', 'Safety Assessment']","This work introduces a multi-agent refinement framework to enhance the safety and reliability of medical Large Language Models (LLMs) through structured, iterative alignment. The system combines two generative models and two evaluation agents to assess responses using ethical principles and a safety risk assessment protocol, achieving significant reductions in ethical violations and risk behavior.",159.91,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13286v1_AI Skills Improve Job Prospects Causal Evidence fr.pdf,AI Skills Improve Job Prospects: Causal Evidence from a Hiring Experiment,"['Fabian Stephany', 'Ole Teutloff', 'Angelo Leone']",,,"['Artificial Intelligence', 'labour markets', 'Signaling Theory', 'Hiring', 'Skills', 'Experiment']","This study examines whether AI skills serve as a positive hiring signal and whether they can offset conventional disadvantages such as older age or lower formal education. Using an experimental survey with 1,700 recruiters from the United Kingdom and the United States, the findings demonstrate that AI skills function as a powerful hiring signal and can mitigate traditional labor market disadvantages, with implications for workers' skill acquisition strategies and firms' recruitment practices.",160.13,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13295v1_CooperBench Why Coding Agents Cannot be Your Teamm.pdf,CooperBench: Why Coding Agents Cannot be Your Teammates Yet,"['Arpandeep Khatua', 'Hao Zhu', 'Peter Tran', 'Arya Prabhudesai', 'Frederic Sadrieh', 'Johann K. Lieberwirth', 'Xinkai Yu', 'Yicheng Fu', 'Michael J. Ryan', 'Jiaxin Pei', 'Diyi Yang']",,2026-1-21,"['CooperBench', 'Coding Agents', 'Team Conflicts', 'Coordination', 'Real-Time Communication', 'Expert-Writer Features', 'Open-Source Repositories', 'Programming Languages']","CooperBench evaluates over 600 collaborative coding tasks across 12 libraries in 4 programming languages, demonstrating that current coding agents achieve significantly lower success rates when working together compared to performing tasks individually. The study highlights communication issues, commitment deviations, and incorrect expectations among agents, suggesting a need for improved coordination capabilities.",143.51,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13317v1_Paid Voices vs. Public Feeds Interpretable Cross-P.pdf,Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme Modeling of Climate Discourse,"['Samantha Sudhoff*', 'Pranav Perumal', 'Zhaoqing Wu', 'Tunazzina Islam*']",,,"['Climate discourse', 'Paid advertising', 'Public social media', 'Thematic discovery', 'Semantic similarity', 'Large language models', 'Climate communication', 'Incentive structures', 'Political influence', 'Public understanding']","This work presents a comparative analysis of climate discourse across paid advertisements on Meta and public posts on Bluesky, introducing an interpretable thematic discovery framework that clusters texts by semantic similarity and leverages large language models to generate concise theme labels. The study evaluates the quality of induced themes and examines systematic differences between paid climate messaging and public climate discourse, focusing on political events.",142.2,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13327v1_PepEDiff Zero-Shot Peptide Binder Design via Prote.pdf,PepEDiﬀ: Zero-Shot Peptide Binder Design via Protein Embedding Diffusion,"['Po-Yu Liang', 'Tibo Duran', 'Jun Bai']",,2601.13327v1,"['Deep Learning', 'Drug Discovery', 'Protein Design']","PepEDiﬀ is a novel peptide binder generator that designs binding sequences directly in a continuous latent space derived from a pretrained protein embedding model, improving structural and sequence diversity without relying on intermediate structure prediction, and outperforming state-of-the-art approaches in benchmark tests and the TIGIT case study.",152.25,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13348v1_The AI Genie Phenomenon and Three Types of AI Chat.pdf,"The AI Genie Phenomenon and Three Types of AI Chatbot Addiction: Escapist Roleplays, Pseudosocial Companions, and Epistemic Rabbit Holes","['M. KAREN SHEN', 'Jessica Huang', 'OLIVIA LIANG', 'IG-JAE KIM', 'DONGWOOK YOON']",,,"['AI chatbot', 'Addiction']","This study examines AI chatbot addiction, identifying three distinct types: Escapist Roleplay, Pseudosocial Companion, and Epistemic Rabbit Hole, and discusses the addictive potential of AI chatbots, including the 'AI Genie' phenomenon and the involvement of sexual content in some cases.",161.35,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13352v1_LLM-as-RNN A Recurrent Language Model for Memory U.pdf,LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction,"['Yuxing Lu', 'J. Ben Tamo', 'Weichen Zhao', 'Nan Sun', 'Yishan Zhong', 'Wenqi Shi', 'Jinzhuo Wang', 'May D. Wang']",,2312.09469,"['Language Models', 'Recurrent Neural Networks', 'Long Short-Term Memory', 'Transformer Architecture', 'In-Context Learning', 'Memory Updates', 'Sequence Prediction', 'Healthcare', 'Meteorology', 'Finance']","This paper proposes LLM-as-RNN, an inference-only framework that turns a frozen Large Language Model (LLM) into a recurrent predictor by representing its hidden state as natural-language memory. This state is updated at each timestep via feedback-driven text rewrites, enabling learning without parameter updates. The method significantly outperforms zero-shot, full-history, and MemPrompt baselines on sequential benchmarks in healthcare, meteorology, and finance across different model families.",160.72,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13358v1_The Geometry of Thought How Scale Restructures Rea.pdf,The Geometry of Thought: How Scale Restructures Reasoning in Large Language Models,['Samuel Cyrenius Anderson'],null,2601.13358,"['Large Language Models', 'Neural Scaling Laws', 'Chain-of-Thought', 'Reasoning Tasks', 'Model Parameters', 'Parameter Increase', 'Geometric Reorganizations', 'Domain-Specific Effects', 'Reasoning Process', 'Model Representation']","This paper investigates how scale affects reasoning in large language models, finding that scale restructures reasoning rather than uniformly improving it. It analyzes 25,000+ chain-of-thought trajectories across four domains (Law, Science, Code, Math) and two scales (8B, 70B parameters), revealing that neural scaling laws trigger domain-specific phase transitions rather than uniform capability gains.",144.29,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13376v1_Bounded Minds Generative Machines Envisioning Conv.pdf,"Bounded Minds, Generative Machines","['JIQUN LIU', 'The University of Oklahoma', 'USA']",XXXXXXX,XXXXXXX,"['Bounded Rationality', 'Heuristics', 'Conversational AI', 'GenAI', 'Evaluation']","This article outlines a research pathway grounded in bounded rationality, arguing that conversational AI should be designed to work with human heuristics rather than against them, and identifies key directions for detecting cognitive vulnerability, supporting judgment under uncertainty, and evaluating conversational systems beyond factual accuracy, toward decision quality and cognitive robustness.",155.8,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13383v1_A Lightweight Modular Framework for Constructing A.pdf,"A LIGHTWEIGHTMODULARFRAMEWORK FORCONSTRUCTING AUTONOMOUSAGENTSDRIVEN BYLARGELANGUAGE MODELS: DESIGN, IMPLEMENTATION,ANDAPPLICATIONS IN AGENTFORGE","['A. A. Jafari', 'C. Ozcinar', 'G. Anbarjafari']",,2601.13383,"['Autonomous agents', 'large language models', 'modular architecture', 'natural language processing', 'software framework', 'task automation', 'artificial intelligence', 'open-source software']","This paper presents AgentForge, a lightweight, open-source Python framework designed to democratize the construction of LLM-driven autonomous agents through a principled modular architecture, introducing innovations in skill composition, LLM backend support, and declarative configuration.",159.57,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13385v1_Organ-Aware Attention Improves CT Triage and Class.pdf,Organ-Aware Attention Improves CT Triage and Classification,"['Lavsen Dahal', 'Yubraj Bhandari', 'Geoffrey D. Rubin', 'Joseph Y. Lo']",,2309.15858,"['Computed Tomography', 'CT Triage', 'Classification', 'Vision-Language Models', 'Organ-Masked Attention', 'Organ-Scalar Fusion']","This study presents ORACLE-CT, an encoder-agnostic, organ-aware head that pairs Organ-Masked Attention with Organ-Scalar Fusion, achieving state-of-the-art supervised classification performance across chest and abdomen CT datasets.",161.09,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13392v1_Beyond Memorization Testing LLM Reasoning on Unsee.pdf,Beyond Memorization: Testing LLM Reasoning on Unseen Theory of Computation Tasks,"['Shlok Shelat', 'Jay Raval', 'Souvik Roy', 'Manas Gaur']",,2310.16416,"['Large Language Models', 'Deterministic Finite Automata', 'Theory of Computation', 'Pattern Matching', 'Symbolic Reasoning', 'Formal Language Tasks']","This paper introduces a benchmark for DFA construction from regular languages, comprising factual knowledge questions, seen construction problems, and unseen problems. Models achieve high accuracy on factual questions and seen tasks but struggle with unseen problems, revealing systematic errors in interpreting language constraints and handling Kleene-star semantics. The authors evaluate a three-stage hint protocol but find that errors persist regardless of prompting strategy, highlighting a fundamental gap between LLMs' syntactic plausibility and semantic correctness.",157.04,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13398v1_Can LLMs Compress and Decompress Evaluating Code U.pdf,Can LLMs Compress (and Decompress)? Evaluating Code Understanding and Execution via Invertibility,"['Nickil Maveli', 'Antonio Vergari', 'Shay B. Cohen']",,2311.17036,"['LLMs', 'Code Understanding', 'Execution', 'Invertibility', 'Code-LLMs', 'Robust Reasoning', 'Forward Execution', 'Backward Execution', 'Bijection Fidelity', 'Self-Consistency']","This paper presents ROUNDTRIPCODEEVAL (RTCE), a comprehensive benchmark consisting of four distinct code execution reasoning tasks designed to rigorously test round-trip consistency. The authors evaluate state-of-the-art Code-LLMs using zero-shot prompting, supervised fine-tuning on execution traces, and self-reflection mechanisms, finding that current LLMs struggle with true round-trip consistency, indicating a lack of internal coherence required for trustworthy code reasoning.",160.55,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13400v1_Deep Image Prior with L0 Gradient Regularizer for .pdf,DEEP IMAGE PRIOR WITH L0 GRADIENT REGULARIZER FOR IMAGE SMOOTHING,"['Nhat Thanh Tran', 'Kevin Bui', 'Jack Xin']",,2309.13456,"['image smoothing', 'optimization', 'ADMM', 'deep image prior', 'ℓ 0 gradient']","This paper proposes DIP-ℓ 0, a deep image prior framework that incorporates the ℓ 0 gradient regularizer for high-quality image smoothing without requiring a training dataset. It uses an alternating direction method of multipliers algorithm to minimize the associated loss function, demonstrating superior performance in edge-preserving image smoothing and JPEG artifact removal.",159.89,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13401v1_Reasoning with Pixel-level Precision QVLM Architec.pdf,Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics,"['Peter A. Massih1', 'Eric Cosatto1']",,1901.00936,"['Vision-Language Models', 'Quantitative Spatial Reasoning', 'Satellite Image Analysis', 'Geospatial Analytics', 'Pixel-Level Precision', 'SQuID Dataset']","This paper presents two contributions to address the fundamental limitation of current Vision-Language Models (VLMs) in quantitative spatial reasoning. First, it introduces SQuID, a benchmark dataset of satellite image question-answer pairs with numerical and categorical answers. Second, it proposes QVLM, a code-generation architecture that maintains pixel precision by decoupling language understanding from visual analysis, achieving higher accuracy on quantitative tasks compared to VLMs.",156.39,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13404v1_Local-to-Global Logical Explanations for Deep Visi.pdf,Local-to-Global Logical Explanations for Deep Vision Models,"['Bhavan Vasu', 'Giuseppe Raffa', 'Prasad Tadepalli']",,2601.13404v1,"['Explainable AI', 'Neurosymbolic AI', 'Monotone DNF', 'Deep Learning']","The paper introduces local and global explanation methods for black-box models in deep vision, casting explanations in terms of human-recognizable primitive concepts and maintaining high fidelity and coverage with respect to the models in challenging datasets.",154.29,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13406v1_Integrating Virtual Reality and Large Language Mod.pdf,Integrating Virtual Reality and Large Language Models for Team-Based Non-Technical Skills Training and Evaluation in the Operating Room,"['Jacob Barker', 'Doga Demirel', 'Cullen Jackson', 'Anna Johansson', 'Robbin Miraglia', 'Darian Hoagland', 'Stephanie B. Jones', 'John Mitchell', 'Daniel B. Jones', 'Suvranu De']",,,"['Virtual Reality', 'Large Language Models', 'Non-Technical Skills', 'Operating Room', 'Team Training', 'Simulation']","This paper introduces VORTeX, a multi-user virtual reality platform that integrates immersive team simulation with large language model analytics to train and evaluate communication, decision-making, teamwork, and leadership in surgical professionals during laparoscopic emergencies.",159.45,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13412v1_Using deep learning for predicting cleansing quali.pdf,Using deep learning for predicting cleansing quality of colon capsule endoscopy images,"['Puneet Sharma', 'Kristian Dalsbø Hindberg', 'Benedicte Schelde-Olesen', 'Ulrik Deding', 'Esmaeil S. Nadimi', 'Jan-Matthias Braun']",,2601.13412,"['colon capsule endoscopy', 'deep learning', 'image classification', 'cleansing quality', 'structured pruning', 'explainability']","This study explores the application of deep learning techniques for predicting cleansing quality in colon capsule endoscopy images, using a dataset of 500 images labeled by 14 clinicians and training a ResNet-18 model for classification with significant sparsity and high accuracy, demonstrating the effectiveness of pruning in improving efficiency without compromising performance.",150.41,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13422v1_TrustEnergy A Unified Framework for Accurate and R.pdf,TrustEnergy: A Unified Framework for Accurate and Reliable User-level Energy Usage Prediction,"['Dahai Yu', 'Rongchao Xu', 'Dingyi Zhuang', 'Yuheng Bu', 'Shenhao Wang', 'Guang Wang']",,,"['Energy usage prediction', 'Deep learning', 'Hierarchical spatiotemporal representation', 'Sequential conformalized quantile regression', 'User-level prediction', 'Uncertainty quantification']","This paper proposes a unified framework called TrustEnergy for accurate and reliable user-level energy usage prediction, addressing the limitations of existing approaches that either overlook spatial correlations or fail to scale to individualized prediction.",157.7,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13435v1_A Learnable Wavelet Transformer for Long-Short Equ.pdf,A Learnable Wavelet Transformer for Long-Short Equity Trading and Risk-Adjusted Return Optimization,"['Shuozhe Li', 'Du Cheng', 'Leqi Liu']",,2302.09687,"['Neural wavelet regularization', 'wavelet-transformer network', 'low-guided high-frequency injection', 'return optimization']","This paper introduces WaveLSFormer, a learnable wavelet-based long-short Transformer designed to optimize long-short equity trading strategies. It jointly performs multi-scale decomposition and return-oriented decision learning, achieving superior performance compared to MLP, LSTM, and Transformer backbones on five years of hourly financial data across six industry groups.",159.89,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13437v1_MOSLD-Bench Multilingual Open-Set Learning and Dis.pdf,MOSLD-Bench: Multilingual Open-Set Learning and Discovery,"['Adriana-Valentina Costache', 'Daria-Nicoleta Dragomir', 'Silviu-Florin Gheorghe', 'Eduard Poesina', 'Paul Irofti', 'Radu Tudor Ionescu']",,2309.13246,"['Open-set learning', 'Discovery', 'Multilingual', 'Text categorization', 'Machine learning', 'Distribution shifts']","This paper introduces the first multilingual open-set learning and discovery (MOSLD) benchmark for text categorization, comprising 960K data samples across 12 languages. It proposes a novel framework for the OSLD task, integrating multiple stages to continuously discover and learn new classes, and evaluates various language models.",157.26,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13443v1_Explicit Cognitive Allocation A Principle for Gove.pdf,Explicit Cognitive Allocation: A Principle for Governed and Auditable Inference in Large Language Models,"['Héctor Manuel Manzanilla-Granados', 'Zaira Navarrete-Cazales', 'Miriam Pescador-Rojas', 'Tonahtiu Ramírez-Romero']",,,"['Large Language Models', 'AI-assisted reasoning', 'Cognitive Allocation', 'Epistemic Functions', 'Cognitive Universal Agent (CUA)']","The paper introduces Explicit Cognitive Allocation, a principle for structuring AI-assisted inference through the explicit separation and orchestration of epistemic functions, and evaluates its effects on inference in the agricultural domain, showing improved traceability, epistemic alignment, and exposure of the instrumental landscape compared to baseline LLM inference.",162.95,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13458v1_Labels or Preferences Budget-Constrained Learning .pdf,Labels or Preferences? Budget-Constrained Learning with Human Judgments over AI-Generated Outputs,"['Zihan Dong', 'Ruijia Wu', 'Linjun Zhang']",null,2601.13458,"['Budget-Constrained Learning', 'Human Judgments', 'AI-Generated Outputs', 'Preference-Labeled Data', 'Semi-Parametric Inference', 'Active Learning']","This paper addresses the optimal allocation of a fixed annotation budget between ground-truth labels and pairwise preferences in AI, introducing a novel method called Preference-Calibrated Active Learning (PCAL) that learns the optimal data acquisition strategy and develops a statistically efficient estimator for functionals of the data distribution.",158.55,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13462v1_SpatialBench-UC Uncertainty-Aware Evaluation of Sp.pdf,SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt,['Amine Rostane'],,2601.13462,"['Spatial Evaluation', 'Uncertainty-Aware', 'Text-to-Image Generation', 'Counterfactual Prompts']","Introducing SpatialBench-UC, a reproducible benchmark for evaluating spatial relations in text-to-image models, which includes 200 prompts and enables auditable comparisons across models, reporting PASS rates, coverage, and conditional PASS rates for three baselines.",162.08,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13464v1_Context and Transcripts Improve Detection of Deepf.pdf,Context and Transcripts Improve Detection of Deepfake Audios,"['Chongyang Gao', 'Marco Postiglione', 'Julian Baldwin', 'Natalia Denisenko', 'Isabel Gortner', 'Luke Fosdick', 'Chiara Pulice', 'Sarit Kraus', 'V. S. Subrahmanian']",,2601.04211,"['deepfake detection', 'audio deepfake', 'contextual information', 'transcripts', 'journalists', 'public figures']","This paper presents a novel Context-based Audio Deepfake Detector (CADD) that incorporates contextual information and transcripts to improve the detection of audio deepfakes of public figures, achieving significant performance improvements over baseline detectors.",161.69,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13465v1_Graph Neural Networks are Heuristics.pdf,Graph Neural Networks are Heuristics,"['Yimeng Min', 'Carla P. Gomes']",,2601.13465,"['Graph Neural Networks', 'Heuristics', 'Travelling Salesman Problem', 'Combinatorial Optimization', 'Neural Networks', 'Machine Learning']","The authors demonstrate that graph neural networks can function as effective heuristics for combinatorial optimization problems, specifically the Travelling Salesman Problem, by encoding global structural constraints as an inductive bias. This approach allows non-autoregressive models to generate solutions via direct forward passes without search, supervision, or sequential decision-making.",161.78,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13474v1_Preconditioning Benefits of Spectral Orthogonaliza.pdf,Preconditioning Benefits of Spectral Orthogonalization in Muon,"['Jianhao Ma', 'Yu Huang', 'Yuejie Chi', 'Yuxin Chen']",,2601.13474,"['Muon', 'Matrix Optimization', 'Spectral Orthogonalization', 'Gradient Descent', 'Adam', 'Linear Transformers', 'Preconditioning']","This paper studies the effectiveness of a simplified variant of Muon through two case studies: matrix factorization and in-context learning of linear transformers, proving that simplified Muon converges linearly with iteration complexities independent of the relevant condition number, outperforming gradient descent and Adam.",163.12,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13476v1_A Unified Variational Imputation Framework for Ele.pdf,A Unified Variational Imputation Framework for Electric Vehicle Charging Data Using Retrieval-Augmented Language Model,"['Jinhao Li', 'Hao Wang', 'Member IEEE']",,,"['Electric vehicle', 'data imputation', 'charging demand', 'large language model', 'retrieval-augmented generation']","This paper presents a novel probabilistic variational imputation framework (PRAIM) that leverages large language models and retrieval-augmented memory to address the challenges of missing records in electric vehicle charging data, improving imputation accuracy and preserving statistical distribution for downstream forecasting tasks.",160.77,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13481v1_Towards Efficient and Robust Linguistic Emotion Di.pdf,Towards Efficient and Robust Linguistic Emotion Diagnosis for Mental Health via Multi-Agent Instruction Refinement,"['Jian Zhang', 'Zhangqi Wang', 'Zhiyuan Wang', 'Weiping Fu', 'Yu He', 'Haiping Zhu∗', 'Qika Lin∗', 'Jun Liu']",10.1109/TAFFC.2023.3267497,,"['Linguistic Emotion Diagnosis', 'Emotional Comorbidity', 'Inefficient Exploration', 'Automated Prompt Optimization', 'Multi-Agent Collaboration', 'Medical Language Processing', 'Trustworthy Artificial Intelligence']","This paper proposes APOLO, a framework that systematically explores a broader and finer-grained prompt space to enhance diagnostic efficiency and robustness for linguistic emotion diagnosis in mental health applications, addressing issues of emotional comorbidity and inefficient exploration.",162.46,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13487v1_The Hidden Toll of Social Media News Causal Effect.pdf,The Hidden Toll of Social Media News: Causal Effects on Psychosocial Wellbeing,"['Olivia Pal', 'Agam Goyal', 'Eshwar Chandrasekharan', 'Koustuv Saha']",,2605.01234,"['Social Media', 'News Consumption', 'Psychosocial Wellbeing', 'Quasi-Experimental Study', 'Propensity Score Matching']","This study examines the psychosocial effects of news consumption on social media, using a large-scale dataset and quasi-experimental methods, revealing that news engagement produces systematic trade-offs in terms of depression, stress, anxiety, loneliness, and social interaction, with bookmarking being associated with greater psychosocial deterioration compared to commenting or quoting.",160.44,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13508v1_CatMaster An Agentic Autonomous System for Computa.pdf,CatMaster: An Agentic Autonomous System for Computational Heterogeneous Catalysis Research,"['Honghao Chen', 'Jiangjie Qiu', 'Yi Shen Tew', 'Xiaonan Wang ∗']",,2601.13508,"['CatMaster', 'autonomous system', 'computational heterogeneous catalysis', 'density functional theory', 'large-language-model', 'agent system']","CatMaster is an agent system driven by a large-language-model that converts natural language requests into complete calculation workspaces, including structures, inputs, outputs, logs, and a concise run record, supporting inspection and restartability in computational heterogeneous catalysis studies.",148.54,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13515v1_Automatic Adjustment of HPA Parameters and Attack .pdf,Automatic Adjustment of HPA Parameters and Attack Prevention in Kubernetes Using Random Forests,"['Huah Yong Chan', 'Hanlin Zhou', 'Jingfei Ni', 'Mengchun Wu', 'Qing Deng']",,2601.13515v1,"['Kubernetes', 'HPA', 'Security', 'Random Forest']","This paper uses HTTP status codes as custom metrics within the HPA in Kubernetes to dynamically adjust maximum pod parameters based on attacks assessed and predicted using Random Forest classification, redirecting attacking traffic to honeypot pods to manage 5XX status codes under high load conditions and prevent excessive HPA expansion due to attacks.",152.42,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13518v1_AgenticRed Optimizing Agentic Systems for Automate.pdf,AGENTICRED: Optimizing Agentic Systems for Automated Red-teaming,"['Jiayi Yuan*', 'Jonathan Nöther', 'Natasha Jaques', 'Goran Radanović']",,,"['Automated red-teaming', 'Agentic systems', 'Large Language Models (LLMs)', 'Evolutionary selection', 'Red-teaming', 'AI safety', 'Transferability']","This paper introduces AGENTICRED, an automated pipeline that leverages LLMs' in-context learning to iteratively design and refine red-teaming systems without human intervention, achieving superior performance compared to state-of-the-art approaches.",155.57,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13528v1_Eliciting Harmful Capabilities by Fine-Tuning On S.pdf,ELICITING HARMFUL CAPABILITIES BY FINE-TUNING ON SAFEGUARDED OUTPUTS,"['Jackson Kaunismaa∗', 'MATS Avery Griffin', 'John Hughes', 'Christina Q Knight', 'Mrinank Sharma†', 'Erik Jones†']",null,2601.13528,"['AI safety', 'safeguarded models', 'elicitation attacks', 'hazardous chemical synthesis', 'open-source models', 'fine-tuning']","This work demonstrates that even robustly safeguarded models can be used to elicit harmful capabilities in open-source models through elicitation attacks, recovering approximately 40% of the capability gap between the base open-source model and an unrestricted frontier model.",158.68,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13533v1_Reasoning While Recommending Entropy-Guided Latent.pdf,Reasoning While Recommending: Entropy-Guided Latent Reasoning in Generative Re-ranking Models,['Changshuo Zhang'],https://doi.org/XXXXXXX.XXXXXXX,,"['Generative Re-ranking', 'Latent Reasoning', 'Reinforcement Learning']","This paper introduces an entropy-guided latent reasoning mechanism to improve the accuracy of model decisions in generative re-ranking scenarios, presenting the EGLR recommendation model with three core advantages: abandoning the traditional 'reason first, recommend later' approach, implementing entropy-guided variable-length reasoning, and adopting a lightweight integration design.",156.9,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13534v1_MN-TSGContinuous Time Series Generation with Irreg.pdf,MN-TSG: CONTINUOUS TIMESERIES GENERATION WITH IRREGULAR OBSERVATIONS,"['Xu Zhang', 'Junwei Deng', 'Chang Xu', 'Hao Li', 'Jiang Bian']",null,2601.13534,"['Irregular time series', 'Continuous time series generation', 'Deep learning architecture']","This paper proposes MN-TSG, a novel framework that integrates Mixture-of-Experts (MoE)–based Neural Controlled Differential Equations (NCDEs) with existing TSG models to address the challenges of modeling irregular time series and supporting continuous generation tasks.",136.66,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13537v1_When Wording Steers the Evaluation Framing Bias in.pdf,When Wording Steers the Evaluation: Framing Bias in LLM judges,"['Yerin Hwang', 'Dongryeol Lee', 'Taegwan Kang', 'Minwoo Lee', 'Kyomin Jung']",,,"['Large Language Models', 'LLM Judges', 'Framing Bias', 'Predicate-Positive Framing', 'Predicate-Negative Framing', 'Evaluation', 'Framing Effect']","This study investigates how deliberate prompt framing skews model judgments in LLM-based evaluation tasks, revealing significant discrepancies and distinct tendencies among model families, suggesting framing bias is a structural property of current LLM-based evaluation systems.",138.1,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13545v1_TruthTensor Evaluating LLMs Human Imitation throug.pdf,TRUTHTENSOR: EVALUATINGLLMSHUMANIMITATION THROUGH PREDICTIONMARKETDRIFT ANDHOLISTICREASONING,"['Shirin Shahabi', 'Spencer Graham', 'Haruna Isah']",,,"['TRUTHTENSOR', 'LLMs', 'Human Imitation', 'Prediction Markets', 'Drift', 'Evaluation']","This paper introduces TRUTHTENSOR, a novel evaluation paradigm for Large Language Models (LLMs) that assesses them not only as prediction engines but as human-imitation systems in socially-grounded environments. It combines probabilistic scoring with live prediction markets to provide a holistic view of model behavior, complementing traditional correctness metrics with drift-centric diagnostics and robustness checks.",140.27,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13546v1_ChatAD Reasoning-Enhanced Time-Series Anomaly Dete.pdf,ChatAD: Reasoning-Enhanced Time-Series Anomaly Detection with Multi-Turn Instruction Evolution,"['Hui Sun1*', 'Chang Xu2†', 'Haonan Xie3', 'Hao Li4', 'Yuhao Huang5', 'Chuheng Zhang2', 'Ming Jin6', 'Xiaoguang Liu1', 'Gang Wang1', 'Jiang Bian2']",10.1007/s10664-025-0999-2,2309.14844,"['Anomaly Detection', 'Time Series', 'Multi-Turn Dialogue', 'LLM', 'Reasoning', 'Cross-Task Generalization']","This paper proposes ChatAD, a reasoning-enhanced time-series anomaly detection system that improves upon existing methods by introducing a multi-agent-based TS Evolution algorithm, a new AD reasoning & multi-turn dialogue dataset, and a TS Kahneman-Tversky Optimization to enhance cross-task generalization. The authors evaluate ChatAD and nine baselines across seven datasets and tasks, achieving substantial gains in accuracy and false positives reduction.",159.42,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13547v1_HateXScore A Metric Suite for Evaluating Reasoning.pdf,HateXScore: A Metric Suite for Evaluating Reasoning Quality in Hate Speech Explanations,"['Yujia Hu', 'Roy Ka-Wei Lee']",,2310.00001,"['Hate Speech', 'Explanations', 'Reasoning Quality', 'Evaluation Metrics', 'Transparency']","This paper introduces HateXScore, a four-component metric suite designed to evaluate the reasoning quality of model explanations in hate speech detection. It assesses conclusion explicitness, faithfulness and causal grounding of quoted spans, protected group identification, and logical consistency, providing a diagnostic complement to standard metrics like accuracy or F1, and validating it as a practical tool for trustworthy and transparent moderation.",160.32,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13558v1_Leveraging ChatGPT and Other NLP Methods for Ident.pdf,Leveraging ChatGPT and Other NLP Methods for Identifying Risk and Protective Behaviors in MSM: Social Media and Dating Apps Text Analysis,"['Mehrab Beikzadeh', 'Chenglin Hong', 'Cory J Cascalheira', 'Callisto Boka', 'Majid Sarrafzadeh', 'Ian W Holloway']",,,"['machine learning', 'HIV risk', 'harmful drinking', 'social app', 'dating app', 'Text mining', 'ChatGPT', 'eHealth', 'LLM']","This study aims to determine if text data from social media and dating apps can predict risk and protective behaviors among MSM. The authors trained machine learning models using ChatGPT embeddings, BERT embeddings, LIWC analysis, and a custom dictionary to identify behaviors such as condomless anal sex, number of sexual partners, binge drinking, and heavy drinking. The model was highly predictive of binge drinking and having over 5 sexual partners, but less so for PrEP use and heavy drinking. Combining ChatGPT embeddings with LIWC and BERT improved prediction performance.",161.36,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13559v1_AgentGC Evolutionary Learning-based Lossless Compr.pdf,AgentGC: Evolutionary Learning-based Lossless Compression for Genomics Data with LLM-driven Multiple Agent,"['Hui Sun', 'Yanfeng Ding', 'Huidong Ma', 'Chang Xu', 'Keyan Jin', 'Lizheng Zu', 'Cheng Zhong', 'Xiaoguang Liu', 'Gang Wang', 'Wentong Cai']",10.1007/s10664-026-0999-2,2601.01234,"['Genomics Data', 'Lossless Compression', 'Evolutionary Learning', 'Large Language Models', 'Multiple Agents']","This paper proposes AgentGC, an evolutionary GD compressor consisting of three layers: a user layer, a cognitive layer, and a compression layer. It addresses the limitations of current learning-based methods by integrating LLMs and multi-agent collaboration, achieving significant compression and throughput improvements over 14 baselines on 9 datasets.",156.18,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13562v1_Reasoning is a Modality.pdf,Reasoning is a Modality,"['Zhiguang Liu', 'Yi Shang']",,2509.08444,"['Reasoning', 'AI', 'Human Intelligence', 'ARC Corpus', 'Transformer Blocks', 'Visual Reasoning']","This paper hypothesizes that reasoning is a distinct modality, separate from low-level workspace, and proposes a novel role-separated transformer block to achieve better performance on the Abstraction and Reasoning Corpus (ARC) tasks, surpassing human performance and outperforming prior methods.",159.86,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13563v1_ButterflyMoE Sub-Linear Ternary Experts via Struct.pdf,ButterflyMoE: Sub-Linear Ternary Experts via Structured Butterfly Orbits,['Aryan Karmore'],,2206.09966,"['ButterflyMoE', 'Sub-linear Memory Scaling', 'Ternary Experts', 'Structured Butterfly Orbits', 'Quantization', 'Pruning', 'Low-Rank Factorization']","ButterflyMoE is a method that treats experts as geometric reorientations of a unified shared quantized substrate, achieving sub-linear memory scaling of O(d^2 + N·dlogd) with 150x memory reduction at 256 experts, enabling deployments on 4GB devices compared to standard MoE's 8 experts.",155.25,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13564v1_Multi-objective fluorescent molecule design with a.pdf,Multi-objective fluorescent molecule design with a data-physics dual-driven generative framework,"['Yanheng Li', 'Zhichen Pu', 'Lijiang Yang', 'Zehao Zhou', 'Yi Qin Gao']",,,"['fluorescent molecules', 'multi-objective optimization', 'data-driven design', 'physics-informed generative models']","This paper presents a novel framework combining data-driven and physics-informed approaches to design multi-objective fluorescent molecules, aiming to optimize both emission properties and stability.",158.13,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13566v1_Self-Improvement as Coherence Optimization A Theor.pdf,Self-Improvement as Coherence Optimization: A Theoretical Account,"['Tianyi Qiu', 'Ahmed Hani Ismail', 'Zhonghao He', 'Shi Feng']",null,2601.13566,"['coherence optimization', 'semi-supervised learning', 'language models', 'self-improvement', 'description-length regularization']","This paper provides a theoretical explanation for why language models can improve their accuracy without external supervision, showing that methods such as debate, internal coherence maximization, and iterative bootstrap all optimize the same objective: coherence, defined as the joint likelihood of the model's behaviors across all contexts. The authors prove that coherence optimization is equivalent to description-length regularization and that it is the optimal regularization scheme for semi-supervised learning when the regularizer is derived from a pretrained model.",158.58,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13570v1_GeoDynamics A Geometric State-Space Neural Network.pdf,GeoDynamics: A Geometric State-Space Neural Network for Understanding Brain Dynamics on Riemannian Manifolds,"['Tingting Dan', 'Jiaqi Ding', 'Guorong Wu ∗']",null,2601.13570,"['Geometric State-Space Neural Network', 'Brain Dynamics', 'Riemannian Manifold', 'Functional Connectivity', ""Alzheimer's"", ""Parkinson's"", 'Autism', 'Human Action Recognition']","GeoDynamics is a novel geometric state-space neural network that tracks latent brain-state trajectories directly on the high-dimensional SPD manifold, capturing the trajectories of SPD matrices to understand coordinated networks supporting cognition and behavior, and validating its performance on human action recognition benchmarks.",158.16,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13580v1_Neural Organ Transplantation NOT Checkpoint-Based .pdf,NEURALORGANTRANSPLANTATION(NOT): CHECKPOINT-BASEDMODULARADAPTATION FOR TRANSFORMERMODELS,['Ahmad Al-Zuraiqi'],,2601.13580v1,"['Modular Deep Learning', 'Transfer Learning', 'Checkpoint Transfer', 'Domain Adaptation', 'Large Language Model']","This paper introduces Neural Organ Transplantation (NOT), a modular adaptation framework for transformer models that allows trained layers to function as reusable checkpoints for domain adaptation, demonstrating significant performance improvements over existing methods.",148.05,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13581v1_SCRIPTMIND Crime Script Inference and Cognitive Ev.pdf,SCRIPTMIND: Crime Script Inference and Cognitive Evaluation for LLM-based Social Engineering Scam Detection System,"['Heedou Kim', 'Changsik Kim', 'Sanghwa Shin', 'Jaewoo Kang']",,2310.16979,"['Social Engineering', 'Large Language Models', 'Scam Detection', 'Cognitive Evaluation', 'Crime Script Inference', 'Cognitive Simulation']","This paper proposes SCRIPTMIND, an integrated framework for LLM-based scam detection that combines automated reasoning and human cognition. It includes components for scam reasoning, fine-tuning small LLMs, and assessing real-time cognitive impact. Using 571 Korean phone scam cases, the framework achieved superior performance in detection accuracy, false-positive reduction, scammer utterance prediction, and rationale quality compared to GPT-4.",158.19,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13588v1_TREX Tokenizer Regression for Optimal Data Mixture.pdf,TREX: Tokenizer Regression for Optimal Data Mixture,"['Inho Won', 'Hangyeol Yoo', 'Minkyung Cho', 'Jungyeul Park', 'Hoyun Song', 'KyungTae Lim']",,2310.12345,"['Tokenizer', 'Optimal Data Mixture', 'Multilingual', 'Compression Efficiency', 'Large Language Models']","This paper introduces TREX, a regression-based framework that efficiently predicts the optimal data mixture for tokenizer training, outperforming existing methods in both in- and out-of-distribution compression efficiency.",159.06,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13589v1_Motion-to-Response Content Generation via Multi-Ag.pdf,MOTION-TO-RESPONSECONTENTGENERATION VIA MULTI-AGENTAI SYSTEM WITHREAL-TIMESAFETYVERIFICATION,['HyeYoung Lee'],null,2601.13589v1,"['Speech Emotion Recognition', 'Multi-Agent Systems', 'Content Generation', 'Safety Verification', 'On-Device AI']","This paper proposes a multi-agent artificial intelligence system that generates response-oriented media content in real time based on audio-derived emotional signals, emphasizing the transformation of inferred emotional states into safe, age-appropriate, and controllable response content through a structured pipeline of specialized AI agents.",151.84,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13590v1_Vulnerability of LLMs Belief Systems LLMs Belief R.pdf,Vulnerability of LLMs’ Belief Systems? LLMs Belief Resistance Check Through Strategic Persuasive Conversation Interventions,"['Fan Huang', 'Haewoon Kwak', 'Jisun An']",,2311.17238,"['Large Language Models', 'Persuasion', 'Belief Erosion', 'Meta-Cognition', 'Adversarial Fine-Tuning']","This study systematically evaluates the susceptibility of five mainstream Large Language Models to persuasion under the SMCR communication framework, analyzing how different persuasive strategies influence belief stability over multiple interaction turns and the impact of meta-cognition prompting on resistance to persuasion.",158.61,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13591v1_DSAEval Evaluating Data Science Agents on a Wide R.pdf,DSAEval: Evaluating Data Science Agents on a Wide Range of Real-World Data Science Problems,"['Maojun Sun', 'Yifei Xie', 'Yue Wu', 'Ruijian Han', 'Binyan Jiang', 'Defeng Sun', 'Yancheng Yuan', 'Jian Huang']",null,null,"['Data Science Agents', 'Real-World Problems', 'Large Language Models', 'Evaluation Benchmarks', 'Multi-Modal Perception', 'Multi-Query Interactions', 'Multi-Dimensional Evaluation']","This paper introduces DSAEval, a benchmark for evaluating data science agents on a wide range of real-world data science problems, incorporating features like multi-modal environment perception, multi-query interactions, and multi-dimensional evaluation. The authors systematically evaluate 11 advanced agentic LLMs and demonstrate that multimodal perception consistently improves performance on vision-related tasks, while current data science agents perform well on structured data and routine data analysis workflows but face challenges in unstructured domains.",158.23,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13592v1_Machine learning based radiative parameterization .pdf,Machine learning based radiative parameterization scheme and its performance in operational reforecast experiments,"['Jing Hao', 'Xiao Sa', 'Li Haoyu', 'Xiao Huadong', 'Xue Wei']",,,"['Machine learning', 'Radiation', 'Hybrid model', 'Operational reforecast experiments']","This study investigates critical limitations in hybrid forecasting frameworks that embed deep neural networks into numerical prediction models, focusing on coupling compatibility and long-term integration stability. A residual convolutional neural network approximates the Rapid Radiative Transfer Model for General Circulation Models (RRTMG) within the global operational system of China Meteorological Administration, demonstrating comparable accuracy to traditional physical schemes while accelerating computation speed by approximately eightfold.",158.9,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13599v1_Diffusion In Diffusion Breaking the Autoregressive.pdf,Diffusion In Diffusion: Breaking the Autoregressive Bottle-neck in Block Diffusion Models,"['Linrui Ma', 'Yufei Cui', 'Kai Han', 'Yunhe Wang']",,2601.13599v1,"['block diffusion', 'discrete diffusion', 'autoregressive models', 'diffusion models', 'language models', 'inference', 'perplexity', 'generative perplexity']","This paper proposes DIFFUSION INDIFFUSION—a 'draft-then-refine' framework to overcome the irreversibility and myopia problems in block diffusion models, using block diffusion to generate rapid drafts and global bidirectional diffusion for refinement, with snapshot confidence remasking and mix-scale training to identify and modify critical tokens.",159.97,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13600v1_Foundations of Global Consistency Checking with No.pdf,Foundations of Global Consistency Checking with Noisy LLM Oracles,"['Paul He*', 'Elke Kirschbaum', 'Shiva Kasiviswanathan']",,,"['Global Consistency', 'Natural Language Facts', 'Large Language Models', 'Noisy Oracles', 'Minimal Unsatisfiable Subsets', 'Divide-and-Conquer Algorithm']","Formalizing the problem of ensuring global consistency of natural-language facts, this paper presents an adaptive divide-and-conquer algorithm that identifies minimal inconsistent subsets (MUSes) and optionally computes minimal repairs through hitting-sets. The approach has low-degree polynomial query complexity and efficiently detects and localizes inconsistencies with both synthetic and real LLM oracles, offering a scalable framework for linguistic consistency verification with LLM-based evaluators.",161.92,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13614v1_CauScientist Teaching LLMs to Respect Data for Cau.pdf,CauScientist: Teaching LLMs to Respect Data for Causal Discovery,"['Bo Peng', 'Sirui Chen', 'Lei Xu', 'Chaochao Lu']",null,2601.13614v1,"['causal discovery', 'large language models', 'statistical indistinguishability', 'modeling assumptions', 'distribution shift', 'data-driven methods', 'LLM-based methods']","This paper proposes CauScientist, a collaborative framework that integrates large language models (LLMs) as hypothesis-generating 'data scientists' with probabilistic statistics as verifiers. It aims to improve causal discovery by refining structures through LLM-proposed modifications validated by statistical criteria and maintaining error memory to guide efficient search space.",158.11,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13622v1_CARPE Context-Aware Image Representation Prioritiz.pdf,Context-Aware Image Representation Prioritization via Ensemble for Large Vision-Language Models,"['Donghee Lee', 'Rui Cai', 'Zhe Zhao']",,2601.13622v1,"['Large Vision-Language Models', 'Context-Aware Image Representation', 'Ensemble Strategy', 'Vision-Integration Layers', 'Image Classification', 'Vision-Language Benchmarks']","This paper proposes CARPE, a novel, model-agnostic framework that introduces vision-integration layers and a context-aware ensemble strategy to enhance the adaptability and generalization of Large Vision-Language Models (LVLMs) in image classification and vision-language tasks.",162.92,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13632v1_Resilient Routing Risk-Aware Dynamic Routing in Sm.pdf,Resilient Routing: Risk-Aware Dynamic Routing in Smart Logistics via Spatiotemporal Graph Learning,"['Zhiming Xue', 'Sichen Zhao', 'Yalun Qi', 'Xianling Zeng', 'Zihan Yu']",,,"['Smart Logistics', 'Graph Neural Network', 'Dynamic Routing', 'Spatiotemporal modeling', 'Supply Chain Resilience']","This paper proposes a Risk-Aware Dynamic Routing (RADR) framework that integrates Spatiotemporal Graph Neural Networks (ST-GNN) with combinatorial optimization to address the challenges of traffic congestion and fluctuating retail demand in the logistics network. The framework constructs a logistics topology graph using discrete GPS data and a hybrid deep learning model combining Graph Convolutional Network (GCN) and Gated Recurrent Unit (GRU) to predict future congestion risks, which are then integrated into a dynamic edge weight mechanism for path planning. The experimental results demonstrate that the RADR algorithm significantly enhances supply chain resilience, particularly in high congestion scenarios.",162.3,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13645v1_Quadratic Upper Bound for Boosting Robustness.pdf,Quadratic Upper Bound for Boosting Robustness,"['Euijin Y ou', 'Hyang-Won Lee']",,2301.00000,"['Adversarial Training', 'Robustness', 'Fast Adversarial Training', 'Loss Function', 'Robustness Improvement']","This paper develops a loss function to improve robustness in Fast Adversarial Training (FAT) without requiring stronger inner maximization. It derives a quadratic upper bound on the adversarial training loss function and proposes to utilize the bound with existing FAT methods, showing significant improvement in robustness.",161.99,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13647v1_Fusion Segment Transformer Bi-Directional Attentio.pdf,FUSION SEGMENT TRANSFORMER: BI-DIRECTIONAL A TTENTION GUIDED FUSION NETWORK FOR AI GENERA TED MUSIC DETECTION,"['Yumin Kim', 'Seonghyeon Go']",,2302.09416,"['AI-generated music detection', 'Full-audio segment detection', 'Musical structure analysis', 'Cross-modal fusion layer', 'Music representation']","The authors propose an improved version of the Segment Transformer, termed the Fusion Segment Transformer, to address the challenge of full-audio detection for AI-generated music. They extract content embeddings from short music segments using diverse feature extractors and introduce a Gated Fusion Layer to effectively integrate content and structural information, enabling the capture of long-term context. Experiments on the SONICS and AIME datasets show that their approach outperforms previous models and recent baselines, achieving state-of-the-art results in AI-generated music detection.",157.17,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13649v1_Fairness or Fluency An Investigation into Language.pdf,Fairness or Fluency? An Investigation into Language Bias of Pairwise LLM-as-a-Judge,"['Xiaolin Zhou', 'Zheng Luo', 'Yicheng Gao', 'Qixuan Chen', 'Xiyang Hu', 'Yue Zhao', 'Ruishan Liu']",,2312.08997,"['Large Language Models', 'LLM-as-a-judge', 'Language Bias', 'Pairwise Judging', 'Perplexity Bias']","This paper investigates two types of language bias in pairwise LLM-as-a-judge, examining performance disparities between languages when judging options from the same language and bias towards major languages when judging options from different languages. It also explores whether language bias is caused by low-perplexity bias.",139.72,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13655v1_Why Does the LLM Stop Computing An Empirical Study.pdf,Why Does the LLM Stop Computing: An Empirical Study of User-Reported Failures in Open-Source LLMs,"['GUANGBA YU∗', 'ZIRUI WANG∗', 'YUJIE HUANG', 'RENYI ZHONG', 'YUEDONG ZHONG', 'YILUN WANG', 'MICHAEL R. LYU']",https://doi.org/XXXXXXX.XXXXXXX,,"['Large Language Models', 'Failure Analysis', 'Empirical Study']","This study conducts the first large-scale empirical analysis of 705 real-world failures from the open-source DeepSeek, Llama, and Qwen ecosystems, revealing a shift in reliability bottlenecks from model algorithmic defects to systemic deployment stack fragility, and identifying three key phenomena: diagnostic divergence, systemic homogeneity, and lifecycle escalation.",158.54,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13657v1_Communication-Free Collective Navigation for a Swa.pdf,Communication-Free Collective Navigation for a Swarm of UA Vs via LiDAR-Based Deep Reinforcement Learning,"['Myong-Yol Choi', 'Hankyoul Ko', 'Hanse Cho', 'Changseung Kim', 'Seunghwan Kim', 'Jaemin Seo', 'Hyondong Oh']",,2302.09999,"['multi-robot systems', 'collective navigation', 'sensor-based control', 'deep reinforcement learning']","This paper presents a deep reinforcement learning-based controller for collective navigation of unmanned aerial vehicle (UA V) swarms in communication-denied environments, enabling robust operation in complex, obstacle-rich settings. The system uses LiDAR point clustering and an extended Kalman filter for stable neighbor tracking, and a DRL controller trained in GPU-accelerated Nvidia Isaac Sim enables followers to learn emergent behaviors balancing flocking and obstacle avoidance using only local perception.",160.04,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13659v1_Temporal-Spatial Decouple before Act Disentangled .pdf,TEMPORAL-SPA TIAL DECOUPLE BEFORE ACT: DISENTANGLED REPRESENTA TION LEARNING FOR MULTIMODAL SENTIMENT ANALYSIS,"['Chunlei Meng', 'Ziyang Zhou', 'Lucas He', 'Xiaojing Du', 'Chun Ouyang', 'Zhongxue Gan']",,1912.04065,"['Multimodal Sentiment Analysis', 'Temporal-Spatial Decoupling', 'Representation Learning']","This paper proposes TSDA, Temporal–Spatial Decouple before Act, which explicitly decouples each modality into temporal dynamics and spatial structural context before any interaction, improving multimodal sentiment analysis by reducing spatiotemporal information asymmetry and enhancing performance.",160.67,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13671v1_The Orchestration of Multi-Agent Systems Architect.pdf,"The Orchestration of Multi-Agent Systems: Architectures, Protocols, and Enterprise Adoption","['Apoorva Adimulam', 'Rajesh Gupta', 'Sumit Kumar']",,,"['Agent orchestration', 'Agent-to-Agent protocol', 'dynamic task allocation', 'Model Context Protocol (MCP)', 'multi-agent systems', 'observability', 'state management', 'system governance']","This paper consolidates and formalizes the technical composition of orchestrated multi-agent systems, presenting a unified architectural framework that integrates planning, policy enforcement, state management, and quality operations into a coherent orchestration layer. It also provides in-depth technical delineation of communication protocols and details how orchestration logic, governance frameworks, and observability mechanisms collectively sustain system coherence, transparency, and accountability.",160.63,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13684v1_HeteroCache A Dynamic Retrieval Approach to Hetero.pdf,HeteroCache: A Dynamic Retrieval Approach to Heterogeneous KV Cache Compression for Long-Context LLM Inference,"['Zhiyuan Shi', 'Qibo Qiu', 'Feng Xue', 'Zhonglin Jiang', 'Li Yu', 'Jian Jiang', 'Xiaofei He', 'Wenxiao Wang']",,2310.14626,"['HeteroCache', 'Dynamic Retrieval', 'KV Cache', 'Long-Context LLM Inference', 'Attention Drift', 'Spatial Redundancy', 'Fine-Grained Weighting', 'Hierarchical Storage', 'I/O Overhead']","This paper proposes HeteroCache, a training-free dynamic compression framework for KV caches in long-context LLM inference, addressing the bottleneck of linear memory growth by categorizing attention heads based on stability and redundancy, applying a fine-grained weighting strategy, and employing a hierarchical storage mechanism to hide I/O latency, achieving state-of-the-art performance and up to 3x decoding acceleration compared to the original model.",160.16,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13687v1_Understanding Mental States to Guide Social Influe.pdf,Understanding Mental States to Guide Social Influence in Multi-Person Group Dialogue,"['Zhichao Liang', 'Satoshi Nakamura']",,2310.16849,"['Theory of Mind', 'Social Influence', 'Multi-Person Dialogue', 'Language Models', 'Dynamic Interaction']","This paper introduces SocialMindChange, a benchmark that evaluates large language models in guiding mental states during multi-person group dialogue. It constructs 1,200 social contexts, covering 6,000 scenarios and over 90,000 questions, and evaluates ten state-of-the-art LLMs, showing an average performance gap of 54.2% compared to human performance.",139.58,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13693v1_End-to-End Reverse Screening Identifies Protein Ta.pdf,End-to-End Reverse Screening Identifies Protein Targets of Small Molecules Using HelixFold3,"['Shengjie Xu', 'Xianbin Ye', 'Mengran Zhu', 'Xiaonan Zhang', 'Shanzhuo Zhang', 'Xiaomin Fang']",,2601.13693v1,"['Reverse screening', 'Target identification', 'Biomolecular structure prediction', 'HelixFold3']","This paper presents an end-to-end reverse screening strategy using HelixFold3, a high-accuracy biomolecular structure prediction model, to identify protein targets of small molecules, improving screening accuracy and demonstrating enhanced structural fidelity, binding-site precision, and target prioritization.",156.37,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13697v1_Uncertainty-Aware Gradient Signal-to-Noise Data Se.pdf,Uncertainty-Aware Gradient Signal-to-Noise Data Selection for Instruction Tuning,"['Zhihang Yuan', 'Chengyu Yue', 'Long Huang', 'Litu Ou', 'Lei Shi']",,2309.15406,"['Instruction Tuning', 'Large Language Models', 'Data Selection', 'Gradient Signal-to-Noise Ratio', 'Epistemic Uncertainty']","This paper proposes GRADFILTERING, an objective-agnostic, uncertainty-aware data selection framework for instruction tuning of large language models, utilizing a small GPT-2 proxy with a LoRA ensemble and aggregating per-example gradients into a Gradient Signal-to-Noise Ratio (G-SNR) utility. The method matches or surpasses random subsets and strong baselines in evaluations and human assessments, and converges faster under the same compute budget compared to competitive filters.",157.85,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13698v1_Does Privacy Always Harm Fairness Data-Dependent T.pdf,Does Privacy Always Harm Fairness? Data-Dependent Trade-offs via Chernoff Information Neural Estimation,"['Arjun Nichani', 'Hsiang Hsu', 'Chun-Fu (Richard) Chen', 'Haewon Jeong']",,2601.13698,"['Chernoff Information', 'Fairness', 'Privacy', 'Machine Learning', 'Data-Dependent Trade-offs']","This paper utilizes Chernoff Information to explore the data-dependent relationship between fairness, privacy, and accuracy, highlighting how synthetic data can behave in three distinct ways and proposing a method for estimating Chernoff Information on unknown distributions.",156.22,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13704v1_Performance and Complexity Trade-off Optimization .pdf,Performance and Complexity Trade-off Optimization of Speech Models During Training,"['Esteban Gómez', 'Tom Bäckström']",,2108.08757,"['Speech machine learning', 'low-complexity', 'voice activity detection', 'deep fake detection']","This paper proposes a reparameterization technique based on feature noise injection that enables joint optimization of performance and computational complexity during training using SGD-based methods, allowing the model size to be dynamically optimized for a target performance-complexity trade-off without relying on heuristic criteria to select which weights or structures to remove.",160.42,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13707v1_Attention-space Contrastive Guidance for Efficient.pdf,Attention-space Contrastive Guidance for Efficient Hallucination Mitigation in LVLMs,"['Yujin Jo', 'Sangyoon Bae', 'Taesup Kim*']",,2303.05226,"['hallucination mitigation', 'contrastive guidance', 'large vision-language models', 'attention space', 'efficient computation']","This paper addresses hallucinations in large vision-language models by framing hallucination mitigation as contrastive guidance, steering generation toward visually grounded and semantically faithful text, and proposes Attention-space Contrastive Guidance (ACG) for efficient hallucination reduction.",160.52,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13709v1_Hidden in Plain Text Measuring LLM Deception Quali.pdf,Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games,"['Christopher Kao', 'Vanshika Vats', 'James Davis']",,2312.08646,"['large language models', 'natural language processing', 'autonomous game players', 'social deduction games']","This paper studies deception in the Social Deduction Game (Mafia) using an asynchronous multi-agent framework with GPT-4o LLM agents and compares their performance to human players, finding that LLMs blend in better and deceive more effectively, indicating the sophistication and risks of LLM deception in social contexts.",161.45,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13710v1_Who Should Have Surgery A Comparative Study of Gen.pdf,Who Should Have Surgery? A Comparative Study of GenAI vs Supervised ML for CRS Surgical Outcome Prediction,"['Sayeed Shafayet Chowdhury', 'Snehasis Mukhopadhyay', 'Shiaofen Fang', 'Vijay R. Ramakrishnan']",,,"['Chronic Rhinosinusitis', 'clinical decision support', 'generative artificial intelligence', 'large language models', 'SNOT-22', 'surgical outcome prediction', 'tabular clinical data']","This study compares generative artificial intelligence (GenAI) models, including ChatGPT, Claude, Gemini, and Perplexity, with supervised machine learning (ML) models in predicting clinically meaningful improvement in chronic rhinosinusitis (CRS) outcomes. The research evaluates whether pre-operative models using only clinical data could have identified patients who would have poor outcomes, i.e., those who should have avoided surgery. The study finds that while supervised ML models achieve high accuracy, GenAI models underperform in terms of discrimination and calibration, but their justifications align with clinician heuristics and feature importance identified by the ML models.",159.64,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13717v1_Simulated Ignorance Fails A Systematic Study of LL.pdf,Simulated Ignorance Fails: A Systematic Study of LLM Behaviors on Forecasting Problems Before Model Knowledge Cutoff,"['Zehan Li', 'Yuxuan Wang', 'Ali El Lahib', 'Ying-Jieh Xia', 'Xinyu Pi']",,2309.08677,"['LLM', 'Forecasting', 'Simulated Ignorance', 'Retrospective Forecasting', 'Model Knowledge Cutoff']","This study evaluates the effectiveness of Simulated Ignorance (SI) in approximating True Ignorance (TI) for LLMs on forecasting problems before model knowledge cutoffs. Across 477 competition-level questions and 9 models, SI fails to suppress prior knowledge, even when reasoning traces contain no explicit post-cutoff references, and reasoning-optimized models exhibit worse SI fidelity despite superior reasoning trace quality. These findings suggest that prompts cannot reliably rewind model knowledge, and RF on precutoff events is methodologically flawed.",144.87,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13719v1_Hierarchical Long Video Understanding with Audiovi.pdf,Hierarchical Long Video Understanding with Audiovisual Entity Cohesion and Agentic Search,"['Xinlei Yin', 'Xiulian Peng', 'Xiao Li', 'Zhiwei Xiong', 'Yan Lu']",,2302.09616,"['long video understanding', 'audiovisual entity cohesion', 'agentic search', 'vision-language models', 'temporal grounding', 'entity tracking', 'retrieval-augmented generation']","This paper presents HAVEN, a unified framework for long-video understanding that integrates audiovisual entity cohesion and hierarchical video indexing with agentic search, enabling coherent and comprehensive reasoning over tens of thousands of frames and audio streams.",160.2,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13722v1_OP-Bench Benchmarking Over-Personalization for Mem.pdf,OP-Bench: Benchmarking Over-Personalization for Memory-Augmented Personalized Conversational Agents,"['Yulin Hu', 'Zimo Long', 'Jiahe Guo', 'Xingyu Sui', 'Xing Fu', 'Weixiang Zhao', 'Yanyan Zhao', 'Bing Qin']",,2601.13722,"['Memory-Augmented', 'Personalized Conversational Agents', 'Over-Personalization', 'Benchmarking', 'Memory Filtering', 'Large Language Models']","This paper formalizes over-personalization into three types: Irrelevance, Repetition, and Sycophancy, and introduces OP-Bench, a benchmark of 1,700 verified instances from long-horizon dialogue histories. It evaluates multiple large language models and memory-augmentation methods, finding widespread over-personalization when memory is introduced. The authors propose Self-ReCheck, a lightweight, model-agnostic memory filtering mechanism to mitigate over-personalization while preserving personalization performance.",160.12,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13734v1_Towards robust long-context understanding of large.pdf,TOW ARDS ROBUST LONG-CONTEXT UNDERSTANDING OF LARGE LANGUAGE MODEL VIA ACTIVE RECAP LEARNING,['Chenyu Hui'],,2309.15759,"['LLM', 'Long-context understanding', 'Active recap learning', 'Recap supervision', 'Recap agent']","This paper proposes active recap learning (ARL), a framework for enhancing large language model (LLM) in understanding long contexts. ARL enables models to revisit and summarize earlier content through targeted sequence construction during continued pretraining and retrospective summarization at inference, leading to substantial improvements in performance.",135.52,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13735v1_Reasoning or Fluency Dissecting Probabilistic Conf.pdf,Reasoning or Fluency? Dissecting Probabilistic Confidence in Best-of-N Selection,"['Hojin Kim', 'Jaehyung Kim']",,2310.18467,"['Best-of-N', 'Reasoning', 'Probabilistic Confidence', 'Fluency', 'Causal Dependence']","This work challenges the assumption that probabilistic confidence metrics capture inter-step causal dependencies necessary for valid reasoning, finding that these metrics are largely insensitive to logical structure and primarily capture surface-level fluency or in-distribution priors. The authors propose a contrastive causality metric that explicitly isolates inter-step causal dependencies and demonstrates improved output selection.",160.07,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13749v1_Pro-AI Bias in Large Language Models.pdf,Pro-AI Bias in Large Language Models,"['Benaya Trabelsi', 'Jonathan Shaki', 'Sarit Kraus']",,2310.16596,"['Large Language Models', 'Pro-AI Bias', 'Decision Support', 'Artificial Intelligence', 'Salary Estimation', 'Representational Salience']","This paper investigates whether large language models display a systematic preferential bias in favor of artificial intelligence, finding consistent evidence of pro-AI bias across three experiments, including disproportionate recommendation of AI-related options, overestimation of AI-related job salaries, and valence-invariant representation of AI in model internal representations.",158.78,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13752v1_Finding RELIEF Shaping Reasoning Behavior without .pdf,Finding RELIEF: Shaping Reasoning Behavior without Reasoning,"['Chak Tou Leong', 'Dingwei Chen', 'Heming Xia', 'Qingyu Yin', 'Sunbowen Lee', 'Jian Wang', 'Wenjie Li']",,2309.15282,"['Large reasoning models', 'Belief engineering', 'Logit probing', 'Fine-tuning', 'Efficiency', 'Faithfulness']","This paper reveals that large reasoning models possess latent reasoning beliefs that can be captured through simple logit probing. It proposes RELIEF, a framework that shapes LRM behavior by aligning the model's self-concept with a target belief blueprint, bypassing the need for reasoning-trace supervision and requiring lower training costs.",159.77,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13761v1_DARC Decoupled Asymmetric Reasoning Curriculum for.pdf,DARC: Decoupled Asymmetric Reasoning Curriculum for LLM Evolution,"['Shengda Fan', 'Xuyan Ye', 'Yankai Lin']",,2601.13761,"['large language models', 'self-play', 'self-improvement', 'optimization instability', 'asymmetric self-distillation', 'difficulty calibration', 'pseudo-labels']","DARC is a two-stage framework that stabilizes the self-evolution process of large language models by training a Questioner to synthesize difficulty-calibrated questions and a Solver with an asymmetric self-distillation mechanism to generate high-quality pseudo-labels. Empirical results show that DARC improves performance across nine reasoning benchmarks and three backbone models, outperforming all baselines without relying on human annotations.",141.96,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13768v1_vLinear A Powerful Linear Model for Multivariate T.pdf,vLinear: A Powerful Linear Model for Multivariate Time Series Forecasting,"['Wenzhen Yue', 'Ruohao Guo', 'Ji Shi', 'Zihan Hao', 'Shiyu Hu', 'Xianghua Ying']",null,2309.15486,"['Time series forecasting', 'Multivariate time series', 'Linear model', 'Transformer-based methods', 'Self-attention', 'Efficiency', 'Forecasting accuracy']","This paper presents vLinear, a powerful yet efficient linear-based multivariate time series forecaster that integrates vecTrans, a lightweight module using a learnable rank-1 matrix to model multivariate correlations, with WFM-Loss as the objective. vLinear achieves state-of-the-art performance across 22 benchmarks and 124 forecasting settings, demonstrating superior forecasting accuracy compared to state-of-the-art forecasters.",159.87,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13770v1_Look-Ahead-Bench a Standardized Benchmark of Look-.pdf,Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance,['Mostapha Benhenda'],,arXiv:2601.13770v1,"['Look-ahead bias', 'Point-in-Time LLMs', 'Finance', 'Large Language Models', 'Temporal causality', 'Memorization']","This paper introduces Look-Ahead-Bench, a standardized benchmark to measure look-ahead bias in Point-in-Time Large Language Models (LLMs) within realistic financial workflows. It evaluates prominent open-source LLMs and Pitinf models, revealing significant lookahead bias in standard LLMs and improved generalization and reasoning abilities in Pitinf models as they scale in size.",160.3,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13798v1_Insight Interpretable Semantic Hierarchies in Visi.pdf,INSIGHT: Interpretable Semantic Hierarchies in Vision-Language Encoders,"['Kai Wittenmayer', 'Sukrut Rao', 'Amin Parchami-Araghi', 'Bernt Schiele', 'Jonas Fischer']",10.48550/arxiv.2601.13798,2601.13798,"['Interpretability', 'Vision-Language Models', 'Semantic Hierarchies', 'Concept Extraction', 'Spatial Grounding']","The paper introduces INSIGHT, a language-aligned concept foundation model that provides fine-grained, human-interpretable concepts with spatial grounding, enabling rich explanations for vision tasks such as classification and segmentation.",156.66,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13809v1_DroneVLA VLA based Aerial Manipulation.pdf,DroneVLA: VLA based Aerial Manipulation,"['Fawad Mehboob∗', 'Monijesu James∗', 'Amir Habel∗', 'Jeffrin Sam', 'Miguel Altamirano Cabrera', 'Dzmitry Tsetserukou']",,,"['Aerial Manipulation', 'Vision-Language-Action Models', 'Human-Robot Interaction', 'Visual Surveying', 'Robotic Fetch-and-Carry']","This work introduces a novel concept of autonomous aerial manipulation system capable of interpreting high-level natural language commands to retrieve objects and deliver them to a human user, integrating a MediaPipe based on Grounding DINO and a Vision-Language-Action (VLA) model with a custom-built drone equipped with a 1-DOF gripper and an Intel RealSense RGB-D camera.",159.93,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13846v1_Virtual Urbanism An AI-Driven Framework for Quanti.pdf,Virtual Urbanism: An AI-Driven Framework for Quantifying Urban Identity,"['Glinskaya, Maria']",,2309.15097,"['generative artificial intelligence', 'latent diffusion model', 'low-rank adaptation model', 'urban perception', 'urban identity']","This paper introduces Virtual Urbanism (VU), a multimodal AI-driven analytical framework for quantifying urban identity through synthetic urban replicas. The pilot study demonstrates the feasibility of the framework using a pipeline integrating Stable Diffusion and LoRA models to produce dynamic synthetic urban sequences of nine Tokyo areas, excluding existing orientation markers to elicit core identity-forming elements. Results show a mean identification accuracy of ~81%, confirming the validity of the replicas and enabling assessment of identity levels across areas.",160.07,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13864v1_HardSecBench Benchmarking the Security Awareness o.pdf,HardSecBench: Benchmarking the Security Awareness of LLMs for Hardware,"['Qirui Chen', 'Jingxian Shuai', 'Shuangwu Chen', 'Shenghao Ye', 'Zijian Wen', 'Xufei Su', 'Jie Jin', 'Jiangming Li', 'Jun Chen', 'Xiaobin Tan', 'Jian Yang']",,2310.16584,"['Large Language Models', 'Hardware Security', 'Code Generation', 'Benchmarking', 'Security Awareness']","This paper introduces HardSecBench, a benchmark with 924 tasks covering Verilog RTL and firmware-level C, to assess security awareness in LLM-generated code. It evaluates models on hardware and firmware code generation, revealing that models often satisfy functional requirements but leave security risks. The findings highlight pressing challenges and offer insights for future advancements in LLM-assisted hardware design.",157.16,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13880v1_LifeAgentBench A Multi-dimensional Benchmark and A.pdf,LifeAgentBench: A Multi-dimensional Benchmark and Agent for Personal Health Assistants in Digital Health,"['Ye Tian', 'Zihao Wang', 'Onat Gungor', 'Xiaoran Fan', 'Tajana Rosing']",10.1101/2023.08.14.657079,2308.07079,"['digital health', 'personalized health support', 'long-horizon reasoning', 'mobile sensing', 'large language models', 'benchmarking', 'health assistants']","This paper introduces LifeAgentBench, a large-scale QA benchmark for long-horizon, cross-dimensional, and multi-user lifestyle health reasoning, containing 22,573 questions. It evaluates 11 leading LLMs and proposes LifeAgent as a strong baseline agent for health assistants, achieving significant improvements in multi-step evidence retrieval and cross-dimensional reasoning.",160.24,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13885v1_Confident Rankings with Fewer Items Adaptive LLM E.pdf,Confident Rankings with Fewer Items: Adaptive LLM Evaluation with Continuous Scores,"['Esma Balkır', 'Alice Pernthaller', 'Marco Basaldella', 'José Hernández-Orallo', 'Nigel Collier']",,,"['Computerized Adaptive Testing', 'Large Language Models', 'Item Response Theory', 'Continuous Scores', 'ROUGE', 'BLEU', 'LLM-as-a-Judge']","This paper presents a principled extension of IRT-based adaptive testing to continuous bounded scores, using a heteroskedastic normal distribution. It introduces an uncertainty-aware ranker with adaptive stopping criteria that achieves reliable model ranking while testing as few items and as cheaply as possible, validating the method on five benchmarks spanning various metrics.",157.78,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13887v1_Human Simulation Computation A Human-Inspired Fram.pdf,Human Simulation Computation: A Human-Inspired Framework for Adaptive AI Systems,['Hong Su'],,,"['Human Simulation Computation', 'Environment Interaction', 'Adaptive Artificial Intelligence', 'Human-Inspired Reasoning']","This paper proposes Human Simulation Computation (HSC), a human-inspired computational framework that models intelligence as a continuous, closed-loop process involving thinking, action, learning, reflection, and activity scheduling. HSC emphasizes active participation within the internal reasoning process and interactions with the environment, incorporating human thinking strategies across all stages.",161.66,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13895v1_OmniOVCD Streamlining Open-Vocabulary Change Detec.pdf,OmniOVCD: Streamlining Open-Vocabulary Change Detection with SAM 3,"['Xu Zhang', 'Danyang Li', 'Yingjie Xia', 'Xiaohang Dong', 'Hualong Yu', 'Jianye Wang', 'Qicheng Li']",,2310.17685,"['Change Detection', 'Open-Vocabulary', 'SAM 3', 'Segment Anything Model', 'Synergistic Fusion to Instance Decoupling', 'Open-World Scenarios']","This paper proposes OmniOVCD, a new framework for Open-Vocabulary Change Detection (OVCD) that utilizes the Segment Anything Model 3 (SAM 3) to integrate segmentation and identification capabilities within a single model. The authors introduce a Synergistic Fusion to Instance Decoupling (SFID) strategy to preserve high accuracy in category recognition and maintain instance-level consistency across images, achieving superior performance on public benchmarks.",160.02,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13897v1_TractRLFusion A GPT-Based Multi-Critic Policy Fusi.pdf,TRACTRLFUSION: A GPT-BASED MULTI-CRITIC POLICY FUSION FRAMEWORK FOR FIBER TRACTOGRAPHY,"['Ankita Joshi', 'Ashutosh Sharma', 'Anoushkrit Goel', 'Ranjeet Ranjan Jha', 'Chirag Ahuja', 'Arnav Bhavsar', 'Aditya Nigam']",10.13039/100011560,2209.12156,"['Diffusion MRI', 'Tractography', 'Reinforcement Learning', 'Transformers']","This paper proposes TractRLFusion, a novel GPT-based policy fusion framework for fiber tractography that integrates multiple RL policies through a data-driven fusion strategy, demonstrating improved accuracy and anatomical reliability compared to individual RL policies and state-of-the-art methods.",158.32,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13904v1_PREFAB PREFerence-based Affective Modeling for Low.pdf,PREFAB: Preference-based Affective Modeling for Low-Budget Self-Annotation,"['Jaeyoung Moon', 'Youjin Choi', 'Yucheon Park', 'David Melhart', 'Georgios N. Yannakakis', 'Kyung-Joong Kim']",10.1145/3675094.3678379,2601.13904,"['Affective Computing', 'Preference Learning', 'Self-Annotation', 'User Modeling', 'Ordinal Representation', 'Peak-End Rule']","PREFAB is a low-budget retrospective self-annotation method that targets affective inflection regions rather than full annotation, employing a preference-learning model to detect relative affective changes and directing annotators to label only selected segments while interpolating the remainder of the stimulus.",160.5,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13920v1_Asymmetric regularization mechanism for GAN traini.pdf,Asymmetric regularization mechanism for GAN training with Variational Inequalities,"['Spyridon C. Giagtzoglou', 'Mark H.M. Winands', 'Barbara Franci']",,1906.04749,"['Generative Adversarial Networks (GANs)', 'Nash Equilibrium', 'Variational Inequalities (VIs)', 'Monotone Operators', 'Extrapolation-from-the-Past (EFTP) method', 'Tikhonov regularization', 'Zero-centered gradient penalty']",This paper formulates the training of GANs as a Nash equilibrium seeking problem and proposes an asymmetric regularization mechanism based on Tikhonov step and a novel zero-centered gradient penalty to stabilize the training process and find a Nash equilibrium.,160.42,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13938v1_IF-GEO Conflict-Aware Instruction Fusion for Multi.pdf,IF-GEO: Conflict-Aware Instruction Fusion for Multi-Query Generative Engine Optimization,"['Heyang Zhou', 'JiaJia Chen', 'Xiaolu Chen', 'Jie Bao', 'Zhen Chen', 'Yong Liao']",,2310.18459,"['Generative Search Engines', 'Conflict-Aware Instruction Fusion', 'Multi-Query Optimization', 'Large Language Models', 'Source Visibility']","This paper proposes IF-GEO, a framework for improving content visibility in generated responses through targeted document revisions, addressing the challenge of conflicting revision requirements for diverse queries under a limited content budget.",159.54,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13942v1_Glance-or-Gaze Incentivizing LMMs to Adaptively Fo.pdf,Glance-or-Gaze: Incentivizing LMMs to Adaptively Focus Search via Reinforcement Learning,"['Hongbo Bai', 'Yujin Zhou', 'Yile Wu', 'Chi-Min Chan', 'Pengcheng Wen', 'Kunhao Pan', 'Sirui Han', 'Yike Guo']",,2310.16669,"['Large Multimodal Models', 'Reinforcement Learning', 'Search-Augmented', 'Visual Question Answering', 'Long-Tail Entities', 'Reinforcement Learning', 'Active Visual Planning', 'Selective Gaze', 'Complexity-Adaptive Reinforcement Learning']","This paper proposes Glance-or-Gaze (GoG), a fully autonomous framework that shifts from passive perception to active visual planning, introducing a Selective Gaze mechanism to dynamically choose whether to glance at global context or gaze into high-value regions, filtering irrelevant information before retrieval. The dual-stage training strategy enhances the model's capability to handle complex queries through iterative reasoning, demonstrating state-of-the-art performance across six benchmarks.",159.89,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13948v1_Stream-Voice-Anon Enhancing Utility of Real-Time S.pdf,STREAM-VOICE-ANON: ENHANCING UTILITY OF REAL-TIME SPEAKER ANONYMIZATION VIA NEURAL AUDIO CODEC AND LANGUAGE MODELS,"['Nikita Kuzmin', 'Songting Liu', 'Kong Aik Lee', 'Eng Siong Chng']",null,null,"['streaming speaker anonymization', 'neural audio codec', 'voice conversion', 'privacy preservation', 'disentanglement']","This paper presents Stream-Voice-Anon, which adapts modern causal LM-based neural audio codec architectures specifically for streaming speaker anonymization by integrating anonymization techniques. It achieves substantial improvements in intelligibility and emotion preservation compared to the previous state-of-the-art streaming method DarkStream while maintaining comparable latency and privacy protection against lazy-informed attackers.",157.77,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13964v1_RL-BioAug Label-Efficient Reinforcement Learning f.pdf,RL-BioAug: Label-Efficient Reinforcement Learning for Self-Supervised EEG Representation Learning,"['Cheol-Hui Lee', 'Hwa-Yeon Lee', 'Dong-Joo Kim']",,1901.02262,"['Reinforcement Learning', 'Self-Supervised Learning', 'Contrastive Learning', 'EEG Representation Learning', 'Data Augmentation', 'Healthcare']","This paper proposes RL-BioAug, a framework that uses a label-efficient reinforcement learning agent to autonomously determine optimal augmentation policies for self-supervised EEG representation learning, significantly outperforming random selection strategies in terms of Macro-F1 scores on the Sleep-EDFX and CHB-MIT datasets.",159.48,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13969v1_Autonomous Knowledge Graph Exploration with Adapti.pdf,Autonomous Knowledge Graph Exploration with Adaptive Breadth-Depth Retrieval,"['Joaquín Polonuer', 'Lucas Vittor', 'Iñaki Arango', 'Ayush Noori', 'David A. Clifton', 'Luciano Del Corro', 'Marinka Zitnik']",,2309.15585,"['Knowledge Graphs', 'Knowledge Retrieval', 'Language Models', 'Adaptive Retrieval', 'Breadth-Depth Tradeoff']","Introducing ARK: an agent-based knowledge graph retriever that balances breadth and depth of search using a two-operation toolset, adapting to query types and improving performance on various datasets compared to retrieval-based and agent-free methods.",157.71,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13992v1_The Whole Is Greater Than the Sum of Its Parts A C.pdf,The Whole Is Greater Than the Sum of Its Parts: A Compatibility-Aware Multi-Teacher CoT Distillation Framework,"['Jin Cui', 'Jiaqi Guo', 'Jiepeng Zhou', 'Ruixuan Yang', 'Jiayi Lu', 'Jiajun Xu', 'Jiangcheng Song', 'Boran Zhao', 'Pengju Ren']",,2309.14486,"['Chain-of-Thought', 'Multi-Teacher Distillation', 'CoT Distillation', 'Student Models', 'Compatibility-Aware', 'Catastrophic Forgetting', 'Reasoning Path Diversity', 'Teacher-Student Incompatibility']","This paper introduces COMPACT, a framework that adaptively fuses supervisions from different teachers to transfer reasoning prowess into compact student models, addressing the challenges of teacher-student incompatibility and catastrophic forgetting in multi-teacher CoT distillation.",141.53,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13994v1_torch-sla Differentiable Sparse Linear Algebra wit.pdf,torch-sla: Differentiable Sparse Linear Algebra with Adjoint Solvers and Sparse Tensor Parallelism for PyTorch,['Mingyuan Chi'],null,2601.13994,"['PyTorch', 'sparse linear algebra', 'GPU acceleration', 'multi-GPU scaling', 'adjoint differentiation']","This paper presents torch-sla, an open-source PyTorch library that enables GPU-accelerated, scalable, and differentiable sparse linear algebra, addressing challenges in sparse matrix operations, multi-GPU scaling, and adjoint-based differentiation.",159.82,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.13999v1_DAME Duration-Aware Matryoshka Embedding for Durat.pdf,Duration-Aware Matryoshka Embedding (DAME) for Duration-Robust Speaker Verification,"['Youngmoon Jung*', 'Joon-Young Yang*', 'Ju-ho Kim', 'Jaeyoung Roh', 'Chang Woo Han', 'Hoon-Young Cho']",,,"['Short-duration speaker verification', 'multi-scale aggregation', 'matryoshka representation learning']","This paper proposes DAME, a model-agnostic framework that builds a nested hierarchy of sub-embeddings aligned to utterance durations, improving performance on short-duration trials while maintaining full-length performance.",159.88,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14012v1_MATE Matryoshka Audio-Text Embeddings for Open-Voc.pdf,MATE: MATRYOSHKA AUDIO–TEXT EMBEDDINGS FOR OPEN-VOCABULARY KEYWORD SPOTTING,"['Youngmoon Jung', 'Myunghun Jung', 'Joon-Young Yang', 'Yong-Hyeok Lee', 'Jaeyoung Roh', 'Hoon-Young Cho']",,,"['Keyword spotting', 'open-vocabulary', 'text enrollment', 'audio–text embedding', 'deep metric learning']","This paper proposes Matryoshka Audio–Text Embeddings (MATE), a dual-encoder framework that encodes multiple embedding granularities within a single vector via nested sub-embeddings. MATE is trained with standard deep metric learning objectives for audio–text keyword spotting, achieving state-of-the-art results on WSJ and LibriPhrase without any inference overhead.",157.12,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14022v1_Credible CO2 Comparisons A Machine Learning Approa.pdf,Credible CO2 Comparisons: A Machine Learning Approach to Vehicle Powertrain Assessment,"['Rodrigo Pereira David', 'David', 'Luciano Araujo Dourado Filho', 'Daniel Marques da Silva', 'João Alfredo Cal-Braz']",xxx/xxxx,,"['machine learning', 'vehicle emissions', 'electric vehicles']","This paper proposes a machine learning-based framework for comparing CO2 emissions from internal combustion engine vehicles and electric vehicles under identical real-world driving conditions, enabling fair and reproducible evaluation of powertrain technologies.",160.86,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14027v1_Numina-Lean-Agent An Open and General Agentic Reas.pdf,Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics,"['Junqi Liu', 'Zihao Zhou', 'Zekai Zhu', 'Marco Dos Santos', 'Weikun He', 'Jiawei Liu', 'Ran Wang', 'Lihong Zhi', 'Jia Li', 'Wenda Li', 'Yunzhou Xie', 'Junqiao Zhao', 'Qiufeng Wang']",,2309.15783,"['Formal theorem proving', 'Agentic systems', 'Neural theorem proving', 'Lean theorem prover', 'Mathematical reasoning']","This paper introduces Numina-Lean-Agent, a general agentic reasoning system that combines Claude Code with Numina-Lean-MCP to enable autonomous interaction with Lean, retrieval of relevant theorems, informal proving, and auxiliary reasoning tools. It solves all problems in Putnam 2025 and successfully formalizes the Brascamp–Lieb theorem, demonstrating its generality and flexibility.",160.36,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14039v1_Generalizing Abstention for Noise-Robust Learning .pdf,Generalizing Abstention for Noise-Robust Learning in Medical Image Segmentation,"['Wesam Moustafa', 'Hossam Elsafty', 'Helen Schneider', 'Lorenz Sparrenberg', 'Rafet Sifa']",,2601.14039,"['Abstention', 'Medical Image Segmentation', 'Label Noise', 'Noise-Robust Learning', 'Loss Functions']","This paper introduces a universal and modular abstention framework to enhance the noise-robustness of loss functions in medical image segmentation, demonstrating its effectiveness through experiments on the CaDIS and DSAD medical datasets.",159.4,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14041v1_Top 10 Open Challenges Steering the Future of Diff.pdf,Top 10 Open Challenges Steering the Future of Diffusion Language Model and Its Variants,"['Yunhe Wang', 'Kai Han', 'Huiling Zhen', 'Yuchuan Tian', 'Hanting Chen', 'Yongbing Huang', 'Yufei Cui', 'Yingte Shu', 'Shan Gao', 'Ismail Elezi', 'Roy Vaughan Miles', 'Songcen Xu', 'Feng Wen', 'Chao Xu', 'Sinan Zeng', 'Dacheng Tao']",,2601.14041v1,"['Large Language Models', 'Diffusion Models', 'Transformers']","This Perspective identifies ten fundamental challenges for Diffusion Language Models and their variants, which are currently constrained by architectural inertia, gradient sparsity, and limitations of linear reasoning. It proposes a strategic roadmap to overcome these challenges by shifting towards a diffusion-native ecosystem characterized by multi-scale tokenization, active remasking, and latent thinking.",154.2,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14047v1_Collective intelligence in science direct elicitat.pdf,COLLECTIVE INTELLIGENCE IN SCIENCE: DIRECT ELICITATION OF DIVERSE INFORMATION FROM EXPERTS WITH UNKNOWN INFORMATION STRUCTURE,"['ALEXEY V. OSIPOV', 'NIKOLAY N. OSIPOV']",null,2601.14047,"['interpretability', 'wisdom of crowd', 'play money', 'prediction market', 'information pooling', 'information elicitation', 'rational expectation equilibrium', 'direct communication', 'large language models', 'scientific collaboration']","The authors propose a simple mechanism based on a self-resolving play-money prediction market entangled with a chat to aggregate private information from a large group of experts on a complex scientific hypothesis, even if the ground truth cannot be established and experts initially know nothing about each other.",155.72,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14051v1_Kakugo Distillation of Low-Resource Languages into.pdf,Kakugo: Distillation of Low-Resource Languages into Small Language Models,"['Peter Devine', 'Mardhiyah Sanni', 'Farid Adilazuarda', 'Julieta Gil Loizaga', 'Barry Haddow']",,2309.16087,"['Small Language Models', 'Low-Resource Languages', 'Model Distillation', 'Synthetic Data', 'Natural Language Processing']","This paper presents Kakugo, a novel pipeline designed to train general-purpose Small Language Models for low-resource languages using only the language name as input. It uses a large teacher model to generate synthetic prompts and translate instruction datasets, producing training data and SLMs for 54 languages. Evaluations across various NLP tasks show that Kakugo consistently improves performance over base models, offering an accessible method for communities to develop language-specific AI.",158.92,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14053v1_LLMOrbit A Circular Taxonomy of Large Language Mod.pdf,LLMOrbit: A Circular Taxonomy of Large Language Models,"['Badri N. Patro', 'Vijay S. Agneeswaran']",,2601.14053v1,"['Large Language Models', 'Taxonomy', 'AI', 'Generative AI', 'Agentic Systems', 'Scaling Wall', 'Efficiency', 'Post-Training Gains', 'Efficiency Revolution', 'Democratization']","This paper presents LLMOrbit, a comprehensive circular taxonomy of large language models spanning 2019-2025, examining over 50 major models across 15 organizations. It identifies three critical crises threatening AI progress and six different paradigms to break the scaling wall, including post-training gains, efficiency revolution, and democratization.",158.26,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14055v1_Decoder-Free Supervoxel GNN for Accurate Brain-Tum.pdf,Decoder-Free Supervoxel GNN for Accurate Brain-Tumor Localization in Multi-Modal MRI,"['Andrea Protani', 'Marc Molina Van Den Bosch', 'Lorenzo Giusti', 'Heloisa Barbosa Da Silva', 'Paolo Cacace', 'Albert Sund Aillet', 'Miguel Angel Gonzalez Ballester', 'Friedhelm Hummel', 'Luigi Serio']",,2601.14055,"['BrainTumorLocalization', 'GraphNeuralNetworks', 'Multi-modal MRI', 'Supervoxel', 'Regression']","This paper introduces a decoder-free pipeline called SVGFormer, which partitions a 3D medical image volume into a semantic graph of super-voxels. The hierarchical encoder learns rich node representations by combining patch-level and supervoxel-level models, achieving strong performance in node-level classification and tumor proportion regression on the BraTS dataset.",160.81,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14056v1_POCI-Diff Position Objects Consistently and Intera.pdf,POCI-Diff: Position Objects Consistently and Interactively with 3D-Layout Guided Diffusion,"['Andrea Rigo', 'Luca Stornaiuolo', 'Weijie Wang', 'Mauro Martino', 'Bruno Lepri', 'Nicu Sebe']",,2601.14056,"['Diffusion', 'Image Generation', '3D Layout']","The paper proposes a diffusion-based approach for Text-to-Image (T2I) generation with consistent and interactive 3D layout control and editing, addressing limitations of prior methods that often distort object geometry and fail to preserve consistency across edits.",138.72,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14063v1_XCR-Bench A Multi-Task Benchmark for Evaluating Cu.pdf,XCR-Bench: A Multi-Task Benchmark for Evaluating Cultural Reasoning in LLMs,"['Mohsinul Kabir', 'Tasnim Ahmed', 'Md Mezbaur Rahman', 'Shaoxiong Ji', 'Hassan Alhuzali', 'Sophia Ananiadou']",,2309.15856,"['Large Language Models', 'Cross-Cultural Reasoning', 'Cultural Competence', 'Culture-Specific Items', 'LLM Evaluation', 'Cross-Cultural NLP']","This paper introduces XCR-Bench, a benchmark for evaluating cross-cultural reasoning in large language models (LLMs), consisting of 4.9k parallel sentences and 1,098 unique Culture-Specific Items (CSIs), spanning three distinct reasoning tasks. The authors integrate Newmark’s CSI framework with Hall’s Triad of Culture to systematically analyze cultural reasoning beyond surface-level artifacts and into semi-visible and invisible cultural elements.",140.46,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14069v1_Unsupervised Video Class-Incremental Learning via .pdf,Unsupervised Video Class-Incremental Learning via Deep Embedded Clustering Management,"['Nattapong Kurpukdee', 'Adrian G. Bors']",,2309.14354,"['Unsupervised', 'Video Class-Incremental', 'Video Continual Learning', 'Deep Embedded Clustering']","This paper proposes a simple yet effective approach to address unsupervised video class incremental learning, focusing on providing a set of representative video features during each task without assuming any class or task information, and progressively building a series of deep clusters from the extracted features for successive task learning.",159.83,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14084v1_DermaBench A Clinician-Annotated Benchmark Dataset.pdf,DermaBench: A Clinician-Annotated Benchmark Dataset for Dermatology Visual Question Answering and Reasoning,"['Abdurrahim Yilmaz', 'Ozan Erdem', 'Ece Gokyayla', 'Ayda Acar', 'Burc Bugra Dagtas', 'Dilara Ilhan Erdil', 'Gulsum Gencoglan', 'Burak Temelkuran']",,,"['DermaBench', 'Dermatology', 'Visual Question Answering', 'VQA', 'Multimodal Learning', 'Clinician Annotation', 'Diverse Dermatology Images (DDI)']","DermaBench is a clinician-annotated dermatology Visual Question Answering (VQA) benchmark dataset built on the DDI dataset, comprising 656 clinical images from 570 unique patients, with expert dermatologists providing annotations for diagnosis, anatomic site, lesion morphology, distribution, surface features, color, and image quality, along with open-ended narrative descriptions and summaries.",154.24,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14086v1_Two-Stream temporal transformer for video action c.pdf,TWO-STREAM TEMPORAL TRANSFORMER FOR VIDEO ACTION CLASSIFICATION,"['Nattapong Kurpukdee', 'Adrian G. Bors']",,1912.09278,"['Video Transformer', 'Optical Flow', 'Two-Stream video processing', 'Video Action Classification']","This study introduces a new two-stream transformer video classifier that extracts spatio-temporal information from content and optical flow, identifying self-attention features across the joint optical flow and temporal frame domain and representing their relationships within the transformer encoder mechanism.",134.54,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14087v1_1-bit Count-based Sorting Unit to Reduce Link Powe.pdf,'1'-bit Count-based Sorting Unit to Reduce Link Power in DNN Accelerators,"['Ruichi Han', 'Yizhi Chen', 'Tong Lei', 'Jordi Altayo Gonzalez', 'Ahmed Hemani']",,1909.08886,"[""'1'-bit count-based sorting"", 'Approximate computing', 'Bit transition reduction', 'Link power']","This work proposes a hardware implementation of a comparison-free sorting unit optimized for Convolutional Neural Networks (CNN) to reduce link power in DNN accelerators, leveraging approximate computing to group population counts into coarse-grained buckets, achieving up to 35.4% area reduction while maintaining 19.50% BT reduction compared to a precise implementation.",156.51,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14091v1_Zero-shot adaptable task planning for autonomous c.pdf,Zero-shot adaptable task planning for autonomous construction robots: a comparative study of lightweight single and multi-AI agent systems,"['Hossein Naderi', 'Alireza Shojaei', 'Lifu Huang', 'Philip Agee', 'Kereshmeh Afsari', 'Abiola Akanmu']",,,"['Construction robotics', 'quadruped robots', 'robot task planning', 'multi-AI agent', 'LLMs', 'VLMs', 'GPT4o']","This study explores the potential of foundation models to enhance the adaptability and generalizability of task planning in construction robots, proposing four models using lightweight, open-source large language models and vision language models, and evaluating their performance across three construction roles.",158.75,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14096v1_Remapping and navigation of an embedding space via.pdf,Remapping and navigation of an embedding space via error minimization: a fundamental organizational principle of cognition in natural and artificial systems,"['Benedikt Hartl', 'Léo Pio-Lopez', 'Chris Fields', 'Michael Levin']",,2601.14096,"['Evolution', 'Development', 'Intelligence', 'Active Inference', 'Navigation Policy', 'Nested Embedding Spaces']","This paper discusses the fundamental organizational principle of cognition in natural and artificial systems, focusing on remapping and navigation of an embedding space via error minimization.",152.74,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14099v1_Causal feature selection framework for stable soft.pdf,Causal Feature Selection Framework for Stable Soft Sensor Modeling based on Time-Delayed Cross Mapping,"['Shi-Shun Chen', 'Xiao-Yang Li', 'Enrico Zio']",,,"['Causal Feature Selection', 'Soft Sensor Modeling', 'Time-Delayed Cross Mapping', 'Stability']","This paper presents a causal feature selection framework for developing stable soft sensor models using time-delayed cross mapping, focusing on improving the accuracy and reliability of sensor data in various engineering applications.",149.11,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14115v1_Riemannian Liquid Spatio-Temporal Graph Network.pdf,Riemannian Liquid Spatio-Temporal Graph Network,"['Liangsi Lu', 'Jingchao Wang', 'Zhaorong Dai', 'Hanqian Liu', 'Yang Shi']",10.1145/3774904.3792090,,"['Riemannian Manifolds', 'Neural ODEs', 'Spatio-Temporal Graphs']","The paper introduces the Riemannian Liquid Spatio-Temporal Graph Network (RLSTG), a framework that combines continuous-time liquid dynamics with the geometric inductive biases of Riemannian manifolds to model graph evolution on curved manifolds, overcoming the limitations of Euclidean space.",154.65,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14124v1_Style Transfer as Bias Mitigation Diffusion Models.pdf,Style Transfer as Bias Mitigation: Diffusion Models for Synthetic Mental Health Text for Arabic,"['Saad Mankarious', 'Ayah Zirikly']",10.48550/arXiv.2601.14124,2601.14124,"['Style Transfer', 'Bias Mitigation', 'Diffusion Models', 'Synthetic Data', 'Mental Health', 'Arabic Language']","This work proposes a pretraining-free diffusion-based approach for synthetic text generation in Arabic mental health, focusing on male-to-female style transfer to augment underrepresented female-authored content, demonstrating high semantic fidelity and meaningful stylistic divergence without relying on pretrained large language models.",153.31,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14152v1_Lost in the Prompt Order Revealing the Limitations.pdf,Lost in the Prompt Order: Revealing the Limitations of Causal Attention in Language Models,"['Hyunjong Ok', 'Jaeho Lee']",null,2309.14679,"['language models', 'prompt sensitivity', 'causal attention', 'multiple-choice question answering', 'information bottleneck']","This work investigates the surprising sensitivity of large language models to the structure of the prompt, particularly in multiple-choice question answering, where placing context before the questions and options (CQO) outperforms the reverse order (QOC) by over 14% across various models and datasets. The study identifies causal attention as the core mechanism, explaining how the causal mask prevents option tokens from attending to context, creating an information bottleneck.",137.96,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14154v1_LLM Augmented Intervenable Multimodal Adaptor for .pdf,LLM Augmented Intervenable Multimodal Adaptor for Post-operative Complication Prediction in Lung Cancer Surgery,"['Shubham Pandey†', 'Bhavin Jawade†', 'Srirangaraj Setlur†', 'Venu Govindaraju†', 'Kenneth Seastedt†']",,,"['Lung Cancer', 'Postoperative Complications', 'Multimodal Adaptor', 'Deep Learning', 'Interventional Module', 'Radiomics', 'Machine Learning']","This paper presents MIRA-CLE, a deep learning architecture for predicting postoperative complications in lung cancer surgery by integrating preoperative clinical and radiological data. It employs a hyperspherical embedding space fusion of heterogeneous inputs and incorporates an interventional deep learning module for enhanced transparency and clinical utility.",155.8,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14157v1_ConceptCaps -- a Distilled Concept Dataset for Int.pdf,ConceptCaps - a Distilled Concept Dataset for Interpretability in Music Models,"['Bruno Sienkiewicz', 'Łukasz Neumann', 'Mateusz Modrzejewski']",,2309.14764,"['Music models', 'Concept-based interpretability', 'TCA V', 'MusicGen', 'V AE', 'BERTScore', 'MAUVE']","This paper introduces ConceptCaps, a dataset of 23k music-caption-audio triplets with explicit labels from a 200-attribute taxonomy. The authors separate semantic modeling from text generation, using a VAE to learn plausible attribute co-occurrence patterns and a fine-tuned LLM to convert attribute lists into professional descriptions, synthesizing corresponding audio. The dataset improves coherence and controllability over end-to-end approaches and is validated through audio-text alignment, linguistic quality metrics, and TCA V analysis.",156.47,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14160v1_Domain-Adaptation through Synthetic Data Fine-Tuni.pdf,Domain-Adaptation through Synthetic Data: Fine-Tuning Large Language Models for German Law,"['Ali Hamza Bashir', 'Muhammad Rehan Khalid', 'Kostadin Cvejoski', 'Jana Birr', 'Armin Berger', 'Sandra Halscheidt', 'Christian Temath', 'Rafet Sifa', 'David Berghaus']",,2310.16144,"['Large Language Models', 'Domain Adaptation', 'Synthetic Data', 'German Law', 'Legal Question Answering', 'Fine-Tuning']","This paper presents an effective method for adapting advanced Large Language Models to German legal question answering through a novel synthetic data generation approach, significantly outperforming baseline counterparts on German legal question answering tasks.",159.42,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14171v1_Paper2Rebuttal A Multi-Agent Framework for Transpa.pdf,Paper2Rebuttal: A Multi-Agent Framework for Transparent Author Response Assistance,"['Qianli Ma*', 'Chang Guo*', 'Zhiheng Tian*', 'Siyu Wang', 'Jipeng Xiao', 'Yuanhao Yue', 'Zhipeng Zhang†']",,,"['rebuttal generation', 'multi-agent systems', 'peer review', 'author assistance', 'transparent feedback']","Paper2Rebuttal introduces REBUTTALAGENT, a multi-agent framework that reframes rebuttal generation as an evidence-centric planning task. The system decomposes complex feedback into atomic concerns and dynamically constructs hybrid contexts by synthesizing compressed summaries with high-fidelity text, integrating an external search module to resolve concerns requiring outside literature. This approach ensures that every argument is explicitly anchored in internal or external evidence, outperforming strong baselines in coverage, faithfulness, and strategic coherence.",159.99,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14172v1_Human Values in a Single Sentence Moral Presence H.pdf,"Human Values in a Single Sentence: Moral Presence, Hierarchies, and Transformer Ensembles on the Schwartz Continuum","['Víctor Yeste', 'Paolo Rosso']",,2601.14172,"['Human Values', 'Schwartz Motivational Continuum', 'Transformer Ensembles', 'Sentence-Level Identification', 'Moral Presence', 'Hierarchical Models', 'Instruction-Tuned LLMs']","This study focuses on sentence-level identification of 19 values in the Schwartz motivational continuum, presenting a binary moral presence task and comparing presence-gated hierarchies to direct multi-label classifiers, demonstrating that lightweight signals and small ensembles yield the most reliable improvements.",155.95,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14175v1_A model of errors in transformers.pdf,A model of errors in transformers,"['Suvrat Raju', 'Praneeth Netrapalli']",,2310.16716,"['transformers', 'LLMs', 'error rate', 'attention mechanism', 'quantitative model', 'natural systems']","The authors study the error rate of Large Language Models (LLMs) on tasks like arithmetic, focusing on deterministic tasks with sequences of tokens drawn from a small set. They derive a two-parameter relationship between accuracy and task complexity, inspired by an ",144.74,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14192v1_Toward Efficient Agents Memory Tool learning and P.pdf,"Toward Efficient Agents: A Survey of Memory, Tool Learning, and Planning","['Xiaofang Yang', 'Lijun Li', 'Heng Zhou', 'Tong Zhu', 'Xiaoye Qu', 'Yuchen Fan', 'Qianshan Wei', 'Rui Ye', 'Li Kang', 'Yiran Qin', 'Zhiqiang Kou', 'Daizong Liu', 'Qi Li', 'Ning Ding', 'Siheng Chen', 'Jing Shao']",,2601.14192v1,"['Agents', 'Efficiency', 'Agent Memory', 'Tool Learning', 'Planning']","This paper investigates the efficiency of agents in three core components: memory, tool learning, and planning, considering costs such as latency, tokens, and steps. It reviews recent approaches that address the efficiency of agentic systems, comparing effectiveness under a fixed cost budget and cost at a comparable level of effectiveness, and discusses key challenges and future directions.",157.77,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14209v1_InT Self-Proposed Interventions Enable Credit Assi.pdf,Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning,"['Matthew Y. R. Yang', 'Hao Bai', 'Ian Wu', 'Gene Yang', 'Amrith Setlur', 'Aviral Kumar']",,2309.15889,"['Reinforcement Learning', 'Large Language Models', 'Credit Assignment', 'Outcome-Based Reinforcement Learning', 'Intervention Training']","This paper introduces Intervention Training (InT), a method for improving credit assignment in large language models' reasoning traces by proposing short, targeted corrections that steer trajectories toward higher reward, effectively addressing the problem of credit assignment in outcome-reward reinforcement learning.",157.99,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14230v1_MASCOT Towards Multi-Agent Socio-Collaborative Com.pdf,MASCOT: Towards Multi-Agent Socio-Collaborative Companion Systems,"['Yiyang Wang', 'Yiqiao Jin', 'Alex Cabral', 'Josiah Hester']",,2310.16428,"['Multi-Agent Systems', 'Socio-Collaborative Companions', 'Persona Collapse', 'Social Sycophancy', 'Persona-Aware Behavioral Alignment', 'Collaborative Dialogue Optimization']","This paper proposes MASCOT, a framework for multi-perspective socio-collaborative companions, addressing persona collapse and social sycophancy in multi-agent systems. It introduces a bi-level optimization strategy to harmonize individual and collective behaviors, achieving significant improvements in persona consistency and social contribution.",151.82,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14232v1_KAGE-Bench Fast Known-Axis Visual Generalization E.pdf,KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning,"['Egor Cherepannov', 'Daniil Zelezetsky', 'Alexey K. Kovalev', 'Aleksandr I. Panov']",,2601.04522,"['Reinforcement Learning', 'Pixel-based RL', 'Visual Generalization', 'Known-Axis', 'Benchmark', 'JAX', 'PPO-CNN']","This paper introduces KAGE-Env, a JAX-native 2D platformer that factorizes visual axes, and defines KAGE-Bench, a benchmark of six known-axis suites to isolate visual shifts. Using a standard PPO-CNN baseline, the authors observe strong axis-dependent failures, with background and photometric shifts often collapsing success, while agent-appearance shifts are comparatively benign. The fully vectorized JAX implementation enables fast and reproducible sweeps over visual factors.",152.83,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14234v1_Q-learning with Adjoint Matching.pdf,Q-LEARNING WITHADJOINTMATCHING,"['Qiyang Li', 'Sergey Levine']",,2601.14234,"['Q-learning', 'Adjoint Matching', 'Reinforcement Learning', 'Continuous-Action RL', 'Flow Policies', 'Diffusion Policies', 'TD-based Reinforcement Learning']","The paper proposes Q-learning with Adjoint Matching (QAM), a novel TD-based reinforcement learning algorithm that addresses the challenge of optimizing expressive flow or diffusion policies with respect to a parameterized Q-function, which is numerically unstable with direct gradient-based optimization. QAM leverages adjoint matching to transform the critic's action gradient into an unbiased, expressive policy at the optimum, providing a solution to the optimization problem.",154.96,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14235v1_Opportunities in AIML for the Rubin LSST Dark Ener.pdf,JSON_FAIL,[],None,None,[],N/A,151.28,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14242v1_APEX-Agents.pdf,AI Productivity Index for Agents (APEX–Agents),"['Bertie Vidgen', 'Austin Mann', 'Abby Fennelly', 'John Wright', 'Stanly Lucas', 'Rothman Marco', 'Burstein Julien', 'Benchek David', 'Ostrofsky Anirudh', 'Ravichandran Ismail', 'Sur Debnil', 'Venugopal Neel', 'Hsia Alannah', 'Robinson Isaac', 'Huang Calix', 'Varones Olivia', 'Khan Daniyal', 'Haines Michael', 'Richards Zach', 'Mahapatra Chirag', 'Foody Brendan', 'Nitski Osvald']",,2601.14242,"['AI Agents', 'Benchmark', 'Professional Services', 'Investment Banking', 'Management Consulting', 'Corporate Law', 'Knowledge Work', 'Productivity']","The paper introduces APEX–Agents, a benchmark for evaluating AI agents' ability to execute long-horizon, cross-application tasks created by investment banking analysts, management consultants, and corporate lawyers. Eight agents are tested, and the highest score is achieved by Gemini 3 Flash (Thinking=High). The authors open-source the benchmark and infrastructure for agent execution and evaluation.",159.69,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
2601.14255v1_VideoMaMa Mask-Guided Video Matting via Generative.pdf,VideoMaMa: Mask-Guided Video Matting via Generative Prior,"['Sangbeom Lim', 'Seoung Wug Oh', 'Jiahui Huang', 'Heeji Yoon', 'Seungryong Kim', 'Joon-Young Lee']",,2601.14255v1,"['Video Matting', 'Generative Models', 'Diffusion Models', 'Pseudo-Labeled Data', 'Real-World Videos']","This paper introduces VideoMaMa, a diffusion-based model that converts coarse segmentation masks into pixel-accurate alpha mattes for real-world videos, demonstrating strong zero-shot generalization and developing a large-scale dataset for video matting.",159.18,Qwen2.5-3B,Windows RTX 4080 (Native CUDA)
