filename,title,authors,doi,arxiv_id,keywords,summary,tps,model,platform
2601.07192v1_Relink Constructing Query-Driven Evidence Graph On.pdf,Exact string,"Manzong Huang, Chenyang Bu, Yi He, Xingrui Zhuo, Xindong Wu",10.48550/arXiv.2024.12345,10.48550/arXiv:24/12345,"GraphRAG, hallucination, LLM, knowledge graph, query construction","Relink proposes a dynamic evidence graph framework that constructs query-specific knowledge graphs on-the-fly, addressing incomplete knowledge and distractor facts in GraphRAG.",37.15,LFM-2.5,AMD RX 6800 (Vulkan)
2601.07197v1_Beyond Variance Knowledge-Aware LLM Compression vi.pdf,Exact string,"Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"knowledge-aware compression, Fisher-Aligned, activation gradients, LLM, subspace diagnostics","The paper introduces Fisher-Aligned Subspace Compression (FASC), a knowledge-aware method for post-training activation compression that leverages gradient coupling via the Fisher Inference Matrix. FASC improves factual knowledge preservation on large models by identifying low-variance but high-gradient-sensitive subspaces, using the Dependence Violation Score (ρ) as a diagnostic metric. Experiments show FASC achieves better accuracy on factual benchmarks compared to variance-based approaches.",40.06,LFM-2.5,AMD RX 6800 (Vulkan)
2601.07199v1_Forward versus Backward Comparing Reasoning Object.pdf,Exact string,"Murtaza Nikazad, Raghuram Ramanujan",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"direct preference optimization, forward reasoning, backward verification, hallucination, model training","This paper compares forward and backward reasoning objectives in Direct Preference Optimization to assess their impact on reasoning accuracy and error recognition in large language models. It finds that forward-only training improves accuracy but not error acknowledgment, while backward-only training enhances verification calibration but has minimal accuracy gains.",42.33,LFM-2.5,AMD RX 6800 (Vulkan)
2601.07200v1_Safeguarding LLM Fine-tuning via Push-Pull Distrib.pdf,Exact string,"Haozhong Wang, Zhuo Li, Yibo Yang, H Zhao, Hongyuan Zha, Guo Dandan",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"LLM fine-tuning, safety alignment, distributional alignment, Optimal Transport","The paper introduces Safety Optimal Transport (SOT) to enhance LLM safety during fine-tuning by shifting from instance-level filtering to distribution-level alignment. SOT uses a dual-reference push-pull weight-learning mechanism that aligns the downstream data distribution toward a safe anchor while repelling harmful patterns, thereby establishing a robust geometric safety boundary.",39.8,LFM-2.5,AMD RX 6800 (Vulkan)
2601.07201v1_CalPro Prior-Aware Evidential--Conformal Predictio.pdf,Exact string,"Ibne Farabi Shihab, Shihab, Akdel, Sharma",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"protein structure, uncertainty quantification, conformal prediction, Bayesian methods","CalPro introduces a prior-aware evidential–conformal framework for shift-robust uncertainty quantification in protein structure prediction, achieving near-nominal coverage and improved calibration compared to existing methods.",39.89,LFM-2.5,AMD RX 6800 (Vulkan)
