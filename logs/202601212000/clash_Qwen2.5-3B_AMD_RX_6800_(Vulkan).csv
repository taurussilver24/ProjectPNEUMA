filename,title,authors,doi,arxiv_id,keywords,summary,tps,model,platform
2601.07192v1_Relink Constructing Query-Driven Evidence Graph On.pdf,Relink: Constructing Query-Driven Evidence Graph On-the-Fly for GraphRAG,"Manzong Huang, Chenyang Bu, Yi He, Xingrui Zhuo, Xindong Wu",Not found,Not found,"Graph-based Retrieval-Augmented Generation, Large Language Models, Knowledge Graph, Query-Driven Evidence Graph, Incompleteness, Distractor Facts","Graph-based Retrieval-Augmented Generation (GraphRAG) mitigates hallucinations in Large Language Models (LLMs) by grounding them in structured knowledge. However, current GraphRAG methods are constrained by a static, pre-constructed Knowledge Graph (KG) paradigm, which faces challenges of incomplete reasoning paths and misleading distractor facts. Relink proposes a reason-and-construct paradigm and a framework that dynamically builds a query-specific evidence graph, instantiating required facts from a latent relation pool and employing a unified, query-aware evaluation strategy to handle incompleteness and misleading facts, achieving significant improvements in open-domain question answering benchmarks.",27.56,Qwen2.5-3B,AMD RX 6800 (Vulkan)
2601.07197v1_Beyond Variance Knowledge-Aware LLM Compression vi.pdf,Beyond Variance: Knowledge-Aware LLM Compression via Fisher-Aligned Subspace Diagnostics,"Ibne Farabi Shihab*, Sanjeda Akter*, Anuj Sharma",,,"Large Language Models, Knowledge Compression, Transformer Architectures, Fisher Information Matrix, Activation-Gradient Coupling","Post-training activation compression is essential for deploying Large Language Models on resource-constrained hardware. Standard methods like Singular Value Decomposition (SVD) are gradient-blind, preserving high-variance dimensions regardless of their impact on factual knowledge preservation. This paper introduces Fisher-Aligned Subspace Compression (FASC), a knowledge-aware compression framework that selects subspaces by directly modeling activation-gradient coupling, minimizing a second-order surrogate of the loss function. FASC leverages the Fisher Information Matrix to identify dimensions critical for factual knowledge, often residing in low-variance but high-gradient-sensitivity subspaces. The Dependence Violation Score (ρ) is proposed as a general-purpose diagnostic metric to quantify activation-gradient coupling, revealing where factual knowledge is stored within transformer architectures. Extensive experiments on Mistral-7B and Llama-3-8B demonstrate that FASC preserves 6-8% more accuracy on knowledge-intensive benchmarks (MMLU, LAMA) compared to variance-based methods at 50% rank reduction, effectively enabling a 7B model to match the factual recall of a 13B uncompressed model. The analysis reveals that ρ serves as a fundamental signal of stored knowledge, with high-ρ layers emerging only when models internalize factual associations during training.",28.78,Qwen2.5-3B,AMD RX 6800 (Vulkan)
2601.07199v1_Forward versus Backward Comparing Reasoning Object.pdf,Forward versus Backward: Comparing Reasoning Objectives in Direct Preference Optimization,"Murtaza Nikazad, Raghuram Ramanujan",Not found,Not found,"Large language models, Reasoning, Direct Preference Optimization, Forward reasoning, Backward verification","This paper investigates the effect of training objective composition on reasoning reliability through Direct Preference Optimization, comparing forward chain-of-thought generation and backward verification training signals.",26.84,Qwen2.5-3B,AMD RX 6800 (Vulkan)
2601.07200v1_Safeguarding LLM Fine-tuning via Push-Pull Distrib.pdf,Safeguarding LLM Fine-tuning via Push-Pull Distributional Alignment,"Haozhong Wang, Zhuo Li, Yibo Yang, He Zhao, Hongyuan Zha, Dandan Guo",,,"Large Language Models, Fine-tuning, Safety Alignment, Optimal Transport, Push-Pull Mechanism, Data Distribution, Harmful Patterns","The paper introduces Safety Optimal Transport (SOT), a novel framework that reframes safe fine-tuning from an instance-level filtering challenge to a distribution-level alignment task grounded in Optimal Transport (OT). SOT optimizes sample importance by actively pulling the downstream distribution towards a trusted safe anchor while simultaneously pushing it away from a general harmful reference, establishing a robust geometric safety boundary that effectively purifies the training data. Extensive experiments demonstrate that SOT significantly enhances model safety while maintaining competitive downstream performance.",27.2,Qwen2.5-3B,AMD RX 6800 (Vulkan)
2601.07201v1_CalPro Prior-Aware Evidential--Conformal Predictio.pdf,CalPro: Prior-Aware Evidential–Conformal Prediction with Structure-Aware Guarantees for Protein Structures,"Ibne Farabi Shihab * 1, Sanjeda Akter * 1, Anuj Sharma 2",,2601.03457,"protein structure prediction, uncertainty quantification, conformal prediction, deep learning, graph-based architecture","A prior-aware evidential-conformal framework for shift-robust uncertainty quantification in protein structure prediction, combining geometric evidential head, differentiable conformal layer, and domain priors (disorder, flexibility). Empirically, it achieves ≤5% coverage degradation across modalities, reduces calibration error by 30–50%, and improves downstream ligand-docking success by 25%.",27.01,Qwen2.5-3B,AMD RX 6800 (Vulkan)
2601.07206v1_LLMRouterBench A Massive Benchmark and Unified Fra.pdf,LLMRouterBench: A Massive Benchmark and Unified Framework for LLM Routing,"Hao Li*, Yiqun Zhang*, Zhaoyan Guo*, Chenxu Wang*, Shengji Tang, Qiaosheng Zhang, Yang Chen, Biqing Qi, Peng Ye, Lei Bai, Zhen Wang†, Shuyue Hu†",Not found,Not found,"Large language models, routing, benchmark, evaluation, performance-cost trade-off","LLMRouterBench is a large-scale benchmark and unified framework for LLM routing, comprising over 400K instances from 21 datasets and 33 models. It provides comprehensive metrics for both performance-oriented and performance-cost trade-off routing, integrating 10 representative routing baselines. The framework confirms strong model complementarity and highlights the limitations of recent routing methods, particularly in reliable performance outperformance and persistent model-recall failures. It also demonstrates the impact of backbone embedding models and the diminishing returns of larger ensembles compared to careful model curation. The benchmark enables latency-aware analysis and is available at https://github.com/ynulihao/LLMRouterBench.",28.08,Qwen2.5-3B,AMD RX 6800 (Vulkan)
2601.07209v1_SIRR-LMM Single-image Reflection Removal via Large.pdf,SIRR-LMM: Single-image Reflection Removal via Large Multimodal Model,"Yu Guo, Zhiqiang Lao, Xiyun Song, Yubin Zhou, Heather Yu",,,"reflection removal, single-image, large multimodal model, path tracing, 3D glass models, HDR environment maps","Introduces a synthetic dataset generation framework that path-traces 3D glass models over real background imagery to create physically accurate reflection scenarios, and leverages the capabilities of Large Multimodal Model (LMM) for improved reflection removal and separation performance.",27.35,Qwen2.5-3B,AMD RX 6800 (Vulkan)
2601.07214v1_BlindU Blind Machine Unlearning without Revealing .pdf,BlindU: Blind Machine Unlearning without Revealing Erasing Data,"Weiqi Wang, Zhiyi Tian, Chenhao Zhang, Shui Yu",Not found,Not found,"Machine Unlearning, Federated Learning, Privacy Leakage, Privacy Preserving, Information Bottleneck","Proposes a method for machine unlearning that does not require the unlearning requesters to upload their data to the server, thus protecting privacy in scenarios where servers are prohibited from accessing users' data, such as federated learning.",26.67,Qwen2.5-3B,AMD RX 6800 (Vulkan)
2601.07224v1_Consolidation or Adaptation PRISM Disentangling SF.pdf,Consolidation or Adaptation? PRISM: Disentangling SFT and RL Data via Gradient Concentration,"Yang Zhao, Yangou Ouyang, Xiao Ding, Hepeng Wang, Bibo Cai, Jinglong Gao, Zhouhao Sun, Li Du, Bing Qin, Ting Liu",Not provided,Not provided,"Schema Theory, Hybrid Supervised Fine-Tuning, Reinforcement Learning, Data Arbitration, Gradient Concentration, Pattern Consolidation, Structural Adaptation","PRISM is a dynamics-aware framework that arbitrates data based on its degree of cognitive conflict with the model's existing knowledge. By analyzing the spatial geometric structure of gradients, PRISM identifies data triggering high spatial concentration as high-conflict signals that require RL for structural restructuring, while data yielding diffuse updates is routed to SFT for efficient consolidation. Extensive experiments on WebShop and ALFWorld demonstrate that PRISM achieves a Pareto improvement, outperforming state-of-the-art hybrid methods while reducing computational costs by up to 3.22 ×. The findings suggest that disentangling data based on internal optimization regimes is crucial for scalable and robust agent alignment.",29.09,Qwen2.5-3B,AMD RX 6800 (Vulkan)
2601.07226v1_Lost in the Noise How Reasoning Models Fail with C.pdf,Lost in the Noise: How Reasoning Models Fail with Contextual Distractors,"Seongyun Lee, Yongrae Jo, Minju Seo, Moontae Lee, Minjoon Seo",,,"reasoning models, agentic AI, external tools, robustness, contextual distractors, emergent misalignment","Recent advances in reasoning models and agentic AI systems have led to an increased reliance on diverse external information. However, this shift introduces input contexts that are inherently noisy, a reality that current benchmarks fail to capture. We introduce NoisyBench, a comprehensive benchmark that systematically evaluates model robustness across 11 datasets in RAG, reasoning, alignment, and tool-use tasks against diverse noise types, including random documents, irrelevant chat histories, and hard negative distractors. Our evaluation reveals a catastrophic performance drop of up to 80% in state-of-the-art models when faced with contextual distractors. Crucially, we find that agentic workflows often amplify these errors by over-trusting noisy tool outputs, and distractors can trigger emergent misalignment even without adversarial intent.",28.98,Qwen2.5-3B,AMD RX 6800 (Vulkan)
2601.07229v2_DiSCo Making Absence Visible in Intelligent Summar.pdf,DiSCo: Making Absence Visible in Intelligent Summarization Interfaces,"ERAN FAINMAN, University of Haifa, Israel, HAGIT BEN SHOSHAN, University of Haifa, Israel, ADIR SOLOMON, University of Haifa, Israel, OSNAT MOKRYN, University of Haifa, Israel",,,"Review Summarization, Absence, Expectations, Learning via surprisability, Missing commonalities","Intelligent interfaces increasingly use large language models to summarize user-generated content, yet these summaries emphasize what is mentioned while overlooking what is missing. This presence bias can mislead users who rely on summaries to make decisions. We present Domain Informed Summarization through Contrast (DiSCo), an expectation-based computational approach that makes absences visible by comparing each entity’s content with domain topical expectations captured in reference distributions of aspects typically discussed in comparable accommodations. This comparison identifies aspects that are either unusually emphasized or missing relative to domain norms and integrates them into the generated text. In a user study across three accommodation domains, namely ski, beach, and city center, DiSCo summaries were rated as more detailed and useful for decision making than baseline large language model summaries, although slightly harder to read. The findings show that modeling expectations reduces presence bias and improves both transparency and decision support in intelligent summarization interfaces.",29.63,Qwen2.5-3B,AMD RX 6800 (Vulkan)
2601.07232v1_Yes FLoReNce I Will Do Better Next Time Agentic Fe.pdf,Agentic Feedback Reasoning for Humorous Meme Detection,"Olivia Shanhong Liu, Pai Chet Ng, De Wen Soh, Konstantinos N. Plataniotis",Not found,Not found,"humorous memes, agentic feedback, closed-loop reasoning, open-loop inference, prompting, multimodal","This paper proposes FLoReNce, an agentic feedback reasoning framework for detecting meme humor. It treats meme understanding as a closed-loop process during learning and an open-loop process during inference, enabling better, self-aligned reasoning without finetuning. FLoReNce improves predictive performance and explanation quality over static multimodal baselines on the PrideMM dataset.",26.33,Qwen2.5-3B,AMD RX 6800 (Vulkan)
2601.07233v1_From Thinking to Justifying Aligning High-Stakes E.pdf,Thinking” to “Justifying”: Aligning High-Stakes Explainability with Professional Communication Standards,"Chen Qian, Yimeng Wang, Yu Chen, Lingfei Wu, Andreas Stathopoulos",,,"explainable AI, Chain-of-Thought, professional communication, legal writing, high-stakes domains","Explainable AI in high-stakes domains should help stakeholders trust and verify system outputs. The paper proposes 'Result → Justify', which constrains the output communication to present a conclusion before its structured justification. SEF operationalizes professional conventions via six metrics for structure and grounding, validating this approach across four tasks in three domains.",27.01,Qwen2.5-3B,AMD RX 6800 (Vulkan)
2601.07238v1_Group Pattern Selection Optimization Let LRMs Pick.pdf,Group Pattern Selection Optimization: Let LRMs Pick the Right Pattern for Reasoning,"Hanbin Wang, Jingwei Song, Jinpeng Li, Fei Mi, Lifeng Shang",,,"Large reasoning models, reinforcement learning, pattern selection, mathematics, science, reasoning patterns","A reinforcement learning framework called GPSO is introduced to optimize the reasoning patterns of large reasoning models, addressing the sub-optimality of default patterns and fostering more robust and adaptable reasoning.",26.62,Qwen2.5-3B,AMD RX 6800 (Vulkan)
2601.07239v1_Stochastic CHAOS Why Deterministic Inference Kills.pdf,"Stochas(c CHAOS: Why Determinis(c Inference Kills, and Distribu(onal Variability Is the Heartbeat of Ar(ﬁcial Cogni(on","Tanmay Joshi1, Shourya Aggarwal1, Anusa Saha1, Aadi Pandey1, Shreyash Dhoot1, Vighnesh Rai1, Raxit Goswami2, Aman Chadha3, Vinija Jain4, Amitava Das1",Not found,Not found,"Large Language Models, Reproducibility, Distributio(nal Variability, Stochasticity, Emergent Abilities, Reasoning, Safety Alignment","This paper argues against deterministic inference in large language models (LLMs), claiming it kills the ability to model uncertainty, makes emergent abilities vanish, disrupts reasoning abilities, and renders safety alignment brittle. The authors advocate for stochastic CHAOS, arguing that distributional variability is the heart of artificial cognition. They present empirical evidence showing that deterministic inference is systematically misleading in various aspects of LLMs.",27.44,Qwen2.5-3B,AMD RX 6800 (Vulkan)
