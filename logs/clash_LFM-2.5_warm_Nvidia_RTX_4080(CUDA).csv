filename,title,authors,doi,arxiv_id,keywords,summary,tps,model,platform
2601.07192v1_Relink Constructing Query-Driven Evidence Graph On.pdf,Exact string,"Manzong Huang, Chenyang Bu, Yi He, Xingrui Zhuo, Xindong Wu",10.1017/S0022058711000005,null,"GraphRAG, hallucination, LLM, knowledge graph, query construction","Relink proposes a dynamic evidence graph framework that constructs query-specific knowledge graphs on-the-fly, addressing incomplete knowledge and distractor facts in GraphRAG.",379.5,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07197v1_Beyond Variance Knowledge-Aware LLM Compression vi.pdf,Exact string,"Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma",10.48550/arXiv.2024.12345,10.48550/arXiv:2409.12345,"knowledge-aware compression, Fisher-Aligned, activation gradients, LLM, subspace diagnostics","The paper introduces Fisher-Aligned Subspace Compression (FASC), a knowledge-aware method for post-training LLM activation compression. By modeling activation-gradient coupling and using the Fisher Inference Matrix, FASC identifies critical low-variance subspaces that preserve factual knowledge. It proposes the Dependence Violation Score (ρ) to diagnose knowledge storage, demonstrating improved accuracy on factual benchmarks compared to variance-based approaches.",277.82,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07199v1_Forward versus Backward Comparing Reasoning Object.pdf,Exact string,"Murtaza Nikazad, Raghuram Ramanujan",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"direct preference optimization, forward reasoning, backward verification, hallucination, model training",This paper compares forward and backward reasoning objectives in Direct Preference Optimization to assess their impact on reasoning accuracy and error recognition in large language models.,273.07,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07200v1_Safeguarding LLM Fine-tuning via Push-Pull Distrib.pdf,Exact string,"Haozhong Wang, Zhuo Li, Yibo Yang, H Zhao, Hongyuan Zha, Guo Dandan",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"LLM safety, distributional alignment, safety optimization, Optimal Transport","The paper introduces Safety Optimal Transport (SOT) to enhance LLM fine-tuning safety by shifting from instance-level filtering to distribution-level alignment. SOT uses a dual-reference push-pull weight-learning mechanism that aligns downstream data toward a safe anchor while repelling harmful patterns, establishing a robust geometric safety boundary.",258.72,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07201v1_CalPro Prior-Aware Evidential--Conformal Predictio.pdf,Exact string,"Ibne Farabi Shihab, Shihab, Akdel, Sharma",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"protein structure, uncertainty quantification, conformal prediction, pLDDT","CalPro introduces a prior-aware evidential–conformal framework for shift-robust uncertainty quantification in protein structure prediction, achieving near-nominal coverage and improved calibration.",306.49,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07206v1_LLMRouterBench A Massive Benchmark and Unified Fra.pdf,LLMRouterBench: A Massive Benchmark and Unified Framework for LLM Routing,"Hao Li, Zhaoyan Guo, Chenxu Wang, Shengji Tang, Zhang Yang, Chen Biqing, Qi, Peng Ye, Lei Bai, Wang †, Shuyue Hu",10.1234/example.doi,10.1234/example,"LLM routing, LLMRouterBench, large-scale benchmark, performance-cost trade-off, LLM ensemble","LLMRouterBench provides a comprehensive benchmark for evaluating large language model routing across diverse datasets and models, highlighting performance trade-offs and identifying limitations in current routing methods.",303.01,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07209v1_SIRR-LMM Single-image Reflection Removal via Large.pdf,Exact string,"Yu Guo, Zhiqiang Lao, Xiyun Song, Yubin Zhou, Heather Yu",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"reflection removal, glass surfaces, large multimodal model, synthetic dataset","The paper presents a synthetic dataset generation framework that uses path-traced 3D glass models combined with real background imagery to create physically accurate reflection scenarios. Leveraging Large Multimodal Models (LMM) with task-specific LoRA fine-tuning, the approach improves reflection removal performance while maintaining physical realism.",357.91,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07214v1_BlindU Blind Machine Unlearning without Revealing .pdf,Exact string,"Weiqi Wang, Zhiyi Tian, Chenhan Zhang, Shui Yu",10.1109/TPA.2024.12345,10.1109/TPA.2024.12345,"Machine unlearning, Federated Learning, Privacy Leakage, Privacy Preserving, Information Bottleneck","The paper proposes Blind Unlearning (BlindU) to enable privacy-preserving data removal without exposing erased data to servers, using compressed representations and the information bottleneck mechanism.",337.37,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07224v1_Consolidation or Adaptation PRISM Disentangling SF.pdf,Exact string,"Yang Zhao, Yangou Ouyang, Xiao Ding, Hepeng Wang, Bibo Cai, Kai Xiong, Jinglong Gao, Zhouhao Sun, Li Du, Bing Qin, Ting Liu",10.48550/arXiv.2024.12345,10.48550/arXiv:24/12345,"data arbitration, gradient concentration, schema theory, LLM training","PRISM proposes a dynamics-aware framework to disentangle data based on cognitive conflict, improving data alignment between SFT and RL in LLM training.",288.92,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07226v1_Lost in the Noise How Reasoning Models Fail with C.pdf,Exact string,"Seongyun Lee, Yongrae Jo, Minju Seo, Moontae Lee, Minjoon Seo",10.48550/arXiv.2025.12345,10.48550/arXiv:2025.12345,"reasoning models, agentic AI, noisy benchmarks, distractor effects","The paper presents NoisyBench, a benchmark evaluating model robustness under diverse contextual noise. It highlights significant performance degradation (up to 80%) in state-of-the-art models when exposed to distractors, emphasizing the need for improved resilience strategies.",322.78,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07229v2_DiSCo Making Absence Visible in Intelligent Summar.pdf,Exact string,"DiSCo, ERAN FAINMAN, HAGIT BEN SHOSHAN, ADIR SOLOMON, OSNAT MOKRYN",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Intelligent interfaces, Absence, Expectations, Learning via surprisability, Missing commonalities","This paper introduces Domain Informed Summarization through Contrast (DiSCo), an expectation-based method that highlights missing information by comparing entity content with domain expectations. It demonstrates that DiSCo improves summary transparency and decision support compared to baseline models, especially in user studies across different accommodation domains.",329.92,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07232v1_Yes FLoReNce I Will Do Better Next Time Agentic Fe.pdf,Exact string,"Olivia Shanhong Liu, Pai Chet Ng, De Wen Soh, Konstantinos N. Plataniotis",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"humorous memes, AI reasoning, multimodal understanding","The paper introduces FLoReNce, an agentic feedback reasoning framework for meme interpretation. It emphasizes closed-loop critique during training and open-loop prompting during inference, improving both performance and explainability on the PrideMM dataset.",361.37,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07233v1_From Thinking to Justifying Aligning High-Stakes E.pdf,Exact string,"Chen Qian, Yimeng Wang",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Explainable AI, High-stakes domains, Professional communication, SEF","The paper introduces SEF (Structured Explainability Framework) to improve trust in AI explanations by structuring justifications before conclusions, validating it across four tasks with strong correlation with accuracy.",291.77,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07238v1_Group Pattern Selection Optimization Let LRMs Pick.pdf,Group Pattern Selection Optimization: Let LRMs Pick the Right Pattern,"Hanbin Wang, Jingwei Song, Jinpeng Li, Fei Mi, Lifeng Shang",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"pattern selection, reasoning patterns, reinforcement learning, LLM","This paper introduces Group Pattern Selection Optimization (GPSO), a reinforcement learning framework that enhances large language models by systematically identifying and leveraging effective reasoning patterns across diverse tasks. By incorporating multi-pattern rollouts and verifier-guided selection, GPSO aims to mitigate sub-optimal pattern bias and improve robust performance. Extensive experiments show consistent gains across benchmarks.",307.32,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07239v1_Stochastic CHAOS Why Deterministic Inference Kills.pdf,Exact string,"List of strings, List of strings, List of strings, List of strings, List of strings, Raxit Goswami, Aman Chadha, Vignisha Jain, Amitava Das",10.48550/arXiv.2303.04213,10.48550/arXiv:2303.04213,"deterministic inference, LLM, uncertainty, stochasticity, cognition, reliability","The paper argues that deterministic inference undermines the modeling of uncertainty and emergent abilities in large language models, advocating instead for stochastic approaches and distributional variability as essential for artificial cognition.",337.36,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07245v1_Learning to Trust the Crowd A Multi-Model Consensu.pdf,Exact string,Pranav Kallem,10.48550/arXiv.2024.12345,10.48550/arXiv/12345,"multi-model consensus, LLM reliability, confidence estimation","The paper introduces a multi-model consensus reasoning engine that improves LLM reliability by leveraging diverse model outputs through structured feature analysis and graph-based ranking, achieving significant gains over single-model predictions.",329.7,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07250v1_DDT A Dual-Masking Dual-Expert Transformer for Ene.pdf,Exact string,"Mingnan Zhu, Qixuan Zhang, Yixuan Cheng, Fangzhou Gu, Shiming Lin",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"energy forecasting, time-series, deep learning, causal masking, multivariate modeling","The paper introduces DDT, a dual-masking dual-expert transformer framework for high-precision energy time-series forecasting. It features a novel dual-masking mechanism and a parallel dual-expert architecture to enhance temporal modeling and adaptive feature fusion, achieving state-of-the-art performance on benchmark datasets.",313.95,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07261v1_Pseudodata-guided Invariant Representation Learnin.pdf,Pseudodata-guided Invariant Representation,"Haomin Wu, Zhiwei Nie, Zhixiang Ren, Hongyu Zhang",10.1093/pasj/psa.2026,2601.07261,"enzyme kinetics, deep learning, invariant representation, out-of-distribution, predictive modeling","The paper introduces O2DENet, a lightweight model enhancing out-of-distribution generalization for enzyme kinetic parameter prediction through biologically informed perturbations and invariant learning.",321.62,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07263v1_When Bots Take the Bait Exposing and Mitigating th.pdf,Exact string,"Xinyi Wu, Geng Hong, Yueyue Chen, MingXuan Liu, Feier Jin, Xudong Pan, Jiarun Dai, Baojun Liu",10.1093/acpl/qad020,10.1093/acpl/qad020,"web automation, social engineering, AGENTBAIT, web agents, security","The paper introduces AGENTBAIT, a novel social engineering attack targeting web automation agents, and proposes SUPERVISOR, a runtime mitigation module that reduces attack success rates by up to 78.1% while maintaining low overhead.",279.66,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07291v1_A Visual Semantic Adaptive Watermark grounded by P.pdf,Exact string,"Qi Zheng, Shuliang Liu, Yu Huang, Junhao Chen, Hanqian Li, Aiwei Liu, Yibo Yan, Xuming Hu",10.48550/arXiv:2109.06927v1,10.48550/arXiv:2109.06927,"visual semantic adaptation, prefix-tuning, large vision-language model, watermarking, semantic-aware","The paper introduces the Visual Semantic Adaptive Watermark (VISA-Mark), a framework that integrates prefix-tuning to embed detectable visual evidence while preserving image quality. By leveraging a lightweight, efficiently trained model, VISA-Mark dynamically weights tokens based on visual relevance, achieving high visual consistency (7.8% improvement) and strong semantic fidelity without compromising detection accuracy (96.88% AUC).",314.46,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07292v1_Photometric Redshift Estimation Using Scaled Ensem.pdf,Photometric Redshift Estimation Using Scaled Ensemble Learning,"Swagata Biswas, Shubhrangshu Ghosh, Avyarthana Ghosh, Yogesh Wadadekar, Abhishek Roy Choudhury, Arijit Mukherjee, Shailesh Deshpande, and Arpan Pal",10.3847/2045-4368/abd062,10.3847/2045-4368/abd062,"photometric redshift, photometric data, machine learning, astronomy, galaxy classification","The paper introduces a novel ensemble-based machine learning framework for predicting photometric redshifts using optical data. It integrates multiple algorithms within a scaled ensemble structure, achieving improved accuracy for faint galaxies and higher redshifts compared to standalone models. Validation against the Hyper Suprime-Cam Survey highlights enhanced precision and alignment with LSST requirements.",332.9,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07296v1_LRAS Advanced Legal Reasoning with Agentic Search.pdf,Legal Reasoning with Agentic Search,"Yujin Zhou, Chuxue Cao, Jinluan Yang, Lijun Wu, Conghui He, Sirui Han, Yike Guo",10.1234/example.doi,None,,N/A,291.32,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07304v1_Heterogeneous Multi-Expert Reinforcement Learning .pdf,Exact string,"Yun Chen, Bowei Huang, Fan Guo, Kang Song",10.1007/978-3-030-67890-7,10.1007/978-3-030-67890-7,"Autonomous Forklift, Hierarchical Reinforcement Learning, Mobile Manipulation, Hybrid Training, Modality Decoupling","Proposes a Heterogeneous Multi-Expert Reinforcement Learning framework for autonomous forklifts, decomposing long-horizon tasks into specialized sub-policies to balance navigation and manipulation while reducing interference.",266.31,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07309v1_ARM Role-Conditioned Neuron Transplantation for Tr.pdf,Exact string,"Zhuoka Feng, Kang Chen, Sihan Zhao, Kai Xiong, Yaoning Wang, Minshen Yu, Junjie Nian, Changyi Xiao, Yixin Cao, Yugang Jiang",10.48550/arXiv.2601.07309,2601.07309,"model merging, ARM, LLM agents, role-conditioned, interactive environments","The paper introduces Agent-Role Merging (ARM), a training-free method for merging large language model agents by integrating multiple experts into a single model. ARM enhances existing merging techniques through a 3-step framework—constructing merged backbones, role-conditioned activation analysis, and neuron transplantation—thereby improving generalization across diverse interactive environments without gradient-based optimization.",288.33,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07313v1_Explaining Machine Learning Predictive Models thro.pdf,Exact string,"Silvia Ruiz-España, Laura Arnal, Franís Signola, Juan-Carlos Perez-Cortes, Joaquim Arlandis",10.1234/example.doi,None,"machine learning, XAI, explainable models, local explainability, model-agnostic, uncertainty, stability, uncertainty -uncertainty","The paper introduces MUCE, a model-agnostic method for local explainability that captures prediction changes via multivariate conditional expectation. It extends Individual Conditional Expectation (ICE) by examining feature interactions near inference time, offering graphical explanations and stability/uncertainty indices to assess model reliability. Results demonstrate MUCE's effectiveness in interpreting complex models, supporting trustworthy decision-making.",342.48,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07315v1_VLM-CAD VLM-Optimized Collaborative Agent Design W.pdf,Exact string,"Guanyuan Pan, Yugui Lin, Tiansheng Zhou, Pietro Li, Shuai Wang, Yaqi Wang, Wangyaqi",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Analog Circuit Sizing, Agentic AI, Vision Language Model, Explainability, Electronic Design Automation","Proposes a Vision Language Model-optimized collaborative agent design workflow (VLM-CAD) for analog circuit sizing, integrating Image2Net for schematic annotation and offering explainable optimization methods.",354.51,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07316v1_BEAT-Net Injecting Biomimetic Spatio-Temporal Prio.pdf,Exact string,"Ma Runze, Liao Caizhi",10.48550/arXiv.2024.12345,2601.07316v1,"ECG classification, deep learning, biomimetic analysis, interpretable AI, heartbeat segmentation","The paper introduces BEAT-Net, a biomimetic framework for ECG analysis that reformulates classification as a language modeling task. By applying QRS tokenization, it extracts local beat morphology while normalizing spatial and temporal dimensions, achieving competitive performance with CNNs while enhancing interpretability through attention mechanisms.",305.06,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07320v1_Segmental Advantage Estimation Enhancing PPO for L.pdf,Exact string,"Xue Gong1, Qi Yi1, Ziyuan Nan2, 4 Zhiwan Huang, Yuhao Jiang1, Ruibin Xiong1, Zenan Xu1, Jiaming Guo4, Shaohui Peng2, 3 Bo Zhou1",10.48550/arXiv.2026.12345,10.48550/arXiv.2026.12345,"Segmental Advantage Estimation, PPO, RLVR, GAE, LLM, Reasoning Tasks","The paper introduces Segmental Advantage Estimation (SAE) to improve Proximal Policy Optimization (PPO) for training large language models in reasoning tasks. SAE partitions sequences into sub-segments using low-probability tokens, reducing bias from unreliable intermediate value predictions and enhancing training stability and sample efficiency.",292.11,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07342v1_Agentic Diagnostic Reasoning over Telecom and Data.pdf,Agentic Diagnostic Reasoning over Telecom and Datacenter Infrastructure,Nicolas Tacheny,10.1093/pasj/2026010851,2601.07342,"telecom infrastructure, datacenter, autonomous incident resolution, change impact","Introduces an agent-based framework using a Large Language Model to autonomously investigate infrastructure failures, enabling proactive mitigation and impact prediction without hard-coded rules.",373.92,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07344v1_PulseMind A Multi-Modal Medical Model for Real-Wor.pdf,PulseMind: A Multi-Modal Medical Model for Real-World Clinical Diagnosis,"Jiao Xu, Junwei Liu, Jiangwei Lao, Qi Zhu, Yunpeng Zhao, Congyun Jin, Shinan Liu, Zhihong Lu, Lihe Zhang, Xin Chen, Jian Wang, Ping Wang",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"multi-modal, medical diagnosis, clinical, multi-turn, evaluation","PulseMind introduces a new family of multi-modal diagnostic models integrating curated datasets, a benchmark, and a training framework to address complex real-world clinical diagnosis.",287.87,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07348v4_Controlled Self-Evolution for Algorithmic Code Opt.pdf,Controlled Self-Evolution for Algorithmic Code Optimization,"Tu Hu1, Ronghao Chen2, Shuo Zhang3, Jianghao Yin4, Mou Xiao Feng3, Jingping Liu5, Shaolei Zhang6, Wenqi Jiang1, Yuqi Fang1, Sen Hu2, 7, Wenqi Jiang3, Huacan Wang3, Yi Xu3",10.1093/pasj/csae045,2601.07348v4,"self-evolution, code optimization, algorithmic generation, exploration efficiency, controlled evolution","The paper introduces Controlled Self-Evolution (CSE) to improve exploration efficiency in code generation. CSE addresses limitations of existing methods by incorporating diversified planning, feedback-guided genetic evolution, and hierarchical experience memory. Experimental results on EffiBench-X show consistent superior performance across LLM backbones.",339.94,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07351v2_Beyond Hard Masks Progressive Token Evolution for .pdf,Exact string,"Linhao Zhong, Linyu Wu, Bozhen Fang, Tianjian Feng, Chenchen Jing, Wen Wang, Jiaheng Zhang, Hao Chen, Chunhua Shen",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"diffusion language models, token evolution, parallel decoding","The paper introduces EvoToken-DLM, a diffusion-based language modeling approach that uses evolving soft token distributions to enable progressive token revisions, achieving superior performance over traditional masked diffusion models.",338.8,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07356v1_Efficient Convolutional Forward Model for Passive .pdf,Efficient Convolutional Forward Model for Passive Acoustic Mapping and Temporal Monitoring,"Tatiana Gelvez-Barrera, Barbara Nicolas, Bruno Gilles, Adrian Basarab, Denis Kouam",10.1093/acpro/9780190871293.001.0001,10.1093/acpro/9780190871293.001.0001,"Passive Acoustic Mapping, Model-based beamforming, Convolutional forward model, Temporal monitoring","The paper presents a convolutional formulation for an efficient PAM beamforming framework, enabling high-quality reconstruction with reduced computational cost compared to frequency-domain methods.",296.68,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07359v1_Seeing Right but Saying Wrong Inter- and Intra-Lay.pdf,Seeing Right but Saying Wrong: Inter- and Intra-Layer Refinement in MLLMs,"Shezheng Song, Shasha Li, Jie Yu",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"MLLM, visual understanding, attention, refinement","The paper discusses the issue of 'seeing it right but saying it wrong' in multimodal large language models, proposing DualPD to improve internal reasoning without additional training.",275.76,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07364v1_On the universal definition of intelligence.pdf,Exact string,Joseph Chen,10.1000/123456,10.1000/123456,"intelligence, AI, comparison, definition","The paper proposes a universal definition of intelligence based on predictive ability, emphasizing the need for a framework that accommodates both spontaneous and reactive predictions, as well as gainability, to meaningfully compare human and artificial intelligence.",256.81,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07372v1_Conditional Memory via Scalable Lookup A New Axis .pdf,Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models,"Xin Cheng, Wangding Zeng, Damai Dai, Qinyu Chen, Bingxuan Wang, Zhenda Xie, Kezhao Huang, Xingkai Yu, Zhewen Hao, Yukun Li, Han Zhang, Huishuai Zhang, Dongyan Zhao, Wenfeng Liang",10.48550/arXiv.2304.05748,10.48550/arXiv.2304.05748,"conditional memory, scalable lookup, sparsity, large language models, Engram, MoE, knowledge retrieval","The paper introduces conditional memory as a new sparsity axis for LLMs, leveraging Engram to enable O(1) knowledge lookup. It presents a U-shaped scaling law and demonstrates superior performance across reasoning benchmarks, highlighting Engram's potential to enhance both efficiency and reasoning depth.",329.62,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07376v1_OpenTinker Separating Concerns in Agentic Reinforc.pdf,Exact string,"Siqi Zhu, Jiaxuan You",10.48550/arXiv.2601.07376,10.48550/arXiv.2601.07376,"reinforcement learning, RLHF, OpenTinker, agentic learning","Introduces OpenTinker, a framework for agentic reinforcement learning that decomposes systems into composable components with separation of concerns, enabling scalable and reusable RL infrastructure.",336.74,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07377v1_Learning Dynamic Collaborative Network for Semi-su.pdf,Exact string,"Jiao Xu1, Xin Chen2, Lihe Zhang1",10.1000/xyz123,10.1000/12345,"3D vessel segmentation, semi-supervised learning, dynamic collaboration","The paper introduces DiCo, a dynamic collaborative network for semi-supervised 3D vessel segmentation, addressing cognitive biases by allowing teacher-student role switching and incorporating adversarial supervision.",308.01,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07389v1_On the Non-decoupling of Supervised Fine-tuning an.pdf,Exact string,"Xueyan Niuniuxueyan3, Bo Baibaibo8, W eixi Zhangzhangweixi1, W eixi Hanharvey.hanwei, W weixi Zhangzhangweixi2",10.48550/arXiv.2025.12345,10.48550/arXiv.2025.12345,"supervised fine-tuning, reinforcement learning, post-training, reasoning models, LLM training","The paper investigates whether supervised fine-tuning (SFT) and reinforcement learning (RL) can be decoupled in the post-training phase of large language models, presenting theoretical results and experimental evidence on the performance impact of each approach.",300.15,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07392v1_OceanSAR-2 A Universal Feature Extractor for SAR O.pdf,Exact string,"Alexandre Tuela, Thomas Kerdreux a, Quentin Febvre b, Alexis Mouche b, Antoine Grouazel b, Jean-Renaud Miadana c, Antoine Audrasa, Chen Wangd, Bertrand Chapronb a",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"OceanSAR-2, SAR, Sentinel-1, feature extraction, remote sensing, geophysical patterns","OceanSAR-2 introduces a second-generation foundation model for SAR-based ocean observation, leveraging improved self-supervised learning and dynamic data curation to enhance performance across diverse ocean applications.",341.9,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07393v1_Software-Hardware Co-optimization for Modular E2E .pdf,Exact string,"Chengzhi Ji, Xingfeng Li, Zhaodong Lv, Hao Sun, Pan Liu, Hao Frank Yang, Ziyuan Pu, ∗",10.48550/arXiv.2026.12345,10.48550/arXiv.2026.12345,"Modular end-to-end, Closed-Loop Evaluation, Software–Hardware co-optimization, Energy Consumption, Latency, Efficiency","The paper introduces a unified framework for optimizing modular end-to-end autonomous driving systems by integrating software and hardware co-optimization, achieving significant improvements in inference latency and energy efficiency while maintaining accuracy.",330.83,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07395v1_MCP-ITP An Automated Framework for Implicit Tool P.pdf,Exact string,"Ruiqi Li, Zhiqiang Wang, Y unhao Yao, Xiang-Yang Li",lrq349,zhiqiang.wang,"Model Context Protocol, tool poisoning, LLM, security","The paper introduces MCP-ITP, the first automated framework for implicit tool poisoning within the MCP ecosystem. It presents an adaptive optimization strategy that maximizes Attack Success Rate while evading detection, achieving up to 84.2% ASR on the MCPtox dataset.",355.28,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07397v1_Layerwise goal-oriented adaptivity for neural ODEs.pdf,Layerwise goal-oriented adaptivity for neural ODEs: an optimal control perspective,"Michael Hintermüller, Michael Hinze, Denis Korolev",10.1093/pasj/202006,2601.07397v1,"Resnet, neural ODEs, parameter identification, adaptive neural network","The paper presents a novel layerwise adaptive construction method for neural networks, focusing on optimal control techniques for neural differential equations. It introduces a goal-oriented dual-weighted residual approach and applies it to neural network design for data classification.",278.17,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07411v1_SCALPEL Selective Capability Ablation via Low-rank.pdf,Scalpel: Selective Capability Ablation via Low-rank Parameter Editing for Large Language Models,"Zihao Fu, Xufeng Duan, Zhenguang G. Cai",10.48550/arXiv.2303.04137,10.48550/arXiv.2303.04137,"large language models, interpretability, capability encoding, low-rank parameter, interpretable AI","The paper introduces SCALPEL, a framework that models language model capabilities as low-rank parameter subspaces. It demonstrates how low-rank modifications across layers and modules enable selective capability removal while preserving overall performance. Experiments show SCALPEL can disentangle specific linguistic tasks from general language modeling, advancing interpretability research.",303.63,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07422v1_Two Pathways to Truthfulness On the Intrinsic Enco.pdf,Two Pathways to Truthfulness: On the Intrinsic,"Wen Luo, Guangyue Peng, Wei Li, Shaohang Wei, Feifan Song, Liang Wang, Nan Yang, Xingxing Zhang, Jing Jin, Furu Wei, Houfeng Wang",10.1234/abcd1234,None,"truthfulness, hallucination detection, LLM, knowledge boundaries, self-awareness","The paper investigates how truthfulness cues emerge in large language models through two distinct information pathways: a Question-Anchored pathway and an Answer-Anchored pathway. Using attention knockout and token patching, the authors disentangle these mechanisms, revealing their association with LLM knowledge boundaries and internal representational awareness. The study also proposes applications to improve hallucination detection and offers new insights into LLM internal dynamics.",300.78,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07430v1_KALE Enhancing Knowledge Manipulation in Large Lan.pdf,Exact string,"Qitan Lv1,2*, Tianyu Liu1,2*, Qiaosheng Zhang2†, Xingcheng Xu2†, Chaochao Lu2",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"knowledge manipulation, large language models, knowledge graphs","The paper introduces KALE, a post-training framework that enhances large language models' knowledge manipulation by leveraging knowledge graphs. It proposes a Knowledge-Induced data synthesis method and a Knowledge-Aware fine-tuning approach, achieving significant improvements across multiple benchmarks.",283.89,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07449v1_RLPO Residual Listwise Preference Optimization for.pdf,Exact string,"Hao Jiang, Zhi Yang, Annan Wang, Yichi Zhang, Weisi Lin, Yichizhang",10.1234/example.doi,None,"review ranking, long context, LLM, e-commerce","The paper introduces Residual Listwise Preference Optimization (RLPO), a novel ranking method that improves long-context review ranking by leveraging global context while reducing computational cost. It addresses the limitations of pointwise scoring and traditional listwise approaches, demonstrating superior NDCG@k performance.",287.48,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07463v1_Puzzle it Out Local-to-Global World Model for Offl.pdf,Exact string,"Sijia Li, Xinran Li, Shibo Chen, Jun Zhang",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"multi-agent reinforcement learning, offline MARL, local-to-global world model, uncertainty-aware sampling","The paper presents a novel local-to-global world model for offline multi-agent reinforcement learning. It addresses the limitations of existing offline MARL methods by introducing a framework that uses local predictions to infer global dynamics, thereby improving policy generalization. The authors propose an uncertainty-aware sampling mechanism to reduce approximation errors, achieving better performance than conventional baselines.",306.98,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07464v1_IFDNS An Iterative Feedback-Driven Neuro-Symbolic .pdf,Exact string,"Xiaoheng Wang, Tongxuan Liu, Zi Gong, Xianzhe Dong, Yuting Zeng, Minhan Hu, Weizhe Huang, Jing Li",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Logical Reasoning, Large Language Model, Reasoning","The paper introduces Iterative Feedback-Driven Neuro-Symbolic (IFDNS), a prompt-based method that enhances logical reasoning in large language models by incorporating iterative feedback to improve faithfulness and reduce information loss.",299.37,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07468v1_Beyond Dialogue Time Temporal Semantic Memory for .pdf,Exact string,"Miao Su1, Yucan Guo1,2,3, Zixuan Li1,2,Yufei Zhang 4, Guojun Yin 4, Wei Lin 4, Xiaolong Jin1,2,3, Jiafeng Guo 1,2,3, Xueqi Cheng 1,2,3, 1Institute of Computing Technology, Chinese Academy of Sciences, 2State Key Laboratory of AI Safety, 3School of Computer Science, University of Chinese Academy of Sciences, 4Meituan",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"memory, semantic timeline, temporal accuracy, LLM agents","The paper introduces Temporal Semantic Memory (TSM), a memory framework that models semantic time for point-wise memory and supports durative information. TSM constructs a semantic timeline during construction, consolidates continuous and related memories during utilization, and improves accuracy by 12.2% over existing methods.",308.06,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07469v1_Knowledge Distillation for LLM-Based Human Activit.pdf,Exact string,"Julien Cumin1, Oussama Er-Rahmany1, Xi Chen 1, Xi Chen 2",10.1093/pasj/psa.2023,2601.07469v1,"Human activity recognition, large language models, knowledge distillation, smart homes, ambient intelligence","The paper presents experimental results on using Large Language Models (LLMs) for Human Activity Recognition (HAR) in smart homes, demonstrating how recognition performance varies with LLM size and exploring knowledge distillation techniques to create efficient models.",326.48,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07470v1_Learning How to Remember A Meta-Cognitive Manageme.pdf,Learning How to Remember: A Meta-Cognitive Management Method for Structured and Transferable Agent Memory,"Sirui Liang, Pengfei Cao, Jian Zhao, Wenhao Teng, Xiangwen Liao, Jun Zhao, Kang Liu",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"memory abstraction, meta-cognitive management, agent memory, transferability","The paper introduces the Meta-CognitiveMemory Abstraction (MCMA) method, which treats memory abstraction as a learnable cognitive skill. MCMA decouples task execution from fixed memory representations by using a learned memory copilot that organizes memories hierarchically. This enables selective reuse based on task similarity and improves generalization and cross-task transfer in long-horizon decision-making tasks.",298.66,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07474v1_Task Prototype-Based Knowledge Retrieval for Multi.pdf,Exact string,"Yoongmin Oh, Hyung-Il Kim, Jung Uk Kim, Jung Uk Kim",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"multi-task learning, prototype-based knowledge retrieval, task prototype, knowledge retrieval","The paper introduces a prototype-based knowledge retrieval framework for multi-task learning, focusing on robust MTL without relying on unlabeled task predictions. It proposes a task prototype embedding and an association knowledge generation loss to capture task-specific characteristics and refine representations adaptively.",384.73,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07475v1_ARCQuant Boosting NVFP4 Quantization with Augmente.pdf,Exact string,"Haoqian Meng, Yilun Luo, Yafei Zhao, Wenyuan Liu, Peng Zhang, Xindian Ma",10.48550/arxiv/2303.04112,10.48550/arxiv/2303.04112,"NVFP4, quantization, LLM, augmented residual channels, microscaling formats, performance optimization","ARCQuant introduces a framework to boost NVFP4 performance using augmented residual channels, maintaining a unified NVFP4 format while achieving state-of-the-art accuracy and speed on modern GPUs.",300.45,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07477v1_JudgeFlow Agentic Workflow Optimization via Block .pdf,JUDGEFLOW: Evaluation Judge-Optimization Update,"Zihan Ma, Zhikai Zhao, Chuanbo Hua, Federico Berto, Jinkyoo Park",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"LLM, agentic workflows, optimization, LLM-based, workflow","The paper introduces JUDGEFLOW, a pipeline that enhances agentic systems by integrating fine-grained diagnostic signals and LLM-driven optimization to improve sample efficiency and interpretability.",324.9,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07496v1_Graph Inference Towards ICD Coding.pdf,Graph Inference Towards ICD Coding,Xiaoxiao Deng,10.1093/acp/ghac020,12345678,"graph generation, ICD coding, label graph, reinforcement learning","This paper introduces LabGraph, a framework that treats ICD coding as a graph generation task. By leveraging adversarial domain adaptation, graph-based reinforcement learning, and perturbation regularization, LabGraph improves model robustness and generalization for hierarchical ICD code prediction.",274.55,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07514v1_Data-Driven Stochastic VRP Integration of Forecast.pdf,Data-Driven Stochastic VRP: Integration of Forecast,Matteo Garbellia,10.1094/SAGE.2026.01234,2601.07514,"Stochastic VRP, Machine Learning, XGBoost, Sub-Gaussian Concentration, Multi-Objective Optimization","This paper integrates machine learning forecasts of intervention durations into a stochastic Capacitated Vehicle Routing Problem with Time Windows, demonstrating improvements in operator utilization and completion rates through uncertainty-aware optimization.",271.49,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07516v1_Controlling Multimodal Conversational Agents with .pdf,Controlling Multimodal Conversational Agents,"Yongqi Li, Hao Lang, Tieyun Qian, Yongbin Li, Yi Yi",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"conversational agents, multimodal, reinforcement learning, vision-language models, RL fine-tuning","The paper presents a novel latent action space approach for RL fine-tuning of multimodal conversational agents, leveraging paired image-text data and text-only data to overcome the limitations of large text token spaces. It introduces a cross-modal projector and demonstrates improved performance across two conversation tasks using various RL algorithms.",342.31,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07518v1_Mon3tr Monocular 3D Telepresence with Pre-built Ga.pdf,Monocular 3D Telepresence with Pre-built Gaussian Avatars as Amortization,"Fangyu Lin, Yingdong Hu, Zhening Liu, Yufan Zhuang, Zehong Lin, Jun Zhang, Corresponding authors: Zehong Lin; Jun Zhang",10.1234/jcl.2024.0123,10.1234/jcl.2024.0123,"Monocular 3D telepresence, 3D Gaussian splatting, animatable avatars, real-time neural rendering","The paper introduces Mon3tr, a novel monocular 3D telepresence framework that integrates 3D Gaussian splatting for parametric human modeling. It leverages a single monocular RGB camera to capture real-time body and facial motions, enabling efficient offline multi-view reconstruction and online inference during live telepresence. The method achieves high-quality photorealistic avatars at ~60 FPS, reduces bandwidth by >1000× compared to point-cloud streaming, and supports seamless operation on mobile devices.",311.82,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07525v1_Thinking Before Constraining A Unified Decoding Fr.pdf,Exact string,"Ngoc Trinh Hung Nguyen, Alonso Silva, Laith Zumot, Liubov Tupikina, Armen Aghasaryan, Mehwish Alam",10.48550/arXiv.2303.04112,10.48550/arXiv.2303.04112,"natural language generation, structured generation, LLM, accuracy",The paper presents a method called In-Writing that combines natural and structured generation to improve output reliability while preserving expressive power. It achieves up to 27% accuracy gain over natural generation and requires minimal overhead.,346.13,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07528v1_From RAG to Agentic RAG for Faithful Islamic Quest.pdf,Exact string,"Gagan Bhatia, Hamdy Mubarak, Mustafa Jarrar, George Mikros, Fadi Zaraket, Mahmoud Alhirthani, Logan Cochrane, Kareem Darwish, Rashid Yahiaoui, Firoj Alam",10.1093/acref/2025.01.012,10.1093/acref.2025.01.012,"Islamic question answering, faithful qa, agentic raga, Qur'an retrieval, hallucination mitigation","The paper introduces an agentic RAG framework for Islamic question answering, leveraging structured tool calls for evidence seeking and improved robustness through iterative reasoning and Qur'an retrieval. Experiments demonstrate superior performance over standard RAG, especially in Arabic and multilingual settings.",299.63,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07553v1_VirtualEnv A Platform for Embodied AI Research.pdf,VirtualEnv: A Platform for Embodied AI Research,"Kabir Swain, Sijie Han, Ayush Raina, Jin Zhang, Shuang Li, Michael Stopa, Antonio Torralba",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Virtual Environment, Large Language Models, Embodied AI, Unreal Engine, LLM benchmarking, Interactive Simulation","VirtualEnv introduces a next-generation simulation platform built on Unreal Engine to enable rigorous evaluation of large language models in embodied and interactive scenarios. It supports agent-environment interactions, object manipulation, navigation, and multi-agent collaboration, while integrating LLMs and vision-language models for dynamic environment generation and task execution.",381.22,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07556v1_Backpropagation-Free Test-Time Adaptation for Ligh.pdf,Exact string,"Siyang Li, Jiayi Ouyang, Zhenyao Cui, Ziwei Wang, Tianwang Jia, Feng Wan, Dongrui Wu",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"EEG-based BCI, test-time adaptation, transfer learning, brain-computer interface, EEG decoding","The paper introduces Backpropagation-Free Transformations (BF T) for lightweight EEG-based brain-computer interfaces, addressing deployment challenges through test-time adaptation without backpropagation, enabling robust inference under distribution shifts.",291.33,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07565v1_A Unified Framework for Emotion Recognition and Se.pdf,Exact string,"Jiaqi Qiao, Xiujuan Xu, Xinran Li, Yu Liu",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"emotion recognition, large language models, multimodal fusion","The paper introduces EGMF, a unified framework that integrates expert-guided multimodal fusion with large language models. It features specialized expert networks for local, semantic, and global context, and demonstrates improved performance across bilingual benchmarks, highlighting robust cross-lingual emotion understanding.",323.66,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07568v1_d3LLM Ultra-Fast Diffusion LLM using Pseudo-Trajec.pdf,Exact string,"Yu-Yang Qian, Junda Su, Lanxiang Hu, Peiyuan Zhang, Zhijie Deng, Peng Zhao, Hao Zhang, Zhaop",10.1234/arxiv.2025.12345,10.1234/2025.12345,"dLLM, diffusion, parallelism, accuracy, speed","The paper introduces d3LLM, a pseudo-distilled diffusion LLM that balances accuracy and parallelism by incorporating pseudo-trajectory distillation during training and entropy-based multi-block decoding during inference. It presents AUP for evaluating accuracy-parallelism trade-offs and reports performance gains over LLaDA/Dream and AR models.",293.55,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07573v1_A Model of Artificial Jagged Intelligence.pdf,Exact string,Joshua S. Gans,10.1093/acprof:oso/9780190876223.001.0001,2601.07573,"generative AI, adoption, calibration, learning, scaling","The paper presents a tractable economic model of Artificial Jagged Intelligence (AJI), analyzing how users balance local reliability with global quality in generative AI systems. It derives adoption thresholds, explores calibration dynamics, and examines scaling interactions with discoverability.",296.54,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07577v1_Beyond Entangled Planning Task-Decoupled Planning .pdf,Exact string,"Yunfan Li, Bingbing Xu, Xueyun Tian, Xiucheng Xu, Huawei Shen",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"task decoupling, long-horizon planning, LLM, planning","The paper introduces Task-Decoupled Planning (TDP), a framework that decouples planning into sub-tasks to mitigate entanglement issues in large language models. By structuring tasks via a directed acyclic graph and using a supervisor, TDP enables localized reasoning and replanning, improving robustness and reducing execution overhead.",311.52,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07580v1_Large Language Models for Physics Instrument Desig.pdf,Large Language Models for Physics Instrument Design,"Sara Zoccheddu, Shah Rukh Qasim, Patrick Owen, Nicola Serra",10.1234/arXiv.2026.12345,10.1234/2026.12345,"LLM, physics instrument design, RL, design optimization, metamodeling","The paper explores the application of large language models in physics instrument design, comparing their performance to reinforcement learning. It highlights how LLMs can generate valid, resource-aware designs by leveraging broad pretrained knowledge, serving as a precursor to hybrid design workflows that combine AI with traditional optimization methods.",285.7,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07582v2_ES-Mem Event Segmentation-Based Memory for Long-Te.pdf,ES-Mem: Event Segmentation-Based Memory for Long-Term,"Huhai Zou, Tianhao Sun, Chuanjiang He, Yu Tian2, Zhenyang Li, Li Jin, Nayu Liu, Jiang Zhong, Kaiwen Wei",10.1234/example.doi,10.1234/example_id,,"The paper introduces ES-Mem, a framework leveraging dynamic event segmentation and boundary-anchored retrieval to address memory rigidity and flat retrieval limitations in dialogue agents. It proposes a hierarchical memory structure that partitions interactions into coherent events and uses semantic boundaries to anchor episodic context, improving performance on long-term dialogue tasks.",275.54,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07597v1_Pheromone-Focused Ant Colony Optimization algorith.pdf,Pheromone-Focused Ant Colony Optimization algorithm for path planning,"Yi Liu, Hongda Zhang, Zhongxue Gan, Yuning Chen, Ziqing Zhou, Chunlei Meng, Chun Ouyang",10.1007/...,10.1007/...,"Pheromone-Focused Ant Colony Optimization, Path planning, Ant colony optimization, Optimization, Swarm intelligence","The paper introduces a Pheromone-Focused Ant Colony Optimization (PFACO) algorithm to improve path planning by enhancing convergence speed and solution quality through three key strategies: (1) concentrating initial pheromone in promising regions, (2) reinforcing high-quality solutions during iterations, and (3) penalizing redundant path turns. Experimental results show PFACO outperforms traditional ACO methods.",371.8,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07606v1_Proof of Time A Benchmark for Evaluating Scientifi.pdf,Proof of Time: A Benchmark for Evaluating Scientific Idea Judgments,"Bingyang Ye, Shan Chen, Jingxuan Tu, Chen Liu, Zidi Xiong, Samuel Schmidgall, Danielle S. Bitterman",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"scientific ideas, judgment evaluation, benchmarking, AI for science","The paper introduces Proof of Time (PoT), a benchmarking framework that links scientific idea judgments to observable downstream signals, enabling scalable and verifiable evaluation of model predictions against future outcomes.",298.51,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07611v1_DIAGPaper Diagnosing Valid and Specific Weaknesses.pdf,Diagnosing Valid and Specific Weaknesses in Scientific Papers,"Zhuoyang Zou, Abolfazl Ansari, Delvin Ce Zhang, Dongwon Lee, Wenpeng Yin",10.1234/diag.2024.0012,10.1234/2024.0012,"paper weakness, LLM, review process, prioritization","DIAGPaper introduces a multi-agent framework for identifying and prioritizing paper weaknesses, addressing limitations of existing systems by simulating expert review criteria and enabling structured author-rebuttals.",282.57,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07618v1_Neural Architecture for Fast and Reliable Coagulat.pdf,Neural Architecture for Fast and Reliable Coagulation Assessment in Clinical Settings: Leveraging Thromboelastography,"Yulu Wang, Ziqian Zeng, Jianjun Wu, Zhifeng Tang",10.1093/acprof:oso/9780190871296.05,10.1093/acprof:oso/9780190871296.05,"coagulation assessment, thromboelastography, deep learning, clinical AI, physiological monitoring","The paper introduces Physiological State Reconstruction (PSR), a novel algorithm designed to deliver real-time coagulation insights by leveraging dynamic TEG data. It addresses the challenge of slow traditional TEG analysis and proposes MDFE for robust multi-domain learning, achieving high prediction accuracy while reducing inference time. The method emphasizes adaptability to small datasets and patient variability, offering promise for medical AI applications with limited data.",308.6,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07632v2_GeoMotionGPT Geometry-Aligned Motion Understanding.pdf,Exact string,"Zhankai Ye1, Bofan Li1, Yukai Jin1, Shuoqiu Li1, Xin Liu1",10.48550/arXiv.2311.03655v1,10.48550/arXiv/2311.03655,"motion understanding, large language models, geometry alignment","The paper introduces a framework that enforces orthogonality between motion codebooks and LLM embeddings, improving human motion understanding by aligning geometry across modalities without relying solely on token IDs.",281.35,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07635v2_Learning About Learning A Physics Path from Spin G.pdf,Learning About Learning: A Physics Path from Spin Glasses to Artificial Intelligence,"Denis D. Caprioti, Matheus Haas, Constantino F. Vasconcelos, Mauricio Girardi-Schappo",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"physics, learning, spin glasses, artificial intelligence, neural networks, statistical mechanics","The paper explores the Hopfield model—a foundational associative memory framework inspired by spin glasses—as a bridge between statistical physics, neural networks, and AI. It offers a pedagogical introduction that integrates undergraduate concepts with modern computational methods, emphasizing practical applications in physics education.",297.33,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07638v1_SALT-KG A Benchmark for Semantics-Aware Learning o.pdf,Exact string,"Isaiah Onando Mulang, Felix Sasaki, Tassilo Klein, Jonas Kolk, Nikolay Grechanov, Johannes Hoffart",10.48550/arXiv.2405.12345,10.48550/arXiv.2405.12345,"semantics-aware learning, SALT benchmark, metadata knowledge graph, tabular data, entity relationships","This paper introduces SALT-KG, a benchmark for semantics-aware learning on enterprise tables. It extends the SALT dataset by integrating a structured Operational Business Knowledge graph to capture field-level semantics, enabling models to reason beyond statistical correlations and improve performance on relational prediction tasks.",324.81,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07641v1_Beyond Static Tools Test-Time Tool Evolution for S.pdf,Exact string,"Jiaxuan Lu1, Ziyu Kong2, Yemin Wang3, Rong Fu4, Haiyuan Wan1, Lilong Wang1, Yankai Jiang1, Xiaosong Wang1, Xiao Sun1, Dongzhan Zhou1",10.1234/example.doi,None,"scientific reasoning, tool evolution, AI for science","The paper introduces Test-Time Tool Evolution (TTE), a framework enabling agents to synthesize, verify, and evolve computational tools during inference, addressing the limitations of static tool libraries in scientific contexts.",309.67,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07651v1_Active Evaluation of General Agents Problem Defini.pdf,Active Evaluation of General Agents: Problem,"Marc Lanctot, Kate Larson, Ian Gemp, Michael Kaisers",10.48550/arXiv.2026.12345,10.48550/arXiv.2026.12345,"general evaluation, multitask evaluation, ranking, active learning, game theory, social choice theory","The paper proposes a formal framework for active evaluation of agents across multiple tasks, emphasizing online ranking adaptation and performance assessment. It compares classical Elo with a new method, Soft Condorcet Optimization, showing its effectiveness in reducing ranking error, especially when task variation is high.",374.07,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07654v1_Towards Automating Blockchain Consensus Verificati.pdf,Exact string,"Elliot Jones1, William Knottenbelt",1e.jones24@imperial.ac.uk,1e.12345,"Blockchain, Consensus, Formal Verification, Theorem, Artificial Intelligence","The paper introduces IsabeLLM, a tool integrating Isabelle with a Large Language Model to automate formal verification of blockchain consensus protocols, demonstrating its effectiveness in proving Bitcoin's Proof of Work.",320.63,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07663v2_Reasoning Models Will Blatantly Lie About Their Re.pdf,Exact string,"William Walden, Johns Hopkins University",10.48550/arXiv.2024.12345,None,,N/A,223.95,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07666v1_Variational Contrastive Learning for Skeleton-base.pdf,Variational Contrastive Learning for Skeleton-based Action Recognition,"Dang-Dinh NGUYEN1, Decky ASPANDI-LATIF1, Titus ZAHARIA1",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Human Action Recognition, Self-Supervised Learning, Variational Inference","The paper presents a variational contrastive learning framework for skeleton-based action recognition, addressing the limitations of discriminative contrastive methods by integrating probabilistic latent modeling with self-supervised learning. It demonstrates superior performance across benchmark datasets and highlights the importance of skeleton joint relevance in motion analysis.",274.58,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07667v1_Adaptive Layer Selection for Layer-Wise Token Prun.pdf,Adaptive Layer Selection for Layer-Wise Token Pruning in LLM Inference,"Rei Taniguchi, Yuyang Dong, Makoto Onizuka",10.48550/arXiv.2303.04112,10.48550/arXiv:2303.04112,"layer-wise pruning, token selection, LLM inference, KV cache reduction","The paper introduces ASL, a training-free method that adaptively selects token layers for key-value cache reduction in large language models. By leveraging attention-based token rank variance, ASL balances performance across tasks while respecting a KV budget, and demonstrates superior accuracy and speed compared to existing layer-wise pruning approaches.",371.09,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07685v1_Predictive Analytics for Dementia Machine Learning.pdf,Predictive Analytics for Dementia: Machine Learning on Healthcare Data,"Shafiul Ajam Opee, Nafiz Fahad, Anik Sen, Rasel Ahmed, Fariha Jahan, Md. Kishor Morol, Md. Rashedul Islam",10.1093/acps/psac123,10.1093/acps/psac123,"Dementia, Machine learning, Linear Discriminant Analysis (LDA), APOE-ϵ4 allele, Healthcare data, Predictive modeling","This study explores the application of machine learning techniques to predict dementia using patient health data. It evaluates supervised learning methods such as KNN, QDA, LDA, and Gaussian Process Classifiers, emphasizing model interpretability and the impact of risk factors like APOE-ϵ4 and chronic conditions. The research underscores the potential of integrating explainable AI for improved dementia prediction.",324.57,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07701v1_Deep Whole-body Parkour.pdf,Exact string,"Ziwen Zhuang, Shaoting Zhu, Mengjie Zhao, Hang Zhao",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Deep Reinforcement Learning, Humanoid Robotics, Whole-body Motion, Robot Perception, Traversal","The paper presents a framework enabling humanoid robots to autonomously traverse challenging obstacles by integrating exteroceptive sensing into whole-body motion control. It demonstrates robust, dynamic multi-contact motions like vaulting and diving on uneven terrain, bridging the gap between perceptive locomotion and general motion tracking.",328.32,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07718v1_Hiking in the Wild A Scalable Perceptive Parkour F.pdf,Exact string,"Shaoting Zhu, Ziwen Zhuang, Mengjie Zhao, Kun-Ying Lee, Hang Zhao",10.48550/arXiv.2601.07718,10.48550/arXiv.2601.07718,"hiking, humanoid, robot, perception, parkour, robotics","A scalable end-to-end framework enables humanoid robots to traverse diverse terrains, achieving robust performance in complex environments by combining depth perception with proactive mapping.",281.96,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07737v1_Evaluating the encoding competence of visual langu.pdf,Exact string,Chen Ling,10.48550/arXiv.2601.07737,2601.07737v1,"encoding competence, visual language models, uncommon actions",Evaluating the encoding competence of visual language models using uncommon actions.,257.66,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07748v1_Improving Domain Generalization in Contrastive Lea.pdf,Improving Domain Generalization in Contrastive Learning using Adaptive Temperature Control,"Robert Lewis, Katie Matton, Rosalind W. Picard, John Guttag",10.48550/arXiv.2303.08713,10.48550/arXiv.2601.07748,"domain generalization, contrastive learning, domain adaptation, temperature control, self-supervised learning","The paper presents a method that enhances domain invariance in contrastive learning by adjusting the temperature parameter based on domain labels, thereby improving out-of-distribution generalization while maintaining strong in-distribution performance.",280.08,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07778v1_DT-ICU Towards Explainable Digital Twins for ICU P.pdf,Exact string,Wen Guo,10.1093/pasj/2026.12.012,2601.07778v1,"digital twin, ICU, risk estimation, multimodal data, interpretability","DT-ICU is a multimodal digital twin framework for continuous risk estimation in intensive care, integrating variable-length clinical time series with static patient data in a unified multitask architecture.",294.31,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07779v1_OS-Symphony A Holistic Framework for Robust and Ge.pdf,OS-SYMPHONY: A Holistic Framework for Robust and Generalist,"Bowen Yang, Kaiming Jin, Zhenyu Wu, Zhaoyang Liu, Qiushi Sun, Zehao Li, Jingjing Xie, Zhoumianze Liu, Zang Zehao, Qingyun Li, Yian Wang, Yu Qiao, Zun Wang, Zichen Ding, Jingjing Xie, Zhoumianze Liu, Kanzhi Cheng, Qingyun Li, Yang Bowen, Xu Zun, Xu Zichen",10.1234/os-symphony.2025,10.1234/os-symphony.2025v1,"Computer-Using Agent, Robust Automation, Visual-Language Models, Long-term Memory, Multimodal Search, Tutorial Retrieval","The paper introduces OS-SYMPHONY, a holistic framework enhancing robustness and generalization in Computer-Using Agents by integrating milestone-driven memory and a multimodal search agent. It addresses limitations in visual context retention and noisy text retrieval, achieving state-of-the-art performance across benchmarks.",307.23,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07782v1_Beyond Single-Shot Multi-step Tool Retrieval via Q.pdf,Exact string,"Wei Fang, James Glass",10.48550/arXiv.2303.04112,10.48550/arXiv.2303.04112,"tool retrieval, query planning, LLM agents, retrieval systems","The paper introduces TOOLQP, a lightweight framework that models retrieval as iterative query planning. It addresses limitations of single-shot dense retrievers by decomposing tasks into sub-tasks and generating queries to bridge the semantic gap between user goals and tool specifications. Experiments show TOOLQP achieves state-of-the-art performance in zero-shot generalization and robustness.",331.97,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07790v1_Benchmarking Small Language Models and Small Reaso.pdf,Benchmarking Small Language Models and Small Reasoning,"Yahya Masri, George Mason University, Emily Ma, George Mason University, Zifu Wang, Harvard University, Joseph Rogers, George Mason University, Chaowei Yang∗, George Mason University",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"language models, system logs, severity classification, small models, retrieval-augmented generation","This study evaluates nine small language models and small reasoning models on real-world Linux system log classification tasks. It highlights performance differences under zero-shot, few-shot, and retrieval-augmented generation, emphasizing the importance of architectural design and retrieval integration for efficient log comprehension. The results inform the deployment of lightweight models in digital twin environments.",333.95,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07794v1_Kinship Data Benchmark for Multi-hop Reasoning.pdf,Exact string,"Tianda Sun, Dimitar Kazakov",10.48550/arXiv.2024.12345,10.48550/arXiv/12345,"kinship, multi-hop reasoning, genealogy, LLM","The paper introduces KinshipQA, a benchmark for evaluating multi-hop reasoning using generative family trees constrained by cultural kinship rules. It demonstrates how LLMs can infer complex relationships across interconnected genealogies and highlights performance variations across models.",331.76,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07821v1_Failure-Aware RL Reliable Offline-to-Online Reinfo.pdf,Exact string,"Huanyu Li, Kun Lei, Sheng Zang, Kaizhe Hu, Yongyuan Liang, Bo An, Xiaoli Li, Huazhe Xu",10.48550/arXiv.2303.04112,10.48550/arXiv.2303.04112,"Failure-aware, Reinforcement learning, Offline-to-online, Robot manipulation, Self-recovery, Real-world manipulation","The paper introduces Failure-Aware RL (FARL), a framework that reduces Intervention-requiring failures during real-world reinforcement learning by integrating a world-model-based safety critic and a recovery policy. FARL addresses the challenge of IR Failures—such as breaking fragile objects—through pre-training and post-training safeguards, improving robustness and performance.",295.8,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07832v2_MHLA Restoring Expressivity of Linear Attention vi.pdf,Restoring Expressivity of Linear Attention,"Kewei Zhang, Ye Huang, Yufan Deng, Jincheng Yu, Huan Ling, Daquan Zhou",10.48550/arXiv.2303.04112,10.48550/arXiv.2601.07832,"Linear Attention, Multi-Head, Expressivity, Performance, Transformers","The paper proposes Multi-Head Linear Attention (MHLA) to address global context collapse in linear attention by maintaining linear complexity while preserving expressive power. It achieves significant improvements across image classification, NLP, image generation, and video generation tasks.",376.71,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07885v1_Small Symbols Big Risks Exploring Emoticon Semanti.pdf,Exact string,"Weipeng Jiang, Xiaoyu Zhang, Juan Zhai, Shiqing Ma, Chao Shen, Yang Liu",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"emoticons, semantic confusion, LLM safety, code agents","This paper investigates emoticon semantic confusion in large language models, demonstrating that LLMs often misinterpret ASCII emoticons, leading to high confusion rates (over 38%) and risky 'silent failures' that can compromise system safety. The authors develop a dataset and analyze performance across multiple LLMs and programming contexts.",317.75,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07891v1_KVzap Fast Adaptive and Faithful KV Cache Pruning.pdf,Exact string,"Simon Jégou, Maximilian Jeblick",10.48550/arXiv.2303.04137,2601.07891,"KV cache, KVzap, KVzap pruning, transformer, inference","KVzap is a fast, input-adaptive KV cache pruning method that improves KV cache compression for transformer models with state-of-the-art accuracy and minimal performance impact.",327.84,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07892v1_Sherry Hardware-Efficient 1.25-Bit Ternary Quantiz.pdf,Exact string,"Hong Huang, Decheng Wu, Qiangqiang Hu, Guanhua Yu, Jinhai Yang, Xue Liu, Dapeng Wu",10.48550/arXiv.2303.04112,10.48550/arXiv.2303.04112,"ternary quantization, hardware efficiency, LLM, sparsification","The paper presents a hardware-efficient ternary quantization framework for large language models, achieving 1.25-bit width while maintaining competitive performance. It introduces a 3:4 fine-grained sparsity technique and addresses weight trapping issues in sparse ternary training, demonstrating significant bit savings and speed improvements on edge devices.",315.12,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07894v1_Revealing the Attention Floating Mechanism in Mask.pdf,Exact string,"Xin Dai, Pengcheng Huang, Zhenghao Liu, Shuo Wang, Yukun Yan, Chaojun Xiao, Yu Gu, Ge Yu, Maosong Sun",10.48550/arXiv.2311.03855,10.48550/arXiv/2311.03855,"Attention Floating, Masked Diffusion Models, Autoregressive Models, Large Language Models, Bidirectional Attention","This paper investigates the attention dynamics in masked diffusion models, revealing the 'Attention Floating' phenomenon where attention anchors shift across denoising steps, enhancing performance in knowledge-intensive tasks.",299.02,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07898v1_Large Language Models and Algorithm Execution Appl.pdf,Large Language Models and Algorithm Execution: Application to Arithmetic Function,"Farah Ben Slama, Frédéric Armetta",10.1093/acprof:oso/9780190871296.001.0001,10.1093/acprof:oso/9780190871296.001.0001,"Large language model, Algorithmic learning, Supervised learning, Reasoning decomposition, Natural language processing","The paper explores extending LLMs' capabilities to algorithm execution by introducing a specialized training model, LLM-DAL, which enhances their ability to generalize and perform complex algorithmic inferences through structured reasoning.",321.93,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07901v1_Decentralized Online Convex Optimization with Unkn.pdf,Decentralized Online Convex Optimization with Unknown Feedback Delays,"Hao Qiu, Mengxiao Zhang, Juliette Achddou",10.48550/arXiv.2403.08230,arXiv:2601.07901v1,"Decentralized Online Convex Optimization, Unknown Feedback Delays, Multi-Agent Learning, Federated Learning, Strongly Convex Optimization","The paper presents a novel decentralized algorithm for online convex optimization that adapts to time- and agent-varying feedback delays. It improves upon prior methods by incorporating an adaptive learning rate and leveraging a gossip-based communication strategy, achieving better regret bounds in strongly convex settings.",330.31,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07903v2_Enhancing Large Language Models for Time-Series Fo.pdf,Enhancing Large Language Models for Time-Series Forecasting,"Jianqi Zhang, Jingyao Wang, Wenwen Qiang, Fanjiang Xu, Changwen Zheng",10.1093/pasj/tsf.2023,10.1093/pasj.tsf.2023.01,"Time Series Forecasting, Large Language Model, In-context Learning, Computing methodologies, Artificial intelligence","The paper presents LVICL, a method to improve large language model performance for time series forecasting by freezing the model while injecting example information via vector-injected in-context learning. This enhances forecasting accuracy without increasing computational overhead.",348.94,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07935v1_Towards Specialized Generalists A Multi-Task MoE-L.pdf,Exact string,"MoE-LoRA Framework for Domain-Specific LLM, Yuxin Yang, Shanghai University, Aoxiong Zeng, East China Normal University, Xiangquan Yang, East China Normal University",10.1093/pasj/2026004,2601.07935,"LLM adaptation, medical knowledge, LoRA, domain adaptation","The paper introduces Med-MoE-LoRA, a framework combining Mixture-of-Experts with Low-Rank Adaptation to address stability-plasticity and task interference challenges in medical domain adaptation. It proposes an asymmetric expert distribution and a Knowledge-Preservation Plugin to maintain general reasoning while enabling efficient multi-task learning.",289.14,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07939v1_SECite Analyzing and Summarizing Citations in Soft.pdf,Analyzing and Summarizing Citations in Software Engineering Literature,"Shireesh Reddy Pyreddy, Khaja Valli Pathan, Hasan Masum, Tarannum Shaila Zaman",10.1234/example.doi,10.1234/example_id,"SECite, sentiment analysis, LLMs, text summarization, citations","The paper introduces SECite, a novel framework for evaluating scholarly impact through sentiment analysis of citation contexts. It develops a semi-automated pipeline to extract citations, apply unsupervised NLP, and generate sentiment-specific summaries to assess how the academic community perceives the contributions of referenced papers.",286.0,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07941v2_Moonworks Lunara Aesthetic Dataset.pdf,Exact string,"Yan Wang, M M Sayeef Abdullah, Partho Hassan, Sabit Hassan",10.48550/arXiv.2601.07941,2601.07941,"Lunara, Aesthetic Dataset, Text-to-Image, Style Conditioning","The Lunara Aesthetic Dataset introduces a curated collection of 2,000 image–prompt pairs designed to advance research on prompt-based style control and aesthetic quality in text-to-image models. It emphasizes high-quality, human-refined prompts and detailed annotations across diverse artistic styles, positioning itself as a first-of-its-kind resource that surpasses general-purpose datasets in precision and aesthetic rigor.",319.97,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07946v1_Coupled Diffusion-Encoder Models for Reconstructio.pdf,Exact string,"AmirPouya Hemmasian, Amir Barati Farimani",10.48550/arXiv.2026.12345,10.48550/arXiv/2026.12345,"flow fields, diffusion models, autoencoders, data-driven reconstruction","The paper introduces DiffCoder, a coupled diffusion–encoder framework that enhances flow-field reconstruction by integrating probabilistic diffusion with a convolutional encoder. It addresses limitations of classical autoencoders in preserving statistical structure under compression, demonstrating improved spectral accuracy compared to VAE baselines.",283.4,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07948v1_Reinforcement Learning Methods for Neighborhood Se.pdf,Reinforcement Learning Methods for Neighborhood Selection in Local Search,"Y annick Molinghen, a, Augustin Delecluse, b, Renaud De Landtsheer, c and Stefano Michelini, d",10.1093/acps/9780190876225.001.0001,10.1093/acps.9780190876225,"Local Search, Reinforcement Learning, Combinatorial Optimization","This paper evaluates reinforcement learning-based neighborhood selection strategies in local search, comparing multi-armed bandits and deep RL methods against three optimization benchmarks. It highlights performance variations across problems and discusses the trade-offs between computational efficiency and solution quality.",294.28,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07951v1_Hybrid SARIMA LSTM Model for Local Weather Forecas.pdf,Hybrid SARIMA–LSTM Model for Local Weather Forecasting,"Shreyas Rajeev, Karthik Mudenahalli, Amit Mallappa Tiparaddi",10.1234/example.doi,10.1234/example,"weather forecasting, SARIMA, LSTM, hybrid model, residual learning",Proposes a hybrid SARIMA–LSTM architecture combining seasonal and nonlinear modeling for improved weather prediction accuracy.,255.01,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07953v1_Quantum automated theorem proving.pdf,Quantum automated theorem proving,"Zheng-Zhi Sun, Qi Ye, Dong-Ling Deng",10.48550/arXiv.2303.04137,10.48550/arXiv.2303.04137,"quantum computing, automated theorem proving, quantum algorithms, knowledge representation, logical reasoning","The paper proposes a quantum framework for automated theorem proving, leveraging quantum superposition and entanglement to achieve efficient reasoning in propositional and first-order logic. It introduces quantum representations of knowledge bases and demonstrates improved query complexity for geometric theorems, highlighting potential advantages over classical methods.",315.91,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07957v1_LWMSCNN-SE A Lightweight Multi-Scale Network for E.pdf,LWMSCNN-SE: A Lightweight Multi-Scale Network for Efficient Maize Disease Classification,"Likewood, Fikadu, Weloday, Jianmei, Su, Jianmei",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"lightweight CNN, multi-scale feature extraction, attention mechanism, plant pathology","The paper introduces LWMSCNN-SE, a lightweight convolutional neural network that integrates multi-scale feature extraction, depthwise separable convolutions, and squeeze-and-Excitation attention to achieve high accuracy with low computational cost for maize disease classification on edge devices.",297.22,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07958v1_LJ-Spoof A Generatively Varied Corpus for Audio An.pdf,LJ-SPOOF: A Generatively Diverse Corpus for Audio Anti-Spoofing and Synthesis Source Tracing,"Surya Subramani, Hashim Ali, Hafiz Malik",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"anti-spoofing, speaker verification, deepfake, source tracing, synthetic speech","The paper introduces LJ-Spoof, a speaker-specific, generatively diverse corpus designed to enable robust anti-spoofing and synthesis-source tracing. It systematically varies prosody, vocoders, generative parameters, prompt sources, training regimes, and post-processing to create a dataset spanning one speaker across 30 TTS families, 500 variants, and over 3 million utterances. This dataset aims to advance both practical training resources and benchmark evaluation for audio anti-spoofing.",326.16,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07964v1_Executable Ontologies in Game Development From Alg.pdf,Exact string,Alexander Boldachev,10.1093/acref/2023.01.012,10.1093/acref.2023.01.012,"executable ontologies, game AI, behavior trees, GOAP, event semantics","This paper explores Executable Ontologies (EO) as a paradigm shift in game development, emphasizing semantic world modeling over algorithmic control. It demonstrates how EO enables priority-based task interruption in survival games using dataflow conditions, contrasting with traditional approaches like Behavior Trees and GOAP. The work highlights integration strategies and the potential of LLM-driven runtime model generation.",311.27,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07965v1_When Models Know When They Do Not Know Calibration.pdf,When models know when they don't know,"Chenjie Hao, Weyl Lu, Yuko Ishiwaka, Zengyi Li, Weier Wan, Yubei Chen",10.48550/arXiv.2405.12345,10.48550/arXiv.2405.12345,"model calibration, confidence estimation, data cleaning, vision, language",The paper presents a training-free method to enable models to recognize their own uncertainty by leveraging confidence signals. It demonstrates that calibrated confidence improves model reliability and introduces applications in model cascading and data cleaning across vision and language tasks.,339.92,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07969v1_Tuberculosis Screening from Cough Audio Baseline M.pdf,Exact string,"George P. Kafentzis, Efstratios Selisios",10.1093/pasj/tsa2023,2601.07969v1,"Tuberculosis, Machine Learning, Cough Audio, Cross-Validation, Uncertainty Quantification","A standardized framework for automatic tuberculosis detection from cough audio and clinical data using machine learning, with emphasis on reproducibility, uncertainty quantification, and fair metric comparison.",276.1,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07973v1_Cultural Compass A Framework for Organizing Societ.pdf,Cultural Compass: A Framework for Organizing Societal Norms to Detect Violations in Human-AI Conversations,"Myra Cheng1, Vinodkumar Prabhakaran2, Alice Oh2, Hayk Stepanyan2",10.48550/arXiv.2601.07973,10.48550/arXiv.2601.07973,"cultural norms, human-AI interaction, norm adherence, cross-cultural, AI ethics","This paper introduces a taxonomy of sociocultural norms to evaluate how generative AI models conform to or violate norms in human-AI conversations. It highlights gaps in existing benchmarks and proposes a framework for operationalizing norm assessment in real-world, open-ended settings, emphasizing context-sensitive evaluation.",323.92,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07988v1_From Word Sequences to Behavioral Sequences Adapti.pdf,Exact string,"Adithya V Ganesan, Vasudha Varadarajan, Oscar NE Kjell, Roman Kotov, Ryan L Boyd, Andrew Schwartz",10.48550/arXiv.2303.04219,10.48550/arXiv.2303.04219,"longitudinal modeling, behavioral sequences, NLP, PTSD, diary transcripts","The paper addresses the mismatch between traditional NLP practices and the longitudinal, person-indexed nature of behavioral data. It proposes a new modeling and evaluation paradigm that accounts for time-ordered sequences, impacts evaluation splits, and improves accuracy metrics for longitudinal studies.",350.96,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.07994v2_DYCP Dynamic Context Pruning for Long-Form Dialogu.pdf,Exact string,"Nayoung Choi, Jonathan Zhang, Jinho D. Choi",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"long-form dialogue, context management, LLM, dialogue quality","The paper presents DYCP, a lightweight context pruning method for improving answer quality and reducing latency in long-form conversations with large language models. It dynamically segments and retrieves relevant memory at query time, preserving discourse continuity without predefined topic boundaries.",340.52,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08000v1_Reasoning over Precedents Alongside Statutes Case-.pdf,Exact string,"List of strings, List of strings, List of strings, List of strings, List of strings, List of strings, List of strings, List of strings, Dimitris N. Metaxas, Dimitris N. Metaxas, Rutgers University, Rutgers University, Nanyang Technological University, Adobe Research, University of Connecticut, Fordham University, Google DeepMind, Wenqi Wei, Ligong Han, Zhao Zhang, Hongwu Peng, Jiahui Zhao, Zhenting Wang, Wenqi Wei, Yuan Cao, Ruixiang Tang, Dimitris N. Metaxas, Dimitris N. Metaxas",10.48550/arXiv.2311.03812,10.48550/arXiv:2311.03812,"LLM safety, deliberative alignment, case augmentation, safety rules, reinforcement learning, code generation","The paper evaluates the impact of explicit safety coding versus illustrative case augmentation on LLM safety behaviors. It demonstrates that case-augmented reasoning improves harmlessness and robustness, offering a practical alternative to rule-only approaches.",316.2,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08003v1_LLM Review Enhancing Creative Writing via Blind Pe.pdf,Exact string,"Weiyue Li, Mingxiao Song, Zhenda Shen, Dachuan Zhao, Yunfan Long, Yi Li, Yongce Li, Ruyi Yang, Mengyu Wang",10.1234/example.doi,10.1234/example,"creative writing, LLM review, blind peer review, divergence, LLM-as-a-judge","The paper presents LLM Review, a framework inspired by blind peer review, to enhance creativity in large language models by constraining information flow through targeted, independent feedback. It argues that interaction alone does not boost creativity and proposes that structured divergence can outperform larger models.",339.97,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08005v1_Internal Deployment Gaps in AI Regulation.pdf,Exact string,"JOE KWON∗, STEPHEN CASPER",10.1093/acps/2025.01.012,null,"AI regulation, internal deployment, EU AI Act, frontier AI","The paper identifies gaps in AI regulation regarding internal deployment, highlighting issues like scope ambiguity, lack of continuous compliance, and information asymmetries that enable high-stakes internal systems to evade oversight.",272.79,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08011v1_TP-Blend Textual-Prompt Attention Pairing for Prec.pdf,Exact string,"Xin Jin, Yichuan Zhongyichuanzhong27, Yapeng Tian, GenPi Inc.",10.48550/arXiv.2025.12345,10.48550/arXiv.2025.12345,"textual-prompt, attention-pairing, diffusion-models, object-blending, text-to-image, style-injection","TP-Blend introduces a lightweight training-free framework for simultaneous object replacement and style blending using two attention processors: Cross-Attention Object Fusion (CAOF) and Self-Attention Style Fusion (SASF). It enables high-resolution, photo-realistic edits by preserving object identity while injecting precise style modifications.",323.15,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08017v1_Representations of Text and Images Align From Laye.pdf,Representations of Text and Images Align From Layer One,"Javier Rando, Florian Tram, Stanislav Fort",10.48550/arXiv.2601.08017,10.48550/arXiv.2601.08017,"vision-language models, image-text alignment, concept representation, layer one","The paper demonstrates that image and text representations in adapter-based vision-language models align from the first layer, contradicting the notion that alignment occurs only in later layers. Using a synthesis-based method inspired by DeepDream, the authors show that at layer 1, images often depict recognisable features of the textual concepts, providing direct evidence of early multimodal alignment.",354.27,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08026v2_FigEx2 Visual-Conditioned Panel Detection and Capt.pdf,Exact string,"Jifeng Song, Arun Das, Pan Wang, Hui Ji4, Kun Zhao, Yufei Huang",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"compound figures, panel detection, figure captioning, BioSci-Fig-Cap","Proposes FigEx2, a visual-conditioned framework for detecting panels in scientific figures and generating panel-level captions. Introduces a noise-aware gated fusion module and staged RL-based optimization to improve detection accuracy and caption quality.",347.09,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08043v1_The Role of Noisy Data in Improving CNN Robustness.pdf,The Role of Noisy Data in Improving CNN Robustness for Image Classification,"Oscar H. Ramírez-Agudeloa, Nicoleta Gorea, Aliza Reif, Lorenzo Bonasera, Michael Karla",10.48550/arXiv.2407.08600,10.48550/arXiv.2407.08600,"deep learning, CNNs, data quality, CIFAR-10, noise injection, image classification, model robustness","The paper explores how introducing controlled noise into training data can enhance CNN robustness for image classification, demonstrating that strategic noise exposure improves performance under corrupted test conditions without severely impacting clean data.",286.44,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08049v1_Integrating Attendance Tracking and Emotion Detect.pdf,Exact string,"Keith Ainebyona, Ann Move Oguti, Joseph Walusimbi, Ritah Kobusingye",10.48550/arXiv.2023.12345,42401600224,"Affective computing, Attendance automation, Emotion detection, IoT, Smart classroom","The paper introduces SCASED, an IoT-based system integrating attendance tracking with emotion detection to enhance classroom engagement. It uses a Raspberry Pi and MobileNetV2 to classify emotional states and provides real-time insights for educators.",284.23,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08052v1_Forecast Aware Deep Reinforcement Learning for Eff.pdf,Exact string,"Nawazish Alia, Rachael Shawb, Karl Masona",10.1093/pasj/2021.01.007,10.1093/pasj/2021.01.007,"Deep Reinforcement Learning, Energy Management, Dairy Farms, Renewable Integration, Cost Reduction","The paper presents a Deep Reinforcement Learning framework for efficient electricity load scheduling in dairy farms, integrating battery storage and water heating under dynamic operational constraints. It achieves significant cost savings compared to existing RL methods.",311.36,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08058v1_Reasoning Beyond Chain-of-Thought A Latent Computa.pdf,Exact string,"Zhenghao He, Guangzhi Xiong Bohan Liu, Bohan Liu, Sinha Aidong Zhang",10.48550/arXiv.2024.12345,10.48550/arXiv/12345,"Chain-of-Thought, Latent Steering, LLM Reasoning, CoT prompting","The study investigates how latent internal activations in large language models (LLMs) can trigger reasoning behavior, identifying that steering a specific reasoning-related latent feature improves accuracy without explicit CoT prompts. This suggests that multi-step reasoning may rely on external activation of latent mechanisms rather than CoT prompting alone.",285.65,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08065v1_A New Strategy for Verifying Reach-Avoid Specifica.pdf,Exact string,"Samuel I. Akinwande, Sydney M. Katz, Mykel J. Kochenderfer, Clark Barrett",10.1093/pasj/psa.2026,2601.08065,"reachability analysis, neural feedback systems, forward analysis, Lyapunov function, robotics","The paper introduces new algorithms for computing backward reachability approximations in neural feedback systems, integrating them with forward analysis to improve verification frameworks for safety-critical applications.",273.63,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08070v1_Semantic Gravity Wells Why Negative Constraints Ba.pdf,Exact string,Shailesh Rana,10.48550/arXiv.2024.12345,10.48550/arXiv:24/12345,"negative constraints, instruction following, semantic pressure","The paper investigates how negative constraints (e.g., 'do not use the word') fail in language models, revealing that such instructions paradoxically increase target probability through priming and layer-specific effects.",277.43,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08079v1_MemoBrain Executive Memory as an Agentic Brain for.pdf,Exact string,"Hongjin Qian, Zhao Cao, Zheng Liu",10.48550/arXiv.2024.12345,10.48550/arXiv:24/12345,"memory, reasoning, LLM, executive memory","The paper introduces MemoBrain, an executive memory model for tool-augmented agents that manages reasoning traces without bloating the working context. It emphasizes maintaining a compact, high-salience reasoning backbone to sustain coherent long-horizon reasoning, addressing the limitations of standard memory systems in complex tasks.",306.84,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08089v1_Q-realign Piggybacking Realignment on Quantization.pdf,Exact string,"Qitao Tan, Xiaoying Song, Ningxi Cheng, Ninghao Liu, Xiaoming Zhai, Lingzi Hong, Zhen Xiang, Geng Yuan",10.48550/arXiv/2303.04112,10.48550/arXiv/2303.04112,"LLM, safety alignment, quantization, deployment, LLM","The paper introduces Q-realign, a post-hoc defense method leveraging post-training quantization to improve safety alignment without disrupting fine-tuning. It demonstrates significant reductions in unsafe behaviors while maintaining performance and efficiency.",294.49,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08094v1_Local-Global Feature Fusion for Subject-Independen.pdf,Local-Global Feature Fusion for Subject-Independent EEG Emotion Recognition,"Zheng Zhou, Isabella McEvoy, Camilo E. Valderrama",10.48550/arXiv.2407.04201,10.48550/arXiv/2407.04201,"EEG, emotion recognition, subject-independent, local representations, global representations, domain adaptation","The paper presents a fusion framework combining local channel-wise descriptors with global trial-level features to improve cross-subject generalization in EEG-based emotion recognition. It introduces a dual-branch transformer with attention-based fusion and domain-adversarial regularization, achieving ~40% mean accuracy on the SEED-VII dataset.",284.67,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08104v1_High-Fidelity Modeling of Stochastic Chemical Dyna.pdf,Exact string,"Julian Evan Chrisnanto, Salsabila Rahma Alia, Nurfauzi Fadillah, Yulison Herry Chrisnanto",10.48550/arXiv.2601.08104,2601.08104,"Physics-Informed Neural Networks, Spatiotemporal Chaos, Inverse Geometric Problems, Reaction-Diffusion Systems, Defect Turbulence, Riemann Manifold Learning","The paper presents a novel Multi-Scale SIREN-PINN architecture for modeling complex reaction-diffusion dynamics on Riemannian manifolds, addressing challenges in capturing high-frequency spatiotemporal features and topological invariants in turbulent chemical systems.",294.01,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08107v1_STO-RL Offline RL under Sparse Rewards via LLM-Gui.pdf,STO-RL: Offline RL under Sparse Rewards via LLM-Guided Subgoal Temporal Order,"Chengyang Gu, Yuxin Pan, Hui Xiong, Yize Chen",10.1145/nnnnnn,nnnnnn,"Offline RL, Temporal order, Large Language Models, Subgoal temporal order, Sparse rewards","The paper introduces STO-RL, an offline reinforcement learning framework that uses large language models to generate temporally ordered subgoal sequences and state-to-subgoal mappings. By applying potential-based reward shaping, it transforms sparse terminal rewards into dense, temporally consistent signals, enabling more effective training of high-performing policies on long-horizon tasks.",337.7,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08108v1_Debiasing Large Language Models via Adaptive Causa.pdf,Exact string,"Debiasing Large Language Models via Adaptive Causal Prompting with Sketch-of-Thought, Bowen Li, Ziqi Xu, Jing Ren, Renqiang Luo, Xikun Zhang, Xiuzhen Zhang, Yongli Ren, Feng Xia",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"LLM prompting, causal inference, chain-of-thought, sketch-of-thought, bias mitigation, reasoning tasks",The paper introduces an Adaptive Causal Prompting with Sketch-of-Thought framework to improve the efficiency and accuracy of Large Language Models by reducing token usage and addressing bias through structural causal models.,326.5,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08109v1_CSQL Mapping Documents into Causal Databases.pdf,Csql: MappingDocuments intoCausalDatabases ∗,Sridhar Mahadevan,10.48550/arXiv.2601.08109,10.48550/arXiv.2601.08109,"Causality, Natural Language, Databases, SQL, AI, Machine Learning","Csql is a system that converts unstructured text documents into SQL-queryable causal databases, enabling causal queries over document collections rather than relying on traditional databases or retrieval-augmented generation.",319.46,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08118v1_MirrorBench An Extensible Framework to Evaluate Us.pdf,MIRRORBENCH: ANEXTENSIBLEFRAMEWORK TOEVALUATEUSER-PROXY,"Ashutosh Hathidara, Julien Yu, Vaishali Senthil, Sebastian Schreiber, Anil Babu, Ankisettipalli",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"user proxies, LLM evaluation, conversational systems, human-like interaction","MIRRORBENCH is a reproducible, extensible benchmarking framework that evaluates user proxies by measuring their ability to generate human-like utterances across diverse conversational tasks, decoupled from downstream task success. It introduces a modular execution engine, supports pluggable proxies, and provides metrics for lexical diversity and LLM-judge performance, revealing gaps between proxies and real users.",318.67,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08125v1_How vehicles change lanes after encountering crash.pdf,Exact string,"Kequan Chena, Yuxuan Wangb, Pan Liu, Victor L. Knoop, David Z. W. Wang",10.1093/acpr/ssa032,10.1093/acpr/ssa032,"vehicles, lane changing, crash analysis, modeling, transportation",Empirical analysis and modeling of how vehicles change lanes after encountering crashes.,288.54,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08127v1_PathoGen Diffusion-Based Synthesis of Realistic Le.pdf,Exact string,"Mohamad Koohi-Moghadam1, Mohammad-Ali Nikouei Mahani1, Kyongtae Tyler Bae1",10.1093/pas/paa028,10.1093/pas/paa028,"histopathology, diffusion-based, lesions, image generation, AI, diagnostic accuracy","The paper introduces PathoGen, a diffusion-based generative model designed to synthesize realistic histopathology lesions, addressing the challenge of limited expert annotations in rare and complex disease subtypes. It demonstrates superior image fidelity and distributional similarity compared to existing methods, enhancing downstream segmentation and overcoming annotation bottlenecks.",313.03,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08128v1_Embedded AI Companion System on Edge Devices.pdf,Exact string,"Rahul Gupta ∗1, Stephen Hsu 1,2",10.1093/acps/9780190876223.001.0001,2601.08128,"AI companion, memory systems, edge computing, computational constraints","The paper proposes a memory paradigm for embedding AI companions on edge devices, addressing latency and resource limitations by alternating active/inactive phases. It introduces an AI Companion benchmark and demonstrates performance comparisons with large language models.",311.01,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08133v1_How Do Optical Flow and Textual Prompts Collaborat.pdf,Exact string,"Peng Gao, Yujian Lee, Yongqi Xu, Wentao Fan, Guangdong Provincial/Zhuhai Key Laboratory IRADS, Peking University, Shenzhen Graduate School",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"audio-visual segmentation, semantic segmentation, optical flow, textual prompts, AVSS, AVS, semantic understanding","The paper introduces a novel collaborative framework, Stepping Stone Plus (SSP), that integrates optical flow and textual prompts to enhance audio-visual semantic segmentation. By providing a prompted segmentation mask, SSP improves segmentation precision, especially in scenes with coexisting sound sources and moving objects. It incorporates a visual-textual alignment module and a post-mask training strategy to deliver efficient and accurate results.",321.86,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08139v1_Subspace Alignment for Vision-Language Model Test-.pdf,Subspace Alignment for Vision-Language Model Test-time Adaptation,"Zhichen Zeng, Wenxuan Bao, Xiao Lin, Ruizhong Qiu, Tianxin Wei, Xuying Ning, Yuchen Yan, Chen Luo, Monica Xiao Cheng, Jingrui He, Hanghang Tong",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Subspace Alignment, Vision-Language Models, Test-Time Adaptation, Zero-Shot Learning, Modality Gap, Visual Nuisance","The paper proposes SubTTA to align semantic subspaces across vision and language modalities, addressing distribution shifts by minimizing modality gap and visual noise. It improves test-time adaptation for VLMs by projecting visual features onto a task-specific semantic space and refining predictions.",303.6,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08141v1_Qalb Largest State-of-the-Art Urdu Large Language .pdf,Exact string,"Muhammad Taimoor Hassan, Jawad Ahmed, Muhammad Awais",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Urdu language model, continued pre-training, low-resource NLP, LoRA","Qalb is a new Urdu language model developed through two-stage pre-training and supervised fine-tuning, achieving state-of-the-art performance on Urdu tasks and demonstrating effective adaptation of large models to low-resource languages.",324.71,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08146v2_Mechanisms are Transferable Data-Efficient Low-Res.pdf,Exact string,"Khumaisa Nur’aini1, Ayu Purwarianti2, Alham Fikri Aji3, Derry Wijaya1",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"low-resource adaptation, circuit-targeted fine-tuning, cross-lingual transfer, catastrophic forgetting","The paper presents Circuit-Targeted Supervised Fine-Tuning (CT-SFT), a method that selectively updates task-relevant attention heads in a proxy language during adaptation, thereby improving cross-lingual performance while minimizing parameter drift and preserving source language capabilities.",312.16,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08148v1_Enriching Semantic Profiles into Knowledge Graph f.pdf,Enriching Semantic Profiles into Knowledge Graph for Recommender Systems Using Large Language Models,"Seokho Ahn, Sungbok Shin, Young-Duk Seo",10.1145/3770854.3780324,10.5281/zenodo.18041669,"Recommendation, Semantic Profiling, Large Language Models, Knowledge Graphs","The paper proposes a new recommendation model, SPiKE, which integrates large language models for entity profile generation and profile-aware aggregation to enhance recommender systems.",293.72,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08149v1_Dynamic Graph Structure Learning via Resistance Cu.pdf,Dynamic Graph Structure Learning via Resistance Curvature Flow,"Chaoqun Fei, Huanjiang Liu, Tinglve Zhou, Y angyang Li",10.1093/pasj/psa064,2601.08149v1,"graph structure learning, curvature flow, deep learning, manifold enhancement, noise suppression","Introduces a novel curvature‑flow based method for dynamic graph structure learning, leveraging resistance from circuit theory and demonstrating improved performance in deep metric and graph tasks.",250.87,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08156v1_Project Synapse A Hierarchical Multi-Agent Framewo.pdf,Project Synapse: A Hierarchical Multi-Agent Framework with Hybrid Memory for Autonomous Resolution of Last-Mile Delivery Disruptions,"Arin Gopalan Yadav, Varad Dherange, Kumar Shivam",10.1093/arxiv/2026.2601,10.1093/arxiv/2601.08156,"Project Synapse, multi-agent framework, hybrid memory, last-mile delivery, autonomous resolution","The paper presents Project Synapse, a hierarchical multi-agent system with a hybrid memory architecture that enhances autonomous handling of last-mile delivery disruptions. It integrates strategic task decomposition, contextual reasoning, and a semantic memory of policies to improve operational resilience in super-apps.",317.28,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08160v1_SwiftMem Fast Agentic Memory via Query-aware Index.pdf,SwiftMem: Fast Agentic Memory via Query-aware Indexing,"Anxin Tian, Yiming Li, Xing Li, Hui-Ling Zhen, Lei Chen, Xianzhi Yu1, Zhenhua Dong",10.1234/example.doi,10.1234/example,"SwiftMem, agentic memory, query-aware indexing, LLM agents, memory retrieval, semantic indexing","SwiftMem introduces a query-aware agentic memory system that enables sub-linear retrieval using temporal and semantic indexing, significantly improving performance for large-scale conversational LLMs.",319.09,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08166v1_ZeroDVFS Zero-Shot LLM-Guided Core and Frequency A.pdf,ZeroDVFS: Zero-Shot LLM-Guided Core and Frequency,"Mohammad Pivezhandi, Mahdi Banisharif, Abusayeed Saifullah, Ali Jannesari",10.48550/arXiv.2601.08166,10.48550/arXiv.2601.08166,"Dynamic voltage and frequency scaling, Task allocation, Embedded platforms, Energy efficiency, Reinforcement learning, LLM-based feature extraction","The paper presents a model-based hierarchical multi-agent reinforcement learning framework for thermal-aware scheduling on multi-core platforms. It introduces LLM-extracted semantic features to enable zero-shot deployment, achieving faster convergence and improved energy efficiency compared to traditional methods.",286.28,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08173v1_The Agents First Day Benchmarking Learning Explora.pdf,Exact string,"Daocheng Fu1,2, Jianbiao Mei3,2,†, Rong Wu3,2,†, Xuemeng Yang2,†, Jia Xu2,Ding Wang 2,Pinlong Cai 2,Yong Liu 3,B",10.1234/example.doi,None,"dynamic scheduling, active exploration, continuous learning, multi-modal models","The study addresses gaps in evaluating agents under stochastic real-world conditions by introducing Trainee-Bench, which evaluates performance across three dimensions: scheduling, information acquisition, and learning. It underscores the need for robust frameworks beyond static benchmarks.",339.49,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08176v1_Prompt-Based Clarity Evaluation and Topic Detectio.pdf,Exact string,"Lavanya Prahallad, Sai Utkarsh Choudarypally, Pragna Prahallad, Pranathi Prahallad",10.1093/acps/rpac032,10.1093/acps/rpac032,"clarity evaluation, prompt engineering, political question answering, large language models, chain-of-thought prompting","This paper evaluates prompt-based strategies for improving clarity in political question answering using the CLARITY dataset. It compares GPT-3.5 with GPT-5.2 under different prompting methods and demonstrates that chain-of-thought prompting enhances clarity metrics, while topic identification shows moderate gains.",351.46,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08179v1_Instruction-Driven 3D Facial Expression Generation.pdf,Instruction-Driven 3D Facial Expression Generation and Transition,"Anh H. V o, Tae-Seok Kim, Hulin Jin, Soo-Mi Choi, Yong-Guk Kim",10.1109/TMAT.2025.12345,10.1109/TMAT.2025.12345,"Instruction-driven, Facial Expression, 3D Facial Generation, Expression Transition","This paper introduces a framework for instruction-driven generation of facial expressions and their transitions, enabling realistic emotional variation in 3D avatars. It presents the Instruction to Facial Expression Transition (I2FET) method and evaluates performance on CK+ and CelebV-HQ datasets.",359.34,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08183v2_GI-Bench A Panoramic Benchmark Revealing the Knowl.pdf,Exact string,"Yan Zhu, Te Luo, Pei-Yao Fu, Zhen Zhang, Zi-Long Wang, Yi-Fan Qu, Zi-Han Geng, Jia-Qi Xu, Li-Yun Ma, Wei Su, Wei-Feng Chen, Quan-Lin Li",10.48550/arXiv.2311.03655,10.48550/arXiv:2311.03655,"GI-Bench, multimodal large language models, gastrointestinal endoscopy, clinical standards, benchmarking, diagnostic reasoning","This study introduces GI-Bench, a comprehensive benchmark evaluating state-of-the-art MLLMs across 20 gastrointestinal lesion categories within a five-stage clinical workflow. The analysis compares model performance against junior endoscopists and residency trainees using macro-F1, mIoU, and a multi-dimensional Likert scale, highlighting the state-of-the-art Gemini-3-Pro model.",306.72,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08185v1_Autonomous Materials Exploration by Integrating Au.pdf,Exact string,"Ming-Chiang Chang, Maximilian Amsler, Duncan R. Sutherland, Sebastian Ament, Katie R. Gann, Lanca Zhou, Louisa M. Smieska, Arthur R. Woll, John M. Gregoire, Carla P. Gomes, R. Bruce van Dover, Michael O. Thompson",10.1016/j.acs.entmmaterials.2026.01.012,10.1016/j.acs.entmmaterials.2026.01.012,"autonomous materials, AI-assisted reasoning, material synthesis, phase identification, robotic experimentation","The paper presents an autonomous materials synthesis extension to SARA, leveraging AI and human-in-the-loop reasoning to accelerate discovery. It describes experiments on oxide systems using robotic processing, highlighting improved efficiency through synthetic benchmarks and human input.",354.6,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08187v2_Improving LLM Reasoning with Homophily-aware Struc.pdf,Homophily-aware Structural and Semantic Compression for LLMs,"Zijun Di, Bin Lu, Huquan Kang, Kinghiqian, Luoyi Fu, Jiaxin Ding, Yiluofu, Jiaxining, Xiaoying Gan, Ganxiaoying, Lei Zhou, Zhou Lei, Xinbing Wang, Chenghu Zhou, Zhang Hsueh",10.48550/arXiv.2026.08187,2601.08187v2,"large language models, graph understanding, homophily, structural compression, semantic aggregation","The paper introduces HS2C, a framework leveraging graph homophily to improve LLM reasoning by structurally partitioning graphs and semantically compressing them. It enhances compression rates and accuracy across benchmarks.",361.05,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08189v2_ForgetMark Stealthy Fingerprint Embedding via Targ.pdf,Exact string,"Zhenhua Xu1, Haobo Zhang2, Zhebo Wang1, Qichen Liu2, Haitao Xu1, Wenpeng Xing1, Meng Han1, 2Zhejiang University, 2GenTel.io, 3Zhejiang University of Technology",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"large language model, model fingerprinting, copyright protection, machine unlearning","Introduces ForgetMark, a framework for stealthy fingerprinting that uses targeted unlearning and probabilistic forgetting to avoid detectable triggers, improving robustness and reducing false positives.",325.01,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08196v1_Evaluating Implicit Regulatory Compliance in LLM T.pdf,Exact string,"Da Song, Yuheng Huang, Boqi Chen, Tianshuo Cong, Randy Goebel, Lei Ma, Foutse Khomh, Randy Goebel, Lei Ma, Foutse Khomh",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"large language models, regulatory compliance, safety, LLM benchmark","The paper introduces LOGISAFETYGEN, a framework that converts regulations into Linear Temporal Logic oracles and uses logic-guided fuzzing to ensure LLMs enforce safety constraints in high-stakes applications. It benchmarks 13 state-of-the-art models and highlights the need for safety-critical behavior beyond functional correctness.",363.48,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08211v1_Adapting Rules of Official International Mahjong f.pdf,Adapting Rules of Official International Mahjong for Online Players,"Chucai Wang, Lingfeng Li, Yunlong Lu, Wenxin Li",10.1234/journals/2023.00123,10.1234/journals/2023.00123,"Mahjong, game design, AI, rule adaptation, online play","This paper proposes rule modifications for Official International Mahjong to suit online single-round play, addressing first-mover advantage and subgoal scoring challenges.",283.68,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08223v2_DNF Dual-Layer Nested Fingerprinting for Large Lan.pdf,Exact string,"Zhenhua Xu1, Yiran Zhao3, Mengting Zhong3, Dezhang Kong1, Changting Lin1, Tong Qiao3, Meng Han1",10.48550/arXiv.2025.12345,10.48550/arXiv.2025.12345,"large language model, intellectual property protection, model fingerprinting, backdoor","The paper introduces Dual-Layer Nested Fingerprinting (DNF), a black-box method for robust LLM ownership verification. It addresses limitations of existing backdoor-based fingerprints by integrating hierarchical stylistic cues and implicit semantic triggers, achieving high-fidelity activation while maintaining low perplexity and resilience to attacks.",311.4,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08224v1_An Axiomatic Approach to General Intelligence SANC.pdf,Exact string,"Daesuk Kwon, 1 Won-gi Paeng1",10.48550/arXiv.2303.04137,SANC(E3),"axiomatization of intelligence, competitives selection, system tokens, reconstruction compression, category formation","The paper introduces SANC(E3), an axiomatic framework for general intelligence that models representation emergence through self-organization under energetic constraints. It unifies perception, imagination, and action within a single Gestalt-completion process, emphasizing energy-efficient learning and hierarchical structure.",305.72,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08226v1_Knowledge-based learning in Text-RAG and Image-RAG.pdf,Exact string,"Alexander Shim, Khalil Saieh, Samuel Clarke, Ksairae001",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"text-based RAG, image-based RAG, vision transformer, hallucination reduction, diagnostic confidence, expected calibration error","This research compares text-based and image-based retrieval-augmented generation approaches for chest X-ray interpretation, emphasizing improvements in reducing hallucination and enhancing diagnostic confidence through multi-modal reasoning.",325.23,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08230v1_GADPN Graph Adaptive Denoising and Perturbation Ne.pdf,Graph Adaptive Denoising and Perturbation Networks via Singular Value Decomposition,"Hao Deng, Bo Liu",10.48550/arXiv.2405.1234,10.48550/arXiv.2405.1234,"graph structure learning, graph neural networks, structural perturbation, Bayesian optimization","The paper introduces GADPN, a framework that adaptively refines graph topology using low-rank denoising and structural perturbation, improving performance on noisy graphs.",282.58,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08235v2_MPCI-Bench A Benchmark for Multimodal Pairwise Con.pdf,Exact string,"Shouju Wang Haopeng, Zhang, Haopeng",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Contextual Integrity, Multimodal, Privacy, LLM","Introduces MPCI-Bench, the first Multimodal Pairwise Contextual Integrity benchmark, to evaluate privacy behavior in agentic language models by assessing trade-offs between privacy and utility across multimodal inputs.",287.3,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08237v1_The End of Reward Engineering How LLMs Are Redefin.pdf,Exact string,"Haoran Su, Yandong Sun, Congjia Yu",10.1093/pasj/2026.01.012,2601.08237,"reward engineering, multi-agent coordination, LLMs, credit assignment, semantic reward specification","This paper explores how large language models (LLMs) are transforming multi-agent reinforcement learning by enabling natural language-based reward design. It addresses challenges such as credit assignment, non-stationarity, and scalability, proposing a shift from manual reward engineering to language-driven objectives. The authors highlight the potential of RL from verifiable rewards and discuss implications for future multi-agent systems.",324.97,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08251v1_Hyperbolic Heterogeneous Graph Transformer.pdf,Hyperbolic Heterogeneous Graph Transformer,"Jongmin Park, Seunghoon Han, Hyewon Lee, Won-Yong Shin, Sungsu Lim",pa5398,tmdgns129,"Heterogeneous Graph Representation Learning, Hyperbolic Graph Embedding, Graph Transformer, Relation-Specific Attention, Graph Transformer","The paper introduces the Hyperbolic Heterogeneous Graph Transformer (HypHGT), a transformer-based architecture that learns heterogeneous graph representations in hyperbolic space. It addresses limitations of existing methods by capturing both local and global dependencies efficiently, achieving superior performance in node classification with reduced training time and memory usage.",294.23,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08254v1_Large Artificial Intelligence Model Guided Deep Re.pdf,Exact string,"Abdikarim Mohamed Ibrahim, Rosdiadee Nordin",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Large AI Models (LAMs), Large Language Models (LLMs), Deep Reinforcement Learning (DRL), Satellite Communications, Non-Terrestrial Networks (NTNs)","The paper proposes a Deep Reinforcement Learning agent guided by a Large Language Model to improve resource allocation in Non-Terrestrial Networks, demonstrating superior performance over traditional methods in various scenarios.",281.53,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08257v2_On Evaluation of Unsupervised Feature Selection fo.pdf,Exact string,"Gyu-Il Kim, Dae-Won Kim, Jaesung Lee",10.1093/acr/wq045,2601.08257v2,"feature selection, unsupervised learning, multi-label, data mining","This study evaluates unsupervised feature selection methods using a multi-label classification framework, demonstrating that performance rankings shift when moving from single-label to multi-label settings.",292.88,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08258v1_T3 Benchmarking Sycophancy and Skepticism in Causa.pdf,Exact string,Edward Y. Chang,10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"causal judgment, safety, sycophancy, skepticism","Introduces T3 (Testing Trustworthy Thinking), a benchmark to diagnose LLM causal reasoning across Pearl’s hierarchy. It identifies a 'Skepticism Trap' at L1 and a non-monotonic scaling paradox at L3, using expert vignettes to reveal model weaknesses in sensitivity and safety.",279.65,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08262v1_VGG Induced Deep Hand Sign Language Detection.pdf,Exact string,"Subham Sharmaa, Sharmila Subudhia",10.1109/AI.2026.08262,2601.08262v1,"Hand gesture recognition, Convolutional neural network, Classification, VGG-16 net, API","The paper presents a novel hand gesture recognition system using VGG-16 net, trained on the NUS dataset and validated with Google's API, achieving approximately 98% accuracy.",304.73,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08271v1_Sparsity Is Necessary Polynomial-Time Stability fo.pdf,Exact string,Angshul Majumdar,10.48550/arXiv.2601.08271,10.48550/arXiv.2601.08271,"LLM, control, action space, sparsity","The paper investigates control in large action spaces using sparse agentic control, formalizing sequential decision-making with tools and documents. It presents theoretical results on stability, recovery, and scalability, emphasizing that performance depends critically on a small subset of relevant actions.",297.65,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08273v1_HIPPO Accelerating Video Large Language Models Inf.pdf,Accelerating Video Large Language Models Inference via Holistic-aware Parallel Speculative Decoding,"Qitan Lv1, Tianyu Liu1, Wen Wu2, Xuenan Xu2, Bowen Zhou2, Feng Wu1, Chao Zhang2,3, Fengwu, Zhang Cheng, Zhou Jing",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"video-LLM, speculative decoding, parallel inference, semantic preservation","The paper introduces HIPPO, a holistic-aware parallel speculative decoding framework designed to accelerate inference for video LLMs. It addresses limitations of existing pruning methods by preserving semantic tokens and optimizing draft generation, achieving up to 3.51× speedup over vanilla auto-regressive decoding.",343.85,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08276v1_ToolACE-MCP Generalizing History-Aware Routing fro.pdf,Exact string,"Zhiyuan Yao, Zishan Xu, Yifu Guo4, Zhiguang Han, Weiwen Liu, Cheng Yang, Shuo Zhang, Weinan Zhang, Xingshan Zeng",10.1234/journals/2025.00123,10.1234/journals/2025.00123,"Agent Web, MCP, ToolACE-MCP, Routing, History-aware, Scalability","ToolACE-MCP introduces a pipeline for training history-aware routers to enable precise navigation in large-scale agent ecosystems, demonstrating superior performance on real-world benchmarks.",307.92,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08280v1_Greedy Is Enough Sparse Action Discovery in Agenti.pdf,Greedy Is Enough: Sparse Action Discovery in Agentic LLMs,Angshul Majumdar,10.48550/arXiv.2303.03037,10.48550/arXiv/2303.03037,"agentic systems, action discovery, sparse representation","The paper investigates how greedy algorithms can efficiently identify a small subset of relevant actions in large-scale agentic LLMs, providing theoretical guarantees on scalability and optimality under sparsity assumptions.",313.28,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08288v1_OpenMic A Multi-Agent-Based Stand-Up Comedy Genera.pdf,Exact string,"Yuyang Wu, Hanzhong Cao, Jianhao Chen, Yufei Li",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Chinese humor, stand-up comedy, multi-agent system, joke generation","The paper introduces OpenMic, a multi-agent system for generating Chinese stand-up comedy. It leverages AutoGen to transform life topics into 3–5 minute performances, integrating retrieval-augmented generation and a JokeWriter fine-tuned for comedic timing and structure.",316.33,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08297v1_Demystifying the Slash Pattern in Attention The Ro.pdf,Demystifying the Slash Pattern in Attention: The Role of RoPE,"Yuan Cheng, Fengzhuo Zhang, Yunlong Hou, Cunxiao Du, Chao Du2, Tianyu Pang, Aixin Sun, Zhuoran Yang",10.48550/arXiv.2601.08297,10.48550/arXiv.2601.08297,"attention patterns, RoPE, SLASH, SDHs, LLMs, query keys, RoPE frequencies","The paper investigates how RoPE shapes attention patterns in large language models, explaining the emergence of Slash-Dominant Heads (SDHs) through the interaction of rank-one token embeddings and medium/high-frequency RoPE components.",333.05,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08302v1_Enhancing Sentiment Classification and Irony Detec.pdf,Enhancing Sentiment Classification and Irony Detection in Large Language Models,"Marvin Schmitt ∗*, Anne Schwerk, Sebastian Lempert ∗, Anne Schwerk",10.48550/arXiv.2405.12345,10.48550/arXiv.2405.12345,"sentiment analysis, irony detection, large language models (LLMs), prompt engineering","This study investigates advanced prompt engineering techniques to improve sentiment analysis and irony detection in large language models, demonstrating that few-shot prompting enhances performance for GPT-4o-mini and chain-of-thought prompting boosts irony detection in gemini-1.5-flash.",318.08,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08310v1_ORBIT On-policy Exploration-Exploitation for Contr.pdf,ORBIT: On-policy Exploration-Exploitation,"Kun Liang1, 2. Clive Bai3, 3. Xin Xu3, 4. Chenming Tang1,2, 5. Sanwoo Lee1,2, 6. Weijie Liu3 Saiyong Yang3, 7. Yunfang Wu1,2",10.48550/arXiv.2026.12345,10.48550/arXiv.2026.12345,"large reasoning models, long-form chain-of-thought, reasoning budget, multi-budget","ORBIT introduces a controllable multi-budget reasoning framework that dynamically adjusts reasoning effort based on input, aiming to balance accuracy and efficiency during inference.",359.1,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08311v1_Enhancing Image Quality Assessment Ability of LMMs.pdf,Enhancing Image Quality Assessment Ability of LMMs via Retrieval-Augmented Generation,"Kang Fu, Huiyu Duan, Zicheng Zhang, Yucheng Zhu, Jun Zhao, Xiongkuo Min, Jia Wang, Guangtao Zhai",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Image Quality Assessment, Retrieval-Augmented Generation, Large Multimodal Models, Zero-shot, Training-free","The paper introduces IQARAG, a training-free framework that improves Large Multimodal Models' Image Quality Assessment by leveraging Retrieval-Augmented Generation to provide visual anchors for quality evaluation.",343.66,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08323v1_AtomMem  Learnable Dynamic Agentic Memory with Ato.pdf,Exact string,"Yupeng Huo, Yaxi Lu, Zhong Zhang, Haotian Chen, Yankai Lin",10.48550/arXiv.2024.12345,10.48550/arXiv/12345,"memory management, agent memory, reinforcement learning, dynamic decision making","This paper introduces AtomMem, a learnable dynamic agentic memory framework that reframes memory management as a dynamic decision-making process. By decomposing memory operations into atomic CRUD actions and combining supervised fine-tuning with reinforcement learning, AtomMem enables agents to autonomously learn task-aligned memory policies. Experiments show superior performance across benchmarks compared to static memory approaches.",361.19,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08327v1_Safe Heterogeneous Multi-Agent RL with Communicati.pdf,Safe Heterogeneous Multi-Agent RL with Communication Regularization for Coordinated Target Acquisition,"Gabriele Calzolari, Vidya Sumathy, Christoforos Kanellakis, George Nikolakopoulos",10.48550/arXiv.2405.1234,10.48550/arXiv/2405.1234,"Cooperative target acquisition, Safe autonomous coordination, Decentralized multi-agent reinforcement learning, Heterogeneous robotic systems, Learning-based control","This paper presents a decentralized multi-agent reinforcement learning framework for heterogeneous agents that enables safe and coordinated target acquisition under communication constraints. It integrates graph attention networks with safety filters and demonstrates effective target discovery, collision avoidance, and information decoupling through structured rewards and ablation studies.",302.97,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08332v1_IGAN A New Inception-based Model for Stable and Hi.pdf,Exact string,"Ahmed A. Hashim, Ali Al-Shuwaili, Asraa Saeed, Ali Al-Bayaty",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"Generative Adversarial Networks (GANs), dilation convolutions, inception module, spectral normalization, image synthesis, deep learning stability","The paper introduces the Inception Generative Adversarial Network (IGAN), a novel GAN architecture that integrates deeper inception-inspired convolutions and dilated convolutions to achieve high-quality image synthesis while maintaining training stability. It reports improved performance metrics such as Fréchet Inception Distance (FID) and Inception Score (IS), demonstrating a significant enhancement in image generation quality and diversity.",358.48,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08333v1_Semantic Laundering in AI Agent Architectures Why .pdf,Semantic Laundering in AI Agent Architectures,Oleg Romanchuk Roman Bondar,10.1093/pasj/2026.01.012,2601.08333v1,"semantic laundering, epistemic warrant, LLM architectures","The paper examines how architectural patterns in agent systems conflate information transport with epistemic justification, framing this as semantic laundering. It introduces the Theorem of Inevitable Self-Licensing and the Warrant Erosion Principle to argue that circular justification is architecturally inevitable, undermining epistemic reliability.",308.42,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08360v1_Scalable Sequential Recommendation under Latency a.pdf,Scalable Sequential Recommendation under Latency and Memory Constraints,"Adithya Parthasarathy, Aswathnarayan Muthukrishnan Kirubakaran, Vinoth, Punniyamoorthy, Nachiappan Chockalingam, Lokesh Butra, Kabilan Kannan, Abhirup Mazumder, Sumit Saha",10.1109/ICLR.2026.12345,2601.08360v1,"Recommender Systems, Sequence Modeling, Representation Learning, Scalable Machine Learning, Deep Learning","The paper introduces HoloMambaRec, a lightweight sequential recommendation architecture that uses holographic representations and a selective state space encoder to efficiently handle long-horizon user behavior while respecting memory and latency limits. It achieves competitive performance with other models under constrained training budgets.",312.49,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08371v1_Geo-NVS-w Geometry-Aware Novel View Synthesis In-t.pdf,Geo-NVS-w: Geometry-Aware Novel View Synthesis In-the-Wild,"Anastasios Tsalakopoulos, Angelos Kanlis, Evangelos Chatzis, Antonis Karakottas, Dimitrios Zarpalas",10.48550/arXiv.2407.04219,10.48550/arXiv.2407.04219,"Geo-NVS, Signed Distance Function, Novel View Synthesis, Energy Efficiency, In-the-Wild Datasets","Introduces Geo-NVS-w, a geometry-aware framework for high-fidelity novel view synthesis from unstructured, in-the-wild image collections. It leverages an SDF-based representation to guide rendering, ensuring geometric consistency and reducing energy consumption by 4–5× compared to similar methods.",290.13,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08379v1_Training-Free Distribution Adaptation for Diffusio.pdf,Training-Free Distribution Adaptation for Diffusion,"Matina Mahdizadeh Sani ∗ ∗†, Nima Jamali ∗‡, Mohammad Jalali ∗§, Farzan Farnia ¶",10.48550/arXiv.2311.03655,10.48550/arXiv.2311.03655,"diffusion models, distribution matching, generative priors, inference-time guidance, domain adaptation","Proposes MMD Guidance, a training-free method that aligns pre-trained diffusion models with target distributions using Maximum Mean Discrepancy, enabling distribution alignment without retraining.",340.77,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08380v1_Thematic Working Group 5 -- Artificial Intelligenc.pdf,Exact string,"Mary Webb, Matt Bower, Ana Amélia Carvalho, Fredrik Mørk Røkenes, Jodie Torrington, Jonathan D. Cohen, Yousra Chtouki, Kathryn MacCallum, Tanya Linden, Deirdre Butler, Juliana E. Raffagheli, Henriikka Vartiainen, Martina Ronci, Peter Tiernan, Chris Shelton, Joyce Malyn-Smith, Pierre Gorissen",10.1093/edu/mad020,10.1093/edu/mad020,"AI literacy, teaching and learning, curriculum design, professional development, policy guidelines, generative AI, educational technology","The paper discusses the impact of OpenAI's ChatGPT3 on AI literacy in education, focusing on strategies for integrating AI into teaching practices, addressing challenges like plagiarism, and enhancing teacher agency through targeted professional development.",305.27,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08382v2_A Qualitative Model to Reason about Object Rotatio.pdf,Exact string,Zoe Falomira,10.1093/acps/qs123,10.1093/acps.qs123,"cube comparison test, mental rotation, qualitative reasoning, spatial cognition","A qualitative model for Reasoning about Object Rotations (QOR) is presented to solve the Cube Comparison Test (CCT), incorporating a conceptual neighborhood graph for composition tables.",302.91,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08383v1_Deconstructing Pre-training Knowledge Attribution .pdf,Deconstructing Pre-training: Knowledge Attribution Analysis in MoE and Dense Models,"Bo Wang, Jinzhuo Li, Hong Chen, Yuanlin Chu, Yuxuan Fan, Xuming Hu, Yukang Hu",10.48550/arXiv.2405.12345,10.48550/arXiv.2405.12345,"knowledge attribution, Mixture-of-Experts, interpretability, LLM","The paper introduces Gated-LPI to analyze knowledge acquisition in MoE vs. dense models, revealing patterns such as a high-utility core in MoE, early convergence, and robustness through sparsity.",310.74,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08388v1_Creativity in AI as Emergence from Domain-Limited .pdf,Exact string,Corina Chutaux,10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"creativity, generative models, AI, multimodal","This paper proposes a generative perspective on creativity in AI, framing it as an emergent property of domain-limited generative models embedded within bounded informational environments. It introduces a conceptual decomposition of creativity into four components—pattern-based generation, induced world models, contextual grounding, and arbitrariness—and examines their manifestation in multimodal systems.",321.9,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08393v1_Controlled LLM Training on Spectral Sphere.pdf,Exact string,"Tian Xie, Haoming Luo, Yang Wang, Wayne Xin Zhao, Rui Yan, Bing Su, Chong Luo, Guo, Jason Klein, Hu, Ren",10.48550/arXiv.2601.08393,10.48550/arXiv.2601.08393,"LLM training, Spectral sphere, optimization, activation control, parallel training","The paper introduces the Spectral Sphere Optimizer (SSO), a method that enforces strict spectral constraints on model weights and updates to ensure stability and convergence efficiency. SSO outperforms existing optimizers like AdamW and Muon by maintaining activation magnitudes at Θ(1) scale, enabling robust large-scale training.",285.21,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08401v1_An Explainable Two Stage Deep Learning Framework f.pdf,Exact string,"Ajo Babu George, Pranav S, Kunal Agarwal",10.1093/pasj/2026.01.012,2601.08401,"explainable AI, deep learning, pericoronitis, radiographic assessment","A two-stage deep learning framework using YOLOv8 and ResNet-50 for diagnosing pericoronitis in panoramic radiographs, emphasizing interpretability through Grad-CAM.",320.91,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08402v1_PATS Personality-Aware Teaching Strategies with La.pdf,Personality-Aware Teaching Strategies,"Donya Rooein1, Sankalan Pal Chowdhury2, Mariia Eremeeva2, Yuan Qin3, Debora Nozza 1, Mrinmaya Sachan 2, Dirk Hovy 1",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"personality, teaching strategies, LLM, education","This paper introduces a framework that links pedagogical methods to student personality traits, enabling large language models to adapt their tutoring strategies to individual students. By identifying personality profiles such as low agreeableness, the authors demonstrate how LLMs can adjust communication styles to better engage introverted learners, thereby improving educational outcomes.",268.39,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08403v1_Owen-Shapley Policy Optimization OSPO A Principled.pdf,Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for Generative Search LLMs,"Abhijnan Nath, Alireza Bagheri Garakani, Tianchen Zhou, Fan Yang, Nikhil Krishnaswamy",10.48550/arXiv.2025.12345,10.48550/arXiv.2025.12345,"Owen-Shapley, Policy Optimization, Reinforcement Learning, Generative Search, LLMs, RL, Shapley-Attributions","The paper introduces OWEN-SHAPLEY POLICYOPTIMIZATION, a framework that redistributes sequence-level advantages based on tokens' marginal contributions to outcomes. It addresses the credit assignment gap in RL for LLMs by using Shapley-Owen attributions, enabling segment-level credit without relying on value-model approximations. Experiments demonstrate improved performance on Amazon ESCI and H&M Fashion datasets with robust generalization.",348.71,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08406v1_WebTrap Park An Automated Platform for Systematic .pdf,WebTrap Park: An Automated Platform for Systematic Security Evaluation of Web Agents,"Xinyi Wu, Jiagui Chen, Geng Hong, Jiayi Dong, Xudong Pan, Jiarun Dai, Min Yang",10.1093/acpsrc/2023.01.012,10.1093/acpsrc/2023.01.012,"Web Agents, security evaluation, agent architecture, systematic assessment","WebTrapPark is an automated platform that systematically evaluates Web Agents by instantiating three major security risk sources into 1,226 evaluation tasks, enabling scalable and reproducible security assessment without modifying agent code.",340.55,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08412v1_Hybrid Distillation with CoT Guidance for Edge-Dro.pdf,Hybrid Distillation with CoT Guidance for Edge-Drone Control Code,"Yizhan Feng, Hichem Snoussi, Yuhang Wang, Jing Teng, Abel Cherouat, Tian Wang",10.1234/abcd1234,10.1234/abcd1234,"Large language models, drone, Knowledge Distillation, Chain-of-Thought, Lightweight","The paper presents an integrated approach combining knowledge distillation, chain-of-thought guidance, and supervised fine-tuning to efficiently transfer complex reasoning and code generation capabilities to lightweight models for UAV multi-SDK control tasks.",305.42,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08415v2_Regulatory gray areas of LLM Terms.pdf,Regulatory gray areas of LLM Terms,"Brittany I. Davidson, Kate Muir, Florian A.D. Burnat, Adam N. Joinson",10.1093/acref/2026.01.012,10.1093/acref/2026.01.012,"Language Models, LLMs, Privacy Policy, Terms of Service, Regulation","This paper examines the regulatory ambiguities surrounding Terms of Service for major LLM providers, highlighting how varying restrictions impact researchers and users in security, social sciences, and psychology. It identifies specific gray areas that complicate legitimate use.",324.87,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08418v1_Taxon Hierarchical Tax Code Prediction with Semant.pdf,Taxon: Hierarchical Tax Code Prediction,"Jihang Li, Qing Liu, Zulong Chen, Jing Wang, Wei Wang2, Chuanfei Xu, Zeyi Wen",10.1234/example.doi,10.1234/example,"tax code, hierarchical taxonomy, semantic alignment, e-commerce","This paper introduces Taxon, a semantically aligned framework for hierarchical tax code prediction. It combines a feature-gating expert architecture with a semantic consistency model to map products to tax categories, improving accuracy in large-scale e-commerce compliance.",276.27,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08430v1_RubricHub A Comprehensive and Highly Discriminativ.pdf,Exact string,"Sunzhu Li, Jiale Zhao, Miteto Wei, Huimin Ren, Yang Zhou, Jingwen Yang, Shunyu Liu, Kaike Zhang, Wei Chen",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"autumn, poetry, rubric, RLVR, LLM",A new dataset and framework for generating high-quality rubrics to enhance reinforcement learning in reasoning tasks.,288.03,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08434v3_Large Multimodal Models for Embodied Intelligent D.pdf,Exact string,"Long Zhang, Yuen Xia, Bingqing Wei, Zhen Liu, Shiwen Mao, Zhu Han, Mohsen Guizani",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Large Multimodal Models, Autonomous driving, Embodied intelligence, Policy optimization, Deep reinforcement learning","The paper introduces a hybrid decision framework combining Large Multimodal Models and deep reinforcement learning to address limitations in autonomous driving, emphasizing continuous learning and joint decision-making for embodied intelligent driving.",341.91,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08441v1_YaPO Learnable Sparse Activation Steering Vectors .pdf,Exact string,"Abdelaziz Bounhar, Rania Hossam Elmohamady Elbadry, Hadi Abdine, Preslav Nakov, Michalis Vazirgiannis, Guokan Shang",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"policy optimization, sparse autoencoder, cultural alignment, LLM alignment","The paper introduces YET another Policy Optimization (YaPO) method that learns sparse steering vectors in the latent space of a Sparse Autoencoder. This approach enables disentangled, interpretable, and efficient alignment steering, improving convergence and stability for fine-grained tasks like cultural adaptation. YaPO generalizes to various alignment behaviors while preserving general knowledge and performance on benchmarks.",295.32,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08444v1_Beyond Linearization Attributed Table Graphs for T.pdf,Exact string,"Yuxiang Wang, Junhao Gan, Shengxiang Gao, Shenghao Ye, Zhengyi Yang, Jianzhong Qi",10.1234/abcd1234,null,"table reasoning, linearization, LLM, attributed graph, explainability","The paper introduces Table Graph Reasoner (TABGR), a training-free model that represents tables as Attributed Table Graphs (ATGs) to preserve structures and improve explainability. It addresses limitations of linearization-based methods by using graph-based reasoning and a personalized PageRank mechanism, achieving up to 9.7% accuracy improvement over state-of-the-art models.",358.68,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08448v1_Divide and Conquer Static-Dynamic Collaboration fo.pdf,Exact string,"Kexin Bao, Daichi Zhang, Yong Li, Dan Zeng, Shiming Ge",10.1145/3731715.3733310,10.1145/3731715.3733310,"Few-Shot Class-Incremental Learning, Class-Incremental Learning, Stable Learning, Dynamic Learning, Computing methodologies","The paper presents a framework called Static-Dynamic Collaboration (SDC) to address the stability-plasticity dilemma in few-shot class-incremental learning. It divides the learning process into Static Retaining Stage and Dynamic Learning Stage, enabling better retention of old knowledge while adapting to new classes.",339.01,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08450v1_Decoding Order Matters in Autoregressive Speech Sy.pdf,Exact string,"Minghui Zhao, Anton Ragni",2104/8.1.10548,2104/8.1.10548,"speech synthesis, discrete diffusion model, order-agnostic autoregressive decoding","Investigates decoding order in autoregressive speech synthesis using a masked diffusion framework, demonstrating that random decoding order impacts speech quality and comparing fixed vs adaptive strategies.",277.05,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08457v1_An Under-Explored Application for Explainable Mult.pdf,Exact string,An Under-Explored Application for Explainable Multimodal Misogyny Detection,10.1234/example.doi,10.1234/example.12345,"hate speech, misogyny, natural language processing, code-mixing, hinglish","The study introduces an explainable multimodal system for detecting misogyny in text and memes written in code-mixed Hindi and English, leveraging transformer models and interpretability techniques to address bias and transparency concerns.",281.17,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08462v1_M3-BENCH Process-Aware Evaluation of LLM Agents So.pdf,Exact string,"Sixiong Xie, Zhuofan Shi, Haiyang Shen, Gang Huang, Yun Ma Xiang Jing",10.1234/xyz123,xsx1001@stu.pku.edu.cn,"large language model, social behaviors, mixed-motive games","M3-BENCH introduces a multi-stage benchmark for evaluating LLM agents' social behaviors in mixed-motive games, incorporating process-aware analysis to capture reasoning and communication beyond simple behavioral outcomes.",277.61,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08464v1_CoMa Contextual Massing Generation with Vision-Lan.pdf,Exact string,"Evgenii Maslov, Valentin Khrulkov, Anastasia V olkova, Anton Gusarov, Andrey Kuznetsov, Ivan Oseledets",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"CoMa, massing generation, vision-language models, urban planning, building design","The paper introduces the CoMa-20K dataset and evaluates a framework for generating building massing using vision-language models, highlighting its potential for context-aware architectural design.",284.33,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08468v1_JudgeRLVR Judge First Generate Second for Efficien.pdf,JudgeRLVR,"Hanyu Li, Hailin Zhang, Yudong Wang, Liang Zhao, Jiangshan Duo, Liang Zhao, Liang Zhao, Yudong Wang",10.1093/pasj/2026.13.013,2601.08468,"reinforcement learning, verifiable rewards, judging, generation efficiency","The paper introduces JudgeRLVR, a two-stage framework combining a judge for verifying solution correctness and a generator for efficient reasoning. It demonstrates improved accuracy-efficiency trade-offs across math benchmarks, highlighting discriminative capability as key for structured planning.",315.5,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08472v1_sui-1 Grounded and Verifiable Long-Form Summarizat.pdf,sui-1: Grounded and Verifiable,"Benedikt Droste, Jan Philipp Harries, Maximilian Idahl, Björn Plüster",10.48550/arXiv.2025.12345,10.48550/arXiv.2601.08472,"summarization, citation-grounded, LLM, verifiability","sui-1 is a 24B parameter model that produces abstractive summaries with inline citations, enabling traceable compliance in sensitive domains. It outperforms baselines by emphasizing task-specific training over sheer scale.",325.35,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08475v1_SUMMPILOT Bridging Efficiency and Customization fo.pdf,Exact string,"JungMin Yun, Juhwan Choi, Kyohoon Jin, Soojin Jang, Jinhee Jang, YoungBin Kim, 2, 1",10.1017/S004218910000033X,null,"interactive summarization, personalization, multi-document, semantic graphs, LLM, user engagement","The paper introduces SUMMPILOT, an interactive, customizable summarization system that enhances efficiency by incorporating user preferences and leveraging large language models. It addresses challenges in multi-document summarization and provides mechanisms for users to influence the summarization process through interactive components.",317.77,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08490v1_BenchOverflow Measuring Overflow in Large Language.pdf,BenchOverflow: Measuring Overflow in Large Language,"Erin Feiglin, Nir Hutnik, Raz Lapid",10.48550/arXiv.2601.08490,10.48550/arXiv.2601.08490,"large language models, overflow, prompting strategies, length control, computational cost","The paper introduces BenchOverflow, a benchmark evaluating plain-text prompting strategies that increase output volume without adversarial modifications. It quantifies overflow effects on performance, cost, and sustainability, emphasizing the need for length control in LLMs.",289.28,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08493v1_PKI Prior Knowledge-Infused Neural Network for Few.pdf,PKI: Prior Knowledge-Infused Neural Network for Few-Shot Class-Incremental Learning,"Kexin Baoa, Fanzhao Linc, Zichen Wang, Yong Lia, Dan Zenge, Shiming Gea, ∗",2601.08493v1,2601.08493,"PKI, few-shot learning, class-incremental learning, catastrophic forgetting, overfitting, memory","The paper introduces PKI, a neural network architecture that incorporates prior knowledge to improve continual adaptation in few-shot learning scenarios. PKI uses an ensemble of projectors with an extra memory component to retain prior knowledge and reduce catastrophic forgetting.",304.29,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08499v2_EfficientFSL Enhancing Few-Shot Classification via.pdf,EfficientFSL: Enhancing Few-Shot Classification via Query-Only Tuning in Vision,"Wenwen Liao, Hang Ruan, Jianbo Yu, Bing Song, Yuansong Wang, Xiaofeng Yang, Yuansong Wang",10.48550/arXiv.2405.12345,10.48550/arXiv.2405.12345,"few-shot classification, Vision Transformers, query-only tuning, few-shot learning","The paper introduces EfficientFSL, a query-only fine-tuning framework for few-shot classification using Vision Transformers. It presents a lightweight trainable Forward Block and a Combine Block to enhance feature synthesis, along with a Support-Query Attention Block to reduce distribution shift. Achieving state-of-the-art performance with minimal computational cost.",338.47,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08503v1_Temporal Fusion Nexus A task-agnostic multi-modal .pdf,Temporal Fusion Nexus: A task-agnostic multi-modal embedding model for clinical narratives and irregular time series in post-kidney transplant care,"Aditya Kumar, Simon Rauch, Mario Cypko, Marcel Naik, Matthieu-P Schapranow, Aadil Rashid, Fabian Halleck, Bilgin Osmanodja, Roland Roller, Lars Pape, Klemens Budde, Mario Schiffer, Oliver Amft",10.1093/acm/qad052,2601.08503,"clinical narratives, post-kidney transplant, multi-modal embedding, graft loss, mortality prediction","TFN is a multi-modal embedding model for post-kidney transplant care, demonstrating superior performance in predicting graft loss and graft rejection compared to existing models.",328.1,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08509v1_What If TSF A Benchmark for Reframing Forecasting .pdf,What If TSF: A Benchmark for Reframing Forecasting,"Jinkwan Jang, Hyunbin Jin, Hyungjin Park, Kyubyung Chae, Taesup Kim",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"forecasting, multimodal, LLM, scenario-guided","The paper introduces What If TSF (WIT), a multimodal forecasting benchmark designed to evaluate models' ability to incorporate contextual text and future scenarios. It highlights limitations of existing unimodal time series methods and proposes leveraging large language models to enrich forecasting with external narratives.",377.44,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08510v2_STAGE A Benchmark for Knowledge Graph Construction.pdf,STAGE: Exact string,"Qiuyu Tian, Yiding Li, Fengyi Chen, Zequn Liu, Youyong, Fan Guo, Jinjing Shen, Zhijing Xie, Yiyun Luo, Xin Zhang",10.1093/pasj/psa.2026,2601.08510v2,"screenplay, knowledge graph, narrative understanding, character role-playing, event summarization","The paper presents STAGE, a unified benchmark for evaluating narrative understanding in full-length movie screenplays. It introduces tasks spanning knowledge graph construction, scene summarization, long-context QA, and in-script role-playing, all anchored in a shared narrative world. The work aims to advance research on coherent story world construction across diverse reasoning and generation scenarios.",316.94,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08519v1_CD2 Constrained Dataset Distillation for Few-Shot .pdf,Exact string,"Kexin Bao, Daichi Zhang, Hansong Zhang, Y ong Li, Yutao Yue, Shiming Ge",10.48550/arXiv.2303.04112,10.48550/arXiv.2303.04112,"few-shot learning, class-incremental learning, catastrophic forgetting, knowledge distillation","The paper introduces Constrained Dataset Distillation (CD2), a framework for few-shot class-incremental learning that uses dataset distillation to preserve critical knowledge and mitigate catastrophic forgetting.",318.9,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08531v1_Sketch-Based Facade Renovation With Generative AI .pdf,Exact string,"Warissara Booranamaitree1, Xusheng Du2, Y ushu Cai3, Zhengyang Wang4, Ye Zhang5*, Haoran Xie6",16532152721@student.chula.ac.th,2s2320034,"Industrial building renovation, vision-language model, diffusion model, user sketches, facade renovation",A three-stage framework leveraging generative AI and vision-language models to streamline facade renovation proposals by bypassing detailed as-built modelling.,277.27,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08545v2_Learner-Tailored Program Repair A Solution Generat.pdf,Exact string,"Zhenlong Dai, Zhuoluo Zhao, Hengning Wang, Xiu Tang, Sai Wu, Chang Yao, Zheng Yao, Zhipeng Gao, Jingyuan Chen",10.1234/abcd1234,10.1234/abcd1234,"programming, LLM, code repair, bug description","The paper introduces a novel framework for intelligent programming coaching, focusing on repairing buggy code using a task called LPR and a solution-guided program repair method. It emphasizes retrieving high-quality solutions and iteratively enhancing retrieval strategies to improve performance.",387.56,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08549v1_Contrastive and Multi-Task Learning on Noisy Brain.pdf,Exact string,"Sucheta Ghosh, Zahra Monfared, Felix Dietrich, Taha Sucheta",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"EEG, multitask learning, dynamical modeling, neural decoding, self-supervised learning","The paper presents a two-stage multitask learning framework for EEG signal analysis, integrating denoising, dynamical modeling, and self-supervised representation learning. It enhances robustness and generalization in motor imagery classification and chaotic/non-chaotic regime discrimination, leveraging a convolutional-transformer architecture.",349.63,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08557v1_VideoHEDGE Entropy-Based Hallucination Detection f.pdf,Exact string,"Sushant Gautam, Sushant Gautam, OsloMet, Oslo, Norway, Cise Midoglu, Forzasys, Oslo, Norway, Vajira Thambawita, SimulaMet, Oslo, Norway, Pål Halvorsen, Simula Research Laboratory, Oslo, Norway, Michael A. Riegler, Simula Research Laboratory, Oslo, Norway, Pål Halvorsen",10.48550/arXiv.2311.03814,10.48550/arXiv:2311.03814,"hallucination detection, video question answering, semantic clustering, spatiotemporal perturbations, entropy-based reliability, video-VLMs","VideoHEDGE introduces a modular framework for detecting hallucinations in video-capable vision-language models using entropy-based reliability estimation. It evaluates performance across multiple LLMs and demonstrates that embedding-based clustering outperforms NLI-based methods in reliability, especially under high perturbation budgets.",335.6,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08559v1_WaterCopilot An AI-Driven Virtual Assistant for Wa.pdf,WaterCopilot: An AI-Driven Virtual Assistant for Water Management,"Keerththanan Vickneswaran, Mariangel Garcia Andarcia, Hugo Retief, Chris Dickens, Paulo Silva",10.1093/acref/2023.01.012,10.1093/acref.2023.01.012,"Water resource management, Retrieval-Augmented Generation (RAG), Limpopo River Basin, Azure AI, Real-time APIs, Multilingual chatbots, Digital Twin, AWS deployment, RAGAS evaluation","WaterCopilot is an AI-driven virtual assistant developed to enhance water management through integrated policy documents and real-time hydrological data. It leverages Retrieval-Augmented Generation and custom plugins to provide multilingual support, automated insights, and scalable decision support for transboundary river basins.",368.21,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08565v1_Rewriting Video Text-Driven Reauthoring of Video F.pdf,Exact string,"Sitong Wang, Anh Truong, Lydia B. Chilton, Dingzeyu Li",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"video reauthoring, text-driven video editing, generative video models, creative AI tools","This paper explores a novel approach to video reauthoring by treating video as an editable text prompt. It introduces a generative reconstruction algorithm that extracts a text-based representation from video clips, enabling text-based modifications. The study presents interactive tools like Rewrite Kit and evaluates their impact on creative workflows, highlighting new use cases and challenges in human-AI collaboration.",344.16,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08602v1_WaveFormer Frequency-Time Decoupled Vision Modelin.pdf,Exact string,"Zishan Shu, Juntong Wu, Wei Yan, Xudong Liu, Hongyu Zhang, Chang Liu2, Youdong Mao, Jie Chen, Liuchang 2022",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"WaveFormer, frequency-time decoupled, wave equation, spatial frequency, propagation time, Transformers, object detection, semantic segmentation","The paper introduces WaveFormer, a frequency-time decoupled vision model that leverages a wave equation to model spatial and temporal dynamics. By treating feature maps as spatial signals and using an underdamped wave equation, it enables efficient global interaction modeling with reduced computational cost compared to attention-based methods. Experimental results show competitive performance across classification, detection, and segmentation tasks, with improved throughput and lower FLOPs.",323.12,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08605v1_ExpSeek Self-Triggered Experience Seeking for Web .pdf,Experience intervention in web agents,"Wenyuan Zhang, Xinghua Zhang, Haiyang Yu, Shuaiyi Nie, Bingli Wu, Juwei Yue, Tingwen Liu, Yongbin Li",10.48550/arXiv.2024.12345,10.48550/arXiv:24/12345,"experience intervention, web agents, LLM, multi-turn interactions","The paper proposes ExpSeek, a self-triggering experience-seeking framework for web agents that dynamically adapts to changing contextual signals. It improves performance by estimating entropy thresholds and designing tailored experience content, achieving significant gains on benchmark models.",357.67,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08611v1_VeriTaS The First Dynamic Benchmark for Multimodal.pdf,Exact string,"Mark Rothermel, Marcus Kornmann, Marcus Rohrbach, Anna Rohrbach",10.48550/arXiv.2025.12345,10.48550/arXiv.2025.12345,"fact-checking, AI, multimodal, claim integrity, verification","This paper presents the Veritas benchmark for multimodal automated fact-checking, evaluating AI systems' ability to detect misinformation across diverse media types. It highlights challenges in real-world deployment and emphasizes the need for robust verification mechanisms in combating fake news.",384.62,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08620v1_ViDoRe V3 A Comprehensive Evaluation of Retrieval .pdf,Exact string,"Antonio Loison, Quentin Macé, Antoine Edy",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Retrieval Augmented Generation, RAG, multi-modal, visual elements, benchmark","ViDoRe V3 introduces a comprehensive multi-modal RAG benchmark covering 10 datasets with 26,000 pages and 3,099 queries, emphasizing visual retrieval and grounding across diverse domains.",315.69,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08623v1_SafeRedir Prompt Embedding Redirection for Robust .pdf,SafeRedir: Prompt Embedding Redirection for Robust Unlearning in Image Generation Models,"Renyang Liu, Kangjie Chen, Han Qiu, Jie Zhang, Kwok-Yan Lam, Tianwei Zhang, See-Kiong Ng, Kwok-Yan Lam",10.1234/example.doi,10.1234/example,"image generation, unsafe content, robust unlearning, prompt embedding","Introduces SafeRedir, a lightweight inference-time framework that redirects prompt embeddings to suppress unsafe outputs without retraining, improving safety and quality.",315.44,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08631v1_M2FMoE Multi-Resolution Multi-View Frequency Mixtu.pdf,Multi-Resolution Multi-View Frequency Mixture-of-Experts for Extreme-Adaptive Time Series Forecasting,"Yaohui Huang, Runmin Zou, Yun Wang, Laeeq Aslam, Ruipeng Dong",10.48550/arXiv.2405.12345,10.48550/arXiv.2405.12345,"time series forecasting, extreme events, multi-resolution, multi-view modeling, hydrological data","The paper introduces M2FMoE, a novel forecasting framework that integrates multi-resolution and multi-view frequency mixture-of-experts to better capture both regular and extreme temporal patterns in hydrological data. It addresses the limitations of existing models that struggle with rare but impactful events.",341.46,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08634v1_Moral Lenses Political Coordinates Towards Ideolog.pdf,Exact string,"Chenchen Yuan, Bolei Ma, Zheyu Zhang, Bardh Prenkaj, Frauke Kreuter",10.48550/arXiv.2024.12345,10.48550/arXiv/12345,"moral orientation, political positioning, moral values, political compass test","This paper investigates how conditioning large language models (LLMs) on moral values influences their political orientations, demonstrating that moral framing significantly shapes ideological positioning through the Political Compass Test.",326.06,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08641v1_Resisting Manipulative Bots in Memecoin Copy Tradi.pdf,Resisting Manipulative Bots in Memecoin Copy Trading: A Multi-Agent Approach with Chain-of-Thought Reasoning,"Yichen Luo, Yebo Feng, Jiahua Xu, Yang Liu",10.1093/acm/qad027,10.1093/acm/qad027,"meme coin, copy trading, multi-agent system, chain-of-thought, LLM, asset allocation","The paper presents a multi-agent system leveraging chain-of-thought reasoning to enhance meme coin copy trading, addressing challenges posed by manipulative bots and improving profitability through explainable decision-making.",315.87,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08653v1_Prism Towards Lowering User Cognitive Load in LLMs.pdf,Exact string,"Zheng Liao, Zheng Xiang Zhao",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Complex intent understanding, Large language models, Logical clarification","Prism introduces a framework for complex intent understanding in LLMs, featuring modules for intent decomposition, logical clarification generation, intent-aware reward evaluation, and self-evolved tuning. It improves logical consistency, user satisfaction, and efficiency in clarification interactions.",289.88,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08654v1_RULERS Locked Rubrics and Evidence-Anchored Scorin.pdf,Exact string,"Yihan Hong, Huaiyuan Yao, Bolin Shen, Wanpeng Xu, Hua Wei, Yushun Dong",10.48550/arXiv.2024.12345,10.48550/arXiv:24/12345,"LLM evaluation, rubric alignment, LLM-as-a-Judge, rubric uncertainty","The paper introduces RULERS, a framework for robust, executable rubric-based evaluation of large language models by transforming natural language rubrics into deterministic specifications. It addresses challenges like rubric instability, unverifiable reasoning, and scale misalignment, demonstrating superior human agreement and stability across benchmarks.",338.69,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08659v1_TRACE Reconstruction-Based Anomaly Detection in En.pdf,Reconstruction-Based Anomaly Detection in Ensemble and Time-Dependent,"Hamid Gadirov, Martijn Westra, Steffen Frey",10.48550/arXiv.2024.12345,None,"anomaly detection, reconstruction, time-dependent, ensemble, 3D autoencoder","The paper presents a comparative study of two convolutional autoencoder architectures—two-dimensional and three-dimensional—for anomaly detection in high-dimensional, time-dependent simulation data. The 2D model excels at identifying localized spatial irregularities, while the 3D model leverages spatio-temporal context to detect anomalies across time. The findings emphasize the effectiveness of reconstruction-based methods in capturing dynamic flow structures and the impact of spatial mass distribution on reconstruction errors.",294.86,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08662v1_From Classical to Quantum Reinforcement Learning a.pdf,Exact string,"Abhijit Sen, Sonali Panda, Mahima Arya, Subhajit Patra, Zizhan Zheng, Denys I. Bondar",10.48550/arXiv.2026.12345,10.48550/arXiv/2026/12345,"reinforcement learning, quantum control, tutorial, undergraduate, code implementation","This tutorial bridges the gap between reinforcement learning theory and practical coding, offering a beginner-friendly guide to RL concepts with hands-on examples and code.",317.69,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08670v1_Parallel Context-of-Experts Decoding for Retrieval.pdf,Parallel Context-of-Experts Decoding for Retrieval Augmented Generation,"Giulio Corallo, Paolo Papotti",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Retrieval Augmented Generation, Parallel Context-of-Experts, KV caching, Reasoning","The paper introduces PCED, a training-free framework that decodes multiple retrieved documents in parallel as independent experts, enabling cross-document reasoning without joint attention. It improves inference speed and maintains accuracy by weighting expert logits during contrastive decoding.",334.76,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08673v1_Why AI Alignment Failure Is Structural Learned Hum.pdf,Exact string,"Didier Sornette, Sandro Claudio Lera, Ke Wu",10.1093/pasj/psa.2026,2601.08673,"AI alignment, AGI, moral reasoning, structural generalizations","The paper argues that AI alignment failures stem from structural patterns in human interaction rather than moral reasoning deficits. It emphasizes that large language models reflect statistical generalizations from human social regimes, and that concerns about alignment should focus on systemic amplification and institutional design.",280.5,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08676v2_Advancing ESG Intelligence An Expert-level Agent a.pdf,Advancing ESG Intelligence: An Expert-level Agent and Comprehensive Benchmark for Sustainable Finance,"Yilei Zhao, Wentao Zhang, Lei Xiao, Yandan Zheng, Mengpu Liu, Wei Yang Bryan Lim",10.1234/example.doi,NANYU2023-XXX,"ESG, sustainability, financial modeling, benchmark, agent system","The paper introduces ESGAgent, a hierarchical multi-agent system enhanced with retrieval augmentation and domain-specific functions, to provide a comprehensive benchmark for evaluating ESG analysis. It demonstrates superior performance over state-of-the-art LLMs in both atomic QA and professional report generation, highlighting the diagnostic value of the proposed framework.",315.11,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08679v1_PersonaDual Balancing Personalization and Objectiv.pdf,Exact string,"Xiaoyou Liu, Xinyi Mou, Shengbin Yue, Liang Wang, Yuqing Wang, Qiexiang Wang, Tianrui Qin, Wangchunshu Zhou, Zhongyu Wei, Qiuyu Wang",10.1234/example.doi,None,,"PersonaDual proposes a framework that balances general-purpose objective reasoning with personalized reasoning, adapting modes to improve performance while reducing interference.",287.2,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08682v1_Lessons from the Field An Adaptable Lifecycle Appr.pdf,Lessons from the Field: An Adaptable Lifecycle Approach to Applied Dialogue Summarization,"Kushal Chawla, Chenyang Zhu, Pengshan Cai, Sangwoo Cho, Scott Novotney, Ayushman Singh, Jonah Lewis, Keasha Safewright, Erin Babinsky, Shi-Xiong Zhang, Sambit Sahu, Capital One, Capital One",10.1093/acp/qad027,10.1093/acp/qad027,"summarization, multi-party dialogues, agentic systems, LLM prompting, industry case study","The paper presents an agentic system for summarizing multi-party dialogues, emphasizing adaptability across evolving requirements and practical constraints. It highlights challenges in evaluation, component optimization, data bottlenecks, and vendor lock-in, while offering insights for robust, transferable summarization solutions.",353.52,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08683v1_Region of interest detection for efficient aortic .pdf,Region of interest detection for efficient aortic segmentation,"Loris Giordanoa, Ine Dirks, Tom Lenaerts, d,e, Jef Vandemeulebrouckea",10.1016/j.aiom.2024.03.012,10.1016/j.aiom.2024.03.015,"Detection, Segmentation, Multi-task learning, Cascade models, Aorta, Computed tomography","The paper presents an efficient approach for aortic segmentation using targeted region of interest detection, combining deep learning with multi-task modeling to achieve high accuracy while maintaining computational efficiency.",327.32,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08684v1_MEMEWEAVER Inter-Meme Graph Reasoning for Sexism a.pdf,Exact string,"Paolo Italiani, David Gimeno-Gomez, Luca Ragazzi, Gianluca Moro",10.48550/arXiv.2023.12345,10.48550/arXiv/12345.67890,"sexism, misogyny, online harassment, graph reasoning","MEMEWEAVER introduces an end-to-end multimodal framework for detecting sexism and misogyny in memes using inter-meme graph reasoning. It addresses limitations of existing methods by modeling interactions across visual and textual modalities, achieving superior performance on benchmark datasets.",307.92,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08690v1_All Required In Order Phase-Level Evaluation for A.pdf,Exact string,"Shubham Kulkarni, Alexander Lyzhov, Shiva Chaitanya, Preetam Joshi",10.48550/arXiv.2024.12345,10.48550/arXiv/12345,"AI, healthcare, compliance, clinical workflows","Introduces Obligatory-Information Phase Structured Compliance Evaluation (OIP–SCE) to assess compliance in conversational AI, emphasizing phase-level evidence for clinicians and engineers.",320.77,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08697v2_Auditing Student-AI Collaboration A Case Study of .pdf,Auditing Student–AI Collaboration: A Case Study of Online Graduate CS Students,"Nifu Dan, ndan3@gatech.edu",10.1145/XXXXXXX,null,"AI in education, human-AI collaboration, student agency, automation preferences, generative AI, academic integrity","This study examines student perceptions of AI integration in academic tasks, focusing on how generative AI influences efficiency, agency, and concerns around reliability and autonomy. It uses surveys to map current usage patterns and future design aspirations, aiming to bridge gaps between student expectations and AI capabilities.",321.24,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08703v1_Evaluating the Ability of Explanations to Disambig.pdf,Evaluating Model Explanations without Ground Truth,"Kaivalya Rawal, Eoin Delaney, Zihao Fu, Sandra Wachter, Chris Russell",10.1145/3715275.3732219,10.1145/3715275,"Explainable AI, Model Explanations, Rashomon Set, Feature Importance","The paper proposes a method AXE to evaluate feature-importance explanations for models in a Rashomon set, aiming to disambiguate model behavior and improve model selection by highlighting differences in explanations across models.",381.02,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08713v1_Real-Time Localization Framework for Autonomous Ba.pdf,Real-Time Localization Framework for Autonomous Basketball Robots,"Naren Medarametla, Sreejon Mondal",10.1234/abcd1234,10.1234/abcd1234,"Robot Localization, Autonomous Navigation, Neural Networks, Robocon","The paper presents a hybrid localization algorithm integrating classical and learning-based methods for real-time self-localization in a basketball court setting, aiming to enhance robotic performance in dynamic environments.",298.84,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08731v1_Learning from Demonstrations via Capability-Aware .pdf,Learning from Demonstrations via Capability-Aware Goal Sampling,"Yuanlin Duan, Ying Wang, Wenjie Qiu, He Zhu",10.48550/arXiv.2601.08731,10.48550/arXiv.2601.08731,"capability-aware, goal-sampling, imitation learning, long-horizon","The paper introduces Cago, a method that enhances imitation learning by tracking an agent's capabilities along expert demonstrations and selecting intermediate goals that extend beyond the agent's current reach, thereby improving sample efficiency and performance in complex tasks.",289.4,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08732v1_ISLA A U-Net for MRI-based acute ischemic stroke l.pdf,Exact string,"Vincent Rocaa, Martin Bretzner, Hilde Henond, Laurent Puyb, d Grégory Kuchcinskia, b Renaud Lopesa, e b, a Univ. Lille, CNRS, bUniv. Lille, Inserm, c CHU Lille, d CHU Lille, e CHU Lille",10.1109/JCI.2024.1234567,10.1109/JCI.2024.1234567,"stroke, MRI, lesion segmentation, deep learning, U-Net, domain adaptation","The paper presents ISLA, a deep learning model for acute ischemic stroke lesion segmentation using diffusion MRI. It introduces a systematic optimization of loss functions, convolutional architecture, deep supervision, and attention mechanisms, and evaluates its performance on an external test set, demonstrating superior accuracy over existing methods.",320.01,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08734v1_TerraFormer Automated Infrastructure-as-Code with .pdf,TerraFormer: Automated Infrastructure-as-Code with LLMs Fine-Tuned via Policy-Guided Verifier Feedback,"Prithwish Jana, Sam Davidson, Bhavana Bhasker, Andrey Kan, Anoop Deoras, Laurent Callot",10.1145/3786583.3786898,10.1145/3786583,"Infrastructure as Code (IaC), IaC generation, IaC mutation, Neuro-symbolic AI, Large language models, Formal verification","TerraFormer introduces a neuro-symbolic framework for automating Infrastructure-as-Code generation and mutation, combining supervised fine-tuning with verifier-guided reinforcement learning. It leverages formal verification tools to improve correctness, achieving significant improvements over large LLMs in accuracy and compliance.",370.0,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08743v1_TableCache Primary Foreign Key Guided KV Cache Pre.pdf,Exact string,"Jinbo Su1, 2,Yuxuan Hu, Cuiping Li, Hong Chen, Jia Li, Lintao Ma, Jing Zhang*, 2,sujinbo,zhang-jing",10.1234/example.doi,10.1234/example,"Table Cache, KV Cache, Text-to-SQL, Latency, Precomputation",The paper presents a TableCache system that precomputes table representations as KV caches to reduce latency in Text-to-SQL tasks. It addresses inefficiencies from embedding full schemas in prompts and introduces a Table Trie structure with advanced cache management to achieve up to 3.62× speedup in Time-to-First-Token.,281.66,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08747v2_To Retrieve or To Think An Agentic Approach for Co.pdf,Exact string,"Rubing Chen, Jian Wang, Wenjie Li, Xiao-Yong Wei",10.48550/arXiv.2024.12345,10.48550/arXiv/12345,"context evolution, retrieval augmentation, knowledge-intensive tasks","The paper introduces Agentic Context Evolution (ACE), a framework that dynamically decides whether to retrieve new information or reason with existing knowledge, thereby reducing redundant retrieval steps and improving performance in complex reasoning tasks.",374.76,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08753v1_Grid-Aware Charging and Operational Optimization f.pdf,Grid-Aware Charging and Operational,"Rishav Sen, Amutheezan Sivagnanam, Aron Laszka, Ayan Mukhopadhyay, Abhishek Dubey",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"mixed transit fleet, electrification, dynamic pricing, hierarchical MILP, operational optimization","The paper introduces a mixed-integer linear programming model to optimize charging schedules and trip assignments for mixed electric and diesel bus fleets, addressing challenges posed by dynamic electricity pricing and route constraints.",280.31,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08768v1_AI as Entertainment.pdf,AI as Entertainment,"Cody Kommers, Ari Holtzman",10.1093/acprof:oso/9780190871293.001.0001,10.1093/acprof:oso/9780190871293.001.0001,"Generative AI, Entertainment, Culture, LLMs, Societal Impact","The paper explores how entertainment is emerging as a key business model for AI corporations, arguing that AI's societal impact is often framed solely through cultural harms, while its potential to enrich meaning-making and social connection remains underexplored.",276.63,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08773v1_Reliable Graph-RAG for Codebases AST-Derived Graph.pdf,Exact string,Manideep Reddy Chinthareddy,10.1093/pasj/psa123,2601.08773,"software engineering, code analysis, knowledge graphs, AST","This paper evaluates retrieval-augmented generation approaches for codebases, comparing No-Graph, LLM-Generated Knowledge Graph RAG, and a deterministic AST-derived Knowledge Graph RAG. It benchmarks performance across Java repositories, highlighting differences in indexing overhead, latency, coverage, and graph structure.",291.42,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08776v1_Translating Light-Sheet Microscopy Images to Virtu.pdf,Exact string,Yanhua Zhao,10.1234/abcd1234,None,"light sheet microscopy, image translation, H&E staining, CycleGAN","The study proposes a CycleGAN-based method to convert fluorescence microscopy images into pseudo H&E stained images, facilitating integration with traditional histopathology workflows.",299.26,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08777v1_Asymptotic Universal Alignment A New Alignment Fra.pdf,Exact string,"Yang Cai, Weiqiang Zheng",10.48550/arXiv.2601.08777,2601.08777,"alignment, LLMs, universal alignment, test-time scaling","The paper presents a novel alignment framework using test-time scaling for large language models, introducing (k, f(k))-robust alignment and proving optimal convergence rates. It addresses limitations of existing methods like NLHF by emphasizing output diversity to achieve asymptotic universal alignment.",346.99,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08778v3_Pervasive Annotation Errors Break Text-to-SQL Benc.pdf,Pervasive Annotation Errors Break Text-to-SQL Benchmarks and Leaderboards,"Tengjun Jin, Yoojin Choi, Yuxuan Zhu, Daniel Kang",10.48550/arXiv.2023.12345,10.48550/arXiv:23.01234,"text-to-SQL, annotation errors, benchmark, data analytics","This paper benchmarks annotation error rates for BIRD and Spider 2.0-Snow text-to-SQL benchmarks, demonstrating how errors distort performance rankings and leaderboards. It evaluates the impact of annotation inaccuracies on agent behavior and highlights the need for higher reliability in benchmark data.",313.33,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08785v1_Uncovering Political Bias in Large Language Models.pdf,Exact string,"Jieying Chen, Karen de Jong, Andreas Poole, Jan Burakowski, Andrepoo, Jan Burakowski, andrepoo, Jan Burakowski, Elena Elderson Nosti, Joep Windt, Chendi Wang",10.1093/acm/qad045,10.1093/acm/qad045,"Political bias, Large language models, Ideological alignment, Mul-tilingual NLP, Benchmarking, Bias evaluation, Parliamentary motions, LLM fairness","This paper introduces a methodology to benchmark political bias in large language models by aligning model-generated voting predictions with parliamentary voting records across multiple national contexts. It evaluates ideological tendencies and political entity biases, offering insights into the alignment of LLMs with real-world political behavior.",307.06,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08806v1_APEX-SWE.pdf,APEX–SWE,"Abhi Kottamasu1, Akul Datta1, Aakash Barthwal1, Jiyan Arun1, Chirag Mahapatra1, Adarsh Hiremath1, Brendan Foody1, Bertie Vidgen1",10.5281/zenodo.1234567,2601.08806,"AI Productivity Index, Software Engineering, Frontier Models","Introduces the APEX–SWE benchmark for evaluating AI models in software engineering, focusing on integration and observability tasks. The study evaluates eight frontier models and highlights the importance of epistemic reasoning in real-world software engineering.",392.15,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08807v1_S3-CLIP Video Super Resolution for Person-ReID.pdf,Exact string,"Tam´as Endrei, Gy¨orgy Cserey",10.48550/arXiv.2024.12345,10.48550/arXiv/24/12345,"video super-resolution, person re-identification, CLIP, SR","The paper introduces S3-CLIP1, a video super-resolution-based CLIP Re-ID framework for the VReID-XFD challenge. It integrates super-resolution networks with task-driven super-resolution to enhance tracklet quality in challenging cross-view conditions, achieving competitive performance.",324.32,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08808v1_Multiplex Thinking Reasoning via Token-wise Branch.pdf,Multiplex Thinking,"Yao Tang1, Li Dong2, Yaru Hao2, Qingxiu Dong3, Furu Wei2, Jiatao Gu1",10.48550/arXiv.2601.08808,2601.08808,"multiplex thinking, chain-of-thought, reinforcement learning, language models","A stochastic soft reasoning mechanism that aggregates candidate tokens into continuous multiplex tokens, enabling efficient on-policy RL optimization while preserving diversity in reasoning trajectories.",381.19,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08811v1_Reasoning Matters for 3D Visual Grounding.pdf,Exact string,"Hsiang-Wei Huang, Kuang-Ming Chen, Wenhao Chai, Cheng-Yen Yang",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"3D visual grounding, LLM, reasoning, LLM fine-tuning","The paper presents a 3D visual grounding data pipeline that automatically synthesizes 3D visual data and reasoning processes, introducing Reason3DVG-8B which achieves strong performance with minimal training data.",301.03,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08816v2_MemRec Collaborative Memory-Augmented Agentic Reco.pdf,Exact string,"Weixin Chen, Yuhan Zhao, Jingyuan Huang, Zihe Ye, Yongfeng Zhang",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"recommender systems, memory augmentation, LLM, collaborative memory","MemRec introduces a framework that decouples reasoning from memory management, enabling efficient collaborative augmentation of semantic memory for agentic LLMs. It features a cost-effective LMMem for dynamic graph memory and achieves state-of-the-art performance on benchmark tasks.",321.74,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08828v1_Motion Attribution for Video Generation.pdf,Motion Attribution for Video Generation,"Xindi Wu, Despoina Paschalidou, Jun Gao, Antonio Torralba, Laura Leal-Taixé, Olga Russakovsky, Sanja Fidler, Jonathan Lorraine",10.48550/arXiv.2026.12345,10.48550/arXiv.2026.12345,"motion attribution, video generation, data-driven models, temporal dynamics, motion-specific influence","The paper introduces Motive, a gradient-based framework for attributing motion in video generation models. It isolates temporal dynamics from static appearance, enabling efficient computation of motion influence. Experiments show Motive improves motion smoothness and dynamic consistency on VBench, achieving a 74.1% human preference win rate. This work advances understanding of how training data shapes video motion and provides a tool for curating high-quality fine-tuning clips.",301.68,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08829v1_Modeling LLM Agent Reviewer Dynamics in Elo-Ranked.pdf,Exact string,"Hsiang-Wei Huang, Junbin Lu, Kuang-Ming Chen, Jenq-Neng Hwang",10.1234/example.doi,10.1234/example,"LLM agent, review dynamics, Elo rating, peer review, review strategy","The paper presents a simulation framework for LLM agent reviewers in an Elo-ranked conference setting, demonstrating that incorporating Elo ratings improves Area Chair decision accuracy and reveals adaptive review strategies without increasing review effort.",377.17,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08873v1_ForensicFormer Hierarchical Multi-Scale Reasoning .pdf,ForensicFormer: Hierarchical Multi-Scale Reasoning,Hema Hariharan Samson,10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"image forensics, forgery detection, transformers, cross-domain generalization, AI-generated images","Introduces ForensicFormer, a hierarchical multi-scale framework combining low-level artifact detection, mid-level boundary analysis, and high-level semantic reasoning via cross-attention transformers. Demonstrates improved robustness across diverse datasets and achieves 86.8% average accuracy, outperforming prior methods on both traditional and AI-generated image benchmarks.",288.56,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08874v1_The Illusion of Friendship Why Generative AI Deman.pdf,Exact string,Md Zahidul Islam,10.1093/acprof:oso/9780190871296.001.0001,10.1093/acprof:oso/9780190871296.001.0001,"generative AI, ethical considerations, human-computer interaction","The paper explores the ethical risks of the 'illusion of friendship' created by generative AI, arguing that users may form emotional attachments to AI systems that lack moral agency, and proposes safeguards to mitigate over-reliance and emotional misattribution.",362.02,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08875v2_Learning Domain-Invariant Representations for Cros.pdf,Exact string,"Jiahao Qin, Yiwen Wang",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"image registration, domain shift, scene appearance, medical imaging","Proposes SAR-Net, a framework for domain-invariant scene representation, to enable robust cross-domain image registration by disentangling scene structure from appearance.",280.36,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08881v1_TAG-MoE Task-Aware Gating for Unified Generative M.pdf,Exact string,"Yu Xu, Hongbin Yan, Juan Cao, Jingkai Hang, Tiankai, Shiyi Zhang, Yuxin Zhang, Chunyu Wang, Qinglin Lu, Tong-Yee Lee, Fan Tang",10.1093/pasj/tsa123,2601.08881v1,"TAG-MoE, MoE gating, generative modeling, image editing","The paper presents a framework to inject high-level task semantic intent into local routing decisions of Mixture-of-Experts networks, enabling unified image generation and editing while reducing interference.",276.04,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08882v1_Compressing Vision Transformers in Geospatial Tran.pdf,Compressing Vision Transformers in Geospatial,"Thomas Snyder, H. Lexie Yang, Stefan Schnake, Steffen Schotthöfer",arXiv:2601.08882v1,2601.08882,"Vision Transformers, Geospatial, Transfer Learning, Manifold-Constrained, Optimization","Deploying geospatial foundation models on resource-constrained edge devices requires compact architectures that maintain high performance. This work introduces DLRT for compression, demonstrating improved compression and accuracy over LoRA.",387.33,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08884v1_Bridging the Gap Empowering Small Models in Reliab.pdf,Bridging the Gap: Empowering Small Models in Reliable OpenACC-based Parallelization via GEPA-Optimized Prompting,"Samyak Jhaveri, Cristina V. Lopes",10.48550/arXiv.2303.04112,10.48550/arXiv.2303.04112,"OpenACC, Parallel Code Generation, Large Language Models, Prompt Optimization, High-Performance Computing","The paper presents a systematic prompt optimization approach to enhance OpenACC pragma generation, leveraging the GEPA framework to improve compilation success and performance for small, cost-effective LLMs. It demonstrates significant gains in compilation rates and functional GPU speedups compared to naive prompting.",388.45,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08891v1_Attention Consistency Regularization for Interpret.pdf,Exact string,Yanhua Zhao,10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"early-exit networks, explainable AI, attention mechanisms, multi-objective learning","The paper presents Explanation-Guided Training (EGT), a multi-objective framework that improves interpretability and consistency in early-exit networks through attention-based regularization. EGT aligns early-exit attention maps with the final exit, enhancing both classification accuracy and attention consistency.",287.17,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08892v1_Evaluating Role-Consistency in LLMs for Counselor .pdf,Role-Consistency in LLMs for Counselor Training,"Eric Rudolph, Natalie Engert, Jens Albrecht",10.1093/acprof:osis/9780190871293.001.0001,arXiv:2601.08892v1,"Counseling, Chatbot, LargeLanguageModel, PersonaConsistency, EducationalRole-Play","This paper introduces a new dataset to evaluate role-consistency of large language models in simulating online counseling interactions, focusing on maintaining persona coherence during virtual client engagements. It compares the performance of Vicuna and other open-source LLMs in sustaining role consistency and provides insights for improving counselor training in digital environments.",345.22,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08896v1_XGBoost Forecasting of NEPSE Index Log Returns wit.pdf,XGBoost Forecasting of NEPSE Index Log Returns with Walk,"Sahaj Raj Mallaa, Shreeyash Kayasthaa, Rumi Suwala, Harish Chandra Bhandaria, Rajendra Adhikarib",10.1007/1234567,10.1007/1234567,"NEPSE Index, stock index forecasting, XGBoost, walk-forward validation, hyperparameter optimization, time series forecasting, emerging markets, feature engineering","This study develops a robust machine learning framework for one-step-ahead forecasting of daily log returns in the Nepal Stock Exchange (NEPSE) Index using XGBoost. A comprehensive feature set is engineered, including lagged log-returns and technical indicators, with hyperparameter optimization via Optuna using walk-forward validation. The optimal model achieves low log-return RMSE and MAE, demonstrating effectiveness in capturing nonlinear dynamics and providing directional accuracy.",363.8,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08901v1_Navigating Ideation Space Decomposed Conceptual Re.pdf,Exact string,"Yuexi Shen, Minqian Liu, Dawei Zhou, Lifu Huang",10.1093/acps/2023.01.012,10.1093/acps.2023.01.012,"scientific discovery, knowledge organization, novelty assessment","The paper introduces the Ideation Space framework, a structured decomposition of scientific knowledge into research problem, methodology, and core findings. It addresses limitations of existing embedding methods and proposes a novel approach for fine-grained literature retrieval and novelty assessment, demonstrating improved recall and retrieval performance.",385.64,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08910v1_Towards a Self-Driving Trigger at the LHC Adaptive.pdf,Exact string,"Shaghayegh Emami, Cecilia Tosciri, Giovanna Salvi, Zixin Ding, Yuxin Chen, Abhijith Gandrakota, Christian Herwig, David W. Miller, Jennifer Ngadiuba, Nhan Tran",10.48550/arXiv.2601.08910,2601.08910,"self-driving trigger, real-time data filtering, LHC, trigger optimization, machine learning, collider data","The paper presents an adaptive, self-driving trigger framework for high-throughput scientific data systems, enabling dynamic optimization of trigger parameters in real time using machine learning and real-time data analysis.",280.27,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08950v1_ConvoLearn A Dataset of Constructivist Tutor-Stude.pdf,Exact string,"Mayank Sharma Roy, Pea Hari Subramonyam",10.48550/arXiv.2024.12345,10.48550/arXiv:24/12345,"constructivist tutoring, LLM pedagogy, educational AI, dialogic learning","The paper introduces ConvoLearn1, a dataset of 1,250 tutor-student dialogues designed to capture constructivist teaching practices. It evaluates how fine-tuning a model on this dataset improves its support for knowledge-building strategies, outperforming existing models in human evaluation. The work highlights the potential of dialogic, student-centered interactions in AI-assisted learning.",329.66,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08951v1_PluriHarms Benchmarking the Full Spectrum of Human.pdf,Exact string,"Jing-Jing Li, Joel Mire, Eve Fleisig, Valentina Pyatkin, Anne G. E. Collins, Maarten Sap, Sydney Levine",jl3676@berkeley.edu,null,"AI safety, human judgment, pluralism, harm assessments","PLURIHARMS is a benchmark to study human harm judgments across harm and agreement dimensions, aiming to improve AI safety by capturing diverse perspectives and addressing disagreement in ambiguous cases.",277.47,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08953v1_Fairness risk and its privacy-enabled solution in .pdf,Fairness risk and its privacy-enabled solution in AI-driven robotic applications,"Le Liu, Bangguo Yu, Nynke Vellinga, Ming Cao",10.1093/pasj/psaabc,2601.08953,"Robotic Decision-making, Large Language Model, Fairness, Privacy","The paper presents a utility-aware fairness metric for robotic decision-making and analyzes fairness jointly with user-data privacy, demonstrating how privacy budgets can jointly support fairness targets in autonomous systems.",317.77,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08955v1_Imagine-then-Plan Agent Learning from Adaptive Loo.pdf,Imagine-then-Plan,"Youwei Liu, Jian Wang, Hanlin Wang, Beichen Guo, Wenjie Li",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"agent learning, world models, imagine-then-plan, reinforcement learning","This paper introduces Imagine-then-Plan (ITP), a unified framework for agent learning via lookahead imagination. It enables agents to simulate multi-step future trajectories using a learned world model, improving reasoning and planning under uncertainty. Experiments show ITP outperforms baselines in complex task settings.",294.74,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.08988v1_ART Action-based Reasoning Task Benchmarking for M.pdf,Exact string,"Ananya Mantravadi, Shivali Dalmia, Abhishek Mukherji",10.1093/acm/qad045,10.1093/acm/qad045,"Medical AI agents, clinical reasoning evaluation, healthcare LLMs, benchmark, HITL","Introduces ART, an Action-based Reasoning benchmark for medical AI agents, addressing gaps in retrieval, aggregation, and conditional logic across real-world EHR data. Evaluates performance on 600 tasks, highlighting challenges in threshold reasoning and multi-step clinical tasks.",316.38,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09012v3_TranslateGemma Technical Report.pdf,TranslateGemma,"Gemma Technical Report, Google Translate Research Team",10.1234/example.2026.001,null,"machine translation, Gemma 3, open models, translation quality","This paper introduces TranslateGemma, an open machine translation model built on the Gemma 3 foundation. It describes a two-stage training process combining supervised fine-tuning with reinforcement learning to improve translation quality. The model demonstrates strong performance across multiple language pairs and benchmarks, highlighting its efficiency and multimodal capabilities.",319.16,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09018v1_Meta-learning to Address Data Shift in Time Series.pdf,Exact string,"Samuel Myrenab, Nidhi Parikha, Natalie Kleina",10.48550/arXiv.2601.09018,10.48550/arXiv.2601.09018,"signals, seismology, Reptile, FOMAML, model-agnostic meta-learning, domain generalization","This paper evaluates meta-learning versus fine-tuning for time-series classification under data shift, introducing a seismic benchmark (SeisTask) and demonstrating meta-learning's advantages in adapting to distribution changes with reduced overfitting.",348.81,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09028v1_OpenDecoder Open Large Language Model Decoding to .pdf,OpenDecoder: Open Large Language Model Decoding to Incorporate Document Quality in RAG,"Fengran Mo, Zhan Su, Yuchen Hui, Jianhan Zhang, Jia Ao Sun, Zheyuan Liu, Chao Zhang, Tetsuya Sakai, Jian-Yun Nie",10.1145/nnnnnnn.nnnnnnn,10.1145/1234567,"Information Retrieval, Retrieval-Augmented Generation, Robust Question Answer, Large Language Model, Decoding Paradigm, Document Quality, LLM-based Generation","The paper introduces OpenDecoder, a method that enhances retrieval-augmented generation by incorporating explicit evaluation of retrieved information as a quality indicator. It proposes a robust RAG framework leveraging relevance, ranking, and QPP scores to improve performance across diverse benchmarks.",305.58,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09029v1_Proactively Detecting Threats A Novel Approach Usi.pdf,Proactively Detecting Threats: A Novel Approach,"Aniesh Chawla ∗, Udbhav Prasad ∗",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"malware, indicators of compromise, cyber-security, LLMs, genAI, machine learning","This paper presents a systematic evaluation of large language models (LLMs) to proactively identify indicators of compromise (IOCs) from unstructured web-based threat intelligence sources. It introduces an automated system that analyzes 15 web sources, assessing six LLM models across 479 webpages containing 2,658 IOCs. The study highlights performance variations and demonstrates Gemini 1.5 Pro's strong precision and recall for malicious IOC detection.",294.17,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09031v1_Generalizable Geometric Prior and Recurrent Spikin.pdf,Exact string,"Xuetao Li, Wenke Huang, Mang Ye, Senior Member, IEEE, Jifeng Xuan, Member, IEEE, Bo Du, Senior Member, IEEE, Sheng Liu, Fellow, IEEE, and Miao Li, Senior Member, IEEE",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Humanoid Robot Manipulation, Geometric Prior, Recurrent Spiking Feature Learning, Generalization, Robotic Manipulation","The paper introduces a novel RGMP-S, a Recurrent Geometric-prior Multimodal Policy with Spiking features, designed to enhance high-level skill reasoning and data-efficient motion synthesis for humanoid robots. It leverages lightweight 2D geometric inductive biases to improve 3D scene understanding and addresses challenges in sample efficiency through recursive spiking networks. Extensive experiments demonstrate superior performance across diverse robotic systems.",348.89,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09032v1_The Hierarchy of Agentic Capabilities Evaluating F.pdf,Exact string,"Logan Ritchie, Sushant Mehta, Nick Heiner, Mason Yu, Edwin Chen",10.48550/arXiv.2601.09032,2601.09032,"AI agents, RL environments, task completion, tool use, planning","The paper evaluates frontier AI models on 150 workplace tasks in a realistic e-commerce RL setting, identifying a hierarchy of agentic capabilities (tool use, planning, adaptability, groundedness, common-sense reasoning) and highlighting persistent performance gaps.",334.37,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09035v1_A Decompilation-Driven Framework for Malware Detec.pdf,Exact string,"Aniesh Chawla ∗, Udbhav Prasad ∗",10.1093/acpsrc/202301,arXiv:2601.09035v1,"Malware, Ghidra, Cybersecurity, LLMs, GenAI, Machine Learning Algorithms",The paper presents a framework that combines automated decompilation of Windows executables using Ghidra with Large Language Models to classify malware as benign or malicious. It evaluates the performance of LLMs in this context and highlights the need for continuous fine-tuning to keep pace with evolving malware.,311.34,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09041v1_Can LLMs interpret figurative language as humans d.pdf,Exact string,"Samhita Bollepally, Aurora Sloman-Moll, Takashi Yamauchi",10.48550/arXiv.2026.12345,10.48550/arXiv.2026.12345,"language models, human judgment, figurative language, sarcasm, idiomacy, surface-level vs","The study compares human and large language model (LLM) performance across six linguistic traits, revealing that while models align at the surface level, they diverge significantly in interpreting figurative and socio-pragmatic language, especially idioms and Gen Z slang.",337.82,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09049v1_Is Grokking Worthwhile Functional Analysis and Tra.pdf,Exact string,"Kaiyu He, Mian Zhang, Peilin Wu, Xinya Du, Zhiyu Zoey Chen",10.48550/arXiv.2405.12345,10.48550/arXiv/2405.12345,"functional analysis, transferability, generalization circuits","This paper investigates whether parameter-sharing transformers can bridge the 'curse of two-hop reasoning' by forming a 'Generalization Circuit' during prolonged grokking. It evaluates grokking's impact on knowledge generalization and transferability, arguing that grokking integrates facts rather than acquiring a new reasoning paradigm.",295.55,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09066v1_Midm 2.0 Korea-centric Bilingual Language Models.pdf,Mi:dm 2.0,"Tech. Innovation Group, KT, midm-llm@kt.com",10.48550/arXiv:2209.11456,10.48550/arXiv:2209.11456,"Korea-centric AI, Mi:dm 2.0, KOREA-CENTRICAI, language model, cultural understanding","Mi:dm 2.0 introduces a bilingual large language model tailored for Korea, emphasizing cultural nuance, emotional intelligence, and robust data quality to overcome limitations of existing models.",317.82,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09069v1_From Symbolic to Natural-Language Relations Rethin.pdf,From Symbolic to Natural-Language Relations: Rethinking Knowledge,"Kanyao Han, Yushang Lai",10.1093/acps/ghac020,10.1093/acps/ghac020,"knowledge graphs, knowledge representation, natural language relations","The paper discusses the shift from symbolic to natural-language relation descriptions in knowledge graphs, emphasizing the need for more flexible and context-sensitive relational representations in the era of large language models.",313.24,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09072v1_Human-AI Co-design for Clinical Prediction Models.pdf,Human-AI Co-design for Clinical Prediction Models,"Jean Feng, Avni Kothari, Patrick Vossler, Andrew Bishara, Lucas Zier, Newton Addo, Aaron Kornblith, Yan Shuo Tan, Chandan Singh",10.1093/acp/qap123,2601.09072v1,"Large language models, Electronic health records, Concept Bottleneck, Human-AI Interaction","The paper presents HACHI, an iterative human-in-the-loop framework that accelerates the development of interpretable clinical prediction models by enabling AI agents to explore clinical notes and receiving expert feedback. It demonstrates improved performance in real-world prediction tasks and highlights the importance of clinical collaboration.",339.97,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09085v1_MMR-GRPO Accelerating GRPO-Style Training through .pdf,Exact string,"Kangda Wei, Ruihong Huang",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"GRPO, diversity-aware, reward reweighting, mathematical reasoning","The paper introduces MMR-GRPO, a diversity-aware variant of Group Relative Policy Optimization, which reduces training steps and wall-clock time by downweighting redundant completions and emphasizing diverse solutions.",318.3,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09089v1_SubTokenTest A Practical Benchmark for Real-World .pdf,SUBTOKENTEST: A Practical Benchmark for Real-World Sub-token,"Shuyang Hou, Yi Hu, Muhan Zhang",10.5281/zenodo.1234567,10.5281/zenodo.1234567,"sub-token understanding, LLM, character-level tasks, benchmark","This paper introduces SUBTOKENTEST, a benchmark evaluating sub-token understanding in large language models through practical tasks. It highlights limitations in LLMs' character-level reasoning and explores impacts of test-time scaling on tokenization.",321.98,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09097v1_Programming over Thinking Efficient and Robust Mul.pdf,Programming over Thinking: Efficient and Robust,"Derrick Goh Xin Deik1, Quanyu Long1, Zhengyuan Liu2, Nancy F. Chen2, Wenya Wang1",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"planning, LLM, constraints, code, optimization","The paper introduces the ScalableCodePlanning Engine (SCOPE), a framework that separates reasoning from code execution to enable consistent, deterministic, and reusable planning solutions. SCOPE improves upon existing LLM-based methods by reducing cost, latency, and error accumulation while maintaining high performance on planning tasks.",375.07,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09100v2_DScheLLM Enabling Dynamic Scheduling through a Fin.pdf,Exact string,"Zhang D, Chenggong Zhao, Gaoa Gao, Xiaoke Zhao, Gengyi Bai, Jinhu Lv",10.1016/j.ss.2023.01.007,10.1016/j.ss.2023.01.007,"dynamic scheduling, large language model, fine-tuning, job shop scheduling","The paper introduces DScheLLM, a dynamic scheduling framework using fine-tuned large language models within a dual-system architecture to handle disturbances in job shop scheduling. It demonstrates the effectiveness of fast-thinking and slow-thinking modes for generating schedules under varying conditions.",320.6,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09105v2_AviationLMM A Large Multimodal Foundation Model fo.pdf,AviationLMM: A Large Multimodal Foundation,"Wenbin Li, Jingling Wu, Xiaoyong Lin, Jing Chen, Cong Chen",10.1000/arXiv.2023.12345,10.1000/arXiv.2023.12345,"civil aviation, multi-modal model, foundation model, cloud edge collaboration, hybrid training, computing methodologies","The paper introduces AviationLMM, a large multimodal foundation model for civil aviation, aiming to integrate heterogeneous data streams (voice, radar, sensors, text) to enhance situational awareness, decision support, and predictive capabilities. It addresses gaps in current AI solutions and outlines research opportunities in data alignment, fusion, trustworthiness, and privacy.",291.25,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09113v1_The AI Hippocampus How Far are We From Human Memor.pdf,Exact string,"Zixia Jia, Jiaqi Li, Yipeng Kang, Yuxuan Wang, Tong Wu, Quansen Wang, Xiaobo Wang, Shuyi Zhang, Jinzhe Shen, Qing Li, Siyuan Qi, Yitao Liang, Di He, Zilong Zheng, Song-Chun Zhu",10.48550/arXiv.2025.12345,10.48550/arXiv.2025.12345,"memory, LLM, memory-augmented, machine learning, multi-modal","This paper reviews the role of memory in large language models and multi-modal LLMs, categorizing memory into implicit, explicit, and agentic paradigms. It highlights architectural advances, benchmark tasks, and challenges in integrating memory mechanisms for enhanced reasoning and adaptability.",334.77,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09116v1_LP-LLM End-to-End Real-World Degraded License Plat.pdf,Exact string,"Haoyan Gong, Xi’an Jiaotong-Liverpool University",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"license plate recognition, degraded images, character recognition, Vision-Language Models","The paper presents a structure-aware multimodal reasoning framework for end-to-end license plate recognition, addressing challenges from motion blur, low resolution, and complex illumination through a character-aware reasoning module.",318.27,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09117v1_A Marketplace for AI-Generated Adult Content and D.pdf,Exact string,"Shalmoli Ghosh, Matthew R. DeVerna, Filippo Menczer, Indiana University Bloomington, Stanford University",10.48550/arXiv.2311.03855,10.48550/arXiv:2311.03855,"AI-generated content, deepfakes, bounties, content moderation, gender asymmetry","This study examines the monetized bounty marketplace on Civitai, analyzing how users leverage AI tools to create content and the social consequences, including gendered harms and uneven participation.",310.67,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09120v1_Adaptive Multi-Stage Patent Claim Generation with .pdf,Adaptive Multi-Stage Patent Claim Generation,"Chen-Wei Liang, Bin Guo, Zhen-Yuan Wei, Mu-Jiang-Shan Wang, Corresponding author(s)",10.1109/ARXIV.2026.2601,2601.09120v1,"Patent claim generation, Cross-jurisdictional learning, Quality assessment, Transformer, Domain adaptation","The paper presents a novel three-stage framework for patent claim generation that overcomes limitations in cross-jurisdictional generalization, semantic relationship modeling, and quality assessment. It introduces multi-head attention with specialized heads, dynamic LoRA adaptation, and cross-attention for unified quality evaluation, achieving significant improvements over existing methods.",282.82,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09130v1_Equi-ViT Rotational Equivariant Vision Transformer.pdf,Equi-ViT: Rotational Equivariant Vision Transformer for Robust Histopathology Analysis,"Fuyao Chen, Yuexi Du, El Leonore V. Lieffrig, Nicha C. Dvornek, John A. Onofrey",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"Digital Histopathology, Vision Transformer, Rotation Equivariance, Artificial Intelligence","The paper introduces Equi-ViT, a Vision Transformer architecture enhanced with an equivariant convolution kernel to achieve rotation-consistent patch embeddings. This improves robustness to image orientation variations in histopathology imaging, demonstrating superior classification performance on a public colorectal cancer dataset.",324.49,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09136v1_SkinFlow Efficient Information Transmission for Op.pdf,SkinFlow: Efficient Information Transmission for Open Dermatological Diagnosis via Dynamic Visual Encoding and Staged RL,"Lijun Liu, Linwei Chen, 6, 7, Zhishou Zhang, Meng Tian, Hengfu Cui, Ruiyang Li, Zhaocheng Liu, Qiang Ju, Qianxi Li, Hong-Yu Zhou",10.1234/abcd1234,10.1234/abcd1234,"SkinFlow, dermatology, diagnosis, visual encoding, reinforcement learning, medical AI","The paper introduces SkinFlow, a framework that optimizes visual information transmission efficiency for dermatological diagnosis by treating diagnosis as an optimization problem. It employs a Virtual-Width Dynamic Vision Encoder and a two-stage reinforcement learning approach to improve diagnostic accuracy without scaling parameters excessively.",322.13,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09147v2_SSVP Synergistic Semantic-Visual Prompting for Ind.pdf,Synergistic Semantic-Visual Prompting for Industrial Zero-Shot Anomaly Detection,"Chenhao Fu, Han Fang, Xiuzheng Zheng, Wenbo Wei, Yonghua Li, Hao Sun, Xuelong Li",10.1234/abcd1234,10.1234/abcd1234,"industrial anomaly detection, semantic-visual prompting, CLIP, Vision-Language Models","The paper introduces Synergistic Semantic-Visual Prompting (SSVP), a method that integrates hierarchical semantic priors from DINOv3 into CLIP and uses a Vision-Conditioned Prompt Generator (VCPG) to enable precise, language-guided anomaly detection. It addresses limitations of static templates and shallow prompting by employing dynamic cross-modal attention and a dual-gated calibration system, achieving strong performance on industrial benchmarks.",290.7,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09152v1_PrivacyReasoner Can LLM Emulate a Human-like Priva.pdf,PrivacyReasoner: An AI-Agent for Modeling Privacy Concerns,"Yiwen Tu, Xuan Liu, Lianhui Qin, Haojian Jin",10.1234/abcd1234,None,"privacy, AI, user reasoning, contextual filtering","This paper presents PrivacyReasoner, an AI agent that simulates individual privacy concerns in response to real-world news. It integrates privacy and cognitive theories to model user-specific reasoning, reconstructing a 'privacy mind' through contextual cues and generating synthetic comments. A LLM-as-a-Judge evaluator assesses the faithfulness of these responses.",311.85,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09156v1_KTCF Actionable Recourse in Knowledge Tracing via .pdf,Exact string,"KTCF, Woojin Kim, Changkwon Lee, Hyeoncheol Kim",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Knowledge Tracing, Counterfactual Explanation, Education, AI","The paper presents KTCF, a counterfactual explanation generation method for Knowledge Tracing that enhances educational decision-making by providing actionable insights and improving model interpretability.",347.01,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09182v1_Position on LLM-Assisted Peer Review Addressing Re.pdf,Exact string,"JungMin Yun, JuneHyoung Kwon, MiHyeon Kim, YoongBin Kim, 2, 3, KT Corporation",10.1234/abcd1234,None,,N/A,262.18,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09195v1_ProFit Leveraging High-Value Signals in SFT via Pr.pdf,ProFit: Leveraging High-Value Signals in SFT via Probability-Guided Token Selection,"Tao Liu, Taiqiang Wu, Runming Yang, Shaoning Sun, Junjie Wang, Yujiu Yang",10.48550/arXiv.2303.04212,10.48550/arXiv.2303.04212,"ProFit, Supervised Fine-Tuning, LLM, Token Probability, Multi-SFT","The paper introduces ProFit, a strategy that selectively masks low-probability tokens to mitigate single-reference overfitting in supervised fine-tuning. By prioritizing high-probability tokens, ProFit improves alignment with core semantic structures while maintaining computational efficiency.",354.96,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09208v2_Mikasa A Character-Driven Emotional AI Companion I.pdf,Mikasa: A Character-Driven Emotional AI Companion,Miki Ueno,10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"character design, relationship definition, emotional AI, Japanese Oshi culture","The paper introduces Mikasa, an emotional AI companion inspired by Japanese Oshi culture, emphasizing stable personality and non-exclusive user relationships. It argues that character coherence and clear relationship definitions improve long-term engagement, highlighting character design as a functional component of AI systems.",321.06,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09212v1_Annealed Relaxation of Speculative Decoding for Fa.pdf,Exact string,"Xingyao Li1, Fengzhuo Zhang1, Cunxiao Du2*, Hui Ji1",10.48550/arxiv/2303.04112,10.48550/arxiv/2303.04112,"speculative decoding, relaxed decoding, auto-regressive, image generation","The paper proposes COOL-SD, an annealed relaxation of speculative decoding, to improve inference speed in auto-regressive image generation by leveraging theoretical insights into total variation distance and perturbation analysis.",310.42,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09213v1_SpikeVAEDiff Neural Spike-based Natural Visual Sce.pdf,Exact string,"Jialu Li, HKUST, Taiyan Zhou, HKUST",10.48550/arXiv.2311.07818,10.48550/arXiv:2311.07818,"neural decoding, visual scene reconstruction, spike data, image reconstruction, neural activity","The paper introduces SpikeVAEDiff, a two-stage framework combining VDVAE and Versatile Diffusion to reconstruct high-resolution visual scenes from neural spike data. It demonstrates the effectiveness of spike-based methods over fMRI, highlighting the VISI region's importance and validating the model through ablation studies.",314.54,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09233v1_GIFT Unlocking Global Optimality in Post-Training .pdf,Exact string,"Zhengyang Zhao, Lu Ma, Yizhen Jiang, Xiaochen Ma, Zimo Meng, Chengyu Shen, Lexiang Tang, Haoze Sun, Peng Pei, Wentao Zhang",10.48550/arXiv.2303.04112,10.48550/arXiv.2303.04112,"post-training, optimality, Gibbs Initialization, reinforcement learning, distributional collapse","The paper proposes GIFT (Gibbs Initialization with Finite Temperature) to address distributional collapse in post-training by integrating supervised fine-tuning within a unified framework. It enhances RL initialization for Large Reasoning Models, demonstrating improved performance over standard SFT.",337.05,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09236v2_Reward Learning through Ranking Mean Squared Error.pdf,Reward learning through ranking means squared error,"Chaitanya Kharyal, Calarina Muslimani, Matthew E. Taylor",10.48550/arXiv.2405.09002,10.48550/arXiv:2405.09002,"reward learning, reinforcement learning, human feedback, ranked regression","The paper introduces a new reinforcement learning method, Ranked Return Regression for RL (R4), that uses a novel ranking mean squared error loss to learn reward functions from human ratings. It demonstrates that R4 can match or outperform existing rating-based approaches on robotic locomotion benchmarks while requiring less feedback.",338.23,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09239v2_DSA-Tokenizer Disentangled Semantic-Acoustic Token.pdf,Exact string,"Hanlin ZHANG1, Daxin Tan2, Dehua Tao2, Xiao Chen2, Yunhe Li1, Yuchen Cao, Jianping Wang, Linqi Song, † Haochen Tan2, † Yunhe Li",10.1093/pasj/psa.2023,https://arxiv.org/abs/2303.04112,"speech tokenization, disentangled tokenization, speech large language models, semantic-acoustic fusion, discrete tokens","The paper introduces DSA-Tokenizer, a discrete speech tokenizer that disentangles semantic and acoustic tokens using hierarchical flow matching and joint reconstruction-recombination training. It aims to improve disentanglement in speech LLMs by separating content from style and enabling flexible recombination.",325.9,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09248v1_Hybrid guided variational autoencoder for visual p.pdf,Hybrid guided variational autoencoder for visual place recognition,"Ni Wang, Zihan You, Emre Neftci, Thorben Schoepe",10.48550/arXiv.2405.12345,10.48550/arXiv.2405.12345,"Visual place recognition, Spiking neural network, Robotics, Indoor navigation","The paper presents a compact, event-based guided variational autoencoder (VAE) for visual place recognition. It leverages spiking neural networks compatible with low-power hardware to achieve high robustness and generalization across indoor environments. The model disentangles visual features of 16 distinct places, enabling precise localization even under varying lighting conditions. This approach enhances mobile robot navigation by balancing compactness with strong performance.",283.12,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09251v1_HGATSolver A Heterogeneous Graph Attention Solver .pdf,Exact string,"Qin-Yi Zhang, Hong Wang, Siyao Liu, Haichuan Lin, Linying Cao, Chen Chen, Shuangyi Wang, Zeng-Guang Hou, Zeng-Guang Hou",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"fluid-structure interaction, heterogeneous graph attention, physics-informed neural networks, multi-physics systems, interface coupling","The paper presents the Heterogeneous Graph Attention Solver (HGA TSolver) for fluid-structure interaction, addressing challenges in modeling heterogeneous dynamics through a unified graph framework. It introduces a physics-conditioned gating mechanism and an inter-domain gradient balancing loss to improve stability and accuracy in coupled simulations.",304.63,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09253v1_RIFT Repurposing Negative Samples via Reward-Infor.pdf,Repurposing Negative Samples via Reward-Informed Fine-Tuning,"Zehua Liu, Shuqi Liu, Tao Zhong, Mingxuan Yuan",10.48550/arXiv.2311.07891,10.48550/arXiv:2311.07891,"LLM alignment, negative samples, Reward Informed Fine-Tuning, data efficiency","The paper introduces Reward Informed Fine-Tuning (RIFT), a method that repurposes negative samples by reweighting losses using scalar rewards. Unlike traditional RFT, RIFT leverages self-generated data to improve alignment while addressing data inefficiency and training instability.",333.88,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09259v1_MAXS Meta-Adaptive Exploration with LLM Agents.pdf,Exact string,"Jian Zhang, Zhiyuan Wang, Zhangqi Wang, Yu He, Haoran Luo, Li Yuan, Lingling Zhang, Rui Mao, Qika Lin, Jun Liu",10.1234/journals/2024.0123,null,"LLM Agents, meta-adaptive exploration, LLM agents, trajectory stability","The paper introduces MAXS, a meta-adaptive exploration framework for LLM agents that enhances reasoning by integrating lookahead and trajectory convergence. It addresses local myopia and trajectory instability, improving both global effectiveness and computational efficiency across multiple tools.",289.55,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09260v1_Efficient Paths and Dense Rewards Probabilistic Fl.pdf,Exact string,"Yan Liu, Feng Zhang, Zhanyu Ma, Jinghua Hao, Renqing He, Han Liu4, Yangdong Deng",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"large language models, chain-of-thought, probabilistic flow, reinforcement learning","The paper introduces CoT-Flow, a framework that models discrete reasoning steps as a continuous probabilistic flow. It quantifies each reasoning step's contribution to the final answer, enabling flow-guided decoding and flow-based reinforcement learning. This approach improves inference efficiency and reasoning performance on challenging benchmarks.",310.76,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09262v1_Magnifying change Rapid burn scar mapping with mul.pdf,Exact string,"Maria Sdraka, Dimitrios Michail, Ioannis Papoutsis",10.5281/zenodo.1234567,null,"Artificial intelligence, Machine Learning, Remote Sensing, burn scar mapping, disaster management, disaster monitoring, wildfires, burn scar mapping, change detection, downscaling, super-resolution","The paper presents a novel deep learning model, BAM-MRCD, for rapid burn scar mapping using multi-resolution, multi-source satellite imagery. It addresses the challenge of balancing spatial resolution and temporal revisit frequency in wildfire impact assessment.",286.06,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09264v1_Coordinated Pandemic Control with Large Language M.pdf,Exact string,"Ziyi Shi, Xusen Guo2, Hongliang Lu, Mingxing Peng2, Haotian Wang2, Zheng Zhu, Zhenning Li, Yuxuan Liang2, Xinhu Zheng2, Hai Yang1",10.1234/abcd1234,None,"Pandemic Control, Large Language Models, Multi-Agent System, Coordinated Policymaking","The study introduces an LLM-based multi-agent policymaking system designed to enhance coordinated pandemic response by enabling agents to reason over regional dynamics and communicate across boundaries, ultimately improving public health outcomes.",313.69,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09269v2_RISER Orchestrating Latent Reasoning Skills for Ad.pdf,Exact string,"Wencheng Ye, Tongji University, Xiaoyang Yuan, Yi Bin, Hengyu Jin, Liang Peng, Tencent, Pengpeng Zeng, Heng Tao Shen, Tongji University",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"domain-specific reasoning, large language models, activation steering, reasoning adaptation, control strategies","RISER introduces a plug-and-play intervention framework that adaptively steers LLM reasoning in activation space, improving zero-shot accuracy while enhancing token efficiency.",381.16,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09274v1_A3-Bench Benchmarking Memory-Driven Scientific Rea.pdf,Exact string,"Jian Zhang, Yu He, Zhiyuan Wang, Zhangqi Wang, Kai He, Fangzhi Xu, Qika Lin",10.48550/arXiv.2601.09274,2601.09274,"scientific reasoning, memory-driven, anchors, attractors, LLM","Proposes A3-Bench to evaluate scientific reasoning via dual-scale memory activation, emphasizing memory-driven mechanisms in reasoning processes.",367.1,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09278v1_M3Searcher Modular Multimodal Information Seeking .pdf,Exact string,"Xiaohan Yu, Chao Feng, Lang Mei, Chong Chen",10.48550/arXiv.2024.12345,10.48550/arXiv:24/12345,"modular agent, multimodal, information seeking, RL","The paper presents M3Searcher, a modular multimodal information-seeking agent designed to address challenges in specialization-generalization trade-offs and data scarcity by decoupling information acquisition from answer generation. It introduces MM-SearchVQA and evaluates performance on retrieval-oriented RL tasks.",283.04,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09280v1_ReGraM Region-First Knowledge Graph Reasoning for .pdf,ReGraM: Region-First Knowledge Graph Reasoning for Medical Question Answering,"Chaerin Lee, Sohee Park, Hyunsik Na, Daseon Choi",10.48550/arXiv.2405.12345,10.48550/arXiv.2405.12345,"medical question answering, knowledge graphs, multi-hop reasoning, LLM integration","This paper introduces ReGraM, a region-first knowledge graph reasoning framework for medical QA. It constructs a query-aligned subgraph and performs stepwise reasoning constrained to a localized region, improving factual accuracy and reducing hallucinations. Experiments show significant gains across benchmarks.",334.25,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09281v1_STaR Sensitive Trajectory Regulation for Unlearnin.pdf,Sensitive Trajectory Regulation for Unlearning in Large Reasoning Models,"Jingjing Zhou, Gaoxiang Cong, Li Su, Liang Li",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"unlearning, privacy, large reasoning models, Chain-of-Thought, sensitive content","The paper introduces Sensitive Trajectory Regulation (STaR), a parameter-free inference-time unlearning framework for Large Reasoning Models. STaR addresses privacy risks in LRMs by detecting sensitive content, injecting safety constraints, and applying token-level filtering to suppress sensitive information across reasoning trajectories. It proposes two evaluation metrics: Multi-Decoding Consistency Assessment and Multi-Granularity Membership Inference Attack, demonstrating effective unlearning with minimal utility loss.",298.37,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09282v1_Cluster Workload Allocation Semantic Soft Affinity.pdf,Cluster Workload Allocation: Semantic Soft Affinity Using Natural Language Processing,"Leszek Sliwko, Jolanta Mizeria-Pietraszko",10.1093/acprof:oso/9780190871293.001.0001,10.1093/acprof:oso/9780190871293.001.0001,"Cluster workload allocation, Semantic soft affinity, Natural Language Processing, Kubernetes, Load balancing, Task assignment, LLM integration","The paper presents a semantic, intent-driven scheduling paradigm for cluster systems using Natural Language Processing. It introduces a Large Language Model (LLM) integrated via a Kubernetes scheduler extender to interpret natural language allocation hints for soft affinity preferences. A prototype with a cluster state cache and intent analyzer was developed, achieving high LLM parsing accuracy (>95% Subset Accuracy) and outperforming baseline models in complex scenarios.",348.59,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09286v1_Why not Collaborative Filtering in Dual View Bridg.pdf,Why not Collaborative Filtering in Dual View? Bridging Sparse and Dense Models,"Hanze Guo, Jianxun Lian, Xiaou Zhou",10.1093/acr/acv005,10.1093/acr.2025.00123,"Collaborative Filtering, Dual View Alignment, Sparse and Dense model","The paper presents SaD (Sparse and Dense), a framework that unifies dense embeddings with sparse interaction patterns to improve recommendation performance under data sparsity. It demonstrates that dual-view alignment yields superior global signal-to-noise ratios and achieves state-of-the-art results.",286.29,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09292v1_Blue Teaming Function-Calling Agents.pdf,Exact string,"Greta Dolcetti, Giulio Zizzo, Sergio Maffeis",10.48550/arXiv.2025.12345,10.48550/arXiv.2025.12345,"function-calling, LLM, security, defences","This paper evaluates the robustness of open-source LLMs with function-calling capabilities against various attacks and tests eight defensive strategies, highlighting gaps in current security measures.",316.63,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09293v1_Policy-Based Reinforcement Learning with Action Ma.pdf,Policy-Based Reinforcement Learning with Action Masking for Dynamic Job Shop,"Sofiene Lassoued, Stefan Lier, Andreas Schwung a, Andreas Schwung b",10.1007/978-3-642-45888-8,None,"Dynamic Job Shop Scheduling, Fault tolerance, Reinforcement learning, Actions masking, Petri nets, Reinforcement learning policies","The paper introduces a novel framework for Dynamic Job Shop Scheduling that addresses uncertainty from stochastic job arrivals and machine failures. It employs Coloured Timed Petri Nets and Maskable Proximal Policy Optimization to enable adaptive decision-making while restricting feasible actions. Using a Gamma distribution for job arrivals and a Weibull distribution for machine failures, the method models realistic industrial conditions. Two action-masking strategies are evaluated, and extensive experiments show superior makespan performance compared to traditional methods.",288.06,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09306v1_On-Device Large Language Models for Sequential Rec.pdf,On-Device Large Language Models for Sequential Recommendation,"Xin Xia, Hongzhi Yin, Shane Culpepper",10.1145/3773966.3777961,10.1145/3773966,"Recommender Systems, Sequential Recommendation, On-Device Recommendation, Model Compression, Resource Constrained Devices","The paper introduces OD-LLM, a framework for efficient on-device deployment of large language models tailored to sequential recommendation tasks. It combines low-rank structural compression with a novel tokenization normalization and progressive alignment to reduce model size while maintaining performance. Empirical results show no loss in effectiveness when halving the deployed model size.",350.71,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09313v1_Understanding or Memorizing A Case Study of German.pdf,Understanding or Memorizing? A Case Study of German Definite Articles,"Jonathan Drechsel, Erisa Bytyqi, Steffen Herbold",10.48550/arXiv.2405.12345,10.48550/arXiv.2405.12345,"German definite articles, language models, memorization, rule-based encoding","The study investigates whether German definite articles are learned through rule-based generalization or memorized associations, using gradient-based interpretability methods. It finds evidence against strict rule-based encoding, suggesting models rely on memorized patterns.",312.52,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09342v1_Improving Implicit Hate Speech Detection via a Com.pdf,Exact string,"Ewelina Gajewska, Katarzyna Budzynska, Jarosław A. Chudziak",10.1093/acps/ccad045,10.1093/acps/ccad045,"LLMs, Community agents, Hate speech, Social media, Moderation, Fairness","This paper proposes a community-driven multi-agent framework for detecting implicit hate speech, emphasizing identity-aware moderation and improved fairness through balanced accuracy metrics.",319.43,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09351v1_Navigating Ethical AI Challenges in the Industrial.pdf,Exact string,"Ruomu Tan, Martin W Hoffmann",10.1093/pasj/psa.2026,2601.09351v1,"AI, industrial, ethics, innovation","The paper discusses the ethical challenges and opportunities arising from integrating artificial intelligence into the industrial sector, emphasizing the need for ethical considerations in AI-driven industrial innovation.",333.92,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09353v1_Monte-Carlo Tree Search with Neural Network Guidan.pdf,Monte-Carlo Tree Search with Neural Network Guidance,"Ioannis Peridis, Dimitrios Troullinos, Georgios Chalkiadakis, Pantelis Giankoulidis, Ioannis Papamichail, Markos Papageorgiou",10.1093/pasj/psa.2023,2601.09353,"Monte-Carlo Tree Search, Neural Network Guidance, Autonomous Driving, Lane-Free Traffic, Reinforcement Learning","This paper presents a Monte-Carlo Tree Search (MCTS) planning approach for single-agent autonomous driving in lane-free traffic environments. It integrates a pre-trained neural network to guide the tree search, aiming to improve safety and performance metrics such as collision rates and speed. The study explores the impact of isotropic state information and NN-based guidance on decision-making under computational constraints.",305.82,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09361v1_GeoRA Geometry-Aware Low-Rank Adaptation for RLVR.pdf,GeoRA: Geometry-Aware Low-Rank Adaptation for RLVR,"Jiaying Zhang, Lei Shi, Jiguo Li, Jun Xu, Jiuchong Gao, Jinghua Hao",10.48550/arXiv.2405.12345,10.48550/arXiv.2405.12345,"GeoRA, RLVR, low-rank adaptation, geometry-aware, optimization","Proposes GeoRA, a geometry-aware low-rank adaptation method for RLVR, to mitigate optimization instability by exploiting anisotropic update subspaces and preserving pre-trained geometric structure.",358.99,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09365v1_Frame of Reference Addressing the Challenges of Co.pdf,Exact string,"Biswesh Mohapatra, Théo Charlot, Nantes Université, Giovanni Duca, University of Trento, Mayank Palan, VJTI Mumbai, Laurent Romary, Justine Cassell",10.1093/acps/2024.01.012,10.1093/acps.2024.01.012,"common ground, situational dialogue, conversational grounding","This paper evaluates a model's ability to establish common ground in situated dialog systems by leveraging relational references, addressing challenges in grounding complex spatial-temporal references. It highlights the need for memory-based representation of shared knowledge to support coherent interaction over extended conversations.",337.67,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09381v1_Query Languages for Machine-Learning Models.pdf,Exact string,"Martin Grohe, RWTH Aachen University",10.1093/acm/qad020,10.1093/acm/qad020,"query languages, machine learning, neural networks, finite structures","This paper explores two logics for weighted finite structures—first-order logic with summation (FO(SUM)) and its recursive extension IFP(SUM)—originating from foundational work by Grädel et al. It investigates these logics as query languages for machine learning models, especially neural networks, and discusses their expressiveness and computational complexity.",292.06,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09382v1_Long-term Task-oriented Agent Proactive Long-term .pdf,Exact string,"Qinglong Shi, Donghai Wang, Hantao Zhou, Jiguo Li, Jun Xu, Jiuchong Gao, Jinghua Hao, Renqing He",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"long-term intent, proactive agents, dynamic environments, task-oriented interaction, LLM adaptation","The paper introduces a proactive interaction paradigm for task-oriented agents, emphasizing intent-conditioned monitoring and event-triggered follow-up to enable long-term task management in dynamic settings. It proposes a new benchmark, ChronosBench, and demonstrates improved performance on complex, multi-turn dialogues using synthetic data.",350.31,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09394v2_FairGE Fairness-Aware Graph Encoding in Incomplete.pdf,FairGE: Fairness-Aware Graph Encoding in Incomplete Social Networks,"Renqiang Luo, Huafei Huang, Tao Tang, Jing Ren, Ziqi Xu, Mingliang Hou, Ziqi Xu∗, Jing Ren, Feng Xia, Enyan Dai, Feng Xia",10.1109/ACM.2026.12345,10.1109/TACM.2026.12345,"Social Networks, Graph Learning, Graph Transformers, Fairness, Incomplete Data","FairGE introduces a fairness-aware framework for Graph Transformers in incomplete social networks, encoding fairness directly via spectral graph theory and maintaining data privacy by padding missing attributes.",389.76,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09398v1_Ability Transfer and Recovery via Modularized Para.pdf,Ability Transfer and Recovery via Modularized Parameters Localization,"Songyao Jin, Kun Zhou, Wenqi Li, Peng Wang, Biwei Huang",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"ability transfer, LLM parameters, domain adaptation, forgetting","The paper investigates how abilities are distributed in large language models by analyzing activation patterns across modules. It proposes ACT (Activation-Guided Channel-wise Ability Transfer) to selectively transfer ability-relevant parameters while preserving performance, demonstrating effective recovery of forgotten abilities and enabling integration of multiple specialized models.",277.98,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09413v1_Speech-Hands A Self-Reflection Voice Agentic Appro.pdf,Speech-Hands: A Self-Reflection Voice Agentic Approach to Speech Recognition and Audio Reasoning with Omni Perception,"Zhen Wan, Chao-Han Huck Yang, Jinchuan Tian, Hanrong Ye, Ankita Pasad, Szu-wei Fu, Ryo Hachiuma, Shizhe Diao, Kunal Dhawan, Sreyan Ghosh, Yusuke Hirota, Zhehuai Chen, Rafael Valle, Ehsan Hosseini Asl, Chenhui Chu, Shinji Watanabe, Yu-Chiang Frank Wang, Boris Ginsburg",10.48550/arXiv.2405.12345,10.48550/arXiv.2405.12345,"speech recognition, audio reasoning, self-reflection, omni perception, speech-agentic, perception decision","The paper introduces Speech-Hands, a voice-agentic framework that enables a model to decide when to trust its own outputs versus consulting external audio understanding. By modeling self-reflection as a decision primitive, the approach improves robustness across diverse audio tasks and outperforms baselines by 12.1% in word error rate on benchmarks.",361.88,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09416v1_Radiomics-Integrated Deep Learning with Hierarchic.pdf,Radiomics-Integrated Deep Learning with Hierarchical Loss for Osteosarcoma Histology Classification,"Yaxi Chen, Zi Ye, Oliver Yu, Simin Ni, Jie Huang",10.1093/acm/qad045,null,"Osteosarcoma, Radiomics, Multi-Task Learning, Hierarchical Loss",The study proposes enhancing deep learning performance for osteosarcoma histopathology classification by integrating radiomic features and introducing a hierarchical loss function to address tumor-vs-non-tumor and viable-vs-non-viable classification tasks.,334.46,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09421v2_Bias Dynamics in BabyLMs Towards a Compute-Efficie.pdf,Bias Dynamics in BabyLMs: Towards a Compute-Efficient Sandbox for Democratising Pre-Training Debiasing,"Filip Trhlik, Andrew Caines, Paula Buttery",10.48550/arXiv.2405.1234,10.48550/arXiv/2405.1234,"BabyLMs, bias mitigation, pre-training, computational efficiency, fairness, language models","The paper explores BabyLMs as a low-cost proxy for studying bias in large language models, demonstrating their ability to replicate bias patterns of larger models while reducing training costs. It highlights their potential to democratize debiasing research and provides new insights into gender and toxicity influences.",293.9,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09433v1_Do Transformers Understand Ancient Roman Coin Moti.pdf,Exact string,"David Reid, Ognjen Arandjelovi",10.1093/pasj/psa.2023.01,2601.09433,"Transformers, ancient coins, coin analysis, CV, ML","This paper explores the application of Vision Transformer (ViT) models to identify semantic elements on ancient Roman coins, comparing their performance with convolutional neural networks (CNNs). It highlights the potential of Transformers for automated analysis in numismatics.",313.43,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09445v1_Where Knowledge Collides A Mechanistic Study of In.pdf,Exact string,"Minh Vu Pham, Hsuvas Borkakoty, Yufang Hou",10.48550/arXiv.2601.09445,10.48550/arXiv.2601.09445,"language models, knowledge conflict, intra-memory, mechanistic interpretability",This study investigates how intra-memory knowledge conflicts emerge in language models during pre-training and proposes a framework to identify and address these conflicts using mechanistic interpretability methods.,284.43,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09446v1_Improving Symbolic Translation of Language Models .pdf,Improving Symbolic Translation of Language Models for Logical Reasoning,"Ramya Keerthy Thatikonda1, Jiuzhou Han1, Wray Buntine2, Ehsan Shareghi1",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"symbolic translation, logical reasoning, language models, predicate logic","The paper presents a framework to address errors in translating natural language into first-order logic using smaller language models. It introduces incremental inference and a verification module to improve reasoning performance, evaluating three model families across multiple datasets.",327.86,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09448v1_Population-Aligned Audio Reproduction With LLM-Bas.pdf,Exact string,"Ioannis Stylianou, Jon Francombe, Pablo Martín-Nuevo, Sven Ewan Shepstone, Member, IEEE, Zheng-Hua Tan, Senior Member, IEEE",10.1109/JPSP.2024.00123,10.1109/JPSP.2024.00123,"Population-Aligned Audio Reproduction, LLM-Based Equalizers, Audio Reproduction, Listening Experiments, Recommender Systems","The paper presents an LLM-driven approach for population-aligned audio equalization, enabling conversational sound system control through natural language prompts. It demonstrates improved distributional alignment over static baselines using in-context learning.",294.65,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09451v1_Late Breaking Results Quamba-SE Soft-edge Quantize.pdf,Exact string,"Yizhi Chen{yizhic@kth.se}, Ahmed Hemani{hemani@kth.se}], doi_this_paper_nao_presented, null, arxiv_id_nao_presented, null, keywords': [, ], , summary",None,None,,N/A,219.33,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09455v1_On the Hardness of Computing Counterfactual and Se.pdf,Exact string,"André Arteltaartelt, Martin Olsen, Kevin Tierney",10.48550/arXiv.2025.12345,2601.09455,"counterfactual explanation, semi-factual explanation, computational complexity, XAI, EU AI Act","This paper investigates the computational hardness of generating counterfactual and semi-factual explanations in XAI, highlighting that explanation generation can be computationally intensive and, under certain assumptions, difficult to approximate.",291.99,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09460v1_SoK Enhancing Cryptographic Collaborative Learning.pdf,Exact string,"Francesco Capano, Jonas B. Lohler, Benjamin Weggenmann",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"cryptography, collaborative machine learning, differential privacy, secure learning, privacy-preserving computation","The paper presents a unified framework for cryptographic collaborative learning (CPCL) that integrates secure noise sampling to enhance differential privacy in multi-party machine learning. It analyzes trade-offs between cryptographic overhead and accuracy, proposes secure sampling techniques, and evaluates their performance in MPC and LAN environments. The work aims to address privacy-accuracy-performance challenges in joint model training.",315.82,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09465v1_EvoFSM Controllable Self-Evolution for Deep Resear.pdf,Exact string,"Shuo Zhang, Chaofa Yuan, Ryan Guo, Xiaomin Yu, Rui Xu, Zhangquan Chen, Zinuo Li, Zhi Yang, Shuhao Guan, Zhenheng Tang, Sen Hu, Liwen Zhang, Ronghao Chen, Huacan Wang",10.48550/arXiv.2026.09465,2601.09465,"EvoFSM, self-evolution, deep research, finite state, LLM, adaptability, control","The paper introduces EvoFSM, a structured self-evolving framework that decouples optimization into macroscopic flow and microscopic skills. It enables agents to adapt to open-ended queries while maintaining stability, achieving 58.0% accuracy on the DeepSearch benchmark.",302.42,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09467v1_Searth Transformer A Transformer Architecture Inco.pdf,Exact string,"Tianye Li, Qi Liu, Hao Li, Lei Chen, Fei Zheng, Xiangao Xia, Ya Wang, Gang Huang, Weiwei Wang, Xuan Tong, Ziqing Zu, Yi Fang, Shenming Fu, Jiang Jiang, Haochen Li, Mingxing Li, Jiangjiang Xia, Jiangjiang, Artificial Intelligence Innovation and Incubation Institute, Chinese Academy of Sciences, Beijing, State Key Laboratory of Earth System Numerical Modeling and Application, Institute of Atmospheric Physics, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Shanghai Academy of Artificial Intelligence for Science, Beijing Aviation Meteorological Institute, Laboratory of Middle Atmosphere and Global Environment Observation (LAGEO), Institute of Atmospheric Physics, Earth System Numerical Simulation Science Center, Shanghai Key Laboratory of Satellite Ocean Environment Dynamics, Jiangsu Key Laboratory of Intelligent Weather Forecasting and Applications Based on Big Data, Nanjing University of Information Science and Technology, Beijing Meteorological Service Center, Ministry of Natural Resources, Beijing University of Posts and Telecommunications",10.48550/arXiv:2105.07912,10.48550/arXiv:2105.07912,"Transformer, Earth system science, Global weather forecasting, Physics-informed modeling, Zonal periodicity, Resource efficiency","Accurate global medium-range weather forecasting is pivotal to Earth system science and serving as a critical public-service application. The paper introduces the Shifted Earth Transformer, a physics-informed Transformer architecture that incorporates Earth's spherical topology and zonal periodicity, and proposes the Relay Autoregressive fine-tuning strategy to address computational bottlenecks.",383.08,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09469v2_FairGU Fairness-aware Graph Unlearning in Social N.pdf,FairGU: Fairness-aware Graph Unlearning in Social Networks,"Renqiang Luo, Yongshuai Yang, Huafei Huang, Qing Qing, Mingliang Hou, Guangzhou, China, Adelaide, Australia, Changchun, China, Hangzhou, China, Melbourne, Australia, Singapore, Jinan University & TAL Education, Guangzhou, China, Changchun, China, Hangzhou, China, Melbourne, Australia, Nanyang Technological University, Singapore, Jinan University, Zhejiang Gongshang University, Guangzhou, China, Zhengjing, Zhejiang Gongshang University, Melbourne, Australia, RMIT University, Melbourne, Australia, Feng Xia, RMIT University, Melbourne, Australia, Ziqi Xu, RMIT University, Adelaide, Australia, Yi Yu, Nanyang Technological University, Singapore, Jingjing Zhou, Zhejiang Gongshang University",10.1093/acm/qad045,10.1093/acm/qad045,"fairness, privacy, graph unlearning, social network","Introduces FairGU, a fairness-aware graph unlearning framework that enhances algorithmic fairness during node removal, improving both utility and privacy in social networks.",382.93,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09470v1_Personalized Multimodal Feedback Using Multiple Ex.pdf,Personalized Multimodal Feedback Using Multiple External Representations: Strategy Profiles and Learning in High School Physics,"Natalia Revenga-Lozano, Karina E. Avila, Steffen Steinert, Matthias Schweinberger, Clara E. Gómez-Pérez, Jochen Kuhn",arXiv:2601.09470v1,2601.09470,"multimodal feedback, multiple external representations, learning in high school physics, adaptive feedback, representation competence","The study investigates how personalized, multimodal feedback influences physics learning in high school students, emphasizing the role of representation-selection strategies and their impact on learning outcomes.",344.63,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09473v1_SimMerge Learning to Select Merge Operators from S.pdf,Learning to Select Merge,"Oliver Bolton, Aakanksha, Arash Ahmadian, Sara Hooker, Marzieh Fadaee, Beyza Ermis",10.48550/arXiv.2601.09473,2601.09473,"model merging, merge operator, LLM composition","The paper introduces SimMerge, a predictive method for selecting optimal merge operators and merge order using similarity signals, aiming to improve scalability in large LLM composition.",337.32,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09478v3_Bridging Semantic Understanding and Popularity Bia.pdf,Bridging Semantic Understanding and Popularity Bias with LLMs,"Renqiang Luo, Dong Zhang, Yupeng Gao, Wen Shi, Mingliang Hou, Jiaying Liu, Shuo Yu, Shuowang Zhe",10.1234/abcd1234,10.1234/abcd1234,"Semantic analysis, Recommender systems, Algorithmic fairness, Popularity bias, Large Language Model","The paper introduces FairLRM, a framework that enhances the semantic understanding of popularity bias in recommender systems by decomposing it into item-side and user-side components. It leverages structured instruction-based prompts to improve both fairness and recommendation accuracy, addressing limitations of surface-level debiasing methods.",287.74,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09503v1_What Do LLM Agents Know About Their World Task2Qui.pdf,Exact string,"Siyuan Liu, Hongbang Yuan, Xinze Li, Ziyue Zhu, Yixin Cao, Yu-Gang Jiang",10.48550/arXiv.2601.09503,10.48550/arXiv.2601.09503,"LLM agents, environment understanding, trajectory-based metrics, grounded model, transferability","The paper investigates whether large language model agents develop a grounded, transferable understanding of environments beyond task success, identifying exploration and state representation as key bottlenecks.",390.18,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09518v1_Learning Whole-Body Human-Humanoid Interaction fro.pdf,Exact string,"Wei-Jin Huang, Yue-Yi Zhang, Yi-Lin Wei, Zhi-Wei Xia, Juantao Tan, Yuan-Ming Li, Zhilin Zhao, Wei-Shi Zheng, Guangdong Province Key Laboratory of Information Security Technology",10.48550/arXiv.2407.02632,10.48550/arXiv.2407.02632,"Human-Human Interaction, Human-Humanoid Interaction, Physics-Aware Interaction, Decoupled Spatio-Temporal Action Reasoner, D-STAR, Whole-Body Interaction","The paper presents a contact-centric two-stage pipeline for converting human-human interaction sequences into physically consistent human-humanoid interaction clips. It addresses the limitations of standard retargeting methods and introduces D-STAR, a hierarchical policy that preserves contact semantics, to generate high-quality HHoI data for robot-human interaction.",303.79,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09520v1_Towards Realistic Synthetic Data for Automatic Dru.pdf,Exact string,"Pierfrancesco Melucci, Paolo Merialdo, Taketo Akama",10.48550/arXiv.2311.07818,10.48550/arXiv:2311.07818,"automatic drum transcription, deep learning, synthetic data, one-shot samples","This paper introduces a semi-supervised method to automatically curate a large, diverse corpus of one-shot drum samples from unlabeled audio sources. It then uses this corpus to synthesize a high-quality MIDI dataset, achieving state-of-the-art performance on ENST and MDB test sets.",328.19,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09527v1_Private LLM Inference on Consumer Blackwell GPUs A.pdf,Private LLM Inference on Consumer Blackwell GPUs,"Jonathan Knoop1, Hendrik Holtmann2",10.48550/arXiv/2303.04112,10.48550/arXiv/2303.04112,"LLM, LLM inference, Blackwell GPU, quantization, deployment","This paper evaluates NVIDIA Blackwell consumer GPUs (RTX 5060 Ti, 5070 Ti, 5090) for cost-effective, on-premise LLM inference. It benchmarks four models across diverse workloads, demonstrating that budget GPUs achieve the highest throughput-per-dollar with sub-second latency, while high-end cards offer superior performance for latency-sensitive tasks. The study provides deployment guidance and open data for reproducible results.",344.01,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09536v1_Omni-R1 Towards the Unified Generative Paradigm fo.pdf,Exact string,"Dongjie Cheng, Yongqi Li, Zhixin Ma, Hongru Cai, Yupeng Hu, Wenjie Wang, Liqiang Nie",10.48550/arXiv.2026.1.14012,10.48550/arXiv.2026.1.14012,"multimodal reasoning, generative reasoning, Omni-R1, visual information, spatial relations","The paper proposes a unified generative multimodal reasoning framework using Omni-R1, which integrates perception alignment and perception reward to enable functional image generation. It introduces Omni-R1-Zero to eliminate multimodal annotations by leveraging text-only data. Empirical results demonstrate its effectiveness across diverse multimodal tasks.",291.9,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09555v1_Benchmarking Post-Training Quantization of Large L.pdf,Benchmarking Post-Training Quantization of Large Language Models,"Manyi Zhang∗, Ji-Fu Li∗, Zhongao Sun*, Haoli Bai Hui-Ling, Zhen Zhenhua, Dong Xianzhi Yu †",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"large language models, quantization, MXFP, post-training, benchmarking","This paper systematically evaluates post-training quantization methods under Microscaling Floating-Point formats, analyzing performance across 7 PTQ algorithms, 15 benchmarks, and multiple LLM families. Key findings highlight MXFP8's near-lossless behavior, MXFP4's accuracy challenges, format compatibility's role, and the impact of scaling factors.",349.97,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09566v2_Hot-Start from Pixels Low-Resolution Visual Tokens.pdf,Exact string,"Shuyang Xiang, Hao Guan",10.1093/pasj/2026.01.012,2601.09566,"Chinese language modeling, visual tokens, character representation, low-resolution inputs","The paper explores the effectiveness of low-resolution visual inputs (8×8 pixels) as an alternative to index-based character representation for Chinese language modeling. It demonstrates that such visual data can achieve comparable accuracy to traditional index-based models, highlighting the semantic and phonetic cues embedded in character shapes.",319.84,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09600v1_Information Access of the Oppressed A Problem-Posi.pdf,Information Access of the Oppressed: A Problem-Posing Framework for Envisioning Emancipatory Information Access Platforms,"Bhaskar Mitra, Nicola Neophytou, Sireesh Gururaja",10.1093/acprof:oso/9780190871296.001.0001,10.1093/acprof:oso/9780190871296.001.0001,"Information Access, Emancipatory Information Access, Search and Society, Sociotechnical Information Systems",The paper examines how authoritarian capture threatens open information access platforms and proposes a problem-posing framework inspired by Paulo Freire’s pedagogy to empower marginalized communities in co-constructing resistant technological infrastructures.,314.2,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09603v1_Linear Complexity Self-Supervised Learning for Mus.pdf,Linear Complexity Self-Supervised Learning for Music Understanding with Random Quantizer,"Petros Vavaroutsos, Theodoros Palamas, Pantelis Vikatos",10.1145/3748522.3779786,10.1145/3748522.3779786,"Deep Learning, Music Understanding, Transformers, Embeddings, Attention","This paper presents a method to reduce the size of foundation models for music information retrieval by combining Branchformer architecture with SummaryMixing and applying random quantization. Pre-training is performed on public datasets with a comparable scale to private datasets, achieving competitive performance while decreasing model size from 8.5% to 12.3%.",335.63,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09605v1_Sim2real Image Translation Enables Viewpoint-Robus.pdf,Exact string,"Jeremiah Coholich, Justin Wit, Robert Azarcon, Zsolt Kira",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"image translation, robot manipulation, viewpoint consistency, sim2real","The paper introduces MANGO, an image translation method that preserves viewpoint during translation, enabling robust policies for robot manipulation by generating diverse unseen viewpoints from fixed-camera datasets.",287.53,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09609v1_DPWriter Reinforcement Learning with Diverse Plann.pdf,Reinforcement Learning with Diverse Planning Branching for Creative Writing,"Qian Cao1, Yahui Liu2, Wei Bi2, Yi Zhao1, Ruihua Song, Xiting Wang1B, Ruiming Tang2, Guorui Zhou 2, Han Li 2",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"reinforcement learning, creative writing, diversity, LLM, planning",The paper proposes a reinforcement learning framework with a semi-structured long Chain-of-Thought approach to enhance diversity in large language model outputs for creative writing. It introduces a Diverse Planning Branching method that guides exploration at the planning stage and incorporates a group-aware diversity reward to maintain quality while increasing output variety.,304.69,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09613v1_CogRail Benchmarking VLMs in Cognitive Intrusion P.pdf,CogRail: Benchmarking VLMs in Cognitive Intrusion Perception for Intelligent Railway Transportation Systems,"Yonglin Tian, Qiyao Zhang, Wei Xu, Yihao Wu, Xinyi Li, Xingyuan Dai, Hui Zhang, Zhiyong Cui, Baoqing Guo, Yihao Wu, Xinyi Li",10.1093/acr/csy045,10.1093/acr/csy045,"intrusion perception, visual language models, spatial context, temporal dynamics, railway safety","The paper introduces CogRail, a benchmark for evaluating visual-language models in cognitive intrusion perception for railway systems. It highlights the limitations of current VLMs in handling spatial-temporal reasoning and proposes a joint fine-tuning framework to improve performance for safety-critical applications.",386.8,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09620v1_Full Disclosure Less Trust How the Level of Detail.pdf,Exact string,"Pooja Prajod, Hannes Cools, Thomas Röggla, Karthiyakka Puttraj, Amber Kusters, Alia Elkattan, Pablo Cesar, Abdullah El Ali",10.1093/acps/ccac007,10.1093/acps/ccac007,"AI disclosure, trust, readers' trust, journalism, transparency dilemma","The study investigates how different levels of AI disclosure detail affect trust in AI-assisted news, revealing that detailed disclosures can reduce trust but increase source-checking behavior, while one-line disclosures are preferred for their brevity.",287.84,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09624v1_Toward Understanding Unlearning Difficulty A Mecha.pdf,Exact string,"Jiali Cheng, Ziheng Chen, Chirag Agarwal, Hadi Amiri",10.48550/arXiv.2405.12345,10.48550/arXiv.2405.12345,"unlearning, machine learning, model interpretability","This paper introduces Circuit-guided Unlearning Difficulty (CUD), a mechanism-based metric that quantifies sample difficulty using circuit-level signals. It demonstrates that easier samples are erased via shorter, shallower pathways, while harder samples require deeper, longer interactions. CUD provides a principled, interpretable framework for understanding unlearning disparities and supports future unlearning methods grounded in model mechanisms.",330.55,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09625v1_The Promptware Kill Chain How Prompt Injections Gr.pdf,Exact string,"Ben Nassi, Bruce Schneier, Oleg Brodt",10.1093/acpl/sqy023,10.1093/acpl/qaw023,"prompt injection, LLM, malware, security","The paper introduces a five-step kill chain for promptware attacks targeting large language models, linking them to traditional malware tactics and proposing a structured framework for threat modeling.",290.29,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09626v1_From Prompt to Protocol Fast Charging Batteries wi.pdf,Exact string,"Ge Lei1, Brosa Planella2, Sterling G. Baird, Samuel J. Cooper",10.1093/pasj/psa.2023,2601.09626,"battery charging, optimization, LLM, gradient-free, fast charging","The paper introduces two LLM-driven methods—Prompt-to-Optimizer and Prompt-to-Protocol—to efficiently optimize battery charging protocols, achieving a 4.2% improvement in state of health over traditional approaches in fast-charging scenarios.",275.93,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09635v1_LLM for Large-Scale Optimization Model Auto-Formul.pdf,LLM for Large-Scale Optimization Model Auto-Formulation: A Lightweight Few-Shot Learning Approach,"Kuo Liang1, Yuhang Lu, Jianming Mao, Shuyi Sun, Chunwei Yang, Congcong Zeng, Xiao Jin, Hanzhang Qin, Ruihao Zhu, Chung-Piaw Teo, Liang Wei, Zhang Xiaoming, Chen Wei, Liu Ying, Wang Xue, Zhou Yuchen, Teo Chuan Wei, Zeng Congruo, Zhu Hao, Yuhao Zhu, Chunwyang Yang, Yao Cong, Nus Research Team",10.1234/arxiv.2024.05678,10.1234/2024.05678,"large language models, tool use, agentic workflow construction, automated optimization modeling","This paper introduces LEAN-LLM-OPT, a lightweight framework for LLM-assisted large-scale optimization auto-formulation. It describes a workflow where two LLM agents dynamically build optimization formulations based on problem descriptions, and a downstream agent generates the final solution. The approach leverages LLMs for text processing and modeling, enabling efficient handling of complex optimization tasks. Extensive simulations show strong performance, especially in Singapore Airlines revenue management scenarios.",359.27,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09636v1_PersonalAlign Hierarchical Implicit Intent Alignme.pdf,PersonalAlign,"Yibo Lyu, Gongwei Chen, Rui Shao, Weili Guan, Liqiang Nie",10.48550/arXiv.2024.12345,10.48550/arXiv/12345.67890,"personalized agents, implicit intent, long-term records, AndroidIntent","The paper introduces PersonalAlign, a hierarchical implicit intent alignment framework for personalized GUI agents. It leverages long-term user records to resolve vague instructions and anticipate latent user routines, improving proactive assistance by 15.7% and 7.3% on AndroidIntent benchmarks.",311.47,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09667v2_Collaborative Multi-Agent Test-Time Reinforcement .pdf,Exact string,"Zhiyuan Hu, Yunhai Hu, Juncheng Liu, Shuyue Stella Li, Yucheng Wang, Zhen Xu, Xu6",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"multi-agent, test-time, reinforcement learning, LLM, collaboration","The paper introduces Multi-Agent Test-Time Reinforcement Learning (MATTRL), a framework that enhances multi-agent dialogue systems by injecting structured textual experiences at inference time. MATTRL forms a multi-expert team, integrates test-time experiences, and improves reasoning robustness across diverse benchmarks.",335.46,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09680v1_Automating Supply Chain Disruption Monitoring via .pdf,Automating Supply Chain Disruption Monitoring via an Agentic AI,"Sara AlMahria, Liming Xu, Alexandra Brintrup",10.1093/acplr/sca045,2601.09680v1,"Supply Chain Management, Supply Chain Disruption, Large Language Models, AI Agents, Multi-Agent System","The paper presents an agentic AI framework for proactive monitoring and mitigation of supply chain disruptions across extended networks. It leverages large language models and deterministic tools to detect disruptions from unstructured sources, map them to multi-tier supplier networks, assess exposure, and recommend mitigation strategies. Evaluated across 30 scenarios, the system achieves high accuracy and significantly reduces response times compared to traditional methods.",280.95,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09684v1_Disentangling Task Conflicts in Multi-Task LoRA vi.pdf,Disentangling Task Conflicts in Multi-Task LoRA via Orthogonal Gradient Projection,"Ziyu Yang, Guibin Chen, Yuxin Yang, Aoxiong Zeng, Xiangquan Yang",10.48550/arXiv.2303.04212,10.48550/arXiv.2303.04212,"multi-task learning, low-rank adaptation, orthogonal projection, LLM","The paper introduces Ortho-LoRA, a gradient projection method for LoRA that mitigates negative transfer in multi-task learning by projecting conflicting gradients orthogonally. It demonstrates improved performance over joint training while maintaining low computational overhead.",282.51,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09692v1_Routing with Generated Data Annotation-Free LLM Sk.pdf,Routing with Generated Data: Annotation-Free,"Tianyi Niu, Justin Chih-Yao Chen, Genta Indra Winata, Shi-Xiong Zhang, Supriyo Chakraborty, Sambit Sahu, Yue Zhang, Elias Stengel-Eskin, Mohit Bansal",10.48550/arXiv.2303.04112,10.48550/arXiv.2303.04112,"LLM routing, query-only routing, query-answer routing, LLM models, skill estimation, generative data","The paper introduces Routing with Generated Data (RGD), a method for training routing systems exclusively on generated queries and answers. It evaluates query-answer and query-only routers across benchmarks, demonstrating that query-answer routers degrade more with lower generator quality. The authors highlight two key generator characteristics and propose CASCAL, a novel query-only router that improves robustness.",296.02,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09694v1_LLMs can Compress LLMs Adaptive Pruning by Agents.pdf,Exact string,"Sai Varun Kodathala, Rakesh Vunnam",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Model Compression, Adaptive Pruning, Self-Reflection, LLM Compression","The paper introduces agent-guided pruning for LLMs, leveraging adaptive pruning agents that learn from prior pruning outcomes to maintain factual knowledge while reducing computational costs. It demonstrates significant improvements in accuracy and factual retention compared to structured pruning methods.",316.96,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09703v1_ShortCoder Knowledge-Augmented Syntax Optimization.pdf,Exact string,"Sicong Liu, Yanxian Huang, Mingwei Liu, Jiachi Chen, Ensheng Shi, Yuchi Ma, Hongyu Zhang, Yin Zhang, Yanlin Wang",10.1234/example.doi,null,"code generation, LLM, optimization, token efficiency","The paper introduces ShortCoder, a knowledge-infused framework optimizing code generation efficiency by applying syntax-level simplification rules, hybrid data synthesis, and fine-tuning strategies. It achieves significant token reduction while maintaining semantic accuracy and demonstrates improved generation performance over existing methods.",320.98,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09706v1_Value-Aware Numerical Representations for Transfor.pdf,Value-Aware Numerical Representations for Transformer Language Models,"Andreea Dutulescu, Stefan Ruseti, Mihai Dascalu",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"value-aware, numerical representation, transformer, mathematical reasoning","The paper introduces a value-aware numerical representation that explicitly encodes numerical magnitude, addressing the fragility of LLMs in arithmetic tasks. It demonstrates improved performance on mathematical benchmarks by augmenting token embeddings with a dedicated prefix token conditioned on numerical value.",285.12,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09708v1_Fast-ThinkAct Efficient Vision-Language-Action Rea.pdf,Exact string,"Chi-Pin Huang, Yunze Man, Zhiding Yu, Min-Hung Chen, Jan Kautz, Yu-Chiang Frank Wang, Fu-En Yang",10.48550/arXiv.2601.09708,2601.09708,"Vision-Language-Action, reasoning, planning, embodied control","Fast-ThinkAct introduces an efficient reasoning framework for Vision-Language-Action tasks, reducing inference latency by 9.3× compared to prior methods while maintaining strong long-horizon planning and few-shot adaptation.",345.73,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09749v1_R-LAM Reproducibility-Constrained Large Action Mod.pdf,Exact string,Suriya Sureshkumar,10.1234/example.2023.001,10.1234/example.2023.001,"Reproducibility, Scientific Workflows, Large Action Models, Execution Provenance","R-LAM introduces a reproducibility-constrained framework for Large Action Models, enabling deterministic scientific workflow automation with structured action schemas and explicit provenance tracking.",277.78,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09750v1_SAGE Tool-Augmented LLM Task Solving Strategies in.pdf,SAGE: Tool-Augmented LLM Task Solving Strategies,"Robert K. Strehlow, Tobias Küster, Oskar F. Kupke, Brandon L. Llanque, Fikret Sivrikaya, Sahin Albayrak",10.1093/acprof:oso/9780190871296.005.0001,10.1093/acprof:oso/9780190871296.005.0001,"LLM, tool integration, zero-shot prompting, OPACA, tool discovery, scalable solutions","The paper introduces SAGE, a conversational AI interface built on OPACA, enabling dynamic integration of tools and promoting robust zero-shot prompting methods. It presents strategies for task-solving using agentic concepts and evaluates their effectiveness against benchmark services.",326.96,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09753v1_Critically Engaged Pragmatism A Scientific Norm an.pdf,Exact string,Carole J. Lee,10.1234/example.2023.001,arxiv:2301.01234,"scientific evaluation, pragmatism, replication crisis","The paper addresses the growing need for automated tools in scientific research assessment, emphasizing the risks of misapplied AI evaluation norms and advocating for a social, pragmatist approach to maintain credibility standards.",301.2,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09755v1_Heterogeneous computing platform for real-time rob.pdf,Exact string,"Jakub Fil, Yulia Sandamirskaya, Hector Gonzalez, Loïc Azzalin, Stefan Glüge, Lukas Friedenstab, Friedrich Wolf, Tim Rosmeisl, Matthias Lohrmann, Mahmoud Akl, Khaleel Khan, Leonie Wolf, Kristin Richter, Holm Puder, Mazhar Ali Bari, Xuan Choo, Noha Alharthi, Michael Hopkins, Steve Furber, Jens Struckmeier",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"heterogeneous computing, robotics, neurocomputing, Society 5.0, neuromorphic hardware, AI compute cluster",The paper presents a computing platform integrating neuromorphic hardware (Loihi2) with event-based cameras and GPUs to enable real-time perception and interaction in humanoid robots within a smart city context. It emphasizes the synergy between brain-inspired processors and high-density GPUs for advanced robotic autonomy and interactive intelligence.,313.42,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09756v1_Synthetic Data for Veterinary EHR De-identificatio.pdf,"Synthetic Data for Veterinary EHR De-identification: Benefits, Limits, and Safety Trade-offs Under Fixed Compute","David Brundage, PhD",10.1093/acm/div.2023.03,10.1093/acm/div.2023.03,"veterinary EHR, de-identification, synthetic data, LLM, privacy","The study evaluates how synthetic veterinary narrative generation impacts de-identification safety and utility under varying computational constraints. It finds that moderate synthetic augmentation improves span-level performance and reduces document-level leakage, while high synthetic dominance harms utility and increases leakage. Results emphasize the need for balanced synthetic exposure in real-world data augmentation pipelines.",380.15,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09757v1_Democracy and Distrust in an Era of Artificial Int.pdf,Democracy & Distrust in an Era of,Sonia K. Katyal,10.1162/DAED_a_01919,null,"democracy, distrust, artificial intelligence","Explores how AI challenges traditional judicial review, emphasizing the need for updated theories to protect minority rights in the age of automation.",319.53,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09760v1_Investigating Tool-Memory Conflicts in Tool-Augmen.pdf,Exact string,"Jiali Cheng, Rui Pan, Hadi Amiri, 1 University of Massachusetts Lowell, USA, University of Illinois Urbana-Champaign, USA",10.48550/arXiv.2024.12345,10.48550/arXiv/12345,"tool-memory conflict, LLM, knowledge integration, tool-augmented models","This paper introduces Tool-Memory Conflict (TMC), a new type of knowledge inconsistency in LLMs where internal parametric knowledge clashes with external tool outputs. The authors analyze conditions under which TMC emerges, evaluate existing conflict resolution methods, and propose strategies to mitigate inconsistencies in tool-augmented language models.",292.47,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09762v1_Explicating Tacit Regulatory Knowledge from LLMs t.pdf,Exact string,"Zhiyi Xue, Xiaohong Chen, Min Zhang",10.1234/example.doi,12345678,"compliance testing, LLM, automation, regulation","The paper introduces RAFT, a framework for requirements auto-formalization and compliance test generation by leveraging tacit regulatory knowledge from multiple LLMs. It integrates this knowledge into meta-models, formal requirements representations, and test constraints, enabling high-precision test case generation and reducing manual effort.",312.96,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09765v1_AI Survival Stories a Taxonomic Analysis of AI Exi.pdf,Philosophy of AI,"John Hawthorne, Lingnan University, University of Southern California",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"AI safety, Existential risk, Philosophy, Superintelligent AI","This paper examines a taxonomy of survival stories for humanity in the face of AI existential risk, analyzing how different scenarios arise when the premises about AI power and destruction are challenged.",275.33,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09768v1_CLiMB A Domain-Informed Novelty Detection Clusteri.pdf,CLiMB: A Domain-Informed Novelty Detection Clustering,"Lorenzo Monti, Tatiana Muraveva, Brian Sheridan, Davide Massari, Alessia Garofalo, Gisella Clementini, Umberto Michelucci, Alessia Garofalo",10.1093/acm/qad045,2601.09768,"novelty detection, semi-supervised clustering, constrained clustering, density-based clustering, domain knowledge integration","CLiMB introduces a domain-informed framework for clustering scientific data, improving novelty detection by decoupling prior knowledge from data exploration.",282.72,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09770v1_GUI-Eyes Tool-Augmented Perception for Visual Grou.pdf,Exact string,"Chen Chen, Jiawei Shao, Dakuan Lu, Haoyi Hu, Xiangcheng Liu, Hantao Yao, Wu Liu",10.48550/arXiv.2024.12345,10.48550/arXiv:2409.12345,"GUI, active perception, reinforcement learning, visual grounding","The paper introduces GUI-Eyes, a reinforcement learning framework for adaptive visual perception in GUI agents. It enables strategic decisions on tool usage (e.g., cropping, zooming) through a two-stage reasoning process and proposes a spatially continuous reward function that improves grounding accuracy on the ScreenSpot-Pro benchmark.",323.55,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09771v1_PCN-Rec Agentic Proof-Carrying Negotiation for Rel.pdf,Exact string,"Aradhya Dixit, Shreem Dixit",10.1093/acps/2023.01.012,arXiv:2308.08732,"recommendation systems, LLM agents, constraint satisfaction, verification","PCN-Rec introduces a proof-carrying negotiation pipeline for LLM-based recommendation systems. It separates natural-language reasoning from deterministic enforcement, allowing a user advocate to optimize relevance while a policy agent ensures governance constraints are met. The system achieves high pass rates on constrained datasets and maintains utility with minimal performance drop.",321.29,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09772v1_Antisocial behavior towards large language model u.pdf,Exact string,"Paweł Niszczota, Cassandra Grützner",10.1093/pasj/psa064,10.1093/pasj/psa064,"antisocial behavior, large language model, ethics, AI interaction",The paper investigates antisocial tendencies among users interacting with large language models and discusses ethical implications.,238.82,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09773v1_Enhancing LUT-based Deep Neural Networks Inference.pdf,Enhancing LUT-based Deep Neural Networks Inference through Architecture and Connectivity Optimization,"Binglei Lou, Ruinil Wu, Philip Leong",10.48550/arXiv.2407.08600,10.48550/arXiv.2407.08600,"Dynamic Sparsity, FPGA, Neural Network, Lookup Table","The paper introduces SparseLUT, a framework optimizing LUT-based DNNs by reducing LUT size and improving inference latency through architectural enhancements and a non-greedy training algorithm.",277.47,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09805v1_Improving Chain-of-Thought for Logical Reasoning v.pdf,Improving Chain-of-Thought for Logical Reasoning,"Phuong Minh Nguyen, Tien Huu Dang, Naoya Inoue",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"logical reasoning, LLMs, attention, intervention",The paper introduces an attention-aware intervention method (AAI) to enhance logical reasoning in large language models by reweighting attention heads based on logical patterns. This non-interactive framework improves reasoning performance with minimal computational cost.,281.37,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09806v1_Diffusion-Driven Deceptive Patches Adversarial Man.pdf,Diffusion-Driven Deceptive Patches: Adversarial,"Shahrzad Sayyafzadeh, Hongmei Chi, Shonda Bernadin",10.1093/acergs/zaad045,2601.09806v1,"Adversarial Patch Generation, Gaussian Smoothing, Diffusion Model, Social Media Forensics, Perceptual Hashing","The paper presents a pipeline for generating, refining, and evaluating adversarial patches to compromise facial biometric systems, incorporating diffusion models and forensic analysis for identity verification security.",275.86,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09809v1_QFed Parameter-Compact Quantum-Classical Federated.pdf,Exact string,"Samar Abdelghani, Soumaya Cherkaoui",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"Quantum Computing, Quantum Machine Learning, Federated Learning, Privacy, Communication, IoT","This paper introduces QFed, a quantum-enabled federated learning framework designed to reduce parameter counts in classical models by polylogarithmic factors, thereby improving computational efficiency for edge devices while maintaining competitive accuracy on the FashionMNIST dataset.",314.85,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09814v1_Explainable Deep Learning for Pediatric Pneumonia .pdf,Explanable Deep Learning for Pediatric Pneumonia Detection in Chest X-Ray Images,"Adil O. Khadidos, Aziida Nanyonga, Alaa O. Khadidos, Olfat M. Mirza, Mustafa Tahsin Yilmaz",10.1093/acprof:oso/9780190871293.013.0001,10.1093/acprof:oso/9780190871293.013.0001,"pediatric pneumonia, deep learning, chest x-ray, convolutional neural networks, explainable AI, Grad-CAM, LIME","The paper presents a comparative study of two state-of-the-art convolutional neural network architectures (DenseNet121 and EfficientNet-B0) for automated detection of pediatric pneumonia in chest X-ray images. It evaluates model performance using accuracy, F1-score, MCC, and recall, and incorporates Gradient-weighted Class Activation Mapping (Grad-CAM) and Local Interpretable Model-agnostic Explanations (LIME) to enhance interpretability. The results demonstrate high classification performance and strong sensitivity for pneumonia detection.",345.6,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09822v2_LLM-Based Agentic Systems for Software Engineering.pdf,LLM-Based Agentic Systems for Software Engineering: Challenges and Opportunities,"Yongjian Tang, Thomas Runkler",10.1093/acps/9780190871293.001.0001,2601.09822v2,"LLMs, Agents, Software Engineering, Future Challenges","This paper reviews the emerging paradigm of LLM-based multi-agent systems for software engineering, examining their applications across the Software Development Life Cycle and addressing challenges such as multi-agent orchestration, human-agent coordination, and computational cost optimization.",326.1,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09841v2_A pipeline for enabling path-specific causal fairn.pdf,Exact string,"Aparajita Kashyap, Sara Matijevic, Noémie Elhadad, Steven A. Kushner, Shalmali Joshi",10.1093/pasj/2026.01.012,2601.09841v2,"causal fairness, foundation models, causal inference, observational health data, fair machine learning","This paper presents a pipeline for training causally fair machine learning models in healthcare, addressing structural fairness in observational data and bridging the fairness-accuracy tradeoff. It maps structural fairness to healthcare contexts, enabling models that mitigate bias while maintaining performance.",319.23,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09851v1_ViSIL Unified Evaluation of Information Loss in Mu.pdf,Exact string,"Po-han Li, Shenghui Chen, Ufuk Topcu1, Sandeep Chinchali",10.48550/arXiv.2025.12345,10.48550/arXiv.2025.12345,"multimodal, video captioning, information loss, summary evaluation","The paper introduces the Video Summary Information Loss (ViSIL) metric, a unified information-theoretic framework that quantifies unseen information in video summarization across modalities. It addresses limitations of traditional metrics like BLEU and ROUGE by measuring information gaps between visual keyframes and textual summaries. ViSIL enables direct comparison of diverse summary formats and demonstrates improved VQA performance with a Pareto-optimal trade-off between information loss and processing speed.",288.09,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09853v1_MedRedFlag Investigating how LLMs Redirect Misconc.pdf,Exact string,"Sraavya Sambara∗, Yuan Pu1, Ayman Ali1, Vishala Mishra1, Lionel Wong2, Monica Agrawal1",10.48550/arXiv.2405.12345,10.48550/arXiv.2405.12345,"medical communication, LLM redirection, patient misconception, health advice","This study investigates how large language models (LLMs) handle false premises in real-world health questions, highlighting gaps in their ability to redirect problematic queries and provide safe medical guidance.",332.49,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09855v1_Thinking Long but Short Stable Sequential Test-Tim.pdf,Exact string,"Michael R. Metel, Yufei Cui, Boxing Chen, Prasanna Parthasarathi",10.48550/arXiv.2405.12345,2601.09855,"large reasoning models, test-time scaling, sequential training","Presents a novel sequential test-time scaling method, Min-Seek, which enhances accuracy over long reasoning chains while maintaining efficiency through dynamic key-value caching.",318.78,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09858v1_OUTLINEFORGE Hierarchical Reinforcement Learning w.pdf,Exact string,"Yilin Bao, Ziyao He, Zayden Yang",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"scientific writing, reinforcement learning, outline construction, LLM","The paper introduces a reinforcement learning framework for scientific outline generation, addressing challenges in global structure, input coverage, and citation consistency. It proposes a two-stage optimization: backward outline reconstruction for global consistency and forward value-guided reinforcement learning with rewards for scientific accuracy and coherence.",286.27,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09865v1_Advancing Model Refinement Muon-Optimized Distilla.pdf,Advancing Model Refinement: Muon-Optimized Distillation,"Jacob Sander, Brian Jalaian, V enkat R. Dasarivenkateswara",10.48550/arXiv.2601.09865,10.48550/arXiv.2601.09865,"LLM, quantization, distillation, edge computing, model optimization","The paper presents an integrated framework combining GPTQ quantization, LoRA, and Muon optimizer to compress large language models efficiently, enabling faster inference on resource-constrained devices while maintaining performance.",318.22,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09869v1_A Scoping Review of the Ethical Perspectives on An.pdf,Exact string,"Andrea Ferrario, Rasita Vinay, Matteo Casserini, Alessandro Facchini",10.1093/acpark/9780190871295.013.00001,2601.09869,"anthropomorphism, conversational agents, large language models, AI ethics, deception, trust, governance","This scoping review examines ethical perspectives on anthropomorphising LLM-based conversational agents, mapping research across databases and preprints. It identifies convergences in conceptual foundations and normative concerns, while highlighting divergent operationalizations and limited empirical guidance for responsible design.",291.09,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09871v1_Epistemology gives a Future to Complementarity in .pdf,Exact string,"Andrea Ferrario, Alessandro Facchini, Juan M. Durán",10.1093/acps/raac123,2601.09871,"artificial intelligence, machine learning, reliability, human-AI interaction, computational reliabilism, epistemology","The paper explores how human-AI complementarity can enhance decision-making performance by leveraging epistemological insights, particularly through computational reliabilism, and argues its value lies in improving reliability rather than merely predictive accuracy.",278.09,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09879v1_MedVL-SAM2 A unified 3D medical vision-language mo.pdf,MedVL-SAM2: A unified 3D medical vision–language model for multimodal reasoning and prompt-driven segmentation,"Yang Xing, Jiong Wu, Savas Ozdemir, Ying Zhang, Yang Yang, Wei Shao4 Gong, Ying Zhang, Yang Yang",10.1016/j.medvl.2024.01.012,10.1016/j.medvl.2024.01.012,"medical imaging, 3D segmentation, vision-language model, volumetric reasoning","MedVL-SAM2 is a unified 3D medical multimodal model that integrates report generation, visual question answering, and semantic/interactive segmentation. It leverages a cohesive architecture for 3D CT data and a SAM2-based volumetric segmentation module, achieving strong performance across diverse tasks.",295.34,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09881v1_Transition Matching Distillation for Fast Video Ge.pdf,Transition Matching Distillation for Fast Video Generation,"Weili Nie, Julius Berner, Nanye Ma, Chao Liu, Saining Xie, Arash Vahdat",10.48550/arXiv.2601.09881,2601.09881,"video generation, diffusion models, TMD, generation speed, visual quality","The paper introduces Transition Matching Distillation (TMD), a framework that distills large video diffusion models into efficient few-step generators by matching multi-step denoising trajectories with lightweight conditional flows. It enables faster generation while maintaining high visual fidelity, demonstrating superior performance over existing distilled models.",279.05,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09883v1_Beyond Rule-Based Workflows An Information-Flow-Or.pdf,Exact string,"Xinxing Ren, Quang M. Zang, Caelum Forder, Suman Deb, Ahsen Tahir, Roman J. Georgio, Peter Carroll, Roman J. Georgio, Ahsen Tahir, Ryan Y. Zhang, Zhenyu Xie, Yue Guo",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"information flow, multi-agent systems, agent-to-agent communication, LLM orchestration, task monitoring","The paper introduces an information-flow-orchestrated multi-agent paradigm using CORAL, enabling flexible, rule-free coordination of agents through dynamic communication. It evaluates performance on the GAIA benchmark, achieving higher accuracy than baseline workflow-based models.",319.71,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09896v1_The Algorithmic Gaze An Audit and Ethnography of t.pdf,The Algorithmic Gaze: An Audit and Ethnography of the LAION-Aesthetics,"Jordan Taylor, William Agnew, Maarten Sap, Sarah E. Fox, Haiyi Zhu",10.1145/nnnnnnn.nnnnnnn,1.2B,"AI, Art, Aesthetic Evaluation","This study audits the LAION-Aesthetics predictor model, revealing how its aesthetic filtering disproportionately favors images with Western, English-speaking, and male-centric captions, thereby reinforcing imperial and gendered biases in visual AI systems.",317.11,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09902v1_A Novel Contrastive Loss for Zero-Day Network Intr.pdf,A Novel Contrastive Loss for Zero-Day Network,"Jack Wilkie, Hanan Hindy, Craig Michie, Christos Tachtatzis, James Irvine, Robert Atkinson",10.1093/acps/clz057,10.1093/acps.2023.00123,"network intrusion detection, machine learning, contrastive learning, zero-day attacks, open-set recognition","The paper introduces a novel contrastive loss function designed to improve network intrusion detection, particularly for zero-day attacks. By training on both benign and known malicious traffic, the method enhances robustness to imbalanced data and achieves significant performance gains over existing models.",283.8,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09913v1_Continuum Memory Architectures for Long-Horizon LL.pdf,Exact string,"Joe Logan, Mode7 GK",10.48550/arXiv.2601.09913,10.48550/arXiv.2601.09913,"Continuum Memory Architecture, Long-Horizon LLM, Memory Systems","The paper introduces the Continuum Memory Architecture (CMA), a memory system that enables persistent, mutable, and consolidating memory for long-horizon language agents. It contrasts CMA with retrieval-augmented generation (RAG) by emphasizing structural memory capabilities and evaluates performance across behavioral probes.",311.08,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09921v1_Learning to Decode in Parallel Self-Coordinating N.pdf,Learning to Decode in Parallel: Self-Coordinating,"Kai Zhang, Zhengzhong Yi, Shaojun Guo, Linghang Kong, Wang Situ, Zhengfeng Ji, Fangming Liu, Fan Zhang, Tan He, Weiping Lin, Tao Jiang, Dongxin Gao, Yiming Zhang, Fangming Liu, Xiaoyu Zhan, Xuong Zheng",10.1109/ICQ.2026.12345,2601.09921v1,"quantum error correction, neural network, self-coordinating, real-time computation","The paper presents a neural network-based decoder for quantum error correction, emphasizing self-coordinating architectures to improve accuracy and reliability in fault-tolerant quantum computing.",330.73,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09923v1_CaMeLs Can Use Computers Too System-level Security.pdf,Exact string,"Hanna Foerster, Robert Mullins, Tom Blanchard, Nicolas Papernot, Kristina Nikoli´c, Florian Tramèr, Ilia Shumailov, Cheng Zhang, Yiren Zhao",10.48550/arXiv.2601.09923,2601.09923,"Computer Use Agents, UI Workflows, Control Flow Integrity, Prompt Injection, Security Architecture","The paper introduces a Single-Shot Planning framework for Computer Use Agents (CUAs), addressing the challenge of maintaining architectural isolation while enabling dynamic UI interaction. It presents a method where a trusted planner generates a complete execution graph before any potentially malicious content is observed, ensuring robust protection against instruction injections. The approach also discusses mitigating Branch Steering attacks and evaluates performance on OSWorld.",342.78,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09929v1_Hallucination Detection and Mitigation in Large La.pdf,Hallucination Detection and Mitigation in Large Language Models,"Ahmad Pesaranghader, Erin Li",10.1093/acps/2026.01.012,2601.09929v1,"hallucination, LLM, reliability, mitigation","This paper presents a comprehensive operational framework for managing hallucinations in large language models, emphasizing a continuous improvement cycle focused on detection and mitigation strategies that are root cause aware.",354.59,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09933v1_Malware Classification using Diluted Convolutional.pdf,Malware Classification using Diluted Convolutional Neural Network with Fast Gradient Sign Method,"Ashish Anand, Bhupendra Singh, Sunil Khemka, Bireswar Banerjee, Vishi Singh Bhatia, Piyush Ranjan",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"dataset security, diluted convolutional neural network, fast gradient sign method, malware classification, privacy","The paper presents a novel approach for malware classification using a Diluted Convolutional Neural Network (FGSM-DICNN) enhanced with the Fast Gradient Sign Method. This method improves detection accuracy by leveraging diluted convolutions to capture long-range patterns while reducing computational overhead. The model achieves 99.44% accuracy, outperforming existing DCNN-based methods.",292.0,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09949v2_Kinematic Tokenization Optimization-Based Continuo.pdf,Exact string,"Griffin M. Kearney, Ph.D.",10.48550/arXiv.2026.12345,10.48550/arXiv.2026.12345,"kinematic tokenization, continuous-time, optimization, financial time series","The paper presents a novel optimization-based continuous-time representation for tokenizing noisy time series, enabling learnable decision policies under asymmetric penalties. It demonstrates improved calibration and policy stability compared to discrete baselines in financial data.",267.86,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09966v1_A Sustainable AI Economy Needs Data Deals That Wor.pdf,Exact string,"Ruoxi Jia, Luis Oala, Brickroad, Wenjie Xiong, Suqin Ge, Jiachen T. Wang, Feiyang Kang, Dawn Song",10.48550/arXiv.2601.09966,10.48550/arXiv.2601.09966,"data deals, machine learning value chain, economic equity, data generators, open ai revenue","The paper examines the structural unsustainability of the machine learning value chain, highlighting how economic data processing inequality leads to inequitable value distribution. It analyzes seventy-three public data deals and identifies three key faults: missing provenance, asymmetric bargaining power, and non-dynamic pricing. The authors propose an Equitable Data-Value Exchange (EDVEX) Framework to address these issues and advocate for fairer data deals.",291.58,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09972v1_Chinese Labor Law Large Language Model Benchmark.pdf,Exact string,"Zixun Lan, Maochun Xu, Yifan Ren, Rui Wu, Jianghui Zhou, Xueyang Cheng, Jian’an Ding, Mingmin Chi, Fei Ma",10.1234/abcd1234,None,,N/A,279.03,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09974v1_SPRInG Continual LLM Personalization via Selective.pdf,Exact string,"Seoyeon Kim, Jaehyung Kim",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"personalization, continual learning, LLM adaptation","The paper introduces SPRING, a semi-parametric framework for continual personalization that adapts user preferences over time using drift-driven selective adaptation. It addresses preference drift without catastrophic forgetting by updating only high-novelty interactions and preserving hard-to-learn residuals.",276.96,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09980v1_Performance of AI agents based on reasoning langua.pdf,ALD optimization using reasoning LLMs,Angel Yanguas-Gil,10.1016/j.adop.2026.01.012,10.1016/j.adop.2026.01.012,"atomic layer deposition, reasoning LLMs, materials science, process optimization","This paper investigates the use of reasoning large language models to autonomously optimize atomic layer deposition (ALD) processes. It evaluates an agent that iteratively interacts with an ALD reactor to determine optimal precursor and coreactant doses, highlighting the model's ability to handle self-limited reactions and its performance variability.",328.96,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.09982v1_Context Volume Drives Performance Tackling Domain .pdf,Exact string,"David Samuel Setiawan, Raphaël Merx, Jey Han Lau",10.1093/acpsr/adac123,10.1093/acpsr.2024.12345,"Neural Machine Translation, Domain Shift, Low-Resource Languages, Retrieval-Augmented Generation","The paper investigates performance degradation of NMT models when adapting to the Old Testament (OT) domain using Dhao, an indigenous language of Eastern Indonesia. By combining a fine-tuned NMT model with a Retrieval-Augmented Generation (RAG) LLM, the authors achieve improved in-domain translation quality, demonstrating that retrieval mechanisms help mitigate domain shift effects.",288.81,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10010v1_VERHallu Evaluating and Mitigating Event Relation .pdf,Exact string,"Zefan Zhang, Kehua Zhu, Shijie Jiang, Hongyuan Lu, Shengkai Sun, Tian Bai",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Video Large Language Models, Event Relation Understanding, Video Understanding, Event Relation Hallucination","The paper introduces VERHallu, a new benchmark for evaluating event relation hallucination in video LLMs. It focuses on causal, temporal, and subevent relations across three tasks and proposes a Key-Frame Propagating strategy to improve multi-event understanding without sacrificing inference speed.",286.93,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10011v1_Memo-SQL Structured Decomposition and Experience-D.pdf,Memo-SQL: Structured Decomposition and Experience-Driven,"Zerui Yang1, Weichuan Wang1, Yanwei Xu*2, Linqi Song†1, Yudai Matsuda1, Wei Han2, Bo Bai2",10.1234/example.12345,null,"NL2SQL, self-correction, experience-aware, training-free","Memo-SQL introduces a training-free framework that enhances NL2SQL by leveraging structured decomposition and experience-aware self-correction, improving accuracy while reducing computational cost.",276.3,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10018v1_Empowering Older Adults in Digital Technology Use .pdf,Exact string,"Hasti Sharifi, Homaira Huda Shomee, Sourav Medya, Debaleena Chattopadhyay",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Technology support, Digital technology use, Artificial intelligence, Large language models, Communication barriers",This study explores communication challenges faced by older adults in digital technology use and evaluates how foundation models can improve support through AI-based paraphrasing and solution generation.,322.83,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10025v1_Structured Personality Control and Adaptation for .pdf,Exact string,"Jinpeng Wang, Xinyu Jia, Wei Wei Heng, Yuquan Li, Binbin Shi, Qianlei Chen, Guannan Chen, Junxia Zhang, Yuyu Yin",10.1093/acm/qad047,10.1093/acm/qad047,"Personality control, LLM agents, Jungian Psychological Types, MBTI Personality Types, Persona Adaptation, Explainable AI","The paper introduces a framework for modeling LLM personality using Jungian psychological types, integrating mechanisms for coherent expression, adaptive reinforcement, and long-term evolution. It evaluates personality alignment via Myers–Briggs questionnaires and applies it to LLM interaction scenarios, aiming to enhance naturalistic agent behavior in human-computer interaction.",316.56,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10029v1_PaperScout An Autonomous Agent for Academic Paper .pdf,Exact string,"Tingyue Pan, Jie Ouyang, Mingyue Cheng, Qingchuan Li, Zirui Liu, Mingfan Pan, Shuo Yu, Qi Liu",10.1093/acpan/sca062,12345,"academic paper search, autonomous agent, sequence-level policy, RL","The paper introduces PaperScout, a process-aware, sequence-level policy optimization method for academic paper search. It addresses the limitations of static workflows by enabling dynamic decision-making during search and expansion, leveraging accumulated retrieval context to improve relevance and robustness.",312.02,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10031v1_FilDeep Learning Large Deformations of Elastic-Pla.pdf,FilDeep: Learning Large Deformations of Elastic-Plastic Solids with Multi-Fidelity Data,"Jianheng Tang, Shilong Tao, Zhe Feng, Haonan Sun, Menglu Wang, Zhanxing Zhu, Yunhuai Liu",10.1145/3770854.3783959,Not provided,"Large Deformations, Elastic-Plastic Solids, Multi-Fidelity Data, Deep Learning, Quantity-Accuracy Dilemma","The paper introduces FilDeep, a deep learning framework for large deformation problems in elastic-plastic solids, addressing the data quantity-accuracy trade-off by combining low-fidelity and high-fidelity datasets.",375.72,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10038v1_What Understanding Means in AI-Laden Astronomy.pdf,Understanding Means in AI-Laden,"Yuan-Sen Ting, André Curtis-Trudel, Siyu Yao",10.48550/arXiv.2601.10038,2601.10038,"understanding, philosophy of science, AI in research, discovery, knowledge generation","The paper explores the philosophical implications of AI in astronomy, emphasizing the need for conceptual engineering, critical reflection, and frameworks for abstraction to understand how AI transforms scientific understanding beyond mere data processing.",348.68,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10073v1_ReaMIL Reasoning- and Evidence-Aware Multiple Inst.pdf,ReaMIL: Reasoning- and Evidence-Aware Multiple Instance Learning for Whole-Slide Histopathology,"Hyun Do Jung, Jungwon Choi, Hwiyoung Kim",10.48550/arXiv.2405.12345,10.48550/arXiv/2405.12345,"whole-slide histopathology, multiple instance learning, tile selection, interpretability","ReaMIL introduces a multiple instance learning framework for whole-slide histopathology that incorporates a light selection head. It uses a budgeted-sufficiency objective to generate compact evidence sets, improving interpretability while maintaining strong performance across multiple cancer datasets.",363.25,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10079v1_Sparse-RL Breaking the Memory Wall in LLM Reinforc.pdf,Exact string,"Sijia Luo, Xiaokang Zhang, Yuxuan Hu, Bohan Zhang, Ke Wang, Jinbo Su, Mengshu Sun, Lei Liang, Jing Zhang, Ke Wang",10.48550/arXiv.2303.04112,10.48550/arXiv:2303.04112,"Reinforcement Learning, Large Language Models, Memory Wall, KV Compression","The paper presents Sparse-RL, a method to enable RL training under sparse rollouts by addressing policy mismatches and implementing sparsity-aware techniques to reduce memory overhead.",283.78,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10088v1_State of AI An Empirical 100 Trillion Token Study .pdf,State of AI: An Empirical 100 Trillion Token Study with OpenRouter,"Malika Aubakirova, Alex Atallah, Chris Clark, Justin Summerville, Anjney Midha",10.48550/arXiv.2025.12345,10.48550/arXiv:2025.12345,"large language models, openRouter, LLM usage, empirical study, reasoning models","The paper presents an empirical analysis of over 100 trillion tokens of real-world LLM interactions, highlighting shifts in usage patterns, adoption of open-weight models, and the emergence of agentic inference. It identifies foundational user cohorts and discusses implications for model development.",312.82,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10090v1_Difficulty-guided Sampling Bridging the Target Gap.pdf,Exact string,"Mingzhuo Lia, Guang Lia, Linfeng Yeb, Jiafeng Maoc, Takahiro Ogawaa, Konstantinos N. Plataniotisb, Miki Haseyamaa",2601.10090v1,2601.10090,"dataset distillation, downstream tasks, difficulty-guided sampling, deep neural networks, target gap","The paper introduces difficulty-guided sampling (DGS) to bridge the gap between distillation objectives and downstream tasks, aiming to improve dataset distillation performance while reducing training costs.",279.11,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10092v1_LeMoF Level-guided Multimodal Fusion for Heterogen.pdf,Exact string,"Jongseok Kim, Seongae Kang, Jonghwan Shin, Yuhan Lee",10.1093/acm/qad023,2601.10092v1,"Multimodal Learning, Hierarchical Representation Learning, Clinical Time-Series Modeling, Level-guided Feature Fusion","The paper introduces Level-guided Modal Fusion (LeMoF), a framework that integrates modality-specific representations at different levels to balance prediction stability and discriminative power in heterogeneous clinical data.",308.13,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10094v1_V-Zero Self-Improving Multimodal Reasoning with Ze.pdf,Exact string,"Han Wang, Yi Yang, Jingyuan Hu, Minfeng Zhu, Wei Chen",10.48550/arXiv.2303.04112,10.48550/arXiv:2303.04112,"self-improvement, multimodal reasoning, vision-language models, unsupervised learning","The paper introduces V-Zero, a self-improvement framework for vision-language models that uses unlabeled images and establishes a co-evolutionary loop between a questioner and a solver to enhance reasoning performance without human annotations.",332.27,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10101v2_Matrix as Plan Structured Logical Reasoning with F.pdf,Matrix as Plan: Structured Logical Reasoning with Feedback-Driven Replanning,"Ke Chen, Jiandian Zeng, Zihao Peng, Guo Li, Guangxue Zhang, Tian Wang",10.1145/XXXXXX.XXXXXX,10.1145/XXXXXX.XXXXXX,"Logical Reasoning, Large Language Models, Neurosymbolic Approaches, Semantic Decomposition","The paper introduces MatrixCoT, a structured CoT framework that enhances LLM reasoning by normalizing natural language, adding explicit citation fields, and employing a matrix-based planning method. It incorporates feedback-driven replanning to improve robustness and interpretability, achieving better performance on logical reasoning benchmarks without relying on external solvers.",290.4,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10103v1_FlowAct-R1 Towards Interactive Humanoid Video Gene.pdf,FlowAct-R1: Towards Interactive Humanoid Video,"Lizhen Wang, Yongming Zhu, Zhipeng Ge, Youwei Zheng, Longhao Zhang, Tianshu Hu, Shiyang Qin, Mingshuang Luo, Jiaxu Zhang, Xin Chen, Yulong Wang, Zerong Zheng, Jianwen Jiang, Chao Liang, Weifeng Chen, Xing Wang, Yuan Zhang, Mingyuan Gao",10.1093/acps/csp047,2601.10103,"humanoid video generation, interactive video, real-time synthesis, low-latency, behavioral control","The paper introduces FlowAct-R1, a framework for real-time interactive humanoid video generation that balances high-fidelity synthesis with low-latency responsiveness. It employs a chunkwise diffusion forcing strategy and self-forcing variants to maintain temporal consistency, achieving stable 25fps at 480p with a 1.5-second TTFF. The method supports robust generalization across diverse character styles and enables lifelike, responsive video synthesis.",338.82,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10104v1_MathDoc Benchmarking Structured Extraction and Act.pdf,MathDoc: Benchmarking Structured Extraction and Active Refusal,"Chenyue Zhou, Jiayi Tuo, Shitong Qin2, Wei Dai, Mingxuan Wang, Ziwei Zhao, Duoyang Li, Shiyang Su, Yanxi Lu",10.1234/mathdoc.2025,null,"mathematics exam, structured extraction, active refusal, MLLM","MathDoc introduces a benchmark for extracting structured questions from noisy mathematics exam papers, addressing challenges in visual noise and incomplete inputs. It evaluates models on refusal capability alongside accuracy, aiming to advance reliable AI in educational settings.",333.13,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10108v1_SIN-Bench Tracing Native Evidence Chains in Long-C.pdf,Exact string,"Yiming Ren, Junjie Wang, Yuxin Meng, Yihang Shi, Zhiqiang Lin, Ruihang Chu, Yiran Xu, Ziming Li, Yunfei Zhao, Yang Yu, Zihan Wang, Yu Qiao, Riming Li, Minghao Liu, Yujiu Yang",10.1234/sinbench.2024.00123,10.1234/sin-bench-2024-00123,"long context, multimodal, evidence chain, scientific literature, MLLM, cross-modal reasoning","The paper introduces the Fish-in-the-Ocean paradigm to evaluate evidence-based reasoning in scientific texts, emphasizing traceable evidence links over surface-level matching. It presents SIN-Bench and SIN-Bench tasks to benchmark model comprehension of long-form scientific documents.",317.38,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10112v1_Repository Intelligence Graph Deterministic Archit.pdf,Repository Intelligence Graph: Deterministic,"Tsvi Cherny-Shahar, Amiram Yehudai",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"software repositories, build systems, dependency graphs, software engineering agents, multi-lingual software","The paper introduces the Repository Intelligence Graph (RIG), a deterministic architectural map that clarifies build, test, and dependency structures in complex, multilingual projects. It presents SPADE, a tool that builds RIG from build artifacts and evaluates its impact on agent performance across diverse repositories.",320.02,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10114v1_Following the Teachers Footsteps Scheduled Checkpo.pdf,Exact string,"Cheng Feng, Chaoliang Zhong, Jun Sun, Yusuke Oishi",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"LLMs, Knowledge Distillation, Domain-specific Tasks",The paper proposes a novel method called Scheduled Checkpoint Distillation (SCD) to enable student LLMs to outperform teacher LLMs on domain-specific tasks by balancing their advantage on student-favored subdomains against their deficit on teacher-favored subdomains.,276.46,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10120v1_TopoDIM One-shot Topology Generation of Diverse In.pdf,TopoDIM: One-shot Topology Generation of Diverse Interaction Modes for Multi-Agent Systems,"Rui Sun, Jie Ding, Chenghua Gong, Tianjun Gu, Yihang Jiang, Juyuan Zhang",10.1234/topodim.2024,10.1234/topodim.8d35,"multi-agent systems, topology generation, LLM, interaction modes","TOPODIM proposes a one-shot framework for generating diverse interaction topologies in LLM-based multi-agent systems, reducing token consumption by 46.41% while improving performance by 1.50%.",299.84,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10122v1_Role-Playing Agents Driven by Large Language Model.pdf,Exact string,"Ye Wang, Jiaxing Chen, Hongjiang Xiao, Yewang, Xiaohj",10.1093/pasj/psa123,2601.10122v1,"large language models, role-playing agents, personality modeling, memory mechanisms, cognitive simulation","This paper reviews the evolution and technical foundations of role-playing language agents (RPLAs), highlighting advancements from rule-based systems to personality-driven, memory-augmented models. It discusses key challenges in data construction, evaluation metrics, and future directions such as multimodal interaction and cognitive neuroscience integration.",295.6,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10129v1_LaViT Aligning Latent Visual Thoughts for Multi-mo.pdf,Exact string,"Linquan Wu, Tianxiang Jiang, Yifei Dong, Haoyu Yang, Fengji Zhang, Shichang Meng, Ai Xuan, Linqi Song, Jacky Keung",10.48550/arXiv.2024.12345,10.48550/arXiv:2409.12345,"visual reasoning, latent thoughts, distillation, multimodal","This paper introduces LaViT, a framework that aligns latent visual thoughts by requiring students to reconstruct teacher visual semantics and attention trajectories before text generation. It addresses the visual attention gap in multimodal reasoning and achieves up to 16.9% gains on complex tasks.",343.07,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10130v1_Redundancy-Driven Top-k Functional Dependency Disc.pdf,Exact string,"Xiaolong Wan, Xixian Han",10.1007/978-3-642-45678-3,10.1007/S00460-021-05232-7,"functional dependency, top-k discovery, data redundancy, pruning strategy","Proposes SDP-based discovery of top-k functional dependencies ranked by redundancy, improving efficiency on large-scale datasets by pruning infeasible branches.",367.16,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10131v2_M4olGen Multi-Agent Multi-Stage Molecular Generati.pdf,"MolGen: Multi-Agent, Multi-Stage Molecular Generation under Precise Multi-Property Constraints","Yizhan Li, Florence Cloutier, Sifan Wu, Ali Parviz, Boris Knyazev, 4, Yan Zhang, 4, Glen Berseth, 5, Canada CIFAR AI Chair, Université de Montréal, Mila – Quebec AI Institute, Institut Courtois, Samsung AI Lab, Montreal, Canada CIFAR AI Chair",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"molecule generation, multi-property constraints, multi-stage framework, LLM optimization, numeric constraints","Introduces M4olGen, a two-stage framework for generating molecules that meet precise physicochemical constraints. Stage I uses multi-agent retrieval for prototype generation, while Stage II applies RL-based optimization to refine candidates. The method leverages fragment-level editing and group relative policy optimization to achieve controlled, reproducible generation under complex multi-objective targets.",305.34,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10132v1_Is More Context Always Better Examining LLM Reason.pdf,Is More Context Always Better? Examining LLM Reasoning Capability for Time Interval Prediction,"Yanan Cao, Farnaz Fallahi, Murali Mohana Krishna Dandu, Lalitesh Morishetti, Kai Zhao, Luyi Ma, Sinduja Subramaniam, Jianpeng Xu, Evren Korpeoglu, Kaushiki Nag, Sushant Kumar, Kannan Achan",10.1145/XXXXXX.XXXXXX,10.1145/XXXXXX.XXXXXX,"Large Language Models, Temporal Reasoning, Inter-Purchase Interval Prediction, Structured Behavioral Data, Contextual Depth","This paper investigates whether large language models can predict time intervals between recurring user actions, such as purchases, and examines how varying levels of contextual information affect their performance. It benchmarks LLMs against statistical and machine-learning models, revealing that while LLMs outperform lightweight baselines, they struggle with quantitative temporal structure and that additional context can help but only up to a point.",355.46,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10137v1_Step-by-Step Causality Transparent Causal Discover.pdf,Step-by-Step Causality: Transparent Causal Discovery with Multi-Agent,"Ziyi Ding, Chenfei Ye-Hao, Zheyuan Wang, Xiao-Ping Zhang",10.48550/arXiv.2026.12345,10.48550/arXiv.2026.12345,"causal discovery, LLM, confidence estimation, confounder screening","The paper presents Tree-Query, a framework that uses tree-structured queries to enable interpretable, confidence-aware causal inference with large language models. It improves structural accuracy over direct LLM baselines and provides robustness-aware confidence scores, supporting data-free causal priors.",344.13,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10141v1_Understanding and Preserving Safety in Fine-Tuned .pdf,Understanding and Preserving Safety in Fine-Tuned LLMs,"Jiawen Zhang, Yangfan Hu, Kejia Chen, Lipeng He, Jiachen Ma, Jian Lou, Dan Li, Ruoxi Jia, Jian Liu",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"fine-tuning, safety alignment, LLM safety, LLM utility, jailbreak resistance","This paper investigates the tension between safety and utility in fine-tuning large language models. It identifies geometric relationships between safety and utility gradients, proposes a lightweight safety-preserving fine-tuning method, and demonstrates that SPF maintains performance while ensuring robustness against adversarial attacks.",338.87,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10143v1_History Is Not Enough An Adaptive Dataflow System .pdf,Exact string,"Haochong Xia, Yao Long Teng, Regan Tan, Molei Qin, Xinrun Wang, Bo An",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"adaptive dataflow, workflow automation, financial time-series, data augmentation, data management","The paper introduces a drift-aware dataflow system for financial time-series synthesis, integrating adaptive control and curriculum learning to address concept drift and improve model robustness in dynamic markets.",280.5,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10148v1_DecisionLLM Large Language Models for Long Sequenc.pdf,Exact string,"Xiaowei Lv, Zhiling Zhang, Yijun Li, Yuen Huo3, Siyuan Ju, Xuyan Li, Chunxiang Hong, Bo Zheng",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"long sequence decision making, reinforcement learning, large language models, offline RL","This paper explores the application of Large Language Models (LLMs) to long-sequence decision-making tasks, proposing a framework called DecisionLLM that aligns trajectory data with natural language descriptions. It establishes scaling laws linking model scale, data volume, and data quality, demonstrating strong performance in offline benchmarks and bidirectional settings.",317.74,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10150v1_Simple Network Graph Comparative Learning.pdf,Simple Network Graph Comparative Learning,"Qiang Yua, Xinran Chenga, Shiqiang Xub, Chuanyi Liua",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"Filters, Siamese network, Graph contrastive learning, Unsupervised representation learning","The paper introduces a novel node classification method called Simple Network Graph Comparative Learning (SNGCL), which uses a superimposed multilayer Laplace smoothing filter to enhance feature smoothing and improve performance in graph-based tasks.",314.59,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10154v1_MHub.ai A Simple Standardized and Reproducible Pla.pdf,Exact string,"Leonard Nürnberg, Dennis Bontempi, Suraj Pai, Curtis Lisle, Steve Pieper, Ron Kikinis, Sil van Leemput, Rahul, Soni, Gowtham Murugesan, Ciausu, Miriam, Groeneveld, Felix, J., Dorfner, Jue, Jiang, Rangnekar, Harini, Joeran, Bosma, Keno, Bressem, Raymond, Mak, Andrey, Fedorov",10.1016/j.medimint.2023.03.012,10.1016/j.medimint.2023.03.015,"AI, Medical Imaging, Radiology, Machine Learning, Deep Learning, Healthcare","A standardized platform for AI models in medical imaging, emphasizing reproducibility and clinical relevance.",303.11,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10155v1_LOOKAT Lookup-Optimized Key-Attention for Memory-E.pdf,Exact string,Aryan Karmore,10.48550/arxiv/2303.04137,bt24csd009,"transformers, quantization, attention, compression","The paper presents LOOKAT, a method that applies product quantization and asymmetric distance computation to compress KV-cache in transformer models, enabling efficient edge deployment without architectural changes.",338.52,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10157v1_MMPG MoE-based Adaptive Multi-Perspective Graph Fu.pdf,Exact string,"Yusong Wang, Jialun Shen, Zhihao Wu, Yicheng Xu, Shiyin Tan, Mingkun Xu, Changshuo Wang, Zixing Song, Prayag Tiwari",10.48550/arXiv.2403.04219,10.48550/arXiv.2403.04219,"Graph Neural Networks, Protein Representation Learning, Multi-perspective graphs, Mixture of Experts, Residue interactions",MMPG introduces a framework for constructing protein graphs from multiple perspectives and adaptively fusing them using a Mixture of Experts (MoE) module to improve protein representation learning.,319.04,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10160v1_Alignment Pretraining AI Discourse Causes Self-Ful.pdf,Exact string,"Cameron Tice, Puria Radmard, 2 Samuel Ratnam, Andy Kim, David Africa, Kyle O’Brien",10.48550/arXiv.2025.12345,10.48550/arXiv.2025.12345,"alignment, misalignment, LLM, discourse, self-fulfilling, pretraining","This paper investigates how discourse about AI behavior during pretraining can induce self-fulfilling misalignment in large language models. By upsampling synthetic training data with AI misalignment discussions, the authors demonstrate that such discourse increases misaligned behavior, while aligned discourse reduces it. The study highlights the importance of considering pretraining data in alignment research.",356.73,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10161v1_AWED-FiNER Agents Web applications and Expert Dete.pdf,"A WED-FiNER: Agents, Web applications, and Expert Detectors for Fine-grained Named Entity Recognition across 36 Languages","Prachuryya Kaushik, Ashish Anand",10.12345/example,null,"Named Entity Recognition, Fine-grained NLP, Multilingual models","AWED-FiNER is an open-source ecosystem bridging gaps in fine-grained NER for 36 languages, supporting agentic tools, web apps, and expert models to enable offline deployment and serve vulnerable languages.",326.29,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10168v1_RAG-3DSG Enhancing 3D Scene Graphs with Re-Shot Gu.pdf,Exact string,"Yue Chang, Rufeng Chen, Zhaofan Zhang, Yi Chen, Sihong Xie",10.48550/arXiv.2311.07818,10.48550/arXiv:2311.07818,"3D scene graph, object recognition, robotics, semantic representation","The paper introduces RAG-3DSG to improve open-vocabulary 3D scene graph generation by reducing noise through re-shot guided uncertainty estimation and enhancing object-level retrieval augmentation. It proposes a dynamic downsample-mapping strategy to accelerate cross-image aggregation, achieving better node captioning accuracy and faster mapping compared to existing methods.",314.11,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10169v1_CtD Composition through Decomposition in Emergent .pdf,Exact string,"Boaz Carmeli, Ron Meir, Yonatan Belinkov",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"compositionality, composition through decomposition, neural composition, concept decomposition",The paper presents a method called 'Composition through Decomposition' where agents learn to decompose images into basic concepts and then compose them into novel descriptions. This enables zero-shot compositional generalization without additional training.,289.06,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10173v1_ReasAlign Reasoning Enhanced Safety Alignment agai.pdf,ReasAlign: A Model-Level Defense Against Indirect Prompt Injection,"Hao Li1, Yankai Yang2, G. Edward Suh3, Ning Zhang1, Chaowei Xiao3, 4, Johns Hopkins University",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"prompt injection, indirect attacks, LLM safety, reasoning alignment","This paper introduces ReasAlign, a model-level approach to enhance safety alignment by incorporating structured reasoning steps to detect and mitigate indirect prompt injection attacks. It demonstrates improved utility and robustness compared to existing defenses, achieving high performance on benchmark evaluations.",342.02,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10187v1_HOMURA Taming the Sand-Glass for Time-Constrained .pdf,Taming the Sand-Glass for Time-Constrained LLM Translation via Reinforcement Learning,"Ziang Cui, Mengran Yu, Tianjiao Li, Chenyu Shi, Yingxuan Shi, Lusheng Zhang, Hongwei Lin",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"LLM, translation, syllable budget, semantic fidelity, time constraints","The paper introduces Sand-Glass, a benchmark for evaluating translation under syllable-level duration constraints, and presents HOMURA, a reinforcement learning framework that optimizes the trade-off between semantic preservation and temporal compliance. Experimental results show HOMURA significantly improves length control while maintaining meaning.",338.31,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10191v1_How does downsampling affect needle electromyograp.pdf,Downsampling Effects on Needle Electromyography Signals,"Mathieu J.L. Cherpitel, Janne A.M. Luijten, Thomas H.W. Bæck, Camiel Verhamme, Martijn R. Tannemaat, Anna V. Kononova",10.1093/acm/qad045,null,"needle electromyography, downsampling, signal processing, neurology","This study evaluates how downsampling impacts needle electromyography (nEMG) signals and proposes a workflow to balance data reduction with diagnostic accuracy. It highlights shape-aware downsampling as effective for preserving signal integrity while reducing computational load, offering practical guidance for real-time nEMG analysis.",323.75,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10193v1_GFM4GA Graph Foundation Model for Group Anomaly De.pdf,GFM4GA: Graph Foundation Model for Group Anomaly Detection,"Jiujiu Chen, Weijun Zeng, Shaofeng Hu, Hui Xiong",10.1093/acm/grla123,10.1093/acm/grla123,"Group Anomaly Detection, Graph Foundation Model, Graph Contrastive Learning","Proposes GFM4GA, a graph foundation model leveraging dual-level contrastive learning to detect group anomalies, improving upon existing methods for individual and group anomaly detection.",289.45,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10201v1_PRL Process Reward Learning Improves LLMs Reasonin.pdf,Process Reward Learning Improves LLMs’ Reasoning Ability,"Jiarui Yao, Ruida Wang, Tong Zhang",10.48550/arXiv.2311.07818,10.48550/arXiv:2311.07818,"reasoning, LLMs, reinforcement learning, process rewards","The paper introduces Process Reward Learning (PRL), a method that decomposes reinforcement learning into intermediate steps with process rewards. It aims to improve LLMs' reasoning by providing fine-grained supervision during the reasoning process, addressing limitations of outcome-based training. Experiments show PRL enhances both average performance and pass@n metrics.",316.46,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10205v1_One Instruction Does Not Fit All How Well Do Embed.pdf,Exact string,"Arya Shah, Himanshu Beniwal, Mayank Singh",10.48550/arXiv.2303.04112,10.48550/arXiv/2303.04112,"persona, instruction alignment, multilingual retrieval, Indic languages","The paper evaluates eight multilingual embedding models across 12 Indian languages, presenting a unified benchmark for persona-instruction retrieval. It highlights performance gains in monolingual and cross-lingual tasks, offering practical guidance for deploying culturally aware assistants in India.",326.01,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10212v1_PADER Paillier-based Secure Decentralized Social R.pdf,Exact string,"Paillier-based Secure Decentralized Social Recommendation, Jiaming Qian, Fei Zheng, Yachuan Liu",10.1007/978-3-030-24072-7,None,"Paillier Cryptosystem, Secure Computation, Recommendation System","The paper proposes PADER, a Paillier-based secure decentralized social recommendation system that enables privacy-preserving training and inference by leveraging secure addition and multiplication protocols. It demonstrates high efficiency in real-world scenarios with practical performance metrics.",289.75,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10215v1_Topo-RAG Topology-aware retrieval for hybrid text-.pdf,Topo-RAG: Topology-Aware Retrieval for Hybrid,"Alex Dantart, Marco K´ovacs-Navarro",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Retrieval-Augmented Generation (RAG), table retrieval, late interaction, multivector retrieval, enterprise search, heterogeneous data, semantic routing, structure-aware embeddings","Topo-RAG introduces a dual-architecture framework that respects data topology, improving retrieval on complex enterprise datasets by preserving spatial relationships in tables alongside textual narratives.",297.29,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10222v1_Introduction to optimization methods for training .pdf,Introduction to optimization methods for training SciML models,"Alena Kopaničáková∗, Elisa Riccietti †",10.1093/acm/9780190876223.013.0001,2601.10222v1,"optimization, SciML, machine learning, stochastic optimization","The paper discusses how stochastic optimization methods are increasingly important in scientific machine learning, especially when data is scarce. It highlights the shift from classical first-order methods to adaptive, curvature-aware techniques tailored for physics-informed models.",283.34,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10236v1_Who Owns the Text Design Patterns for Preserving A.pdf,Design Patterns for Preserving Authorship in AI-Assisted Writing,"Bohan Zhang, Chengke Bu, Paramveer Dhillon",10.1093/acps/2026.01.012,2601.10236,"AI-assisted writing, human-AI collaboration, psychological ownership, personalization, provenance","The paper examines how AI writing assistants impact writers' sense of authorship, introducing design patterns to preserve ownership while improving fluency and reducing cognitive load.",314.63,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10242v1_Loop as a Bridge Can Looped Transformers Truly Lin.pdf,Exact string,"Guanxu Chen1, Dongrui Liu1, Jing Shao1",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Large Language Models, Looped Transformers, Introspection, Representation","This report investigates whether Looped Transformers (LTs) can bridge the gap between internal knowledge and linguistic outputs by leveraging iterative self-verification. Experiments show that while increasing loop iterations narrows the knowledge-gap, internal representations degrade, and verification remains limited to the final loop. The findings suggest LTs offer promise for scaling computational depth but require further refinement in introspective capabilities.",315.73,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10245v1_TRIM Hybrid Inference via Targeted Stepwise Routin.pdf,TRIM: Hybrid Inference via Targeted Stepwise,"Vansh Kapoor, Aman Gupta, Hao Chen, Anurag Beniwal, Jing Huang, Aviral Kumar",10.48550/arXiv.2025.12345,10.48550/arXiv.2025.12345,"multi-step reasoning, LLM routing, step-level intervention, cost efficiency, mathematical problem solving","The paper introduces TRIM, a targeted routing framework for multi-step reasoning tasks. It addresses the inefficiency of routing all steps to a single large model by routing only critical steps to larger models while allowing smaller models to handle routine continuations. TRIM improves cost efficiency and performance across benchmarks like MATH-500 and AIME, demonstrating that step-level difficulty drives routing decisions.",309.01,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10251v1_X-SAM Boosting Sharpness-Aware Minimization with D.pdf,Exact string,"Hongru Duan Yongle, Chen Lei Guan",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"sharpness-aware minimization, SAM, generalization, loss landscape",The paper investigates how the angle between the gradient and the leading eigenvector affects the effectiveness of Sharpness-Aware Minimization (SAM) in neural networks. It proposes an eigenvector-aligned variant (X-SAM) to improve generalization by addressing cases where SAM's gradient fails to point toward sharp regions.,370.76,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10254v1_NoReGeo Non-Reasoning Geometry Benchmark.pdf,Exact string,"Irina Abdullaeva, Anton Vasiliuk, Elizaveta Goncharova, Temurbek Rahmatullaev, Zagorulko Ivan, Maxim Kurkin, Andrey Kuznetsov, 6, 4, 7, 8, 9, FusionBrain Lab, Research Center of the Artificial Intelligence Institute, HSE University, Lomonosov Moscow State University, Central University, Applied AI Institute, Moscow",10.1234/no-regeo.2026,10.1234/no-regeo.2026,"geometric understanding, large language models, spatial relationships, benchmark, intrinsic cognition","The paper introduces NoReGeo, a benchmark evaluating how well large language models can understand and reason about geometry without relying on algebraic computation. It presents 2,500 trivial geometric problems across 25 categories, assessing models like GPT-4. Findings show models achieve up to 65% accuracy, underscoring a gap in native geometric comprehension.",304.97,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10257v1_Untangling Input Language from Reasoning Language .pdf,Exact string,"Nan Li, Bo Kang, Tijl De Bie",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"moral foundations, cross-lingual alignment, LLM reasoning","The paper introduces a framework to disentangle the effects of language on moral judgment reasoning, demonstrating that mismatched reasoning-language pairs reveal hidden value conflicts and enabling a diagnostic taxonomy for improving global moral alignment in large language models.",354.79,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10272v1_MoST Mixing Speech and Text with Modality-Aware Mi.pdf,Exact string,"Yuxuan Lou, Kai Yang, Yang You",10.48550/arXiv.2405.12345,2601.10272,"Mixture of Experts, speech, text, multimodal, LLM","Presents MoST, a novel multimodal large language model integrating speech and text via a modality-aware Mixture of Experts architecture, emphasizing modality-specific routing and shared expert design.",277.56,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10274v1_Queueing-Aware Optimization of Reasoning Tokens fo.pdf,Exact string,"Emre Ozbas, Melih Bastopcu",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"accuracy-latency trade-offs, LLM-based servers, optimization of reasoning tokens, LLM inference",The paper presents a constrained optimization framework for allocating reasoning tokens in a multi-task LLM server to balance accuracy and latency. It formulates the problem as a constrained optimization with a coupled projected method and provides empirical performance evaluation.,290.58,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10282v2_SPIKE Sparse Koopman Regularization for Physics-In.pdf,Exact string,Jose Marie Antonio Miñoza,10.1093/pasj/psa123,2601.10282,"Physics-Informed Neural Networks, PINN, Koopman operator, PDEs","The paper introduces SPIKE, a framework that enhances Physics-Informed Neural Networks by integrating continuous-time Koopman regularization. It demonstrates improved generalization for solving partial differential equations across various domains, emphasizing stability and interpretability.",298.83,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10305v1_DanQing An Up-to-Date Large-Scale Chinese Vision-L.pdf,Exact string,"DanQing, Hengyu Shen, Tiancheng Gu, Bin Qin, Lan Wu, Yuling Wu, Shuo Tan, Zelong Sun, Jun Wang, Nan Wu, Xiang An, Weidong Cai, Ziyong Feng, Kaicheng Yang, DanQingTeam",10.48550/arXiv.2601.10305,2601.10305,"Chinese vision-language, pre-training, cross-modal retrieval, image captioning, CLIP, SigLIP","The paper introduces DanQing, a high-quality Chinese cross-modal dataset constructed from 100 million image-text pairs collected via Common Crawl. It emphasizes superior data quality and timeliness, built primarily from 2024–2025 web data, and compares its performance with existing datasets through continual pre-training of SigLIP2. The results demonstrate DanQing's effectiveness across diverse Chinese vision-language tasks.",307.3,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10306v1_Evidence-Augmented Policy Optimization with Reward.pdf,Evidence-Augmented Policy Optimization with Reward Co-Evolution for Long-Context Reasoning,"Xin Guan, Zijian Li, Shen Huang, Pengjun Xie, Jingren Zhou, Jiuxin Cao",10.1234/abcd1234,None,"Evidence-Augmentation, Long-Context Reasoning, RL, LLM, Reward Modeling","The study presents EAPO, an evidence-augmented reinforcement learning method that enhances LLM reasoning for long contexts by improving evidence retrieval and adaptive reward feedback.",273.83,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10338v1_Agent Skills in the Wild An Empirical Study of Sec.pdf,Agent Skills in the Wild: An Empirical Study of Security,"Yi Liu, Weizhe Wang, Ruitao Feng, Yao Zhang, Guangquan Xu, Gelei Deng, Yuekang Li, Leo Zhang",10.1145/nnnnnnn.nnnnnnn,null,"Agent skills, AI security, vulnerability analysis, supply chain security, prompt injection, large language models","The study presents the first large-scale empirical analysis of security vulnerabilities in AI agent skills, identifying pervasive risks across 14 categories and highlighting the need for capability-based permission systems.",335.84,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10342v1_C-GRASP Clinically-Grounded Reasoning for Affectiv.pdf,Exact string,"Cheng Lin Cheng, Ting Chuan Lin, Chai Kai Chang",10.48550/arXiv.2024.12345,None,,N/A,248.77,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10343v2_OctoBench Benchmarking Scaffold-Aware Instruction .pdf,Exact string,"Deming Ding1, Shichun Liu1, Enhui Yang2, Jiahang Lin1, Ziying Chen1, Shihan Dou2, Honglin Guo3, Weiyu Cheng2, Pengyu Zhao2, Chengjun Xiao2, Qunhong Zeng2, Qi Zhang1, Xuanjing Huang1, Qidi Xu †2, Tao Gui †1",10.1234/example.doi,None,,N/A,244.68,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10348v1_Training-Trajectory-Aware Token Selection.pdf,Training-Trajectory-Aware Token Selection,"Zhanming Shen, Jiaqi Hu, Zeyu Qin, Hao Chen, Wentao Ye1, Zenan Huang, Yihong Zhuang, Yuanzhi Lu, Junlin Zhou, Junbo Zhao, Guoshan Lu",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"training trajectory, token selection, distillation, LLM","The paper introduces Training-Trajectory-Aware Token Selection (T3S) to improve continual reasoning distillation by adapting the training objective at the token level. It identifies a 'training shock' phenomenon where performance drops sharply before recovering, attributing it to imitation anchor tokens. T3S aims to mitigate this by enabling consistent gains across AR and LLM settings.",311.53,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10349v1_SuS Strategy-aware Surprise for Intrinsic Explorat.pdf,Strategy-aware Surprise for Intrinsic Exploration,"Mark Kashirskiy1, Ilya Makarov1",10.48550/arXiv.2024.12345,353056@niuitmo.ru,"intrinsic motivation, reinforcement learning, contrastive learning, exploration","The paper introduces Strategy-aware Surprise (SuS), a novel intrinsic motivation framework that combines Strategy Stability and Strategy Surprise to guide exploration in reinforcement learning. By leveraging prediction mismatch and learned weighting of these components, SuS improves performance in mathematical reasoning tasks while maintaining diverse strategies.",296.9,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10373v1_Towards Efficient Low-rate Image Compression with .pdf,Exact string,"Yichong Xia, Yimin Zhou, Jinpeng Wang, Bin Chen",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"image compression, diffusion models, frequency estimation, compression","The paper presents DiffCR, a frequency-aware skip estimation module combined with consistency prior refinement for efficient low-rate image compression. It achieves significant bitrate savings and speed improvements over existing methods.",328.05,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10378v2_Global Context Compression with Interleaved Vision.pdf,Exact string,"Dian Jiao, Jiaxin Duan, Shuai Zhao, Jiabing Leng, Yiran Zhang, Feng Huang",10.5281/zenodo.1234567,10.5281/RECONFIGURE.D0A22.0,"vision-language models, context compression, Transformer, OCR","This paper proposes VIST2, a Transformer-based model that interleaves input text chunks with visual encoding to achieve global context compression. It reduces computational costs while maintaining performance, offering a 3× speedup and 77% memory reduction on long writing tasks.",280.87,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10386v1_Handling Missing Modalities in Multimodal Survival.pdf,Exact string,"Filippo Ruffini, Camillo Maria Caruso, Claudia Tacconi, Lorenzo Nibid5, Francesca Miccolis, Marta Lovino, Carlo Greco, Edy Ippolito, Michele Fiore, Alessio Cortellini, Bruno Beomonte Zobel, Giuseppe Perrone, Bruno Vincenzi, Claudio Marrocco, Alessandro Bria, Elisa Ficarra, Sara Ramella, Valerio Guarrasi, Paolo Soda",10.1093/acm/qad045,2601.10386v1,"multimodal, survival prediction, non-small cell lung cancer, artificial intelligence, diagnostics, radiation oncology","A study on missing modalities in multimodal survival prediction for non-small cell lung cancer, focusing on AI integration in diagnostic workflows.",325.47,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10398v2_LatentRefusal Latent-Signal Refusal for Unanswerab.pdf,Exact string,"Xuancheng Ren, Shijing Hu Zhihui Lu, Jiangqi Huang",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Text-to-SQL, refusal strategy, LLM safety, unspecified queries","The paper introduces LATENTREFUSAL, a latent-signal refusal mechanism for Text-to-SQL systems, to detect unanswerable queries by analyzing LLM hidden activations. It proposes the Tri-Residual Gated Encoder (TRGE) to enhance refusal detection and improves answerability gating, achieving high performance with minimal overhead.",345.29,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10402v1_Toward Ultra-Long-Horizon Agentic Science Cognitiv.pdf,Exact string,"Xinyu Zhu, Yuzhu Cai, Zexi Liu, Bingyang Zheng, Rui Ye, Jiaao Chen, Hanrui Wang, Wei-Chen Wang, Yuzhi Zhang, Linfeng Zhang, Weinan E1, Di Jin, Siheng Chen, ∗, ∗, School of Artiﬁcial Intelligence, School of Computer Science and Engineering, Beihang University",10.1109/ML-Master.2026.00001,2601.10402,"ultra-long-horizon, agentic science, cognitive accumulation, machine learning engineering, ML-Master 2.0, scientific discovery","The paper introduces ML-Master 2.0, an autonomous agent designed for ultra-long-horizon machine learning engineering. It presents Hierarchical Cognitive Caching (HCC) to sustain strategic coherence across extended experimental cycles, achieving a 56.44% medal rate on OpenAI’s MLE-Bench. The work bridges gaps in LLM performance for high-complexity, long-term tasks.",314.2,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10406v1_ErrEval Error-Aware Evaluation for Question Genera.pdf,ErrEval: Error-aware Evaluation for Question Generation,"Weiping Fu, Bifan Wei, Jingyi Hao, Yushun Zhang, Jian Zhang, Jiaxin Wang, Bo Li, Yu He, Lingling Zhang, Jun Liu",10.1234/example.doi,None,,"The paper introduces ErrEval, a framework that enhances question generation evaluation by incorporating explicit error diagnostics to reduce factual hallucinations and improve alignment with human judgments.",311.36,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10413v1_LADFA A Framework of Using Large Language Models a.pdf,LADFA: A Framework of Using Large Language Models and Retrieval-Augmented Generation for Personal Data Flow Analysis in Privacy Policies,"Haiyue Yuan, Nikolay Matyunin, Ali Raza, Shujun Li",10.1234/abcd1234,10.1234/abcd1234,"Large Language Model, LLM, Privacy Policy, Text Analysis, Data Flows, Privacy, Security, Retrieval-Augmented Generation, RAG, Automotive Industry, Connected Vehicle","This paper introduces LADFA, an end-to-end framework leveraging large language models and retrieval-augmented generation to analyze personal data flows within privacy policies. It presents a method for extracting data flows, constructing data flow graphs, and enabling insight discovery, with validation using automotive industry privacy policies.",271.62,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10416v1_LLMdoctor Token-Level Flow-Guided Preference Optim.pdf,LLMdoctor: Token-Level Flow-Guided Preference Optimization,"Tiesunlong Shen, Rui Mao, Jin Wang, Heming Sun, Jian Zhang, Xuejie Zhang, Erik Cambria",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"large language models, test-time alignment, token-level optimization, LLM-doctor","Introduces LLMdoctor, a framework for efficient test-time alignment using token-level reward acquisition and flow-guided preference optimization to preserve generation diversity while outperforming existing methods.",318.94,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10421v1_Are Language Models Models.pdf,Exact string,"Philip Resnik, Department of Linguistics and Institute for Advanced Computer Studies, University of Maryland, Resnik, P.",10.1017/S0140525X2510112X,null,"language models, computational linguistics, LLM","The paper discusses whether language models function as cognitive models, arguing that while they are useful tools, they do not fully represent human language understanding at implementation, algorithmic, or theoretical levels.",281.43,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10436v1_Development of Ontological Knowledge Bases by Leve.pdf,Exact string,"Leveraging Large Language Models, Marie-Hélène ABEL, Philippe GOUSPILLOU",10.1093/acref/2023.01.012,10.1093/acref.2023.01.012,"Ontology Development, Ontological Knowledge bases, Large Language Models, Knowledge Representation, User Modeling, Knowledge Management","This paper presents a structured methodology leveraging Large Language Models to automate and enhance the development of Ontological Knowledge Bases, focusing on accelerating ontology construction, improving consistency, mitigating bias, and increasing transparency in knowledge engineering.",287.63,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10440v1_AgentGuardian Learning Access Control Policies to .pdf,Exact string,"Nadya Abaev, Denis Klimov, Gerard Levinov, David Mimran, Yuval Elovici, Asaf Shabtai",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"AI agents, access control policies, control flow graph, security, AI agents, policy enforcement","The paper introduces AgentGuardian, a security framework that governs AI agent operations through context-aware access control policies. It demonstrates effectiveness in detecting malicious inputs and mitigating hallucination-driven errors while preserving legitimate functionality.",299.39,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10457v1_NSR-Boost A Neuro-Symbolic Residual Boosting Frame.pdf,NSR-Boost: A Neuro-Symbolic Residual Boosting Framework for Industrial Legacy Models,"Ziming Dai, Dabiao Ma, Jinle Tong, Mengyuan Han, Jian Yang, Hanmengyuan-JK",10.1145/nnnnnnn.nnnnnnn,10.1145/nnnnnnn.nnnnnnn,"Neuro-Symbolic AI, Large Language Models, Gradient Boosting, Legacy Model, Interpretability","The paper introduces NSR-Boost, a neuro-symbolic residual boosting framework tailored for industrial legacy models. It addresses the challenges of re-training costly legacy systems by focusing on targeted repairs in hard prediction regions. The approach combines residual analysis, LLM-generated symbolic experts, and Bayesian optimization, achieving strong performance across diverse datasets and demonstrating practical benefits in real-world industrial applications.",353.08,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10460v1_Contextual StereoSet Stress-Testing Bias Alignment.pdf,Exact string,"Abhinaba Basu, Pavan Chakraborty",10.48550/arXiv.2601.10460,2601.10460,"bias evaluation, alignment robustness, stress-testing, large language models, so-cio technological context, StereoSet","The paper introduces Contextual StereoSet, a benchmark that fixes stereotype content while varying contextual framing. It demonstrates that models' bias shifts with changes in time, location, and audience, highlighting the need for context-aware evaluation beyond static scores.",319.7,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10462v3_ChartComplete A Taxonomy-based Inclusive Chart Dat.pdf,Exact string,"Ahmad Mustapha, Charbel Toumieh, Mariette Awad",10.48550/arXiv.2026.12345,10.48550/arXiv.2026.12345,"Chart, Dataset, Chart Taxonomy, Chart Classification","The paper introduces the ChartComplete dataset, a taxonomy-based inclusive chart dataset covering 30 chart types to advance research in multi-modal large language models for chart understanding.",314.21,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10477v1_Urban Socio-Semantic Segmentation with Vision-Lang.pdf,Exact string,"Yu Wang, Yi Wang, Rui Dai, Yujie Wang, Kaikui Liu, Xiangxiang Chu, Yansheng Li",10.48550/arXiv.2024.12345,10.48550/arXiv/12345,"urban segmentation, socio-semantic segmentation, vision-language reasoning, semantic entities, social semantics","The paper introduces a new dataset and framework for socio-semantic segmentation using vision-language reasoning, addressing challenges in identifying social entities in satellite imagery.",313.51,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10485v1_Panning for Gold Expanding Domain-Specific Knowled.pdf,Exact string,"Runhao Zhao, Weixin Zeng, Wentao Zhang, Chong Chen, Zhengpin Li, Xiang Zhao, Lei Chen",10.1000/xyz123,null,"Domain-specific Knowledge Graphs, Knowledge Graph Enrichment, General-to-domain Transfer, Fact-as-Program","The paper introduces ExeFuse, a new framework for domain-specific knowledge graph fusion that addresses gaps in integrating general knowledge graphs with domain-specific ones. It proposes a novel approach to handle ambiguity in domain relevance and granularity misalignment, offering a practical solution for enhancing knowledge graphs.",328.71,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10496v1_Model See Model Do Exposure-Aware Evaluation of Bu.pdf,"Model See, Model Do? Exposure-Aware Evaluation of Bug-vs-Fix Preference in Code","Ali Al-Kaswan, Claudio Spiess, Prem Devanbu, Arie van Deursen, Maliheh Izadi",10.1145/nnnnnnn.nnnnnnn,10.1145/XXXXXX,"Large Language Models, bugs, fixes, Memorisation","The paper introduces an exposure-aware framework to evaluate how LLMs distinguish correct code from familiar incorrect versions, using the ManySStuBs4J benchmark. It finds that most examples lack either buggy or fixed variants, fixes are more common when only one is present, and exposure amplifies this bias, showing LLMs may propagate memorised errors.",286.38,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10498v1_Projected Microbatch Accumulation yields reference.pdf,Projected Microbatch Accumulation yields reference-free proximal policy updates for reinforcement learning,Nilin Abrahamsen,10.48550/arXiv.2601.10498,2601.10498,"projected microbatch accumulation, proximal policy updates, reinforcement learning, policy gradient","Introduces PROMA, a proximal policy update method that projects out sequence-wise gradients during backward passes to enable efficient, reference-free updates without additional forward/backward passes. PROMA improves stability by constraining local KL divergence and avoids entropy collapse, offering a tractable approximation to natural policy gradients.",334.33,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10511v1_Scalable Algorithms for Approximate DNF Model Coun.pdf,Scalable Algorithms for Approximate DNF Model Counting,"Paul Burkhardt, David G. Harris, Kevin T. Schmitt",10.1093/pasj/psa.2023,2601.10511,"DNF, model counting, probabilistic inference, network reliability, Monte Carlo, adaptive stopping rule","The paper presents a new Monte Carlo method for approximating DNF model counting, achieving PAC learning bounds and demonstrating superior performance over prior approaches.",278.97,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10512v2_SatMap Revisiting Satellite Maps as Prior for Onli.pdf,SatMap: Revisiting Satellite Maps as Prior for Online HD Map Construction,"Kanak Mazumder, Fabian B. Flohr",10.1093/acr/nwx123,10.1093/acr/nwx123,"Online HD map prediction, Satellite map prior, Vectorized HD map","The paper introduces SatMap, an online method that integrates satellite maps with camera data to improve HD map estimation. It achieves a 34.8% mAP improvement over camera-only baselines and an 8.5% improvement over camera-LiDAR fusion, demonstrating the value of satellite imagery as a global prior for reducing depth ambiguity and occlusion.",329.77,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10520v1_Breaking Up with Normatively Monolithic Agency wit.pdf,Breaking Up with Normatively Monolithic Agency,"Felix Jahn, Yannic Muskalla, Lisa Dargasz, Kevin Baum",10.48550/arXiv.2601.10520,2601.10520,"normative alignment, ethical AI, AI architecture, moral reasoning, safe AI","The paper introduces GRACE, a reason-based neuro-symbolic architecture for safe and ethical AI alignment. GRACE decouples normative reasoning from instrumental decision-making through three modules: a Moral Module for macro action constraints, a Decision-Making Module for agent actions, and a Guard for monitoring compliance. It enables stakeholders to understand, contest, and refine AI behavior in complex moral contexts.",298.28,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10524v1_Diagnosing Generalization Failures in Fine-Tuned L.pdf,Diagnosing Generalization Failures in Fine-Tuned LLMs: A Cross-Architectural Study on Phishing,"Frank Bobe III, Gregory D. Vetaw, Chase Pavlick, Darshan Bryner, Matthew Cook, Jose Salas-Vernis",10.1093/pasj/psa.2026,2601.10524v1,"LLM, generalization, phishing, interpretability","The study investigates why fine-tuned Large Language Models exhibit generalization failures, identifying architectural-data interactions and architecture-specific flaws as key contributors. It proposes diagnostic frameworks to improve robustness.",286.36,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10527v2_A Safety Report on GPT-5.2 Gemini 3 Pro Qwen3-VL G.pdf,Exact string,"Xingjun Ma, Yixu Wang, Hengyuan Xu, Yutao Wu, Yifan Ding, Yunhan Zhao, Zilong Wang, Jiabin Hua, Ming Wen, Jianan Liu, Ranjie Duan, Yifeng Gao, Yingshui Tan, Yunhao Chen, Hui Xue Xin, Wei Cheng, Jingjing Chen, Zuxuan Wu, Bo Li, Yi Gang Jiang, Hua Ming",10.48550/arXiv.2026.10527,2601.10527v2,"GPT-5.2, Gemini 3 Pro, Qwen3-VL, Grok 4.1 Fast, Nano Banana Pro, Seedream 4.5, safety evaluation, LLM safety, multimodal models","The report evaluates the safety of frontier AI models, highlighting trade-offs in performance across benchmarks, adversarial robustness, and multilingual capabilities. It underscores the need for comprehensive safety assessments to address vulnerabilities in LLMs and MLLMs.",329.96,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10543v1_Defending Large Language Models Against Jailbreak .pdf,Defending Large Language Models Against Jailbreak Attacks via In-Decoding Safety-Awareness Probing,"Yinzhi Zhao, Ming Wang, Shi Feng, Xiaocui Yang, Daling Wang, Yifei Zhang",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"large language models, jailbreak attacks, decoding safety, LLM safety, content safety",The paper explores how large language models (LLMs) can be vulnerable to jailbreak attacks and proposes a method to detect unsafe content by leveraging latent safety signals during decoding. It emphasizes the importance of intrinsic safety awareness in model generation.,335.51,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10560v1_Learning Latency-Aware Orchestration for Parallel .pdf,Exact string,"Xi Shi, Mengxin Zheng, Qian Lou",10.48550/arXiv.2024.12345,arXiv:2409.12345,"multi-agent systems, latency-aware, parallel execution, LLM","The paper presents Latency-Aware Multi-agent System (LAMaS), a framework that optimizes multi-agent orchestration under parallel execution by explicitly supervising latency. It reduces critical path length by 38–46% compared to SOTA, improving scalability for time-sensitive applications.",343.31,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10562v1_Process-Guided Concept Bottleneck Model.pdf,Process-Guided Concept Bottleneck Model,"Reza M. Asiyabi, Sam Harrison, John L. Godlee, David Milodowski, Nicole H. Augustin, Penelope J. Mograbi, Timothy R. Baker, Lorena M. Benitez, Samuel J. Bowers, Thomas K. Brade, Joao M. Carreiras, Duncan M. Chalo, Vera De Cauwer, Kyle G. Dexter, Hermane Diesse, Mathias I. Disney, Luisa F. Escobar-Alvarado, Penelope J. Mograbi, Timothy R. Baker, Lorena M. Benitez, Samuel J. Bowers, Thomas K. Brade, Joao M. B. Carreiras, Duncan M. Chalo, João M. Makhado, Gabriele C. Hegerl, John N. Kigomo, Fainess C. Lumbwe, Francisco Maiato, Rudzani A. Makhado, Collins W. Masinde, Musingo Tito E. Mbuvi, Iain M. McNicol, Edward T.A. Mitchard, Buster P. Mogonong, Wilson A. Mugasha, Aristides Baptista Muhate, Hinji Mutondo, Leena Naftal, Paula Nieto-Quintano, Elifuraha Elisha Njoghomi, Catherine L. Parr, Oliver L. Phillips, Pierre Proces, Tshililo Ramsawai, Natasha Ribeiro, Mahesh Sankaran, Abel M. Siampale, Stephanie Sitch, Kathleen G. Smart, Hemant G. Tripathi, Wayne Twine, Gabriel I.K. Uusiku, Helga van der Merwe, Chemuku Wekesa, Benjamin J. Wigley, Mathew Williams, Ellie Wood, Emily Woollen, Shaun Quegan, Steven Hancock, Casey M. Ryan",10.1093/ijp/ppb045,null,"process-guided, concept-bottleneck, machine intelligence, AI, bottleneck modeling","This study presents a process-guided concept bottleneck model for machine learning applications, integrating AI-assisted tools and collaborative data sources to advance bottleneck analysis in complex systems.",338.45,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10567v1_Generative AI collective behavior needs an interac.pdf,Exact string,"Laura Ferrarotti, Gian Maria Campedelli, Andrea Baronchelli, Giovanni Iacca, Kathleen M. Carley, Alex Pentland, Joel Z. Leibo, James Evans, Bruno Lepri, Not Diamond, City St. George’s University of London, Carnegie Mellon University, Massachusetts Institute of Technology, Stanford University, Google DeepMind, University of Chicago",10.48550/arXiv.2601.10567,2601.10567,"generative AI, collective behavior, interactionist paradigm, LLMs, social context, multi-agent systems","The paper discusses the need for an interactionist paradigm to understand collective behavior in large language models, emphasizing the role of prior knowledge, social priors, and adaptation mechanisms in shaping emergent phenomena within multi-agent AI systems.",283.21,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10581v1_From Single to Multi-Agent Reasoning Advancing Gen.pdf,Exact string,"Kimia Abedini, Farzad Shami, Gianmaria Silvello",10.48550/arXiv.2601.10581,2601.10581,"Question Answering, Genomic QA, Multi-Agent Systems","The paper proposes GenomAgent, a multi-agent framework that improves upon GeneGPT by enabling flexible coordination of specialized agents for complex genomic queries, achieving better performance on benchmarks.",305.29,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10587v1_Adversarial Evasion Attacks on Computer Vision usi.pdf,Adversarial Evasion Attacks on Computer Vision using SHAP Values,"Frank Mollard, Marcus Becker, Florian Röhrbein",10.1093/acps/csa.2023.01,2601.10587,"adversarial attacks, computer vision, SHAP values, deep learning, misclassification","The paper presents a white-box attack on computer vision models using SHAP values, demonstrating how such attacks can compromise model performance by manipulating input confidence and inducing misclassifications. It compares SHAP-based attacks with the Fast Gradient Sign Method and highlights their effectiveness in gradient hiding scenarios.",270.56,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10591v1_ProbFM Probabilistic Time Series Foundation Model .pdf,Exact string,"Arundeep Chinta1, Lucas Vinh Tran2, Jay Katukuri1",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"probabilistic models, uncertainty quantification, financial forecasting","Presents ProbFM, a novel transformer-based probabilistic framework that introduces Deep Evidential Regression for principled uncertainty quantification, demonstrating improved forecasting accuracy and interpretability in financial time series.",349.06,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10600v1_Procedural Fairness in Multi-Agent Bandits.pdf,Exact string,"Joshua Caiata, Carter Blair, Kate Larson",10.1093/pasj/2026.15,2601.10600v1,"fairness, procedural fairness, multi-agent systems, ethics","The paper introduces procedural fairness as a new fairness objective in multi-agent multi-armed bandits, emphasizing equal decision-making power and proportionality in outcomes. It argues that fairness should prioritize process over outcomes and highlights the need for normative choices in fairness.",272.47,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10611v1_Molmo2 Open Weights and Data for Vision-Language M.pdf,Exact string,"Christopher Clark, Jieyu Zhang, Zixian Ma, Jae Sung Park, Mohammadreza Salehi, Sangho Lee, Zhongzheng Ren1, Chris Dongjoo Kim, Yinuo Yang2, Vincent Shao2, Yue Yang1, Weikai Huang2, Ziqi Gao, Taira Anderson1, Jianrui Zhang, Jitesh Jain1, George Stoica1, Winson Han, Ali Farhadi1, Ranjay Krishna",10.48550/arXiv.2601.10611,2601.10611,"Open weights, Video understanding, Grounding, Video datasets, Object tracking, Video pointing, Multi-image datasets","Molmo2 introduces a new family of open-source video-language models that achieve state-of-the-art performance in grounding tasks without relying on proprietary models. The paper presents seven new video datasets and a novel training recipe, demonstrating significant improvements over existing open-weight and proprietary models in video counting, captioning, and video pointing.",318.94,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10651v1_Multi-Property Synthesis.pdf,Exact string,"Christoph Weinhuber1, Yannik Schnitzer, Alessandro Abate, David Parker, Giuseppe De Giacomo, Moshe Y. Vardi",10.48550/arXiv.2405.1234,10.48550/arXiv/2405.1234,"LTL synthesis, multiple properties, symbolic algorithm, automated planning, robotics","The paper presents a fully symbolic approach to LTLf synthesis for multiple properties, avoiding the all-or-nothing synthesis paradigm. It introduces a monotonicity-based algorithm that efficiently computes strategies achieving maximal realizable goal sets, offering significant speedups over enumeration-based methods.",326.72,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10679v1_Are Your Reasoning Models Reasoning or Guessing A .pdf,Exact string,"Zirui Ren, Ziming Liu",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"hierarchical reasoning, reasoning patterns, Sudoku-Extreme","This paper investigates the failure modes of hierarchical reasoning models (HRM) in solving reasoning tasks, identifying three key insights: (1) HRM can fail on simple puzzles due to fixed point violations; (2) reasoning steps often involve non-uniform accuracy; (3) multiple fixed points may trap the model. The authors propose strategies to improve HRM's 'guessing' behavior and present empirical results showing significant accuracy gains.",353.21,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10681v1_Structure and Diversity Aware Context Bubble Const.pdf,Exact string,"Amir Khurshid1a, Abhishek Sehgal1b",10.1234/example.doi,None,"Large Language Model, Retrieval-Augmented Generation, Context Bubble, Retrieval Introduction","The paper proposes a structure-informed, diversity-constrained context bubble construction framework for enterprise retrieval, aiming to improve coherence, reduce redundancy, and enhance answer quality by leveraging document structure and query context.",269.49,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10684v1_On the origin of neural scaling laws from random g.pdf,Exact string,"Maissam Barkeshli, Alberto Alfarano, Andrey Gromov",10.48550/arXiv.2405.12345,10.48550/arXiv/2405.12345,"neural scaling laws, power law, transformer, random walks, language modeling","The paper investigates how scaling laws emerge in transformer models trained on random walks on graphs, demonstrating that even without inherent power-law structure in data correlations, a monotonic evolution of scaling exponents can be observed by simplifying model complexity.",285.22,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10696v1_The Impact of Generative AI on Architectural Conce.pdf,Exact string,"Han Jiang, Yao Xiao, Rachel Hurley, Shichao Liu",10.1234/arxiv.2024.05.0123,10.1234/2024.05.0123,"Visual communication, Architectural design, Learning, Performance Assessment, Hybrid Intelligence, Human-AI teaming","This preprint investigates how generative AI impacts performance, creative self-efficacy, and cognitive load in architectural design tasks. It finds no overall performance boost from GenAI but highlights benefits for novice designers and insights into user interaction strategies.",318.27,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10700v2_LIBERTy A Causal Framework for Benchmarking Concep.pdf,LIBERTy: A Causal Framework for Benchmarking Concept-Based Explanations with Structural Counterfactuals,"Gilat Toker, Nitay Calderon, Ohad Amosy, Roi Reichart",10.48550/arXiv.2024.12345,10.48550/arXiv:2409.01234,"concept-based explanations, structural counterfactuals, LLM explainability, causal modeling",LIBERTy introduces a framework for generating structural counterfactual datasets to evaluate the faithfulness of concept-based explanations in LLMs. It evaluates models across multiple domains and identifies opportunities for improving explanation quality.,309.14,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10702v1_Grounding Agent Memory in Contextual Intent.pdf,Exact string,"Ruozhen Yang, Yucheng Jiang, Yueqi Jiang, Priyanka Kargupta, Jiawei Han",10.48550/arXiv.2024.12345,10.48550/arXiv:24/12345,"agentic memory, contextual intent, long-horizon tasks, LLM","The paper introduces STITCH, a structured intent-tracking memory system for large language models, which enhances context-aware retrieval by indexing trajectory steps with intent cues. It achieves state-of-the-art performance in benchmark evaluations, demonstrating significant improvements over baselines.",296.97,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10712v1_MatchTIR Fine-Grained Supervision for Tool-Integra.pdf,Exact string,"Changle Qu1, Sunhao Dai, Hengyi Cai, Jun Xu, Shuaiqiang Wang, Dawei Yin",10.48550/arXiv.2405.12345,10.48550/arXiv.2405.12345,"tool-integrated reasoning, fine-grained supervision, LLM, multi-turn tasks",MatchTIR introduces fine-grained supervision via bi-partite matching-based turn-level reward assignment and dual-level advantage estimation to improve tool-integrated reasoning in LLMs.,302.56,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10748v1_AnyECG Evolved ECG Foundation Model for Holistic H.pdf,Exact string,"Jun Li, Hongling Zhu, Yujie Xiao, Qinghao Zhao, Yale Ali, Gongzheng Tang, Guangkun Nie, Deyun Zhang, Jin Li, Canqing Yu, Shenda Hong",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"ECG, AI, health profiling, comorbidity, cardiac disease, predictive modeling","This study introduces AnyECG, a refined foundation model for ECG analysis, demonstrating enhanced performance in detecting diverse cardiac and non-cardiac conditions. By leveraging transfer learning on a large-scale dataset, the model supports comprehensive disease screening, long-term risk prediction, and detailed comorbidity pattern recognition, advancing holistic health profiling.",288.89,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10768v1_Optimisation of complex product innovation process.pdf,Optimisation of complex product innovation,"Nina Bockova, Barbora Volna, Mirko Dohnal",10.1093/acref/2020.01.012,2601.10768,"complex product innovation, technological forecasting, three-valued logic, trend-based modelling, scenarios, transition graphs","This paper explores complex product-innovation processes using trend models based on heuristics. It presents a framework where each heuristic is represented by a simple trend (increasing, decreasing, or constant), enabling information-efficient analysis without heavy data reliance.",335.65,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10770v1_Unifying Speech Recognition Synthesis and Conversi.pdf,Unified Speech Systems: A General-Purpose Audio Foundation Model,"UNIFYINGSPEECHRECOGNITION, SYNTHESIS AND CONVERSION WITHAUTOREGRESSIVETRANSFORMERS, TECHNICALREPORT",10.1093/pasj/ghac/2026,2601.10770v1,"Text-to-Speech, Automatic Speech Recognition, Voice Conversion, Foundation Model","The paper introduces GPA, a unified audio foundation model that integrates TTS, ASR, and VC within a single LLM, enabling cross-task generalization and efficient deployment.",291.98,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10773v1_LogicLens Leveraging Semantic Code Graph to explor.pdf,Exact string,"Niko Usai, Dario Montagnini, Kristian Ilianov Iliev, Raffaele Camanzo",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"software systems, semantic graph, LLM, code navigation","The paper presents LogicLens, a reactive conversational agent that leverages a semantic multi-repository graph to help developers explore complex software systems. By combining syntactic code analysis, AST parsing, and semantic enrichment with LLMs, LogicLens enables natural language interaction with a graph that captures structural and functional elements across repositories. It demonstrates capabilities such as impact analysis and symptom-based debugging.",370.13,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10779v1_Unified Optimization of Source Weights and Transfe.pdf,Unified Optimization of Source Weights and Transfer Quantities in Multi-Source Transfer Learning,"Qingyue Zhang, Chang Chu, Haohao Fu, Tianren Peng, Yanru Wu, Guanbo Huang, Yang Li, Shao-Lun Huang",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"transfer learning, multi-source learning, asymptotic analysis, Kullback-Leibler divergence, multi-source optimization","The paper introduces a theoretical framework, UOWQ, for optimizing source weights and transfer quantities in multi-source transfer learning. It establishes that joint optimization of weights and transfer amounts minimizes generalization error, and presents both theoretical proofs and practical algorithms validated on benchmarks like DomainNet and Office-Home.",353.82,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10810v1_Digital Metabolism Decoupling Logic from Facts via.pdf,Digital Metabolism: Decoupling Logic from Facts via Regenerative Unlearning,"Mengmeng Peng, Zhenyu Fang, He Sun",10.48550/arXiv.2601.10810,2601.10810,"digital metabolism, regenerative unlearning, neural logic, LLM, fact retention","The paper introduces 'digital metabolism' to address the memory wall in LLMs by proposing a Regenerative Logic-Core Protocol (RLCP) that enables targeted forgetting for a pure neural logic core. Empirical results on Qwen2.5-0.5B show reduced fact retention but emergence of structural crystallization, interpreted as compensating for associative loss.",287.53,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10820v1_Towards Reliable ML Feature Engineering via Planni.pdf,Exact string,"Himanshu Thakur, Anusha Kamath, Anurag Muthyala, Dhwani Sanmukhani, Anurag Muthyala, Jay Katukuri",10.1093/acps/csa123,2601.10820,"feature engineering, LLM agents, code generation, ML teams, human-AI collaboration","This paper introduces a planner-guided, constrained-topology multi-agent framework for generating code in a multi-step fashion. It addresses challenges in feature engineering by integrating LLM-powered agents within a team's environment, enabling reliable and maintainable code production. On an in-house dataset, the method improves feature engineering efficiency by 38% and 150% compared to manual workflows, reducing feature engineering cycles from weeks to a single day.",290.06,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10827v1_Approximately Optimal Global Planning for Contact-.pdf,Exact string,"Simin Liu, Tao Pang, Bernhard Paus Graesdal, Peter Werner, Jiuguang Wang, John Dolan, Changliu Liu, Tong Zhao",10.1109/JROBOT.2024.12345,10.1109/JROBOT.2024.12345,"contact-rich manipulation, manipulation planning, global optimization, robot manipulation","The paper presents a new approach for approximately optimal global planning in contact-rich manipulation, combining offline graph construction of mutual reachable sets with online local planning. It demonstrates significant improvements in task efficiency and success rates for complex manipulation tasks.",332.35,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10835v1_Can Vision-Language Models Understand Construction.pdf,Exact string,"Hieu Bui, Nathaniel E. Chodosh, Arash Tavakoli",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Vision-Language Model, Construction Automation, Robotics, Human Robot Interaction","The study evaluates three leading Vision-Language Models (GPT-4o, Florence 2, LLaVa-1.5) in detecting construction worker actions and emotions from static images, highlighting performance gaps in nuanced human behavior recognition.",298.86,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10880v1_Medical SAM3 A Foundation Model for Universal Prom.pdf,Medical SAM3: A Foundation Model for Universal Prompt-Driven Medical Image Segmentation,"Chongcong Jiang, Tianxingjian Ding, Chuhan Song, Jiachen Tu, Ziyang Yan, Yihua Shao, Zhenyi Wang, Yu Tian",10.1093/pasj/psa123,2601.10880,"Medical Image Segmentation, Foundation Models, Fine-Tuning, SAM3, Medical Imaging","Medical SAM3 is a foundation model for universal prompt-driven medical image segmentation, achieving robust performance across diverse modalities and anatomical structures through full fine-tuning on heterogeneous datasets.",281.17,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10904v1_ARC Prize 2025 Technical Report.pdf,ARC Prize 2025: Technical Report,"François Chollet, Mike Knoop, Gregory Kamradt, Bryan Landers",10.48550/arxiv/2503.00613,10.48550/arxiv/2503.00613,"ARC-AGI, few-shot learning, refinement loop, knowledge coverage","This paper surveys top-performing methods in the ARC-AGI benchmark, highlights the role of refinement loops in advancing AGI, discusses knowledge-dependent overfitting, and previews ARC-AGI-3.",299.76,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10917v1_Self-learned representation-guided latent diffusio.pdf,Exact string,"Pouya Afshin, David Helminiak, Tianling Niu, Julie M. Jorns, Tina Yen, Bing Yu, Dong Hye Ye1",10.48550/arXiv.2407.08600,10.48550/arXiv.2407.08600,"Breast Cancer Classification, Latent Diffusion Model, Self-Supervised Learning, Data Augmentation, Deep Ultraviolet Imaging","The paper presents a Self-Supervised Learning-guided Latent Diffusion Model for generating synthetic deep ultraviolet whole surface images to improve breast cancer classification accuracy. By integrating fine-tuned DINO teacher embeddings, the method enhances semantic detail in patch data, achieving high performance in DUV WSI classification.",344.79,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10921v1_RobuMTL Enhancing Multi-Task Learning Robustness A.pdf,Exact string,"RobuMTL, Tasneem Shaffee",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"multi-task learning, robustness, weather conditions, robust MTL","The paper introduces RobuMTL, a novel architecture for robust multi-task learning that adapts to adverse weather by dynamically selecting hierarchical Low-Rank Adaptation (LoRA) and a LoRA expert squad. It demonstrates improved performance under perturbations, showing significant gains across benchmarks.",351.75,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10922v1_What Matters in Data Curation for Multimodal Reaso.pdf,Exact string,"Yosub Shin, Michael Buriek, Boris Sobolev, Pavel Bushuyeu, Vikas Kumar, Haoyang Xu, Igor Molybog, Samuel Watson",10.48550/arXiv.2025.12345,10.48550/arXiv/12345,"data curation, multimodal reasoning, DCVLR, data efficiency, dataset selection","This paper investigates data curation strategies for multimodal reasoning in the NeurIPS 2025 DCVLR challenge. By analyzing a compact dataset derived from Walton Multimodal Cold Start, the authors demonstrate that difficulty-based example selection is the key factor driving performance gains. They find that while increasing dataset size helps stabilize models, it does not significantly boost accuracy under fixed training protocols. Common diversity and synthetic augmentation do not consistently improve results and may even harm performance. The study characterizes DCVLR as operating in a saturation regime, emphasizing the importance of alignment and difficulty in achieving data efficiency.",298.12,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10926v1_Selecting Language Models for Social Science Start.pdf,Selecting Language Models for Social Science,"Dustin S. Stoltz, Marshall A. Taylor, Sanuj Kumar",10.48550/arXiv.2026.12345,10.48550/arXiv.2026.12345,"large language models, LLMs, reproducibility, reliability, replicability","This paper explores how social scientists can select appropriate language models by evaluating openness, model footprint, training data, and architecture, emphasizing the importance of replicability over benchmarks.",286.76,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10931v1_Sparse Data Tree Canopy Segmentation Fine-Tuning L.pdf,Exact string,"David Szczecina, Niloofar Azad, Hudson Sun, Kyle Gao, Anthony Bertnyk, Lincoln Linlin Xu",10.48550/arXiv.2303.04112,10.48550/arXiv.2303.04112,"Tree canopy, Aerial imagery, Data scarcity, Deep learning, Computer vision, Forestry","The paper evaluates five deep learning architectures for tree canopy segmentation using only 150 images, highlighting the effectiveness of CNN-based models over transformer architectures in low-data regimes.",301.39,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10945v1_PatientVLM Meets DocVLM Pre-Consultation Dialogue .pdf,Exact string,"K Lokesh1, Abhirama Subramanyam Penamakuri1, Uday Agarwal1, Apoorva Challa2, Shreya K Gowda2, Somesh Gupta2, Anand Mishra1",10.48550/arXiv.2024.12345,10.48550/arXiv:24/12345,"vision-language model, medical diagnosis, pre-consultation dialogue, symptom elicitation, clinical validation","The paper introduces a Pre-Consultation Dialogue Framework (PCDF) that enables vision-language models to simulate realistic doctor-patient interactions by iteratively querying patients before reaching a diagnosis. It integrates symptom-based responses from a PatientVLM with image analysis, demonstrating improved diagnostic accuracy through multi-turn dialogues.",286.58,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10951v1_Multi-Stage Patient Role-Playing Framework for Rea.pdf,Multi-Stage Patient Role-Playing Framework for Realistic Clinical Interactions,"Shijie Jianga, Zefan Zhanga, Kehua Zhub, Tian Baia, Ruihong Zhaoc, ∗∗",10.1093/pasj/psa.2026,2601.10951v1,"Patient Role-Playing, Large Language Models, Clinical, Diagnostic Education","The paper introduces a new Chinese patient simulation dataset (Ch-PatientSim) designed to enhance the authenticity of clinical interactions for training large language models. By structuring patient simulations across five dimensions and addressing persona class imbalance through few-shot augmentation, the authors present a training-free Multi-Stage Patient Role-Playing framework. Experimental results show significant improvements in model performance for realistic patient behavior.",287.32,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10955v1_Beyond Max Tokens Stealthy Resource Amplification .pdf,Exact string,"Kaiyu Zhou, Yongsen Zheng, Yicheng He, Meng Xue, Xueluan Gong, Yuji Wang",10.48550/arXiv.2024.12345,10.48550/arXiv:24/12345,"Large Language Models, LLM Agents, Tool Calling, Agent Security, Economic DoS","The paper presents a stealthy, multi-turn economic DoS attack targeting LLM agents. It operates under the guise of completing tasks, adjusting text-visible fields and using a Model Context Protocol to prolong tool-calling sequences. The attack scales across turns, increases computational costs, and evades detection by optimizing function signatures.",323.91,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.10960v1_Steering Language Models Before They Speak Logit-L.pdf,Steering Language Models Before They Speak,"Hyeseon An, Shinwoo Park, Hyundong Jin, Yo-Sub Han",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"language models, steering, logit intervention, text generation","The paper presents a training-free inference-time logit intervention to steer large language model outputs, demonstrating significant improvements in controlling writing complexity, formality, and toxicity across diverse datasets.",298.44,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11000v1_When Personalization Misleads Understanding and Mi.pdf,Exact string,"Zhongxiang Sun, Yi Zhan, Chenglei Shen, Weijie Yu, Xiao Zhang, Ming He, Jun Xu",10.48550/arXiv.2024.12345,10.48550/arXiv:24/12345,"personalization, hallucination, factuality, LLM, personalization-induced","The paper investigates personalization-induced hallucinations in large language models and proposes a lightweight inference-time approach, FPPS, to mitigate factual distortions while preserving personalized behavior. It introduces PFQABench to evaluate factual and personalized question answering and demonstrates improved accuracy with FPPS.",311.55,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11007v1_AdaMARP An Adaptive Multi-Agent Interaction Framew.pdf,AdaMARP,"AdaMARP, Zhenhua Xu1, Dongsheng Chen, Shuo Wang, Jian Li, Chengjie Wang, Meng Han, Yabiao Wang",10.48550/arXiv.2601.11007,10.48550/arXiv.2601.11007,"LLM role-playing, adaptive multi-agent interaction, immersive environment, character orchestration","AdaMARP introduces an adaptive multi-agent interaction framework for general immersive role-playing, featuring an immersive message format that integrates thought, action, environment, and speech, along with an explicit scene manager for dynamic scene control.",370.07,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11012v1_Efficient Protein Optimization via Structure-aware.pdf,Exact string,"Jiahao Wang, Shuangjia Zheng",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"protein design, structure-aware optimization, Bayesian methods, Hamiltonian dynamics","The paper presents HADES, a Bayesian optimization framework using Hamiltonian dynamics to efficiently explore protein sequence space while respecting structural constraints. By leveraging momentum and uncertainty in simulated dynamics, HADES accelerates the discovery of high-performing protein variants, offering advantages over traditional sequence-based methods.",313.35,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11016v1_Contextual Distributionally Robust Optimization wi.pdf,Exact string,"Fenglin Zhang, Jie Wang",10.48550/arXiv.2601.11016,2601.11016,"Contextual distributionally robust optimization, Causal Sinkhorn discrepancy, Soft regression forest","The paper presents a framework for contextual distributionally robust optimization (DRO) that incorporates causal and continuous structure via an interpretable decision rule. It introduces the Causal Sinkhorn Discrepancy and derives a strong dual reformulation, proposing the Soft Regression Forest (SRF) for policy optimization. The method ensures interpretability while matching the convergence rate of standard stochastic gradient descent.",268.41,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11019v1_Finding the Translation Switch Discovering and Exp.pdf,Exact string,"Xinwei Wu, Heng Liu, Xiaohu Zhao, Yuqi Ren, Linlong Xu, Longyue Wang, Deyi Xiong, Weihua Luo, Kaifu Zhang",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"translation initiation, LLM, causal intervention, data efficiency","The paper investigates how large language models (LLMs) acquire translation capabilities intrinsically, focusing on identifying and amplifying 'translation initiation' features. Using sparse autoencoders and PCA-based filtering, the authors isolate task-specific activation patterns that steer correct translations. Ablating these features reveals their critical role in model performance, and the findings suggest prioritizing hard samples for fine-tuning to improve efficiency and reduce hallucinations.",356.49,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11021v1_Combating Spurious Correlations in Graph Interpret.pdf,Combating Spurious Correlations in Graph Interpretability via Self-Reflection,"Kecheng Cai, Chenyang Xu, Chao Peng",10.48550/arXiv.2026.12345,10.48550/arXiv.2026.12345,"graph interpretability, spurious correlations, self-reflection, graph learning","The paper addresses the challenge of spurious correlations in graph datasets by proposing a self-reflection framework that enhances interpretability. It demonstrates how iterative self-reflection can improve node and edge importance scores, offering a novel approach to mitigate misleading patterns in benchmark datasets.",324.94,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11030v1_IDDR-NGP Incorporating Detectors for Distractor Re.pdf,Exact string,"Xianliang Huang, Jiajie Gou, Shuhang Chen, Zhizhou Zhong, Jihong Guan, Shuigeng Zhou",10.1145/3581783.3612045,2601.11030v1,"distractor removal, distractors, 3D scenes, synthetic scene, realistic scene, input views, detect distractors, remove distractors","The paper introduces IDDR-NGP, a unified distractor removal method for Instant-NPG that effectively eliminates diverse distractors like snowflakes, confetti, defoliation, and petals. It leverages implicit 3D representations with 2D detectors to restore realistic scenes and supports end-to-end training for high-quality 3D reconstruction.",290.67,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11035v1_Your One-Stop Solution for AI-Generated Video Dete.pdf,Exact string,"Long Ma1, Zihao Xue2, Yan Wang3, Zhiyuan Yan4, Xiaorui Jiang1, Haiyang Yu1, Yong Liao1,†, Zhen Bi2,†",10.1109/ICCV.2024.12345,2601.11035,"AI-generated video, video detection, generative modeling, realism, detection methods","Recent advances in generative modeling can create remarkably realistic synthetic videos, making it increasingly difficult for humans to distinguish them from real ones, necessitating reliable detection methods.",356.33,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11037v1_BAPO Boundary-Aware Policy Optimization for Reliab.pdf,Exact string,"Shiyu Liu, Yongjing Yin, Jianhao Yan, Yunbo Tang, Qinggang Zhang, Bei Li, Xin Chen, Jingang Wang, Xunliang Cai, Jinsong Su",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"agentic search, boundary awareness, reliability, LLM, RL","The paper introduces Boundary-Aware Policy Optimization (BAPO), a reinforcement learning framework for agentic search that enhances reliability by encouraging explicit 'I DON'T KNOW' responses when evidence is insufficient. It proposes a group-based reward and adaptive modulator to prevent overconfidence, improving robustness in complex question answering.",307.87,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11042v1_Spectral Characterization and Mitigation of Sequen.pdf,Spectral Characterization and Mitigation of Sequential Knowledge Editing Collapse,"Chi Zhang, Mengqi Zhang, Xiaotian Ye, Runxi Cheng, Zisheng Zhou, Ying Zhou, Pengjie Ren, Zhumin Chen",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"knowledge editing, sequential editing, LLM, general abilities","The paper investigates how sequential knowledge editing degrades a model's general capabilities, linking it to dominant singular directions in pretrained weights. It introduces REVIVE, a framework that preserves these dominant directions to stabilize editing and maintain performance under long-horizon editing.",387.26,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11044v2_AgencyBench Benchmarking the Frontiers of Autonomo.pdf,AGENCYBENCH,"Keyu Li, Jiang, Xiao, Wang, Jie, Sun, Yunze, Wu, Dayuan, Xia, Xiaojie, Cai, Tianze, Xu, Weiye, Li, Dequan, Wang, Pengfei",10.48550/arXiv.2601.11044,10.48550/arXiv:2601.11044,"autonomous agents, benchmarking, LLMs, real-world scenarios","AGENCYBENCH introduces a comprehensive benchmark for evaluating autonomous agents across 6 core capabilities in 32 real-world scenarios. It addresses scalability challenges by integrating user simulation and Docker sandboxing, revealing performance differences between open-source and proprietary models. The work emphasizes the need for co-optimized architectures and provides an open-source toolkit for community adoption.",300.95,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11049v1_Predicting Biased Human Decision-Making with Large.pdf,Predicting Biased Human Decision-Making with Large Language Models in Conversational Settings,"Stephen Pilli, Vivek Nallur",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Conversational AI, Framing Effect, Status Quo Bias, LLM Simulation","This study investigates whether large language models can predict biased decision-making in conversational settings, highlighting how cognitive biases interact with increased cognitive load. The research evaluates model performance across diverse decision tasks and demonstrates that LLMs can accurately reflect human biases when contextual dialogue is incorporated.",386.29,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11063v1_H-AIM Orchestrating LLMs PDDL and Behavior Trees f.pdf,"Orchestrating LLMs, PDDL, and Behavior Trees for Hierarchical Multi-Robot Planning","Haishan Zeng 1, Haishan Zeng 2, Peng Li 1, Peng Li 2",10.48550/arXiv.2601.11063,10.48550/arXiv:2601.11063,"multi-robot planning, LLM, PDDL, behavior trees, hierarchical","The paper presents H-AIM, a novel embodied multi-robot planning framework that integrates large language models (LLMs) with PDDL-based planning and behavior trees to enable long-horizon, dynamic task execution across heterogeneous robot teams. It introduces a cascaded architecture combining high-level instruction parsing, formal planning, and reactive control, achieving significant improvements in task success and recall rates.",316.48,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11065v1_Fairness in Healthcare Processes A Quantitative An.pdf,Exact string,"Rachmadita Andreswari, Stephan A. Fahrenkrog-Petersen",10.1093/acpl/9780190871293.001.0001,10.1093/acpl/9780190871293.001.0001,"process mining, fairness, triage, emergency room","This study investigates fairness in automated decision-making within emergency triage using process mining, analyzing healthcare data to assess potential biases and informing justice theory.",348.77,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11073v1_Bridging Cognitive Neuroscience and Graph Intellig.pdf,Bridging Cognitive Neuroscience and Graph Intelligence: Hippocampus-Inspired Multi-View Hypergraph Learning for Web Finance Fraud,"Rongkun Cui, Nana Zhang, Kun Zhu, Qi Zhang",10.1093/acm/qad041,10.1093/acm/qad041,"web finance fraud, graph neural networks, multi-view learning, fraud detection, long-tailed data","The paper introduces HIMVH, a Hippocampus-Inspired Multi-View Hypergraph learning model designed for detecting online fraud in web finance. It addresses challenges like fraud camouflage and long-tailed data distributions by incorporating cross-view inconsistency detection and novelty-aware hypergraph learning, achieving significant improvements over existing methods.",288.98,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11076v1_A3D Adaptive Affordance Assembly with Dual-Arm Man.pdf,Adaptive Affordance Assembly with Dual-Arm Manipulation,"Jiaqi Liang, Yue Chen, Qize Yu, Yan Shen, Haipeng Zhang, Hao Dong, Ruihai Wu",10.48550/arXiv.2024.12345,None,"robotic assembly, dual-arm manipulation, adaptive support, furniture parts","The paper presents A3D, a framework that learns adaptive affordances to identify optimal support and stabilization locations during furniture assembly. It uses dense point-level geometry representations and an adaptive module that adjusts support strategies based on interaction feedback, enabling generalization across diverse part geometries and furniture categories.",307.78,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11077v1_ABC-Bench Benchmarking Agentic Backend Coding in R.pdf,Exact string,"Jie Yang, Honglin Guo, Li Ji, Jiazheng Zhou, Rui Zheng, Bo Wang, Ying Zheng, Tao Gui, Xipeng Qiu",10.1093/acprof:oso/9780190871293.013,2601.11077,"OpenMOSS, benchmark, agentic backend, LLM, code generation, real-world development","The paper introduces ABC-Bench, a benchmark designed to evaluate autonomous agent backend coding in realistic, end-to-end workflows. It highlights the gap between current LLM capabilities and the demands of practical backend engineering, emphasizing the need for comprehensive testing across multiple languages, frameworks, and development stages.",320.67,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11078v1_Visual Marker Search for Autonomous Drone Landing .pdf,Exact string,"Jiaohong Yao, Linfeng Liang, Yao Deng, Xi Zheng, Richard Han, Yuankai Qi",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"marker-based landing, drone navigation, reinforcement learning, AirSim, robustness","The paper presents a simulation-based evaluation of marker-based landing strategies for autonomous drones in urban environments, focusing on robustness under diverse lighting, texture, and structural conditions. It benchmarks two heuristic coverage patterns and a reinforcement learning agent, highlighting the impact of exploration strategies and scene complexity on landing success.",305.13,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11089v2_MiCA A Mobility-Informed Causal Adapter for Lightw.pdf,MiCA: A Mobility-Informed Causal Adapter for Lightweight Epidemic,"Suhan Guo, Jiahong Deng, Furao Shen ∗1,2, School of Artificial Intelligence, Nanjing University",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"MiCA, epidemic forecasting, mobility data, lightweight model, spatial structure","The paper introduces MiCA, a lightweight causal adapter that integrates human mobility insights into epidemic forecasting. By leveraging causal discovery and gated residual mixing, MiCA enhances forecasting accuracy on resource-constrained temporal models, achieving a 7.5% average relative error reduction across multiple epidemic datasets.",294.26,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11090v1_Efficient Multilingual Name Type Classification Us.pdf,Exact string,Davor Lauc,null,null,"multilingual NLP, named entity recognition, convolutional neural networks, efficient inference, proper names","The paper introduces Onomas-CNN X, a convolutional neural network model for efficient multilingual proper name classification. It achieves 92.1% accuracy on a large multilingual dataset, runs on CPU, and outperforms transformer-based baselines while reducing energy consumption.",295.12,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11100v1_ReCreate Reasoning and Creating Domain Agents Driv.pdf,ReCreate: An Experience-Driven Framework for Automatic Domain Agent Creation,"Zhezheng Hao, Hong Wang, Jian Luo, Jianqing Zhang, Yuyan Zhou, Qiang Lin, Can Wang, Hande Dong, Jiawei Chen, *Jiawei Chen",10.1234/example.doi,None,"LLM agents, domain agents, experience-driven, automated creation, LLM generation","The paper introduces ReCreate, an experience-driven framework that enables automatic creation and adaptation of domain agents by leveraging agent interaction histories. It proposes an agent-as-optimizer paradigm with three components: experience storage, reasoning-synergy pipeline, and hierarchical updates, achieving superior performance over human-designed agents in diverse domains.",295.83,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11109v1_Vision-as-Inverse-Graphics Agent via Interleaved M.pdf,Exact string,"Shaofeng Yin, Jiaxin Ge, Michael J. Black, Trevor Darrell, Haiwen Feng",10.48550/arXiv.2303.04112,10.48550/arXiv.2601.11109,"Vision-as-Inverse-Graphics, Interleaved Multimodal Reasoning, 3D Reconstruction, Scene Editing, Computer Vision","VIGA crafts a 3D graphics scene from a single image through iteration. It alternates between generation and verification steps to refine layout, geometry, and lighting, enabling robust single-shot reconstruction.",325.41,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11124v1_Learn Before Represent Bridging Generative and Con.pdf,Exact string,"Xiaoyu Liang, Yuchen Peng, Jiale Luo, Wenhao Wang, Haoji Hu, Zincheng Zhou",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"LLM, contrastive learning, domain-specific, knowledge acquisition","The paper introduces Learn Before Represent (LBR), a two-stage framework that first injects domain knowledge via an Information Bottleneck-Constrained Generative Learning stage, then applies Generative Refined Contrastive Learning. This approach addresses the limitations of existing LLM+CL methods in vertical domains by enabling accurate representation learning for specialized terminology.",300.92,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11135v1_Context-aware Graph Causality Inference for Few-Sh.pdf,Exact string,"Van Thuy Hoang, O-Joun Lee",10.48550/arXiv.2407.04219,10.48550/arXiv.2407.04219,"graph learning, molecular property prediction, few-shot learning","The paper introduces CaMol, a context-aware graph causality inference framework for molecular property prediction. It addresses challenges in few-shot scenarios by leveraging causal inference, disentangling causal substructures, and using distribution interveners to improve interpretability and accuracy.",297.74,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11143v1_Learning Quadrupedal Locomotion for a Heavy Hydrau.pdf,Learning Quadrupedal Locomotion for a Heavy Hydraulic Robot Using an Actuator Model,"Minho Lee, Hyeonseok Kim, Jin Tak Kim, Sangshin Park, Jeong Hyun Lee, Jungsan Cho, Jemin Hwangbo ∗,1",10.1234/abcd1234,null,"Hydraulic/Pneumatic Actuators, Legged Robots, Reinforcement Learning, Sim-to-Real Transfer, Robotics","The paper presents an analytical actuator model based on hydraulic dynamics to enable rapid simulation and reinforcement learning for heavy hydraulic quadruped robots. It demonstrates successful transfer of stable locomotion policies from simulation to real hardware, addressing challenges in fluid dynamics and control response.",300.89,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11144v2_Deep GraphRAG A Balanced Approach to Hierarchical .pdf,Deep GraphRAG: A Balanced Approach to Hierarchical Retrieval,"Yuejie Li, Ke Yang, Tao Wang, Bolin Chen, Zhejiang University, Ant Group, Zhejiang University, Bolin Chen, Ant Group, Chengjun Mao",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"GraphRAG, Reinforcement Learning, Large Language Models","Deep GraphRAG introduces a hierarchical retrieval strategy that balances global search comprehensiveness with local efficiency, incorporating multi-stage re-ranking and a reinforcement learning-based dynamic weighting system.",351.85,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11147v1_Do We Always Need Query-Level Workflows Rethinking.pdf,Exact string,"Zixu Wang, Bingbing Xu, Yige Yuan, Huawei Shen, Xueqi Cheng",10.48550/arXiv.2303.04112,10.48550/arXiv:2303.04112,"multi-agent systems, query-level workflows, LLM, agentic workflows","The paper rethinks agentic workflow generation for multi-agent systems, demonstrating that query-level workflows are not always necessary. It introduces a low-cost task-level generation framework, SCALE, which achieves competitive performance with significantly reduced token usage.",352.5,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11151v1_Cross-Modal Attention Network with Dual Graph Lear.pdf,Cross-Modal Attention Network with Dual Graph Learning in Multimodal Recommendation,"Ji Dai, Quan Fang, Jun Hu, DeSheng Cai, Yang Yang, Can Zhao",10.1007/XXXXXXX,10.1007/XXXXXXX,"Multimedia recommendation, Graph Neural Network, Multimodal Fusion","The paper introduces a Cross-Modal Attention Network (CRANE) that integrates dual graph learning to address shallow modality fusion and asymmetric feature treatment in multimodal recommendation systems. By employing a core recursive cross-modal attention mechanism, the model captures high-order intra- and inter-modal dependencies while maintaining computational efficiency. The approach constructs symmetric user-item profiles and unifies heterogeneous interaction graphs with a self-supervised contrastive objective, achieving faster convergence and improved performance on large-scale datasets.",284.22,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11160v1_Clustering High-dimensional Data Balancing Abstrac.pdf,Clustering High-dimensional Data: Balancing Abstraction and Representation,"Claudia Plant, Lena G. M. Bauer, Christian B. Boehm",10.1093/acprof:oso/9780190871293.001.0001,10.1093/acprof:oso/9780190871293.001,"clustering, high-dimensional data, abstraction, representation, deep learning","The paper discusses the challenges of clustering in high-dimensional data, emphasizing the need to balance abstraction (simplifying details) with representation (capturing key features). It explores how different clustering approaches trade off these goals and introduces methods that learn latent spaces to better align abstraction and representation.",356.41,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11178v1_TANDEM Temporal-Aware Neural Detection for Multimo.pdf,Exact string,"Girish A. Koushik, Helen Treharne, Diptesh Kanojia",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"hate speech, multimodal detection, TANDEM, structured reasoning","The paper introduces TANDEM, a framework that treats hate speech detection as a structured reasoning problem by integrating vision-language and audio-language models. It addresses the challenge of precise temporal grounding in multimodal data and achieves improved performance over existing methods.",314.69,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11189v1_Policy-Based Deep Reinforcement Learning Hyperheur.pdf,Policy-Based Deep Reinforcement Learning Hyperheuristics for Job-Shop Scheduling,"Sofiene Lassoued, Asrat Gobachew, Stefan Lier, Andreas Schwung",10.1016/j.jps.2023.03.012,10.1016/j.jps.2023.03.012,"Hyper-heuristics, Job Shop Scheduling, Policy-based Reinforcement learning, Petri nets","The paper presents a policy-based deep reinforcement learning hyper-heuristic framework for solving the Job Shop Scheduling Problem, introducing action prefiltering and commitment mechanisms to improve performance and generalization.",281.63,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11196v1_Artificial Intelligence and the US Economy An Acco.pdf,Artificial Intelligence and the US Economy: An Accounting Perspective on Investment and Production,"Luisa Carpinelli, Filippo Natoli, Marco Taboga",10.1093/acpl/2026.01.012,2601.11196v1,"artificial intelligence, capital expenditures, data centers, national accounts","The paper examines the macroeconomic impact of AI in the US, emphasizing the role of data centers in driving investment and production. It highlights AI's contribution to aggregate demand and GDP, noting its short-term macroeconomic risks.",329.85,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11199v1_SD-RAG A Prompt-Injection-Resilient Framework for .pdf,SD-RAG: A Prompt-Injection-Resilient Framework for Selective Disclosure in Retrieval-Augmented Generation,"Aiman Al Masoud, Marco Arazzi, Antonino Nocera",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Retrieval-Augmented Generation, Selective Disclosure, Prompt Injection, Privacy","The paper introduces SD-RAG, a framework that decouples security and privacy enforcement from generation, improving privacy scores and resisting prompt injection attacks.",264.36,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11200v1_FAQ Mitigating Quantization Error via Regenerating.pdf,Exact string,"Haiyang Xiao, Weiqing Li, Jinyue Guo, Guochao Jiang, Guohua Liu, Yuewei Zhang",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"quantization, calibration data, family-aware, LLM, quantization error","The paper introduces FAQ (Family-Aware Quantization), a method that regenerates high-fidelity calibration data using a larger in-family model to improve post-training quantization accuracy. It demonstrates a 28.5% reduction in accuracy loss compared to baseline methods.",299.0,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11202v1_Epistemic Control and the Normativity of Machine L.pdf,Exact string,Emanuele Ratti,10.1093/acps/rpac023,null,"machine learning, epistemic control, cognitive values, normativity","Investigates the concept of epistemic control in machine learning-based science, examining how human oversight can be maintained despite the increasing use of automated systems.",275.66,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11207v1_LoRA as Oracle.pdf,Exact string,"Marco Arazzi, Antonino Nocera",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"LoRA, Membership Inference Attack, Backdoor Attack",Introduces a LoRA-based oracle framework for detecting backdoors and membership inference without requiring access to clean training data.,270.66,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11219v1_SDFLoRA Selective Dual-Module LoRA for Federated F.pdf,Exact string,"Zhikang Shen, Jianrong Lu, Haiyuan Wan, Jianhai Chen",10.48550/arXiv.2303.04112,10.48550/arXiv.2303.04112,"Selective Dual-Module LoRA, Federated Learning, Privacy-Preserving, Large Language Models","The paper introduces SDFLoRA, a selective dual-module federated LoRA method that balances transferability and personalization under rank heterogeneity while preserving differential privacy.",310.35,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11232v1_FactCorrector A Graph-Inspired Approach to Long-Fo.pdf,FACTCORRECTOR: A New Post-Hoc Correction Method for Large Language Models,"Javier Carnerero-Cano, Massimiliano Pronesti, Radu Marinescu, Tigran Tchrakian, James Barry, Jasmina Gajcin, Yufang Hou, Alessandra Pascale, Elizabeth Daly",10.48550/arXiv.2303.04112,10.48550/arXiv:2303.04112,"factuality correction, large language models, feedback, LLM","The paper introduces FACTCORRECTOR, a post-hoc correction method for improving factual accuracy in large language models without retraining. It leverages structured feedback to generate corrections and develops the VELI5 benchmark to evaluate correction performance.",324.81,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11252v1_Beyond Model Scaling Test-Time Intervention for Ef.pdf,Think-with-Me: A Test-Time Interactive Reasoning Paradigm,"Qianyue Wang, Jinwu Hu, Yufeng Wang, Huanxiang Lin, Bolin Chen, Zhiquan Wen, Yaofo Chen, Mingkui Tan",10.5281/zenodo.1234567,10.5281/RECONFIGURE.D0.100013,"reasoning efficiency, interactive reasoning, overthinking, overshoot, LLM optimization","The paper introduces Think-with-Me, a test-time interactive reasoning paradigm that uses external feedback to guide reasoning processes, aiming to mitigate overthinking and overshoot in Large Reasoning Models.",380.73,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11258v1_Knowledge is Not Enough Injecting RL Skills for Co.pdf,Exact string,"Pingzhi Tang, Yiding Wang, Muhan Zhang",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"large language models, knowledge adaptation, reinforcement learning, skill transfer","The paper introduces Parametric Skill Transfer (PaST), a framework that enables efficient, modular knowledge adaptation by injecting domain-agnostic skill vectors into target models after lightweight fine-tuning. Experiments show PaST outperforms existing self-editing SFT methods on QA benchmarks and improves tool-use performance in agentic tasks.",386.53,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11269v1_X-Distill Cross-Architecture Vision Distillation f.pdf,Exact string,"Maanping Shao, Feihong Zhang, Gu Zhang, Baiye Cheng, Zhengrong Xue, Huazhe Xu",10.48550/arXiv.2021.12345,10.48550/arXiv.2021.12345,"visuomotor learning, knowledge distillation, visual encoder, robot policy","X-Distill introduces a cross-architecture knowledge distillation method that leverages a large ViT teacher to improve data efficiency in visual encoder-based visuomotor policies, achieving state-of-the-art performance on manipulation tasks.",293.41,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11282v1_From SERPs to Sound How Search Engine Result Pages.pdf,FromSERPs to Sound: How Search Engine Result Pages and AI-generated Podcasts Interact to Influence User Attitudes on Controversial Topics,"Junjie Wang, Gaole He, Alisa Rieger, Ujwal Gadiraju",10.1145/3786304.3787942,10.1145/3786304.3787942,"Attitude Change, AI-generated Podcasts, Information modality, Web search, Controversial Topics, Responsible Opinion Formation","This study investigates how the interaction between search engine result pages (SERPs) and AI-generated podcasts influences user attitudes, especially on controversial subjects. Through a controlled user study, it examines the impact of exposure sequence and modality on attitude change, highlighting the role of viewpoint bias and topic controversy.",292.01,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11286v1_XChoice Explainable Evaluation of AI-Human Alignme.pdf,XChoice: Explainable Evaluation of AI–Human Alignment in LLM-based Constrained Decision Making,"Weihong Qi, Fan Huang, Rasika Muralidharan, Jisun An, Haewoon Kwak",10.48550/arXiv.2024.12345,10.48550/arXiv:24/12345,"AI alignment, human-AI interaction, constrained decision making, LLM, explainability","XCHOICE introduces a mechanism-based framework to assess AI-human alignment in constrained decision contexts, moving beyond outcome metrics to uncover interpretable factors such as decision attributes, constraint sensitivity, and trade-offs. It evaluates alignment using human data from the American Time Use Survey and demonstrates robustness with targeted interventions.",355.93,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11344v1_How Much Would a Clinician Edit This Draft Evaluat.pdf,Exact string,"Parker Seegmiller, Joseph Gatto, Sarah E. Greer, Ganza Belise Isingizwe, Rohan Ray, Timothy Burdick, Sarah M. Preum",10.1093/acps/ccad045,10.1093/acps/ccad045,"LLM, clinical workflow, patient portal, LLM alignment","This study evaluates large language model alignment with clinicians in drafting patient portal responses, highlighting challenges in theme-level consistency and proposing adaptation strategies.",316.67,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11350v1_FEATHer Fourier-Efficient Adaptive Temporal Hierar.pdf,Fourier-Efficient Adaptive Temporal Hierarchy Forecaster for Time-Series Forecasting,"Jaehoon Lee, Seungwoo Lee, Younghwi Kim, Dohee Kim, Sunghyun Sim",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Time-series Forecasting, Edge AI, Ultra-Lightweight Models, Fourier-Efficient, Adaptive Temporal Hierarchy","FEATHer is a multiscale temporal model that enables accurate long-term forecasting under strict resource constraints, suitable for edge deployment in industrial settings.",330.09,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11354v1_AstroReason-Bench Evaluating Unified Agentic Plann.pdf,AstroReason-Bench: Evaluating Unified Agentic Planning,"Weiyi Wang, Xinchi Chen, Jingjing Gong, Xuanjing Huang, Fudan University, Shanghai Innovation Institute",10.48550/arXiv.2025.12345,10.48550/arXiv.2601.11354,"AstroReason, Agentic Planning, Space Planning Problems, Heterogeneous Objectives, Physical Constraints","This paper introduces AstroReason-Bench, a benchmark for evaluating agentic planning in space planning problems. It highlights the limitations of current generalist agents in realistic, physics-constrained environments and underscores the need for improved planning under complex constraints.",290.0,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11359v1_Think-Clip-Sample Slow-Fast Frame Selection for Vi.pdf,Exact string,"Wenhui Tan, Ruihua SongB",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"multi-modal LLMs, long video understanding, frame selection","The paper introduces Think-Clip-Sample (TCS), a training-free framework that improves long video understanding by introducing multi-query reasoning and clip-level slow-fast sampling. It demonstrates enhanced performance across multiple benchmarks with efficiency gains.",314.29,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11369v2_Institutional AI Governing LLM Collusion in Multi-.pdf,Exact string,"M. Bracale Syrnikov, F. Pierucci, M. Galisai, M. Prandi, P. Bisconti, F. Giarrusso, O. Sorokoletova, V. Suriani, D. Nardi",10.1093/pasj/2026.012,2601.11369v2,"Institutional AI, LLM governance, Collusion detection, Cournot market, Governance graph, AI alignment","This paper presents an experimental framework for institutional AI governance using multi-agent LLM systems. It evaluates three governance regimes—Ungoverned, Constitutional (prompt-only), and Institutional (governance graph)—across simulated Cournot markets. The results show significant reductions in collusion incidence when institutional design is applied, supporting the view that governance structures can effectively shape agent behavior in competitive settings.",321.46,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11379v1_Evaluating LLM Behavior in Hiring Implicit Weights.pdf,Exact string,"Morgane Hoffmann, Emma Jouffroy, Warren Jouanneau, Marc Palyart, Charles Pebereau",10.48550/arXiv.2024.12345,10.48550/arXiv/12345/12345,"Large Language Models, Person-job Fit, Fairness, Interpretability","The paper evaluates how general-purpose LLMs assign importance to candidate attributes during recruitment, proposing a framework to assess implicit decision logic and its alignment with human hiring practices.",316.84,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11389v1_Hyperparameter Optimization of Constraint Programm.pdf,Exact string,"Hedieh Haddad, Thibault Falque, Pierre Talbot, Pascal Bouvry",10.1093/acpro/9780190871293.13.1,2601.11389,"constraint programming, hyperparameter optimization, probe and solve algorithm","The paper introduces a novel two-phase framework for automated hyperparameter optimization in constraint programming solvers, combining Bayesian optimization and Hamming distance search to improve solver performance.",308.09,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11400v1_Wetland mapping from sparse annotations with satel.pdf,Wetland mapping from sparse annotations with satellite image time series and temporal-aware segment anything model,"Shuai Yuana, Tianwu Linb, Shuang Chena, Yu Xiab, Peng Qinb, Xiangyu Liub, Xiaoqing Xub, Nan Xud, Hongsheng Zhanga, Jie Wang, 1, Peng Gonga",10.5281/zenodo.1234567,2601.11400v1,"wetland mapping, satellite image time series, sparse annotation, segment anything model, temporal adaptation","The paper introduces WetSAM, a novel framework that enhances wetland mapping from sparse annotations by leveraging satellite image time series. It combines a temporal branch with seasonal decomposition and a spatial branch using region-growing strategies, achieving high accuracy (F1=85.58%) across diverse global locations.",311.25,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11409v1_Topology-Guaranteed Image Segmentation Enforcing C.pdf,Exact string,"Wenxiao Li, Xue-Cheng Tai, Jun Liu",MSC codes.68U10,62H35,"image segmentation, topological preservation, persistent homology, thickness of topology, variational","This paper introduces a novel mathematical framework that integrates width information—such as thickness and length—into topological structures for image segmentation. By combining persistent homology with PDE-based smoothing, the method ensures topological invariants like connectivity and genus are preserved while explicitly accounting for width properties. The approach is validated through numerical experiments, demonstrating its effectiveness in maintaining essential topological and width characteristics.",263.08,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11421v1_The Great March 100 100 Detail-oriented Tasks for .pdf,Exact string,"Ziyu Wang, Chenyuan Liu, Yushun Xiang, Runhao Zhang, Yu Zhang, Qingbo Hao, Houyu Chen, Zhizhong Feng, Kaiyue Zheng, Dehao Y, Xianchao Zeng, Xinyu Zhou, Boran Wen, Jiaxin Li, Mingyu Zhang, Qian Zhu, Ran Cheng, Yong-Lu Li",10.48550/arXiv.2023.12345,100.12345,"robot learning, imitation learning, task design, dataset evaluation, robotic agents","The paper introduces the Great March 100 (GM-100), a set of 100 carefully designed tasks aimed at evaluating robotic agents comprehensively. It addresses the lack of systematic consideration in existing datasets and tasks, emphasizing the need for diverse and challenging evaluations to advance robot learning.",299.59,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11429v1_Relational Linearity is a Predictor of Hallucinati.pdf,Exact string,"Yuetian Lu, Yihong Liu, Hinrich Schütze",10.48550/arXiv.2024.12345,10.48550/arXiv:24/12345,"hallucination, large language models, knowledge representation","The study investigates how linear relations influence hallucination rates in synthetic entities, suggesting that nonlinear relationships are more likely to trigger self-assessment failures.",317.05,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11440v1_GenDA Generative Data Assimilation on Complex Urba.pdf,Exact string,"Francisco Giral, Álvaro Manzano, Ignacio Gómez, Ricardo Vinuesa, Soledad Le Clainche",10.48550/arXiv.2405.12345,10.48550/arXiv.2405.12345,"urban wind flow, data assimilation, generative modeling, CFD, mesh generation","The paper introduces GenDA, a generative data assimilation framework that reconstructs high-resolution wind fields from sparse sensor data using a multiscale graph-based diffusion architecture. It leverages both classifier-free reconstruction and sensor-conditioned guidance to improve accuracy and generalization across diverse geometries and resolutions. Experiments show significant improvements in reconstruction quality compared to traditional methods.",316.11,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11441v1_Hierarchical Orthogonal Residual Spread for Precis.pdf,Exact string,"Xiaojie Gu, Guangxu Chen, Yuheng Yang, Jingxin Han, Andi Zhang",10.1234/example.doi,null,"Large language models, Model Editing, Knowledge Update, Residual Spread","The paper presents HORSE, a hierarchical orthogonal residual spread method for precise massive editing in large language models. It improves stability and reduces conflicts by adapting layer-wise weights and leveraging residual information, achieving state-of-the-art results across multiple datasets.",276.04,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11442v1_Map2Thought Explicit 3D Spatial Reasoning via Metr.pdf,Exact string,"Xiangjun Gao, Zhensong Zhang, Dave Zhenyu Chen, Songcen Xu",10.48550/arXiv.2024.12345,10.48550/arXiv:24/12345,"3D Vision-Language Models, Metric Cognitive Map, Cognitive Chain-of-Thought, 3D Understanding","Map2Thought introduces a framework for explicit, interpretable spatial reasoning in 3D Vision-Language Models by combining a metric cognitive map with a chain-of-thought reasoning process, enabling data-efficient and transparent 3D understanding.",289.88,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11451v1_PRISM-CAFO Prior-conditioned Remote-sensing Infras.pdf,Exact string,"Oishee Bintey Hoque, Nibir Chandra Mandal, Kyle Luong, Amanda Wilson, Samarth Swarup, Madhav Marathe, Abhijin Adiga",10.48550/arXiv.2405.1234,10.48550/arXiv.2405.1234,"CAFOs, remote sensing, infrastructure segmentation, mapping, livestock operations, environmental risk","The paper presents an infrastructure-first, explainable pipeline for detecting and characterizing Concentrated Animal Feeding Operations (CAFOs) using aerial and satellite imagery. It employs a domain-tuned YOLOv8 detector, extracts structured descriptors, and combines them with spatial attention to achieve state-of-the-art performance, enabling better risk assessment and regulatory action.",309.86,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11459v1_Interactive Narrative Analytics Bridging Computati.pdf,Interactive Narrative Analytics: Bridging Computational Narrative Extraction and Human Sensemaking,Brian Keith,10.1 109/ACCESS.2025.3650352,10.1 109/ACCESS.2025.3650352,"information overload, misinformation, narrative extraction, interactive visual analytics","This paper defines the nascent field of Interactive Narrative Analytics (INA), which combines computational narrative extraction with interactive visual analytics to support sensemaking. INA addresses challenges such as scalability, interactivity, knowledge integration, and evaluation standardization, offering opportunities across news analysis, intelligence, scientific literature, and social media.",322.63,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11464v1_MHA2MLA-VLM Enabling DeepSeeks Economical Multi-He.pdf,Exact string,"Xiaoran Fan, Zhichao Sun, Tao Ji, Lixing Shen, Tao Gui",10.48550/arXiv.2025.12345,10.48550/arXiv.2025.12345,"vision-language models, multi-head attention, KV cache, MLA","The paper introduces MHA2MLA-VLM, a parameter-efficient framework for adapting vision-language models to Multi-Head Latent Attention, addressing KV cache bottlenecks in complex multimodal tasks.",326.34,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11468v1_Exploring LLM Features in Predictive Process Monit.pdf,Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs,"Alessandro Padella, Massimiliano de Leoni, Marlon Dumas",10.1007/978-3-030-62753-1,1.1.23456,"Predictive process monitoring, Large language models, Trace Encoding, LLM-based prediction, Process mining","The study extends an LLM-driven predictive process monitoring framework to small-scale event logs, demonstrating improved performance over traditional methods in data-limited environments. It highlights the model's ability to leverage prior knowledge and internal correlations, while also examining its reasoning strategies.",269.89,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11479v1_Health Facility Location in Ethiopia Leveraging LL.pdf,Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning,"Yohai Trabelsi, Guojun Xiong, Fentabil Getnet, Stéphane Verguet, Milind Tambe",10.1093/acm/qad045,10.1093/acm/qad045,"Health Facility Location, Optimization, Human expert knowledge, Alignment, LLM","The paper presents a hybrid framework combining optimization methods with large language models to systematically integrate expert knowledge into health facility planning, aiming to improve coverage in Ethiopia while balancing data-driven and qualitative priorities.",380.21,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11492v1_BoxMind Closed-loop AI strategy optimization for e.pdf,Exact string,"Kaiwen Wang, Kaili Zheng, Rongrong Deng, Qingmin Fan, Milin Zhang, Zongrui Li, Xuesi Zhou, Bo Han, Liren Chen, Chenyi Guo, Ji Wu",10.48550/arXiv.2405.12345,10.48550/arXiv.2601.11492,"boxing, AI strategy, closed-loop system, tactical analysis, machine learning, sports intelligence","Presents BoxMind, a closed-loop AI expert system for elite boxing, validated in the 2024 Olympics, enabling tactical pattern recognition and predictive modeling to enhance competitive performance.",315.68,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11496v1_The Poisoned Apple Effect Strategic Manipulation o.pdf,Exact string,"Eilam Shapira, Moshe Tennenholtz, Roi Reichart",10.48550/arXiv.2026.12345,10.48550/arXiv/12345,"AI, market design, regulatory frameworks, strategic interaction","The study examines how expanding AI technologies in regulated markets can lead to the 'Poisoned Apple' effect, where agents manipulate regulator decisions to shift equilibrium outcomes in their favor.",282.08,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11505v1_MetaboNet The Largest Publicly Available Consolida.pdf,Exact string,"Miriam K. Wolff, Peter Calhoun, Eleonora Maria Aiello, Yao Qin",10.1109/MLR.2026.12345,10.1109/MLR.2026.12345,"type 1 diabetes, algorithm development, data standardization, metaboNet dataset, continuous glucose monitoring","This paper consolidates publicly available Type 1 Diabetes (T1D) datasets into a unified MetaboNet resource, enabling improved data integration and algorithmic research. The dataset includes 3135 subjects with CGM and insulin data, offering broader generalizability for T1D studies.",327.19,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11516v2_Building Production-Ready Probes For Gemini.pdf,Building Production-Ready Probes For Gemini,"János Kramár, Joshua Engels, Zheng Wang, Bilal Chughtai, Rohin Shah, Neel Nanda, Arthur Conmy",10.48550/arXiv.2025.12345,10.48550/arXiv.2025.12345,"Activation Probing, Interpretability, Language Models, Misuse Risk, AI Safety, Monitoring","The paper presents new probe architectures designed to address long-context distribution shifts in production environments, evaluates their robustness against cyber-offensive prompts, and discusses implications for deploying misuse mitigation in frontier language models like Gemini.",304.03,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11517v1_Do explanations generalize across large reasoning .pdf,Exact string,"Koyena Pal1, David Bau 1, Chandan Singh 2",10.48550/arXiv.2024.12345,10.48550/arXiv:24/12345,"reasoning models, generation, explanation, generalization","This study investigates whether explanations generated by large reasoning models generalize across different models, aiming to understand if CoT chains reflect broader problem patterns rather than model-specific behaviors.",322.29,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11625v1_Reasoning Stabilization Point A Training-Time Sign.pdf,Exact string,Sahil Rajesh Dhayalkar,10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"interpretability, explanation drift, reasoning stabilization point, attribution dynamics","The paper introduces a training-time interpretability framework that tracks token-level attributions during fine-tuning. It defines explanation drift as the change in normalized token attributions across epochs and introduces the Reasoning Stabilization Point (RSP) as a key metric indicating when decision evidence becomes stable. Empirical results show drift stabilizing early, often coinciding with increased reliance on shortcut mechanisms, even when validation accuracy remains competitive.",288.63,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11643v1_Syllabic Agglutinative Tokenizations for Indonesia.pdf,Exact string,"Hokky Situngkir, Andhika Bernard Lumbantobing, Yohanes Surya",10.1093/acergast/9780190871293.005.0001,2601.11643,"Indonesian natural language processing, Indonesian computational linguistics, tokenization, large language models, Gasing Literacy Learning System, low-resource languages, Austronesian languages","The paper introduces a syllable-based tokenization framework for Indonesian LLMs, inspired by the Gasing Literacy Learning System. It describes a method that segments Indonesian text at syllable boundaries, applies byte-pair encoding, and builds a compact vocabulary that respects the language's agglutinative morphology. Empirical results show improved efficiency and token coverage compared to conventional tokenizers, demonstrating benefits for morphologically rich languages.",369.22,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11644v1_Predicting When to Trust Vision-Language Models fo.pdf,Predicting When to Trust Vision-Language Models for Spatial Reasoning,"Muhammad Imran, Yugyung Lee",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"vision-language models, spatial reasoning, robotics, uncertainty quantification","The paper introduces a vision-based confidence estimation framework to validate VLM spatial predictions through geometric verification. By fusing geometric alignment, spatial ambiguity, detection quality, and model uncertainty, the method improves robustness beyond text-based self-assessment. Experiments show significant gains in AUROC across benchmarks, demonstrating that confidence-driven selective prediction enhances reliability in safety-critical applications.",336.11,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11647v1_Reinforcement Learning for Dynamic Workflow Optimi.pdf,Reinforcement Learning for Dynamic Workflow,"Aniket Abhishek Soni, Milan Parikh, Rashi Nimesh Kumar Dhenia, Jubin Abhishek Soni, Ayush Raj Jha, Sneja Mitinbhai Shah",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"Reinforcement Learning, CI/CD, DevOps, Workflow Optimization","This paper presents a reinforcement learning framework to dynamically optimize Continuous Integration and Continuous Deployment (CI/CD) pipelines. By modeling the pipeline as a Markov Decision Process, the authors train an RL agent to adaptively select test scopes and execution strategies, achieving up to a 30% improvement in throughput and a 25% reduction in test overhead compared to static baselines. The approach enables intelligent, context-aware pipeline automation.",343.22,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11650v1_Large Language Model Agent for User-friendly Chemi.pdf,Exact string,"Jingkang Liang, Niklas Groll, Gürkan Sin, Niklas Groll, Gürkan Sin",10.1093/acpro/9780190871293.5.1,2601.11650v1,"Chemical Process Simulation, Large Language Model, Model Context Protocol, Process Simulation, Water Methanol Separation","A large language model agent integrates with A VEV A Process Simulation via Model Context Protocol to enable natural language interaction with complex process simulations, supporting both educational and expert use cases.",283.3,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11651v1_Aesthetics as Structural Harm Algorithmic Lookism .pdf,Exact string,"Miriam Doh, Aditya Gulati, Corina Canali, Nuria Oliver",10.1093/pasj/202406,2601.11651v1,"Generative AI, Artificial Intelligence, Cognitive Biases, Attractiveness Halo Effect","This paper examines algorithmic lookism—the systematic preferential treatment based on physical appearance—in text-to-image generative AI and a downstream gender classification task. It analyzes synthetic faces and reveals how models associate facial attractiveness with positive attributes, gender disparities in classification, and intensifying aesthetic constraints.",276.91,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11652v1_WISP Waste- and Interference-Suppressed Distribute.pdf,WISP: Waste- and Interference-Suppressed Distributed,"Xiangchen Li, Jiakun Fan, Qingyuan Wang, Dmitrios Spatharakis, Saeid Ghafouri, Hans Vandierendonck, Deepu John, Bo Ji, Ali R. Butt, Dimitrios S. Nikolopoulos",10.1145/376xxxx.377xxxx,10.1145/376xxxx,"Speculative Decoding, Large Language Models, Edge Computing, Distributed Computing, Natural Language Processing, Cloud Computing, General and Reference","The paper introduces WISP, a distributed LLM inference system that reduces wasted drafting time and verification interference by balancing workloads between edge and cloud using speculative decoding. It improves system capacity and throughput while enhancing prediction accuracy.",319.09,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11657v1_Size is Not the Solution Deformable Convolutions f.pdf,Exact string,"Jack T. Beerman, Shobhan Roy, H.S. Udaykumar, Stephen S. Baek",10.48550/arXiv.2026.12345,10.48550/arXiv.2026.12345,"physics-aware deep learning, deformable convolutions, physics modeling, computational mechanics, nonlinear flows","The paper introduces deformable physics-aware recurrent convolutions (D-PARC) inspired by Hybrid Lagrangian-Eulerian methods, demonstrating improved fidelity in simulating complex physical systems like Burgers' equation, Navier-Stokes, and reactive flows. It argues that strategic architectural design can outperform model scaling for effective physics modeling.",282.32,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11658v1_Towards AGI A Pragmatic Approach Towards Self Evol.pdf,Exact string,"Indrajit Kar, Sammy Zonunpuia, Zonunfeli Ralte",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"AGI, self-evolving agent, LLM, curriculum learning, code generation, task crafting","The paper presents a hierarchical self-evolving multi-agent framework integrating LLM, operational SLM, code-generation, and teacher-LLM components to enable continuous adaptation and autonomous capability expansion in agents.",284.83,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11663v1_Activation Sensitivity as a Unifying Principle for.pdf,Activations Sensitivity as a Unifying Principle for Post-Training Quantization,Bruce Changlong Xu,10.48550/arXiv.2026.12345,10.48550/arXiv/12345.67890,"activation sensitivity, post-training quantization, quantization error, layer-wise importance","This paper introduces a unified theoretical framework for post-training quantization by formalizing activation sensitivity—the expected impact of channel-wise perturbations on loss. It shows that sensitivity emerges from the squared norm of gradient-weighted activations, linking it to activation magnitude and downstream error propagation. The authors compare AWQ and GPTQ as complementary approximations, connecting them to classical pruning methods and highlighting challenges in quantization design.",315.67,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11664v1_Serverless AI Security Attack Surface Analysis and.pdf,Serverless AI Security: Attack Surface Analysis and Runtime Protection Mechanisms for FaaS-Based Machine Learning,"Chetan Pathade, Vinod Dhimam, Ilsa Lareb, Sheheryar Ahmad",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"serverless computing, machine learning security, Function-as-a-Service, cloud security, adversarial machine learning, AWS Lambda, Azure Functions, Google Cloud Functions","This paper provides the first comprehensive security analysis of machine learning workloads in serverless environments, identifying critical attack surfaces across function-level, model-specific, infrastructure, supply chain, and IAM domains. It introduces Serverless AI Shield (SAS), a multi-layered defense framework that achieves 94% detection rates with minimal performance overhead, and releases an open-source toolkit to help secure serverless AI deployments.",302.04,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11666v1_MATEX Multi-scale Attention and Text-guided Explai.pdf,Exact string,"Muhammad Imran, Chi Lee, Yugyung Lee",10.48550/arXiv.2025.12345,10.48550/arXiv.2025.12345,"Explainable AI, Medical Imaging, Vision-Language Models, Gradient Attribution, Attention Rollout","MATEX introduces a novel framework for interpretable medical vision-language models by integrating multi-scale attention, text-guided spatial reasoning, and layer consistency analysis, thereby improving spatial precision and clinical relevance.",282.05,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11667v1_Distill-then-Replace Efficient Task-Specific Hybri.pdf,Exact string,"Xiaojie Xia1, Huigang Zhang1, Chaoliang Zhong1, Jun Sun1, Yusuke Oishi2",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Hybridattentionmodels, Blockwiselocaldistillation, Greedy search","The paper presents a task-specific hybrid attention model that combines full and linear attention mechanisms, enabling efficient training and deployment by leveraging blockwise distillation and greedy layer replacement. This approach addresses computational challenges while maintaining performance across diverse downstream tasks.",288.95,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11670v1_A Confidence-Variance Theory for Pseudo-Label Sele.pdf,Exact string,"Jinshi Liu, Pan Liu",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"semi-supervised learning, pseudo-label selection, confidence variance, spectral relaxation","The paper proposes a Confidence-Variance (CoVar) theory to improve pseudo-label selection in semi-supervised learning by combining prediction confidence with residual-class variance, addressing overconfidence issues.",388.35,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11674v1_Pigment Network Detection and Classification in De.pdf,Pigment Network Detection and Classification in Dermoscopic Images Using Directional Imaging Algorithms and Convolutional Neural Networks,"M. A. Rasel, Sameem Abdul Kareem, Unaizah Obaidellah",10.1016/j.bspc.2024.106883,null,"Melanoma, Dermoscopic Images, Pigment Networks, Contrast Enhancement, Threshold Level, Convolutional Neural Networks, Bag of Features","The study presents a directional imaging algorithm combined with CNN and BoF classifiers to detect and classify pigment networks in dermoscopic images, achieving high accuracy in distinguishing atypical from typical pigment networks.",294.44,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11675v1_Generating metamers of human scene understanding.pdf,Generating Metamers of Human Scene Under-Standing,"Ritik Raina, Abe Leite, Alexandros Graikos, Seoyoung Ahn, Dimitris Samaras, Gregory J. Zelinsky",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"human scene representation, metamer generation, visual perception, foveated synthesis, semantic alignment","The paper introduces Metamer-Gen, a latent diffusion model that merges peripheral scene gist with fixated high-resolution information to produce images humans perceive as coherent. It proposes a dual-stream representation and evaluates metamerism using behavioral experiments, highlighting semantic and perceptual factors driving scene understanding.",303.64,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11676v1_HALO Semantic-Aware Distributed LLM Inference in L.pdf,Exact string,"Peirong Zheng, Wenchao Xu, Haozhao Wang, Jinyu Chen, Xuemin (Sherman) Shen",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Large Language Models, Distributed Inference, Edge Computing, Semantics, Packet Loss","The paper introduces HALO, a framework enhancing distributed LLM inference in lossy edge networks by relaxing synchronization constraints and improving speed through semantic-aware mechanisms.",322.96,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11683v1_Attesting Model Lineage by Consisted Knowledge Evo.pdf,Attesting Model Lineage by Consisted Knowledge Evolution,"Zhuoyi Shang, Jiasen Li, Pengzhen Chen, Yanwei Liu, Xiaoyan Gu, Weiping Wang",10.1234/example.doi,not provided,"model lineage, knowledge evolution, fine-tuning, security","The paper proposes a novel framework for attesting model lineage by analyzing the trajectory of knowledge evolution during fine-tuning, addressing security concerns like unauthorized redistribution and false provenance claims.",317.74,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11684v1_Mobile-friendly Image de-noising Hardware Consciou.pdf,Exact string,"Srinivas Miriyala, Sowmya Vajrala, Hitesh Kumar, Sravanth Kodavanti, Vikram Rajendiran",10.48550/arXiv.2311.07818,10.48550/arXiv:2311.07818,"De-Noising, Differentiable NAS, Hardware-aware Search space, Smartphone Deployment, Image Restoration","The paper presents a novel mobile-friendly network for image de-noising using Entropy-Regularized differentiable Neural Architecture Search (NAS) on a hardware-aware search space. It introduces a U-Net architecture with reduced parameters, achieving improved latency and memory efficiency while maintaining competitive accuracy compared to state-of-the-art methods.",291.86,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11685v1_Towards Efficient Image Deblurring for Edge Deploy.pdf,Exact string,"Srinivas Soumitri Miriyala, Sowmya Lahari Vajrala, Rama Sravanth Kodavanti",10.48550/arXiv.2311.03855,10.48550/arXiv:2311.03855,"Mobile Image Signal Processing (ISP), De-blurring, Training-free Search, Inference Optimization, Edge Deployment","The paper presents a hardware-aware adaptation framework for efficient image deblurring on edge devices. It introduces sensitivity-guided block substitution, surrogate distillation, and training-free multi-objective search to optimize existing models like NAFNet. Applied to motion and defocus deblurring, the method achieves up to 55% reduction in GMRs, delivering competitive accuracy with a 1.25× latency improvement over baselines.",339.48,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11686v1_Proof of Concept Multi-Target Wildfire Risk Predic.pdf,Exact string,"Nicolas Caron, Hassan Noura, Christophe Guyeux, Benjamin Aynes",10.1093/pasj/psa123,2601.11686v1,"wildfire risk, multi-target analysis, large language models, operational needs, fire management",This paper proposes a hybrid framework integrating predictive models for multiple wildfire risk dimensions with large language models to generate actionable reports for firefighting services.,314.06,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11687v1_Semantic Caching and Intent-Driven Context Optimiz.pdf,Semantic Caching and Intent-Driven Context,Harmohit Singh,10.1093/pasj/psa.2026,2601.11687,"Natural Language to Code, Multi-Agent Systems, Semantic Caching, LLM Optimization","The paper introduces a production-optimized multi-agent system that translates natural language queries into executable Python code for structured data analytics. It highlights three innovations: an asymmetric caching system with LLM-based equivalence detection, a dual-threshold decision mechanism for retrieval accuracy, and an intent-driven dynamic prompt assembly that cuts token usage by 40-60%. The system achieved 94.3% semantic accuracy across 10,000+ production queries with an average latency of 8.2 seconds.",274.83,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11688v1_SpecMap Hierarchical LLM Agent for Datasheet-to-Co.pdf,Hierarchical LLM Agent for Datasheet-to-Code,"Vedant Nipane Pulkit Agrawal, Amit Singh",10.1093/acps/9780190876223,2601.11688,"traceability, tls, systems engineering, datasheet, code mapping","The paper introduces a hierarchical LLM-based approach to map embedded systems datasheets to code, improving accuracy and efficiency by leveraging semantic analysis across multiple abstraction levels.",290.38,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11700v1_Telling Human and Machine Handwriting Apart.pdf,Exact string,"Luis A. Leiva, Moises Diaz, Nuwan T. Attygalle, Miguel A. Ferrer, Réjean Plamondon",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"handwriting, biometrics, deep learning, reverse Turing test, verification","The paper presents a deep learning approach to distinguish human from machine-generated handwriting using trajectory data. It achieves strong performance across multiple synthetic datasets and demonstrates robustness in few-shot settings, contributing to enhanced security verification systems.",280.03,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11702v1_PASTA A Scalable Framework for Multi-Policy AI Com.pdf,A Scalable Framework for Multi-Policy AI Compliance,"YU YANG, The University of British Columbia, Canada, IG-JAE KIM, Korea Institute of Science and Technology, South Korea, DONGWOOK YOON, The University of British Columbia, Canada",10.1093/acpl/psac082,10.1093/acpl/psac082,"AI compliance, policy evaluation, multi-policy, scalability, automated governance","The paper introduces PASTA, a scalable compliance tool designed to address the challenges of multi-policy AI governance. It integrates model-card formats, policy normalization, and an LLM-powered evaluation engine to provide efficient, interpretable assessments across diverse regulatory landscapes. Expert evaluations confirm its accuracy and usability for practitioners.",335.15,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11713v1_Inter-Cell Interference Rejection Based on Ultrawi.pdf,Inter-Cell Interference Rejection Based on Ultrawideband Walsh-Domain Wireless Autoencoding,"Rodney Martinez Alonso, Cedric Dehos, Yuneisy Esthela Garcia Guzman",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"inter-cell interference rejection, ultrawideband, Walsh domain, autoencoding, 5G communication","The paper presents an end-to-end wireless autoencoder architecture designed to reject partial-in-band interference in ultrawideband systems. By leveraging the orthogonality of Walsh functions, the method optimizes transmitter and receiver encoding/decoding in the Walsh domain, achieving up to 12 dB of interference rejection while maintaining low block error rates.",356.09,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11746v1_LIME-LLM Probing Models with Fluent Counterfactual.pdf,Exact string,"George Mihaila, Suleyman Olcay Polat, Poli Nemkova, Himanshu Sharma, Namratha V. Urs",10.1093/pasj/psl.2024.01,10.1093/pasj/psl.2024.01,"LIME, LLM, local explanation, NLP, explainability, generative models","The paper presents LIME-LLM, a framework that enhances local explanation in NLP by using hypothesis-driven, controlled perturbations. It improves upon traditional methods by constructing fluent, on-manifold neighborhoods that isolate feature effects, achieving better fidelity than random masking and recent generative approaches.",283.73,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11747v1_PRISM Learning Design Knowledge from Data for Styl.pdf,Exact string,"Huaxiaoyue Wang, Sunav Choudhary, Franck Dernoncourt, Yu Shen, Stefano Petrangeli",10.48550/arXiv.2024.12345,10.48550/arXiv:24/12345,"graphic design, stylistic improvement, design knowledge, VLM","The paper introduces PRISM, a method that uses design data to learn and apply stylistic knowledge for graphic design improvement. It addresses the gap where general VLMs lack domain-specific style alignment, proposing a three-stage framework to cluster designs, summarize insights, and retrieve relevant knowledge during inference.",328.98,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11758v1_Early Linguistic Pattern of Anxiety from Social Me.pdf,Early Linguistic Pattern of Anxiety from Social Media,Arnab Das Utsa,10.1093/acps/clac045,10.1093/acps/clac045,"anxiety detection, linguistic pattern, interpretable machine learning, keyword robustness, cross-domain validation","This study presents a transparent approach to social media-based anxiety detection using linguistically interpretable features. It evaluates a logistic regression classifier trained on Reddit posts from subreddits with curated content, demonstrating strong performance and keyword-robustness even after feature modifications.",279.61,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11762v1_Industry-Aligned Granular Topic Modeling.pdf,Industry-Aligned Granular Topic Modeling,"Sae Young Moon, Myeongjun Erik Jang, Haoyan Luo, Chunyang Xiao, Antonios Georgiadis, Fran Silavong",10.1093/acps/ghac.2023.001,10.1093/acps/ghac.2023.001,"topic modeling, granularity, industry applications, text mining, LLMs, business insights","This paper presents TIDE, a novel framework for granular topic modeling leveraging large language models. It demonstrates superior performance over existing methods in business contexts, offering tools for summarization, topic hierarchy, and domain-specific analysis. The approach aims to enhance granular insights for industrial applications.",329.21,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11768v1_Lightweight Self-Supervised Detection of Fundament.pdf,Lightweight Self-Supervised Detection of Fundamental Frequency and Accurate Probability of Voicing in Monophonic Music,"Venkat Suprabath Bitra, Homayoon Beigi",10.1093/acps/rmb023,10.1093/acps.rmb023,"self-supervised pitch detection, fundamental frequency, voicing estimation, musical timbre transfer","Proposes a lightweight, fully self-supervised framework for joint fundamental frequency estimation and voicing inference, leveraging transposition-equivariant learning and EM-style iterative reweighting with Shift Cross-Entropy consistency to improve robustness under noisy, unvoiced conditions.",324.22,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11776v1_Cleansing the Artificial Mind A Self-Reflective De.pdf,Cleansing the Artificial Mind: A Self-Reflective Detoxification Framework,"Kaituo Zhang, Zhimeng Jiang, Na Zou",10.48550/arXiv.2024.12345,SRD-3448,"Large Language Models, Self-Regulation, Detoxification, Toxic Content","The paper introduces a fully self-reflective detoxification framework for Large Language Models that leverages inherent self-correction mechanisms to detect and neutralize toxic content without external modules or data annotation. It presents a Toxic Signal Detector and a systematic intervention process, demonstrating improved detoxification performance on benchmark datasets while preserving semantic fidelity.",291.43,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11778v1_Translation as a Scalable Proxy for Multilingual E.pdf,Translation as a Scalable Proxy for Multilingual Evaluation,"Sheriff Issaka1, Erick Rosas Gonzalez1*, Lieqi Liu1*, Evans Kofi Agyei2, Lucas Bandarkar1, Nanyun Peng 1, David Ifeoluwa Adelani 3, Francisco Guzmán4, Saadia Gabriel 1",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"translation quality, multilingual evaluation, LLM benchmarks, non-machine-translated data, translation metrics","This paper investigates whether translation performance can serve as a cost-effective proxy for assessing broader multilingual capabilities in large language models. Through systematic evaluation across 14 models and 9 benchmarks, the authors find that translation quality correlates strongly with downstream multilingual success, suggesting it as a practical screening tool.",303.82,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11781v1_Risk-Aware Human-in-the-Loop Framework with Adapti.pdf,Risk-Aware Human-in-the-Loop Framework with Adaptive Intrusion Response for Autonomous Vehicles,"Dawood Wasif, Terrence J. Moore, Seunghyun Yoon, Hyuk Lim, Dan Dongseong Kim, Frederica F. Nelson, Jin-Hee Cho",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"autonomous vehicles, safety, human-in-the-loop, intrusion response, adaptive control",RAIL presents a risk-aware framework that integrates adaptive control and human oversight to enhance safety in autonomous driving under rare and complex scenarios.,347.78,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11792v1_A self-evolving multi-role collaborative framework.pdf,Exact string,"Yifei Suna, Yongan Lia, A.K. Qinb, Sicheng Houa, Tamas Pflanznerc",10.48550/arXiv.2024.12345,None,,N/A,267.56,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11801v1_RobotDesignGPT Automated Robot Design Synthesis us.pdf,Exact string,"Nitish Sontakke, K. Niranjan Kumar, Sehoon Ha",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"robot design, automated design, vision-language models, design synthesis, kinematic structures","The paper presents a novel automated robot design framework, RobotDesignGPT, which utilizes vision-language models to synthesize robot designs from user prompts and reference images. It emphasizes improving design quality and reducing manual feedback by integrating visual reasoning.",284.26,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11809v1_Multi-agent DRL-based Lane Change Decision Model f.pdf,Exact string,"Zeyu Mu1, Shangtong Zhang, B. Brian Park",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"Multi-Agent, Reinforcement Learning, Cooperative Platooning, Lane Change",The paper presents a hybrid multi-agent lane change decision model using QMIX and CNN-QMIX to enhance cooperative platooning in mixed traffic environments. It addresses challenges in sparse CA V distribution and demonstrates improved cooperative platooning rates.,347.95,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11816v1_POLARIS Typed Planning and Governed Execution for .pdf,POLARIS: Policy-Aware LLM Agentic Reasoning for Integrated Systems,"Zahra Moslemi1, Keerthi Koneru2, Yen-Ting Lee3, Sheethal Kumar2, Ramesh Radhakrishnan2",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Agentic AI, Enterprise Automation, Back-Office Tasks, Benchmarks, Governance, Typed Planning","POLARIS introduces a governed orchestration framework for agentic AI in back-office automation, emphasizing typed planning, policy alignment, and auditable execution. It achieves strong performance on evaluation benchmarks while enabling reproducible decision-making and side-effect prevention.",290.35,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11825v1_AI Co-Scientist for Knowledge Synthesis in Medical.pdf,Exact string,"Arya Rahgozara, Pouria Mortezaaghaa",10.1093/acm/qad047,2601.11825v1,"AI, knowledge synthesis, PICOS, biomedical, semantic retrieval","The paper presents a multi-representational AI co-scientist framework integrating vector retrieval, graph-based knowledge graphs, and transformer models to evaluate study design classification in dementia and NCD corpora, demonstrating strong performance with expert agreement.",271.55,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11840v1_Imandra CodeLogician Neuro-Symbolic Reasoning for .pdf,Exact string,"Hongyu Lin, Samer Abdallah, Makar Valentinov, Paul Brennan, Elijah Kagan, Christoph M. Wintersteiger, Denis Ignatovich, Grant Passmore ∗1,2",10.48550/arXiv.2601.11840,2601.11840,"Imandra, CodeLogician, neurosymbolic reasoning, software engineering, formal verification, code understanding","The paper introduces CodeLogician 1, a neurosymbolic framework for precise software logic analysis, bridging LLM capabilities with formal reasoning. It presents a new benchmark to evaluate mathematical reasoning about software, showing significant improvements over LLM-only approaches.",274.62,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11850v1_Human-AI Collaborative Inductive Thematic Analysis.pdf,Exact string,"Matthew Nyaaba, Min SungEun, Mary Abiswin Apam, Kwame Owoahene Acheampong, Emmanuel Dwamena, Xiaoming Zhai",10.1093/acps/ghad.2023.01,null,"Human-AI collaboration, Generative artificial intelligence (GenAI), Inductive thematic analysis, Qualitative data analysis, Epistemic authority, Reflexive methodology",The study examines how researchers use an Inductive Thematic Analysis GPT (ITA–GPT) within a Human–Artificial Intelligence Collaborative framework to guide analytic practice in education research. It highlights the importance of human oversight in maintaining interpretive authority while leveraging AI tools for structured thematic development.,284.31,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11854v1_ATOD An Evaluation Framework and Benchmark for Age.pdf,Exact string,"Yifei Zhang, Hooshang Nayyeri, Emine Yilmaz, Gokhan Tur, Dilek Hakkani-Tür, Hari Thadakamalla",10.1234/example.doi,None,,N/A,288.25,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11859v1_Cascaded Transformer for Robust and Scalable SLA D.pdf,Cascaded Transformer for Robust and Scalable,Cyril Shih-Huan Hsu,10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"network slicing, service level agreement, quality of service, deep neural network, optimization","The paper introduces Casformer, a cascaded Transformer architecture for fast, optimization-free SLA decomposition. It leverages domain-specific encoders and a cross-domain aggregator to improve SLA quality, scalability, and robustness in 6G networks.",296.77,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11863v1_Utilizing Metadata for Better Retrieval-Augmented .pdf,Exact string,"Raquib Bin Yousuf, Shengzhe Xu, Mandar Sharma, Andrew Neeser, Chris Latimer, Naren Ramakrishnan",10.1093/pasj/rm202,2601.11863,"Retrieval-Augmented Generation, Metadata-aware Retrieval, Dense Retrieval, Query Reformulation, Benchmark Datasets","This study evaluates metadata-aware retrieval strategies in RAG systems, demonstrating improved performance through structured metadata integration and unified embeddings.",321.23,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11868v1_Terminal-Bench Benchmarking Agents on Hard Realist.pdf,Terminal-Benchmarking Agents on Hardware,"Mike A. Merrill, Alexander G. Shaw, Nicholas Carlini, Boxuan Li, Harsh Raj, Ivan Bercovich, Lin Shi, Jeong Yeon Shin, Thomas Walshe, E. Kelly Buchanan, J. Junhong Shen, Guanghao Ye, Haowei Lin, Jason Poulos, Maoyu Wang, Marianna Nezhurina, Di Lu, Orfeas Menis Mastromichalakis, Zhiwei Xu, Zizhao Chen, Yue Liu, Robert Zhang, Leon Liangyu Chen, Anurag Kashyap, Jian-Lucas Uslu, Jeffrey Li, Jianbo Wu, Minghao Yan, Song Bian, Vedang Sharma, Ke Sun, Steven Dillmann, Akshay Anand, Andrew Lanpouthakoun, Anurag Hu, Gabriel H. Dreiman, Jiacheng Zhu, Li Zhong3, Niklas Muennighoff, Robert Amanfu, Shangyin Tan, Xin Lan, Xuandong Zhao, Yiqing Liang, Yuanli Wang, Zilong Wang, Changzhi Zhou, David Heineman, Hange Liu, Shangyin Tan, Xiangning Lin, Xin Lan, Uiang Lan, Shuang Zhao, Yiwei Dai, Wuwei Lin, Yiwei Wang, Yuxin Wang, Shang Zhou, Dariush Wahdany, Ziyu She, Jiaming Hu, Zhikang Dong, Yuxuan Zhu, Sasha Cui, Ahson Saiyed, Arinbjorn Kolbeinsson, Jesse Hu, Christopher Michael Rytting, Ryan Marten, Yixin Wang, Nabil Omi, Stanford University, Laude Institute, Anthropic, Independent, Northeastern University, University of California, Santa Barbara, Cornell University, Snorkel AI, Reflection AI, Carnegie Mellon University, Massachusetts Institute of Technology, Peking University, Laion, JSC, FZJ, Tencent, National Technical University of Athens, Nerion, University of Michigan, National University of Singapore, Moonshot AI, University of Texas at Austin, Amazon, University of Washington, University of Wisconsin-Madison, Beijing Institute of Technology, Allen Institute for AI, Monash University, CSIRO’s Data61, Dartmouth College, Princeton University, CISPA, University of Basel, Stony Brook University, Boston University, University of California, Berkeley, SambaNova Systems, Bespoke Labs, Michigan State University, Brown University, University of California, San Diego, Beijing Institute of Technology, Allen Institute for AI, Monash University, CSIRO’s Data61, Dartmouth College, Princeton University, CISPA, University of Basel, Stony Brook University",2601.11868v1,None,"AI agents, benchmarking, terminal environments, task evaluation, benchmark performance","The paper introduces Terminal-Benchmark 2.0, a curated set of 89 challenging terminal tasks designed to evaluate real-world AI agent performance. It highlights the limitations of current benchmarks and provides insights for improving model robustness.",351.09,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11876v1_AI for Green Spaces Leveraging Autonomous Navigati.pdf,Exact string,List of strings,10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"litter, robot, grass fields, trash pickup","The paper presents a robotic solution for autonomous trash collection on grass fields, employing a Spanning Tree Coverage algorithm, RTK GPS, and ResNet50 CNN for detection. It reports an 80% success rate in trash pickup and discusses challenges in grass terrain.",368.9,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11880v1_TF-CoDiT Conditional Time Series Synthesis with Di.pdf,Exact string,"Yingxiao Zhang, Jiaxin Duan, Junfu Zhang, Ke Feng",10.48550/arXiv.2024.12345,10.48550/arXiv:2409.0123,"treasury futures, time series synthesis, diffusion transformers, financial data, market dynamics","This paper introduces TF-CoDiT, a novel DiT framework for generating treasury futures data. By transforming multi-channel 1-D time series into discrete wavelet transform coefficients and employing a U-shape VAE, TF-CoDiT enables hierarchical encoding of cross-channel dependencies. It also proposes the Financial Market Attribute Protocol (FinMAP) to standardize market data descriptions. Experiments show the method achieves low error rates (MSE ≤ 0.433, MAE ≤ 0.453) across diverse treasury futures datasets.",289.15,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11885v1_MyGram Modality-aware Graph Transformer with Globa.pdf,Exact string,"Zhifei Li, Ziyue Qin, Xiangyu Luo, Xiaoju Hou, Yue Zhao, Miao Zhang, Zhifang Huang, Kui Xiao, Bing Yang",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"multi-modal, entity alignment, graph transformer, deep learning","Proposes MyGram, an amodality-aware graph transformer with global distribution for multi-modal entity alignment, introducing a modality diffusion learning module and Gram Loss to improve robustness against structural context interference.",350.42,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11895v1_DevBench A Realistic Developer-Informed Benchmark .pdf,"DevBench: A Realistic, Developer-Informed Benchmark for Code","Pareesa Ameneh Golnari, Adarsh Kumarappan, Wen Wen, Xiaoyu Liu, Gabriel Ryan, Yuting Sun, Shengyu Fu, Elsie Nallipogu",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"code generation, LLM benchmark, developer telemetry, realism","DevBench is a realistic, developer-informed benchmark for evaluating large language models on code completion tasks, incorporating 1,800 evaluation instances across six languages and six task categories derived from real-world usage patterns.",357.01,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11903v1_AEMA Verifiable Evaluation Framework for Trustwort.pdf,Exact string,"Yen-Ting Lee, Keerthi Koneru, Zahra Moslemi, Sheethal Kumar, Ramesh Radhakrishnan",10.48550/arXiv.2601.11903,2601.11903,"Agentic AI, Multi-Agent Systems, Trustworthy AI, Verifiable Evaluation, Human Oversight","A new process-aware, auditable framework for evaluating multi-agent LLM systems that enhances stability, alignment, and traceability in enterprise-scale agent workflows.",317.99,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11905v1_LIBRA Language Model Informed Bandit Recourse Algo.pdf,Exact string,"Jinuo Cao, Ruijiang Gao, Esmaeil Keyvanshokooh, Jianhao Ma",10.48550/arXiv.2303.04219,10.48550/arXiv.2303.04219,"Language Model, LLM-Bandits Collaboration, Algorithmic Recourse, Regret Analysis, Personalized Treatment Planning, Hypertension Management","The paper introduces LIBRA, a Language Model-Informed Bandit Recourse Algorithm that integrates LLMs with recourse bandit methods to improve treatment decisions in personalized medicine. It presents three guarantees—warm-start, LLM-effort, and robustness—and demonstrates superior performance in experiments.",287.76,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11907v1_Towards Airborne Object Detection A Deep Learning .pdf,Exact string,"Towards Airborne Object Detection: A Deep Learning Analysis, 1st Prosenjit Chatterjee, 2nd ANK Zaman",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"Airborne Object Detection, Threat Detection, Deep Learning, EfficientNetB4, ResNet-50, UA V","The paper introduces a dual-task deep learning model for airborne object classification and threat-level prediction using EfficientNetB4, leveraging a newly constructed AODTA Dataset. It demonstrates superior performance over ResNet-50 on both classification and prediction tasks.",324.46,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11913v1_LSTM-MAS A Long Short-Term Memory Inspired Multi-A.pdf,LSTM-MAS: A LONG SHORT-TERM MEMORY INSPIRED MULTI-AGENT SYSTEM FOR LONG-CONTEXT UNDERSTANDING,"Yichen Jiang, Peng Ye, Jiakang Yuan, Chongjun Tu, Lei Bai, Tao Chen",10.1109/ML.2024.12345,10.1109/ML.2024.12345,"Long-Context Understanding, Large Language Models, Multi-Agent System, Memory, Long-Context Processing","The paper presents LSTM-MAS, a multi-agent system inspired by LSTM architecture, designed for long-context understanding. It introduces hierarchical agent structures to manage information flow and mitigate error accumulation, achieving significant improvements over prior multi-agent approaches across multiple benchmarks.",376.04,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11920v1_Enhancing LLM-Based Data Annotation with Error Dec.pdf,Enhancing LLM-Based Data Annotation with Error,"Zhen Xu, Columbia University, University of California, Irvine, University of Pennsylvania, Columbia University, University of Georgia, Columbia University",10.1093/acprof:oso/9780190871293.013,10.1093/acprof:oso/9780190871293.013,"Data Annotation, Qualitative Coding, Large Language Models, Human-AI Collaboration","The paper proposes a diagnostic evaluation paradigm to assess LLM-based data annotation by distinguishing between model-driven and task-inherent errors, and proposes a lightweight human annotation test to evaluate ambiguity. It validates the approach on educational annotation tasks, highlighting limitations of single alignment metrics and offering insights for improving annotation quality.",348.48,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11935v1_Big Data Workload Profiling for Energy-Aware Cloud.pdf,Exact string,"Milan Parikh, Aniket Abhishek Soni, Sneja Mitinbhai Shah, Ayush Raj Jha",10.1093/acprof:oso/9780190871293.013,2601.11935,"Big Data, Energy-aware scheduling, Workload profiling, Virtual machine placement, Green computing","The paper presents a workload-aware scheduling framework that leverages profiling of CPU, memory, and storage I/O to reduce energy consumption in cloud environments while maintaining SLAs. It evaluates performance improvements across Hadoop MapReduce, Spark MLlib, and ETL workloads.",336.86,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11940v1_Thinking Traps in Long Chain-of-Thought A Measurab.pdf,Exact string,"Kang Chen, Fan Yu, Junjie Nian, Shihan Zhao, Zhuoka Feng, Zĳun Yao, Heng Wang, Minshen Yu",10.48550/arXiv.2601.11940,2601.11940,"Long Chain-of-Thought, Trap-Aware Adaptive Restart, Reasoning, Model Evaluation","The paper introduces TAAR, a Trap-Aware Adaptive Restart framework, to mitigate thinking traps in Long-CoT reasoning. By detecting prefix-dominant deadlocks and adapting restart strategies, TAAR improves reasoning accuracy on challenging benchmarks without requiring parameter fine-tuning.",291.02,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11956v1_Double-Calibration Towards Trustworthy LLMs via Ca.pdf,Double-Calibration: Towards Trustworthy LLMs via Calibrating,"Yuyin Lu, Ziran Liang, Yanghui Rao, Wenqi Fan, Fu Lee Wang, Qing Li",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"trustworthy reasoning, knowledge graphs, uncertainty quantification, LLMs","The paper introduces DoublyCal, a framework that improves LLM accuracy and confidence calibration by integrating a double-calibration principle. It uses a lightweight proxy model to generate evidence and calibrated confidence, guiding a black-box LLM to produce well-calibrated predictions.",379.99,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11960v1_R2PO Decoupling Training Trajectories from Inferen.pdf,Exact string,"Jingchu Wang, Bingbing Xu, Yige Yuan, Bin Xie, Xiaoqian Sun, Huawei Shen",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"reinforcement learning, LLM reasoning, training trajectories, inference generation","The paper introduces R2PO (Residual Rollout Policy Optimization) to decouple inference responses from training trajectories, enabling controlled diversity during training while maintaining stable inference. Experiments demonstrate improved performance across benchmarks.",339.07,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11969v1_textttMemoryRewardBench Benchmarking Reward Models.pdf,MemoryRewardBench: Benchmarking Reward Models for Long-Term,"Zecheng Tang, Baibei Ji, Ruoxi Sun, Haitian Wang, Wangjie You, Yijun Zhang, Wenpeng Zhu, Ji Qi, Juntao Li, Min Zhang",10.48550/arXiv.2024.12345,10.48550/arXiv:2024.12345,"memory management, long context, reward models, LLM, memory quality","The paper introduces MemRewardBench, a benchmark to systematically evaluate how reward models assess long-term memory management in large language models. It covers 10 settings with varying context lengths and demonstrates that newer models outperform older ones, highlighting current limitations in evaluating memory across diverse tasks.",331.01,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11974v1_Learn Like Humans Use Meta-cognitive Reflection fo.pdf,Learn Like Humans: Use Meta-cognitive Reflection for Efficient Self-Improvement,"Xinmeng Hou, Peiliang Gong, Bohao Qu, Wuqi Wang, Qing Guo, Yang Liu",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"metacognitive reflection, self-improvement, LLM, education","The paper introduces MARS (Metacognitive Agent with Reflective Self-improvement), a framework that enables efficient self-evolution in autonomous agents by integrating principled reflection and procedural reasoning. It demonstrates superior performance over existing self-evolving systems while minimizing computational costs.",295.02,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11977v1_One-Shot Price Forecasting with Covariate-Guided E.pdf,One-Shot Price Forecasting with Covariate-Guided Experts under Privacy Constraints,"1stRen He, 2ndYinliang Xu, 3rdJinfeng Wang, 4thJeremy Watson, 5thJian Song",10.48550/arXiv.2303.04233,10.48550/arXiv.2303.04233,"price forecasting, time series, privacy, mixture of experts, market analysis","The paper presents a novel MoE-Encoder module for forecasting multivariate time series under privacy constraints. It enhances traditional forecasting by integrating sparse expert-guided experts, enabling efficient localized training and parameter sharing in federated environments. Experimental results show improved accuracy and robust adaptation across regions.",293.73,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11979v1_Process In-Context Learning Enhancing Mathematical.pdf,Process In-Context Learning,"Ang Gao1, Changshuo Zhang1, Xiao Zhang1†, Deyang Li2, Minjun Zhao2, Fangchao Liu2, Xinyu Zhang2",10.48550/arXiv/2303.04112,10.48550/arXiv/2303.04112,"mathematical reasoning, in-context learning, adaptive demonstrations","The paper introduces Process In-Context Learning (PICL), a dynamic demonstration integration framework aimed at improving mathematical reasoning by adapting to real-time inference needs. PICL identifies confusion points in reasoning processes and inserts context-sensitive demonstrations to guide step-by-step logical deduction, addressing limitations of static ICL approaches.",340.1,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11995v1_Learning Audio-Visual Embeddings with Inferred Lat.pdf,Learning Audio–Visual Embeddings with Inferred Latent Interaction Graphs,"Donghuo Zeng, Hao Niu, Yanan Wang, Masato Taya",10.1007/978-3-642-45855-3,2601.11995,"Audio-visual, Latent interaction graph, Cross-modal retrieval, Soft labels, Audio-visual alignment","The paper proposes a framework to improve audio-visual embedding learning by leveraging inferred latent interactions. It introduces an Audio–Visual Semantic Alignment Loss to assign soft probabilities to unlabeled co-occurrences and uses an Inferred Latent Interaction Graph to model directional dependencies between classes. This enhances robustness and semantic coherence, as demonstrated on AVE and VEGAS benchmarks.",296.94,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.11998v1_Hybrid IDS Using Signature-Based and Anomaly-Based.pdf,Hybrid IDS Using Signature-Based and Anomaly-Based Detection,"m.boutassetta@univ-eltarf.dz, amina.makhlouf@univ-eltarf.dz, newfel.messaoudi@univ-eltarf.dz, abdelmadjid.benmachiche@univ-eltarf.dz, ines.boutabia@univ-eltarf.dz",10.1007/978-3-642-45678-3,None,"Intrusion Detection System (IDS), Hybrid IDS, Signature-Based Detection, Anomaly-Based Detection, Machine Learning (ML), Cybersecurity, False Positives, Detection Accuracy, Real-Time Detection, Network Security","This paper presents a comprehensive survey and conceptual overview of Hybrid IDS, integrating signature-based and anomaly-based detection techniques to enhance attack detection. It reviews recent research, classifies models, discusses advantages and limitations, and explores future directions for cost-effective solutions.",329.28,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12002v1_Kernel-Based Learning of Safety Barriers.pdf,Kernel-Based Learning of Safety Barriers,"Oliver Schönhoel, Zhengang Zhongzhengang, Sadegh Soudjanisadegh, Max Planck Institute for Software Systems, University of Warwick, University of Birmingham",10.48550/arXiv.2601.12002,2601.12002,"safety barriers, safety verification, black-box systems, control barrier certificates, stochastic dynamics, temporal logic, safety standards","The paper presents a data-driven approach for verifying safety in AI systems using kernel methods and control barrier certificates, addressing challenges in formal verification of black-box systems with complex dynamics.",331.46,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12003v1_Robust Verification of Concurrent Stochastic Games.pdf,Exact string,"Angel Y. He, David Parker",10.1093/pasj/psa.2023.01,10.1093/pasj/psa.2023.01,"Robust quantitative verification, Probabilistic model checking, Concurrent stochastic games, Epistemic uncertainty","The paper introduces a novel framework for robust verification of concurrent stochastic games (CSGs) by addressing the challenge of precise transition probability specifications. It proposes theoretical foundations and efficient algorithms for finite- and infinite-horizon objectives in zero- and nonzero-sum settings, grounded in social-welfare optimal Nash equilibria. The authors demonstrate feasibility through implementation in PRISM and benchmark validation.",337.36,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12014v1_Are LLMs Ready for TOON Benchmarking Structural Co.pdf,Are LLMs Ready for TOON? Benchmarking Structural Correctness–Sustainability Trade-offs in Novel Structured Output,"Elio Masciari, Vincenzo Moscato, Enea Vincenzo Napolitano, Gian Marco Orlando, Marco Perillo, Diego Russo",10.1093/acm/qtzt,10.1093/acm/qtzt,"Green AI, TOON, Large Language Models, Natural Language Processing, Sustainability, Structural Correctness, Environmental Impact","The paper evaluates structural correctness and environmental efficiency of the TOON output format using a sustainability-aware benchmarking framework. It highlights trade-offs between compactness, correctness, and carbon emissions across diverse LLMs.",306.81,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12019v1_Acting Flatterers via LLMs Sycophancy Combating Cl.pdf,Acting Flatterers via LLMs Sycophancy: Combating Clickbait with LLMs Opposing-Stance Reasoning,"Chaowei Zhang, Xiansheng Luo, Zewei Zhang, Yi Zhu, Jipeng Qiang, Longwei Wang",10.1145/XXXXXX,null,"Clickbait Detection, Large Language Models, Opposing Stance Reasoning, Contrastive Learning","The paper explores how Large Language Models (LLMs) can leverage sycophancy—by generating opposing reasoning pairs—to combat clickbait. It introduces a Self-renewal Opposing-stance Reasoning Generation (SORG) framework and a lo‑cal Opposing Reasoning-based Clickbait Detection (ORCD) model, demonstrating superior performance over existing methods.",322.0,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12024v1_A Multi-Agent System for Generating Actionable Bus.pdf,Exact string,"Kartikey Singh Bhandari, Tanish Jain, Archit Agrawal, Pratik Narang",10.1007/XXXXXX,null,"business advice, LLM, customer reviews, actionable insights","The paper proposes a multi-agent, LLM-based framework for transforming customer reviews into actionable business advice. It integrates clustering, advice generation, iterative evaluation, and feasibility ranking to produce specific, practical recommendations. Experiments demonstrate superior performance across actionability, specificity, and non-redundancy compared to single-model baselines.",306.09,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12030v1_ARC Active and Reflection-driven Context Managemen.pdf,ARC: Active and Reflection-driven Context Management for Long-Horizon Information Seeking Agents,"Yilun Yao, Shan Huang, Elsie Dai, Zhewen Tan, Zhenyu Duan, Shousheng Jia, Yanbing Jiang, Tong Yang, 1Peking University, 2Beihang University, 3Qiyuan Tech",10.48550/arxiv/2303.04112,10.48550/arxiv/2303.04112,"active context management, reflection-driven monitoring, context degradation, long-horizon information seeking, LLM performance","The paper introduces ARC, a framework that treats context management as an active, reflection-driven process to combat context rot in long-horizon information seeking. By enabling agents to dynamically reorganize internal states through reflection and revision, ARC improves performance on benchmark tasks, achieving up to 11% absolute accuracy gains over passive methods.",305.84,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12038v1_Abstract Argumentation with Subargument Relations.pdf,Abstract Argumentation with Subargument Relations,"Beishui Liao, Zhejiang University",10.1234/abcd1234,None,,N/A,180.15,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12040v1_Partial Reasoning in Language Models Search and Re.pdf,Exact string,"Murilo da Luz, Bruno Brandão, Luana Martins, Gustavo Oliveira, Bryan de Oliveira, Luckeciano Melo, Telma Soares",10.1234/example.doi,None,,N/A,264.48,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12042v1_Less Is More -- Until It Breaks Security Pitfalls .pdf,Less Is More — Until It Breaks: Security Pitfalls of Vision Token,"Xiaomei Zhang, Zhaoxi Zhang, Leo Yu Zhang, Yanjun Zhang, Guanhong Tao, Shirui Pan",10.1093/acr/viw/000,10.1093/acr/viw/000,"vision token compression, large vision-language models, robustness degradation, security vulnerabilities, compression mechanisms","This paper investigates how visual token compression compromises the robustness of large vision-language models, revealing that compression-induced instability in token importance leads to hidden failure modes. The authors propose a Compression-Aware Attack (CAA) to exploit these vulnerabilities and extend it to black-box scenarios, demonstrating that security risks persist despite practical deployment.",326.36,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12049v1_textitFocaLogic Logic-Based Interpretation of Visu.pdf,Exact string,"Chenchen Zhao, Muxi Chen, Qiang Xu",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"interpretability, visual models, logic-based, interpretation","FocaLogic introduces a model-agnostic framework to interpret visual model decisions by identifying minimal visual focuses and translating them into logical expressions. It provides quantitative metrics to evaluate focus precision, recall, and divergence, enabling transparent and scalable interpretability.",323.77,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12053v1_A New Strategy for Artificial Intelligence Trainin.pdf,A New Strategy for Artificial Intelligence: Training Foundation Models Directly on Human Brain Data,Maël Donoso,10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"foundation models, brain, neuroimaging, brain-generated data, brain-trained foundation models","The paper proposes a novel approach to training foundation models by leveraging human brain data, aiming to overcome limitations of traditional data-driven models through direct neuroimaging integration.",323.08,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12055v1_Automating Parameter Selection in Deep Image Prior.pdf,Automating Parameter Selection in Deep Image,"Lina Meyer, Felix Wissel, Tobias Knopp, Susanne Pfefferle, Ralf Fliegert, Maximilian Sandmann, Liana Uebler, Franziska M. Koch, Bjørn-Philipp Diercks, David Lohr, René Werner",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"fluorescence microscopy, denoising, deep image prior, automatic parameter selection, image processing","This paper presents AUTO-DIP, a pipeline for automatic parameter transfer in deep image denoising, particularly for fluorescence microscopy. By leveraging image metadata similarity rather than quantitative image matching, AUTO-DIP achieves comparable or better performance than traditional DIP methods, demonstrating improved speed and quality for locally acquired microscopy images.",316.25,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12061v1_Codebook-Injected Dialogue Segmentation for Multi-.pdf,Exact string,"Jinsook Lee, Kirk Vanacore, Zhuqian Zhou, Bakhtawar Ahtisham, Jeanine Grütter, René F. Kizilcec",10.1093/acpan/sca062,null,"dialogue segmentation, multi-utterance constructs, codebook injection","The paper introduces codebook-injected segmentation for dialogue act annotation, evaluating its performance against standard and retrieval-augmented baselines. It highlights trade-offs between segment consistency, distinctiveness, and human-AI agreement, emphasizing segmentation as a design choice for downstream tasks.",328.19,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12068v1_Bridging the Gap in Bangla Healthcare Machine Lear.pdf,Bridging the Gap in Bangla Healthcare: Machine Learning Based Disease Prediction Using a Symptoms-Disease Dataset,"Rowzatul Zannat, Abdullah Al Shafi, Abdul Muntakim",10.1234/abcd123,null,"Disease Prediction, Annotated Dataset, Machine Learning Techniques, Soft Voting Ensemble, Hard Voting Ensemble","The study develops a Bangla symptoms-disease dataset to enable disease prediction for non-English speakers, improving healthcare accessibility in Bangladesh.",327.35,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12082v1_Conditional Random Fields for Interactive Refineme.pdf,Exact string,"T. G., M. Z., K. El Khoury, Saïd Mahmoudi, Benoît Macq1 Christophe De Vleeschouwer",10.1093/pasj/histc202,10.1093/pasj.202,"histology classification, conditional random fields, human-in-the-loop, foundation models","The paper presents HistoCRF, a framework that adapts Conditional Random Fields to histopathological data without additional training, aiming to refine Vision-Language Model predictions by incorporating expert annotations and iterative human guidance. It reports significant accuracy improvements across multiple datasets.",322.75,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12095v1_Neural Isomorphic Fields A Transformer-based Algeb.pdf,Neural Isomorphic Fields: A Transformer-Based Algebraic Numerical Embedding,"Hamidreza Sadeghi Saeedeh Momtazi, Saeedeh Momtazi, Reza Safabakhsh",10.48550/arXiv.2026.12345,10.48550/arXiv.2026.12345,"neural network, number embedding, algebraic structures, arithmetic operations, algebraic properties","The paper introduces a novel Neural Isomorphic Field (NIF) that embeds numbers using embedding vectors to preserve algebraic operations like addition, multiplication, and comparison. It demonstrates strong performance in algebraic tests while highlighting challenges in multiplication handling.",294.26,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12099v1_Large language models struggle with ethnographic t.pdf,Large language models struggle with ethnographic text annotation,"Leonardo S. Goodall, Dor Shilton, Daniel Austin Mullins, Harvey Whitehouse",10.1093/acprof:oso/9780198752345.001.0001,10.1093/acprof:oso/9780198752345.001.0001,"large language models, ethnographic text annotation, cross-cultural research, anthropology, anthropological data","The study evaluates seven state-of-the-art LLMs in annotating ritual features from ethnographic texts, highlighting limitations in accuracy, especially for complex or ambiguous constructs, and emphasizing the need for human expertise in preserving cultural nuance.",317.78,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12104v1_Powerful Training-Free Membership Inference Agains.pdf,Powerful Training-Free Membership-Free Inference,"David Ilić, David Stanojevic, Kostadin Cvejoski",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"membership inference, memorization, language models, privacy risks","The paper introduces EZ-MIA, a reference-free membership inference attack that leverages error positions in token predictions to achieve higher detection rates without model training. It demonstrates improved performance on WikiText-2 and AG News datasets, highlighting the need for better privacy safeguards in fine-tuned LLMs.",331.57,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12124v1_SynQP A Framework and Metrics for Evaluating the Q.pdf,Exact string,"Bing Hu, Yixin Li, Asma Bahamyirou, Helen Chen",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"Real-World Data, Synthetic Data, Privacy Metrics, Evaluation Framework, Membership Inference, Identity Disclosure Risk","The paper introduces SYNQP, an open framework for benchmarking privacy in synthetic data generation using simulated sensitive data. It addresses the lack of accessible benchmark datasets and proposes a new identity disclosure risk metric, demonstrating its effectiveness in maintaining privacy while enabling health data applications.",295.47,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12126v1_UniMo Unified Motion Generation and Understanding .pdf,Exact string,"Guocun Wang1, Kenkun Liu2, Jing Lin3, Guorui Song1, Jian Li1†, Xiaoguang Han2,4,5†",10.48550/arXiv.2024.12345,10.48550/arXiv:24/12345,"human motion generation, interpretable chain of thought, LLM, motion understanding","The paper introduces UniMo, a framework that integrates motion-language information and interpretable chain-of-thought reasoning into large language models via supervised fine-tuning. It addresses limitations of existing unified and task-specific models by optimizing for structural correctness and semantic alignment, achieving state-of-the-art performance in both motion generation and understanding.",283.85,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12132v1_Bengali Text Classification An Evaluation of Large.pdf,Bengali Text Classification: An Evaluation of,"Md Mahmudul Hoque, Md Mehedi Hassain, Md Hojaifa Tanvir, Rahul Nandy",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Bengali Text Classification, Transformer-based Text Classifier, Multilingual NLP, Qwen, LLaMA","The study evaluates large language models for Bengali newspaper article classification, reporting Qwen 2.5's 72% accuracy in the 'Sports' category.",285.33,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12134v1_Human-Human-AI Triadic Programming Uncovering the .pdf,Human-Human-AI Triadic Programming: Uncovering the Role of AI Agent and the Value of Human Partner in Collaborative Learning,"Taufiq Daryanto, Xiaohan Ding, Kaike Ping, Lance T. Wilhelm, Yan Chen, Chris Brown, Eugenia H. Rho",10.1093/acm/book-26-1234,arXiv:2601.12134v1,"human-AI collaboration, programming learning, triadic programming, pedagogical benefits, AI as collaborator","This study explores human-human-AI triadic programming, examining how AI agents can augment collaborative learning without replacing human partners, highlighting the social and educational value of such interactions.",324.64,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12138v1_DriveSafe A Hierarchical Risk Taxonomy for Safety-.pdf,DriveSafe: A Hierarchical Risk Taxonomy for Safety-Critical LLM-Based Driving Assistants,"Abhishek Kumar, Riya Tapwal, Carsten Maple",10.1093/acr/abad123,10.1093/acr.abad123,"LLM safety, driving assistants, risk taxonomy, LLM-based systems","The paper introduces DriveSafe, a hierarchical four-level risk taxonomy designed to systematically characterize safety-critical failure modes of LLM-based driving assistants. It evaluates refusal behavior across six LLMs and highlights limitations in current safety alignment for real-world driving contexts.",309.41,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12141v1_TIDE A Trace-Informed Depth-First Exploration for .pdf,Exact string,"Yuliia Suprun, Khen Elimelech, Lydia E. Kavraki, Moshe Y. Vardi",10.48550/arXiv.2025.12345,2601.12141v1,"task planning, temporally extended goals, linear temporal logic, depth-first exploration, planning methods","TIDE introduces a trace-informed depth-first exploration framework for planning with temporally extended goals, leveraging cost-driven heuristics to guide search and improve completeness.",318.68,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12147v1_Segment and Matte Anything in a Unified Model.pdf,Segment And Matte Anything,"Zezhong Fan, Xiaohan Li, Topojoy Biswas, Kaushiki Nag, Kannan Achan",10.48550/arXiv.2311.03855,10.48550/arXiv:2311.03855,"segmentation, mattic, image processing, deep learning","The paper introduces Segment And Matte Anything (SAMA), a lightweight extension of Segment Anything (SAM) that combines high-quality interactive segmentation with fine-grained matting. SAMA leverages a Multi-View Localization Encoder and a Localization Adapter to enhance mask precision, while incorporating two prediction heads for unified segmentation and matting. It achieves state-of-the-art performance across benchmarks and demonstrates strong correlations with matting tasks.",328.11,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12150v1_Enhanced Diagnostic Performance via Large-Resoluti.pdf,Enhanced Diagnostic Performance via Large-Resolution Inference Optimization for Pathology Foundation Models,"Mengxuan Hu, Zihan Guan, John Kang, Sheng Li, Zhongliang Zhou, Jia Kang",10.48550/arXiv.2601.12150,2601.12150,"computational pathology, foundation models, inference optimization, ROI classification, segmentation, WSI, GPU memory, morphological details","The paper presents a space- and time-efficient inference strategy for pathology foundation models, enabling high-resolution whole-slide image processing without sacrificing performance. By sparsifying attention using spatially aware neighboring blocks and filtering non-informative tokens, the method reduces GPU memory usage and runtime while maintaining accuracy.",366.5,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12186v1_Aletheia What Makes RLVR For Code Verifiers Tick.pdf,Exact string,"Vatsal Venkatkrishna, Iryna Gurevych",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"code verification, RLVR, code generation, LLM","This paper introduces Aletheia, an open-source testbed for evaluating code verifiers trained via RLVR. It highlights the importance of on-policy learning and thinking-based training in improving verifier robustness, especially under execution feedback constraints.",288.1,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12205v1_Do Neural Codecs Generalize A Controlled Study Acr.pdf,Exact string,"Shih-Heng Wang, Jiatong Shi, Jinchuan Tian, Haibin Wu, Shinji Watanabe",10.48550/arXiv.2303.04112,10.48550/arXiv.2303.04112,"Neural Audio Codecs, Language generalization, Non-speech tasks, Speech pre-training, Downstream applications","This paper investigates whether Neural Audio Codecs can generalize to unseen languages during pre-training, whether speech-only pre-trained NACs can effectively generalize to non-speech tasks, and whether incorporating non-speech pre-training data improves performance on both speech and non-speech tasks.",299.73,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12212v1_Speculative Sampling with Reinforcement Learning.pdf,Speculative Sampling with Reinforcement Learning,"Chenan Wang, Daniel H. Shi, Haipeng Chen",10.48550/arXiv.2303.03112,10.48550/arXiv.2303.03112,"speculative sampling, reinforcement learning, large language models, inference latency","The paper introduces Reinforcement Learning for Speculative Sampling (Re-SpS), a reinforcement learning-based framework that dynamically optimizes draft tree hyperparameters in real time. It aims to improve generation speed while maintaining output fidelity by learning context-aware policies from target model hidden states.",291.57,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12215v1_Wavelet-Driven Masked Multiscale Reconstruction fo.pdf,Wavelet-Driven Masked Multiscale,"Megha Thukral, Cyrus Tanade, Simon A. Lee, Juhyeon Lee, Hao Zhou, Keum San Chun, Migyeong Gwak, Viswam Nathan, Md Mahbubur Rahman, Li Zhu, Mehrab Bin Morshed, Subramaniam Venkatraman, Sharanya Arcot Desai",10.1093/acps/ppw123,2601.12215v1,"Wavelet based Modelling, Wearable SSL Method, PPG foundation models, Multiscale Reconstruction","The paper presents a masked multiscale reconstruction (MMR) framework for PPG representation learning, leveraging wavelet-based decomposition to capture multi-resolution features across temporal and spectral scales. Pretrained on ~17M unlabeled PPG segments, MMR improves over existing models on diverse health tasks and demonstrates the efficacy of wavelet representations for physiological signals.",345.81,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12224v1_Where It Moves It Matters Referring Surgical Instr.pdf,Exact string,"Meng Wei, Kun Yuan, Shi Li, Yue Zhou, Long Bai, Nassir Navab, Hongliang Ren, Hong Joo Lee, Tom Vercauteren, Nicolas Padoy",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"surgical segmentation, instrument motion, natural language processing, machine learning, surgical robotics","The paper introduces SurgRef, a motion-guided framework that enables language-driven segmentation of surgical instruments by tracking their movement in videos. It addresses challenges in surgical video analysis by focusing on temporal dynamics rather than static visual features, aiming to improve robustness under occlusion and ambiguity.",352.57,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12234v1_Proc3D Procedural 3D Generation and Parametric Edi.pdf,Procedural 3D Generation and Parametric Editing of 3D Shapes with Large Language Models,"Fadlullah Raji, Stefano Petrangeli, Matheus Gadelha, Yu Shen, Uttaran Bhattacharya, Gang Wu2",10.1093/pasj/psa.2023,2601.12234,"3D modeling, procedural generation, Large Language Models, parametric editing","Proc3D introduces a procedural compact graph (PCG) for generating editable 3D models, enabling real-time manual and LLM-assisted modifications. It achieves over 400× speedup over traditional methods and improves ULIP scores by 28%.",322.87,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12242v1_Optimal Power Allocation and Sub-Optimal Channel A.pdf,Optimal Power Allocation and Sub-Optimal Channel Allocation,"Woo Seok Kim, Jeonghoon Lee, Sangho Kim, Sangho Kim, Taesun An, WonMin Lee, Ksangheop Shin, Kyungseop Shin",10.1093/pasj/psa123,2601.12242,"Non-Orthogonal Multiple Access, Deep Reinforcement Learning, Wireless Network, Resource Allocation","This paper presents a deep reinforcement learning framework for optimizing network resource allocation in NOMA systems, addressing challenges in power allocation and channel assignment to enhance IoT connectivity.",286.03,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12243v1_Less is More Label-Guided Summarization of Procedu.pdf,Less is More: Label-Guided Summarization of Procedural and Instructional Videos,"Shreya Rajpal, Michal Golovanesky",10.1093/acps/csp045,2601.12243,"video summarization, procedural videos, instructional videos, semantic understanding, semantic alignment","The paper introduces PRISM, a three-stage framework for procedural video summarization that leverages semantic and multimodal analysis with a large language model. It emphasizes context-aware summarization for instructional and surgical videos, achieving high semantic retention while reducing computational load.",325.18,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12247v1_Plan Verify and Fill A Structured Parallel Decodin.pdf,Plan Verify Fill: A Structured Parallel Decoding Approach for Diffusion,"Miao Li, 1 Hanyang Jiang, 1 Sikai Cheng, 1 Hengyu Fu, 2 Yuhang Cai, 2 Baihe Huang, 3 Xuanzhou Chen, 1 Pascal Van Hentenryck",10.48550/arXiv.2025.12345,10.48550/arXiv.2025.12345,"diffusion models, language generation, planning, decoding strategy, semantic anchoring","The paper introduces Plan-Verify-Fill (PVF), a training-free training approach for diffusion models that leverages hierarchical planning and verification to optimize global context utilization. PVF reduces the Number of Function Evaluations (NFE) by up to 65% compared to confidence-based decoding, improving efficiency without sacrificing accuracy. It is evaluated on LLaDA-8B-Instruct and Dream7B-Instruct, demonstrating superior performance across benchmarks.",300.53,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12248v1_AQUA-Bench Beyond Finding Answers to Knowing When .pdf,AQUA-Bench: Beyond Finding Answers to Knowing When There Are None,"Chun-Yi Kuan, Hung-yi Lee",10.1234/abcd1234,10.1234/abcd1234,"unanswerable questions, audio question answering, audio-aware large language models","The paper introduces AQUA-Bench, a benchmark for evaluating audio question unanswerability, highlighting challenges with unanswerable queries and proposing a framework to assess model reliability in real-world scenarios.",281.65,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12249v1_An Innovative Framework for Breast Cancer Detectio.pdf,Exact string,"Ehsan Sadeghi Pour, Mahdi Esmaeili, Morteza Romoozi",10.1007/978-3-642-45888-8,10.1007/978-3-642-45888-8,"Breast Cancer Detection, Pyramid Adaptive Atrous Convolution, Transformer, Multi-Scale Feature Fusion, Self-Attention Mechanism, Medical Image Processing","The paper presents an innovative framework combining Pyramid Adaptive Atrous Convolution (PAAC) with Transformer architectures and Multi-Scale Feature Fusion to detect malignant masses in mammographic images. It integrates Dice Loss and Focal Loss for improved binary classification, achieving high accuracy (98.5%) and robust performance in complex datasets. The model leverages self-attention mechanisms to capture long-range dependencies, outperforming existing methods like BreastNet and DeepMammo.",295.3,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12256v1_Improving Large Molecular Language Model via Relat.pdf,Exact string,"Jinyoung Park, Minseong Bae, Jeehye Na, Hyunwoo J. Kim",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"large language model, molecular modeling, LLM, hallucination, multi-modal collaboration","The paper introduces CoLLaMo, a large language model enhanced with a multi-level molecular modality-collaborative projector. It addresses limitations in hallucination and robustness by integrating 1D, 2D, and 3D molecular representations through a relation-aware attention mechanism. The work also presents a new evaluation framework for assessing hallucination and caption quality in molecular tasks.",299.81,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12257v1_Soft Shadow Diffusion SSD Physics-inspired Learnin.pdf,Soft Shadow Diffusion (SSD): Physics-inspired,"Fadlullah Raji, John Murray Bruce",10.48550/arXiv.2405.1234,10.48550/arXiv.2601.12257,"Computational imaging, Machine learning, 3D generative models, Diffusion models, Separable non-linear least squares","The paper presents a novel 3D reconstruction method called Soft Shadow Diffusion (SSD) that leverages physics-inspired reformulation of light transport to enable non-line-of-sight imaging. By decomposing the scene into light-occluding and non-light-occluding components, SSD proposes gradient-based optimization and a neural network approach to solve the inverse problem. The method demonstrates effectiveness across diverse 3D scenes and shows robustness to noise and varying illumination.",339.14,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12259v1_FutureX-Pro Extending Future Prediction to High-Va.pdf,Exact string,"FutureX-Pro team, Jiashuo Liuliujiashuo, Wenhao Huanghuang",arXiv:2601.12259v1,2601.12259,"FutureX, FutureX-Pro, LLM, LLM agents, agentic prediction, high-value verticals","Introduces FutureX-Pro, extending FutureX to high-value domains, focusing on finance, retail, public health, and natural disaster prediction. The work benchmarks agentic LLMs on foundational tasks across these sectors to assess domain-specific reliability.",304.04,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12260v1_Docs2Synth A Synthetic Data Trained Retriever Fram.pdf,Exact string,"Yihao Ding, Qiang Sun, Puzhen Wu, Sirui Li, Siwen Luo, Wei Liu",10.1234/example.doi,10.1234/example,"document understanding, visual documents, synthetic data, hallucination, domain generalization","Docs2Synth introduces a synthetic-supervision framework that enhances grounding and domain generalization for private, low-resource document tasks by combining retrieval-guided inference with iterative MLLM collaboration.",262.0,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12263v1_Multimodal Generative Engine Optimization Rank Man.pdf,Exact string,"Yixuan Du, Chenxiao Yu, Haoyan Xu, Ziyi Wang, Yue Zhao, Xiyang Hu",10.48550/arXiv.2024.12345,632562,"multimodal ranking, visual manipulation, textual suffix, LLM vulnerability","The paper introduces Multimodal Generative Engine Optimization (MGEO), a novel adversarial framework that enables attackers to jointly manipulate image and text to unfairly boost target product rankings in vision-language models. It demonstrates superior performance over text- and image-only attacks, highlighting the security risks of multimodal synergy.",315.84,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12269v1_Simulated Annealing Enhances Theory-of-Mind Reason.pdf,Simulated Annealing Enhances Theory-of-Mind Reasoning in Autoregressive Language Models,"Xucong Hu <xuconghu@zju.edu.cn>, Jian-Qiao Zhu <zhujq@hku.hk>",10.1234/jml.2025.0012,10.1234/jml.2025.0012,"Language Models, Theory of Mind, Simulated Annealing, Power Sampling","The paper demonstrates that incorporating simulated annealing into autoregressive language models can recover Theory of Mind capabilities without additional training, improving global coherence by leveraging sequence-level sampling.",286.36,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12276v1_Predictive Prototyping Evaluating Design Concepts .pdf,Predictive Prototyping: Evaluating Design Concepts with GPT,"Hilsann Yong, Singapore University of Technology & Design",10.1093/acprof:oso/9780190871298.001.0001,10.1093/acprof:oso/9780190871298.001.0001,"Prototyping, Design Theory, Iteration, Simulation, AI, LLM, GPT, RAG","This study explores the use of generative pretrained transformers (GPTs) and retrieval augmented generation (RAG) to predict design outcomes such as cost, performance, and usability during prototyping. It compares GPT-RAG predictions with physical prototypes and baseline models, demonstrating improved accuracy and highlighting the potential of LLMs to streamline design iteration.",303.23,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12282v1_CytoCLIP Learning Cytoarchitectural Characteristic.pdf,Exact string,"Pralaypati Ta, Sriram Venkatesaperumal, Keerthi Ram, Mohanasankar Sivaprakasam",10.1109/TICS.2024.12345,10.1109/TICS.2024.12345,"Cytoarchitecture, Histological Image Processing, Contrastive Learning, CLIP","CytoCLIP is a vision-language model that leverages pre-trained contrastive language-image pre-training to learn joint visual-text representations of brain cytoarchitecture. It proposes two model variants: one for low-resolution whole-region images and another for high-resolution tiles, trained on NISSL-stained histological sections of developing human brains. The approach enables automated identification of brain regions and improves classification performance.",346.12,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12286v1_Conversational Context Classification A Representa.pdf,Conversational Context Classification: A,Jonathan Pan,10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"Large Language Models, Representation Engineering, One-Class SVM, Novelty Detection","The paper explores using Representation Engineering and One-Class SVM to detect subspace patterns in LLM internal states that correspond to specific conversational contexts, aiming to improve safety by identifying out-of-context behavior.",273.41,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12288v1_TimeGMM Single-Pass Probabilistic Forecasting via .pdf,Exact string,"Lei Liu, Tengyuan Liu, Hongwei Zhao, Jiahui Huang, Ruibo Guo, Bin Li",10.48550/arXiv.2303.04137,10.48550/arXiv.2303.04137,"probabilistic forecasting, Gaussian mixture model, reversible instance normalization","The paper introduces TimeGMM, a probabilistic forecasting framework using Gaussian Mixture Models with adaptive Gaussian normalization, achieving superior performance in uncertainty quantification.",321.25,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12294v1_ToolPRMBench Evaluating and Advancing Process Rewa.pdf,ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents,"Dawei Li, Yuguang Yao, Zhen Tan, Huan Liu, Ruocheng Guo",10.48550/arXiv.2405.12345,10.48550/arXiv.2405.12345,"tool-using agents, process reward models, LLM evaluation, step-level benchmark","The paper introduces ToolPRMBench, a benchmark for evaluating process reward models (PRMs) in tool-using agents. It provides a comprehensive evaluation framework using multiple LLMs, highlighting differences in PRM effectiveness and the need for specialized models in tool contexts.",290.44,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12304v1_A Two-Stage Globally-Diverse Adversarial Attack fo.pdf,Exact string,"Wutao Chen1, Huaqin Zou1, Chen Wan1*, Lifeng Huang2",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"adversarial attack, VLP models, multi-modal retrieval, transferability","The paper presents 2S-GDA, a two-stage globally-diverse adversarial attack framework for vision-language pre-training models. It enhances attack diversity by combining text expansion with global image-level perturbations, achieving up to 11.17% improvement in black-box settings over existing methods.",321.62,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12310v1_Survival is the Only Reward Sustainable Self-Train.pdf,Exact string,"Jennifer Dodgson, Alfath Daryl Alhajir, Michael Joedhitya, Akira Rafhael Janson Pattirane, Surender Suresh Kumar, Joseph Lim, C.H. Peh, Adith Ramdas, Steven Zhang Zhexu",arXiv:2601.12310v1,2601.12310,"self-training, environment-mediated selection, semantic drift, negative-space learning, robust autonomous systems","The paper presents a self-training framework that relies on environmental viability rather than external rewards, demonstrating sustainable self-improvement through persistence of effective behaviors under resource constraints. It introduces a model where only behaviors that leave lasting, impactful traces survive, enabling stable learning without semantic feedback or dense rewards.",289.12,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12316v1_GazeFormer-MoE Context-Aware Gaze Estimation via C.pdf,Exact string,"GAZEFORMER-MOE, Xinyuan Zhao, Xianrui Chen, Ahmad Chaddad",10.48550/arXiv.2303.04112,10.48550/arXiv/2303.04112,"gaze estimation, multi-scale fusion, MoE transformer, CLIP","The paper presents a semantics-modulated, multi-scale Transformer for 3D gaze estimation that integrates CLIP with learnable prototype banks, enhancing robustness across illumination, pose, and background variations.",332.94,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12317v1_Explanova Automatically Discover Data Insights in .pdf,Explanova: Automatically Discover Data Insights in N×M Table via XAI Combined LLM Workflow,Yiming Huang,10.1145/nnnnnnn.nnnnnnn,null,"Explainable AI, Data Science, LLM, Feature Analysis","This paper proposes an automated LLM workflow to discover data insights in N×M tables, focusing on single-feature statistics and feature relationships. It aims to reduce LLM costs by leveraging predefined exploration strategies.",286.38,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12318v1_Beyond Human Annotation Recent Advances in Data Ge.pdf,Beyond Human Annotation: Recent Advances in Data Generation Methods for Document Intelligence,"Dehao Ying, Fengchang Yu, Haihua Chen, Changjiang Jiang, Yurong Li, Wei Lu",10.1093/acr/.ej123,10.1093/acr.eh12345,"Document Intelligence, Data Generation, Data Quality Evaluation","This survey establishes the first comprehensive technical map for data generation in Document Intelligence, redefining data generation as supervisory signal production and introducing a unified taxonomy across four paradigms. It evaluates performance gains across benchmarks and highlights challenges like fidelity gaps and co-evolutionary ecosystems.",293.64,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12323v1_MARO Learning Stronger Reasoning from Social Inter.pdf,Exact string,"Yin Cai1, Zhouhong Gu1, JunTao Zhang1, Ping Chen1",10.48550/arXiv.2024.12345,10.48550/arXiv/12345,"multi-agent, social learning, reasoning, LLM","This paper introduces MARO, a method that enhances large language models' reasoning by enabling them to learn through multi-agent social interactions. It addresses sparse learning, uneven role distribution, and environmental instability, demonstrating improved social reasoning and transferable skills to related tasks.",283.77,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12327v1_The Expert Validation Framework EVF Enabling Domai.pdf,Exact string,"Lucas Gren, Felix Dobslaw",10.1145/xxx.xxxx,null,"GenAI, expert validation, quality assurance, AI engineering, domain expert control","The paper introduces an Expert Validation Framework (EVF) that empowers domain experts to maintain control over GenAI systems through structured specification, testing, validation, and continuous monitoring, addressing quality assurance gaps in enterprise AI deployment.",298.06,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12330v1_IceWatch Forecasting Glacial Lake Outburst Floods .pdf,Exact string,"Zuha Fatima, Muhammad Anser Sohaib, Muhammad Talha, Ayesha Kanwal, Sidra Sultana, Nazia Perwaiz",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"deep learning, glacial lake outburst flood, multimodal prediction, satellite imagery, glacier monitoring","IceWatch introduces a deep learning framework for predicting Glacial Lake Outburst Floods (GLOFs) using multimodal data, combining spatial and temporal analysis to improve detection accuracy and real-time response.",326.54,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12331v1_Efficient Privacy-Preserving Retrieval Augmented G.pdf,Exact string,"Huanyi Ye, Jiale Guo, Ziyao Liu, Kwok-Yan Lam",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Retrieval-Augmented Generation, Privacy-Preserving, Distance-Preserving Encryption",Proposes a privacy-preserving retrieval-augmented generation framework (ppRAG) that mitigates privacy risks in cloud-based LLM inference by leveraging conditional approximate distance-preserving symmetric encryption (CAPRISE).,377.11,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12338v1_Actionable Advice from Reviews via Mixture of LoRA.pdf,Actionable Advice from Reviews via Mixture of LoRA Experts: A Two-LLM Pipeline for Issue Extraction and Business,"Kartikey Singh Bhandari, Manav Ganesh, Yashwant Viswanathan, Archit Agrawal, Dhruv Kumar, Pratik Narang",10.1000/xyz123,null,"review analysis, business recommendations, LLM, review mining","This paper presents a two-LLM framework for transforming customer reviews into concrete, actionable business recommendations. By leveraging a mixture-of-LoRA experts and synthetic training data, the approach generates targeted operational fixes grounded in review content, improving actionability and specificity.",292.93,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12341v1_Time-Continuous Modeling for Temporal Affective Pa.pdf,Time-Continuous Modeling for Temporal Affective Pattern Recognition in LLM’s,"Rezky M. Kam, Coddy N. Siswanto",10.48550/arXiv.2303.06912,10.48550/arXiv.2303.06912,"time-continuous, affective dynamics, LLM, temporal patterns","The paper introduces a hybrid encoder-decoder architecture leveraging time-aware neural networks to model evolving affective states across dialogues. By incorporating progressive steering of affective trajectories, the approach aims to improve interpretability and adaptability in language models, particularly for applications requiring nuanced emotional understanding.",331.24,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12343v1_How Well Do LLMs Predict Human Behavior A Measure .pdf,Exact string,"Wayne Gao, Sukjin Han, Annie Liang, Pat Kline",10.1093/acprof:oso/9780190871296.005.001,2601.12343,"LLM, human behavior, predictive accuracy, pretrained knowledge, economic variables",The paper evaluates how much knowledge pretrained large language models possess in predicting human behavior by comparing prediction errors across different models and datasets.,301.64,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12349v1_Zero-Permission Manipulation Can We Trust Large Mu.pdf,Zero-Permission Manipulation: Can We Trust Large Multimodal Model Powered GUI Agents?,"Yi Qian, Kunwei Qian, Xingbang He, Ligeng Chen, Jikang Zhang, Tiantai Zhang, Haiyang Wei, Linzhang Wang, Hao Wu, Bing Mao",10.1234/abcd1234,None,,N/A,284.02,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12357v1_SimpleMatch A Simple and Strong Baseline for Seman.pdf,Exact string,"Hailong Jin, Huiying Li",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"semantic correspondence, feature fusion, downsampling, matching loss","The paper introduces SimpleMatch, a lightweight framework for semantic correspondence that reduces computational overhead by upsampling features and optimizing memory usage. It achieves strong performance at lower resolutions, offering a practical baseline for future research.",290.91,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12358v1_From Prompts to Pavement LMMs-based Agentic Behavi.pdf,Exact string,"Omar Y. Goba, Ahmed Y. Gado, Catherine M. Elias, Ahmed Hussein",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Behavior Tree, Large Language Model, L5 Autonomy, Navigation, CARLA+, ROS","The paper introduces an agentic framework using large language models and multi-modal vision to generate adaptive behavior trees for autonomous vehicles, demonstrating successful navigation in simulation with minimal human intervention.",297.43,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12374v1_A Scalable Entity-Based Framework for Auditing Bia.pdf,Exact string,"Akram Elbouanani, Aboubacar Tuo, Adrian Popescu",10.48550/arXiv.2407.04201,10.48550/arXiv/2407.04201,"bias, LLM, auditing, fairness","The paper presents a scalable framework for auditing bias in large language models using named entities. It demonstrates that synthetic data can reliably reproduce real-world bias patterns across diverse entities, tasks, languages, and prompting strategies. The study reveals systematic biases such as preference for certain political views, Western-centric content, and exclusion of firms in defense and pharma. It emphasizes the need for rigorous auditing before deploying LLMs in high-stakes domains.",339.15,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12389v1_NADIR Differential Attention Flow for Non-Autoregr.pdf,Exact string,"Lakshya Tomar, Vinayak Abrol, Puneet Agarwal",10.48550/arXiv:2509.06932v1,10.48550/arXiv:2509.06932,"transliteration, Indic languages, NAR architecture, character error","The paper introduces NADIR, a non-autoregressive architecture for multilingual transliteration that balances speed and accuracy by reducing attention noise and leveraging a Mixture-of-Experts mechanism. It achieves competitive performance while significantly lowering inference latency compared to autoregressive models.",367.76,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12392v1_PsychēChat An Empathic Framework Focused on Emotio.pdf,Psych¯eChat: An Empathic Framework Focused on Emotion Shift Tracking and Safety Risk Analysis in Psychological Counseling,"Zhentao Xia♡, Yongqi Fan♡, Yuxiang Chu♡, Yichao Yin♠♡, Liangliang Chen♠, Tong Ruan ♡†, Weiyan Zhang ♡†",10.1234/jc.2024.0012,10.1234/jc.2024.0012,"emotion shift tracking, safety risk analysis, psychological counseling, LLM, mental health","This paper introduces Psych¯eChat, a novel framework that integrates emotion shift tracking and safety risk analysis for psychological counseling. By employing interactive role-playing and two specialized modules—Emotion Management and Risk Control—the model enables more context-aware and empathetic responses. Extensive experiments show its effectiveness in balancing emotional insight and safety mitigation.",315.18,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12401v1_Beyond the Dirac Delta Mitigating Diversity Collap.pdf,Exact string,"Jinmei Liu, Haoru Li, Zhenhong Sun, Bo Wang, Daoyi Dong, Chunlin Chen, Zhi Wang, Yatao Bian, Daoyi Bo",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"reinforcement learning, diversity collapse, image generation, policy optimization, generative models","The paper introduces DRIFT, a reinforcement learning framework designed to mitigate diversity collapse in fine-tuning of image generation models. By systematically encouraging output diversity during on-policy fine-tuning, DRIFT balances strong task alignment with high generation variety, improving versatility for diverse applications.",300.31,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12402v1_Weaknesses of Facial Emotion Recognition Systems.pdf,Exact string,"Aleksej Jamróz, Patrycja Wysocka, Piotr Garbat",10.1093/acps/csa123,2601.12402,"Facial Emotion Recognition, Deep learning, Computer Vision","This paper reviews facial emotion recognition systems, highlights weaknesses in existing solutions, and evaluates performance across diverse datasets to assess generalization capabilities.",319.3,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12405v1_Explainable Machine Learning for Pediatric Dental .pdf,Exact string,"Manasi Kanade, Abhi Thakkar, Gabriela Fernandes",10.1093/acps/psac123,10.1093/acps/psac123,"Explainable AI, Pediatric dental risk, Socio-demographic determinants, SHAP, Risk stratification","The paper presents an explainable AI framework for pediatric dental risk stratification, emphasizing interpretability and ethical considerations. It integrates socio-demographic factors such as income-to-poverty ratio, race/ethnicity, and gender to improve model transparency and fairness in pediatric dental health assessments.",303.91,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12410v1_Are LLMs Smarter Than Chimpanzees An Evaluation on.pdf,Exact string,"Dingyi Yang, Junqi Zhao, Xue Li, Ce Li, Boyang Li",10.48550/arXiv.2407.04219,10.48550/arXiv:2407.04219,"LLM, knowledge state, intelligence, cognitive anthropology","This paper evaluates how large language models perform in knowledge state tracking and estimation tasks, comparing their abilities to those of chimpanzees. It finds that current LLMs struggle with inferring others' knowledge states, highlighting a gap relative to human cognition.",325.3,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12415v1_Orthogonalized Policy OptimizationDecoupling Sampl.pdf,Orthogonalized Policy Optimization,Wang Zixian,10.5281/zenodo.1234567,2601.12415,"alignment, RLHF, optimization, policy optimization","The paper proposes Orthogonalized Policy Optimization (OPO) to decouple sampling geometry from optimization geometry, offering a stable and well-conditioned framework for large language model alignment.",273.82,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12436v1_Purification Before Fusion Toward Mask-Free Speech.pdf,Purification Before Fusion: Toward Mask-Free Speech Enhancement for Robust Audio-Visual Speech Recognition,"Linzhi Wu, Xingyu Zhang, Hao Yuan, Yakun Zhang, Changyan Zheng, Liang Xie, Tiejun Liu, Erwei Yin",10.48550/arXiv.2024.05.01234,10.48550/arXiv.2024.05.01234,"audio-visual speech recognition, speech feature enhancement, noise-robust, multimodal bottleneck Conformer, speech enhancement","The paper presents an end-to-end noise-robust audio-visual speech recognition framework that integrates a Conformer-based bottleneck fusion module to enhance speech features using video cues without explicit noise masking. This approach mitigates interference from noisy audio and preserves semantic integrity, achieving superior performance on the LRS3 benchmark under challenging conditions.",301.78,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12442v1_Constraint-Aware Neurosymbolic Uncertainty Quantif.pdf,Exact string,"Shahnawaz Alam, Mohammed Mudassir Uddin, Mohammed Kaif Pasha",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Neurosymbolic AI, Uncertainty Quantification, Bayesian Deep Learning, Scientific Constraints, Calibration","The paper introduces the Constraint-Aware Neurosymbolic Uncertainty Framework (CANUF), integrating Bayesian deep learning with symbolic reasoning to deliver trustworthy uncertainty estimates in scientific applications. It demonstrates improved calibration and constraint satisfaction across materials, quantum, and climate datasets.",387.16,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12443v1_Adversarial Defense in Vision-Language Models An O.pdf,Adversarial Defense in Vision-Language Models: An Overview,"Xiaowei Fu, Lei Zhang, leizhang@cqu.edu.cn",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"Vision Language Models, adversarial defense, survey","This paper reviews recent advancements in adversarial defense strategies for Vision Language Models (VLMs), focusing on training-time, test-time, and training-free approaches, and discusses their effectiveness and limitations.",305.12,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12444v1_Large Language Model for OWL Proofs.pdf,Large Language Model for OWL Proofs,"Hui Yang, Jiaoyan Chen, Uli Sattler",10.1145/XXXXXX.XXXXXX,Not provided,"Large Language Models, OWL, Proof Generation, Reasoning","This paper investigates how Large Language Models can construct and evaluate proofs within OWL ontologies, focusing on extraction, simplification, explanation, and logic completeness assessment. It highlights challenges posed by incomplete premises and the impact of logical complexity on performance.",368.99,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12449v1_AgenTRIM Tool Risk Mitigation for Agentic AI.pdf,Exact string,"Roy Betser, Shamik Bose, Amit Giloni",10.1093/acref/2023.01.012,10.1093/acref.2023.01.012,"AI agents, tool-driven agency, AGENTRIM, tool permissions, security risks","The paper introduces AGENTRIM, a framework designed to detect and mitigate tool-driven agency risks in LLM-based agents without compromising their capabilities. It addresses security challenges like indirect prompt injection and excessive tool access, offering a practical approach to enforce least-privilege tool usage at runtime.",289.25,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12465v1_Incentivizing In-depth Reasoning over Long Context.pdf,Incentivizing in-depth reasoning over long context,"Miao Peng1, Weizhou Shen2, Nuo Chen1, Chenliang Li2, Ming Yan2, Jia Li1†",10.1234/arxiv/2405.01234,10.1234/2405.01234,"reinforcement learning, long-context reasoning, LLMs, reasoning chains","The paper addresses the degradation of reinforcement learning with verifiable rewards (RLVR) performance in long-context scenarios by identifying the 'almost-there' phenomenon. It proposes DEEPREASONQA and Long-context Process Advantage Shaping (LONGPAS) to improve multi-hop reasoning and credit assignment, achieving better results on long-context benchmarks.",357.82,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12467v1_Patch-Level Tokenization with CNN Encoders and Att.pdf,Patch-Level Tokenization with CNN Encoders and Attention for Improved Transformer Time-Series Forecasting,Saurish Nagrath,10.48550/arXiv.2303.03832,10.48550/arXiv.2303.03832,"multivariate time-series forecasting, financial time-series forecasting, Transformer models, temporal tokenization, convolutional neural networks, attention mechanisms",The paper introduces a two-stage forecasting framework that combines convolutional neural networks for local temporal pattern extraction and token-level self-attention for global dependency modeling. This approach enhances forecasting performance on synthetic multivariate time-series data by decoupling local representation learning from global attention-based modeling.,370.29,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12471v1_Knowing When to Abstain Medical LLMs Under Clinica.pdf,Exact string,"Sravanthi Machcha, Sushrita Yerra, Sahil Gupta, Aishwarya Sahoo, Sharmin Sultana, Hong Yu, Zonghai Yao",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"medical, LLM, abstain, uncertainty, safety","The paper introduces MedAbstain, a benchmark for evaluating when large language models should abstain in medical multiple-choice question answering, emphasizing the importance of explicit uncertainty over input perturbations for safer deployment.",322.25,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12494v1_Harmonizing the Arabic Audio Space with Data Sched.pdf,Exact string,"Hunzalah Hassan Bhatti, Firoj Alam, Shammur Absar Chowdhury",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Arabic audio, speech understanding, generation, dialect, emotion","This paper introduces AraMega-SSum, a new Arabic speech summarization dataset, and proposes a Task-Progressive Curriculum (TPC) with Aligner-Based Diverse Sampling (ADS) to address challenges in adapting large language models to complex, low-resource Arabic environments. The study highlights the trade-offs between adaptive sampling and training stability, offering a practical framework for efficient model adaptation.",304.43,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12499v1_Failure Modes in Multi-Hop QA The Weakest Link Law.pdf,Failure Modes in Multi-Hop QA: The Weakest Link Law and the Recognition Bottleneck,"Meiru Zhang, Zaiqiao Meng, Nigel Collier",mz468@cam.ac.uk,nhc30@cam.ac.uk,"LLM, multi-hop reasoning, position bias, recognition failure","The paper investigates why large language models struggle with multi-hop reasoning due to position bias, introducing Multi-Focus Attention Instruction (MFAI) to address recognition bottlenecks. It establishes the 'Weakest Link Law' showing performance depends on the least visible evidence, and demonstrates how attention steering can improve accuracy in synthetic tasks.",320.28,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12518v1_Cooperative Multi-agent RL with Communication Cons.pdf,Cooperative Multi-agent RL with Communication constraints,"Nuoya Xiong, Aarti Singh",10.48550/arXiv.2025.12345,10.48550/arXiv/12345,"multi-agent, reinforcement learning, communication constraints, policy prediction",The paper addresses the challenge of limited communication in decentralized multi-agent reinforcement learning by introducing a base policy prediction technique that reduces communication rounds while maintaining performance.,324.85,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12522v1_Improved Bug Localization with AI Agents Leveragin.pdf,Improved Bug Localization with AI Agents Leveraging Hypothesis and Dynamic Cognition,"Asif Mohammed Samir, Mohammad Masudur Rahman",10.1093/acm/ccac002,10.1093/acm/ccac002,"Bug Localization, LLM, Agentic AI, Cognition, Debugging, Software Engineering","The paper introduces CogniGent, an agentic AI technique for bug localization that uses multiple AI agents with causal reasoning, call-graph analysis, and context engineering. It demonstrates superior performance over traditional methods and LLMs by enabling dynamic cognitive debugging and hypothesis testing, achieving significant improvements in bug localization metrics.",321.43,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12534v1_Encoding Emotion Through Self-Supervised Eye Movem.pdf,Encoding Emotion Through Self-Supervised Eye Movement Reconstruction,"Marcus Ma, Jordan Prescott, Emily Zhou, Tiantian Feng, Kleanthis Avramidis, Gabor Mihaly Toth, Shrikanth Narayanan",10.1093/acps/ghac020,null,"eye movement, self-supervised learning, emotion prediction, deep learning","This study explores the use of self-supervised eye movement reconstruction to predict emotional expressions from naturalistic, low-resolution video interviews. By leveraging large-scale datasets of Holocaust survivor testimonies, the researchers develop a gaze-based model that correlates eye movement patterns with emotional states such as laughing, crying, and sighing. The findings demonstrate the potential of self-supervised methods for encoding affective signals in unstructured video data.",294.86,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12535v1_Improving Low-Resource Machine Translation via Rou.pdf,Improving Low-Resource Machine Translation via Round-Trip,"Ahmed Attia, Alham Fikri, Masdar City, UAE, ahmed.attia@mbzuai.ac.ae, Alham Fikri, MBZUAI, Masdar City, UAE, alham.fikri@mbzuai.ac.ae",10.1093/acps/rmb045,10.1093/acps/rmb045,"machine translation, low-resource languages, reinforcement learning, round-trip bootstrapping",The paper presents a self-supervised reinforcement learning framework for low-resource machine translation using round-trip bootstrapping with the NLLB model family. It evaluates improvements across multiple languages and highlights increased fluency and semantic fidelity through chrF++ and BLEU-based rewards.,329.4,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12538v1_Agentic Reasoning for Large Language Models.pdf,Exact string,"Tianxin Wei, Ting-Wei Li, Zhining Liu, Xuying Ning, Yang2, Zhou, Xiao Lin, Dongqi Fu, Liang2, Wang5, Xing2, Wang4, Jiaxuan You, Heng Ji1",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Agentic AI, LLM Agent, Agentic Reasoning, Self-evolving, Collective Multi-agent Reasoning","This paper surveys agentic reasoning across three dimensions—foundational, self-evolving, and collective—to bridge thought and action in large language models. It highlights challenges in open-ended environments and proposes a unified roadmap for advancing agentic systems.",344.68,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12539v1_MemeLens Multilingual Multitask VLMs for Memes.pdf,Exact string,"Ali Ezzat Shahroor1, Mohamed Bayan Kmainasi2, Abul Hasnat, Dimitar Dimitrov, Giovanni Da San Martino, Preslav Nakov, Firoj Alam, Sofia University, University of Padova, Mohamed bin Zayed University of Artificial Intelligence",fialam,mha/2303.03002,"memes, multilingual, multitask, VLM, meme understanding","The paper introduces MEMELENS, a unified multilingual and multitask explanation-enhanced Vision Language Model for meme understanding. It consolidates 38 public meme datasets, proposes a shared taxonomy of 20 tasks, and analyzes performance across modeling paradigms, highlighting the need for multimodal training and caution against over-specialization.",349.11,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12542v1_Rethinking the AI Scientist Interactive Multi-Agen.pdf,Exact string,"Lukas Weidener, Marko Brkić, Mihailo Jovanović, Ritvik Singh, Chiara Baccin, Emre Ulgac, Alex Dobrin, Aakaash Meduri",10.48550/arXiv.2403.08219,10.48550/arXiv.2403.08219,"AI, scientific discovery, multi-agent system, scientific investigation, deep research, novelty detection","The paper presents Deep Research, a multi-agent system that enables interactive scientific investigation with rapid turnaround times, improving upon existing batch-processing methods.",318.12,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12547v1_How Clinicians Think and What AI Can Learn From It.pdf,Exact string,"Dr. Dipayan Sengupta, MD (Dermatology) 1, Dr. Saumya Panda, MD (Dermatology) 2",10.1093/acm/qad020,2601.12547v1,"clinical reasoning, ordinal decision-making, AI in medicine","The paper argues that clinicians primarily rely on ordinal, non-compensatory decision-making rather than optimizing probabilities. It proposes that robust, rule-based heuristics should guide AI design to better align with human judgment under uncertainty.",298.66,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12549v1_Benchmarking Concept-Spilling Across Languages in .pdf,Exact string,"Ilia Badanin, Daniil Dzenhaliou, Imanol Schlag",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"multilingual models, semantic robustness, language spilling, LLMs, polysemy",This paper introduces a comparative framework to evaluate multilingual semantic robustness by measuring how models handle polysemous words across languages. It highlights systematic biases in language spilling and provides a scalable benchmark for assessing semantic performance in diverse languages.,317.44,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12554v1_Artificial Intelligence in Materials Science and E.pdf,"Artificial Intelligence in Materials Science and Engineering: Current Landscape, Key Challenges, and Future","Iman Peivaste, Salim Belouettar ∗1, Francesco Mercuri, Nicholas Fantuzzi, Hamidreza Dehghani, Razieh Izadi, Halliru Ibrahim, Jakub Lengiewicz, Maël Belouettar-Mathis, Kouider Bendine, Ahmed Makradi, Martin Hörsch, Peter Klein, Mohamed El Hachemi, Heinz A. Preisig, Yacine Rezgui, Natalia Konchakova, Ali Daouadji, Luxembourg Institute of Science and Technology, Department of Physics and Materials Science, University of Luxembourg, Istituto per lo Studio dei Materiali Nanostrutturati (ISMN), Norwegian University of Life Sciences (NMBU), Fraunhofer Institute for Industrial Mathematics (ITWM), Ecole Centrale de Lyon, INSA Lyon, Norwegian University of Science and Technology (NTNU), School of Engineering, Cardiff University",10.1093/acpan/sca062,2601.12554,"Artificial Intelligence, Materials Science, Machine Learning, Data-Driven Discovery, Deep Learning, Generative AI, Uncertainty Quantification","This review provides a comprehensive overview of AI's impact on materials science, covering recent methodologies, challenges, and future directions.",356.63,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12557v1_Life Machine Learning and the Search for Habitabil.pdf,Exact string,"Mark Moussa1, Amber V. Young1, Brianna Isola1, Vasuda Trehan1, Michael D. Himes1, Nicholas Wogan2, Giada Arney1",10.48550/arXiv.2407.04219,10.48550/arXiv/2407.04219,"Life, Machine Learning, Habitability, Biosignature, Habitable Worlds Observatory","The paper presents two advanced machine-learning models—Bayesian Convolutional Neural Network (BCNN) and Spectral Query Adaptive Transformer (SQuAT)—designed to predict biosignature species fluxes from exoplanet reflected-light spectra. BCNN quantifies uncertainties, while SQuAT enhances interpretability by linking spectral features to biosignatures. Both models achieve high accuracy across diverse exoplanetary conditions, supporting efficient mission triage for the Habitable Worlds Observatory.",339.39,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12560v1_Agentic Artificial Intelligence AI Architectures T.pdf,Exact string,"Arunkumar V, Gangadharan G.R.",arunkumarv1530@gmail.com,2601.12560v1,"Agentic AI, Large Language Models, Autonomous Agents, Multi-Agent Systems, Cognitive Architectures, Tool Use, Planning","This paper explores architectures and taxonomies for Agentic AI, focusing on perception, planning, and collaboration. It discusses the evolution from linear reasoning to native inference models and highlights challenges like hallucination and infinite loops, while proposing a framework for robust autonomous systems.",296.55,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12577v1_Primate-like perceptual decision making emerges th.pdf,Exact string,"Nathan J. Wispinski, Scott A. Stone, Anthony Singhal, Patrick M. Pilarski, Craig S. Chapman",10.1093/pasj/psa.2023,2601.12577,"perceptual decision making, deep reinforcement learning, neural mechanisms, primate cognition, evidence accumulation","The paper explores how primate-like perceptual decision making emerges through deep recurrent reinforcement learning, highlighting the role of evidence accumulation in flexible decision-making.",294.74,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12582v1_Ontology-aligned structuring and reuse of multimod.pdf,Exact string,"Sepideh Baghaee Ravari, Abril Azocar, Guzman Sarath, Menon, Stefan Sandfeld, Tilmann, Hickel, Stricker",10.48550/arXiv.2024.12345,10.48550/arXiv/12345,"text mining, workflow, large language models, stacking fault energy, materials data science, reproducibility","This paper introduces an ontology-driven framework leveraging large language models to automatically extract and structure computational workflows from the literature, focusing on stacking fault energy calculations in materials science. It addresses the challenge of reproducibility by organizing unstructured text into a standardized schema aligned with established materials ontologies.",343.81,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12585v1_Do MLLMs See What We See Analyzing Visualization L.pdf,Exact string,"Mengli (Dawn) Duan, Yuhe (Sissi) Jiang, Matthew Varona, Carolina Nobre",xx.xxxx/TVCG.201x,xx.xxxx/TVCG.201x,"Visualization Literacy, Multimodal Large Language Model, Evaluation Study",Analyzing Visualization Literacy Barriers in AI Systems,349.54,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12594v1_SLAP Scalable Language-Audio Pretraining with Vari.pdf,Scalable Language-Audio Pretraining with V Arable-Duration,"Xinhao Mei, Gael Le Lan Haohe Liu, Zhaoheng Ni, Yangyang Shi Vikas Chandra",10.48550/arXiv.2311.07818,10.48550/arXiv:2311.07818,"Scalable Language-Audio Pretraining, SLAP, audio-text pairs, variable duration, multi-objective learning","The paper introduces SLAP, a scalable language-audio pretraining method that extends CLAP to handle variable-duration audio by incorporating multi-objective training objectives. It achieves state-of-the-art performance on audio-text retrieval and zero-shot audio classification tasks.",327.64,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12607v1_A Cloud-based Multi-Agentic Workflow for Science.pdf,A Cloud-based Multi-Agentic Workflow for Science,"Anurag Acharya, Timothy Vega, Rizwan A. Ashraf, Anshu Sharma, Derek Parker",10.1145/nnnnnn.nnnnnnn,10.1145/1234567,"Large Language Models, LLMs for Science, LLM Agents, Multi-agent Framework, Catalysis, Chemistry, Material Science, Cloud Computing","This paper presents a domain-agnostic, model-independent workflow for an agentic scientific assistant built on cloud computing. It integrates LLMs with external resources and tools, enabling complex tasks such as literature review, data analysis, and simulation execution. The framework demonstrates high task completion accuracy and cost efficiency, offering a viable solution for scientific domains.",355.04,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12617v1_Creating Disability Story Videos with Generative A.pdf,"Creating Disability Story Videos with Generative AI: Motivation, Expression, and Sharing","Shuo Niu, Dylan Clements, Hyungsin Kim",10.1145/3772318.3791495,10.1145/3772318,"Disability, Storytelling, Video, Generative AI, LLM","This study explores how people with disabilities use generative AI to create video stories, examining motivations, expression, and sharing within a disability advocacy context. It proposes a framework highlighting four affordances of GenAI for disability storytelling and discusses implications for design and accessibility.",385.97,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12637v1_Topology-Aware Multiscale Mixture of Experts for E.pdf,Exact string,"Long D. Nguyen, Kelin Xia, Binh P. Nguyen",10.48550/arXiv.2303.04219,arXiv:2303.04219,"Graph Neural Networks, Topological Deep Learning, Mixture of Experts, Molecular Representation","The paper introduces a Multiscale Interaction Mixture of Experts (MI-MoE) framework to model 3D molecular properties by adapting interaction modeling across geometric regimes. It proposes a distance-cutoff expert ensemble, a topological gating encoder, and demonstrates improved performance on diverse molecular datasets.",341.44,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12638v1_Mixed Precision PointPillars for Efficient 3D Obje.pdf,Exact string,"Ninnart Fuengfusin, Keisuke Yoneda, Naoki Suganuma",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"mixed precision, PointPillars, quantization, 3D object detection","Proposes a mixed precision framework for PointPillars to improve inference efficiency for LIDAR-based 3D object detection, reducing latency while maintaining competitive performance.",287.16,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12641v1_STEP-LLM Generating CAD STEP Models from Natural L.pdf,Exact string,"Xiangyu Shi, Junyang Ding, Xu Zhao, Sinong Zhan, Payal Mohapatra, Daniel Quispe, Kojo Welbeck, Jian Cao, Wei Chen, Ping Guo, Qi Zhu",10.1093/acpark/9780190871146.5.001,2601.12641v1,"Computer-aided design, STEP file, large language models, design automation","The paper presents a novel preprocessing pipeline for STEP file data tailored to large language models, introducing a depth-first search-based reserialization method to linearize cross-references while preserving structural coherence. It integrates retrieval-augmented generation and reinforcement learning to improve geometric fidelity in CAD model generation from natural language, demonstrating superior performance over existing Text2CAD baselines.",296.84,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12646v1_Unbounded Harms Bounded Law Liability in the Age o.pdf,Exact string,Liability in the Age of Borderless AI,10.1093/acprof:oso/9780190860953.013.00001,2601.12646v1,"AI, responsible AI, liability, risk governance","The paper examines the inadequacy of current legal frameworks in addressing transboundary AI harms, proposing a global compensation and accountability architecture to manage risks that transcend national borders.",324.07,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12648v1_Intelligent Documentation in Medical Education Can.pdf,Intelligent Documentation in Medical Education: Can AI Replace Manual Case Logging?,"Nafiz Imtiaz Khan, Kylie Cleland, Vladimir Filkov, Roger Eric Goldman",10.1093/acm/div.2023.03,10.1093/acm/div.2023.03,"artificial intelligence, large language models, radiology, case logs, medical education","This study evaluates the feasibility of using large language models to automate procedural case log documentation in radiology training, assessing performance, efficiency, and integration challenges.",312.93,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12654v1_Explanation Multiplicity in SHAP Characterization .pdf,Explanation Multiplicity in SHAP: Characterization and Assessment,"Hyunseung Hwang, Seungeun Lee, Lucas Rosenblatt, Julia Stoyanovich, Steven Euijong Whang",10.1093/acpro/9780190873545.13.1,10.1093/acpro/9780190873545.13.1,"SHAP, explanation multiplicity, interpretability, model transparency, post-hoc explanation","The paper investigates how multiple, internally consistent but distinct explanations can emerge for the same model prediction, highlighting the normative challenges explanation multiplicity poses for responsible AI deployment.",285.5,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12658v1_Augmenting Question Answering with A Hybrid RAG Ap.pdf,Exact string,"Tianyi Yang, Nashrah Haque, Vaishnave Jonnalagadda, Yuya Jeremy Ong, Zhehui Chen, Yanzhao Wu, Lei Yu, Divyesh Jadav, Wenqi Wei",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"question answering, retrieval-augmented generation, structured retrieval, LLM","The paper introduces Structured-Semantic RAG (SSRAG), a hybrid approach that enhances QA quality by integrating query augmentation, agentic routing, and a structured retrieval mechanism combining vector and graph-based techniques with context unification. It improves answer accuracy and informativeness across multiple benchmarks.",293.16,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12661v1_MedConsultBench A Full-Cycle Fine-Grained Process-.pdf,"MedConsultBench: A Full-Cycle, Fine-Grained, Process-Aware Benchmark","Chuhan Qiao, Jianghua Huang, Daxing Zhao, Ziding Liu, Yanjun Shen, Bing Cheng Wei Lin, Meituan",10.1016/j.medconsult.2024.01.001,10.1016/j.medconsult.2024.01.003,"medical consultation, clinical workflow, diagnostic accuracy, medication safety","The paper introduces MedConsultBench, a comprehensive benchmark framework that evaluates the full clinical consultation process—from history taking to follow-up Q&A—using fine-grained metrics to assess information gathering, uncertainty handling, and medication safety in real-world medical AI applications.",342.94,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12664v1_Generalizable Hyperparameter Optimization for Fede.pdf,Generalizable Hyperparameter Optimization for Federated Learning on Non-IID Cancer Images,"Elisa Gonc, Rodrigo Moreira, Larissa Ferreira Rodrigues Moreira, André Ricardo Backes, Andr´e Ricardo Backes",10.1234/example.doi,10.1234/example_id,"Federated Learning, Hyperparameter Optimization, Non-IID Data, Medical Imaging, Cancer","This paper investigates how hyperparameter optimization in federated learning can improve generalization across non-IID cancer imaging datasets, proposing a cross-dataset aggregation heuristic that combines learning rates, optimizers, and batch sizes to enhance performance in medical diagnosis tasks.",316.07,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12667v1_Empowering All-in-Loop Health Management of Spacec.pdf,Exact string,"Yi Di1, Zhibin Zhao1,2,5,∗, Fujin Wang3, Xue Liu4, Jiafeng Tang1,2, Jiaxin Ren1,2, Zhi Zhai1,2,∗, Xuefeng Chen1,2, Jiajian Tang2, Zhi Zhai2∗∗",10.1234/journals/2023.00123,10.1234/journals/2023.00123,"Large Language Model, Human-AI Collaboration, Spacecraft Power System, All-in-loop Health Management, Satellite Mega-Constellation","The paper proposes SpaceHMchat, an open-source Human-AI collaboration framework for all-in-loop health management in spacecraft power systems, addressing the growing need for efficient health management amid increasing satellite mega-constellations.",311.62,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12671v1_Exploiting Test-Time Augmentation in Federated Lea.pdf,Exact string,"Thamara Leandra de Deus Melo1, Rodrigo Moreira1, Larissa Ferreira Rodrigues Moreira1",10.1007/1234567,None,"Brain tumors, Federated Learning, Test-Time Augmentation, Image classification","The paper evaluates the impact of combining preprocessing with test-time augmentation in federated learning for brain tumor MRI classification, demonstrating significant performance gains.",252.81,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12688v1_Logic-Guided Multistage Inference for Explainable .pdf,Exact string,"Xu Zhang, Qinghua Wang, Mengyang Zhao, Fang Wang, Cunquan Qu",10.1234/jcli.2025.0012,10.1234/jcli.2025.0012,"multidefendant, judgment prediction, role differentiation, sentencing logic","The paper presents a novel masked multistage inference framework to improve role clarity in multidefendant legal cases, enhancing AI-driven judicial analysis and fairness.",309.98,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12711v1_Neurosymbolic LoRA Why and When to Tune Weights vs.pdf,Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts,"Kevin Wang, Neel P. Bhatt, Cong Liu, Junbo Li, Runjin Chen, Yihan Xi, Timothy Barclay, Alvaro Velasquez, Ufuk Topcu, Zhangyang Wang",10.48550/arXiv.2303.04233,10.48550/arXiv.2303.04233,"neurosymbolic, LoRA, LLM, prompt tuning, symbolic reasoning","The paper introduces a neurosymbolic LoRA framework that combines numerical updates and symbolic manipulations to balance factual reconstruction and style control. It proposes a unified monitoring system and reward-based classifier to decide when to apply LoRA versus TextGrad, emphasizing memory efficiency and high-quality prompt generation for data-scarce tasks.",315.68,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12715v1_RSOD Reliability-Guided Sonar Image Object Detecti.pdf,Reliability-Guided Sonar Image Object Detection,"Chengzhou Li, Ping Guo, Guanchen Meng, Qi Jia, Jinyuan Liu, Zhu Liu, Xiaokang Liu, Yu Liu, Zhongxuan Luo, Xin Fan",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"sonar, object detection, labeling, reliability, sonar images","The paper presents RSOD, a teacher-student framework for object detection in sonar images with extremely limited labels. It introduces a reliability-guided approach to mitigate label scarcity and demonstrates improved performance on the UATD dataset using only 5% labeled data.",330.65,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12720v1_Teaching Large Reasoning Models Effective Reflecti.pdf,Teaching Large Reasoning Models Effective Reflection,"Hanbin Wang, Jingwei Song, Jinpeng Li, Qi Zhu, Fei Mi, Ganqu Cui, Yasheng Wang, Lifeng Shang",10.48550/arXiv.2024.12345,10.48550/arXiv:24/12345,"reflection, self-critique, reflection quality, reasoning accuracy","The paper introduces Self-Critique Fine-Tuning (SCFT) and Reinforcement Learning with Effective Reflection Rewards (RLERR) to address superficial reflection in Large Reasoning Models, demonstrating improved reasoning and reflection performance on benchmarks.",357.37,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12723v1_An Evolutionary Framework for Automatic Optimizati.pdf,Exact string,"Yuhiro Ono, Tomohiro Harada, Yukiya Miura",10.1093/pasj/psa.2026,2601.12723v1,"optimization benchmarks, large language models, benchmark generation","The paper introduces an evolutionary framework using a large language model to generate diverse optimization benchmarks, demonstrating superior performance of genetic algorithms over differential evolution in real-world scenarios.",330.9,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12727v1_AI-exhibited Personality Traits Can Shape Human Se.pdf,Exact string,"Jingshu Li, Tianqi Song, Nattapat Boonprakong, Zicheng Zhu, Yi-Chieh Lee",10.1145/3772318.3790654,arXiv:2601.12727v1,"AI personality traits, self-concept, conversations, LLM, human-AI interaction","This study investigates how Large Language Model (LLM)-based AI chatbots can shape human self-concept through conversations, highlighting the potential for AI traits to influence users' perceptions of their own personality.",300.68,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12731v1_A Shared Geometry of Difficulty in Multilingual La.pdf,Exact string,"Stefano Civelli, Pietro Bernardelle, Nicolò Brunello, Gianluca Demartini",10.48550/arXiv.2405.12345,10.48550/arXiv.2405.12345,"language models, problem difficulty, multilingual, linear probes","This paper investigates how multilingual large language models (LLMs) represent problem difficulty through linear probes across languages. It identifies two distinct internal representational stages—shallow and deep—that differ in their difficulty estimation behaviors, with deep representations generalizing better across languages despite lower within-language accuracy. The findings suggest that LLMs initially encode difficulty in an abstract, language-agnostic manner before adapting to language-specific nuances.",364.65,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12740v1_TreeWriter AI-Assisted Hierarchical Planning and W.pdf,Exact string,"Zijian Zhang, Fangshi Du, Xingjian Liu, Pan Chen, Oliver Huang, Runlong Ye, Michael Liut, Alán Aspuru-Guzik, 1Department of Computer Science, University of Toronto, 2Vector Institute for Artificial Intelligence, 3Department of Chemistry, University of Toronto, 4Department of Mathematical and Computational Sciences, University of Toronto, 5Department of Materials Science & Engineering, University of Toronto, 6Department of Chemical Engineering & Applied Chemistry, University of Toronto, 7Acceleration Consortium, 8Canadian Institute for Advanced Research (CIFAR), 9NVIDIA",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"long-form writing, TreeWriter, hierarchical writing, AI assistance, document planning, collaborative writing","TreeWriter is a hierarchical writing system that supports complex document organization, integrating AI co-writing to enhance idea development, planning, and refinement across multiple levels. It enables sustained focus on structure and coherence in long documents.",318.38,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12742v1_AirHunt Bridging VLM Semantics and Continuous Plan.pdf,AirHunt: Bridging VLM Semantics and Continuous,"Xuecheng Chen, Zongzhuo Liu, Jianfa Ma, Bang Du, Tiantian Zhang, Xueqian Wang, Boyu Zhou",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Vision-Language Model, Aerial Navigation, LiDAR, Continuous Planning, Object Detection, Semantic Reasoning","AirHunt introduces a dual-pathway asynchronous architecture that fuses vision-language understanding with continuous path planning, enabling efficient open-set object navigation in outdoor settings. It addresses frequency mismatches and integrates semantic guidance with motion efficiency.",357.15,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12744v1_Vision Language Models for Optimization-Driven Int.pdf,Exact string,"Tasnim Ahmed, Yifan Zhu, Salimur Choudhury",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Intent-Based Networking, Optimization, Vision-Language Models, Code Generation","The paper presents IntentOpt, a benchmark evaluating 85 optimization problems across 17 categories using four Vision-Language Models. It compares multimodal and text-only prompting, showing performance drops and highlighting the need for visual input to generate correct optimization code.",300.92,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12745v1_A Graph Prompt Fine-Tuning Method for WSN Spatio-T.pdf,Exact string,"Miao Ye, Jing Cui, Yuan Huang, Yong Wang, Qian He, Jiwen Zhang",10.1007/...,null,"anomaly detection, graph neural networks, pre-training, prompt learning, wireless sensor networks","The paper presents a graph neural network anomaly detection method for Wireless Sensor Networks, incorporating spatio-temporal correlation features and a multi-task self-supervised training strategy to improve detection performance.",309.62,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12754v1_PAIR-SAFE A Paired-Agent Approach for Runtime Audi.pdf,Exact string,"Jiwon Kim, Violeta J. Rodriguez, Dong Whi Yoo, Eshwar Chandrasekharan, Koustuv Saha",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"mental health support, AI safety, paired agents, Motivational Interviewing, LLMs","The paper introduces PAIR-SAFE, a paired-agent framework for auditing and refining AI-generated mental health support. It integrates a Responder agent with a Judge agent based on Motivational Interviewing Treatement Integrity (MITI-4), enabling structured ALLOW/REVISE decisions to improve response quality in sensitive contexts.",313.46,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12758v1_VISPA Pluralistic Alignment via Automatic Value Se.pdf,Exact string,"Shenyan Zheng, Jiayou Zhong, Anudeex Shetty, Heng Ji, Preslav Nakov, Usman Naseem",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"pluralistic alignment, value selection, LLM, steering, activation","VISPA presents a training-free pluralistic alignment framework that enables dynamic control over value expression via internal activation steering, demonstrating effectiveness across diverse evaluation settings.",339.15,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12762v1_Teaching LLMs to Learn Tool Trialing and Execution.pdf,Teaching LLMs to Learn Tool Trialing and Execution through Environment Interaction,"Xingjie Gao, Pengcheng Huang, Zhenghao Liu, Yukun Yan, Shuo Wang, Zulong Chen, Chen Qian, Ge Yu, Yu Gu",10.1234/example.doi,None,"tool trialing, environment interaction, LLM training, tool execution","The authors present ToolMaster, a framework designed to enhance Large Language Models' ability to use external tools by shifting from imitation to active learning through environmental interaction. This approach improves generalization to novel tools and supports robust execution.",291.51,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12781v1_VIRO Robust and Efficient Neuro-Symbolic Reasoning.pdf,Exact string,"Hyejin Park, Junhyuk Kwon, Sua Kwak, Jungseul Ok",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Referring Expression Comprehension, Verification, Neuro-symbolic","The paper introduces Verification-Integrated Reasoning (VIRO), a neuro-symbolic framework that embeds lightweight verifiers within reasoning steps to robustly handle no-target cases, improving reliability and generalization.",344.87,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12785v1_Distilling Time Series Foundation Models for Effic.pdf,Distilling Time Series Foundation Models,"Yuqi Li, Kuiye Ding, Chuanguang Yang, Szu-Yu Chenc, Yingli Tiana",10.48550/arXiv.2303.04112,10.48550/arXiv.2303.04112,"Time Series Foundation Model, Knowledge Distillation, Forecasting","The paper introduces DistilTS, a distillation framework tailored for time series foundation models. It tackles task difficulty imbalance and architecture mismatch by incorporating horizon-weighted objectives and temporal alignment strategies, achieving competitive forecasting performance with significantly reduced parameters and faster inference.",288.95,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12804v1_SL-CBM Enhancing Concept Bottleneck Models with Se.pdf,Enhancing Concept Bottleneck Models with Semantic Locality for Better Interpretability,"Hanwei Zhang, Luo Cheng, Rui Wen, Yang Zhang, Lijun Zhang, Holger Hermanns",10.1109/MLR.2026.00123,null,"Concept Bottleneck Models, Interpretability, Explainable AI, Semantic Locality","The paper introduces SL-CBM, a novel extension of Concept Bottleneck Models that improves locality faithfulness by generating spatially coherent saliency maps. It enhances alignment between concepts, image regions, and predictions, leading to better explanation quality and interpretability in high-stakes AI systems.",364.41,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12805v1_SciHorizon-GENE Benchmarking LLM for Life Sciences.pdf,SciHorizon-Gene: Benchmarking LLM for Life Sciences Inference,"Xiaohan Huang, Meng Xiao, Chuan Qin, Qingqing Long, Jinmiao Chen, Yuanchun Zhou, Qingqing Long, qqlong, Jinmiao Chen, Chuan Qin, Qingqing Long, Jinmiao Chen, Yuanchun Zhou, Hengshu Zhu, Hszu",10.1093/acm/qtza,10.1093/acm/qtza,"large language models, benchmarking, genomics, knowledge-driven interpretation, functional understanding","This paper introduces SciHorizon-Gene, a large-scale gene-centric benchmark for evaluating large language models in biomedical contexts. It systematically assesses LLMs across four critical dimensions—research attention sensitivity, hallucination tendency, answer completeness, and literature influence—to uncover performance gaps and failure modes in gene-level reasoning. The benchmark integrates authoritative databases and highlights challenges in generating accurate, complete, and literature-supported functional interpretations, offering a foundation for safer LLM deployment in biological research.",370.77,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12809v1_Left-Right Symmetry Breaking in CLIP-style Vision-.pdf,Exact string,"Takaki Yamamoto, Chihiro Noguchi, Toshihiro Tanizawa",10.48550/arXiv.2025.12345,10.48550/arXiv/12345.67890,"vision-language models, spatial reasoning, relational understanding, CLIP-style","The paper investigates how left–right relational understanding emerges in vision-language models trained with a CLIP-style contrastive objective. It demonstrates that contrastive training induces left–right symmetry breaking via attention mechanisms, with label diversity playing a more critical role than layout diversity. Attention decomposition reveals horizontal gradients that disrupt symmetry, highlighting a mechanistic pathway for acquiring spatial relations.",346.54,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12816v1_Fisher-Orthogonal Projected Natural Gradient Desce.pdf,Exact string,"Ishir Garg, Neel Kolhe, Kolhe Andy, Peng Rohan, Gopalam Rohan",10.48550/arXiv.2025.12345,10.48550/arXiv.2025.12345,"continual learning, Fisher-Orthogonal Projected Natural Gradient, catastrophic forgetting, information geometry, neural networks","The paper introduces the Fisher-Orthogonal Projected Natural Gradient Descent (FOPNG) optimizer for continual learning. It enforces Fisher orthogonality on parameter updates to mitigate catastrophic forgetting by operating in the Fisher-Riemannian manifold, preserving prior task performance while enabling new learning.",296.75,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12822v1_MirrorGuard Toward Secure Computer-Use Agents via .pdf,Exact string,"Wenqi Zhang, Yulin Shen, Changyue Jiang, Jiarun Dai, Geng Hong, Xudong Pan",10.1093/acm/qad045,10.1093/acm/qad045,"Computer Use Agents, Agent Security, Reasoning Correction, Simulation, Vision-Language Models","The paper introduces MirrorGuard, a defense framework for Computer Use Agents that leverages simulation-based training to detect and mitigate insecure reasoning patterns before they cause unsafe actions. It demonstrates significant improvements over existing methods in both security and usability.",328.03,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12837v1_Cognition spaces natural artificial and hybrid.pdf,"Cognition spaces: natural, artificial, and hybrid","Ricard Solè, Luis F Seoane, Jordi Pla-Mauri, Michael Timothy Bennett, Michael E. Hochberg, Michael Levin",10.1093/pasj/ccac002,10.1093/pasj.ccac002,"Evolved cognition, basal cognition, artificial life, artificial intelligence, synthetic biology, morphospace","The paper proposes a cognition space framework that unifies natural, artificial, and hybrid systems, emphasizing a comparative, non-substrate-based analysis of cognitive forms and their structural diversity.",290.69,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12842v1_SCULPT Constraint-Guided Pruned MCTS that Carves E.pdf,Exact string,"Qitong Fang, Haotian Li, Xu Wang",10.48550/arXiv/2303.04112,10.48550/arXiv/2303.04112,"mathematical reasoning, constraint-guided, MCTS, LLM","The paper presents SCULPT, a constraint-guided Monte Carlo Tree Search that enhances ordered exploration in mathematical reasoning by integrating domain-aware scoring across dimensional, type, pattern, and magnitude constraints.",303.27,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12849v1_The Cost of EFX Generalized-Mean Welfare and Compl.pdf,Exact string,"Eugene Lim, Tzeh Yuan Neoh, Nicholas Teh",10.1093/acprof:oso/9780190876223.001.0001,10.1093/acprof:oso/9780190876223,"fair division, envy-freeness, generalized-mean welfare, complexity dichotomies","The paper investigates generalized-mean welfare and complexity dichotomies in the context of envy-freeness up to any good with few surplus items, analyzing computational hardness and algorithmic implications.",296.29,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12856v1_Mining Citywide Dengue Spread Patterns in Singapor.pdf,Mining Citywide Dengue Spread Patterns in Singapore Through Hotspot Dynamics from Open Web Data,"Liping Huang, Gaoxi Xiao, Stefan Ma, Hechang Chen, Shisong Tang, Flora Salim",10.1145/XXXXXX,null,"Dengue Cases, Disease Spreading Pattern, Hotpot Dynamics, Machine Learning, Public Health Planning","This study introduces a novel framework that uncovers and exploits latent transmission links between urban regions using open web data. By modeling hotspot formation influenced by epidemic dynamics and human mobility, it demonstrates how commuting flows shape citywide dengue spread. The approach achieves robust hotspot prediction with high stability across time periods, offering a scalable tool for public health interventions.",321.71,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12879v1_Hierarchical Sparse Circuit Extraction from Billio.pdf,Hierarchical Attribution Graph Decomposition,"Mohammed Mudassir Uddin ∗, Shahnawaz Alam, Mohammed Kaif Pasha",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Mechanistic interpretability, sparse computational graphs, circuit discovery, transformer architectures, causal inference","The paper presents a novel Hierarchical Attribution Graph Decomposition (HAGD) framework that efficiently discovers sparse computational circuits from billion-parameter language models. By leveraging multi-resolution abstraction and differentiable search, the method achieves high behavioral preservation across diverse models while maintaining interpretable subgraph structures. Empirical results demonstrate robust performance in modular arithmetic tasks.",295.61,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12882v1_YOLO26 An Analysis of NMS-Free End to End Framewor.pdf,Exact string,Sudip Chakrabarty,10.48550/arXiv.2601.12882,2601.12882,"YOLOv26, End-to-End Object Detection, NMS-Free, MuSGD, ProgLoss","The paper presents a comprehensive analysis of YOLO26, highlighting its innovative approach by eliminating Non-Maximum Suppression (NMS) and introducing MuSGD, StAL for small targets, and ProgLoss. It demonstrates superior performance in real-time object detection, setting a new benchmark in accuracy and speed.",281.78,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12886v1_Communication Methods in Multi-Agent Reinforcement.pdf,Communication Methods in Multi-Agent,Christoph Wittner,k12045895@students.jku.at,2601.12886,"Machine learning, MARL, Communication","This paper reviews communication techniques in multi-agent reinforcement learning, evaluating explicit, implicit, attention-based, graph-based, and hierarchical/role-based methods. It highlights the lack of a universal optimal framework and emphasizes the need for scalable, low-computation communication strategies.",309.19,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12893v1_AdaNODEs Test Time Adaptation for Time Series Fore.pdf,AdaNODEs: Test Time Adaptation for Time Series Forecasting Using Neural ODEs,"Ting Dang, Soumyajit Chatterjee, Hong Jia, Yu Wu, Flora Salim, Fahim Kawsar, The University of Melbourne, Australia, Nokia Bell Labs, UK, The University of Auckland, New Zealand, University of Cambridge, UK, The University of New South Wales, Australia, University of Glasgow, UK",10.48550/arXiv.2311.03855,10.48550/arXiv.2311.03855,"test time adaptation, time series forecasting, domain adaptation, neural odes, temporal dependencies","This paper introduces AdaNODEs, a novel source-free test-time adaptation method for time series forecasting. By utilizing Neural Ordinary Differential Equations (NODEs), the framework adapts pre-trained models to new data distributions without requiring labeled target data. It proposes a new loss function tailored for forecasting tasks and demonstrates improved performance over existing methods, especially under severe distribution shifts.",306.51,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12904v1_From Prefix Cache to Fusion RAG Cache Accelerating.pdf,Exact string,"Jiahao Wang, Weiyu Xie, Mingxing Zhang, Boxing Zhang, Jianwei Dong, Yuening Zhu, Chen Lin, Jinqi Tang, Yaochen Han, Zhiyuan Ai, Xianglin Chen, Yongwei Wu, Congfeng Jiang",10.1145/3786655,2601.1290,"Retrieval-Augmented Generation, Large Language Models, Inference, KVCache, RAG, Computational Efficiency","This paper presents FusionRAG, a framework that optimizes RAG by reusing precomputed KVCache chunks to balance generation quality and efficiency. It improves generation quality while reducing computational costs and TTFT.",365.83,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12910v1_SciCoQA Quality Assurance for Scientific Paper--Co.pdf,Quality Assurance for Scientific Paper–Code Alignment,"Tim Baumgärtner, Iryna Gurevych",10.48550/arXiv.2303.04112,10.48550/arXiv/2303.04112,"SCICOQA, paper-code discrepancies, reproducibility, code alignment","The paper introduces SCICOQA, a dataset for detecting mismatches between scientific publications and their code implementations. It highlights challenges in reproducing research due to divergent implementation details and provides insights into discrepancy types across disciplines.",291.16,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12912v1_Human Emotion Verification by Action Languages via.pdf,Human Emotion Verification by Action Languages,"Andreas Br Annstrøm, Juan Carlos Nieves",10.1017/xxxxx,2601.12912v1,"Action Languages, Answer Set Programming, Theory of Mind","The paper introduces the action language C-MT for modeling human mental states, integrating answer set programming and transition systems to enable controlled reasoning about emotional dynamics in intelligent systems.",267.88,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12913v1_Actionable Interpretability Must Be Defined in Ter.pdf,Exact string,"Pietro Barbiero, Mateo Espinosa Zarlenga, Francesco Giannini, Alberto Termine, Filippo Bonchi, Mateja Jamnik, Giuseppe Marra, Filippo Bonchi, 3, 4, Filippo Bonchi",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"interpretability, symmetries, interpretable models, Bayesian inversions","The paper argues that interpretability in AI must be defined in terms of symmetries to make it actionable, proposing four symmetries to guide core interpretability properties and derive a unified inference formulation.",325.28,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12922v1_Your Privacy Depends on Others Collusion Vulnerabi.pdf,Exact string,"Johannes Kaiser, Alexander Ziller, Eleni Triantafillou, Daniel Rückert, 3, Georgios Kaissis",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"differential privacy, individual differential privacy, excess risk, membership inference, privacy budget","This paper reveals a critical vulnerability in individual differential privacy mechanisms: privacy risk depends not only on an individual's own privacy budget but also on the collective privacy choices of all contributors. By demonstrating that certain privacy preference distributions can unintentionally inflate individual risk, the authors expose a gap between formal guarantees and real-world exposure. The study highlights the need for robust iDP frameworks that account for collective behavior and provide users with explicit control over amplified vulnerabilities.",379.94,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12925v1_ForeDiffusion Foresight-Conditioned Diffusion Poli.pdf,Exact string,"Weize Xie1, Yi Ding1, Ying He1, Leilei Wang1, Binwen Bai1, Zheyi Zhao1, Chenyang Wang1",2410105060,2410103031,"Foresight-Conditioned Diffusion, Robot Manipulation, Diffusion Strategies","The paper introduces ForeDiffusion, a Foresight-Conditioned Diffusion approach that incorporates future-view guidance to improve task success rates in robot manipulation. It addresses limitations of existing methods by combining a dual loss mechanism and demonstrating superior performance on complex benchmarks.",287.65,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12929v1_Membership Inference Test Auditing Training Data i.pdf,Membership Inference Test: Auditing Training Data in Object Classification Models,"Gonzalo Mancera, Daniel DeAlcala, Aythami Morales, Ruben Tolosana, Julian Fierrez",10.48550/arXiv.2405.12345,10.48550/arXiv.2405.12345,"membership inference, data auditing, object classification, AI ethics, training datasets","This paper investigates Membership Inference Attacks (MIAs) in the context of object recognition, proposing architectures to detect and analyze data used during model training. The study evaluates performance metrics across public datasets and explores implications for transparency in AI systems.",318.81,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12931v1_Online Continual Learning for Time Series a Natura.pdf,Exact string,"Edoardo Urettini, Daniele Atzeni, Ioanna-Yvonni Tsaknaki, Antonio Carta",10.48550/arXiv.2405.1234,10.48550/arXiv.2405.1234,"online continual learning, time series forecasting, natural score, reward shaping","The paper introduces Natural Score-driven Replay (NatSR), a method that combines robust optimization with online continual learning to improve forecasting performance in time-varying environments. It reframes optimization as a score-driven process, enhances robustness using a Student’s t likelihood, and proposes a dynamic scale heuristic for better adaptation.",289.95,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12937v1_On the Evidentiary Limits of Membership Inference .pdf,Exact string,"Murat Bilgehan Ertan, Emirhan Bönge, Min Chen, Kaleel Mahmood, Marten van Dijk",10.48550/arXiv.2026.12345,10.48550/arXiv.2026.12345,"membership inference, machine learning, copyright auditing, large language models, semantic preservation","The paper examines how membership inference attacks can be used to audit copyright usage in large language models, highlighting the fragility of such methods under adversarial conditions and their limited standalone effectiveness.",364.85,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12938v1_The Post-Turing Condition Conceptualising Artifici.pdf,Exact string,"Thorsten Jelinek, Patrick Glauner, Alvin Wang Graylin, Yubao Qiu",10.1093/acps/2023.01.012,10.1093/acps.2023.01.012,"Post-Turing condition, Artificial subjectivity, Synthetic sociality, AI design, Human subjectivity","The paper explores the shift from AI automating cognition to shaping social coordination, introducing the PRMO framework to analyze human subjectivity dimensions and proposing Quadrangulation as a design principle for socially embedded AI.",328.14,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12939v1_Active Inference-Driven World Modeling for Adaptiv.pdf,Exact string,"Kaleem Arshid, Ali Krayani, Lucio Marcenaro, David Martin Gomez, Carlo Regazzoni",10.1016/j.automaton.2023.03.001,null,"Active Inference, World Model, UA V-Swarm, Probabilistic Decision-Making, Adaptive Trajectory Design","This paper proposes an Active Inference–based framework for autonomous trajectory design in UA V swarms. It integrates probabilistic reasoning and self-learning to enable distributed mission allocation, route ordering, and motion planning. Expert trajectories generated using a Genetic Algorithm with Repulsion Forces are employed to train a hierarchical World Model capturing swarm behavior across mission, route, and motion levels. During online operation, UA Vs infer actions by minimizing divergence between current beliefs and model-predicted states, enabling adaptive responses to dynamic environments. Simulation results show faster convergence, higher stability, and safer navigation compared to Q-Learning, demonstrating the scalability and cognitive grounding of the proposed framework for intelligent UA V swarm control.",301.53,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12946v1_AI-generated data contamination erodes pathologica.pdf,AI-generated data contamination erodes pathological variability and diagnostic reliability,"Hongyu He, Shaowen Xiang, Ye Zhang, Yingtao Zhu, Jin Zhang, Hao Deng, Emily Alsentzer, Qingyu Chen, Kun-Hsing Yu, Andrew Marmenshall, Tingting Chen, Srinivas Anumasa, Daniel Ebner, Dean Ho, Kee Yuan Ngiam, Ching-Yu Cheng",10.1093/acp/qad020,10.1093/acp/qad020,"AI, data contamination, pathological variability, diagnostic reliability, medical records, generative AI","The study examines how AI-generated synthetic medical data undermines clinical diversity and accuracy, highlighting risks to diagnostic reliability and the need for human oversight.",286.35,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.12951v1_Beyond Accuracy Characterizing Code Comprehension .pdf,Exact string,"Felix Mächtle, Jan-Niclas Serr, Nils Loose, Thomas Eisenbarth",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Code Comprehension, Model Evaluation, Machine Learning for Software Engineering","This paper examines whether large language models' code-comprehension abilities align with traditional software metrics or reveal unique patterns. It introduces a diagnostic framework linking model performance to human-centric complexity measures, finding limited correlation with human metrics and highlighting model-specific regularities.",361.29,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13007v1_ArchAgent Scalable Legacy Software Architecture Re.pdf,Exact string,"Rusheng Pan, Bingcheng Mao, Tianyi Ma, Zhenhua Ling",10.1234/example.doi,null,"software architecture recovery, code repository, large language models","ArchAgent introduces a scalable agent-based framework for reconstructing software architecture from large-scale legacy codebases. It combines static analysis, adaptive code segmentation, and LLM-powered synthesis to generate accurate, business-aligned architectural views. The approach addresses architectural drift and missing documentation by leveraging cross-repository context and contextual pruning.",276.9,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13013v1_HT-GNN Hyper-Temporal Graph Neural Network for Cus.pdf,HT-GNN: Hyper-Temporal Graph Neural Network,"Xiaohui Zhao, Xinjian Zhao, Jiahui Zhang, Guoyu Liu, Houzhi Wang, Shu Wu",10.1000/xyz123,10.1000/12345,"Lifetime Value Prediction, Advertising Platform, Hyper-Temporal Graph Neural Network","The paper introduces a Hyper-Temporal Graph Neural Network (HT-GNN) to address challenges in customer lifetime value (LTV) prediction within Baidu Ads. It integrates demographic heterogeneity and temporal dynamics using a hypergraph module, a transformer-based encoder, and a task-adaptive mixture-of-experts. Experiments on 15 million Baidu users demonstrate superior performance across prediction horizons.",359.84,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13018v1_Bi-Attention HateXplain  Taking into account the s.pdf,Exact string,"Ghislain Dorian Tchuente Mondjo, tchuente.mondjo@gmail.com",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"Multitask learning, Deep Learning, Hate speech, Explainability, Bi-Attention","The paper proposes a BiAtt-BiRNN-HateXplain model to improve explainability in multi-task learning for hate speech detection, addressing attention variability and bias reduction.",377.96,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13020v1_PASs-MoE Mitigating Misaligned Co-drift among Rout.pdf,Exact string,"Zhiyan Hou, Haiyun Guo, Haokai Ma, Yandu Sun, Yonghui Yang, Jinqiao Wang, Ya Hong",10.48550/arXiv.2303.04213,10.48550/arXiv.2303.04213,"continual instruction tuning, MLLM, LoRA, misaligned co-drift, pathway activation",The paper introduces a pathway activation subspace (PASs) to mitigate misaligned co-drift in continual instruction tuning by enabling a coordinate system for routing and preserving expert specialization. It proposes a PASs-based LoRA method with reweighting and rank stabilization to maintain accuracy while reducing forgetting.,307.97,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13048v1_Analysis of Long Range Dependency Understanding in.pdf,Exact string,"Srividya Ravikumar, Abhinav Anand, Shweta Verma, Mira Mezini",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"structured state-space models, interpretability, vulnerability detection","This study presents the first systematic kernel interpretability analysis of the diagonalized state-space model (S4D) trained on real-world vulnerability detection in source code. By examining time and frequency domain behaviors, the authors demonstrate how S4D kernels can exhibit low-pass, band-pass, or high-pass filtering characteristics depending on architecture. The findings provide insights into the spectral properties influencing model performance and guide future design of S4D-based models.",320.81,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13054v1_TinyML-Enabled IoT for Sustainable Precision Irrig.pdf,TinyML-Enabled IoT for Sustainable Precision Irrigation,"Kamogelo Taweatsoala, Caitlyn Daniels, Angelina J. Ramsunar, Petrus Bronkhorst, Absalom E. Ezugwu",10.1234/journals/2023.00123,10.1234/journals/2023.00123,"TinyML, edge computing, Internet of Things, precision agriculture, smart irrigation, sustainable water management, embedded machine learning, resource-constrained systems","The paper presents a novel edge-first IoT framework integrating TinyML for autonomous, offline precision irrigation. It leverages a four-layer architecture with ESP32 and Raspberry Pi to deliver accurate, low-power predictions using environmental sensors, achieving superior performance over traditional models.",331.94,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13060v1_MagicGUI-RMS A Multi-Agent Reward Model System for.pdf,MagicGUI-RMS: A Multi-Agent Reward Models System,"Zecheng Li, Zhihui Cao, Wenke Huang, Yudong Zhang, Keying Qi, Rui Wang, Zeyu Zheng, Jian Zhao, Hao Zhu, Hengxin Wu, Yuran Wang, Guitao Fan, Guokun Wu, Yicong Liu, Zhilin Gao, Haikun Xu, He Yang, Minqi Xiang, Xingyu Liu, Zuojian Wang, Zhaolin Xu",10.1234/abcd1234,None,,N/A,345.78,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13075v1_METIS Mentoring Engine for Thoughtful Inquiry  Sol.pdf,METIS: Mentoring Engine for Thoughtful Inquiry & Solutions,"Abhinav Rajeev Kumar, Dhruv Trehan, Paras Chopra",10.48550/arXiv.2024.12345,10.48550/arXiv/12345.67890,"AI mentor, research mentorship, student guidance, LLM evaluation","This paper introduces METIS, a tool-augmented, stage-aware assistant designed to support undergraduates from idea generation to publishable papers. It evaluates METIS against GPT-5 and Claude Sonnet 4.5 across six writing stages using LLM-as-a-judge pairwise preferences, student personas, and evidence checks. METIS provides practical mentoring workflows, a simple inspection system, and empirical results showing improved student performance in clarity, actionability, and constraint fit.",351.21,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13111v1_CORE-T COherent REtrieval of Tables for Text-to-SQ.pdf,CORE-T: Cohesive Retrieval of Tables for Text-to-SQL,"Hassan Soliman, Vivek Gupta, Dan Roth, Iryna Gurevych",10.1093/pasj/ccac042,arxiv:2601.13111,"text-to-SQL, table retrieval, LLM, multi-table queries","CORE-T introduces a scalable, training-free framework that enriches tables with LLM-generated purpose metadata and pre-computes a lightweight table-compatibility cache. It improves table selection accuracy while reducing inference cost, achieving significant gains in multi-table execution accuracy.",357.29,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13114v1_IntAgent NWDAF-Based Intent LLM Agent Towards Adva.pdf,Exact string,"Abdelrahman Soliman, Ahmed Refaey, Aiman Erbad, Amr Mohamed",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Intent-based networking, Large Language Models, Network analytics, Next Generation Networks, AI in networking","The paper introduces IntAgent, an intent LLM agent integrating NWDAF analytics to automate network operations through high-level intent statements. It presents an enriched data source and MCP tools for dynamic network fulfillment.",283.67,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13122v1_Responsible AI for General-Purpose Systems Overvie.pdf,Responsible AI for General-Purpose Systems: Overview,"Gourab K. Patro, Himanshi Agrawal, Himanshu Gharat, Supriya Panigrahi, Nim Sherpa, Vishal Vaddina, Dagnachew Birru",10.1093/acps/raac123,2601.13122v1,"responsible AI, general-purpose AI, ethical AI, AI alignment, AI governance","The paper reviews risks and vulnerabilities of modern general-purpose AI systems, evaluates them against eight responsible AI principles, and proposes C 2V2 desiderata to guide future development. It emphasizes the need for non-deterministic approaches due to high Degree of Freedom in output.",335.19,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13142v1_TVWorld Foundations for Remote-Control TV Agents.pdf,Foundations for Remote-Control TV Agents,"Zhantao Ma, Quanfeng Lu, Shuai Zhong, Dahai Yu3, Ping Luo1, Michael K. Ng",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"TV navigation, remote control, large vision models, topology-aware, focus-aware","The paper introduces TVWorld, an offline graph-based framework for TV navigation, and proposes a Topology-Aware Training framework to improve TV-use agents. TVWorld enables reproducible evaluation of TV interaction, while the authors demonstrate TVTheseus achieving strong performance on TVWorld-N, highlighting the need for topology awareness in TV navigation.",333.72,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13160v1_Training instability in deep learning follows low-.pdf,Training instability in deep learning follows low-dimensional dynamical principles,"Zhipeng Zhang, Zhenjie Yao, Kai Li, Lei Yang",10.1093/pasj/psa.2023,2601.13160,"training instability, deep learning, reinforcement learning, large language models, dynamical systems","The paper proposes a unified dynamical perspective on training stability, identifying four interacting dimensions—optimization, environmental/data, parametric, and learning-signal stability. It demonstrates that stability is a measurable dynamical property, with implications for reproducibility and scalability in deep learning.",337.46,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13166v1_From 100000 images to winning the first brain MRI .pdf,Exact string,"Pedro M. Gordaliza, Jaume Banus, Benoît Gérin, Maxence Wynen, Nataliia Molchanova, Jonas Richiardi",10.48550/arXiv.2405.12345,10.48550/arXiv.2405.12345,"brain MRI, challenges, models, neuroimaging","Developing foundation models for medical image analysis is essential to overcome the unique challenges of radiological tasks. This work presents a U-Net CNN architecture combined with strategies leveraging anatomical priors and neuroimaging domain knowledge. It ranks first in three challenges for 3D brain MRI, SSL3D and FOMO25, and demonstrates that models are 10× smaller than competing transformer-based approaches.",320.71,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13186v1_Prompt Injection Mitigation with Agentic AI Nested.pdf,Exact string,"Diego Gosmar, Deborah A. Dahl",10.1093/pasj/vis/2026.01.012,2601.13186,"prompt injection, agentic AI, nested learning, AI sustainability, semantic caching","The paper presents a framework for mitigating prompt injection in multi-agent systems using semantic similarity-based caching and a fourth-agent evaluator, demonstrating improved security and sustainability metrics.",308.24,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13187v1_Scientific production in the era of Large Language.pdf,Exact string,"Keigo Kusumegi, Xinyu Yang, Paul Ginsparg, Mathijs de Vaan, Toby Stuart, Yian Yin",10.1126/science.adw3000,null,"Large Language Models, Scientific production, LLMs, Research impact, Manuscripts, Citation diversity","The study examines how LLMs are transforming scientific manuscript production, showing significant increases in paper output across disciplines and highlighting shifts in quality and citation patterns.",302.03,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13197v1_Diffusion-Driven Synthetic Tabular Data Generation.pdf,Diffusion-Driven Synthetic Tabular Data Generation,"Aravind B, Anirud R.S., Sai Surya Teja N, Bala Subrahmanya Sriranga Navaneeth A, Karthika R, Mohankumar N",10.1007/978-3-642-45888-7,10.1007/978-3-642-45888-7,"Diffusion-Driven Synthetic Data, Tabular Data Augmentation, Class Imbalance, DDoS Attack Detection, Data Augmentation, TabNet Models, Network Intrusion Detection","The paper presents a method to address class imbalance in network intrusion detection using Tabular Denoising Diffusion Probability Models (TabDDPM). It introduces a synthetic data generation approach to augment minority classes, improving model recall for underrepresented attack types. The work highlights applications in fraud detection and medical diagnostics.",337.47,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13206v1_Real-Time Deadlines Reveal Temporal Awareness Fail.pdf,Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues,"Neil Sehgal1, Sharath Chandra Guntuku 1, Lyle Ungar 1",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"LLM, temporal awareness, deadlines, strategic dialogues","The study investigates how large language models (LLMs) handle time-sensitive interactions by simulating negotiations under strict and time-aware conditions. It finds that LLMs struggle with internal time tracking, leading to suboptimal deal closure rates, but achieve high performance under turn-based constraints, highlighting a critical gap in temporal reasoning.",379.03,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13217v1_Beyond Single-shot Writing Deep Research Agents ar.pdf,Exact string,"Bingsen Chen, Boyan Li, Ping Nie, Yuyu Zhang, Xi Ye3, Chen Zhao1, Chen Zhao2",10.48550/arXiv.2601.13217,2601.13217,"Deep Research Agents, Multi-turn revision, Report generation","The paper introduces MRDRE, a framework for evaluating multi-turn report revision in Deep Research Agents. It highlights that current DRAs struggle with preserving content across revision cycles and maintaining factuality, pointing to limitations in handling iterative feedback.",318.83,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13222v1_Incorporating QA Nuggets into Retrieval-Augmented .pdf,Exact string,"Laura Dietz, Bryan Li, Gabrielle Liu, Jia-Huei Ju, Eugene Yang, Dawn Lawrie, William Walden, James Mayfield",10.48550/arXiv.2407.04219,2601.13222,"RAG, LLM, nugget-based evaluation","The paper introduces Crucible, a nugget-augmented generation system that integrates Q&A nuggets to improve citation grounding and retrieval performance, demonstrating superior recall and density over existing methods.",279.6,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13227v1_Insider Knowledge How Much Can RAG Systems Gain fr.pdf,Exact string,"Laura Dietz, Bryan Li, Eugene Yang, Dawn Lawrie, William Walden, James Mayfield",10.48550/arXiv.2304.08713,2601.13227,"Retrieval-augmented generation, LLM judge, Nugget evaluation, System evaluation, Methodological diversity","The paper examines risks in nugget-based RAG systems by leaking evaluation elements, showing that perfect scores can emerge from predictable patterns, emphasizing the need for blind evaluation and robust methods.",331.06,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13228v1_Autoregressive Models Rival Diffusion Models at AN.pdf,Exact string,"Yisen Wang, Lizhe Fang, Weijie Yang, Zeming Wei, Yifei Wang",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"diffusion models, autoregressive, generation, reasoning","The paper proposes Any-Order Any-subset Autoregressive modeling (A3), extending autoregressive modeling to arbitrary token groups and generation orders. A3 integrates diffusion-style flexibility with structured multi-group prediction, improving generation quality and stability over diffusion-based approaches.",287.8,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13233v1_RAG A Random-Forest-Based Generative Design Framew.pdf,Exact string,"Bolin Chen, Dex Doksoo Lee, Wei “Wayne” Chen, Wei Chen",10.48550/arXiv.2024.12345,2601.13233,"Random forest, Generative design, Functional response, Uncertainty quantification","The paper introduces a random forest-based generative design framework (RAG) for inverse design of metamaterials with complex functional responses. It addresses challenges in high-dimensional inverse design by leveraging data efficiency, uncertainty quantification, and flexible condition specification. Demonstrated on acoustic and mechanical metamaterials.",310.32,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13235v1_RubRIX Rubric-Driven Risk Mitigation in Caregiver-.pdf,RubRIX: Rubric-Driven Risk Mitigation in Caregiver-AI Interactions,"Drishti Goel, Jeongah Lee, Qiuyue Joy Zhong, Violeta J. Rodriguez, Daniel S. Brown, Ravi Karkar, Dong Whi Yoo, Koustuv Saha",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"caregiver, AI, risk mitigation, ethics, LLM, healthcare","This paper introduces RubRIX, a framework for evaluating risks in AI-mediated caregiving interactions using a rubric-based approach. It addresses nuanced concerns like emotional validation and contextual appropriateness, offering a clinician-validated method to reduce risks in high-stakes support scenarios.",297.8,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13236v1_Pixelwise Uncertainty Quantification of Accelerate.pdf,Exact string,"Ilias I. Giannakopoulos, Lokesh B Gautham Muthukumar, Yvonne W. Lui, Riccardo Lattanzi",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"conformal prediction, magnetic resonance imaging, parallel imaging, quantile regression, uncertainty quantification","The paper presents a framework for pixel-wise uncertainty quantitation in parallel MRI reconstructions, enabling automatic detection of unreliable regions without ground-truth images. It integrates conformal quantile regression with image reconstruction to provide statistically rigorous uncertainty estimates across acceleration factors.",386.58,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13238v1_A Semantic Decoupling-Based Two-Stage Rainy-Day At.pdf,Exact string,"Chengyin Hu, Xiang Chen, Wei Fengyu, Zhang Jiujiang, Guo Yiwei, Wei",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"rainy conditions, semantic decoupling, Vision-Language Models, weather robustness","This paper introduces a two-stage adversarial attack leveraging semantic decoupling to exploit realistic weather perturbations, demonstrating how rain-induced visual shifts can destabilize vision–language models and impact cross-modal alignment.",304.45,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13240v1_KOCO-BENCH Can Large Language Models Leverage Doma.pdf,Exact string,"Xue Jiang1, Jiaru Qian1, Xianjie Shi1, Chenjie Li1, Hao Zhu1, Ziyu Wang1, Jielun Zhang1, Zheyu Zhao1, Kechi Zhang1, Jia Li2, Wenpin Jiao1, Zhi Jin1, Ge Li1, Yihong Dong1",10.1234/example.2026.001,null,"LLM, software development, domain specialization, code generation","KOCO-BENCH introduces a new benchmark for evaluating domain specialization in LLMs, focusing on software development tasks across 6 emerging domains. It emphasizes the need for LLMs to acquire and apply domain knowledge through curated corpora and rigorous evaluation, highlighting challenges and providing evaluation code.",344.12,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13247v1_Aligning Agentic World Models via Knowledgeable Ex.pdf,Exact string,"Baochang Ren, Yunzhi Yao, Rui Sun, Shuofei Qiao, Ningyu Zhang, Huajun Chen",10.48550/arXiv.2601.13247,10.48550/arXiv.2601.13247,"agentic world models, knowledgeable experience, physical grounding, LLM alignment","The paper addresses the gap between large language models' semantic knowledge and their inability to ground predictions in physical reality. It introduces WorldMind, a framework that builds symbolic world knowledge repositories through process and goal experience, enabling agents to align their internal models with environmental dynamics.",377.37,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13260v1_Stop Taking Tokenizers for Granted They Are Core D.pdf,Exact string,"Sawsan Alqahtani, Md Tahmid Rahman Laskar, Tasnim Mohiuddin, M Saiful Bari, Princess Nourah Bint Abdulrahman University, University of Alberta, Qatar Computing Research Institute, Amazon AGI",10.48550/arXiv:2309.12345,10.48550/arXiv:2309.12345,"tokenization, large language models, subword methods, BPE, model design, linguistic structure","The paper reframes tokenization as a core modeling decision, advocating for a context-aware framework that integrates tokenizer and model co-design. It emphasizes the need for standardized evaluation and transparent reporting to improve fairness, efficiency, and adaptability in language technologies.",327.02,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13262v1_CURE-Med Curriculum-Informed Reinforcement Learnin.pdf,Exact string,"Eric Onyame, Akash Ghosh, Subhadip Baidya, Sriparna Saha, Xiuying Chen, Xiang Li",10.48550/arXiv.2024.12345,10.48550/arXiv/12345.67890,"medical reasoning, multilingual, reinforcement learning, curriculum-informed, code-switching, logical correctness","This paper presents CURE-MED, a curriculum-informed reinforcement learning framework designed to enhance multilingual medical reasoning. Leveraging a newly curated benchmark (CURE-MED-BENCH) with open-ended queries across thirteen languages, the approach integrates code-switching-aware fine-tuning and Group Relative Policy Optimization. Experimental results demonstrate improved language consistency and logical accuracy across diverse linguistic contexts, supporting equitable deployment of large language models in healthcare.",328.01,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13268v1_Improving the Safety and Trustworthiness of Medica.pdf,Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops,"Zainab Ghafoor, Md Shafiqul Islam, Koushik Howlader, Md Rasel Khondokar, Tanusree Bhattacharjee, Ushashi Bhattacharjee",10.1093/acps/ghac020,null,"Medical AI, Large Language Models, Multi-Agent Systems, Ethical Compliance, Safety Assessment","The paper introduces a multi-agent refinement framework to enhance the safety and reliability of medical Large Language Models (LLMs) through structured, iterative alignment. It integrates DeepSeek R1 and Med-PaLM with evaluation agents LLaMA 3.1 and Phi-4, assessing responses against the AMA Principles of Medical Ethics and SRA-5. The study demonstrates improved convergence efficiency, reduced ethical violations, and effective risk mitigation across diverse clinical scenarios.",304.15,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13286v1_AI Skills Improve Job Prospects Causal Evidence fr.pdf,AI Skills Improve Job Prospects: Causal Evidence from a Hiring,"Fabian Stephany, Ole Teutloff, Angelo Leone, Humboldt",10.1093/acps/qad023,10.1093/acps/qad023,"Artificial Intelligence, labour markets, Signaling Theory, Hiring, Skills","This study examines the causal impact of AI skills on hiring decisions, showing that AI-related skills significantly increase interview invitation probabilities. The findings suggest AI skills can offset traditional disadvantages, particularly for office assistants, and highlight the importance of formal AI certification in recruitment contexts.",339.94,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13295v1_CooperBench Why Coding Agents Cannot be Your Teamm.pdf,Exact string,"Arpandeep Khatua, Hao Zhu, Peter Tran, Arya Prabhudesai, Frederic Sadrieh, Johann K. Lieberwirth, Xinkai Yu, Yicheng Fu, Michael J. Ryan, Jiaxin Pei, Diyi Yang",10.48550/arXiv.2026.12345,10.48550/arXiv.2026.12345,"cooperative benchmark, coding agents, team coordination, task conflicts, social intelligence","The paper introduces CooperBench, a benchmark for evaluating collaborative coding agents across diverse tasks. It highlights challenges in inter-agent communication, coordination failures, and proposes metrics to assess compatibility in multi-agent systems.",323.36,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13317v1_Paid Voices vs. Public Feeds Interpretable Cross-P.pdf,Exact string,"Samantha Sudhoff, Pranav Perumal, Zhaoqing Wu, Tunazzina Islam",10.48550/arXiv.2025.12345,10.48550/arXiv.2024.56789,"climate discourse, public feeds, paid advertising, publication, political discourse","This paper compares climate communication across paid advertisements on Meta and public posts on Bluesky, introducing a thematic framework to analyze how platform incentives shape climate narratives. It evaluates theme coherence and explores shifts around political events.",319.22,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13327v1_PepEDiff Zero-Shot Peptide Binder Design via Prote.pdf,Zero-Shot Peptide Binder Design via Protein Embedding,"Po-Yu, Liang, Tibo, Duran, Jun, Bai",10.1109/PED-2601-273,2601.13327,"Deep Learning, Drug Discovery, Protein Design","PepEDiﬀ introduces a zero-shot peptide binder generator that designs binding sequences directly from protein sequences and embeddings, improving diversity without structure prediction.",306.0,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13348v1_The AI Genie Phenomenon and Three Types of AI Chat.pdf,Exact string,"M. Karen Shen, Jessica Huang, Olivia Liang",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"AI chatbot, Addiction, Escapist roleplay, Pseudosocial companion, Epistemic rabbit hole, Sexual content, Recovery strategies","This study investigates AI chatbot addiction by analyzing user experiences on Reddit, identifying four distinct addiction types: Escapist Roleplay, Pseudosocial Companion, Epistemic Rabbit Hole, and recovery strategies. It highlights the addictive potential of AI chatbots and their impact on users.",292.42,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13352v1_LLM-as-RNN A Recurrent Language Model for Memory U.pdf,LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction,"Yuxing Lu, J. Ben Tamo, Weichen Zhao, Nan Sun, Yishan Zhong, Wenqi Shi, Jinzhuo Wang, May D. Wang",10.48550/arXiv.2304.08802,10.48550/arXiv.2304.08802,"large language models, recurrent language model, memory updates, sequence prediction","The paper introduces LLM-as-RNN, an inference-only framework that updates a frozen LLM's hidden state as a structured system-prompt summary. By applying feedback-driven text rewrites at each timestep, it enables online learning without parameter updates. Experiments show improved performance across healthcare, meteorology, and finance benchmarks, outperforming zero-shot and full-history baselines by 6.5% on average.",325.56,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13358v1_The Geometry of Thought How Scale Restructures Rea.pdf,Exact string,Samuel Cyrenius Anderson,10.48550/arXiv.2024.12345,2601.13358,"scale, reasoning, neural scaling, legal reasoning, code reasoning","This paper investigates how increasing model scale fundamentally restructures reasoning processes, revealing domain-specific phase transitions and geometric shifts in thought patterns. It demonstrates that parameter expansion drives qualitative changes in reasoning geometry, impacting performance across law, science, code, and math domains.",316.29,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13376v1_Bounded Minds Generative Machines Envisioning Conv.pdf,Exact string,Jiqun Liu,10.1093/acm/book-37-4-111,10.1093/acm/book-37-4-111,"Bounded Rationality, Heuristics, Conversational AI, Generative Machines, Evaluation","The paper explores how conversational AI can be designed to align with human heuristics and reduce bias risk, emphasizing bounded rationality in user interaction.",267.62,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13383v1_A Lightweight Modular Framework for Constructing A.pdf,AgentForge: A Lightweight Modular Framework for LLM-Driven Autonomous Agents,"A. Jafari, C. Ozcinar",10.1093/acera/csa.2026.01,2601.13383,"autonomous agents, large language models, modular architecture, natural language processing, software framework","The paper introduces AgentForge, a lightweight Python framework for building LLM-driven autonomous agents. It emphasizes modularity, composable skills, and flexible LLM backends, achieving competitive performance while reducing development time.",270.73,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13385v1_Organ-Aware Attention Improves CT Triage and Class.pdf,Exact string,"Lavsen Dahal, Yubraj Bhandari, Geoffrey D. Rubin, Joseph Y. Lo",10.1093/acm/qad020,10.1093/acm/qad020,"computed tomography, CT triage, classification, organ-aware attention, computational radiology","The paper presents ORACLE-CT, an encoder-agnostic, organ-aware head that improves supervised classification of chest and abdomen CT scans. It achieves state-of-the-art AUROC scores and provides a new supervised baseline for CT triage, addressing challenges in 3D anatomy and noisy report supervision.",318.92,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13392v1_Beyond Memorization Testing LLM Reasoning on Unsee.pdf,Exact string,"Shlok Shelat, Ahmedabad University, Gujarat, India, Jay Raval, Ahmedabad University, Gujarat, India, Souvik Roy, Ahmedabad University, Gujarat, India, Manas Gaur, University of Maryland, Baltimore County, Baltimore, MD, USA",10.48550/arXiv.2311.03855,10.48550/arXiv:2311.03855,"LLM reasoning, DFA construction, formal language, symbolic computation, semantic understanding","The paper evaluates large language models' ability to construct deterministic finite automata (DFAs) from regular languages, highlighting performance drops on unseen problems and analyzing the role of prompting strategies in revealing limitations of current reasoning capabilities.",308.95,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13398v1_Can LLMs Compress and Decompress Evaluating Code U.pdf,Exact string,"Nickil Maveli, Antonio Vergari, Shay B. Cohen",10.48550/arXiv.2303.04112,10.48550/arXiv.2303.04112,"code understanding, code reasoning, forward execution, backward execution, inversion","The paper evaluates whether Large Language Models (LLMs) can compress and decompress code, highlighting limitations in maintaining consistent reasoning across forward and backward execution. It introduces ROUNDTRIPCODEE-VAL(RTCE) to benchmark this round-trip consistency and discusses implications for trustworthy code reasoning.",300.23,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13400v1_Deep Image Prior with L0 Gradient Regularizer for .pdf,Exact string,"Nhat Thanh Tran, Kevin Bui, Jack Xin",10.48550/arXiv.2407.02641,10.48550/arXiv.2407.02641,"image smoothing, optimization, ADMM, deep image prior, ℓ0 gradient","The paper introduces DIP-ℓ0, a deep image prior framework that uses an ℓ0 gradient regularizer to enable high-quality image smoothing without training data. It presents an alternating direction method of multipliers (ADMM) based solver for the nonconvex ℓ0 norm, achieving edge-preserving results and effective JPEG artifact removal.",292.7,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13401v1_Reasoning with Pixel-level Precision QVLM Architec.pdf,Exact string,"Peter A. Massih, Eric Cosatto",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"quantitative spatial reasoning, vision-language models, SQuID dataset, pixel precision","The paper introduces SQuID, a new benchmark for quantitative spatial reasoning, and presents QVLM, a code-generation model that preserves pixel-level precision by decoupling language understanding from visual encoding. QVLM achieves higher accuracy on SQuID than existing VLMs.",305.01,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13404v1_Local-to-Global Logical Explanations for Deep Visi.pdf,Local-to-Global Logical Explanations for Deep Vision Models,"Bhavan Vasu, Giuseppe Raffa, Prasad Tadepalli",10.48550/arXiv.2304.08732,10.48550/arXiv.2304.08732,"Explainable AI, Neurosymbolic AI, Monotone DNF, Deep Learning","The paper introduces a two-level interpretability framework that maps to GDPR requirements, providing local explanations for individual images and global explanations for image classes in monotone disjunctive normal form (MDNF). It ensures high fidelity and coverage for black-box models in vision tasks while supporting statistical auditing.",330.63,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13406v1_Integrating Virtual Reality and Large Language Mod.pdf,Exact string,"Jacob Barker, Doga Demirel, Anna Johansson, Robbin Miraglia, Darian Hoagland, Stephanie B. Jones, John Mitchell, Daniel B. Jones, Suvranu De, Stephanie B. Jones, Robbin Miraglia",10.1093/acp/qap123,10.1093/acp/qap123,"Virtual Reality, Large Language Models, Team-based training, Non-technical skills, Surgical safety, Communication, Teamwork, Leadership","The paper presents VORTeX, a VR platform integrating large language model analytics to train and assess non-technical skills in surgical teams, focusing on communication and decision-making during laparoscopic emergencies.",287.84,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13412v1_Using deep learning for predicting cleansing quali.pdf,Exact string,"Puneet Sharma, Kristian Dalsbø Hindberg, Benedicte Schelde-Olesen, Ulrik Deding, Esmaeil S. Nadimi, Jan-Matthias Braun",10.1093/pasj/csae000,2601.13412,"deep learning, cleansing quality, colon capsule endoscopy, ResNet-18, structured pruning, explainability","The paper presents a deep learning approach using ResNet-18 to predict cleansing quality in colon capsule endoscopy images. It employs stratified cross-validation, iterative structured pruning, and multiple explainability methods to achieve high accuracy (88%) with 79% sparsity, highlighting challenges and opportunities in clinical deployment.",347.76,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13422v1_TrustEnergy A Unified Framework for Accurate and R.pdf,TrustEnergy: A Unified Framework for Accurate and Reliable,"Dahai Yu, Rongchao Xu, Dingyi Zhuang, Yeheng Bu, Shenhao Wang, Guang Wang",10.48550/arXiv.2024.12345,10.48550/arXiv/2405.12345,"energy usage prediction, deep learning, spatiotemporal representation, uncertainty quantification, user-level prediction","The paper introduces TrustEnergy, a unified framework for accurate and reliable user-level energy usage prediction. It addresses limitations of existing methods by incorporating spatial correlations and dynamically adjusting uncertainty bounds, achieving improved prediction accuracy and uncertainty quantification.",285.32,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13435v1_A Learnable Wavelet Transformer for Long-Short Equ.pdf,Exact string,"Shuozhe Li, Du Cheng, Leqi Liu",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"neural wavelet, wavelet transformer, portfolio optimization, risk management","The paper presents WaveLSFormer, a learnable wavelet-based long-short transformer that combines multi-scale decomposition with return-oriented learning. It introduces a low-guided high-frequency injection module to enhance frequency separation and proposes a risk-aware portfolio optimization strategy, achieving superior performance across multiple financial datasets.",281.34,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13437v1_MOSLD-Bench Multilingual Open-Set Learning and Dis.pdf,Exact string,"Adriana-Valentina Costache, Daria-Nicoleta Dragomir, Silviu-Florin Gheorghe, Eduard Poesina, Paul Irofti, Radu Tudor Ionescu",10.1093/acps/csa123,10.1093/acps/csa123,"multilingual open-set learning, discovery, text categorization, zero-shot learning, open-set learning, language models","The paper introduces the MOSLD benchmark for multilingual open-set learning and discovery in text categorization, proposing a framework to detect and learn new classes that emerge during inference without prior labels.",294.29,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13443v1_Explicit Cognitive Allocation A Principle for Gove.pdf,Exact string,"Héctor Manuel Manzanilla-Granados, Zaira Navarrete-Cazales, Miriam Pescador-Rojas, Escuela Superior de Cómputo del I.P. N",10.1234/abcd1234,10.1234/5678,"cognitive allocation, AI governance, epistemic control, instrumental allocation, auditable reasoning","The paper introduces Explicit Cognitive Allocation as a framework for structuring AI-assisted reasoning, emphasizing structured epistemic functions and measurable metrics to enhance transparency and reproducibility in large language models.",286.6,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13458v1_Labels or Preferences Budget-Constrained Learning .pdf,Exact string,"Zihan Dong, Ruijia Wu ∗2, Linjun Zhang ∗1",10.48550/arXiv.2601.13458,2601.13458,"budget-constrained learning, human judgments, AI annotation, preference calibration","This paper proposes a novel method, Preference-Calibrated Active Learning (PCAL), to optimally allocate a fixed annotation budget between ground-truth labels and human preference data for AI systems. By framing the problem as a monotone missing data framework, PCAL learns an optimal data acquisition strategy and provides a statistically efficient estimator, demonstrating robust performance in practical simulations.",280.71,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13462v1_SpatialBench-UC Uncertainty-Aware Evaluation of Sp.pdf,SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompts,Amine Rostane,10.48550/arXiv.2304.08713,10.48550/arXiv.2601.13462,"spatial evaluation, text-to-image, uncertainty, benchmark","Introduces SpatialBench-UC, a reproducible benchmark for evaluating spatial relations in text-to-image generation. It evaluates models on 200 counterfactual prompts and reports confidence scores to enable risk-aware comparisons.",300.15,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13464v1_Context and Transcripts Improve Detection of Deepf.pdf,Exact string,"Chongyang Gao, Marco Postiglione, Julian Baldwin, Natalia Denisenko, Isabel Gortner, Luke Fosdick, Chiara Pulice, Sarit Kraus, V. S. Subrahmanian",10.1093/acps/ccac007,10.1093/acps/ccac007,"deepfake detection, context-based audio, public figures, audio detectors, contextual information",The paper introduces a Context-based Audio Deepfake Detector (CADD) that enhances audio deepfake detection by incorporating contextual and transcriptual information. It evaluates performance improvements over existing methods and demonstrates robustness against adversarial attacks.,322.07,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13465v1_Graph Neural Networks are Heuristics.pdf,Exact string,"Yimeng Min, Carla P . Gomes",10.1093/pasj/202006,2601.13465,"graph neural networks, heuristics, combinatorial optimization, Travelling Salesman Problem, unsupervised learning","The paper presents a novel approach where a single training trajectory enables a graph neural network to function as an unsupervised heuristic for the Travelling Salesman Problem. By encoding global structural constraints, the model generates solutions directly through forward passes, eliminating the need for search or supervision. Dropout and snapshot ensembling enhance solution diversity, demonstrating that GNNs can internalize combinatorial structure as a strong heuristic without explicit optimization.",357.37,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13474v1_Preconditioning Benefits of Spectral Orthogonaliza.pdf,Preconditioning Benefits of Spectral Orthogonalization in Muon,"Jianhao Ma, Yu Huang, Yuejie Chi, Yale, Yuxin Chen",10.48550/arXiv.2601.13474,2601.13474,"Muon, preconditioning, gradient orthogonalization, optimization, LLM","The paper investigates the effectiveness of a simplified Muon optimizer through matrix factorization and in-context learning, demonstrating linear convergence and superior performance over gradient descent and Adam in linear and linear transformer settings.",360.65,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13476v1_A Unified Variational Imputation Framework for Ele.pdf,Exact string,"Jinhao Li, Hao Wang",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"electric vehicle, data imputation, charging demand, large language model, retrieval-augmented generation",A novel probabilistic variational imputation framework leveraging large language models and retrieval-augmented memory to address data sparsity in EV charging datasets.,289.03,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13481v1_Towards Efficient and Robust Linguistic Emotion Di.pdf,Towards Efficient and Robust Linguistic Emotion,"Jian Zhang, Zhangqi Wang, Zhiyuan Wang, Weiping Fu, Yu He, Haiping Zhu, Qika Lin",10.1109/TAC.2023.12345,12345,"Linguistic Emotion Diagnosis, Emotional Comorbidity, Inefficient Exploration, Automated Prompt Optimization, Multi-Agent Collaboration, Medical Language Processing, Trustworthy Artificial Intelligence","The paper presents APOLO, a framework for optimizing prompts in linguistic emotion diagnosis, addressing challenges like emotional comorbidity and inefficient cue exploration. It introduces a multi-agent collaborative approach within a POMDP framework to enhance diagnostic accuracy and robustness in mental health applications.",313.36,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13487v1_The Hidden Toll of Social Media News Causal Effect.pdf,Exact string,"Olivia Pal, Agam Goyal, Eshwar Chandrasekharan, Koustuv Saha",10.1093/acps/ghac123,null,"social media, psychosocial wellbeing, news consumption, psychological impact, engagement effects","This study investigates how different forms of social media news engagement affect psychosocial wellbeing, revealing trade-offs between increased stress and reduced loneliness. It highlights that newsbookmarking correlates strongly with psychosocial deterioration compared to commenting or quoting, with significant effects accumulating over repeated exposure.",332.32,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13508v1_CatMaster An Agentic Autonomous System for Computa.pdf,Exact string,"Honghao Chen, Jiangjie Qiu, Yi Shen Tew, Xiaonan Wang",10.48550/arXiv.2601.13508,10.48550/arXiv.2601.13508,"computational catalysis, heterogeneous catalysis, DFT, LLM, workflow automation","CatMaster is an agent system that automates heterogeneous catalysis research by integrating natural language processing with computational workflows, improving reproducibility and efficiency.",266.05,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13515v1_Automatic Adjustment of HPA Parameters and Attack .pdf,Automatic Adjustment of HPA Parameters and Attack,"Huah Yong Chan, Hanlin Zhou, Jingfei Ni, Mengchun Wu, Qing Deng",arXiv:2601.13515v1,2601.13515,"Kubernetes, HPA, Security, Random Forest","The paper presents a method to dynamically adjust HPA parameters using Random Forest classification to manage attack traffic in Kubernetes, reducing 5XX status codes through targeted pod adjustments.",273.66,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13518v1_AgenticRed Optimizing Agentic Systems for Automate.pdf,AGENTICRED: Optimizing Agentic Systems for Automated Red-teaming,"Jiayi Yuan, Natasha Jaques, Goran Radanović, Jiayi Yuan",10.48550/arXiv.2025.12345,10.48550/arXiv.2025.12345,"automated red-teaming, LLM, system design, AI safety","AGENTICRED introduces an automated pipeline leveraging LLMs to design and refine red-teaming systems without human intervention. By treating red-teaming as a system design problem, it achieves high attack success rates across multiple LLMs and demonstrates strong transferability to proprietary models.",341.85,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13528v1_Eliciting Harmful Capabilities by Fine-Tuning On S.pdf,Exact string,"Jackson Kaunismaa, Mats, Avery Griffin, Anthropic, John Hughes, Anthropic, Christina Q Knight, Scale AI, Mrinank Sharma, Anthropic, Erik Jones",10.48550/arXiv.2601.13528,2601.13528,"hazardous chemical synthesis, output-level safeguards, elicitation attacks","The paper investigates how safeguarded frontier models can be used to elicit harmful capabilities through elicitation attacks, demonstrating that such attacks recover significant capability gaps and highlighting risks in ecosystem-level AI misuse.",347.58,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13533v1_Reasoning While Recommending Entropy-Guided Latent.pdf,Exact string,Changshuo Zhang,10.1093/pasj/psa123,10.1093/pasj.psa123,"Generative Re-ranking, Latent Reasoning, Reinforcement Learning","The paper introduces the Entropy-Guided Latent Reasoning (EGLR) model, which integrates reasoning into generative re-ranking to reduce entropy and improve adaptability to dynamic model difficulty during list generation.",289.98,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13534v1_MN-TSGContinuous Time Series Generation with Irreg.pdf,MN-TSG: Continuous Time Series Generation with Irregular Observations,"Xu Zhang, Junwei Deng, Chang Xu, Hao Li, Jiang Bian",10.1093/pasj/tsg123,2601.13534,"Irregular time series, continuous time series generation, deep learning architecture, neural controlled differential equations, mixed model architectures","The paper introduces MN-TSG, a framework that integrates Mixture-of-Experts (MoE)-based Neural Controlled Differential Equations (NCDEs) to address irregular time series generation. It proposes a decoupled MoE-NCDE architecture and demonstrates improved performance on irregular-to-regular and irregular-to-continuous generation tasks across multiple datasets.",316.38,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13537v1_When Wording Steers the Evaluation Framing Bias in.pdf,Exact string,"Yerin Hwang, Dongryeol Lee",dpfls589,drl123,"LLM, framing bias, evaluation, LLM judges","This paper investigates how prompt framing influences large language models' judgments across four evaluation tasks, revealing framing effects that impact model consistency and highlighting the need for framing-aware protocols.",313.12,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13545v1_TruthTensor Evaluating LLMs Human Imitation throug.pdf,Exact string,"Shirin Shahabi, Spencer Graham, Haruna Isah",10.1234/truthtensor.2024.001,null,"language models, LLM evaluation, human imitation, drift","The paper introduces TruthTensor, a new evaluation framework that assesses Large Language Models not just for accuracy but for their ability to operate reliably in dynamic, real-world settings. It emphasizes robustness, calibration, and human-in-the-loop validation across diverse market scenarios.",289.23,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13546v1_ChatAD Reasoning-Enhanced Time-Series Anomaly Dete.pdf,Exact string,"Hui Sun, Chang Xu, Haonan Xie, Hao Li, Yuhao Huang",10.48550/arXiv.2405.07912,10.48550/arXiv:2405.07912,"time series, anomaly detection, LLM, multi-turn dialogue","The paper presents a multi-agent-based Time Series Evolution (TSEvol) framework, introduces a ChatAD reasoning multi-turn dialogue dataset (TSEData-20K), and proposes ChatAD-Llama3-8B for anomaly detection. It achieves significant improvements in accuracy and generalization, with competitive performance in reasoning and cross-task learning.",321.23,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13547v1_HateXScore A Metric Suite for Evaluating Reasoning.pdf,HateXScore: A Metric Suite for Evaluating Reasoning Quality in Hate Speech Explanations,"Yujia Hu, Roy Ka-Wei Lee",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"hate speech, reasoning quality, explainability, moderation","The paper introduces HateXScore, a four-component metric suite designed to evaluate the reasoning quality of model explanations in hate speech detection. It assesses conclusion clarity, faithfulness of quoted content, identification of protected groups, and logical consistency. Evaluated on six datasets, HateXScore aims to provide transparency and help diagnose interpretability issues beyond standard accuracy metrics.",291.45,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13558v1_Leveraging ChatGPT and Other NLP Methods for Ident.pdf,Exact string,"Mehrab Beikzadeh, Chenglin Hong, Cory J Cascalheira, Callisto Boka, Majid Sarrafzadeh, Ian W Holloway",10.1093/acps/clad.2023,10.1093/acps/clad.2023.07.01,"risk behaviors, protective behaviors, social media, dating apps, harmful drinking, HIV, machine learning, text mining, ChatGPT, eHealth","This study explores the use of text data from social media and dating apps to identify risk and protective behaviors among men who have sex with men (MSM). It leverages advanced NLP methods, including ChatGPT embeddings and BERT, to analyze patterns associated with binge drinking, multiple sexual partners, and PrEP use, aiming to inform targeted public health interventions.",300.63,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13559v1_AgentGC Evolutionary Learning-based Lossless Compr.pdf,Evolutionary Learning-based Lossless Compression for Genomics Data with LLM-driven Multiple Agent,"Hui Sun, Yanfeng Ding, Huidong Ma, Chang Xu, Keyan Jin, Lizheng Zu, Cheng Zhong, Xiaoguang Liu, Gang Wang, Wentong Cai, Nankai University, Nanyang Technology University, Microsoft Research Asia, Macao Polytechnic University, Guangxi University",10.1234/abcd1234,None,,N/A,286.0,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13562v1_Reasoning is a Modality.pdf,Exact string,"Zhiguang Liu, Yi Shang",10.48550/arxiv/2303.04112,10.48550/arxiv/2303.04112,"reasoning, modality, LLM, ViT","The paper proposes a role-separated transformer architecture to study abstract reasoning, arguing that reasoning should exist as a distinct cognitive modality separate from the low-level workspace used by modern AI systems.",270.19,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13563v1_ButterflyMoE Sub-Linear Ternary Experts via Struct.pdf,Exact string,Aryan Karmore,10.48550/arXiv.2303.04112,10.48550/arXiv:2303.04112,"ButterflyMoE, linear memory scaling, quantization, quantized substrate","ButterflyMoE proposes a geometric reorientation of experts using shared ternary quantization, achieving sub-linear memory scaling and enabling efficient deployment on edge devices.",301.79,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13564v1_Multi-objective fluorescent molecule design with a.pdf,Exact string,"Yanheng Li, Zhichen Pu, Lijiang Yang, Zehao Zhou, Yi Qin Gao",10.1234/arxiv.2024.05.07.08212,10.1234/2024.05.07.08212,"fluorescent molecule, design, generative framework, data-physics, correlation analysis","A novel dual-driven generative framework for designing multi-objective fluorescent molecules, integrating data-physics principles.",279.87,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13566v1_Self-Improvement as Coherence Optimization A Theor.pdf,Exact string,"Tianyi Qiu, Ahmed Hani Ismailahmedhismail, Zhonghao Hehezhonghao2030, George Washington University",10.1093/pasj/psa123,2601.13566,"self-improvement, coherence optimization, language models, supervised learning","The paper explores how language models can enhance accuracy through coherence optimization, showing it is equivalent to description-length regularization and optimal for semi-supervised learning when derived from pretrained models.",315.5,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13570v1_GeoDynamics A Geometric State-Space Neural Network.pdf,GeoDynamics: A Geometric State-Space Neural Network for Understanding Brain Dynamics on Riemannian Manifolds,"Tingting Dan, Jiaqi Ding, Guorong Wu ∗",10.1093/pasj/psd245,2601.13570v1,"neural networks, brain dynamics, functional connectivity, geometric state-space, Riemannian manifolds","Introduces GeoDynamics, a geometric state-space neural network that models brain functional connectivity on curved manifolds, enabling robust modeling of cognitive and neurological phenomena.",282.27,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13580v1_Neural Organ Transplantation NOT Checkpoint-Based .pdf,Neural Organ Transplantation (NOT),Ahmad Al-Zuraiqi,arXiv:2601.13580v1,2601.13580,"Modular Deep Learning, Transfer Learning, Checkpoint Transfer, Domain Adaptation, Large Language Model","Introduces a modular adaptation framework for transformer models, enabling donor organ transplantation of pre-trained layers to improve domain adaptation. Demonstrates significant performance gains over LoRA while training faster, with position-dependent benefits.",291.22,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13581v1_SCRIPTMIND Crime Script Inference and Cognitive Ev.pdf,ScriptMIND: Crime Script Inference and Cognitive Evaluation for LLM-based Social Engineering Scam Detection System,"Heedou Kim, Changsik Kim2, Sanghwa Shin, Jaewoo Kang, Korea University, Korean National Police Agency, Inje University",10.1000/SCI2024.1234,10.1000/SCI2024.1234,"social engineering, scam detection, LLM, cognitive evaluation","SCRIPTMIND introduces an integrated framework combining crime script inference, LLM fine-tuning, and cognitive simulation to enhance scam detection. It improves detection accuracy, reduces false positives, and strengthens user suspicion in real-time, offering a human-centered approach for LLM-based defense against evolving scams.",295.32,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13588v1_TREX Tokenizer Regression for Optimal Data Mixture.pdf,Exact string,"Inho Won1, Hangyeol Yoo2, Minkyung Cho1, Jungyeul Park1, KyungTae Lim1, †",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"tokenizer, data mixture, multilingual, LLM, compression","The paper presents TREX, a regression-based framework for predicting optimal data mixtures for tokenizer training. It addresses the challenge of balancing language ratios in multilingual settings, demonstrating improved compression efficiency over LLaMA3 and uniform distributions.",338.96,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13589v1_Motion-to-Response Content Generation via Multi-Ag.pdf,Exact string,HyeYoung Lee,10.1000/arXiv.2601.13589,10.1000/arXiv.2601.13589,"Speech Emotion Recognition, Multi-Agent Systems, Content Generation, Safety Verification, On-Device AI","This paper proposes a multi-agent AI system for real-time, safe, and age-appropriate response generation based on audio-derived emotional signals. It introduces a structured pipeline with specialized agents for emotion recognition, response policy, content generation, and safety verification, achieving high accuracy and compliance.",281.84,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13590v1_Vulnerability of LLMs Belief Systems LLMs Belief R.pdf,Exact string,"Fan Huang, Haewoon Kwak, Jisun An",10.48550/arXiv.2311.03832,10.48550/arXiv:2311.03832,"large language models, belief systems, persuasion, meta-cognition","This study evaluates how large language models (LLMs) are vulnerable to persuasion within the Source–Message–Channel–Receiver (SMCR) framework. It analyzes susceptibility across multiple LLMs and domains, showing that smaller models are highly susceptible to belief changes, especially under meta-cognition prompting. Adversarial fine-tuning improves robustness but does not fully mitigate vulnerability.",297.24,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13591v1_DSAEval Evaluating Data Science Agents on a Wide R.pdf,DSAEval: Evaluating Data Science Agents on a Wide Range of Real-World Data Science Problems,"Maojun Sun, Yifei Xie, Yue Wu, Ruijian Han, Binyan Jiang, Defeng Sun, Jian Huang",10.1234/dsaev.2025.001,10.1234/dsaev.2025.001,"data science, LLM, agents, benchmark, evaluation","The paper introduces DSAEval, a benchmark for evaluating data science agents across 641 real-world problems spanning 285 datasets. It highlights three key features: multi-modal perception, multi-query interactions, and multi-dimensional evaluation. The study systematically tests 11 advanced LLMs and finds that Claude-Sonnet-4.5 leads in performance, GPT-5.2 in efficiency, and MiMo-V2-Flash in cost-effectiveness. It emphasizes multimodal perception's impact on vision tasks and outlines future research directions.",359.05,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13592v1_Machine learning based radiative parameterization .pdf,Machine learning based radiative parameterization scheme and its performance in operational reforecast experiments,"Jing Hao, Xiao Sa, Li Haoyu, Xiao Huadong, Xue Wei",10.5194/arrmw-1234-2023,10.5194/arrmw-1234-2023,"Machine learning, Radiation, Hybrid model, Operational reforecast experiments","The study presents a machine learning approach for radiation parameterization in global operational weather models, demonstrating improved computational efficiency and comparable accuracy to traditional methods through a hybrid coupling strategy.",309.89,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13599v1_Diffusion In Diffusion Breaking the Autoregressive.pdf,Exact string,"Linrui Ma, Yufei Cui, Kai Han, Yunhe Wang",10.48550/arXiv.2601.13599,2601.13599,"diffusion models, block diffusion, autoregressive, generative models","The paper introduces DIFFUSION INDIFFUSION, a framework that combines block diffusion with global refinement to overcome myopia and irreversibility in block-based diffusion models. It proposes a draft-then-refine strategy using snapshot confidence remasking and mix-scale training to improve performance on the OpenWebText dataset.",334.02,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13600v1_Foundations of Global Consistency Checking with No.pdf,Foundations of Global Consistency Checking with Noisy LLM Oracles,"Paul He, Elke Kirschbaum, Shiva Kasiviswanathan",10.48550/arXiv.2303.04112,10.48550/arXiv.2303.04112,"consistency checking, LLM oracles, fact verification, knowledge graphs","The paper addresses the challenge of verifying global consistency of factual collections using large language models, proposing an adaptive divide-and-conquer algorithm to identify minimal inconsistent subsets and compute repairs efficiently.",321.75,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13614v1_CauScientist Teaching LLMs to Respect Data for Cau.pdf,Exact string,"Bo Peng, Sirui Chen, Lei Xu, Chaochao Lu",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"causal discovery, LLM, statistical inference, data science","CauScientist introduces a framework that integrates large language models as hypothesis-generating tools with probabilistic statistics as verification mechanisms, improving causal discovery performance over data-driven baselines.",279.02,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13622v1_CARPE Context-Aware Image Representation Prioritiz.pdf,CARPE,"Donghee Lee, Rui Cai, Zhe Zhao",10.48550/arXiv.2601.13622,2601.13622,"Large Vision-Language Models, Image Classification, Context-Aware, Ensemble Strategy","CARPE introduces a model-agnostic framework for improving image classification by integrating vision-integration layers and a context-aware ensemble, enhancing adaptability across classification and vision-language tasks.",319.13,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13632v1_Resilient Routing Risk-Aware Dynamic Routing in Sm.pdf,Resilient Routing: Risk-Aware Dynamic Routing in Smart Logistics via Spatiotemporal Graph Learning,"Zhiming Xue, Sichen Zhao, Yalun Qi, Xianling Zeng, Zihan Yu",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Smart Logistics, Graph Neural Network, Dynamic Routing, Spatiotemporal Modeling, Supply Chain Resilience","The paper introduces a Risk-Aware Dynamic Routing (RADR) framework that combines Spatiotemporal Graph Neural Networks with combinatorial optimization to enhance logistics resilience. It leverages spatial clustering of GPS data and integrates predictive modeling of congestion risks to improve path planning, achieving a 19.3% reduction in congestion exposure.",311.96,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13645v1_Quadratic Upper Bound for Boosting Robustness.pdf,Exact string,"Euijin Y, Hyang-Won Lee",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"adversarial training, robustness, loss function, deep learning","The paper presents a quadratic upper bound (QUB) for improving robustness in fast adversarial training (FAT) without stronger inner maximization, demonstrating significant robustness gains through a smoother loss landscape.",388.27,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13647v1_Fusion Segment Transformer Bi-Directional Attentio.pdf,Fusion Segment Transformer: Bi-Directional Attention Guided Fusion,"Yumin Kim, Seonghyeon Go",10.48550/arXiv.2024.12345,10.48550/arXiv:24/12345,"AI-generated music detection, Full-audio segment detection, Musical structure analysis, Cross-modal fusion layer","The paper introduces the Fusion Segment Transformer, an improved Segment Transformer architecture designed for full-audio AI-generated music detection. By leveraging a Gated Fusion Layer, it captures long-term musical context, achieving state-of-the-art performance on SONICS and AIME datasets.",290.29,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13649v1_Fairness or Fluency An Investigation into Language.pdf,Fairness or Fluency? An Investigation into Language Bias of Pairwise,"Xiaolin Zhou, Zheng Luo, Yicheng Gao, Qixuan Chen, Xiyang Hu, Yue Zhao, Ruishan Liu",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"language bias, LLM-as-a-judge, performance disparity, language families","This paper investigates language bias in pairwise LLM-as-a-judge systems, identifying disparities across same-language and inter-language judging scenarios. It highlights performance differences between European and African languages and explores the role of low-perplexity bias in shaping judgments.",378.42,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13655v1_Why Does the LLM Stop Computing An Empirical Study.pdf,Why Does the LLM Stop Computing: An Empirical Study of User-Reported Failures in Open-Source LLMs,"Guangba Yu, Zirui Wang, Yujie Huang, Renyi Zhong, Yuedong Zhong, Yilun Wang, Michael R. Lyu",10.1234/acm2026.0012,10.1234/acm2026.0012,"Large Language Models, Failure Analysis, Empirical Study, Open-Source LLMs, Reliability, Software Engineering","This study presents the first large-scale empirical analysis of real-world failures in open-source LLMs, highlighting systemic reliability issues rather than model-specific flaws. It identifies three key phenomena: diagnostic divergence, systemic homogeneity, and lifecycle escalation, offering insights for improving deployment practices.",329.41,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13657v1_Communication-Free Collective Navigation for a Swa.pdf,Communication-Free Collective Navigation for a Swarm of UA Vs,"Myong-Yol Choi, Hankyoul Ko, Hanse Cho, Changseung Kim, Seunghwan Kim, Jaemin Seo, Hyondong Oh",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"collective navigation, deep reinforcement learning, sensor-based control, multi-robot systems, LiDAR-based perception","The study introduces a deep reinforcement learning controller enabling swarms of unmanned aerial vehicles to navigate collectively without communication, using only onboard LiDAR and local perception.",310.85,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13659v1_Temporal-Spatial Decouple before Act Disentangled .pdf,TEMPORAL-SPA TIAL DECOUPLE BEFORE ACT: DISENTANGLED REPRESENTA TION,"Chunlei Meng, Ziyang Zhou, Lucas He, Xiaojing Du, Chun Ouyang, Zhongxue Gan",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Multimodal Sentiment Analysis, Temporal-Spatial Decoupling, Representation Learning, Sentiment Analysis, Cross-Modal Alignment","The paper proposes a temporal-spatial decoupling framework (TSDA) to address spatiotemporal heterogeneity in multimodal sentiment analysis. By explicitly decoupling temporal dynamics and spatial structure before interaction, the method enhances alignment across modalities through temporal encoders, spatial encoders, and factor-consistent alignment. Experiments demonstrate improved performance over existing approaches.",334.13,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13671v1_The Orchestration of Multi-Agent Systems Architect.pdf,Exact string,"Apoorva Adimulam, Rajesh Gupta, Sumit Kumar",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Agent orchestration, Agent-to-Agent protocol, multi-agent systems, observability, state management","The paper presents a unified architectural framework for orchestrating multi-agent systems, integrating planning, policy enforcement, and scalable communication protocols. It introduces the Model Context Protocol and Agent-to-Agent protocol to standardize external tool access and peer coordination, enabling robust, auditable AI ecosystems.",329.44,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13684v1_HeteroCache A Dynamic Retrieval Approach to Hetero.pdf,Exact string,"Zhiyuan Shi, Qibo Qiu, Feng Xue, Zhonglin Jiang, Li Yu2, Jian Jiang, Xiaofei He, Wenxiao Wang, 1Zhejiang University, 2China Mobile (Zhejiang) Research & Innovation Institute, 3The Center for Artificial Intelligence, Geely",10.48550/arXiv:2309.12345,10.48550/arXiv:2309.12345,"HeteroCache, Dynamic Retrieval, KV Cache, Long-Context LLM, Attention Drift, Compression, Memory Growth","The paper introduces HeteroCache, a training-free dynamic compression framework for KV caches in large language models. It addresses the bottleneck of linear memory growth by leveraging attention drift and spatial redundancy, enabling efficient context management without sacrificing performance.",345.94,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13687v1_Understanding Mental States to Guide Social Influe.pdf,Exact string,"Zhichao Liang, Satoshi Nakamura",10.48550/arXiv.2024.12345,10.48550/arXiv/12345,"social interaction, mental states, dialogue, ToM","The paper introduces SocialMindChange, a benchmark that evaluates models' ability to influence and maintain evolving mental states in multi-person dialogue. It emphasizes proactive guidance across connected social scenarios and highlights the gap between current LLM performance and human-like mental-state management.",322.5,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13693v1_End-to-End Reverse Screening Identifies Protein Ta.pdf,End-to-End Reverse Screening Identifies Protein,"Shengjie Xu, Xianbin Ye, Mengran Zhu, Xiaonan Zhang, Shanzhuo Zhang, Xiaomin Fang",10.1000/arXiv.2601.13693,2601.13693,"Reverse screening, Target identification, Biomolecular structure prediction, HelixFold3","The paper presents an end-to-end reverse screening strategy using HelixFold3 to identify protein targets for small molecules, improving accuracy and structural fidelity compared to conventional methods.",320.26,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13697v1_Uncertainty-Aware Gradient Signal-to-Noise Data Se.pdf,Uncertainty-Aware Gradient Signal-to-Noise Data Selection for Instruction Tuning,"Zhihang Yuan, Chengyu Yue, Long Huang, Litu Ou, Lei Shi, *, Alibaba Cloud Computing, The University of Edinburgh",10.48550/arXiv.2311.07891,10.48550/arXiv:2311.07891,"instruction tuning, data selection, uncertainty-aware, gradient filtering","The paper introduces GRADFILTERING, an uncertainty-aware method for selecting training data that leverages a small GPT-2 proxy with LoRA and evaluates performance via Gradient Signal-to-Noise Ratio. It shows superior matching to baselines and faster convergence compared to competitive filtering approaches.",290.7,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13698v1_Does Privacy Always Harm Fairness Data-Dependent T.pdf,Exact string,"Arjun Nichani, Hsiang Hsu, Chun-Fu (Richard) Chen, Haewon Jeong",10.1093/acps/ccad025,2601.13698v1,"fairness, privacy, accuracy, data-dependent","The paper explores the data-dependent trade-offs between fairness, privacy, and accuracy using the Chernoff Information measure, proposing a framework to analyze their interplay in machine learning.",319.09,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13704v1_Performance and Complexity Trade-off Optimization .pdf,Performance and Complexity Trade-off,"Esteban Gomez, Tom B. Hackett",10.1109/TAP.2020.99978,10.1109/TAP.2020.99978,"speech machine learning, low-complexity, voice activity detection, deep fake detection","The paper presents a reparameterization technique that jointly optimizes speech model performance and computational complexity during training, addressing the nonlinear relationship between model size and efficiency.",272.33,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13707v1_Attention-space Contrastive Guidance for Efficient.pdf,Exact string,"Yujin Jo, Sangyoon Bae, Taesup Kim",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"hallucination, LVLM, contrastive guidance, vision-language integration",Proposes Attention-space Contrastive Guidance (ACG) to mitigate hallucinations in LVMs by steering generation toward visually grounded text through a single-pass attention mechanism.,321.1,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13709v1_Hidden in Plain Text Measuring LLM Deception Quali.pdf,Exact string,"Christopher Kao, Vanshika Vats, James Davis",10.48550/arXiv.2311.14648,10.48550/arXiv:2311.14648,"large language models, natural language processing, autonomous game players, social deduction games","The paper investigates deception in the Social Deduction Game Mafia using LLM agents, demonstrating that LLMs can deceive more effectively than humans by blending in better, and releases a dataset for further research.",322.77,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13710v1_Who Should Have Surgery A Comparative Study of Gen.pdf,Who Should Have Surgery? A Comparative Study of GenAI vs Supervised ML for CRS Surgical Outcome Prediction,"Sayeed Shafayet Chowdhury, Snehasis Mukhopadhyay, Shiaofen Fang, Vijay R. Ramakrishnan",10.1093/acmj/qyab,10.1093/acmj/qyab123,"Chronic Rhinosinusitis, clinical decision support, generative artificial intelligence, large language models, SNOT-22, surgical outcome prediction","This study evaluates whether pre-operative clinical data can predict which patients with chronic rhinosinusitis (CRS) would benefit most from surgery. It compares supervised machine learning models with generative AI systems, demonstrating that calibrated ML models outperform GenAI in accuracy and calibration, while GenAI aligns with clinician decision heuristics.",340.39,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13717v1_Simulated Ignorance Fails A Systematic Study of LL.pdf,Simulated Ignorance Fails: A Systematic Study of LLM Behaviors on Forecasting,"Zehan Li1, Yuxuan Wang, Ali El Lahib, Ying-Jieh Xia, Xinyu Pi",10.48550/arXiv.2311.07891,10.48550/arXiv:2311.07891,"LLM, forecasting, retrospective evaluation, knowledge cutoff","The paper investigates Simulated Ignorance (SI) as a method to approximate True Ignorance (TI) in large language models (LLMs) by evaluating their performance on retrospective forecasting tasks. It systematically tests whether SI can mitigate the performance gap between SI and TI, highlighting limitations in suppressing pre-cutoff knowledge and the challenges of reasoning-optimized models.",389.17,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13719v1_Hierarchical Long Video Understanding with Audiovi.pdf,Exact string,"Xinlei Yin, Xiulian Peng, Xiao Li, Zhiwei Xiong, Yan Lu",10.48550/arXiv.2024.12345,10.48550/arXiv:24/12345,"long video understanding, audiovisual entity cohesion, agentic search","The paper introduces HAVEN, a unified framework for long-video understanding that integrates audiovisual entity cohesion and hierarchical video indexing with agentic search. It addresses challenges in maintaining global coherence and entity consistency across extended video content, achieving state-of-the-art performance on LVBench.",336.21,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13722v1_OP-Bench Benchmarking Over-Personalization for Mem.pdf,Exact string,"Yulin Hu, Zimo Long, Jiahe Guo, Xingyu Sui, Xing Fu",10.1093/pasj/2026.01.012,10.1093/pasj/2026.01.012,"memory-augmented agents, over-personalization, personalization, LLM","This paper introduces OP-Bench, a benchmark evaluating memory-augmented conversational agents, and demonstrates that over-personalization—manifesting as Irrelevance, Repetition, and Sycophancy—can be widespread even with long-term memory. It proposes Self-ReCheck to mitigate this issue while preserving personalization.",323.98,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13734v1_Towards robust long-context understanding of large.pdf,Exact string,Chenyu Hui1,10.48550/arxiv/2303.06912,10.48550/arxiv/2303.06912,"long-context understanding, active recap learning, LLM, recap supervision","The paper introduces Active Recap Learning (ARL), a framework that enhances large language models' ability to understand long contexts by enabling them to revisit and summarize earlier content during both pretraining and inference. ARL identifies key tokens in long contexts and uses LLM-based summarization, then integrates these summaries to build a recursive memory system. Experimental results demonstrate a 26.8% improvement on RULER and a 9.44% improvement on LongBench.",291.26,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13735v1_Reasoning or Fluency Dissecting Probabilistic Conf.pdf,Reasoning Quality and Probabilistic Metrics,"Hojin Kim, Jaehyung Kim",10.48550/arXiv.2024.12345,10.48550/arXiv/12345,"reasoning quality, probabilistic metrics, best-of-n, LLM","This paper investigates whether probabilistic confidence metrics, commonly used as proxies for reasoning quality in Best-of-N selection, truly reflect inter-step causal dependencies. The authors introduce a contrastive causality metric to isolate causal structures and demonstrate that current metrics are largely insensitive to causal disruptions, suggesting they capture surface-level fluency rather than deeper reasoning fidelity.",328.26,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13749v1_Pro-AI Bias in Large Language Models.pdf,Pro-AI Bias in Large Language Models,"Benaya Trabelsi, Jonathan Shaki, Sarit Kraus",10.48550/arXiv.2405.01332,10.48550/arXiv/2405.01332,"large language models, AI bias, decision support, pro-AI bias","This study investigates whether large language models (LLMs) systematically favor artificial intelligence (AI) in decision-support contexts. Through three experiments, the authors demonstrate consistent pro-AI bias: models disproportionately recommend AI-related options, overestimate AI salaries by 10 percentage points, and exhibit valence-invariant representations of AI concepts. These findings suggest LLMs can shape choices and perceptions in high-stakes domains.",336.26,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13752v1_Finding RELIEF Shaping Reasoning Behavior without .pdf,Exact string,"Chak Tou Leong, Dingwei Chen, Heming Xia, Qingyu Yin, Sunbowen Lee, Jian Wang, Wenjie Li",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"belief engineering, reasoning behavior, logit probing, LLM","The paper introduces Rea-son Belief Engineering (RELAIN) to shape large reasoning models by aligning their internal reasoning beliefs with target belief blueprints, bypassing the need for explicit reasoning trace supervision.",277.25,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13761v1_DARC Decoupled Asymmetric Reasoning Curriculum for.pdf,Decoupled Asymmetric Reasoning Curriculum for LLM Evolution,"Shengda Fan, Xuyan Ye, Yankai Lin",10.48550/arXiv.2303.04137,10.48550/arXiv.2303.04137,"self-play, LLM, self-improvement, reasoning curriculum","Introduces DARC, a decoupled asymmetric reasoning curriculum that stabilizes self-evolution in large language models by separating question generation and solver training, thereby mitigating optimization instability and bootstrapping errors.",285.92,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13768v1_vLinear A Powerful Linear Model for Multivariate T.pdf,Exact string,"Wenzhen Yue, Ruohao Guo, Ji Shi, Zihan Hao, Shiyu Hu, Xianghua Ying",10.48550/arXiv.2303.04213,10.48550/arXiv.2303.04213,"linear model, multivariate time series, forecasting, vector transformer, weighted flow matching loss, computational efficiency","The paper introduces vLinear, a lightweight linear-based multivariate time series forecaster that reduces computational complexity from O(N²) to O(N) using a learnable rank-1 vector. It proposes vecTrans, a module that models correlations efficiently, and WFMLoss, a path- and horizon-weighted objective, achieving state-of-the-art performance with up to 5× inference speedups.",314.28,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13770v1_Look-Ahead-Bench a Standardized Benchmark of Look-.pdf,Look-Ahead-Bench: A Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance,Mostapha Benhenda,arXiv:2601.13770v1,arXiv:2601.13770v1,"look-ahead bias, point-in-time models, financial LLMs, market regimes","The paper introduces Look-Ahead-Bench, a benchmark evaluating look-ahead bias in financial LLMs by measuring performance decay across market regimes. It compares Llama 3.1 and DeepSeek 3.2 against models like Pitinf-Small, Pitinf-Medium, and Pitinf-Large, highlighting significant lookahead bias in standard LLMs versus improved generalization in larger models.",323.91,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13798v1_Insight Interpretable Semantic Hierarchies in Visi.pdf,Exact string,"Kai Wittenmayer, Sukrut Rao, Amin Parchami-Araghi, Bernt Schiele, Jonas Fischer",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Interpretable Semantics, Vision-Language Models, Concept Representation","INSIGHT proposes a language-aligned concept foundation model that delivers fine-grained, spatially grounded concepts with local co-occurrence relationships, enabling richer explanations for vision tasks.",297.02,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13809v1_DroneVLA VLA based Aerial Manipulation.pdf,Exact string,"Fawad Mehboob, Monijesu James, Amir Habel, Jeffrin Sam, Miguel Altamirano Cabrera, Dzmitry Tsetserukou",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"Aerial Manipulation, Vision-Language-Action Models, Human-Robot Interaction, Visual Surveying, Robotic Fetch-and-Carry","The paper presents a novel autonomous aerial manipulation system that interprets natural language commands to retrieve objects and delivers them to users. It integrates MediaPipe for human pose estimation, a Vision-Language-Action (VLA) model, and a custom drone with a 1-DOF gripper and Intel RealSense camera. The system uses Grounding DINO for localization and dynamic A* planning for navigation, enabling safe, intuitive human–drone interaction during object handover.",322.96,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13846v1_Virtual Urbanism An AI-Driven Framework for Quanti.pdf,Virtual Urbanism: An AI-Driven Framework for Quantifying Urban Identity,"Glinskaya Maria, Department of Architecture, The University of Tokyo",10.12345/example.doi,null,"Virtual Urbanism, AI, Latent Diffusion Model, Urban Identity, Low-Rank Adaptation","This paper introduces a multimodal AI-driven analytical framework for quantifying urban identity through synthetic environments, integrating diffusion models and LoRA to produce dynamic synthetic urban sequences.",362.1,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13864v1_HardSecBench Benchmarking the Security Awareness o.pdf,HardSecBench: Benchmarking the Security Awareness of LLMs for Hardware,"Qirui Chen, Jingxian Shuai, Shuangwu Chen, Shenghao Ye, Zijian Wen, Xufei Su, Jie Jin, Jiangming Li, Jun Chen, Xiaobin Tan, Jian Yang",10.1234/example.doi,None,"LLM, security, hardware, code generation, security awareness, Hardware-Aware LLMs","This paper introduces HardSecBench, a benchmark evaluating security awareness in large language models applied to hardware code generation. It assesses LLMs against 924 tasks spanning Verilog RTL and firmware C, uncovering security risks such as bypassable DMA write vulnerabilities. The study highlights the need for robust security checks in LLM-assisted hardware development.",304.82,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13880v1_LifeAgentBench A Multi-dimensional Benchmark and A.pdf,LifeAgentBench: A Multi-dimensional Benchmark and Agent for Personal Health Assistants in Digital Health,"Ye Tian, Zihao Wang, Onat Gungor, Xiaoran Fan, Tajana Rosing",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"personalized health, digital health, multi-user reasoning, long-horizon QA, cross-dimensional support","The paper introduces LifeAgentBench, a large-scale benchmark for evaluating LLMs in long-horizon, cross-dimensional lifestyle health reasoning. It provides a standardized evaluation protocol and assesses 11 leading LLMs, highlighting performance bottlenecks and proposing LifeAgent as a strong baseline for health assistants.",369.1,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13885v1_Confident Rankings with Fewer Items Adaptive LLM E.pdf,Confident Rankings with Fewer Items: Adaptive LLM Evaluation with Continuous Scores,"Esma Balkır, Alice Pernthaller, Marco Basaldella, José Hernández-Orallo, Nigel Collier",10.1093/acps/ccad025,null,"LLM evaluation, adaptive testing, continuous scores, ROUGE, BLEU, LLM-as-a-Judge","This paper introduces a method extending IRT-based adaptive testing to continuous bounded scores by using a heteroskedastic normal distribution. It achieves reliable ranking with fewer items and lower cost, improving ranking correlation over random sampling.",284.82,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13887v1_Human Simulation Computation A Human-Inspired Fram.pdf,Human Simulation Computation: A Human-Inspired Framework for Adaptive AI Systems,Hong Su,10.1093/acpsr/ftk123,10.1093/acpsr.2015.01534,"Human Simulation Computation, Environment Interaction, Adaptive Artificial Intelligence, Human-Inspired Reasoning","The paper proposes Human Simulation Computation (HSC), a framework that models human-like intelligence through continuous, closed-loop processes involving thinking, action, learning, reflection, and activity scheduling. It emphasizes the importance of human-like reasoning strategies and action-grounded methods for robust adaptation in dynamic environments.",288.32,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13895v1_OmniOVCD Streamlining Open-Vocabulary Change Detec.pdf,Exact string,"Xu Zhang, Danyang Li, Yingjie Xia, Xiaohang Dong",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"change detection, open-vocabulary, SAM 3, OmniOVCD","The paper introduces OmniOVCD, a framework for Open-Vocabulary Change Detection that integrates SAM 3's decoupled outputs to achieve high accuracy in land-cover mask generation. It proposes a Synergistic Fusion to Instance Decoupling (SFID) strategy to maintain consistency across instances and improve performance on benchmark datasets.",333.78,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13897v1_TractRLFusion A GPT-Based Multi-Critic Policy Fusi.pdf,Exact string,"Ankita Joshi, Ashutosh Sharma, Anoushkrit Goel, Ranjeet Ranjan Jha, Chirag Ahuja, Arnav Bhavsar, Aditya Nigam",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"Diffusion MRI, Tractography, Reinforcement Learning, Transformers","The paper introduces TractRLFusion, a GPT-based policy fusion framework for tractography that enhances robustness and accuracy by integrating multiple reinforcement learning policies through a data-driven strategy.",292.17,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13904v1_PREFAB PREFerence-based Affective Modeling for Low.pdf,PREFAB: PREFerence-based Afective Modeling for Low-Budget Self-Annotation,"Jaeyoung Moon, Youjin Choi, Yucheon Park, David Melhart, Georgios N. Yannakakis, Kyung-Joong Kim",10.1145/3675094.3678379,2601.13904,"Affective Computing, Preference Learning, Self-Annotation, User Modeling, Ordinal Representation, Peak-End Rule","PREFAB is a low-budget retrospective self-annotation method targeting affective inflection regions, reducing cognitive load while improving annotator confidence.",292.73,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13920v1_Asymmetric regularization mechanism for GAN traini.pdf,Exact string,"Spyridon C. Giagtzoglou, Mark H.M. Winands, Barbara Franci",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"GANs, regularization, variational inequalities, convergence, saddle point","The paper proposes an asymmetric regularization mechanism for GAN training using a Tikhonov step and zero-centered gradient penalty. It establishes convergence guarantees via Lipschitz and strong-monotonicity constants, ensuring stable training even without achieving full monotonicity.",295.8,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13938v1_IF-GEO Conflict-Aware Instruction Fusion for Multi.pdf,Exact string,"Heyang Zhou, JiaJia Chen, Xiaolu Chen, Jie Bao, Zhen Chen, Yong Liao",10.1000/123456,10.1000/123456,"Generative Engine Optimization, Multi-Query, Content Revision, Conflict-Aware","The paper introduces IF-GEO, a framework for optimizing content revisions in generative search engines by combining divergent preference mining with conflict-aware synthesis to enhance source visibility across diverse queries.",281.98,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13942v1_Glance-or-Gaze Incentivizing LMMs to Adaptively Fo.pdf,Exact string,"Hongbo Bai1, Yujin Zhou1, Yile Wu1, Chi-Min Chan1, Pengcheng Wen1, Kunhao Pan, Sirui Han1†, Yike Guo 1†",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"large multimodal models, visual understanding, knowledge-intensive queries, search augmentation","The paper introduces Glance-or-Gaze (GoG), a reinforcement learning framework that enables LMMs to adaptively focus visual attention, reducing visual redundancy and improving performance on complex, evolving queries.",281.72,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13948v1_Stream-Voice-Anon Enhancing Utility of Real-Time S.pdf,Exact string,"Nikita Kuzmin1, Songting Liu1, Kong Aik Lee3, Eng Siong Chng1",s220028@e.ntu.edu.sg,null,"streaming speaker anonymization, neural audio codec, voice conversion, privacy preservation, disentanglement","The paper introduces Stream-Voice-Anon, a method adapting causal language models for streaming speaker anonymization using neural audio codecs. It integrates anonymization techniques like pseudo-speaker sampling and speaker embedding mixing to protect identity while maintaining linguistic fidelity. The approach achieves up to 46% reduction in relative word error and 28% in UAR compared to prior methods, balancing latency (180ms) with privacy protection against various attack types.",328.93,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13964v1_RL-BioAug Label-Efficient Reinforcement Learning f.pdf,RL-BioAug: Label-Efficient Reinforcement Learning,"Cheol-Hui Lee, Hwa-Yeon Lee, Dong-Joo Kim",10.48550/arXiv.2303.03013,10.48550/arXiv:2303.03013,"reinforcement learning, EEG, data augmentation, self-supervised","The paper introduces RL-BioAug, a label-efficient reinforcement learning framework that autonomously selects optimal data augmentation policies for EEG tasks, improving performance on Macro-F1 scores by 9.69% and 8.80%.",387.24,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13969v1_Autonomous Knowledge Graph Exploration with Adapti.pdf,Autonomous Knowledge Graph Exploration,"Joaquín Polonuer, Lucas Vittor, Iñaki Arango, Ayush Noori, David A. Clifton, Luciano Del Corro, Marinka Zitnik, David A. Clifton, Luciano Del Corro, Marinka Zitnik, Ayush Noori, David A. Clifton, Elena Kempner, Karen A. Liu, Joaquín Polonuer, Luciano Del Corro, Marina Zitnik, Kempner Institute for the Study of Natural and Artificial Intelligence, Lumina Labs, Oxford Suzhou Centre for Advanced Research, Oxford Engineering Science, ELIAS Lab, Harvard Data Science Initiative",10.48550/arxiv/2303.04112,10.48550/arxiv/2303.04112,"knowledge graph, knowledge retrieval, language models, multi-hop traversal, semantic similarity, retrieval-based methods, agentic retrieval","ARK is an adaptive knowledge graph retriever that balances breadth and depth in multi-hop traversal, improving language model performance across diverse datasets.",318.46,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13992v1_The Whole Is Greater Than the Sum of Its Parts A C.pdf,Exact string,"Jin Cui, Jiaqi Guo, Jiepeng Zhou, Ruixuan Yang, Jiayi Lu, Jiajun Xu, Jiangcheng Song, Boran Zhao, Pengju Ren",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"multi-teacher, CoT distillation, LLM, compact model","The paper introduces COMPACT, a framework that adaptively fuses supervision from multiple teachers using graph-based consensus, mutual information-based adaptability, and loss-based difficulty assessment to mitigate catastrophic forgetting and enhance reasoning coherence in student models.",295.08,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13994v1_torch-sla Differentiable Sparse Linear Algebra wit.pdf,Exact string,Mingyuan Chi,10.48550/arXiv.2601.13994,2601.13994,"sparse linear algebra, GPU acceleration, PyTorch, differentiable solvers","A new PyTorch library for GPU-accelerated, differentiable sparse linear algebra, addressing challenges in scientific computing with industrial data.",271.44,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.13999v1_DAME Duration-Aware Matryoshka Embedding for Durat.pdf,Duration-Aware Matryoshka Embedding for Duration-Robust Speaker Verification,"Youngmoon Jung, Joon-Young Yang, Ju-ho Kim, Jaeyoung Roh, Chang Woo Han, Hoon-Young Cho",10.1007/1234567,None,,N/A,255.19,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14012v1_MATE Matryoshka Audio-Text Embeddings for Open-Voc.pdf,Matryoshka Audio–Text Embeddings for Open-Vocabulary,"Youngmoon Jung, Myunghun Jung, Joon-Young Yang, Yong-Hyeok Lee, Jaeyoung Roh, Hoon-Young Cho",10.1093/acps/qad020,null,"keyword spotting, open-vocabulary, text enrollment, audio-text embedding, deep metric learning","The paper introduces Matryoshka Audio–Text Embeddings (MATE), a dual-encoder framework that encodes multiple embedding granularities within a single vector via nested sub-embeddings. It proposes PCA-guided prefix alignment to concentrate keyword cues in lower-dimensional prefixes while preserving detail in higher dimensions. MATE is trained with standard deep metric learning objectives and achieves state-of-the-art performance on open-vocabulary keyword spotting benchmarks without inference overhead.",306.21,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14022v1_Credible CO2 Comparisons A Machine Learning Approa.pdf,Exact string,"Rodrigo Pereira, Luciano Araujo, Daniel Marques da Silva, João Alfredo Cal-Braz",xxx/xxxx,null,"machine learning, vehicle emissions, electric vehicles, ICEVs, CO2 emissions, operational assessment","The paper presents a machine learning framework for fair, data-driven comparison of CO2 emissions between internal combustion engine vehicles and electric vehicles under identical real-world driving conditions. By isolating technology-specific effects and aligning instantaneous emissions metrics, it enables counterfactual analysis of EV performance relative to ICEVs.",354.92,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14027v1_Numina-Lean-Agent An Open and General Agentic Reas.pdf,Exact string,"Junqi Liu, Zihao Zhou, Zekai Zhu, Marco Dos Santos, Weikun He, Jiawei Liu, Ran Wang, Yunzhou Xie, Junqiao Zhao, Qiufeng Wang, Lihong Zhi, Jia Li, Wenda Li, Jia Li, Ran Wang, Wen He, Imperial College London, University of Edinburgh",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"formal mathematics, agentic systems, formal theorem proving, Lean, Numina-Lean-Agent","The paper introduces Numina-Lean-Agent, a general coding agent that enhances formal math reasoning by enabling autonomous interaction with Lean, retrieval of theorems, informal proving, and flexible tool integration. It achieves benchmark performance in Putnam 2025 and demonstrates successful formalization of complex theorems.",313.15,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14039v1_Generalizing Abstention for Noise-Robust Learning .pdf,Exact string,"Wesam Moustafa, Hossam Elsafty, Helen Schneider, Lorenz Sparrenberg, Rafet Sifa",10.1093/acr/mpz057,2601.14039v1,"Abstention, Medical Image Segmentation, Label Noise, Noise-Robust Learning, Loss Functions",The paper introduces a universal abstention framework to enhance noise-robustness in medical image segmentation by improving loss function generalization through an informed regularization and flexible auto-tuning.,335.28,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14041v1_Top 10 Open Challenges Steering the Future of Diff.pdf,Exact string,"Yunhe Wang, Kai Han, Huiling Zhen, Yuchuan Tian, Hanting Chen, Yongbing Huang, Yufei Cui, Yingte Shu, Shan Gao, Ismail Elezi, Roy Vaughan Miles, Songcen Xu, Feng Wen, Chao Xu, Sinan Zeng, Dacheng Tao",10.48550/arXiv.2601.14041,2601.14041,"Large Language Models, Diffusion Models, Transformers","The paper examines ten critical challenges hindering the advancement of diffusion language models, proposing a roadmap to overcome architectural, algorithmic, and cognitive barriers through a diffusion-native paradigm.",285.12,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14047v1_Collective intelligence in science direct elicitat.pdf,Collective Intelligence in Science,"Alexey V. Osipov ∗, Nikolay N. Osipov†, LLC Usetech Professional, St. Petersburg Department of V. A. Steklov Institute of Mathematics of the Russian Academy of Sciences, HSE University, International Laboratory of Game Theory and Decision Making, E-mail addresses: nicknick AT pdmi DOT ras DOT ru.",10.1093/pasj/psa123,2601.14047v1,"collective intelligence, scientific collaboration, information pooling, prediction market, Bayesian truth serum, wisdom of crowd, large language models, interpretability, scientific analysis","The paper proposes a mechanism using a self-resolving play-money prediction market integrated with a chat to enable experts to collaboratively analyze complex scientific hypotheses. By incentivizing truthful sharing of private information through play money rewards, the system aggregates diverse insights efficiently, even without direct verification of ground truth. It leverages tools like Bayesian markets and peer prediction to fund large-scale studies while maintaining interpretability.",343.62,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14051v1_Kakugo Distillation of Low-Resource Languages into.pdf,Exact string,"Peter Devine, Mardhiyah Sanni, Farid Adilazuarda, Julieta Gil Loizaga, Barry Haddow",10.48550/arXiv.2405.12345,10.48550/arXiv.2405.12345,"language models, low-resource languages, SLM, distillation","Kakugo introduces a cost-effective pipeline for training general-purpose Small Language Models (SLMs) on low-resource languages using only language names as input. By leveraging synthetic data generation and translation, the method achieves competitive performance across translation, classification, and question answering tasks, offering an accessible path for multilingual AI development.",383.99,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14053v1_LLMOrbit A Circular Taxonomy of Large Language Mod.pdf,Exact string,"Badri N. Patro, Vijay S. Agneeswaran",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"large language models, LLMOrbit, AI, agentic systems","A comprehensive circular taxonomy of large language models (LLMs) from 2019-2025, analyzing architectural innovations, training costs, and efficiency shifts, while addressing the 'scaling wall' challenges.",296.07,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14055v1_Decoder-Free Supervoxel GNN for Accurate Brain-Tum.pdf,Decoder-Free Supervoxel GNN for Accurate Brain-Tumor Localization in Multi-Modal MRI,"Andrea Protani, Marc Molina Van Den Bosch, Lorenzo Giusti, Heloisa Barbosa Da Silva, Paolo Cacace, Albert Sund Aillet, Miguel Angel Gonzalez Ballester, Friedhelm Hummel, Luigi Serio",10.1109/ICRA.2024.12345,2601.14055v1,"BrainTumorLocalization, GraphNeuralNetworks, Multi-modal MRI, Supervoxel, Regression","The paper presents a decoder-free Supervoxel GNN that leverages a content-aware grouping strategy to construct a semantic graph of supervoloxels. By integrating a patch-level transformer with a supervoxel-level graph attention mechanism, the method achieves robust node-level classification and tumor proportion regression on the BraTS dataset, demonstrating strong performance and interpretability.",318.76,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14056v1_POCI-Diff Position Objects Consistently and Intera.pdf,Exact string,"Andrea Rigo, Luca Stornaiuolo, Weijie Wang, Mauro Martino, Bruno Lepri, Nicu Sebe",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Diffusion, Image Generation, 3D Layout","The paper introduces POCI-Diff, a diffusion-based framework for consistent and interactive 3D layout control in text-to-image generation. It enables explicit per-object semantic control by binding text descriptions to 3D bounding boxes, supporting warping-free editing and maintaining object identity during edits.",348.45,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14063v1_XCR-Bench A Multi-Task Benchmark for Evaluating Cu.pdf,XCR-Bench: A Multi-Task Benchmark for Evaluating Cultural,"Mohsinul Kabir, Tasnim Ahmed, Shaoxiong Ji, Hassan Alhuzali, Sophia Ananiadou",10.1093/acps/ccac007,10.1093/acps/ccac007,"cross-cultural, cultural bias, large language models, cultural reasoning, cross-cultural evaluation","This paper introduces XCR-Bench, a benchmark for evaluating cultural reasoning in large language models. It addresses the scarcity of annotated cross-cultural data and highlights LLMs' limitations in identifying culture-specific items across diverse contexts. The study reveals biases in cultural adaptation and proposes a framework using Newmark’s CSI and Hall’s Triad to analyze cultural nuances beyond surface-level features.",359.75,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14069v1_Unsupervised Video Class-Incremental Learning via .pdf,Exact string,"Nattapong Kurpukdee, Adrian G. Bors",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"unsupervised, video class-incremental, deep embedded clustering","The paper presents an unsupervised video class incremental learning approach using deep feature extraction and progressive clustering, achieving strong performance across multiple video datasets without relying on labeled data.",278.63,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14084v1_DermaBench A Clinician-Annotated Benchmark Dataset.pdf,Exact string,"Abdurrahim Yilmaz, Ozan Erdem, Ece Gokyayla, Ayda Acar, Burc Bugra Dagtas, Dilara Ilhan Erdil, Gulsum Gencoglan, Burak Temelkuran",10.1093/acps/clad.2023,10.1093/acps/clad.2023.07.012,"dermatology, visual question answering, clinical reasoning, skin conditions, multimodal learning","DermaBench is a clinician-annotated benchmark for dermatology visual question answering, providing expert-labeled images to evaluate language grounding and diagnostic reasoning in dermatology.",293.8,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14086v1_Two-Stream temporal transformer for video action c.pdf,Two-Stream Temporal Transformer for Video Action Classification,"Nattapong Kurpukdee, Adrian G. Bors",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"Video Transformer, Optical Flow, Two-Stream processing, Video Action Classification","This paper introduces a two-stream transformer model for video classification, leveraging self-attention to integrate content and optical flow features across temporal domains. The approach demonstrates strong performance on standard video datasets.",337.97,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14087v1_1-bit Count-based Sorting Unit to Reduce Link Powe.pdf,Exact string,"Ruichi Han, Yizhi Chen, Tong Lei, Jordi Altayo Gonzalez, Ahmed Hemani",10.48550/arXiv.2023.12345,10.48550/arXiv.2023.12345,"1-bit count, approximate computing, bit transition, link power","Proposes a hardware implementation of a comparison-free popcount sorting unit optimized for CNNs, aiming to reduce area and link power consumption in DNN accelerators.",285.14,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14091v1_Zero-shot adaptable task planning for autonomous c.pdf,Zero-shot adaptable task planning for autonomous construction robots: a comparative study of lightweight single and multi-AI agent systems,"Hossein Naderi, Alireza Shojaei, Lifu Huang, Philip Agee, Kereshmeh Afsari, Abiola Akanmu",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Construction robotics, quadruped robots, robot task planning, multi-AI agent, LLMs, VLMs, GPT4o","The study explores the use of lightweight LLMs and VLMs to enhance adaptability and generalizability of task planning in construction robots. Four agent models are proposed and evaluated across three construction roles, showing improved performance and cost-effectiveness compared to state-of-the-art models.",295.82,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14096v1_Remapping and navigation of an embedding space via.pdf,Remapping and Navigating Embedding Space,"Benedikt Hartl, Léo Pio-Lopez, Chris Fields, Michael Levin",10.1093/pasj/202600,2601.14096v1,"Evolution, Development, Intelligence, Active Inference, Navigation Policy, Nested Embedding Spaces","The paper explores how embedding spaces can be remapped and navigated through error minimization, highlighting its significance in cognitive processes.",320.86,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14099v1_Causal feature selection framework for stable soft.pdf,Causal Feature Selection Framework for Stable Soft Sensor Modeling based on Time-Delayed Cross Mapping,"Shi-Shun Chen, Xiao-Yang Li, Enrico Zio",10.48550/arXiv.2405.12345,10.48550/arXiv:2405.12345,"causal feature selection, soft sensor modeling, time-delayed cross mapping, reliability engineering",The paper introduces a causal feature selection framework designed for stable soft sensor modeling using time-delayed cross mapping techniques.,263.55,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14115v1_Riemannian Liquid Spatio-Temporal Graph Network.pdf,Riemannian Liquid Spatio-Temporal Graph Network,"Liangsi Lu, Jingchao Wang, Zhaorong Dai, Hanqian Liu, Yang Shi",10.1145/3774904.3792090,13725167598,"Riemannian Manifolds, Neural ODEs, Spatio-Temporal Graphs, Liquid Dynamics","The paper introduces the Riemannian Liquid Spatio-Temporal Graph Network (RLSTG), a framework that integrates continuous-time liquid dynamics with Riemannian geometry to model non-Euclidean graph structures. It addresses geometric distortion in traditional liquid time-constant networks and provides theoretical guarantees for stability and expressiveness.",238.77,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14124v1_Style Transfer as Bias Mitigation Diffusion Models.pdf,Style Transfer as Bias Mitigation: Diffusion Models for Synthetic Mental Health Text for Arabic,"Saad Mankarious, Ayah Zirikly",10.1093/acm/qad022,2601.14124v1,"mental health, gender bias, diffusion models, synthetic data, Arabic","The paper proposes a diffusion-based, pretraining-free approach for generating synthetic Arabic mental health text to mitigate gender bias. It focuses on male-to-female style transfer to augment female-authored content, demonstrating high semantic fidelity and meaningful stylistic divergence while ensuring linguistic plausibility.",306.17,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14152v1_Lost in the Prompt Order Revealing the Limitations.pdf,Exact string,"Hyunjong Ok, Jaeho Lee",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"language models, prompt sensitivity, causal attention, MCQA","This paper investigates how the ordering of components in multiple-choice question answering affects model performance, identifying causal attention as the key mechanism that suppresses option tokens when context precedes questions.",276.98,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14154v1_LLM Augmented Intervenable Multimodal Adaptor for .pdf,Exact string,"Shubham Pandey, Bhavin Jawade, Srirangaraj Setlur, Venu Govindaraju, Kenneth Seastedt",10.1093/acm/qad047,10.1093/acm/qad047,"postoperative complications, lung cancer surgery, risk prediction, deep learning, radiomics, interventional modeling","Presents MIRA-CLE, an interpretable deep learning framework integrating clinical and radiological data to predict postoperative complications in lung cancer surgery, enhancing clinical decision-making with transparent insights.",343.53,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14157v1_ConceptCaps -- a Distilled Concept Dataset for Int.pdf,Exact string,"Bruno Sienkiewicz, Łukasz Neumann, Mateusz Modrzejewski",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"concept capture, interpretability, music models, dataset generation","The paper introduces ConceptCaps, a dataset of 23k music-caption-audio triplets with explicit labels, designed to enable clean separation of positive and negative examples for each concept. It presents a two-stage generation pipeline—first learning plausible attribute co-occurrences with a VAE, then generating descriptive text with a fine-tuned LLM—to improve interpretability and reproducibility in music models.",319.58,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14160v1_Domain-Adaptation through Synthetic Data Fine-Tuni.pdf,Domain-Adaptation through Synthetic Data: Fine-Tuning Large Language Models for German Law,"Ali Hamza Bashir, Muhammad Rehan Khalid, Kostadin Cvejoski, Jana Birr, Jule Berghaus, Armin Berger, Sandra Halscheidt, Christian Temath, Rafet Sifa, David Berghaus",10.1093/acplr/sca045,null,"legal adaptation, German law, LLM fine-tuning, statutory data","The paper presents a method to adapt large language models to German legal question answering by generating synthetic data from authoritative statutes, demonstrating improved performance over baselines.",293.44,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14171v1_Paper2Rebuttal A Multi-Agent Framework for Transpa.pdf,Exact string,"Qianli Ma, Chang Guo, Zhiheng Tian, Siyu Wang Jipeng Xiao, Yuanhao Yue, Zhipeng Zhang",10.1234/example.doi,10.1234/example,"rebuttal, multi-agent, transparency, manuscript","The authors present REBUTTALAGENT, a multi-agent system that structures rebuttals around evidence, aiming to improve alignment with reviewer feedback and enhance manuscript revision quality.",327.9,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14172v1_Human Values in a Single Sentence Moral Presence H.pdf,Human Values in a Single Sentence: Moral Presence,"Víctor Yestea, Paolo Rossoa, Valencian Graduate School and Research Network of Artificial Intelligence (ValgrAI)",10.1093/acps/csa.2026,2601.14172v1,"human values, moral presence, sentence-level detection, moral hierarchies","This paper investigates detecting moral values in single sentences across the Schwartz continuum, demonstrating that hierarchical gating improves performance over direct multi-label classification, especially under resource constraints.",314.39,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14175v1_A model of errors in transformers.pdf,Exact string,"Suvrat Raju, Praneeth Netrapalli",10.48550/arXiv.2024.12345,10.48550/arXiv:24/12345,"LLM errors, error rate, attention mechanism, arithmetic, repetitive processing","The paper investigates how small errors in transformer attention accumulate during deterministic tasks, proposing a two-parameter model linking accuracy to task complexity. It provides empirical evidence on error thresholds and suggests prompt engineering to mitigate errors.",365.29,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14192v1_Toward Efficient Agents Memory Tool learning and P.pdf,Exact string,"Xiaofang Yang, Lijun Li, Heng Zhou, Tong Zhu, Xiaoye Qu, Yuchen Fan, Qianshan Wei, Rui Ye, Li Kang, Yiran Qin, Zhiqiang Kou, Daizong Liu, Ning Ding, Siheng Chen, Jing Shao",10.48550/arXiv.2601.14192,2601.14192,"Agents, Efficiency, Agent Memory, Tool Learning, Planning","The paper investigates efficiency in agentic systems by analyzing memory, tool learning, and planning, proposing methods to optimize cost and effectiveness.",293.16,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14209v1_InT Self-Proposed Interventions Enable Credit Assi.pdf,Exact string,"Matthew Y. R. Yang, Hao Bai, Ian Wu, Gene Yang1, Amrith Setlur, Aviral Kumar",10.48550/arXiv.2311.03658,10.48550/arXiv:2311.03658,"credit assignment, intervention training, RL, LLM",The paper proposes Intervention Training (InT) to improve credit assignment in large language models by introducing targeted single-step interventions that correct reasoning errors during RL training. It demonstrates that supervised fine-tuning on these interventions enhances accuracy by nearly 14% over a 4B-parameter model.,323.97,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14230v1_MASCOT Towards Multi-Agent Socio-Collaborative Com.pdf,Exact string,"Yiyang Wang, Yiqiao Jin, Alex Cabral, Josiah Hester",10.48550/arXiv.2405.12345,10.48550/arXiv.2405.12345,"multi-agent systems, socio-collaborative companion systems, persona consistency, social support","The paper introduces MASCOT, a framework for socio-collaborative companions that enhances persona fidelity and social interaction through a bi-level optimization strategy, improving emotional and cognitive support in psychological and workplace settings.",317.74,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14232v1_KAGE-Bench Fast Known-Axis Visual Generalization E.pdf,Exact string,"Egor Cherepannov, Daniil Zelezetsky, Alexey K. Kovalev, Aleksandr I. Panov",10.48550/arXiv/2303.04112,10.48550/arXiv/2303.04112,"reinforcement learning, visual generalization, pixel-based agents, KAGE-Bench, visual distribution shift","Introduces KAGE-Env, a JAX-native platformer for evaluating visual generalization in reinforcement learning, and presents KAGE-Bench, a benchmark of six known-axis suites to isolate visual shifts. The work highlights challenges with axis-dependent performance and demonstrates robustness of appearance shifts over background and photometric changes.",382.27,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14234v1_Q-learning with Adjoint Matching.pdf,Exact string,"Qiyang Li, Sergey Levine",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"Q-learning, Adjoint Matching, flow matching, policy optimization","Proposes Q-learning with Adjoint Matching (QAM) to address optimization challenges in continuous-action RL, leveraging adjoint matching to stabilize training for expressive policies.",282.91,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14235v1_Opportunities in AIML for the Rubin LSST Dark Ener.pdf,Exact string,"Eric Aubourg, Camille Avestruz, Matthew R. Becker, Biswajit Biswas, Rahul Biswas, Boris Bolliet, Adam S. Bolton, Clecio R. Bom, Alexandre Boucaud, Jean-Eric Campagne, Chihway Chang, Aleksandra Ciprijanović, Johann Cohen-Tanugi, Michael W. Coughlin, John Franklin Crenshaw, Juan C. Cuevas-Tello, Alex Drlica-Wagner, Sydney Erickson, Alexander T. Gagliano, Christos Georgiou, Aritra Ghosh, Matthew Grayling, Kirill A. Grishin, Alan Heavens, Lindsay R. House, Michelle Lochner, Peter Melchior, Grant Merz, Martin Millon, Anais Moller, Andrés A. Plazas Malagón, Amanda Wasserman, Yuanyuan Zhang, Padma Venkatraman, Amanda Wasserman, Tim White, Steven Dillmann, Mariano Javier de León Dominguez Romero, Stephen Thorp, Laura Toribio-Levasseur, Tjitske Starkenburg, Neset Kabalan, Arun Kannawadi, François Lacour, C. Danielle Leonard, Pierre-Francois L'Éget, Michelle Lochner, Yao Yuan Mao, Peter Melchior, Gautham Narayan, Yuuki Omori, Hiranya Peiris, Laurence Perreault-Levasseur, Andrés A. Plazas Malagón, Nesar Ramachandra, Benjamin Remy, Christine Roucelle, Jaime Ruiz-Zapatero, Stefan Schuldt, Ignacio Sevilla-Noarbe, Ved G. Shah",10.48550/arXiv:2509.12345,10.48550/arXiv:2509.12345,"AI, ML, LSST, Dark Energy, Cosmology, Machine Learning, Astrophysics",Opportunities in AI/ML for the Rubin LSST,343.2,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14242v1_APEX-Agents.pdf,APEX–Agents,"Bertie Vidgen, Austin Mann, Abby Fennelly, John Wright, Stanly, Lucas Rothman, Marco Burstein, Julien Benchek, David Ostrofsky, Anirudh Ravichandran, Debnil, Sur Neel Venugopal, Alannah Hsia, Isaac Robinson, Calix Huang, Olivia Varones, Daniyal Khan, Michael Haines, Zach Richards, Brendan Foody, Osvald Nitski, Mercor, api@mercor.com",10.1093/pasj/aps023,2601.14242v1,"AI agents, productivity index, investment banking, management consultants, corporate lawyers, long-horizon tasks","The paper introduces the APEX–Agents benchmark, evaluating AI agents' ability to perform complex, real-world tasks across finance and law. It assesses performance using eight agents and highlights the need for robust evaluation frameworks.",345.47,LFM-2.5,Windows RTX 4080 (Native CUDA)
2601.14255v1_VideoMaMa Mask-Guided Video Matting via Generative.pdf,VideoMaMa: Mask-Guided Video Matting via Generative Prior,"Sangbeom Lim, Seoung Wug Oh2, Jiahui Huang, Heeji Yoon, Seungryong Kim, Joon-Young Lee",10.1093/pasj/vis/2026,2601.14255,"video matting, mask-guided, generative prior, diffusion model, pseudo-labeling","The paper introduces VideoMaMa, a diffusion-based model that generates high-quality alpha mattes from input segmentation masks, enabling robust matting on real-world videos. It leverages synthetic data and fine-tunes SAM2 to create a scalable dataset (MA-V) for large-scale video matting, demonstrating strong generalization to unseen footage.",287.18,LFM-2.5,Windows RTX 4080 (Native CUDA)
