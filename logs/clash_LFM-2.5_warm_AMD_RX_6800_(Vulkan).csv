filename,title,authors,doi,arxiv_id,keywords,summary,tps,inference_time,tokens,mode,model,platform
2601.07192v1_Relink Constructing Query-Driven Evidence Graph On.pdf,Exact string,"Manzong Huang, Chenyang Bu, Yi He, Xingrui Zhuo, Xindong Wu",10.48550/arXiv.2024.12345,10.48550/arXiv:24/12345,"GraphRAG, hallucination, LLM, knowledge graph, query construction","Relink proposes a dynamic evidence graph framework that constructs query-specific knowledge graphs on-the-fly, addressing incomplete knowledge and distractor facts in GraphRAG.",39.9,3.86,154,warm,LFM-2.5,AMD RX 6800 (Vulkan)
2601.07197v1_Beyond Variance Knowledge-Aware LLM Compression vi.pdf,Exact string,"Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma",10.48550/arXiv.2024.12345,10.48550/arXiv:2409.12345,"knowledge-aware compression, Fisher-Aligned, activation gradients, LLM, subspace diagnostics","The paper introduces Fisher-Aligned Subspace Compression (FASC), a knowledge-aware method for post-training activation compression that leverages gradient coupling via the Fisher Inference Matrix. FASC improves factual knowledge preservation on large models by identifying low-variance but high-gradient-sensitive subspaces, using the Dependence Violation Score (ρ) as a diagnostic metric. Experiments show FASC outperforms variance-based approaches in accuracy on factual benchmarks while enabling efficient deployment.",40.01,5.449,218,warm,LFM-2.5,AMD RX 6800 (Vulkan)
2601.07199v1_Forward versus Backward Comparing Reasoning Object.pdf,Exact string,"Murtaza Nikazad, Raghuram Ramanujan",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"direct preference optimization, hallucination, forward reasoning, backward verification","This paper compares forward and backward reasoning objectives in Direct Preference Optimization to assess their impact on model accuracy and error recognition. It finds that forward-only training improves accuracy but not error detection, while backward-only training enhances verification but reduces false positives. Both approaches offer complementary benefits.",41.98,3.954,166,warm,LFM-2.5,AMD RX 6800 (Vulkan)
2601.07200v1_Safeguarding LLM Fine-tuning via Push-Pull Distrib.pdf,Exact string,"Haozhong Wang, Zhuo Li, Yibo Yang, H Zhao, Hongyuan Zha, Guo Dandan",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"LLM fine-tuning, safety alignment, distributional alignment, Optimal Transport","The paper introduces Safety Optimal Transport (SOT) to enhance LLM safety during fine-tuning by shifting from instance-level filtering to distribution-level alignment. SOT uses a dual-reference push-pull weight-learning mechanism that repositions the downstream data distribution toward a safe anchor while pushing it away from harmful references, thereby establishing a robust geometric safety boundary. Experiments show SOT improves safety without sacrificing performance.",42.3,5.06,214,warm,LFM-2.5,AMD RX 6800 (Vulkan)
2601.07201v1_CalPro Prior-Aware Evidential--Conformal Predictio.pdf,Exact string,"Ibne Farabi Shihab, Shihab, Akdel, Sharma",10.48550/arXiv.2024.12345,10.48550/arXiv.2024.12345,"protein structure, uncertainty quantification, conformal prediction, Bayesian methods","CalPro introduces a prior-aware evidential–conformal framework for shift-robust uncertainty quantification in protein structure prediction, achieving near-nominal coverage with improved calibration and reduced calibration error.",40.69,3.834,156,warm,LFM-2.5,AMD RX 6800 (Vulkan)
