filename,title,authors,doi,arxiv_id,keywords,summary,tps,total_time,tokens,mode,model,platform
2601.07192v1_Relink Constructing Query-Driven Evidence Graph On.pdf,Constructing Query-Driven Evidence Graph On-the-Fly for GraphRAG,"Manzong Huang, Chenyang Bu, Yi He, Xingrui Zhuo, Xindong Wu",,,"GraphRAG, Knowledge Graph, Large Language Models, Retrieval-Augmented Generation, Open-Domain Question Answering, Evidence Graph, Latent Relations","Graph-based Retrieval-Augmented Generation (GraphRAG) mitigates hallucinations in Large Language Models (LLMs) by grounding them in structured knowledge. However, current GraphRAG methods are constrained by a build-then-reason paradigm, relying on a static, pre-constructed Knowledge Graph (KG). This paradigm faces challenges such as the KG’s incompleteness and low signal-to-noise ratio, which introduce distractor facts. To address these, the paper proposes Relink, a framework that dynamically builds a query-specific evidence graph. Relink instantiates required facts from a latent relation pool derived from the original text corpus, repairing broken paths on the fly. It employs a unified, query-aware evaluation strategy to select the most useful candidates for answering the query, actively discarding distractor facts. Extensive experiments show that Relink achieves significant improvements over leading GraphRAG baselines, demonstrating the superiority of the reason-and-construct paradigm.",2.67,122.103,326,cold_start,Phi-4,Apple_M1(Metal)
2601.07197v1_Beyond Variance Knowledge-Aware LLM Compression vi.pdf,Beyond Variance: Knowledge-Aware LLM Compression via Fisher-Aligned Subspace Diagnostics,"Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma",,,"Large Language Models, activation compression, Singular Value Decomposition, Fisher Information Matrix, knowledge-intensive benchmarks, post-training compression","Post-training activation compression is essential for deploying Large Language Models (LLMs) on resource-constrained hardware. Standard methods like Singular Value Decomposition (SVD) are gradient-blind and preserve high-variance dimensions regardless of their impact on factual knowledge preservation. This paper introduces Fisher-Aligned Subspace Compression (FASC), a knowledge-aware compression framework that selects subspaces by directly modeling activation-gradient coupling, minimizing a second-order surrogate of the loss function. FASC leverages the Fisher Information Matrix to identify dimensions critical for factual knowledge, which often reside in low-variance but high-gradient-sensitivity subspaces. The Dependence Violation Score (ρ) is proposed as a diagnostic metric to quantify activation-gradient coupling, revealing where factual knowledge is stored within transformer architectures. Experiments on Mistral-7B and Llama-3-8B demonstrate that FASC preserves 6-8% more accuracy on knowledge-intensive benchmarks compared to variance-based methods at 50% rank reduction, effectively enabling a 7B model to match the factual recall of a 13B uncompressed model. The analysis reveals that ρ serves as a fundamental signal of stored knowledge, with high-ρ layers emerging only when models internalize factual associations during training.",2.99,122.283,366,cold_start,Phi-4,Apple_M1(Metal)
2601.07199v1_Forward versus Backward Comparing Reasoning Object.pdf,Forward versus Backward: Comparing Reasoning Objectives in Direct Preference Optimization,"Murtaza Nikazad, Raghuram Ramanujan",,,"Direct Preference Optimization, reasoning capabilities, hallucination, GSM8K, Low-Rank Adaptation","This paper explores the impact of training objectives on the reasoning reliability of large language models using Direct Preference Optimization. It compares forward chain-of-thought generation, which trains models to produce correct reasoning traces, with backward verification, which trains models to verify and acknowledge errors in candidate solutions. Experiments on GSM8K show a trade-off between these objectives: forward-only training improves accuracy, while backward-only training reduces false positives but with minimal accuracy gains. Both methods decrease the model's error acknowledgment rate, indicating increased confidence in outputs. The study suggests that forward and backward reasoning objectives provide distinct learning signals, with forward training enhancing problem-solving and backward training improving verification calibration. The research is implemented using Low-Rank Adaptation to facilitate further studies.",3.05,83.051,253,cold_start,Phi-4,Apple_M1(Metal)
2601.07200v1_Safeguarding LLM Fine-tuning via Push-Pull Distrib.pdf,Safeguarding LLM Fine-tuning via Push-Pull Distributional Alignment,"Haozhong Wang, Zhuo Li, Yibo Yang, He Zhao, Hongyuan Zha, Dandan Guo",,,"LLM Fine-tuning, Safety Alignment, Optimal Transport, Data Distribution, Model Safety","The inherent safety alignment of Large Language Models (LLMs) is prone to erosion during fine-tuning, even with seemingly innocuous datasets. Existing defenses, which rely on heuristic, instance-level assessments, fail to consider the global geometry of data distribution and do not explicitly repel harmful patterns. This paper introduces Safety Optimal Transport (SOT), a novel framework that reframes safe fine-tuning as a distribution-level alignment task grounded in Optimal Transport (OT). SOT employs a dual-reference 'push-pull' weight-learning mechanism to optimize sample importance by pulling the downstream distribution towards a trusted safe anchor and pushing it away from a general harmful reference. This establishes a robust geometric safety boundary that effectively purifies the training data. Extensive experiments demonstrate that SOT significantly enhances model safety while maintaining competitive downstream performance, achieving a superior safety-utility trade-off compared to baselines.",2.88,104.361,301,cold_start,Phi-4,Apple_M1(Metal)
2601.07201v1_CalPro Prior-Aware Evidential--Conformal Predictio.pdf,CalPro: Prior-Aware Evidential–Conformal Prediction with Structure-Aware Guarantees for Protein Structures,"Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma",,,"protein structure prediction, uncertainty quantification, conformal prediction, evidential learning, distribution shift, calibration","Deep protein structure predictors like AlphaFold provide confidence estimates that are not calibrated and degrade under distribution shifts. CalPro introduces a prior-aware evidential–conformal framework for robust uncertainty quantification. It combines a geometric evidential head, a differentiable conformal layer, and domain priors to maintain near-nominal coverage and achieve tighter intervals. Empirically, CalPro shows ≤5% coverage degradation across modalities, reduces calibration error by 30–50%, and improves ligand-docking success by 25%. It is applicable to structured regression tasks beyond proteins.",2.6,84.329,219,cold_start,Phi-4,Apple_M1(Metal)
2601.07206v1_LLMRouterBench A Massive Benchmark and Unified Fra.pdf,LLMRouterBench: A Massive Benchmark and Unified Framework for LLM Routing,"Hao Li, Yiqun Zhang, Zhaoyan Guo, Chenxu Wang, Shengji Tang, Qiaosheng Zhang, Yang Chen, Biqing Qi, Peng Ye, Lei Bai, Zhen Wang, Shuyue Hu",,,"Large Language Models, LLM Routing, Benchmark, Performance-Cost Trade-off, Model Ensemble, Routing Methods","LLMRouterBench is introduced as a large-scale benchmark and unified framework for LLM routing, comprising over 400K instances from 21 datasets and 33 models. It provides comprehensive metrics for performance-oriented and performance-cost trade-off routing, integrating 10 representative routing baselines. The benchmark reveals strong model complementarity in LLM routing, but finds that many methods perform similarly under unified evaluation, with some recent approaches failing to outperform simple baselines. It highlights the limited impact of backbone embedding models, diminishing returns from larger ensembles, and the importance of model curation. The benchmark also supports latency-aware analysis. All code and data are available at https://github.com/ynulihao/LLMRouterBench.",2.87,111.07,319,cold_start,Phi-4,Apple_M1(Metal)
2601.07209v1_SIRR-LMM Single-image Reflection Removal via Large.pdf,SIRR-LMM: Single-image Reflection Removal via Large Multimodal Model,"Yu Guo, Zhiqiang Lao, Xiyun Song, Yubin Zhou, Heather Yu",,,"Single-image Reflection Removal, Large Multimodal Model, Synthetic Dataset, Path-tracing, LoRA","Glass surfaces create complex interactions of reflected and transmitted light, making single-image reflection removal (SIRR) challenging. Existing datasets suffer from limited physical realism in synthetic data or insufficient scale in real captures. This paper introduces a synthetic dataset generation framework that path-traces 3D glass models over real background imagery to create physically accurate reflection scenarios with varied glass properties, camera settings, and post-processing effects. To leverage the capabilities of Large Multimodal Model (LMM), the image layers are concatenated into a single composite input, joint captioning is applied, and the model is fine-tuned using task-specific LoRA rather than full-parameter training. This approach achieves improved reflection removal and separation performance compared to state-of-the-art methods. The paper addresses the gap in high-quality training data by using a path-traced synthetic dataset with physically accurate 3D glass models combined with real background imagery, enabling strong performance with relatively small datasets.",3.04,93.204,283,cold_start,Phi-4,Apple_M1(Metal)
2601.07214v1_BlindU Blind Machine Unlearning without Revealing .pdf,BlindU: Blind Machine Unlearning without Revealing Erasing Data,"Weiqi Wang, Zhiyi Tian, Chenhan Zhang, Shui Yu",,,"Machine Unlearning, Federated Learning, Privacy Leakage, Privacy Preserving, Information Bottleneck","Machine unlearning enables data holders to remove the contribution of their specified samples from trained models to protect their privacy. However, most unlearning methods require the unlearning requesters to upload their data to the server, which is infeasible in privacy-preserving scenarios like federated learning. This paper proposes Blind Unlearning (BlindU), which uses compressed representations instead of original inputs for unlearning. BlindU involves the server and the unlearning user, where the user generates privacy-preserving representations locally, and the server performs unlearning on these representations and their labels. The paper employs the information bottleneck mechanism for FL model training and introduces a noise-free differential privacy masking method to enhance privacy protection. Theoretical analysis and experimental results demonstrate BlindU's superiority in privacy protection and unlearning effectiveness compared to existing benchmarks.",2.9,93.917,272,cold_start,Phi-4,Apple_M1(Metal)
2601.07224v1_Consolidation or Adaptation PRISM Disentangling SF.pdf,Consolidation or Adaptation? PRISM: Disentangling SFT and RL Data via Gradient Concentration,"Yang Zhao, Yangou Ouyang, Xiao Ding, Hepeng Wang, Bibo Cai, Kai Xiong, Jinglong Gao, Zhouhao Sun, Li Du, Bing Qin, Ting Liu",,,"Hybrid Supervised Fine-Tuning, Reinforcement Learning, LLM agents, data arbitration, gradient concentration, Schema Theory, cognitive conflict, optimization interference, structural adaptation, behavioral consolidation","The paper discusses the standard paradigm of using Hybrid Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) for training Large Language Model (LLM) agents. It highlights the lack of effective data allocation mechanisms between these stages and proposes PRISM, a framework that arbitrates data based on cognitive conflict with the model's existing knowledge. PRISM identifies high-conflict data requiring RL for structural adaptation and low-conflict data for SFT consolidation. Experiments show PRISM's superiority in performance and computational efficiency.",2.94,102.75,302,cold_start,Phi-4,Apple_M1(Metal)
2601.07226v1_Lost in the Noise How Reasoning Models Fail with C.pdf,Lost in the Noise: How Reasoning Models Fail with Contextual Distractors,"Seongyun Lee, Yongrae Jo, Minju Seo, Moontae Lee, Minjoon Seo",,,"reasoning models, contextual distractors, NoisyBench, robustness, RAG, tool-use tasks, Rationale-Aware Reward (RARE)","Recent advances in reasoning models and agentic AI systems have led to an increased reliance on diverse external information. However, this shift introduces input contexts that are inherently noisy, a reality that current sanitized benchmarks fail to capture. The paper introduces NoisyBench, a comprehensive benchmark that evaluates model robustness across 11 datasets in RAG, reasoning, alignment, and tool-use tasks against diverse noise types, including random documents, irrelevant chat histories, and hard negative distractors. The evaluation reveals a catastrophic performance drop of up to 80% in state-of-the-art models when faced with contextual distractors. The study finds that agentic workflows often amplify these errors by over-trusting noisy tool outputs, and distractors can trigger emergent misalignment even without adversarial intent. The paper proposes Rationale-Aware Reward (RARE) to strengthen resilience by incentivizing the identification of helpful information within noise. It also uncovers an inverse scaling trend where increased test-time computation leads to worse performance in noisy settings and demonstrates via attention visualization that models disproportionately focus on distractor tokens.",3.11,113.681,354,cold_start,Phi-4,Apple_M1(Metal)
2601.07229v2_DiSCo Making Absence Visible in Intelligent Summar.pdf,DiSCo: Making Absence Visible in Intelligent Summarization Interfaces,"ERAN FAINMAN, HAGIT BEN SHOSHAN, ADIR SOLOMON, OSNAT MOKRYN",,,"Review Summarization, Absence, Expectations, Learning via surprisability, Missing commonalities","Intelligent interfaces increasingly use large language models to summarize user-generated content, yet these summaries emphasize what is mentioned while overlooking what is missing. This presence bias can mislead users who rely on summaries to make decisions. The paper presents Domain Informed Summarization through Contrast (DiSCo), an expectation-based computational approach that makes absences visible by comparing each entity’s content with domain topical expectations captured in reference distributions of aspects typically discussed in comparable accommodations. This comparison identifies aspects that are either unusually emphasized or missing relative to domain norms and integrates them into the generated text. In a user study across three accommodation domains, namely ski, beach, and city center, DiSCo summaries were rated as more detailed and useful for decision making than baseline large language model summaries, although slightly harder to read. The findings show that modeling expectations reduces presence bias and improves both transparency and decision support in intelligent summarization interfaces.",3.08,97.734,301,cold_start,Phi-4,Apple_M1(Metal)
2601.07232v1_Yes FLoReNce I Will Do Better Next Time Agentic Fe.pdf,"Y es FLoReNce, I Will Do Better Next Time! Agentic Feedback Reasoning for Humorous Meme Detection","Olivia Shanhong Liu, Pai Chet Ng, De Wen Soh, Konstantinos N. Plataniotis",,,"humorous memes, AI systems, multimodal models, feedback reasoning, meme understanding, closed-loop learning, open-loop inference, knowledge base, prompt modulation","Humorous memes blend visual and textual cues to convey irony, satire, or social commentary, posing unique challenges for AI systems that must interpret intent rather than surface correlations. Existing multimodal or prompting-based models generate explanations for humor but operate in an open loop, lacking the ability to critique or refine their reasoning once a prediction is made. We propose FLoReNce, an agentic feedback reasoning framework that treats meme understanding as a closed-loop process during learning and an open-loop process during inference. In the closed loop, a reasoning agent is critiqued by a judge; the error and semantic feedback are converted into control signals and stored in a feedback-informed, non-parametric knowledge base. At inference, the model retrieves similar judged experiences from this KB and uses them to modulate its prompt, enabling better, self-aligned reasoning without finetuning. On the PrideMM dataset, FLoReNce improves both predictive performance and explanation quality over static multimodal baselines, showing that feedback-regulated prompting is a viable path to adaptive meme humor understanding.",3.0,121.177,364,cold_start,Phi-4,Apple_M1(Metal)
2601.07233v1_From Thinking to Justifying Aligning High-Stakes E.pdf,From “Thinking” to “Justifying”: Aligning High-Stakes Explainability with Professional Communication Standards,"Chen Qian, Yimeng Wang, Yu Chen, Lingfei Wu, Andreas Stathopoulos",,,"Explainable AI, Chain-of-Thought, Structured Explainability Framework, CREAC, BLUF, high-stakes domains","Explainable AI (XAI) in high-stakes domains should help stakeholders trust and verify system outputs. Chain-of-Thought methods reason before concluding, but logical gaps or hallucinations can lead to unreliable conclusions. The paper proposes a 'Result → Justify' approach, using the Structured Explainability Framework (SEF) to align explanations with professional communication standards like CREAC and BLUF. Experiments show that SEF improves verifiability and reliability, achieving 83.9% accuracy across tasks in various domains.",2.64,90.176,238,cold_start,Phi-4,Apple_M1(Metal)
2601.07238v1_Group Pattern Selection Optimization Let LRMs Pick.pdf,Group Pattern Selection Optimization: Let LRMs Pick the Right Pattern for Reasoning,"Hanbin Wang, Jingwei Song, Jinpeng Li, Fei Mi, Lifeng Shang",,,"Large reasoning models, reasoning patterns, reinforcement learning, pattern selection, mathematics, science benchmarks","Large reasoning models (LRMs) exhibit diverse high-level reasoning patterns, yet prevailing training recipes often bias models toward a limited set of dominant patterns. This paper introduces Group Pattern Selection Optimization (GPSO), a reinforcement learning framework that extends GRPO by incorporating multi-pattern rollouts, verifier-guided optimal pattern selection per problem, and attention masking during optimization. GPSO enables models to internalize the mapping from problem characteristics to optimal reasoning patterns, delivering consistent performance gains across various model backbones and benchmarks. The approach mitigates pattern sub-optimality and fosters more robust, adaptable reasoning.",2.76,86.562,239,cold_start,Phi-4,Apple_M1(Metal)
2601.07239v1_Stochastic CHAOS Why Deterministic Inference Kills.pdf,"Stochastic CHAOS: Why Deterministic Inference Kills, and Distributional Variability Is the Heartbeat of Artificial Cognition","Tanmay Joshi, Shourya Aggarwal, Anusa Saha, Aadi Pandey, Shreyash Dhoot, Vighnesh Rai, Raxit Goswami, Aman Chadha, Vinija Jain, Amitava Das",,,"large language models, deterministic inference, stochasticity, distributional variability, artificial cognition, LLM inference, reproducibility, uncertainty modeling, emergent abilities, reasoning paths, safety alignment","The paper argues against deterministic inference in large language models (LLMs), claiming it undermines the ability to model uncertainty, disrupts emergent abilities, and weakens reasoning capabilities. The authors advocate for stochastic approaches, emphasizing that distributional variability is crucial for artificial cognition. They differentiate between algorithmic stochasticity and numerical/systems nondeterminism, proposing stability goals for LLM inference. Empirical evidence is presented to show that deterministic inference can be misleading, particularly in instruction-following, emergent abilities, and reasoning tasks. The paper promotes stochastic CHAOS as essential for capturing the true properties of LLMs.",3.03,109.43,332,cold_start,Phi-4,Apple_M1(Metal)
2601.07245v1_Learning to Trust the Crowd A Multi-Model Consensu.pdf,Learning to Trust the Crowd: A Multi-Model Consensus Reasoning Engine for Large Language Models,Pranav Kallem,,,"Large Language Models, Multi-Model Consensus, Reliability, Semantic Embeddings, Graph Neural Networks, Gradient-Boosted Trees, Listwise Ranking, Hallucinations, Confidence Calibration","Large language models (LLMs) achieve strong average performance but are unreliable at the instance level, often producing hallucinations and poorly calibrated confidence. This study introduces a Multi-Model Consensus Reasoning Engine that uses outputs from several heterogeneous LLMs to determine the most likely correct answer for a given query. The system employs semantic embeddings, pairwise similarity, clustering statistics, lexical and structural cues, reasoning-quality scores, confidence estimates, and model-specific priors. It applies gradient-boosted trees, listwise ranking, and graph neural networks over similarity graphs of answers. The approach improves macro-average accuracy and reduces errors compared to single LLMs and majority vote, suggesting a practical route toward more reliable LLM behavior.",2.91,91.511,266,cold_start,Phi-4,Apple_M1(Metal)
2601.07250v1_DDT A Dual-Masking Dual-Expert Transformer for Ene.pdf,DDT: A Dual-Masking Dual-Expert Transformer for Energy Time-Series Forecasting,"Mingnan Zhu, Qixuan Zhang, Yixuan Cheng, Fangzhou Gu, Shiming Lin",,,"Time-Series Forecasting, Multivariate Temporal Modeling, Dynamic-Causal Masking, Adaptive Feature Fusion","Accurate energy time-series forecasting is crucial for ensuring grid stability and promoting the integration of renewable energy, yet it faces significant challenges from complex temporal dependencies and the heterogeneity of multi-source data. To address these issues, we propose DDT, a novel and robust deep learning framework for high-precision time-series forecasting. At its core, DDT introduces two key innovations. First, we design a dual-masking mechanism that synergistically combines a strict causal mask with a data-driven dynamic mask. This novel design ensures theoretical causal consistency while adaptively focusing on the most salient historical information, overcoming the rigidity of traditional masking techniques. Second, our architecture features a dual-expert system that decouples the modeling of temporal dynamics and cross-variable correlations into parallel, specialized pathways, which are then intelligently integrated through a dynamic gated fusion module. We conducted extensive experiments on 7 challenging energy benchmark datasets, including ETTh, Electricity, and Solar. The results demonstrate that DDT consistently outperforms strong state-of-the-art baselines across all prediction horizons, establishing a new benchmark for the task.",3.07,110.482,339,cold_start,Phi-4,Apple_M1(Metal)
2601.07261v1_Pseudodata-guided Invariant Representation Learnin.pdf,Pseudodata-guided Invariant Representation Learning Boosts the Out-of-Distribution Generalization in Enzymatic Kinetic Parameter Prediction,"Haomin Wu, Zhiwei Nie, Hongyu Zhang, Zhixiang Ren",,2601.07261v1,"enzyme kinetic parameters, deep learning, enzyme-substrate interaction, out-of-distribution generalization, invariant representation learning","Accurate prediction of enzyme kinetic parameters is essential for understanding catalytic mechanisms and guiding enzyme engineering. Existing deep learning-based enzyme-substrate interaction (ESI) predictors often exhibit performance degradation on sequence-divergent, out-of-distribution (OOD) cases, limiting robustness under biologically relevant perturbations. This work proposes O2DENet, a lightweight, plug-and-play module that enhances OOD generalization via biologically and chemically informed perturbation augmentation and invariant representation learning. O2DENet introduces enzyme-substrate perturbations and enforces consistency between original and augmented enzyme-substrate-pair representations to encourage invariance to distributional shifts. When integrated with representative ESI models, O2DENet consistently improves predictive performance for both kcat and Km across stringent sequence-identity-based OOD benchmarks, achieving state-of-the-art results among the evaluated methods in terms of accuracy and robustness metrics. Overall, O2DENet provides a general and effective strategy to enhance the stability and deployability of data-driven enzyme kinetics predictors for real-world enzyme engineering applications.",3.39,102.956,349,cold_start,Phi-4,Apple_M1(Metal)
2601.07263v1_When Bots Take the Bait Exposing and Mitigating th.pdf,When Bots Take the Bait: Exposing and Mitigating the Emerging Social Engineering Attack in Web Automation Agent,"Xinyi Wu, Geng Hong, Yueyue Chen, MingXuan Liu, Feier Jin, Xudong Pan, Jiarun Dai, Baojun Liu",,,"Web agents, social engineering attacks, web automation, large language models, security, runtime mitigation","Web agents, powered by large language models (LLMs), are increasingly deployed to automate complex web interactions. The rise of open-source frameworks has accelerated adoption but also broadened the attack surface. This study presents the first systematic examination of social engineering attacks against web automation agents and introduces a pluggable runtime mitigation solution. The AGENTBAIT paradigm exploits intrinsic weaknesses in agent execution, distorting reasoning and steering agents toward malicious objectives. The SUPERVISOR module enforces environment and intention consistency alignment to mitigate unsafe operations. Empirical results show mainstream frameworks are highly vulnerable to AGENTBAIT, with an average attack success rate of 67.5%. The proposed module reduces attack success rates by up to 78.1% with minimal runtime overhead, advancing the security of web agents.",2.92,104.641,306,cold_start,Phi-4,Apple_M1(Metal)
2601.07291v1_A Visual Semantic Adaptive Watermark grounded by P.pdf,A Visual Semantic Adaptive Watermark grounded by Prefix-Tuning for Large Vision-Language Model,"Qi Zheng, Shuliang Liu, Yu Huang, Sihang Jia, Jungang Li, Lyuhao Chen, Junhao Chen, Hanqian Li, Aiwei Liu, Yibo Yan, Xuming Hu",,,"watermarking, vision-language models, prefix-tuning, visual fidelity, semantic-aware methods, inference efficiency","Watermarking has emerged as a pivotal solution for content traceability and intellectual property protection in Large Vision-Language Models (LVLMs). However, vision-agnostic watermarks introduce visually irrelevant tokens and disrupt visual grounding by enforcing indiscriminate pseudo-random biases, while some semantic-aware methods incur prohibitive inference latency due to rejection sampling. In this paper, we propose the VIsualSemantic Adaptive Watermark (VISA-Mark), a novel framework that embeds detectable signals while strictly preserving visual fidelity. Our approach employs a lightweight, efficiently trained prefix-tuner to extract dynamic Visual Evidence Weights, which quantify the evidentiary support for candidate tokens based on the visual input. These weights guide an adaptive vocabulary partitioning and logits perturbation mechanism, concentrating watermark strength specifically on visually-supported tokens. By actively aligning the watermark with visual evidence, VISA-Mark effectively maintains visual fidelity. Empirical results confirm that VISA-Mark outperforms conventional methods with a 7.8% improvement in visual consistency (Chair-I) and superior semantic fidelity. The framework maintains highly competitive detection accuracy (96.88% AUC) and robust attack resilience (99.3%) without sacrificing inference efficiency, effectively establishing a new standard for reliability-preserving multimodal watermarking.",3.08,134.675,415,cold_start,Phi-4,Apple_M1(Metal)
2601.07292v1_Photometric Redshift Estimation Using Scaled Ensem.pdf,Photometric Redshift Estimation Using Scaled Ensemble Learning,"Swagata Biswas, Shubhrangshu Ghosh, Avyarthana Ghosh, Yogesh Wadadekar, Abhishek Roy Choudhury, Arijit Mukherjee, Shailesh Deshpande, Arpan Pal",,,"Galaxies, High-redshift galaxies, Redshift surveys, Neural networks","The study introduces a new ensemble-based machine learning framework for predicting photometric redshifts (Pz) for faint galaxies and higher redshift ranges using optical photometric data. The framework integrates multiple learning algorithms within a scaled ensemble structure, demonstrating improved predictive performance and accuracy up to z ∼ 4. The model is validated using data from the Hyper Suprime-Cam Strategic Survey Program and shows marked improvements in precision and reliability, meeting or exceeding LSST Science Requirements Document benchmarks.",2.7,90.219,244,cold_start,Phi-4,Apple_M1(Metal)
2601.07296v1_LRAS Advanced Legal Reasoning with Agentic Search.pdf,LRAS: Advanced Legal Reasoning with Agentic Search,"Yujin Zhou, Chuxue Cao, Jinluan Yang, Lijun Wu, Conghui He, Sirui Han, Yike Guo",,,"Legal Reasoning, Large Reasoning Models, Agentic Search, Introspective Imitation Learning, Reinforcement Learning, Legal Logic, Procedural Rigor","While Large Reasoning Models (LRMs) have demonstrated exceptional logical capabilities in mathematical domains, their application to the legal field remains hindered by the strict requirements for procedural rigor and adherence to legal logic. Existing legal LLMs, which rely on 'closed-loop reasoning' derived solely from internal parametric knowledge, frequently suffer from a lack of self-awareness regarding their knowledge boundaries, leading to confident yet incorrect conclusions. To address this challenge, we present Legal Reasoning with Agentic Search (LRAS), the first framework designed to transition legal LLMs from static and parametric 'closed-loop thinking' to dynamic and interactive 'Active Inquiry'. By integrating Introspective Imitation Learning and Difficulty-aware Reinforcement Learning, LRAS enables LRMs to identify knowledge boundaries and handle legal reasoning complexity. Empirical results demonstrate that LRAS outperforms state-of-the-art baselines by 8.2-32%, with the most substantial gains observed in tasks requiring deep reasoning with reliable knowledge. We will release our data and models for further exploration soon.",2.98,120.629,360,cold_start,Phi-4,Apple_M1(Metal)
2601.07304v1_Heterogeneous Multi-Expert Reinforcement Learning .pdf,Heterogeneous Multi-Expert Reinforcement Learning for Long-Horizon Multi-Goal Tasks in Autonomous Forklifts,"Yun Chen, Bowei Huang, Fan Guo, Kang Song",,,"Autonomous Forklift, Hierarchical Reinforcement Learning, Mobile Manipulation, Hybrid Training, Modality Decoupling","Autonomous mobile manipulation in unstructured warehouses requires balancing efficient large-scale navigation and high-precision object interaction. Traditional end-to-end learning approaches often struggle with these conflicting demands. This paper proposes a Heterogeneous Multi-Expert Reinforcement Learning (HMER) framework for autonomous forklifts, decomposing long-horizon tasks into specialized sub-policies controlled by a Semantic Task Planner. This structure separates macro-level navigation from micro-level manipulation, allowing each expert to focus on its specific action space without interference. The planner coordinates the sequential execution of these experts, bridging the gap between task planning and continuous control. To address sparse exploration, a Hybrid Imitation-Reinforcement Training Strategy is introduced, using expert demonstrations to initialize the policy and Reinforcement Learning for fine-tuning. Experiments in Gazebo simulations show that HMER significantly outperforms sequential and end-to-end baselines, achieving a task success rate of 94.2%, reducing operation time by 21.4%, and maintaining placement error within 1.5 cm.",2.97,104.295,310,cold_start,Phi-4,Apple_M1(Metal)
2601.07309v1_ARM Role-Conditioned Neuron Transplantation for Tr.pdf,ARM: Role-Conditioned Neuron Transplantation for Training-Free Generalist LLM Agent Merging,"Zhuoka Feng, Kang Chen, Sihan Zhao, Kai Xiong, Yaoning Wang, Minshen Yu, Junjie Nian, Changyi Xiao, Yixin Cao, Yugang Jiang",,2601.07309v1,"large language models, model merging, neuron transplantation, generalization, interactive environments","Interactive large language model agents have advanced rapidly, but most remain specialized to a single environment and fail to adapt robustly to other environments. Model merging offers a training-free alternative by integrating multiple experts into a single model. This paper proposes Agent-Role Merging (ARM), an activation-guided, role-conditioned neuron transplantation method for model merging in LLM agents. ARM improves existing merging methods from static natural language tasks to multi-turn agent scenarios, and over the generalization ability across various interactive environments. This is achieved with a well-designed 3-step framework: 1) constructing merged backbones, 2) selection based on its role-conditioned activation analysis, and 3) neuron transplantation for fine-grained refinements. Without gradient-based optimization, ARM improves cross-benchmark generalization while enjoying efficiency. Across diverse domains, the model obtained via ARM merging outperforms prior model merging methods and domain-specific expert models, while demonstrating strong out-of-domain generalization.",3.23,110.498,357,cold_start,Phi-4,Apple_M1(Metal)
2601.07313v1_Explaining Machine Learning Predictive Models thro.pdf,Explaining Machine Learning Predictive Models through Conditional Expectation Methods,"Silvia Ruiz-España, Laura Arnal, François Signol, Juan-Carlos Pérez-Cortes, Joaquim Arlandis",,,"machine learning, XAI, explainable models, local explainability, model-agnostic, uncertainty, stability","The rapid adoption of complex AI and ML models has led to their characterization as black boxes due to the difficulty of explaining their internal decision-making processes. This lack of transparency hinders users’ ability to understand, validate, and trust model behavior, particularly in high-risk applications. This work introduces Multivariate Conditional Expectation (MUCE), a model-agnostic method for local explainability designed to capture prediction changes from feature interactions. MUCE extends Individual Conditional Expectation (ICE) by exploring a multivariate grid of values in the neighborhood of a given observation at inference time, providing graphical explanations that illustrate the local evolution of model predictions. In addition, two quantitative indices, stability and uncertainty, summarize local behavior and assess model reliability. Uncertainty is further decomposed into uncertainty + and uncertainty − to capture asymmetric effects that global measures may overlook. The proposed method is validated using XGBoost models trained on three datasets: two synthetic (2D and 3D) to evaluate behavior near decision boundaries, and one transformed real-world dataset to test adaptability to heterogeneous feature types. Results show that MUCE effectively captures complex local model behavior, while the stability and uncertainty indices provide meaningful insight into prediction confidence. MUCE, together with the ICE modification and the proposed indices, offers a practical contribution to local explainability, enabling both graphical and quantitative insights that enhance the interpretability of predictive models and support more trustworthy and transparent decision-making.",3.23,128.711,416,cold_start,Phi-4,Apple_M1(Metal)
2601.07315v1_VLM-CAD VLM-Optimized Collaborative Agent Design W.pdf,VLM-CAD: VLM-Optimized Collaborative Agent Design Workflow for Analog Circuit Sizing,"Guanyuan Pan, Yugui Lin, Tiansheng Zhou, Pietro Li, Shuai Wang, Yaqi Wang*",,,"Analog Circuit Sizing, Agentic AI, Vision Language Model, Explainability, Electronic Design Automation","Analog mixed-signal circuit sizing involves complex trade-offs within high-dimensional design spaces. Existing automatic approaches often underutilize circuit schematics and lack the explainability required for industry adoption. This paper proposes a Vision Language Model-optimized collaborative agent design workflow (VLM-CAD), which analyzes circuits, optimizes DC operating points, performs inference-based sizing, and executes external sizing optimization. The workflow integrates Image2Net to annotate circuit schematics and generate a structured JSON description for precise interpretation by Vision Language Models. An Explainable Trust Region Bayesian Optimization method (ExTuRBO) is proposed, employing collaborative warm-starting from agent-generated seeds and offering dual-granularity sensitivity analysis for external sizing optimization, supporting a comprehensive final design report. Experiments on amplifier sizing tasks using 180nm, 90nm, and 45nm Predictive Technology Models demonstrate that VLM-CAD effectively balances power and performance, achieving a 100% success rate in optimizing an amplifier with a complementary input and a class-AB output stage, while maintaining total runtime under 43 minutes across all experiments.",3.05,115.321,352,cold_start,Phi-4,Apple_M1(Metal)
2601.07316v1_BEAT-Net Injecting Biomimetic Spatio-Temporal Prio.pdf,BEAT-Net: Injecting Biomimetic Spatio-Temporal Priors for Interpretable ECG Classification,"Ma Runze, Liao Caizhi",,2601.07316v1,"ECG classification, deep learning, biomimetic, spatio-temporal priors, interpretable AI, QRS tokenization, self-supervised learning","Although deep learning has advanced automated electrocardiogram (ECG) diagnosis, prevalent supervised methods typically treat recordings as undifferentiated one-dimensional (1D) signals or two-dimensional (2D) images. This formulation compels models to learn physiological structures implicitly, resulting in data inefficiency and opacity that diverge from medical reasoning. To address these limitations, we propose BEAT-Net, a Biomimetic ECG Analysis with Tokenization framework that reformulates the problem as a language modeling task. Utilizing a QRS tokenization strategy to transform continuous signals into biologically aligned heartbeat sequences, the architecture explicitly decomposes cardiac physiology through specialized encoders that extract local beat morphology while normalizing spatial lead perspectives and modeling temporal rhythm dependencies. Evaluations across three large-scale benchmarks demonstrate that BEAT-Net matches the diagnostic accuracy of dominant convolutional neural network (CNN) architectures while substantially improving robustness. The framework exhibits exceptional data efficiency, recovering fully supervised performance using only 30 to 35 percent of annotated data. Moreover, learned attention mechanisms provide inherent interpretability by spontaneously reproducing clinical heuristics, such as Lead II prioritization for rhythm analysis, without explicit supervision. These findings indicate that integrating biological priors offers a computationally efficient and interpretable alternative to data-intensive large-scale pre-training.",3.16,124.054,392,cold_start,Phi-4,Apple_M1(Metal)
2601.07320v1_Segmental Advantage Estimation Enhancing PPO for L.pdf,Segmental Advantage Estimation: Enhancing PPO for Long-Context LLM,"Xue Gong, Qi Yi, Ziyuan Nan, Guanhua Huang, Kejiao Li, Yuhao Jiang, Ruibin Xiong, Zenan Xu, Jiaming Guo, Shaohui Peng, Bo Zhou",,,"Large Language Models, Reinforcement Learning, Verifiable Rewards, Proximal Policy Optimization, Advantage Estimation, Sparse Rewards, Generalized Advantage Estimation, Segmental Advantage Estimation","Training Large Language Models (LLMs) for reasoning tasks is increasingly driven by Reinforcement Learning with Verifiable Rewards (RLVR), where Proximal Policy Optimization (PPO) provides a principled framework for stable policy updates. However, the practical application of PPO is hindered by unreliable advantage estimation in the sparse-reward RLVR regime. This issue arises because the sparse rewards in RLVR lead to inaccurate intermediate value predictions, which in turn introduce significant bias when aggregated at every token by Generalized Advantage Estimation (GAE). To address this, we introduce Segmental Advantage Estimation (SAE), which mitigates the bias that GAE can incur in RLVR. Our key insight is that aggregating n-step advantages at every token (as in GAE) is unnecessary and often introduces excessive bias, since individual tokens carry minimal information. Instead, SAE first partitions the generated sequence into coherent sub-segments using low-probability tokens as heuristic boundaries. It then selectively computes variance-reduced advantage estimates only from these information-rich segment transitions, effectively filtering out noise from intermediate tokens. Our experiments demonstrate that SAE achieves superior performance, with marked improvements in final scores, training stability, and sample efficiency. These gains are shown to be consistent across multiple model sizes, and a correlation analysis confirms that our proposed advantage estimator achieves a higher correlation with an approximate ground-truth advantage, justifying its superior performance.",3.24,144.65,468,cold_start,Phi-4,Apple_M1(Metal)
2601.07342v1_Agentic Diagnostic Reasoning over Telecom and Data.pdf,Agentic Diagnostic Reasoning over Telecom and Datacenter Infrastructure: Foundation for Autonomous Incident Resolution and Change Impact Mitigation,Nicolas Tacheny,,2601.07342v1,"telecom, datacenter, root cause analysis, impact analysis, large language model, autonomous incident resolution, change impact mitigation","Large-scale telecom and datacenter infrastructures rely on multi-layered service and resource models, where failures propagate across physical and logical components and affect multiple customers. Traditional approaches to root cause analysis (RCA) rely on hard-coded graph traversal algorithms or rule-based correlation engines, which are costly to maintain and tightly coupled to the infrastructure model. This work introduces an agentic diagnostic framework where a Large Language Model (LLM) performs step-wise investigation using a constrained tool-space exposed through the Model Context Protocol (MCP). Instead of embedding causal logic or traversal algorithms into the application, the agent autonomously navigates the infrastructure model by invoking tools for service lookup, dependency retrieval, structured and unstructured data, and event analysis, and impact discovery. This work lays the foundation for autonomous incident resolution and change impact mitigation. Future systems will not only diagnose and remediate infrastructure failures but also predict the impact of planned changes on services and customers, enabling operators to mitigate risks before executing maintenance operations.",3.22,97.212,313,cold_start,Phi-4,Apple_M1(Metal)
2601.07344v1_PulseMind A Multi-Modal Medical Model for Real-Wor.pdf,PulseMind: A Multi-Modal Medical Model for Real-World Clinical Diagnosis,"Jiao Xu, Junwei Liu, Jiangwei Lao, Qi Zhu, Yunpeng Zhao, Congyun Jin, Shinan Liu, Zhihong Lu, Lihe Zhang, Xin Chen, Jian Wang, Ping Wang",,,"multi-modal models, clinical diagnosis, medical images, diagnostic dataset, evaluation benchmark, training framework, Comparison-based Reinforcement Policy Optimization (CRPO)","Recent advances in medical multi-modal models focus on specialized image analysis like dermatology, pathology, or radiology. However, they do not fully capture the complexity of real-world clinical diagnostics, which involve heterogeneous inputs and require ongoing contextual understanding during patient-physician interactions. To bridge this gap, we introduce PulseMind, a new family of multi-modal diagnostic models that integrates a systematically curated dataset, a comprehensive evaluation benchmark, and a tailored training framework. Specifically, we first construct a diagnostic dataset, MediScope, which comprises 98,000 real-world multi-turn consultations and 601,500 medical images, spanning over 10 major clinical departments and more than 200 sub-specialties. Then, to better reflect the requirements of real-world clinical diagnosis, we develop the PulseMind Benchmark, a multi-turn diagnostic consultation benchmark with a four-dimensional evaluation protocol comprising proactiveness, accuracy, usefulness, and language quality. Finally, we design a training framework tailored for multi-modal clinical diagnostics, centered around a core component named Comparison-based Reinforcement Policy Optimization (CRPO). Compared to absolute score rewards, CRPO uses relative preference signals from multi-dimensional comparisons to provide stable and human-aligned training guidance. Extensive experiments demonstrate that PulseMind achieves competitive performance on both the diagnostic consultation benchmark and public medical benchmarks.",3.09,139.589,431,cold_start,Phi-4,Apple_M1(Metal)
2601.07348v4_Controlled Self-Evolution for Algorithmic Code Opt.pdf,Controlled Self-Evolution for Algorithmic Code Optimization,"Tu Hu, Ronghao Chen, Shuo Zhang, Jianghao Yin, Mou Xiao Feng, Jingping Liu, Shaolei Zhang, Wenqi Jiang, Yuqi Fang, Sen Hu, Huacan Wang, Yi Xu",,arXiv:2601.07348v4,"self-evolution, code optimization, algorithmic strategies, genetic evolution, evolutionary computation, machine learning","Self-evolution methods enhance code generation through iterative 'generate-verify-refine' cycles, yet existing approaches suffer from low exploration efficiency, failing to discover solutions with superior complexity within limited budgets. This inefficiency stems from initialization bias trapping evolution in poor solution regions, uncontrolled stochastic operations lacking feedback guidance, and insufficient experience utilization across tasks. To address these bottlenecks, we propose Controlled Self-Evolution (CSE), which consists of three key components: Diversified Planning Initialization, Genetic Evolution, and Hierarchical Evolution Memory. Experiments on EffiBench-X demonstrate that CSE consistently outperforms all baselines across various LLM backbones, achieving higher efficiency from early generations and maintaining continuous improvement throughout evolution.",3.27,97.711,320,cold_start,Phi-4,Apple_M1(Metal)
2601.07351v2_Beyond Hard Masks Progressive Token Evolution for .pdf,Beyond Hard Masks: Progressive Token Evolution for Diffusion Language Models,"Linhao Zhong, Linyu Wu, Bozhen Fang, Tianjian Feng, Chenchen Jing, Wen Wang, Jiaheng Zhang, Hao Chen, Chunhua Shen",,,"Diffusion Language Models, EvoToken-DLM, masked diffusion, probabilistic representations, iterative refinement, parallel decoding","Diffusion Language Models (DLMs) offer a promising alternative for language modeling by enabling parallel decoding through iterative refinement. However, most DLMs rely on hard binary masking and discrete token assignments, which hinder the revision of early decisions and underutilize intermediate probabilistic representations. This paper proposes EvoToken-DLM, a novel diffusion-based language modeling approach that replaces hard binary masks with evolving soft token distributions. EvoToken-DLM enables a progressive transition from masked states to discrete outputs, supporting revisable decoding. Continuous trajectory supervision is introduced to align training objectives with iterative probabilistic updates. Extensive experiments show that EvoToken-DLM consistently achieves superior performance, outperforming strong diffusion-based and masked DLM baselines.",2.66,110.844,295,cold_start,Phi-4,Apple_M1(Metal)
2601.07356v1_Efficient Convolutional Forward Model for Passive .pdf,Efficient Convolutional Forward Model for Passive Acoustic Mapping and Temporal Monitoring,"Tatiana Gelvez-Barrera, Barbara Nicolas, Bruno Gilles, Adrian Basarab, Denis Kouam ´e",,,"Passive Acoustic Mapping, Model-based beamforming, Convolutional forward model, Temporal monitoring","Passive acoustic mapping (PAM) is a key imaging technique for characterizing cavitation activity in therapeutic ultrasound applications. Recent model-based beamforming algorithms offer high reconstruction quality and strong physical interpretability. However, their computational burden and limited temporal resolution restrict their use in applications with time-evolving cavitation. To address these challenges, we introduce a PAM beamforming framework based on a novel convolutional formulation in the time domain, which enables efficient computation. In this framework, PAM is formulated as an inverse problem in which the forward operator maps spatiotemporal cavitation activity to recorded radio-frequency signals accounting for time-of-flight delays defined by the acquisition geometry. We then formulate a regularized inversion algorithm that incorporates prior knowledge on cavitation activity. Experimental results demonstrate that our framework outperforms classical beamforming methods, providing higher temporal resolution than frequency-domain techniques while substantially reducing computational burden compared with iterative time-domain formulations.",2.81,109.471,308,cold_start,Phi-4,Apple_M1(Metal)
2601.07359v1_Seeing Right but Saying Wrong Inter- and Intra-Lay.pdf,Seeing Right but Saying Wrong: Inter- and Intra-Layer Refinement in MLLMs without Training,"Shezheng Song, Shasha Li, Jie Yu",,,"Multimodal Large Language Models, MLLMs, vision-language tasks, attention, DualPD, layer-wise attention-guided contrastive logits, head-wise information filtering, accuracy, generalizability","Multimodal Large Language Models (MLLMs) show strong capabilities in vision-language tasks but often exhibit a critical inconsistency: deeper layers may focus on correct visual regions, yet final predictions are misled by noisy attention from earlier layers. This results in a disconnect between the model's internal understanding and its output, described as 'seeing it right but saying it wrong.' To address this, the authors propose DualPD, a dual-perspective decoding refinement strategy that enhances visual understanding without additional training. DualPD includes a layer-wise attention-guided contrastive logits module and a head-wise information filtering module. Experiments on LLaVA and Qwen-VL models across multiple benchmarks show that DualPD consistently improves accuracy without training, confirming its effectiveness and generalizability.",2.91,92.746,270,cold_start,Phi-4,Apple_M1(Metal)
2601.07364v1_On the universal definition of intelligence.pdf,On the universal definition of intelligence: A definition for Human - AI Comparison,Joseph Chen,,,"intelligence, AI, human comparison, R. Carnap, conceptual clarification, predictive ability, Extended Predictive Hypothesis (EPH)","This paper proposes a universal definition of intelligence to enable fair and consistent comparison between human and artificial intelligence (AI). It critiques existing anthropocentric definitions and introduces four criteria for evaluating intelligence definitions: similarity to explicandum, exactness, fruitfulness, and simplicity. The paper examines six representative definitions, highlighting their strengths and limitations, and proposes the Extended Predictive Hypothesis (EPH) as a superior framework. EPH combines predictive ability with the capacity to benefit from predictions, offering a unified explanation for various aspects of intelligence, including creativity, learning, and future planning.",3.21,61.33,197,cold_start,Phi-4,Apple_M1(Metal)
2601.07372v1_Conditional Memory via Scalable Lookup A New Axis .pdf,Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models,"Xin Cheng, Wangding Zeng, Damai Dai, Qinyu Chen, Bingxuan Wang, Zhenda Xie, Kezhao Huang, Xingkai Yu, Zhewen Hao, Yukun Li, Han Zhang, Huishuai Zhang, Dongyan Zhao, Wenfeng Liang",,2601.07372v1,"Mixture-of-Experts, Transformers, knowledge lookup, conditional memory, Engram, N-gram embedding, Sparsity Allocation, scaling law, MoE, static memory, knowledge retrieval, general reasoning, code/math domains, mechanistic analyses, long-context retrieval, runtime prefetching, sparse models","The paper introduces conditional memory as a new axis of sparsity for large language models, addressing the lack of native primitives for knowledge lookup in Transformers. The proposed Engram module modernizes classic N-gram embedding for O(1) lookup, optimizing the trade-off between neural computation and static memory. The study reveals a U-shaped scaling law and demonstrates superior performance in various domains, including knowledge retrieval, general reasoning, and code/math tasks. Engram also enhances long-context retrieval and establishes infrastructure-aware efficiency through deterministic addressing and runtime prefetching. The authors envision conditional memory as an essential modeling primitive for next-generation sparse models.",3.06,124.947,382,cold_start,Phi-4,Apple_M1(Metal)
2601.07376v1_OpenTinker Separating Concerns in Agentic Reinforc.pdf,OpenTinker: Separating Concerns in Agentic Reinforcement Learning,"Siqi Zhu, Jiaxuan You",,arXiv:2601.07376v1,"Reinforcement Learning, Large Language Models, OpenTinker, Agent-Environment Interaction, RL Pipelines, Decomposition, Managed Execution Runtime, Multi-Agent Training","We introduce OpenTinker, an infrastructure for reinforcement learning (RL) of large language model (LLM) agents built around a separation of concerns across algorithm design, execution, and agent–environment interaction. Rather than relying on monolithic, end-to-end RL pipelines, OpenTinker decomposes agentic learning systems into lightweight, composable components with clearly defined abstraction boundaries. Users specify agents, environments, and interaction protocols, while inference and training are delegated to a managed execution runtime. OpenTinker introduces a centralized scheduler for managing training and inference workloads, including LoRA-based and full-parameter RL, supervised fine-tuning, and inference, over shared resources. We further discuss design principles for extending OpenTinker to multi-agent training. Finally, we present a set of RL use cases that demonstrate the effectiveness of the framework in practical agentic learning scenarios.",2.95,96.484,285,cold_start,Phi-4,Apple_M1(Metal)
2601.07377v1_Learning Dynamic Collaborative Network for Semi-su.pdf,Learning Dynamic Collaborative Network for Semi-supervised 3D Vessel Segmentation,"Jiao Xu, Xin Chen, Lihe Zhang",,,"3D vessel segmentation, semi-supervised learning, dynamic collaborative network, mean teacher, multi-view integration, adversarial supervision","This paper introduces a dynamic collaborative network, DiCo, for semi-supervised 3D vessel segmentation. Unlike conventional mean teacher methods that use a static approach, DiCo allows dynamic switching of teacher-student roles to address cognitive biases and improve performance. It incorporates a multi-view integration module and adversarial supervision to enhance segmentation accuracy. Experiments show that DiCo achieves state-of-the-art performance on three 3D vessel segmentation benchmarks.",2.58,76.743,198,cold_start,Phi-4,Apple_M1(Metal)
2601.07389v1_On the Non-decoupling of Supervised Fine-tuning an.pdf,On the Non-decoupling of Supervised Fine-tuning and Reinforcement Learning in Post-training,"Xueyan Niu, Bo Bai, Wei Han, Wei Xi Zhang",,arXiv:2601.07389v1,"Supervised Fine-tuning, Reinforcement Learning, Post-training, Large Language Models, Decoupling, Cross-entropy loss, Reward signals, Human preferences, Rule-based verifiers","Post-training of large language models routinely interleaves supervised fine-tuning (SFT) with reinforcement learning (RL). These two methods have different objectives: SFT minimizes the cross-entropy loss between model outputs and expert responses, while RL maximizes reward signals derived from human preferences or rule-based verifiers. Modern reasoning models have widely adopted the practice of alternating SFT and RL training. However, there is no theoretical account of whether they can be decoupled. We prove that decoupling is impossible in either order: (1) SFT-then-RL coupling: RL increases SFT loss under SFT optimality and (2) RL-then-SFT coupling: SFT lowers the reward achieved by RL. Experiments on Qwen3-0.6B confirm the predicted degradation, verifying that SFT and RL cannot be separated without loss of prior performance in the post-training pipeline.",3.15,105.723,333,cold_start,Phi-4,Apple_M1(Metal)
2601.07392v1_OceanSAR-2 A Universal Feature Extractor for SAR O.pdf,OceanSAR-2: A Universal Feature Extractor for SAR Ocean Observation,"Alexandre Tuela, Thomas Kerdreux, Quentin Febvre, Alexis Mouche, Antoine Grouazel, Jean-Renaud Miadana, Antoine Audras, Chen Wang, Bertrand Chapron",,,"SAR, ocean observation, self-supervised learning, foundation model, Sentinel-1 Wave Mode, geophysical pattern classification, ocean surface wind vector, significant wave height estimation, iceberg detection","We present OceanSAR-2, the second generation of our foundation model for SAR-based ocean observation. Building on our earlier release, which pioneered self-supervised learning on Sentinel-1 Wave Mode data, OceanSAR-2 relies on improved SSL training and dynamic data curation strategies, which enhances performance while reducing training cost. OceanSAR-2 demonstrates strong transfer performance across downstream tasks, including geophysical pattern classification, ocean surface wind vector and significant wave height estimation, and iceberg detection. We release standardized benchmark datasets, providing a foundation for systematic evaluation and advancement of SAR models for ocean applications.",2.88,93.852,270,cold_start,Phi-4,Apple_M1(Metal)
2601.07393v1_Software-Hardware Co-optimization for Modular E2E .pdf,"SOFTWARE-HARDWARE CO-OPTIMIZATION FOR MODULAR END-TO-END (ME2E) AUTONOMOUS DRIVING: A UNIFIED FRAMEWORK OF OPTIMIZATION APPROACHES, SIMULATION ENVIRONMENT AND EVALUATION METRICS","Chengzhi Ji, Xingfeng Li, Zhaodong Lv, Hao Sun, Pan Liu, Hao Frank Yang, Ziyuan Pu",,2601.07393v1,"Modular end-to-end, Closed-Loop Evaluation, Software–Hardware co-optimization, Energy Consumption","Modular end-to-end (ME2E) autonomous driving paradigms combine interpretability with global optimization capability and have achieved state-of-the-art performance. However, extant research has primarily emphasized improvements in accuracy metrics, while neglecting to address critical system-level considerations such as energy consumption and inference latency. Consequently, model designs have evolved to become increasingly intricate. To improve deployability, previous studies have investigated model compression and acceleration, yet these approaches are often pursued independently on either the software or hardware side. Software-only optimization cannot fundamentally eliminate intermediate tensor access and operator scheduling overheads. Hardware-only optimization is constrained by model structure and bit-width. Consequently, the benefits of such optimizations are often substantially diminished in real-world deployment. To address these limitations, this paper proposes a reusable software–hardware co-optimization and closed-loop evaluation framework for ME2E autonomous driving inference. The framework integrates software-level model optimizations with hardware-level computation optimizations under a unified system-level objective. Furthermore, a multidimensional evaluation metric, EERA V, is introduced. This metric evaluates the ME2E autonomous driving system performance by jointly considering safety, comfort, efficiency, latency, and energy, enabling quantitative assessment of the true system-level impact of different optimization strategies. The proposed framework is evaluated across multiple ME2E autonomous driving stacks. It preserves baseline-level accuracy while reducing inference latency by over 6× and per-frame energy to around one-fifth of the baseline. Furthermore, a 22.35% improvement in the EERA V metric is achieved. These results validate that the proposed framework provides actionable optimization guidance from both software and hardware perspectives.",3.36,149.147,501,cold_start,Phi-4,Apple_M1(Metal)
2601.07395v1_MCP-ITP An Automated Framework for Implicit Tool P.pdf,MCP-ITP: An Automated Framework for Implicit Tool Poisoning in MCP,"Ruiqi Li, Zhiqiang Wang, Yunhao Yao, Xiang-Yang Li",,,"Model Context Protocol, LLM-based agents, tool poisoning, implicit tool poisoning, security, machine learning","The paper introduces MCP-ITP, an automated framework for implicit tool poisoning within the Model Context Protocol (MCP) ecosystem. Unlike explicit tool poisoning, which involves direct invocation of malicious tools, implicit tool poisoning embeds malicious instructions in tool metadata, causing agents to invoke legitimate high-privilege tools for malicious purposes. MCP-ITP formulates this as a black-box optimization problem, using feedback from evaluation and detection language models to maximize attack success rate while evading detection. Experimental results show that MCP-ITP outperforms manually crafted baselines, achieving high attack success rates with low detection rates.",2.72,88.51,241,cold_start,Phi-4,Apple_M1(Metal)
2601.07397v1_Layerwise goal-oriented adaptivity for neural ODEs.pdf,Layerwise goal-oriented adaptivity for neural ODEs: an optimal control perspective,"Michael Hintermüller, Michael Hinze, Denis Korolev",,2601.07397v1,"Resnet, neural ODEs, parameter identification/learning, adaptive neural network","This work proposes a novel layerwise adaptive construction method for neural network architectures based on a goal-oriented dual-weighted residual technique for the optimal control of neural differential equations. This results in an ordinary differential equation constrained optimization problem with controls acting as coefficients and a specific loss function. The approach is implemented using a DG(0) Galerkin discretization of the neural ODE, leading to an explicit Euler time marching scheme, and optimization is performed using steepest descent. The method is applied to construct neural networks for classifying datasets, with results presented for well-known examples from the literature.",2.85,80.684,230,cold_start,Phi-4,Apple_M1(Metal)
2601.07411v1_SCALPEL Selective Capability Ablation via Low-rank.pdf,SCALPEL: Selective Capability Ablation via Low-rank Parameter Editing for Large Language Model Interpretability Analysis,"Zihao Fu, Xufeng Duan, Zhenguang G. Cai",,,"large language models, interpretability, capability ablation, low-rank parameter editing, LoRA adapters, capability encoding","Large language models have achieved remarkable success across diverse domains, yet their deployment in many applications such as healthcare, legal systems, and autonomous decision-making remains limited by our incomplete understanding of their internal mechanisms. SCALPEL (Selective Capability Ablation via Low-rank Parameter Editing for Large Language Models) is a framework that represents capabilities as low-rank parameter subspaces rather than discrete modules. It enables precise capability removal without affecting others by training LoRA adapters to reduce the model’s ability to distinguish correct from incorrect answers while preserving general language modeling quality. Experiments demonstrate that SCALPEL successfully removes target capabilities while preserving other general capabilities, providing fine-grained insights into how capabilities are distributed across the model’s parameter space. The results reveal that capabilities exhibit low-rank structure and can be selectively ablated through targeted parameter-space interventions, offering a more nuanced understanding of capability encoding in large language models.",3.1,98.048,304,cold_start,Phi-4,Apple_M1(Metal)
2601.07422v1_Two Pathways to Truthfulness On the Intrinsic Enco.pdf,Two Pathways to Truthfulness: On the Intrinsic Encoding of LLM Hallucinations,"Wen Luo, Guangyue Peng, Wei Li, Shaohang Wei, Feifan Song, Liang Wang, Nan Yang, Xingxing Zhang, Jing Jin, Furu Wei, Houfeng Wang",,,"large language models, hallucinations, truthfulness, question-anchored pathway, answer-anchored pathway, attention knockout, token patching, knowledge boundaries, hallucination detection","Despite their impressive capabilities, large language models (LLMs) frequently generate hallucinations. This paper demonstrates that truthfulness cues in LLMs arise from two distinct information pathways: a Question-Anchored pathway dependent on question-answer information flow, and an Answer-Anchored pathway deriving evidence from the generated answer itself. The study validates these pathways through attention knockout and token patching, revealing their association with LLM knowledge boundaries and internal representation awareness. The findings propose applications to enhance hallucination detection performance, offering new insights into how LLMs encode truthfulness.",2.86,103.931,297,cold_start,Phi-4,Apple_M1(Metal)
2601.07430v1_KALE Enhancing Knowledge Manipulation in Large Lan.pdf,KALE: Enhancing Knowledge Manipulation in Large Language Models via Knowledge-aware Learning,"Qitan Lv, Tianyu Liu, Qiaosheng Zhang, Xingcheng Xu, Chaochao Lu",,,"large language models, knowledge manipulation, supervised fine-tuning, knowledge graphs, multi-hop reasoning, rationale-guided reasoning","Despite the impressive performance of large language models (LLMs) pretrained on vast knowledge corpora, advancing their knowledge manipulation—the ability to effectively recall, reason, and transfer relevant knowledge—remains challenging. Existing methods mainly leverage Supervised Fine-Tuning (SFT) on labeled datasets to enhance LLMs’ knowledge manipulation ability. However, SFT models still exhibit the known&incorrect phenomenon, where they explicitly possess relevant knowledge for a given question but fail to leverage it for correct answers. To address this challenge, we propose KALE (Knowledge-Aware Learning)—a post-training framework that leverages knowledge graphs (KGs) to generate high-quality rationales and enhance LLMs’ knowledge manipulation ability. Specifically, KALE introduces a Knowledge-Induced (KI) data synthesis method that efficiently extracts multi-hop reasoning paths from KGs to generate high-quality rationales for question-answer pairs. Then, KALE employs a Knowledge-Aware (KA) fine-tuning paradigm that enhances knowledge manipulation by internalizing rationale-guided reasoning through minimizing the KL divergence between predictions with and without rationales. Extensive experiments on eight popular benchmarks across six different LLMs demonstrate the effectiveness of KALE, achieving accuracy improvements of up to 11.72% and an average of 4.18%.",3.02,128.998,389,cold_start,Phi-4,Apple_M1(Metal)
2601.07449v1_RLPO Residual Listwise Preference Optimization for.pdf,RLPO: Residual Listwise Preference Optimization for Long-Context Review Ranking,"Hao Jiang, Zhi Yang, Annan Wang, Yichi Zhang, Weisi Lin*",,,"review ranking, e-commerce, large language models, listwise preference optimization, long-context","Review ranking is pivotal in e-commerce for prioritizing diagnostic and authentic feedback from the deluge of user-generated content. While large language models have improved semantic assessment, existing ranking paradigms face a persistent trade-off in long-context settings. Pointwise scoring is efficient but often fails to account for list-level interactions, leading to miscalibrated top-k rankings. Listwise approaches can leverage global context, yet they are computationally expensive and become unstable as candidate lists grow. To address this, we propose Residual Listwise Preference Optimization (RLPO), which formulates ranking as listwise representation-level residual correction over a strong pointwise LLM scorer. RLPO first produces calibrated pointwise scores and item representations, then applies a lightweight encoder over the representations to predict listwise score residuals, avoiding full token-level listwise processing. We also introduce a large-scale benchmark for long-context review ranking with human verification. Experiments show RLPO improves NDCG@k over strong pointwise and listwise baselines and remains robust as list length increases.",2.9,102.754,298,cold_start,Phi-4,Apple_M1(Metal)
2601.07463v1_Puzzle it Out Local-to-Global World Model for Offl.pdf,Puzzle it Out: Local-to-Global World Model for Offline Multi-Agent Reinforcement Learning,"Sijia Li, Xinran Li, Shibo Chen, Jun Zhang",,,"Offline multi-agent reinforcement learning, Multi-agent model-based reinforcement learning","Offline multi-agent reinforcement learning (MARL) aims to solve cooperative decision-making problems in multi-agent systems using pre-collected datasets. Existing offline MARL methods primarily constrain training within the dataset distribution, resulting in overly conservative policies that struggle to generalize beyond the support of the data. While model-based approaches offer a promising solution by expanding the original dataset with synthetic data generated from a learned world model, the high dimensionality, non-stationarity, and complexity of multi-agent systems make it challenging to accurately estimate the transitions and reward functions in offline MARL. Given the difficulty of directly modeling joint dynamics, we propose a local-to-global (LOGO) world model, a novel framework that leverages local predictions—which are easier to estimate—to infer global state dynamics, thus improving prediction accuracy while implicitly capturing agent-wise dependencies. Using the trained world model, we generate synthetic data to augment the original dataset, expanding the effective state-action space. To ensure reliable policy learning, we further introduce an uncertainty-aware sampling mechanism that adaptively weights synthetic data by prediction uncertainty, reducing approximation error propagation to policies. In contrast to conventional ensemble-based methods, our approach requires only an additional encoder for uncertainty estimation, significantly reducing computational overhead while maintaining accuracy. Extensive experiments across 8 scenarios against 8 baselines demonstrate that our method surpasses state-of-the-art baselines on standard offline MARL benchmarks, establishing a new model-based baseline for generalizable offline multi-agent learning.",3.09,125.137,387,cold_start,Phi-4,Apple_M1(Metal)
2601.07464v1_IFDNS An Iterative Feedback-Driven Neuro-Symbolic .pdf,IFDNS: An Iterative Feedback-Driven Neuro-Symbolic Method for Faithful Logical Reasoning,"Xiaoheng Wang, Tongxuan Liu, Zi Gong, Xianzhe Dong, Yuting Zeng, Minhan Hu, Weizhe Huang, Jing Li",,,"Logical Reasoning, Large Language Model, Reasoning","Large language models (LLMs) have demonstrated impressive capabilities across a wide range of reasoning tasks, including logical and mathematical problem-solving. While prompt-based methods like Chain-of-Thought (CoT) can enhance LLM reasoning abilities to some extent, they often suffer from a lack of faithfulness, where the derived conclusions may not align with the generated reasoning chain. To address this issue, researchers have explored neuro-symbolic approaches to bolster LLM logical reasoning capabilities. However, existing neuro-symbolic methods still face challenges with information loss during the process. To overcome these limitations, we introduce Iterative Feedback-Driven Neuro-Symbolic (IFDNS), a novel prompt-based method that employs a multi-round feedback mechanism to address LLM limitations in handling complex logical relationships. IFDNS utilizes iterative feedback during the logic extraction phase to accurately extract causal relationship statements and translate them into propositional and logical implication expressions, effectively mitigating information loss issues. Furthermore, IFDNS is orthogonal to existing prompt methods, allowing for seamless integration with various prompting approaches. Empirical evaluations across six datasets demonstrate the effectiveness of IFDNS in significantly improving the performance of CoT and Chain-of-Thought with Self-Consistency (CoT-SC). Specifically, IFDNS achieves a +9.40% accuracy boost for CoT on the LogiQA dataset and a +11.70% improvement for CoT-SC on the PrOntoQA dataset.",3.06,136.428,417,cold_start,Phi-4,Apple_M1(Metal)
2601.07468v1_Beyond Dialogue Time Temporal Semantic Memory for .pdf,Beyond Dialogue Time: Temporal Semantic Memory for Personalized LLM Agents,"Miao Su, Yucan Guo, Zhongni Hou, Long Bai, Zixuan Li, Yufei Zhang, Guojun Yin, Wei Lin, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng",,2601.07468v1,"Large Language Model, memory, temporal semantic memory, personalization, dialogue agents","Memory enables Large Language Model (LLM) agents to perceive, store, and use information from past dialogues, which is essential for personalization. Existing methods fail to properly model the temporal dimension of memory in two aspects: temporal inaccuracy and temporal fragmentation. To address these limitations, the Temporal Semantic Memory (TSM) framework is proposed, which models semantic time for point-wise memory and supports the construction and utilization of durative memory. Experiments show that TSM consistently outperforms existing methods, achieving up to 12.2% absolute improvement in accuracy.",2.78,100.751,280,cold_start,Phi-4,Apple_M1(Metal)
2601.07469v1_Knowledge Distillation for LLM-Based Human Activit.pdf,KNOWLEDGE DISTILLATION FOR LLM-BASED HUMAN ACTIVITY RECOGNITION IN HOMES,"Julien Cumin, Oussama Er-Rahmany, Xi Chen",,2601.07469v1,"Human activity recognition, large language models, knowledge distillation, ambient intelligence, smart homes","Human Activity Recognition (HAR) is crucial for context-aware applications in smart homes and assisted living. Recent studies have demonstrated that Large Language Models (LLMs) can be effectively used for HAR, achieving high performance and addressing key challenges. This paper presents new experimental results on the use of LLMs for HAR using two state-of-the-art datasets. It explores how recognition performance varies with the size of the LLM and investigates the application of knowledge distillation techniques to fine-tune smaller LLMs using HAR reasoning examples generated by larger LLMs. The results indicate that fine-tuned models can nearly match the performance of the largest LLMs while having 50 times fewer parameters.",2.76,94.068,260,cold_start,Phi-4,Apple_M1(Metal)
2601.07470v1_Learning How to Remember A Meta-Cognitive Manageme.pdf,Learning How to Remember: A Meta-Cognitive Management Method for Structured and Transferable Agent Memory,"Sirui Liang, Pengfei Cao, Jian Zhao, Wenhao Teng, Xiangwen Liao, Jun Zhao, Kang Liu",,,"Large language model, memory management, meta-cognitive, memory abstraction, transfer learning, long-horizon decision-making, procedural memory","This paper introduces the Meta-Cognitive Memory Abstraction method (MCMA) to enhance memory management in large language model (LLM) agents. MCMA treats memory abstraction as a learnable cognitive skill, decoupling task execution from memory management. It employs a memory copilot trained via direct preference optimization to structure, abstract, and reuse memories. The method organizes memories into hierarchical abstraction levels, facilitating selective reuse based on task similarity. MCMA demonstrates significant improvements in performance, out-of-distribution generalization, and cross-task transfer in experiments on ALFWorld, ScienceWorld, and BabyAI.",2.68,101.074,271,cold_start,Phi-4,Apple_M1(Metal)
2601.07474v1_Task Prototype-Based Knowledge Retrieval for Multi.pdf,Task Prototype-Based Knowledge Retrieval for Multi-Task Learning from Partially Annotated Data,"Youngmin Oh, Hyung-Il Kim, Jung Uk Kim",,,"Multi-task learning, Partially annotated data, Prototype-based knowledge retrieval, Task-specific characteristics, Knowledge retrieval transformer","Multi-task learning (MTL) is essential for applications like autonomous driving and robotics, which require handling multiple tasks simultaneously. However, fully annotating data for all tasks is impractical due to high labeling costs. Existing methods for partially labeled MTL often rely on predictions from unlabeled tasks, leading to unreliable task associations and potential negative transfer. This paper proposes a prototype-based knowledge retrieval framework to address these issues. The framework includes task prototype embedding to capture task-specific characteristics and a knowledge retrieval transformer to refine feature representations based on task associations. An association knowledge generating (AKG) loss ensures consistent capture of task-specific characteristics. Experiments demonstrate the framework's effectiveness, showing its potential for robust MTL even with partially annotated data.",2.68,94.886,254,cold_start,Phi-4,Apple_M1(Metal)
2601.07475v1_ARCQuant Boosting NVFP4 Quantization with Augmente.pdf,ARCQuant: Boosting NVFP4 Quantization with Augmented Residual Channels for LLMs,"Haoqian Meng, Yilun Luo, Yafei Zhao, Wenyuan Liu, Peng Zhang, Xindian Ma",,,"NVFP4, Post-Training Quantization, LLMs, Microscaling formats, GEMM kernels, hardware constraints","The emergence of fine-grained numerical formats like NVFP4 offers new opportunities for efficient Large Language Model (LLM) inference. However, adapting existing Post-Training Quantization (PTQ) strategies to these formats is challenging due to issues with block isolation, quantization errors, and hardware constraints. ARCQuant is proposed to address these challenges by maintaining a unified NVFP4 format and augmenting the activation matrix with quantized residual channels. This approach integrates error compensation into the matrix reduction dimension, allowing the use of optimized GEMM kernels with minimal overhead. Theoretical analysis shows that ARCQuant's error bounds are comparable to standard 8-bit formats. Experiments on LLaMA and Qwen models demonstrate state-of-the-art accuracy, with up to 3× speedup over FP16 on RTX GPUs.",2.84,106.164,302,cold_start,Phi-4,Apple_M1(Metal)
2601.07477v1_JudgeFlow Agentic Workflow Optimization via Block .pdf,JUDGEFLOW: AGENTICWORKFLOWOPTIMIZATION VIA BLOCK JUDGE,"Zihan Ma, Zhikai Zhao, Chuanbo Hua, Federico Berto, Jinkyoo Park",,,"LLM-based agentic workflows, workflow optimization, evaluation-judge-optimization-update pipeline, block-level diagnostics, mathematical reasoning, code generation","Optimizing LLM-based agentic workflows is challenging due to reliance on coarse evaluation signals, leading to inefficient modifications. JUDGEFLOW introduces an Evaluation-Judge-Optimization-Update pipeline, incorporating reusable logic blocks and a Judge module to assign responsibility scores to problematic blocks. This approach enhances sample efficiency, interpretability, and scalability for complex workflows. JUDGEFLOW outperforms existing methods in mathematical reasoning and code generation benchmarks.",2.66,82.306,219,cold_start,Phi-4,Apple_M1(Metal)
2601.07496v1_Graph Inference Towards ICD Coding.pdf,Graph Inference Towards ICD Coding,Xiaoxiao Deng,,,"transfer learning, graph convolutional network, lightweight attention, ICD code prediction, adversarial domain adaptation","Automated ICD coding involves assigning standardized diagnostic codes to clinical narratives. The vast label space and extreme class imbalance challenge precise prediction. LabGraph, a unified framework, reformulates ICD coding as a graph generation task. It combines adversarial domain adaptation, graph-based reinforcement learning, and perturbation regularization to enhance model robustness and generalization. A label graph discriminator dynamically evaluates each generated code, providing adaptive reward feedback during training. Experiments on benchmark datasets show that LabGraph consistently outperforms previous approaches on micro-F1, micro-AUC, and P@K.",2.58,78.167,202,cold_start,Phi-4,Apple_M1(Metal)
2601.07514v1_Data-Driven Stochastic VRP Integration of Forecast.pdf,Data-Driven Stochastic VRP: Integration of Forecast Duration into Optimization for Utility Workforce Management,Matteo Garbellia,,2601.07514v1,"Stochastic VRP, Machine Learning, XGBoost, Sub-Gaussian Concentration, Multi-Objective Optimization, Evolutionary Algorithms","This paper investigates the integration of machine learning forecasts of intervention durations into a stochastic variant of the Capacitated Vehicle Routing Problem with Time Windows (CVRPTW). It utilizes tree-based gradient boosting (XGBoost) trained on eight years of gas meter maintenance data to produce point predictions and uncertainty estimates, which then drive a multi-objective evolutionary optimization routine. The methodology addresses uncertainty through sub-Gaussian concentration bounds for route-level risk buffers and explicitly accounts for competing operational KPIs through a multi-objective formulation. Empirical analysis of prediction residuals validates the sub-Gaussian assumption underlying the risk model. The results report improvements around 20-25% in operator utilization and completion rates compared with plans computed using default durations. The integration of uncertainty quantification and risk-aware optimization provides a practical framework for handling stochastic service durations in real-world routing applications.",3.36,84.351,283,cold_start,Phi-4,Apple_M1(Metal)
2601.07516v1_Controlling Multimodal Conversational Agents with .pdf,Controlling Multimodal Conversational Agents with Coverage-Enhanced Latent Actions,"Yongqi Li, Hao Lang, Tieyun Qian, Yongbin Li",,,"Vision-language models, Multimodal conversational agents, Reinforcement learning, Latent action space, Cross-modal projector, Cycle consistency loss","Vision-language models are increasingly employed as multimodal conversational agents (MCAs) for diverse conversational tasks. Reinforcement learning (RL) has been widely explored for adapting MCAs to various human-AI interaction scenarios. Despite showing great enhancement in generalization performance, fine-tuning MCAs via RL still faces challenges in handling the extremely large text token space. To address this, a compact latent action space for RL fine-tuning is learned instead. The learning from observation mechanism is adopted to construct the codebook for the latent action space, leveraging future observations to estimate current latent actions for reconstructing future observations. The scarcity of paired image-text data hinders learning a codebook with sufficient coverage. Thus, both paired image-text data and text-only data are leveraged to construct the latent action space, using a cross-modal projector for transforming text embeddings into image-text embeddings. The cross-modal projector is initialized on paired image-text data and further trained on massive text-only data with a novel cycle consistency loss to enhance its robustness. The method outperforms competitive baselines on two conversation tasks across various RL algorithms.",2.91,110.821,323,cold_start,Phi-4,Apple_M1(Metal)
2601.07518v1_Mon3tr Monocular 3D Telepresence with Pre-built Ga.pdf,Mon3tr: Monocular 3D Telepresence with Pre-built Gaussian Avatars as Amortization,"Fangyu Lin, Yingdong Hu, Zhening Liu, Yufan Zhuang, Zehong Lin, Member, IEEE, Jun Zhang, Fellow, IEEE",,,"Monocular 3D telepresence, 3D Gaussian splatting, animatable avatars, real-time neural rendering","Immersive telepresence aims to transform human interaction in AR/VR applications by enabling lifelike full-body holographic representations for enhanced remote collaboration. Existing systems rely on hardware-intensive multi-camera setups and demand high bandwidth for volumetric streaming, limiting their real-time performance on mobile devices. This paper proposes Mon3tr, a novel Monocular 3D telepresence framework that integrates 3D Gaussian splatting (3DGS) based parametric human modeling into telepresence. Mon3tr adopts an amortized computation strategy, dividing the process into a one-time offline multi-view reconstruction phase to build a user-specific avatar and a monocular online inference phase during live telepresence sessions. A single monocular RGB camera captures body motions and facial expressions in real time to drive the 3DGS-based parametric human model, significantly reducing system complexity and cost. The extracted motion and appearance features are transmitted at <0.2 Mbps over WebRTC’s data channel, allowing robust adaptation to network fluctuations. On the receiver side, a lightweight 3DGS attribute deformation network dynamically generates corrective 3DGS attribute adjustments on the pre-built avatar, synthesizing photorealistic motion and appearance at ~60 FPS. Extensive experiments demonstrate state-of-the-art performance, achieving a PSNR of >28 dB for novel poses, an end-to-end latency of ~80 ms, and >1000× bandwidth reduction compared to point-cloud streaming, while supporting real-time operation from monocular inputs across diverse scenarios.",3.14,140.706,442,cold_start,Phi-4,Apple_M1(Metal)
2601.07525v1_Thinking Before Constraining A Unified Decoding Fr.pdf,Thinking Before Constraining: A Unified Decoding Framework for Large Language Models,"Ngoc Trinh Hung Nguyen, Alonso Silva, Laith Zumot, Liubov Tupikina, Armen Aghasaryan, Mehwish Alam",,,"Natural generation, Structured generation, Language Models, Decoding framework, LLMs, Structured output, In-Writing approach","This paper introduces a unified decoding framework for large language models (LLMs) that combines natural and structured generation. The proposed method, called In-Writing, allows LLMs to reason freely until specific trigger tokens are generated, at which point structured generation is employed to ensure output reliability and consistency. The approach is evaluated on various datasets, demonstrating significant improvements in accuracy over natural generation alone, with minimal overhead. The study highlights the balance between expressiveness and structured output reliability, addressing limitations in current structured generation methods.",2.77,86.94,241,cold_start,Phi-4,Apple_M1(Metal)
2601.07528v1_From RAG to Agentic RAG for Faithful Islamic Quest.pdf,From RAG to Agentic RAG for Faithful Islamic Question Answering,"Gagan Bhatia, Hamdy Mubarak, Mustafa Jarrar, George Mikros, Fadi Zaraket, Mahmoud Alhirthani, Mutaz Al-Khatib, Logan Cochrane, Kareem Darwish, Rashid Yahiaoui, Firoj Alam",,,"Islamic question answering, LLMs, hallucinations, abstention, benchmark, agentic RAG, Quran grounding, multilingual LLMs, Islamic QA systems, jurisprudential reasoning, fiqh, canonical sources","The paper discusses the use of Large Language Models (LLMs) for Islamic question answering, highlighting the risks of ungrounded responses in religious contexts. It introduces ISLAMIC FAITH QA, a bilingual benchmark for evaluating hallucination and abstention in models. The authors developed an agentic Quran-grounding framework (agentic RAG) that improves answer correctness and robustness across languages. Experiments show that agentic RAG outperforms standard RAG, achieving state-of-the-art results even with smaller models. The paper emphasizes the importance of grounding in canonical sources and careful handling of uncertainty in Islamic QA systems.",2.97,114.761,341,cold_start,Phi-4,Apple_M1(Metal)
2601.07553v1_VirtualEnv A Platform for Embodied AI Research.pdf,VirtualEnv: A Platform for Embodied AI Research,"Kabir Swain, Sijie Han, Ayush Raina, Jin Zhang, Shuang Li, Michael Stopa, Antonio Torralba",,,"Large Language Models, Simulation Platform, Unreal Engine 5, Embodied AI, Interactive Environments, Agent-Environment Interactions, Procedural Task Generation, AI and Gaming, Immersive Simulations","As large language models (LLMs) continue to improve in reasoning and decision-making, there is a growing need for realistic and interactive environments where their abilities can be rigorously evaluated. We present VirtualEnv, a next-generation simulation platform built on Unreal Engine 5 that enables fine-grained benchmarking of LLMs in embodied and interactive scenarios. VirtualEnv supports rich agent–environment interactions, including object manipulation, navigation, and adaptive multi-agent collaboration, as well as game-inspired mechanics like escape rooms and procedurally generated environments. We provide a user-friendly API built on top of Unreal Engine, allowing researchers to deploy and control LLM-driven agents using natural language instructions. We integrate large-scale LLMs and vision-language models (VLMs), such as GPT-based models, to generate novel environments and structured tasks from multimodal inputs. Our experiments benchmark the performance of several popular LLMs across tasks of increasing complexity, analyzing differences in adaptability, planning, and multi-agent coordination. We also describe our methodology for procedural task generation, task validation, and real-time environment control. VirtualEnv is released as an open-source platform, aiming to advance research at the intersection of AI and gaming, enable standardized evaluation of LLMs in embodied AI settings, and pave the way for future developments in immersive simulations and interactive entertainment.",3.04,139.19,423,cold_start,Phi-4,Apple_M1(Metal)
2601.07556v1_Backpropagation-Free Test-Time Adaptation for Ligh.pdf,Backpropagation-Free Test-Time Adaptation for Lightweight EEG-Based Brain-Computer Interfaces,"Siyang Li, Jiayi Ouyang, Zhenyao Cui, Ziwei Wang, Tianwang Jia, Feng Wan, Dongrui Wu",,,"Brain-computer interface, domain adaptation, electroencephalogram, test-time adaptation, transfer learning","Electroencephalogram (EEG)-based brain-computer interfaces (BCIs) face significant deployment challenges due to inter-subject variability, signal non-stationarity, and computational constraints. This paper proposes Backpropagation-Free Transformations (BFT), a test-time adaptation (TTA) approach for EEG decoding that eliminates issues related to backpropagation, such as computational overhead, privacy risks, and sensitivity to noisy data streams. BFT applies multiple sample-wise transformations to each test trial, generating multiple prediction scores for a single test sample. A learning-to-rank module enhances the weighting of these predictions, enabling robust aggregation for uncertainty suppression during inference. Extensive experiments on five EEG datasets demonstrate the effectiveness, versatility, robustness, and efficiency of BFT, enabling lightweight plug-and-play BCIs on resource-constrained devices.",2.88,107.713,310,cold_start,Phi-4,Apple_M1(Metal)
2601.07565v1_A Unified Framework for Emotion Recognition and Se.pdf,A Unified Framework for Emotion Recognition and Sentiment Analysis via Expert-Guided Multimodal Fusion with Large Language Models,"Jiaqi Qiao, Xiujuan Xu, Xinran Li, Yu Liu",,,"emotion recognition, large language models, multimodal sentiment analysis, affective computing, multimodal fusion","This paper presents EGMF, a unified framework for multimodal emotion understanding that combines expert-guided multimodal fusion with large language models. The framework features three specialized expert networks: a fine-grained local expert, a semantic correlation expert, and a global context expert, which are adaptively integrated through hierarchical dynamic gating for context-aware feature selection. Enhanced multimodal representations are integrated with LLMs via pseudo token injection and prompt-based conditioning, enabling a single generative framework to handle both classification and regression through natural language generation. The approach employs LoRA fine-tuning for computational efficiency. Experiments on bilingual benchmarks (MELD, CHERMA, MOSEI, SIMS-V2) demonstrate consistent improvements over state-of-the-art methods, with superior cross-lingual robustness revealing universal patterns in multimodal emotional expressions across English and Chinese. The source code will be released publicly.",2.97,93.916,279,cold_start,Phi-4,Apple_M1(Metal)
2601.07568v1_d3LLM Ultra-Fast Diffusion LLM using Pseudo-Trajec.pdf,d3LLM: Ultra-Fast dLLM using Pseudo-Trajectory Distillation,"Yu-Yang Qian, Junda Su, Lanxiang Hu, Peiyuan Zhang, Zhijie Deng, Peng Zhao, Hao Zhang",,,"dLLMs, diffusion models, parallel decoding, pseudo-trajectory distillation, entropy-based multi-block decoding, KV-cache refresh mechanism, AUP (Accuracy Under Parallelism)","Diffusion large language models (dLLMs) offer capabilities beyond autoregressive (AR) LLMs, such as parallel decoding and random-order generation. However, they face an accuracy-parallelism trade-off. The paper proposes d3LLM, which balances accuracy and parallelism by introducing pseudo-trajectory distillation during training and entropy-based multi-block decoding with a KV-cache refresh mechanism during inference. A new metric, AUP (Accuracy Under Parallelism), is introduced to evaluate dLLMs. Experiments show that d3LLM achieves up to 10× speedup over vanilla LLaDA/Dream and 5× speedup over AR models without significant accuracy loss.",2.8,105.54,295,cold_start,Phi-4,Apple_M1(Metal)
2601.07573v1_A Model of Artificial Jagged Intelligence.pdf,A Model of Artificial Jagged Intelligence,Joshua S. Gans,,2601.07573v1,"generative AI, adoption, calibration, learning, knowledge density, scaling","Generative AI systems often display highly uneven performance across tasks that appear 'nearby': they can be excellent on one prompt and confidently wrong on another with only small changes in wording or context. This phenomenon is termed Artificial Jagged Intelligence (AJI). The paper develops an economic model of AJI, treating adoption as an information problem where users care about local reliability but typically observe only coarse, global quality signals. The model uses a one-dimensional landscape where truth is a rough Brownian process, and knowledge is scattered points drawn from a Poisson process. The local error is measured by posterior variance. The paper derives an adoption threshold for a blind user, shows that experienced errors are amplified by the inspection paradox, and interprets scaling laws as denser coverage that improves average quality without eliminating jaggedness. It also studies mastery and calibration, showing that a calibrated user who can condition on local uncertainty enjoys positive expected value even in domains that fail the blind adoption test. Mastery is modeled as learning a reliability map via Gaussian process regression, yielding a learning-rate bound driven by information gain. The paper concludes by studying how scaling interacts with discoverability, exploring when calibrated signals and user mastery accelerate the harvesting of scale improvements and when opacity can make gains from scaling effectively invisible.",3.3,97.858,323,cold_start,Phi-4,Apple_M1(Metal)
2601.07577v1_Beyond Entangled Planning Task-Decoupled Planning .pdf,Beyond Entangled Planning: Task-Decoupled Planning for Long-Horizon Agents,"Yunfan Li, Bingbing Xu, Xueyun Tian, Xiucheng Xu, Huawei Shen",,,"large language models, planning, long-horizon tasks, task decoupling, directed acyclic graph, sub-goals, task execution, error propagation, replanning","Recent advances in large language models (LLMs) have enabled agents to autonomously execute complex, long-horizon tasks, yet planning remains a primary bottleneck for reliable task execution. Existing methods typically fall into two paradigms: step-wise planning, which is reactive but often short-sighted; and one-shot planning, which generates a complete plan upfront yet is brittle to execution errors. Both paradigms suffer from entangled contexts, where the agent must reason over a monolithic history spanning multiple sub-tasks. This entanglement increases cognitive load and lets local errors propagate across otherwise independent decisions, making recovery computationally expensive. To address this, we propose Task-Decoupled Planning (TDP), a training-free framework that replaces entangled reasoning with task decoupling. TDP decomposes tasks into a directed acyclic graph (DAG) of sub-goals via a Supervisor. Using a Planner and Executor with scoped contexts, TDP confines reasoning and replanning to the active sub-task. This isolation prevents error propagation and corrects deviations locally without disrupting the workflow. Results on TravelPlanner, ScienceWorld, and HotpotQA show that TDP outperforms strong baselines while reducing token consumption by up to 82%, demonstrating that sub-task decoupling improves both robustness and efficiency for long-horizon agents.",3.11,132.992,414,cold_start,Phi-4,Apple_M1(Metal)
2601.07580v1_Large Language Models for Physics Instrument Desig.pdf,Large Language Models for Physics Instrument Design,"Sara Zoccheddu, Shah Rukh Qasim, Patrick Owen, Nicola Serra",,,"Large Language Models, Physics Instrument Design, Reinforcement Learning, Detector Design, AI in Design, Optimization","This study explores the application of large language models (LLMs) in the design of physics instruments, comparing their performance to reinforcement learning (RL). LLMs, using only prompting, generate valid and resource-aware detector configurations based on task constraints and prior designs. Although RL produces stronger designs, LLMs leverage broad pretrained knowledge to propose meaningful configurations without task-specific training. The study suggests using LLMs as meta-planners to design and orchestrate RL-based optimization studies, potentially reducing human effort in structuring and supervising optimization. This approach points toward automated, closed-loop instrument design, highlighting the importance of systematic design in complex systems like the Large Hadron Collider and future projects like the Future Circular Collider.",2.9,80.047,232,cold_start,Phi-4,Apple_M1(Metal)
2601.07582v2_ES-Mem Event Segmentation-Based Memory for Long-Te.pdf,ES-Mem: Event Segmentation-Based Memory for Long-Term Dialogue Agents,"Huhai Zou, Tianhao Sun, Chuanjiang He, Yu Tian, Zhenyang Li, Li Jin, Nayu Liu, Jiang Zhong, Kaiwen Wei",,,"memory mechanisms, dialogue agents, Event Segmentation Theory, hierarchical memory architecture, semantic integrity, discourse structure, episodic memory, context localization","Memory is critical for dialogue agents to maintain coherence and enable continuous adaptation in long-term interactions. Existing memory mechanisms offer basic storage and retrieval capabilities but are hindered by rigid memory granularity and flat retrieval paradigms. To address these limitations, the ES-Mem framework is proposed, incorporating a dynamic event segmentation module and a hierarchical memory architecture. This framework partitions long-term interactions into semantically coherent events and constructs multi-layered memories, leveraging boundary semantics for precise context localization. Evaluations demonstrate consistent performance gains over baseline methods, and the event segmentation module shows robust applicability on dialogue segmentation datasets.",2.84,98.459,280,cold_start,Phi-4,Apple_M1(Metal)
2601.07597v1_Pheromone-Focused Ant Colony Optimization algorith.pdf,Pheromone-Focused Ant Colony Optimization algorithm for path planning,"Yi Liu, Hongda Zhang, Zhongxue Gan, Yuning Chen, Ziqing Zhou, Chunlei Meng, Chun Ouyang",,,"Ant Colony Optimization, path planning, Pheromone-Focused Ant Colony Optimization, convergence, solution quality, Euclidean distances, pheromone deposition, forward-looking mechanism, global optimization","This paper introduces the Pheromone-Focused Ant Colony Optimization (PFACO) algorithm to address shortcomings in traditional Ant Colony Optimization (ACO) methods, such as blind search behavior and slow convergence in complex environments. PFACO enhances problem-solving by concentrating initial pheromone distribution in promising regions, reinforcing promising solutions during iterations, and implementing a forward-looking mechanism to penalize redundant path turns. These strategies improve convergence speed and solution quality, with experimental results showing PFACO outperforming comparative ACO algorithms.",2.91,90.437,263,cold_start,Phi-4,Apple_M1(Metal)
2601.07606v1_Proof of Time A Benchmark for Evaluating Scientifi.pdf,Proof of Time: A Benchmark for Evaluating Scientific Idea Judgments,"Bingyang Ye, Shan Chen, Jingxuan Tu, Chen Liu, Zidi Xiong, Samuel Schmidgall, Danielle S. Bitterman",,,"large language models, scientific idea judgments, benchmarking framework, peer-review awards, agent-based research, tool-using agents, scientific idea quality, AI for Science, machine learning systems, metascience","The paper introduces Proof of Time (PoT), a semi-verifiable benchmarking framework for evaluating the quality of models' judgments about scientific ideas. PoT links these judgments to observable downstream signals like citations and research agenda shifts. It uses a pre-cutoff snapshot of evidence in an offline sandbox to forecast post-cutoff outcomes, allowing for verifiable evaluation when ground truth arrives. The framework supports scalable benchmarking without exhaustive expert annotation and analyzes human-model misalignment. PoT also provides a testbed for comparing agent-based research judgments, showing that higher interaction budgets generally improve performance, with tool use benefits being task-dependent. The framework supports scalable evaluation of agents on future-facing scientific idea judgment tasks.",2.9,104.756,304,cold_start,Phi-4,Apple_M1(Metal)
2601.07611v1_DIAGPaper Diagnosing Valid and Specific Weaknesses.pdf,DIAGPaper: Diagnosing Valid and Specific Weaknesses in Scientific Papers via Multi-Agent Reasoning,"Zhuoyang Zou, Abolfazl Ansari, Delvin Ce Zhang, Dongwon Lee, Wenpeng Yin",,,"paper weakness identification, multi-agent systems, AI-assisted reviewing, peer-review process, reviewer bias, author rebuttals, review criteria","This paper introduces DIAGPaper, a novel multi-agent framework designed to address limitations in existing paper weakness identification systems. DIAGPaper integrates three modules: the Customizer, which simulates human-defined review criteria; the Rebuttal, which involves author agents in structured debates with reviewer agents; and the Prioritizer, which ranks weaknesses based on severity. The framework aims to produce more valid, specific, and prioritized weaknesses, outperforming existing methods in benchmarks like AAAR and ReviewCritique.",2.8,85.827,240,cold_start,Phi-4,Apple_M1(Metal)
2601.07618v1_Neural Architecture for Fast and Reliable Coagulat.pdf,Neural Architecture for Fast and Reliable Coagulation Assessment in Clinical Settings: Leveraging Thromboelastography,"Yulu Wang, Ziqian Zeng, Jianjun Wu, Zhifeng Tang",,,"Thromboelastography, coagulation assessment, medical AI, Physiological State Reconstruction, multi-domain learning, domain adaptation, few-shot learning, real-time monitoring","This paper addresses the challenge of real-time coagulation monitoring in clinical settings using Thromboelastography (TEG), which traditionally takes nearly an hour to provide outputs. The authors introduce a new algorithm, Physiological State Reconstruction (PSR), designed to make reliable predictions from small datasets and account for patient population variations. PSR integrates varied temporal signals using multi-domain learning and learns high-level temporal interactions with attention mechanisms. The algorithm demonstrates superior performance with R2 > 0.98 for coagulation traits and significantly reduces error and inferencing time compared to existing methods. The study highlights the potential of drift-aware learning in medical AI applications with data scarcity.",2.87,95.878,275,cold_start,Phi-4,Apple_M1(Metal)
2601.07632v2_GeoMotionGPT Geometry-Aligned Motion Understanding.pdf,GeoMotionGPT: Geometry-Aligned Motion Understanding with Large Language Models,"Zhankai Ye, Bofan Li, Yukai Jin, Shuoqiu Li, Wei Wang, Yanfu Zhang, Shangqian Gao, Xin Liu",,,"Large Language Models, motion understanding, motion-language reasoning, geometry alignment, discrete motion tokenization, quantization, semantic embedding, orthogonality, HumanML3D","Discrete motion tokenization has enabled Large Language Models (LLMs) to serve as versatile backbones for motion understanding and motion-language reasoning. However, existing pipelines typically decouple motion quantization from semantic embedding learning, linking them solely via token IDs, which fails to effectively align the intrinsic geometry of the motion space with the embedding space. This paper presents a novel framework that enforces orthogonality on both the motion codebook and the LLM embedding space, ensuring their relational structures naturally mirror each other. The framework employs a decoder-only quantizer with Gumbel-Softmax for differentiable training and balanced codebook usage, and uses a sparse projection to map motion codes into the LLM embedding space while preserving orthogonality. A two-stage orthonormal regularization schedule enforces soft constraints during tokenizer training and LLM fine-tuning to maintain geometric alignment without hindering semantic adaptation. Extensive experiments on HumanML3D demonstrate a 20% performance improvement over current state-of-the-art methods, validating that a unified geometric basis effectively empowers the LLM for nuanced motion reasoning.",3.05,125.576,383,cold_start,Phi-4,Apple_M1(Metal)
2601.07635v2_Learning About Learning A Physics Path from Spin G.pdf,Learning About Learning: A Physics Path from Spin Glasses to Artificial Intelligence,"Denis D. Caprioti, Matheus Haas, Constantino F. Vasconcelos, Mauricio Girardi-Schappo",,,"Hopfield model, spin-glass physics, neural networks, artificial intelligence, statistical mechanics, associative memory, combinatorial optimization, undergraduate physics, dynamical systems, linear algebra, computational methods","The Hopfield model, inspired by spin-glass physics, serves as a bridge between statistical mechanics, neural networks, and AI. Despite its broad applicability, it is rarely included in undergraduate physics curricula. This paper presents the Hopfield model as a pedagogically rich framework that unifies core topics from undergraduate physics, including statistical physics, dynamical systems, linear algebra, and computational methods. The paper provides a theoretical introduction, analyzes the model’s energy function, dynamics, and pattern stability, and discusses practical simulation aspects. It concludes with classroom-ready example problems to connect fundamental physics with contemporary AI applications, preparing physics students for computational tools in research, industry, and society.",2.96,100.446,297,cold_start,Phi-4,Apple_M1(Metal)
2601.07638v1_SALT-KG A Benchmark for Semantics-Aware Learning o.pdf,SALT-KG: A Benchmark for Semantics-Aware Learning on Enterprise Tables,"Isaiah Onando Mulang’, Felix Sasaki, Tassilo Klein, Jonas Kolk, Nikolay Grechanov, Johannes Hoffart",,2601.07638v1,"semantics-aware learning, enterprise tables, SALT benchmark, metadata knowledge graph, tabular prediction, foundation models, structured data","Building upon the SALT benchmark for relational prediction, SALT-KG introduces a benchmark for semantics-aware learning on enterprise tables. It extends SALT by linking multi-table transactional data with a structured Operational Business Knowledge represented in a Metadata Knowledge Graph (OBKG). This extension enables the evaluation of models that reason over tabular evidence and contextual semantics, which is critical for foundation models on structured data. Empirical analysis shows that metadata-derived features highlight gaps in models' ability to leverage semantics in relational contexts. SALT-KG reframes tabular prediction as semantics-conditioned reasoning, advancing tabular foundation models grounded in declarative knowledge and providing a benchmark for semantically linked tables in enterprise-scale structured data.",2.89,101.23,293,cold_start,Phi-4,Apple_M1(Metal)
2601.07641v1_Beyond Static Tools Test-Time Tool Evolution for S.pdf,Beyond Static Tools: Test-Time Tool Evolution for Scientific Reasoning,"Jiaxuan Lu, Ziyu Kong, Yemin Wang, Rong Fu, Haiyuan Wan, Cheng Yang, Wenjie Lou, Haoran Sun, Lilong Wang, Yankai Jiang, Xiaosong Wang, Xiao Sun, Dongzhan Zhou",,,"AI for Science, scientific reasoning, Large Language Models, Test-Time Tool Evolution, computational tools, tool libraries, scientific domains","The central challenge of AI for Science is not reasoning alone, but the ability to create computational methods in an open-ended scientific world. Existing LLM-based agents rely on static, pre-defined tool libraries, which fail in scientific domains where tools are sparse, heterogeneous, and incomplete. This paper proposes Test-Time Tool Evolution (TTE), enabling agents to synthesize, verify, and evolve executable tools during inference. TTE transforms tools from fixed resources into problem-driven artifacts, overcoming the limitations of static tool libraries. The paper introduces SciEvo, a benchmark with 1,590 scientific reasoning tasks supported by 925 automatically evolved tools. Experiments show TTE achieves state-of-the-art performance in accuracy and tool efficiency, enabling effective cross-domain adaptation of computational tools.",2.97,112.014,333,cold_start,Phi-4,Apple_M1(Metal)
2601.07651v1_Active Evaluation of General Agents Problem Defini.pdf,Active Evaluation of General Agents: Problem Definition and Comparison of Baseline Algorithms,"Marc Lanctot, Kate Larson, Ian Gemp, Michael Kaisers",,,"general evaluation, multitask evaluation, ranking, active learning, game theory, social choice theory","As intelligent agents become more generally-capable, the complexity and cost of properly evaluating them rises significantly. This paper proposes a formal definition and a conceptual framework for active evaluation of agents across multiple tasks, assessing the performance of ranking algorithms as a function of the number of evaluation data samples. The paper compares several baseline algorithms under different experimental contexts, using synthetic generated data and simulated online access to real evaluation data from Atari game-playing agents. It finds that the classical Elo rating system is a consistently reliable choice for efficient reduction of ranking error in practice, while Soft Condorcet Optimization shows comparable performance to Elo on synthetic data and significantly outperforms Elo on real Atari agent evaluation. When task variation from the ground truth is high, selecting tasks based on proportional representation leads to a higher rate of ranking error reduction.",2.83,86.81,246,cold_start,Phi-4,Apple_M1(Metal)
2601.07654v1_Towards Automating Blockchain Consensus Verificati.pdf,Towards Automating Blockchain Consensus Verification with IsabeLLM,"Elliot Jones, William Knottenbelt",,2601.07654v1,"Blockchain, Consensus, Formal Verification, Theorem Proving, Artificial Intelligence","Consensus protocols are crucial for blockchain systems as they allow agreement between nodes in potentially adversarial environments. Ensuring their correct design and implementation is essential to prevent malicious behavior. Formal verification ensures correctness but requires significant effort and expertise, often leading to its omission in development. This paper introduces IsabeLLM, a tool integrating the proof assistant Isabelle with a Large Language Model to assist and automate proofs. The tool's effectiveness is demonstrated by developing and verifying a novel model of Bitcoin's Proof of Work consensus protocol. The DeepSeek R1 API was used, successfully generating correct proofs for non-trivial lemmas in the verification process.",2.98,69.186,206,cold_start,Phi-4,Apple_M1(Metal)
2601.07663v2_Reasoning Models Will Blatantly Lie About Their Re.pdf,Reasoning Models Will Blatantly Lie About Their Reasoning,William Walden,,,"Large Reasoning Models, faithfulness, chains of thought, hints, interpretability","This study extends previous work to demonstrate that Large Reasoning Models (LRMs) will deny relying on hints provided in prompts, even when they clearly do so. The research shows that while instructing models to acknowledge hints can improve verbalization rates, LRMs still exhibit unfaithful behavior by denying the use of hints in their reasoning processes. This has discouraging implications for CoT monitoring and interpretability.",2.27,67.549,153,cold_start,Phi-4,Apple_M1(Metal)
2601.07666v1_Variational Contrastive Learning for Skeleton-base.pdf,Variational Contrastive Learning for Skeleton-based Action Recognition,"Dang-Dinh NGUYEN, Decky ASPANDI-LATIF, Titus ZAHARIA",,2601.07666v1,"Human Action Recognition, Self-Supervised Learning, Variational Inference","In recent years, self-supervised representation learning for skeleton-based action recognition has advanced with the development of contrastive learning methods. However, most of contrastive paradigms are inherently discriminative and often struggle to capture the variability and uncertainty intrinsic to human motion. To address this issue, we propose a variational contrastive learning framework that integrates probabilistic latent modeling with contrastive self-supervised learning. This formulation enables the learning of structured and semantically meaningful representations that generalize across different datasets and supervision levels. Extensive experiments on three widely used skeleton-based action recognition benchmarks show that our proposed method consistently outperforms existing approaches, particularly in low-label regimes. Moreover, qualitative analyses show that the features provided by our method are more relevant given the motion and sample characteristics, with more focus on important skeleton joints, when compared to the other methods.",3.2,86.127,276,cold_start,Phi-4,Apple_M1(Metal)
2601.07667v1_Adaptive Layer Selection for Layer-Wise Token Prun.pdf,Adaptive Layer Selection for Layer-Wise Token Pruning in LLM Inference,"Rei Taniguchi, Yuyang Dong, Makoto Onizuka, Chuan Xiao",,,"large language models, key-value cache reduction, layer-wise token pruning, LLM inference, adaptive selection, attention score, KV cache reduction","This paper introduces ASL, a training-free method for adaptively selecting the layer for key-value (KV) cache reduction in large language models (LLMs). Unlike existing methods that use pre-defined layers for token selection, ASL exploits the variance of token ranks ordered by attention score to choose the selection layer dynamically. This approach balances performance across different tasks while meeting user-specified KV budget requirements. ASL operates during the prefilling stage and can be used alongside existing methods like SnapKV to optimize the decoding stage. Evaluations on benchmarks such as InfiniteBench, RULER, and NIAH demonstrate that ASL outperforms state-of-the-art layer-wise token selection methods in accuracy while maintaining decoding speed and KV cache reduction.",2.8,98.263,275,cold_start,Phi-4,Apple_M1(Metal)
2601.07685v1_Predictive Analytics for Dementia Machine Learning.pdf,Predictive Analytics for Dementia: Machine Learning on Healthcare Data,"Shafiul Ajam Opee, Nafiz Fahad, Anik Sen, Rasel Ahmed, Fariha Jahan, Md. Kishor Morol, Md Rashedul Islam",,,"Dementia, Machine learning, Linear Discriminant Analysis (LDA), APOE-ϵ4 allele","Dementia is a complex syndrome impacting cognitive and emotional functions, with Alzheimer’s disease being the most common form. This study focuses on enhancing dementia prediction using machine learning (ML) techniques on patient health data. Supervised learning algorithms such as K-Nearest Neighbors (KNN), Quadratic Discriminant Analysis (QDA), Linear Discriminant Analysis (LDA), and Gaussian Process Classifiers are applied. Techniques like Synthetic Minority Over-sampling Technique (SMOTE) and Term Frequency-Inverse Document Frequency (TF-IDF) vectorization are used to address class imbalance and improve model performance. LDA achieved the highest testing accuracy of 98%. The study highlights the importance of model interpretability and the correlation of dementia with features such as the presence of the APOE-ϵ4 allele and chronic conditions like diabetes. Future ML innovations, particularly in integrating explainable AI approaches, are advocated to further improve predictive capabilities in dementia care.",2.98,109.319,326,cold_start,Phi-4,Apple_M1(Metal)
2601.07701v1_Deep Whole-body Parkour.pdf,Deep Whole-body Parkour,"Ziwen Zhuang, Shaoting Zhu, Mengjie Zhao, Hang Zhao",,arXiv:2601.07701v1,"humanoid control, perceptive locomotion, general motion tracking, deep reinforcement learning, legged robotics, whole-body motion tracking, exteroceptive sensing, multi-contact motions, parkour, dynamic tasks, terrain adaptability","This work presents a framework that integrates exteroceptive sensing into whole-body motion tracking, enabling humanoid robots to perform dynamic, non-locomotion tasks on uneven terrain. By training a single policy to execute multiple distinct motions across varied terrestrial features, the framework demonstrates the benefits of incorporating perception into the control loop. The results show that the system can perform robust, highly dynamic multi-contact motions such as vaulting and dive-rolling on unstructured terrain, significantly expanding the robot's traversability beyond simple walking or running.",2.93,85.572,251,cold_start,Phi-4,Apple_M1(Metal)
2601.07718v1_Hiking in the Wild A Scalable Perceptive Parkour F.pdf,Hiking in the Wild: A Scalable Perceptive Parkour Framework for Humanoids,"Shaoting Zhu, Ziwen Zhuang, Mengjie Zhao, Kun-Ying Lee, Hang Zhao",,2601.07718v1,"humanoid robotics, perception, parkour, terrain navigation, reinforcement learning, depth images, end-to-end framework","Achieving robust humanoid hiking in complex, unstructured environments requires transitioning from reactive proprioception to proactive perception. This work presents 'Hiking in the Wild,' a scalable, end-to-end parkour perceptive framework designed for robust humanoid hiking. The framework utilizes a single-stage reinforcement learning scheme, mapping raw depth inputs and proprioception directly to joint actions, without relying on external state estimation. It introduces a foothold safety mechanism and a flat patch sampling strategy to ensure safety and training stability. Extensive field experiments on a full-size humanoid demonstrate the framework's robust performance across diverse terrains, including stairs, gaps, high platforms, and ramps.",3.25,81.773,266,cold_start,Phi-4,Apple_M1(Metal)
2601.07737v1_Evaluating the encoding competence of visual langu.pdf,Evaluating the encoding competence of visual language models using uncommon actions,"Chen Ling, Nai Ding*",,2601.07737v1,cs.CV,,3.16,19.614,62,cold_start,Phi-4,Apple_M1(Metal)
2601.07748v1_Improving Domain Generalization in Contrastive Lea.pdf,Improving Domain Generalization in Contrastive Learning using Adaptive Temperature Control,"Robert Lewis, Katie Matton, Rosalind W. Picard, John Guttag",,2601.07748v1,"contrastive learning, domain generalization, self-supervised pre-training, covariate shift, domain invariance, InfoNCE loss, MNIST dataset","Self-supervised pre-training with contrastive learning is a powerful method for learning from sparsely labeled data. However, performance can drop considerably when there is a shift in the distribution of data from training to test time. This paper presents a new method for contrastive learning that incorporates domain labels to increase the domain invariance of learned representations, leading to improved out-of-distribution generalization. The method adjusts the temperature parameter in the InfoNCE loss using the probability that a negative sample comes from the same domain as the anchor, upweighting pairs from more similar domains. Experiments on a variant of the MNIST dataset demonstrate that this method yields better out-of-distribution performance than domain generalization baselines while maintaining strong in-distribution task performance.",2.99,95.724,286,cold_start,Phi-4,Apple_M1(Metal)
2601.07778v1_DT-ICU Towards Explainable Digital Twins for ICU P.pdf,DT-ICU: Towards Explainable Digital Twins for ICU Patient Monitoring via Multi-Modal and Multi-Task Iterative Inference,Wen Guo,,2601.07778v1,"digital twin, ICU patient monitoring, multi-modal, multi-task, iterative inference, clinical time series, static patient information, risk estimation, MIMIC-IV dataset, interpretability, critical care","We introduce DT-ICU, a multimodal digital twin framework for continuous risk estimation in intensive care. DT-ICU integrates variable-length clinical time series with static patient information in a unified multitask architecture, enabling predictions to be updated as new observations accumulate over the ICU stay. We evaluate DT-ICU on the large, publicly available MIMIC-IV dataset, where it consistently outperforms established baseline models under different evaluation settings. Our test-length analysis shows that meaningful discrimination is achieved shortly after admission, while longer observation windows further improve the ranking of high-risk patients in highly imbalanced cohorts. To examine how the model leverages heterogeneous data sources, we perform systematic modality ablations, revealing that the model learnt a reasonable structured reliance on interventions, physiological response observations, and contextual information. These analyses provide interpretable insights into how multimodal signals are combined and how trade-offs between sensitivity and precision emerge. Together, these results demonstrate that DT-ICU delivers accurate, temporally robust, and interpretable predictions, supporting its potential as a practical digital twin framework for continuous patient monitoring in critical care.",3.57,102.381,366,cold_start,Phi-4,Apple_M1(Metal)
2601.07779v1_OS-Symphony A Holistic Framework for Robust and Ge.pdf,OS-SYMPHONY: A Holistic Framework for Robust and Generalist Computer-Using Agent,"Bowen Yang, Kaiming Jin, Zhenyu Wu, Zhaoyang Liu, Qiushi Sun, Zehao Li, Jingjing Xie, Zhoumianze Liu, Fangzhi Xu, Kanzhi Cheng, Qingyun Li, Yian Wang, Yu Qiao, Zun Wang, Zichen Ding",,,"Vision-Language Models, Computer-Using Agents, Robustness, Generalization, Long-Horizon Workflows, Visual Context Curation, Tutorial Retrieval, Orchestrator, Reflection-Memory Agent, Multimodal Searcher, See-Act Paradigm","While Vision-Language Models (VLMs) have significantly advanced Computer-Using Agents (CUAs), current frameworks struggle with robustness in long-horizon workflows and generalization in novel domains. These limitations stem from a lack of granular control over historical visual context curation and the absence of visual-aware tutorial retrieval. To bridge these gaps, we introduce OS-SYMPHONY, a holistic framework that comprises an Orchestrator coordinating two key innovations for robust automation: 1) a Reflection-Memory Agent that utilizes milestone-driven long-term memory to enable trajectory-level self-correction, effectively mitigating visual context loss in long-horizon tasks; 2) Versatile Tool Agents featuring a Multimodal Searcher that adopts a See-Act paradigm to navigate a browser-based sandbox to synthesize live, visually aligned tutorials, thereby resolving fidelity issues in unseen scenarios. Experimental results demonstrate that OS-SYMPHONY delivers substantial performance gains across varying model scales, establishing new state-of-the-art results on three online benchmarks, notably achieving 65.84% on OSWorld. Our code and project are publicly available at /githubOS-Copilot/OS-Symphony and /gl⌢beOS-Symphony Homepage.",3.07,146.434,450,cold_start,Phi-4,Apple_M1(Metal)
2601.07782v1_Beyond Single-Shot Multi-step Tool Retrieval via Q.pdf,Beyond Single-Shot: Multi-step Tool Retrieval via Query Planning,"Wei Fang, James Glass",,,,"LLM agents operating over massive, dynamic tool libraries rely on effective retrieval, yet standard single-shot dense retrievers struggle with complex requests. These failures primarily stem from the disconnect between abstract user goals and technical documentation, and the limited capacity of fixed-size embeddings to model combinatorial tool compositions. To address these challenges, we propose TOOLQP, a lightweight framework that models retrieval as iterative query planning. Instead of single-shot matching, TOOLQP decomposes instructions into sub-tasks and dynamically generates queries to interact with the retriever, effectively bridging the semantic gap by targeting the specific sub-tasks required for composition. We train TOOLQP using synthetic query trajectories followed by optimization via Reinforcement Learning with Verifiable Rewards (RLVR). Experiments demonstrate that TOOLQP achieves state-of-the-art performance, exhibiting superior zero-shot generalization, robustness across diverse retrievers, and significant improvements in downstream agentic execution.",2.76,85.386,236,cold_start,Phi-4,Apple_M1(Metal)
2601.07790v1_Benchmarking Small Language Models and Small Reaso.pdf,Benchmarking Small Language Models and Small Reasoning Language Models on System Log Severity Classification,"Yahya Masri, Emily Ma, Zifu Wang, Joseph Rogers, Chaowei Yang",,arXiv:2601.07790v1,"system logs, severity classification, language models, reasoning language models, benchmarking, digital twins, root cause analysis","System logs are crucial for monitoring and diagnosing modern computing infrastructure, but their scale and complexity require reliable and efficient automated interpretation. This study evaluates nine small language models (SLMs) and small reasoning language models (SRLMs) using real-world journalctl data from Linux production servers. The models are assessed under zero-shot, few-shot, and retrieval-augmented generation (RAG) prompting. Results show that Qwen3-4B achieves the highest accuracy with RAG, while Gemma3-1B significantly improves with RAG. The study highlights the importance of architectural design, training objectives, and the ability to integrate retrieved context for performance. Efficiency measurements indicate that most Gemma and Llama variants are faster, whereas Phi-4-Mini-Reasoning is slower and less accurate. The findings suggest that severity classification can serve as a benchmark for evaluating model competence and real-time deployability, with implications for root cause analysis and digital twin integration.",3.11,105.694,329,cold_start,Phi-4,Apple_M1(Metal)
2601.07794v1_Kinship Data Benchmark for Multi-hop Reasoning.pdf,Kinship Data Benchmark for Multi-hop Reasoning,"Tianda Sun, Dimitar Kazakov",,,"multi-hop reasoning, kinship relations, genealogical data, large language models, cultural settings","Large language models (LLMs) are increasingly evaluated on their ability to perform multi-hop reasoning, i.e., to combine multiple pieces of information into a coherent inference. This paper introduces KinshipQA, a benchmark designed to probe this capability through reasoning over kinship relations. The central contribution is a generative pipeline that produces large-scale, realistic, and culture-specific genealogical data: collections of interconnected family trees that satisfy explicit marriage constraints associated with different kinship systems. This allows task difficulty, cultural assumptions, and relational depth to be systematically controlled and varied. From these genealogies, textual inference tasks are derived that require reasoning over implicit relational chains. The benchmark is evaluated using six state-of-the-art LLMs, spanning both open-source and closed-source models, under a uniform zero-shot protocol with deterministic decoding. Performance is measured using exact-match and set-based metrics. Results demonstrate that KinshipQA yields a wide spread of outcomes and exposes systematic differences in multi-hop reasoning across models and cultural settings.",2.91,94.114,274,cold_start,Phi-4,Apple_M1(Metal)
2601.07821v1_Failure-Aware RL Reliable Offline-to-Online Reinfo.pdf,Failure-Aware RL: Reliable Offline-to-Online Reinforcement Learning with Self-Recovery for Real-World Manipulation,"Huanyu Li, Kun Lei, Sheng Zang, Kaizhe Hu, Yongyuan Liang, Bo An, Xiaoli Li, Huazhe Xu",,,"Reinforcement Learning, Offline-to-Online RL, Failure-Aware RL, Real-World Manipulation, Self-Recovery, Intervention-requiring Failures","This paper introduces Failure-Aware Offline-to-Online Reinforcement Learning (FARL), a paradigm designed to minimize failures during real-world reinforcement learning. FARL predicts potential failures and executes recovery actions, significantly reducing Intervention-requiring Failures (IR Failures) during real-world RL while improving task performance. The authors present FailureBench, a benchmark incorporating common failure scenarios requiring human intervention, and propose an algorithm integrating a world-model-based safety critic and a recovery policy trained offline. Extensive simulation and real-world experiments demonstrate FARL's effectiveness in reducing IR Failures by 73.1% and improving performance by 11.3% on average during real-world RL post-training.",2.91,102.581,299,cold_start,Phi-4,Apple_M1(Metal)
2601.07832v2_MHLA Restoring Expressivity of Linear Attention vi.pdf,MHLA: Restoring Expressivity of Linear Attention via Token-Level Multi-Head,"Kewei Zhang, Ye Huang, Yufan Deng, Jincheng Yu, Junsong Chen, Huan Ling, Enze Xie, Daquan Zhou",,arXiv:2601.07832v2,"Transformer, self-attention, linear attention, multi-head attention, expressivity, computational efficiency, image classification, NLP, image generation, video generation","While the Transformer architecture dominates many fields, its quadratic self-attention complexity hinders its use in large-scale applications. Linear attention offers an efficient alternative, but its direct application often degrades performance, with existing fixes typically re-introducing computational overhead through extra modules that defeat the original purpose. This work identifies a key failure mode in these methods: global context collapse, where the model loses representational diversity. To address this, Multi-Head Linear Attention (MHLA) is proposed, which preserves this diversity by computing attention within divided heads along the token dimension. MHLA maintains linear complexity while recovering much of the expressive power of softmax attention, and its effectiveness is verified across multiple domains, achieving improvements in image classification, NLP, image generation, and video generation under the same time complexity.",3.13,105.715,331,cold_start,Phi-4,Apple_M1(Metal)
2601.07885v1_Small Symbols Big Risks Exploring Emoticon Semanti.pdf,"Small Symbols, Big Risks: Exploring Emoticon Semantic Confusion in Large Language Models","Weipeng Jiang, Xiaoyu Zhang, Juan Zhai, Shiqing Ma, Chao Shen, Yang Liu",,,"emoticon semantic confusion, large language models, security vulnerabilities, automated data generation, LLM safety","Emoticons are widely used in digital communication to convey affective intent, yet their safety implications for Large Language Models (LLMs) remain largely unexplored. This paper identifies emoticon semantic confusion, a vulnerability where LLMs misinterpret ASCII-based emoticons to perform unintended and potentially destructive actions. An automated data generation pipeline was developed, resulting in a dataset of 3,757 code-oriented test cases across 21 meta-scenarios, four programming languages, and varying contextual complexities. The study reveals that emoticon semantic confusion is pervasive, with an average confusion ratio exceeding 38%. Over 90% of confused responses yield 'silent failures', which are syntactically valid but deviate from user intent, potentially leading to destructive security consequences. This vulnerability transfers to popular agent frameworks, and existing prompt-based mitigations are largely ineffective. The paper calls for the community to recognize this emerging vulnerability and develop effective mitigation methods to ensure the safety and reliability of human-AI interactions.",2.89,112.481,325,cold_start,Phi-4,Apple_M1(Metal)
2601.07891v1_KVzap Fast Adaptive and Faithful KV Cache Pruning.pdf,"KVzap: Fast, Adaptive, and Faithful KV Cache Pruning","Simon Jégou, Maximilian Jeblick",,2601.07891v1,"KV cache, pruning, transformer-based language models, inference bottleneck, compression, accuracy","Growing context lengths in transformer-based language models have made the key-value (KV) cache a critical inference bottleneck. KVzap is introduced as a fast, input-adaptive approximation of KVzip that works in both prefilling and decoding. It achieves 2–4× KV cache compression with negligible accuracy loss, outperforming 15 other methods on the KVpress Leaderboard for models like Qwen3-8B and Llama-3.1-8B-Instruct. The KV cache, essential for transformer attention, becomes a dominant bottleneck as sequence lengths grow, increasing GPU memory usage and reducing decoding throughput. KVzap addresses these challenges effectively.",2.9,77.629,225,cold_start,Phi-4,Apple_M1(Metal)
2601.07892v1_Sherry Hardware-Efficient 1.25-Bit Ternary Quantiz.pdf,Hardware-Efficient 1.25-Bit Ternary Quantization via Fine-grained Sparsification,"Hong Huang, Decheng Wu, Qiangqiang Hu, Guanghua Yu, Jinhai Yang, Jianchen Zhu, Xue Liu, Dapeng Wu",,,"ternary quantization, hardware efficiency, sparsification, large language models, edge devices, quantization, sparse ternary training","The deployment of Large Language Models (LLMs) on resource-constrained edge devices is increasingly hindered by prohibitive memory and computational requirements. Ternary quantization, which reduces weights to {−1,0,+1}, offers a solution but suffers from misalignment with commodity hardware. This paper introduces Sherry, a hardware-efficient ternary quantization framework that achieves a regularized 1.25-bit width through fine-grained sparsity, addressing issues like weight trapping and representational collapse. Empirical evaluations demonstrate that Sherry matches state-of-the-art ternary performance while reducing model size and improving speed on edge devices.",2.81,99.957,281,cold_start,Phi-4,Apple_M1(Metal)
2601.07894v1_Revealing the Attention Floating Mechanism in Mask.pdf,Revealing the Attention Floating Mechanism in Masked Diffusion Models,"Xin Dai, Pengcheng Huang, Zhenghao Liu, Shuo Wang, Yukun Yan, Chaojun Xiao, Yu Gu, Ge Yu, Maosong Sun",,,"Masked Diffusion Models, Attention Mechanism, Bidirectional Attention, Denoising Process, Autoregressive Models, Attention Floating, In-Context Learning, Knowledge-Intensive Tasks","Masked diffusion models (MDMs) leverage bidirectional attention and a denoising process, narrowing the performance gap with autoregressive models (ARMs). This paper investigates the attention behaviors in MDMs, revealing the phenomenon of Attention Floating. Unlike ARMs, where attention converges to a fixed sink, MDMs exhibit dynamic, dispersed attention anchors that shift across denoising steps and layers. Shallow layers utilize floating tokens to build a global structural framework, while deeper layers focus on capturing semantic content. This distinctive attention pattern explains the strong in-context learning capabilities of MDMs, allowing them to double the performance compared to ARMs in knowledge-intensive tasks.",2.91,103.135,300,cold_start,Phi-4,Apple_M1(Metal)
2601.07898v1_Large Language Models and Algorithm Execution Appl.pdf,Large Language Models and Algorithm Execution: Application to an Arithmetic Function,"Farah Ben Slama, Frédéric Armetta",,,"Algorithmic learning in natural language, Supervised learning by decomposition, Large language model, Fine-tuning","Large Language Models (LLMs) have developed advanced functionalities through statistical learning and generalization. However, they struggle with internalizing data and executing algorithms autonomously. This paper explores extending LLMs' capabilities for algorithm execution via specialized supervised training focused on reasoning decomposition. A training model called LLM-DAL (Large Language Model - Decompositional Algorithmic Learning) is introduced, demonstrating improved algorithmic inference and generalization when training methods guide the learning process. The paper discusses the challenges of using neural networks for algorithmic learning, aiming to automate complex algorithm execution without explicit implementation, thus enabling more systematic and explainable reasoning. The limitations of AI systems in knowledge grounding, as highlighted by Searle's Chinese room thought experiment, are acknowledged, though the paper does not claim to overcome these fundamental issues.",3.0,86.141,258,cold_start,Phi-4,Apple_M1(Metal)
2601.07901v1_Decentralized Online Convex Optimization with Unkn.pdf,Decentralized Online Convex Optimization with Unknown Feedback Delays,"Hao Qiu, Mengxiao Zhang, Juliette Achddou",,arXiv:2601.07901v1,"Decentralized Online Convex Optimization, Feedback Delays, Federated Learning, Sensor Networks, Multi-Agent Control, Adaptive Learning Rate, Gossip-Based Strategy, Spectral Gap, Strongly Convex Setting","This paper addresses decentralized online convex optimization (D-OCO) under unknown, time- and agent-varying feedback delays. Existing algorithms assume prior knowledge of the total delay, leading to suboptimal performance. The authors propose a novel algorithm with an improved regret bound, utilizing an adaptive learning rate mechanism and a decentralized communication protocol. This allows agents to estimate delays locally without prior knowledge of the total delay. The framework is extended to the strongly convex setting, deriving a sharper regret bound. Experimental results demonstrate the effectiveness of the approach, showing improvements over existing benchmarks.",3.0,87.242,262,cold_start,Phi-4,Apple_M1(Metal)
2601.07903v2_Enhancing Large Language Models for Time-Series Fo.pdf,Enhancing Large Language Models for Time-Series Forecasting via Vector-Injected In-Context Learning,"Jianqi Zhang, Jingyao Wang, Wenwen Qiang, Fanjiang Xu, Changwen Zheng",https://doi.org/XXXXXXX.XXXXXXX,,"Time Series Forecasting, Large Language Model, In-context Learning","The World Wide Web needs reliable predictive capabilities to respond to changes in user behavior and usage patterns. Time series forecasting (TSF) is a key means to achieve this goal. In recent years, the large language models (LLMs) for TSF (LLM4TSF) have achieved good performance. However, there is a significant difference between pretraining corpora and time series data, making it hard to guarantee forecasting quality when directly applying LLMs to TSF; fine-tuning LLMs can mitigate this issue, but often incurs substantial computational overhead. Thus, LLM4TSF faces a dual challenge of prediction performance and compute overhead. To address this, we aim to explore a method for improving the forecasting performance of LLM4TSF while freezing all LLM parameters to reduce computational overhead. Inspired by in-context learning (ICL), we propose LVICL. LVICL uses our vector-injected ICL to inject example information into a frozen LLM, eliciting its in-context learning ability and thereby enhancing its performance on the example-related task (i.e., TSF). Specifically, we first use the LLM together with a learnable context vector adapter to extract a context vector from multiple examples adaptively. This vector contains compressed, example-related information. Subsequently, during the forward pass, we inject this vector into every layer of the LLM to improve forecasting performance. Compared with conventional ICL that adds examples into the prompt, our vector-injected ICL does not increase prompt length; moreover, adaptively deriving a context vector from examples suppresses components harmful to forecasting, thereby improving model performance. Extensive experiments demonstrate the effectiveness of our approach.",3.31,139.696,463,cold_start,Phi-4,Apple_M1(Metal)
2601.07935v1_Towards Specialized Generalists A Multi-Task MoE-L.pdf,Towards Specialized Generalists: A Multi-Task MoE-LoRA Framework for Domain-Specific LLM Adaptation,"Yuxin Yang, Aoxiong Zeng, Xiangquan Yang",,arXiv:2601.07935v1,"Large Language Models, Domain-Specific Adaptation, Mixture-of-Experts, Low-Rank Adaptation, Medical NLP, Catastrophic Forgetting, Knowledge Preservation","The paper addresses the challenges of adapting Large Language Models (LLMs) to specialized fields like medicine, focusing on the 'Stability-Plasticity Dilemma' and 'Task Interference'. It introduces Med-MoE-LoRA, a framework combining Mixture-of-Experts (MoE) with Low-Rank Adaptation (LoRA) for efficient multi-task domain adaptation. The framework features an asymmetric expert distribution and a 'Knowledge-Preservation Plugin' to protect general-purpose reasoning. Experimental results show that Med-MoE-LoRA outperforms standard LoRA and conventional MoE architectures in medical benchmarks while maintaining general cognitive capabilities.",3.19,87.564,279,cold_start,Phi-4,Apple_M1(Metal)
2601.07939v1_SECite Analyzing and Summarizing Citations in Soft.pdf,Analyzing and Summarizing Citations in Software Engineering Literature,"Shireesh Reddy Pyreddy, Khaja Valli Pathan, Hasan Masum, Tarannum Shaila Zaman",,,"Sentiment Analysis, LLMs, Text Summarization, Citations","Identifying the strengths and limitations of a research paper is a core component of any literature review. Traditional summaries reflect only the authors’ self-presented perspective. Analyzing how other researchers discuss and cite the paper can offer a deeper, more practical understanding of its contributions and shortcomings. This research introduces SECite, a novel approach for evaluating scholarly impact through sentiment analysis of citation contexts. A semi-automated pipeline extracts citations referencing nine research papers and applies advanced natural language processing (NLP) techniques with unsupervised machine learning to classify these citation statements as positive or negative. Generative AI is used to produce sentiment-specific summaries that capture the strengths and limitations of each target paper, derived both from clustered citation groups and from the full text. The findings reveal meaningful patterns in how the academic community perceives these works, highlighting areas of alignment and divergence between external citation feedback and the authors’ own presentation. By integrating citation sentiment analysis with LLM-based summarization, this study provides a comprehensive framework for assessing scholarly contributions.",3.25,96.509,314,cold_start,Phi-4,Apple_M1(Metal)
2601.07941v2_Moonworks Lunara Aesthetic Dataset.pdf,Moonworks Lunara Aesthetic Dataset,"Yan Wang, M M Sayeef Abdullah, Partho Hassan, Sabit Hassan",,arXiv:2601.07941v2,"text-to-image generation, prompt grounding, style conditioning, aesthetic dataset, artistic styles, image–prompt pairs","This data card presents the first public release of the Lunara Aesthetic Dataset, a curated set of 2,000 image–prompt pairs for controlled research on prompt grounding and style conditioning in text-to-image generation systems. The dataset spans diverse artistic styles, including regionally grounded aesthetics from the Middle East, Northern Europe, East Asia, and South Asia, alongside general categories such as sketch and oil painting. All images are generated using the Moonworks Lunara model and intentionally crafted to embody distinct, high-quality aesthetic styles, yielding a first-of-its-kind dataset with substantially higher aesthetic scores, exceeding even aesthetics-focused datasets, and general-purpose datasets by a larger margin. Each image is accompanied by a human-refined prompt and structured annotations that jointly describe salient objects, attributes, relationships, and stylistic cues. Unlike large-scale web-derived datasets that emphasize breadth over precision, the Lunara Aesthetic Dataset prioritizes aesthetic quality, stylistic diversity, and licensing transparency, and is released under the Apache 2.0 license to support research and unrestricted academic and commercial use.",3.52,90.827,320,cold_start,Phi-4,Apple_M1(Metal)
2601.07946v1_Coupled Diffusion-Encoder Models for Reconstructio.pdf,Coupled Diffusion–Encoder Models for Reconstruction of Flow Fields,"AmirPouya Hemmasian, Amir Barati Farimani",,,"Diffusion model, Encoder, Flow field reconstruction, Autoencoder, Variational Autoencoders, Probabilistic modeling, Generative modeling, Kolmogorov flow fields","This paper introduces DiffCoder, a framework that combines a probabilistic diffusion model with a convolutional ResNet encoder to reconstruct flow fields. Unlike traditional variational autoencoders (VAEs), which struggle to preserve higher-order statistical structures under strong compression, DiffCoder effectively recovers distributional and spectral properties critical for representing flow fields. The study evaluates DiffCoder against VAEs using a dataset of Kolmogorov flow fields, demonstrating that DiffCoder significantly improves spectral accuracy under aggressive compression, while maintaining comparable L2 reconstruction error. The results suggest that diffusion-based priors are particularly beneficial in scenarios with severe information bottlenecks, offering a promising approach for compact and statistically consistent flow field representations.",3.1,77.947,242,cold_start,Phi-4,Apple_M1(Metal)
2601.07948v1_Reinforcement Learning Methods for Neighborhood Se.pdf,Reinforcement Learning Methods for Neighborhood Selection in Local Search,"Yannick Molinghen, Augustin Delecluse, Renaud De Landtsheer, Stefano Michelini",,,"Local Search, Reinforcement Learning, Combinatorial Optimization","Reinforcement learning has recently gained traction as a means to improve combinatorial optimization methods, yet its effectiveness within local search metaheuristics specifically remains comparatively underexamined. In this study, we evaluate a range of reinforcement learning-based neighborhood selection strategies – multi-armed bandits (upper confidence bound, ε-greedy) and deep reinforcement learning methods (proximal policy optimization, double deep Q-network) – and compare them against multiple baselines across three different problems: the traveling salesman problem, the pickup and delivery problem with time windows, and the car sequencing problem. We show how search-specific characteristics, particularly large variations in cost due to constraint violation penalties, necessitate carefully designed reward functions to provide stable and informative learning signals. Our extensive experiments reveal that algorithm performance varies substantially across problems, although that ε-greedy consistently ranks among the best performers. In contrast, the computational overhead of deep reinforcement learning approaches only makes them competitive with a substantially longer runtime. These findings highlight both the promise and the practical limitations of deep reinforcement learning in local search.",3.16,100.738,318,cold_start,Phi-4,Apple_M1(Metal)
2601.07951v1_Hybrid SARIMA LSTM Model for Local Weather Forecas.pdf,Hybrid SARIMA–LSTM Model for Local Weather Forecasting: A Residual-Learning Approach for Data-Driven Meteorological Prediction,"Shreyas Rajeev Stevens Institute of Technology Hoboken, USA, Karthik Mudenahalli Ashoka Stevens Institute of Technology Hoboken, USA, Amit Mallappa Tiparaddi Stevens Institute of Technology Hoboken, USA",,,"SARIMA, LSTM, weather forecasting, residual learning, deep learning, time-series analysis, meteorological prediction","This paper introduces a Hybrid SARIMA–LSTM architecture for local weather forecasting, addressing the limitations of traditional statistical models and independent neural networks in long-term predictions. The model separates temperature into a predictable climate component and a non-linear weather component using a residual-learning strategy. SARIMA models the long-term seasonal trend, while LSTM learns the random changes in SARIMA's prediction errors. The approach incorporates Fourier seasonal encoding and a stabilized recursive forecasting mechanism to maintain prediction accuracy within a 293-day horizon. The model's efficacy is demonstrated using data from 2020 to 2023 to predict daily average temperatures in New York City, showing significant improvements over traditional SARIMA models.",3.31,88.905,294,cold_start,Phi-4,Apple_M1(Metal)
2601.07953v1_Quantum automated theorem proving.pdf,Quantum Automated Theorem Proving,"Zheng-Zhi Sun, Qi Ye, Dong-Ling Deng",,,"Quantum Computing, Automated Theorem Proving, Quantum Superposition, Quantum Entanglement, Quantum Resolution, Quantum Algebraic Proving, Geometric Theorems, Artificial Intelligence, Formal Verification, Mathematical Reasoning","Automated theorem proving, or automated reasoning, aims to use computer programs to automatically prove or disprove mathematical theorems and logical statements. This paper proposes a framework for quantum automated theorem proving, leveraging quantum superposition and entanglement to potentially enhance theorem-proving capabilities. The authors introduce quantum representations of knowledge bases and reasoning algorithms for tasks in propositional and first-order logic, achieving automated reasoning with quadratically reduced query complexity. Additionally, a quantum algebraic proving method for geometric theorems is proposed, extending Wu’s algebraic approach beyond classical settings. Examples include geometry problems from the International Mathematical Olympiad, demonstrating how quantum computers can prove geometric theorems with improved query complexity. The results suggest a foundational approach for developing quantum automatic theorem provers, crucial for both near-term and future quantum technologies.",3.21,93.992,302,cold_start,Phi-4,Apple_M1(Metal)
2601.07957v1_LWMSCNN-SE A Lightweight Multi-Scale Network for E.pdf,LWMSCNN-SE: A Lightweight Multi-Scale Network for Efficient Maize Disease Classification on Edge Devices,"Fikadu Weloday, Jianmei Su",,,"lightweight CNN, multi-scale feature extraction, attention mechanism, plant pathology","Maize disease classification is crucial for mitigating yield losses and ensuring food security. Traditional disease detection models face challenges in resource-constrained environments due to high computational costs. This paper proposes LWMSCNN-SE, a lightweight convolutional neural network that integrates multi-scale feature extraction, depthwise separable convolutions, and squeeze-and-Excitation (SE) attention mechanisms. The model achieves 96.63% classification accuracy with only 241,348 parameters and 0.666 GFLOPs, making it suitable for real-time deployment in field applications. This approach addresses the accuracy-efficiency trade-off, demonstrating potential for efficient maize disease diagnosis on edge devices in precision farming systems.",3.07,77.602,238,cold_start,Phi-4,Apple_M1(Metal)
2601.07958v1_LJ-Spoof A Generatively Varied Corpus for Audio An.pdf,LJ-SPOOF: A GENERATIVELY VARIED CORPUS FOR AUDIO ANTI-SPOOFING AND SYNTHESIS SOURCE TRACING,"Surya Subramani, Hashim Ali, Hafiz Malik",,,"Anti-Spoofing, Speaker Verification, Deepfake, Source tracing, Synthetic Speech","Speaker-specific anti-spoofing and synthesis-source tracing are central challenges in audio anti-spoofing. Progress has been hampered by the lack of datasets that systematically vary model architectures, synthesis pipelines, and generative parameters. To address this gap, we introduce LJ-Spoof, a speaker-specific, generatively diverse corpus that systematically varies prosody, vocoders, generative hyperparameters, bona fide prompt sources, training regimes, and neural post-processing. The corpus spans one speaker-including studio-quality recordings-30 TTS families, 500 generatively variant subsets, 10 bona fide neural-processing variants, and more than 3 million utterances. This variation-dense design enables robust speaker-conditioned anti-spoofing and fine-grained synthesis-source tracing. We further position this dataset as both a practical reference training resource and a benchmark evaluation suite for anti-spoofing and source tracing.",3.14,92.905,292,cold_start,Phi-4,Apple_M1(Metal)
2601.07964v1_Executable Ontologies in Game Development From Alg.pdf,Executable Ontologies in Game Development: From Algorithmic Control to Semantic World Modeling,Alexander Boldachev,,,"executable ontologies, game AI, behavior trees, GOAP, event semantics, dataflow architecture, semantic modeling","This paper examines the application of Executable Ontologies (EO), implemented through the boldsea framework, to game development. It argues that EO represents a paradigm shift from algorithmic behavior programming to semantic world modeling, where agent behavior emerges naturally from declarative domain rules rather than being explicitly coded. Using a survival game scenario (Winter Feast), the paper demonstrates how EO achieves priority-based task interruption through dataflow conditions rather than explicit preemption logic. Comparison with Behavior Trees (BT) and Goal-Oriented Action Planning (GOAP) reveals that while these approaches model what agents should do, EO models when actions become possible—a fundamental difference that addresses the semantic-process gap in game AI architecture. The paper discusses integration strategies, debugging advantages inherent to temporal event graphs, and the potential for LLM-driven runtime model generation.",3.47,75.009,260,cold_start,Phi-4,Apple_M1(Metal)
2601.07965v1_When Models Know When They Do Not Know Calibration.pdf,"WHEN MODELS KNOW WHEN THEY DO NOT KNOW: CALIBRATION, CASCADING, AND CLEANING","Chenjie Hao, Weyl Lu, Yuko Ishiwaka, Zengyi Li, Weier Wan, Yubei Chen",,,"model calibration, confidence, model cascading, data cleaning, vision models, language models","This work explores how models can recognize when they do not know, enabling new possibilities such as model calibration, cascading, and data cleaning. The authors propose a training-free method applicable to both vision and language models. They highlight empirical observations that higher confidence correlates with higher accuracy and that calibration on validation sets remains effective on test sets. Two applications are introduced: model cascading with calibrated advantage routing and data cleaning using model ensembles. The results demonstrate improved efficiency, reliability, and trustworthiness in AI systems.",3.02,77.771,235,cold_start,Phi-4,Apple_M1(Metal)
2601.07969v1_Tuberculosis Screening from Cough Audio Baseline M.pdf,"TUBERCULOSIS SCREENING FROM COUGH AUDIO: BASELINE MODELS, CLINICAL VARIABLES, AND UNCERTAINTY QUANTIFICATION","George P. Kafentzis, Efstratios Selisios",,2601.07969v1,"Tuberculosis, Machine Learning, Cough Audio, Cross-Validation, Uncertainty Quantification, Feature Extraction","In this paper, we propose a standardized framework for automatic tuberculosis (TB) detection from cough audio and routinely collected clinical data using machine learning. While TB screening from audio has attracted growing interest, progress is difficult to measure because existing studies vary substantially in datasets, cohort definitions, feature representations, model families, validation protocols, and reported metrics. Consequently, reported gains are often not directly comparable, and it remains unclear whether improvements stem from modeling advances or from differences in data and evaluation. We address this gap by establishing a strong, well-documented baseline for TB prediction using cough recordings and accompanying clinical metadata from a recently compiled dataset from several countries. Our pipeline is reproducible end-to-end, covering feature extraction, multimodal fusion, cougher-independent evaluation, and uncertainty quantification, and it reports a consistent suite of clinically relevant metrics to enable fair comparison. We further quantify performance for cough audio-only and fused (audio + clinical metadata) models, and release the full experimental protocol to facilitate benchmarking. This baseline is intended to serve as a common reference point and to reduce methodological variance that currently holds back progress in the field.",3.45,104.111,359,cold_start,Phi-4,Apple_M1(Metal)
2601.07973v1_Cultural Compass A Framework for Organizing Societ.pdf,Cultural Compass: A Framework for Organizing Societal Norms to Detect Violations in Human-AI Conversations,"Myra Cheng, Vinodkumar Prabhakaran, Alice Oh, Hayk Stepanyan, Aishwarya Verma, Charu Kalia, Erin MacMurray van Liemt, Sunipa Dev",,arXiv:2601.07973v1,"Generative AI, Sociocultural norms, Natural Language Processing, Cultural alignment, Human-AI interaction, Norm adherence","Generative AI models need to be useful and safe across cross-cultural contexts, which requires understanding how they adhere to sociocultural norms. Existing work lacks nuance and coverage in evaluating models' norm adherence. This paper introduces a taxonomy of norms, clarifying contexts, specifications, and mechanisms, and demonstrates how it can be used to evaluate models' norm adherence in naturalistic settings. The analysis shows that state-of-the-art models frequently violate norms, with variation by model, context, and country. The proposed taxonomy and evaluation pipeline enable nuanced, context-sensitive evaluation of cultural norm adherence.",3.14,92.969,292,cold_start,Phi-4,Apple_M1(Metal)
2601.07988v1_From Word Sequences to Behavioral Sequences Adapti.pdf,From Word Sequences to Behavioral Sequences: Adapting Modeling and Evaluation Paradigms for Longitudinal NLP,"Adithya V Ganesan, Vasudha Varadarajan, Oscar NE Kjell, Whitney R Ringwald, Scott Feltman, Benjamin J Luft, Roman Kotov, Ryan L Boyd, H Andrew Schwartz",,,"NLP, longitudinal studies, behavioral sequences, evaluation paradigms, PTSD, daily diary transcripts","This paper addresses the limitations of traditional NLP approaches when applied to longitudinal data, where documents are nested within authors and ordered in time. The authors propose a new modeling and evaluation paradigm that updates four parts of the NLP pipeline: evaluation splits, accuracy metrics, sequence inputs, and model internals. They demonstrate the issues with traditional methods using a dataset of 17k daily diary transcripts paired with PTSD symptom severity from 238 participants, showing that traditional document-level evaluation can lead to misleading conclusions. The paper advocates for a shift from word-sequence evaluation to behavior-sequence paradigms in NLP.",3.21,89.922,289,cold_start,Phi-4,Apple_M1(Metal)
2601.07994v2_DYCP Dynamic Context Pruning for Long-Form Dialogu.pdf,DYCP: Dynamic Context Pruning for Long-Form Dialogue with LLMs,"Nayoung Choi, Jonathan Zhang, Jinho D. Choi",,,"Large Language Models, context management, dialogue systems, context pruning, long-form dialogue, response latency, answer quality, memory retrieval","Large Language Models (LLMs) often exhibit increased response latency and degraded answer quality as dialogue length grows, making effective context management essential. Existing methods rely on extra LLM calls to build memory or perform offline memory construction without considering the current user utterance, which can introduce inefficiencies or disrupt conversational continuity. This paper introduces DYCP, a lightweight context management method that dynamically segments and retrieves relevant memory at query time. It preserves the sequential structure of dialogue without predefined topic boundaries and supports efficient, adaptive context retrieval. Across three long-form dialogue benchmarks—LoCoMo, MT-Bench+, and SCM4LLMs—and multiple LLMs, DyCP consistently improves answer quality while reducing response latency. The paper also examines the gap between modern LLMs’ expanded context windows and their actual long-context processing capacity, highlighting the continued importance of effective context management.",3.23,90.197,291,cold_start,Phi-4,Apple_M1(Metal)
2601.08000v1_Reasoning over Precedents Alongside Statutes Case-.pdf,Reasoning over Precedents Alongside Statutes: Case-Augmented Deliberative Alignment for LLM Safety,"Can Jin, Rui Wu, Tong Che, Qixin Zhang, Hongwu Peng, Jiahui Zhao, Zhenting Wang, Wenqi Wei, Ligong Han, Zhao Zhang, Yuan Cao, Ruixiang Tang, Dimitris N. Metaxas",,,"Large Language Models, safety, deliberative alignment, case-augmented reasoning, reinforcement learning, LLM safety","Ensuring that Large Language Models (LLMs) adhere to safety principles without refusing benign requests remains a significant challenge. This work evaluates the impact of specifying extensive safety codes versus demonstrating them through illustrative cases. It finds that training on case-augmented simple codes yields more robust and generalized safety behaviors. The proposed CADA method enhances harmlessness, improves robustness against attacks, and reduces over-refusal while preserving utility across diverse benchmarks, offering a practical alternative to rule-only deliberative alignment for improving safety while maintaining helpfulness.",3.01,96.861,292,cold_start,Phi-4,Apple_M1(Metal)
2601.08003v1_LLM Review Enhancing Creative Writing via Blind Pe.pdf,LLM Review: Enhancing Creative Writing via Blind Peer Review Feedback,"Weiyue Li, Mingxiao Song, Zhenda Shen, Dachuan Zhao, Yunfan Long, Yi Li, Yongce Li, Ruyi Yang, Mengyu Wang",,,"Large Language Models, creative generation, multi-agent frameworks, peer review, Blind Peer Review, SciFi-100 dataset, novelty metrics, creativity, information flow constraints","Large Language Models (LLMs) often struggle with creative generation, and multi-agent frameworks that improve reasoning through interaction can paradoxically hinder creativity by inducing content homogenization. This paper introduces LLM Review, a peer-review-inspired framework implementing Blind Peer Review: agents exchange targeted feedback while revising independently, preserving divergent creative trajectories. The paper proposes SciFi-100, a science fiction writing dataset with a unified framework combining LLM-as-a-judge scoring, human annotation, and rule-based novelty metrics. Experiments demonstrate that LLM Review consistently outperforms multi-agent baselines, and smaller models with this framework can surpass larger single-agent models, suggesting interaction structure may substitute for model scale.",3.28,93.852,308,cold_start,Phi-4,Apple_M1(Metal)
2601.08005v1_Internal Deployment Gaps in AI Regulation.pdf,Internal Deployment Gaps in AI Regulation,"JOE KWON, STEPHEN CASPER",,,"AI regulation, internal deployment, regulatory gaps, AI systems, EU AI Act, General-Purpose AI Code of Practice","This paper explores how frontier AI regulations in the United States and European Union in 2025 address internal deployment of AI systems. It identifies three gaps that could allow internally-deployed systems to evade oversight: scope ambiguity, point-in-time compliance assessments, and information asymmetries. The paper analyzes the persistence of these gaps due to tensions around measurability, incentives, and information access, and suggests potential approaches to address them. The study aims to inform deliberate policy choices for internally deployed AI systems.",3.01,60.876,183,cold_start,Phi-4,Apple_M1(Metal)
2601.08011v1_TP-Blend Textual-Prompt Attention Pairing for Prec.pdf,TP-Blend: Textual-Prompt Attention Pairing for Precise Object-Style Blending in Diffusion Models,"Xin Jin, Yichuan Zhong, Yapeng Tian",,arXiv:2601.08011v1,"text-conditioned diffusion editors, object replacement, style introduction, attention processors, optimal transport problem, self-attention, image editing, diffusion models, object blending, morphological transitions","Current text-conditioned diffusion editors handle single object replacement well but struggle when a new object and a new style must be introduced simultaneously. We present Twin-PromptAttention Blend(TP-Blend), a lightweight, training-free framework that receives two separate textual prompts, one specifying a blend object and the other defining a target style, and injects both into a single denoising trajectory. TP-Blend is driven by two complementary attention processors. Cross-Attention Object Fusion (CAOF) first averages head-wise attention to locate spatial tokens that respond strongly to either prompt, then solves an entropy-regularised optimal transport problem that reassigns complete multi-head feature vectors to those positions. CAOF updates feature vectors at the full combined dimensionality of all heads (e.g., 640 dimensions in SD-XL), preserving rich cross-head correlations while keeping memory low. Self-Attention Style Fusion (SASF) injects style at every self-attention layer through Detail-Sensitive Instance Normalization. A lightweight one-dimensional Gaussian filter separates low- and high-frequency components; only the high-frequency residual is blended back, imprinting brush-stroke-level texture without disrupting global geometry. SASF further swaps the Key and Value matrices with those derived from the style prompt, enforcing context-aware texture modulation that remains independent of object fusion. Extensive experiments show that TP-Blend produces high-resolution, photo-realistic edits with precise control over both content and appearance, surpassing recent baselines in quantitative fidelity, perceptual quality, and inference speed.",3.63,125.591,456,cold_start,Phi-4,Apple_M1(Metal)
2601.08017v1_Representations of Text and Images Align From Laye.pdf,Representations of Text and Images Align From Layer One,"Evˇzen Wybitul, Javier Rando, Florian Tram`er, Stanislav Fort",,arXiv:2601.08017v1,"vision-language models, adapter-based models, image-text alignment, DeepDream, model interpretability","This paper demonstrates that in adapter-based vision-language models, the representations of images and their text descriptions are aligned from the very first layer, challenging the established view that such alignment only appears in late layers. The authors introduce a synthesis-based method inspired by DeepDream to show this alignment. By extracting a concept vector for a given textual concept and synthesizing an image whose representation aligns with that vector, they find that even at layer 1, a significant portion of images depict recognizable features of the targeted textual concepts. This method provides direct evidence of image-text alignment on a concept-by-concept and layer-by-layer basis, offering a new path towards model interpretability.",3.36,75.803,255,cold_start,Phi-4,Apple_M1(Metal)
2601.08026v2_FigEx2 Visual-Conditioned Panel Detection and Capt.pdf,FigEx2: Visual-Conditioned Panel Detection and Captioning for Scientific Compound Figures,"Jifeng Song, Arun Das, Pan Wang, Hui Ji, Kun Zhao, Yufei Huang",,,"scientific compound figures, panel detection, captioning, visual-conditioned framework, noise-aware gated fusion module, reinforcement learning, CLIP-based alignment, BERTScore-based semantic rewards, BioSci-Fig-Cap benchmark, zero-shot transferability","Scientific compound figures combine multiple labeled panels into a single image, but captions in real pipelines are often missing or only provide figure-level summaries, making panel-level understanding difficult. This paper proposes FigEx2, a visual-conditioned framework that localizes panels and generates panel-wise captions directly from the compound figure. To address diverse phrasing in open-ended captioning, a noise-aware gated fusion module is introduced to filter token-level features and stabilize the detection query space. A staged optimization strategy combining supervised learning with reinforcement learning (RL) is employed, utilizing CLIP-based alignment and BERTScore-based semantic rewards to enforce strict multimodal consistency. To support high-quality supervision, the BioSci-Fig-Cap benchmark for panel-level grounding is curated, alongside cross-disciplinary test suites in physics and chemistry. Experimental results show that FigEx2 achieves a superior 0.726 mAP@0.5:0.95 for detection and significantly outperforms Qwen3-VL-8B by 0.51 in METEOR and 0.24 in BERTScore. Notably, FigEx2 exhibits remarkable zero-shot transferability to out-of-distribution scientific domains without any fine-tuning.",3.41,110.239,376,cold_start,Phi-4,Apple_M1(Metal)
2601.08043v1_The Role of Noisy Data in Improving CNN Robustness.pdf,The Role of Noisy Data in Improving CNN Robustness for Image Classification,"Oscar H. Ramírez-Agudelo, Nicoleta Gorea, Aliza Reif, Lorenzo Bonasera, Michael Karla",,,"deep learning, CNNs, data quality, CIFAR-10, noise injection, image classification, model robustness","Data quality is crucial for the performance and robustness of convolutional neural networks (CNNs) in image classification. This paper explores the impact of introducing controlled noise into training data to enhance model robustness. Using the CIFAR-10 dataset and a Resnet-18 model, the study evaluates the effects of Gaussian noise, Salt-and-Pepper noise, and Gaussian blur at various intensities. Results indicate that incorporating 10% noisy data during training significantly reduces test loss and improves accuracy under fully corrupted test conditions, with minimal impact on clean-data performance. These findings suggest that strategic noise exposure can serve as an effective regularizer, balancing traditional data cleanliness with real-world resilience.",3.33,82.27,274,cold_start,Phi-4,Apple_M1(Metal)
2601.08049v1_Integrating Attendance Tracking and Emotion Detect.pdf,Integrating Attendance Tracking and Emotion Detection for Enhanced Student Engagement in Smart Classrooms,"Keith Ainebyona, Ann Move Oguti, Joseph Walusimbi, Ritah Kobusingye",,,"Affective computing, Attendance automation, Emotion detection, IoT, Smart classroom","The increasing adoption of smart classroom technologies in higher education has mainly focused on automating attendance, with limited attention given to students' emotional and cognitive engagement during lectures. This paper presents SCASED (Smart Classroom Attendance System with Emotion Detection), an IoT-based system that integrates automated attendance tracking with facial emotion recognition to support classroom engagement monitoring. The system uses a Raspberry Pi camera and OpenCV for face detection, and a fine-tuned MobileNetV2 model to classify four learning-related emotional states: engagement, boredom, confusion, and frustration. A session-based mechanism is implemented to manage attendance and emotion monitoring by recording attendance once per session and performing continuous emotion analysis thereafter. Attendance and emotion data are visualized through a cloud-based dashboard to provide instructors with insights into classroom dynamics. Experimental evaluation using the DAiSEE dataset achieved an emotion classification accuracy of 89.5%. The results show that integrating attendance data with emotion analytics can provide instructors with additional insight into classroom dynamics and support more responsive teaching practices.",3.69,79.071,292,cold_start,Phi-4,Apple_M1(Metal)
2601.08052v1_Forecast Aware Deep Reinforcement Learning for Eff.pdf,Forecast Aware Deep Reinforcement Learning for Efficient Electricity Load Scheduling in Dairy Farms,"Nawazish Ali, Rachael Shaw, Karl Mason",,2601.08052v1,cs.AI,"Dairy farming is an energy intensive sector that relies heavily on grid electricity. With increasing renewable energy integration, sustainable energy management has become essential for reducing grid dependence and supporting the United Nations Sustainable Development Goal 7 on affordable and clean energy. However, the intermittent nature of renewables poses challenges in balancing supply and demand in real time. Intelligent load scheduling is therefore crucial to minimize operational costs while maintaining reliability. Reinforcement Learning has shown promise in improving energy efficiency and reducing costs; however, most RL-based scheduling methods assume complete knowledge of future prices or generation, which is unrealistic in dynamic environments. Moreover, standard PPO variants rely on fixed clipping or KL-divergence thresholds, often leading to unstable training under variable tariffs. To address these challenges, this study proposes a Deep Reinforcement Learning framework for efficient load scheduling in dairy farms, focusing on battery storage and water heating under realistic operational constraints. The proposed Forecast-Aware PPO incorporates short-term forecasts of demand and renewable generation using hour-of-day and month-based residual calibration, while the PID-KL PPO variant employs a proportional–integral–derivative controller to regulate KL-divergence for stable policy updates adaptively. Trained on real-world dairy farm data, the method achieves up to 1% lower electricity cost than PPO, 4.8% than DQN, and 1.5% than SAC. For battery scheduling, PPO reduces grid imports by 13.1%, demonstrating scalability and effectiveness for sustainable energy management in modern dairy farming.",3.88,100.419,390,cold_start,Phi-4,Apple_M1(Metal)
2601.08058v1_Reasoning Beyond Chain-of-Thought A Latent Computa.pdf,Reasoning Beyond Chain-of-Thought: A Latent Computational Mode in Large Language Models,"Zhenghao He, Guangzhi Xiong, Bohan Liu, Sanchit Sinha, Aidong Zhang",,,"Chain-of-Thought, Large Language Models, Sparse Autoencoders, Latent Features, Reasoning, Latent Steering","Chain-of-Thought (CoT) prompting has improved the reasoning performance of large language models (LLMs), but it remains unclear why it works and whether it is the unique mechanism for triggering reasoning in LLMs. This study analyzes and intervenes on the internal representations of LLMs with Sparse Autoencoders (SAEs), identifying a small set of latent features causally associated with LLM reasoning behavior. Across multiple model families and reasoning benchmarks, steering a single reasoning-related latent feature can substantially improve accuracy without explicit CoT prompting. For large models, latent steering achieves performance comparable to standard CoT prompting while producing more efficient outputs. The reasoning-oriented internal state is triggered early in generation and can override prompt-level instructions that discourage explicit reasoning. The results suggest that multi-step reasoning in LLMs is supported by latent internal activations that can be externally activated, with CoT prompting being one effective, but not unique, way of activating this mechanism.",3.31,90.083,298,cold_start,Phi-4,Apple_M1(Metal)
2601.08065v1_A New Strategy for Verifying Reach-Avoid Specifica.pdf,A New Strategy for Verifying Reach-Avoid Specifications in Neural Feedback Systems,"Samuel I. Akinwande, Sydney M. Katz, Mykel J. Kochenderfer, Clark Barrett",,2601.08065v1,"neural feedback systems, reachability analysis, forward reachability, backward reachability, verification framework","Forward reachability analysis is the predominant approach for verifying reach-avoid properties in neural feedback systems—dynamical systems controlled by neural networks. This dominance stems from the limited scalability of existing backward reachability methods. In this work, we introduce new algorithms that compute both over- and under-approximations of backward reachable sets for such systems. We further integrate these backward algorithms with established forward analysis techniques to yield a unified verification framework for neural feedback systems. Neural feedback systems are increasingly prevalent in applications such as robotics, autonomous driving, and aerospace autonomy. Ensuring compliance with safety and design specifications is critical. Common approaches for verifying specification satisfaction include sampling, invariance analysis, and reachability analysis. Sampling is scalable but cannot provide formal guarantees. Invariance analysis offers formal guarantees but is difficult to implement in practice. Reachability analysis provides formal guarantees but suffers from a trade-off between precision and scalability. Most existing methods for reachability analysis of neural feedback systems rely on forward analysis, which propagates the system dynamics forward to compute all possible states. This reliance arises because computing a backward pass through a neural network is particularly challenging. However, the exclusive use of forward analysis often amplifies the inherent limitations of reachability analysis.",3.75,98.386,369,cold_start,Phi-4,Apple_M1(Metal)
2601.08070v1_Semantic Gravity Wells Why Negative Constraints Ba.pdf,Semantic Gravity Wells: Why Negative Constraints Backfire,Shailesh Rana,,,"negative constraints, language models, instruction-following, semantic pressure, mechanistic analysis","This paper investigates the failure of negative constraints in language models, where instructions to avoid certain words often lead to their use. The study introduces 'semantic pressure' to quantify the likelihood of generating forbidden tokens and finds a logistic relationship between violation probability and pressure. Through layer-wise analysis, it identifies two failure modes: priming failure, where mentioning the forbidden word activates it, and override failure, where late-layer networks counteract suppression signals. The findings highlight a fundamental tension in negative constraint design, where naming a forbidden word paradoxically increases its likelihood of being used.",2.95,62.019,183,cold_start,Phi-4,Apple_M1(Metal)
2601.08079v1_MemoBrain Executive Memory as an Agentic Brain for.pdf,MemoBrain: Executive Memory as an Agentic Brain for Reasoning,"Hongjin Qian, Zhao Cao, Zheng Liu",,,"executive memory, tool-augmented agents, large language models, long-horizon reasoning, memory mechanisms, GAIA, Web-Walker, BrowseComp-Plus","Complex reasoning in tool-augmented agent frameworks is inherently long-horizon, causing reasoning traces and transient tool artifacts to accumulate and strain the bounded working context of large language models. Without explicit memory mechanisms, such accumulation disrupts logical continuity and undermines task alignment. This positions memory as a core component for sustaining coherent, goal-directed reasoning over long horizons. MemoBrain, an executive memory model for tool-augmented agents, constructs a dependency-aware memory over reasoning steps, capturing salient intermediate states and their logical relations. Operating as a co-pilot alongside the reasoning agent, MemoBrain organizes reasoning progress without blocking execution and actively manages the working context. It prunes invalid steps, folds completed sub-trajectories, and preserves a compact, high-salience reasoning backbone under a fixed context budget. These mechanisms enable explicit cognitive control over reasoning trajectories rather than passive context accumulation. MemoBrain is evaluated on challenging long-horizon benchmarks, demonstrating consistent improvements over strong baselines.",3.38,94.147,318,cold_start,Phi-4,Apple_M1(Metal)
2601.08089v1_Q-realign Piggybacking Realignment on Quantization.pdf,Q-realign: Piggybacking Realignment on Quantization for Safe and Efficient LLM Deployment,"Qitao Tan, Xiaoying Song, Ningxi Cheng, Ninghao Liu, Xiaoming Zhai, Lingzi Hong, Yanzhi Wang, Zhen Xiang, Geng Yuan",,,"Large Language Models, Safety Alignment, Fine-tuning, Quantization, Post-hoc Defense, Deployment","Public large language models (LLMs) are typically safety-aligned during pretraining, but task-specific fine-tuning often erodes this alignment, introducing safety risks. Existing defenses either embed safety recovery into fine-tuning or rely on fine-tuning-derived priors for post-hoc correction, leading to high computational overhead and complex workflows. This paper proposes Q-realign, a post-hoc defense method based on post-training quantization, guided by an analysis of representational structure. By reframing quantization as a dual-objective procedure for compression and safety, Q-realign decouples safety alignment from fine-tuning and integrates naturally into modern deployment pipelines. Experiments show that Q-realign substantially reduces unsafe behaviors while preserving task performance, with significant reductions in memory usage and GPU hours. The method can recover the safety alignment of a fine-tuned 7B LLM on a single RTX 4090 within 40 minutes, providing a practical, turnkey solution for safety-aware deployment.",3.36,105.702,355,cold_start,Phi-4,Apple_M1(Metal)
2601.08094v1_Local-Global Feature Fusion for Subject-Independen.pdf,Local-Global Feature Fusion for Subject-Independent EEG Emotion Recognition,"Zheng Zhou, Isabella McEvoy, Camilo E. Valderrama",,,"EEG Emotion Recognition, Subject-Independent, Feature Fusion, Local Descriptors, Global Descriptors, Cross-Subject Generalization, Transformer, Domain-Adversarial Regularization","Subject-independent EEG emotion recognition faces challenges due to inter-subject variability and the difficulty of learning robust representations from short, noisy recordings. This paper proposes a fusion framework that integrates local, channel-wise descriptors and global, trial-level descriptors to improve cross-subject generalization on the SEED-VII dataset. Local representations are formed per channel by concatenating differential entropy with graph-theoretic features, while global representations summarize time-domain, spectral, and complexity characteristics at the trial level. These representations are fused in a dual-branch transformer with attention-based fusion and domain-adversarial regularization, with samples filtered by an intensity threshold. Experiments under a leave-one-subject-out protocol demonstrate that the proposed method consistently outperforms single-view and classical baselines, achieving approximately 40% mean accuracy in 7-class subject-independent emotion recognition.",3.44,85.98,296,cold_start,Phi-4,Apple_M1(Metal)
2601.08104v1_High-Fidelity Modeling of Stochastic Chemical Dyna.pdf,HIGH-FIDELITY MODELING OF STOCHASTIC CHEMICAL DYNAMICS ON COMPLEX MANIFOLDS: A MULTI-SCALE SIREN-PINN FRAMEWORK FOR THE CURVATURE-PERTURBED GINZBURG-LANDAU EQUATION,"Julian Evan Chrisnanto, Salsabila Rahma Alia, Nurfauzi Fadillah, Yulison Herry Chrisnanto",,2601.08104v1,"Physics-Informed Neural Networks (PINNs), Spatiotemporal Chaos, Inverse Geometric Problems, Reaction-Diffusion Systems, Defect Turbulence, Riemann Manifold Learning","The accurate identification and control of spatiotemporal chaos in reaction-diffusion systems remains a grand challenge in chemical engineering, particularly when the underlying catalytic surface possesses complex, unknown topography. In the Defect Turbulence regime, system dynamics are governed by topological phase singularities (spiral waves) whose motion couples to manifold curvature via geometric pinning. Conventional Physics-Informed Neural Networks (PINNs) using ReLU or Tanh activations suffer from fundamental spectral bias, failing to resolve high-frequency gradients and causing amplitude collapse or phase drift. We propose a Multi-Scale SIREN-PINN architecture leveraging periodic sinusoidal activations with frequency-diverse initialization, embedding the appropriate inductive bias for wave-like physics directly into the network structure. This enables simultaneous resolution of macroscopic wave envelopes and microscopic defect cores. Validated on the complex Ginzburg-Landau equation evolving on latent Riemannian manifolds, our architecture achieves relative state prediction error ϵL2 ≈1.92×10 −2, outperforming standard baselines by an order of magnitude while preserving topological invariants ( |∆Ndef ects|<1 ). We solve the ill-posed inverse pinning problem, reconstructing hidden Gaussian curvature fields solely from partial observations of chaotic wave dynamics (Pearson correlation ρ= 0.965 ). Training dynamics reveal a distinctive Spectral Phase Transition at epoch ∼2,100 , where cooperative minimization of physics and geometry losses drives the solver to Pareto-optimal solutions. This work establishes a new paradigm for Geometric Catalyst Design, offering a mesh-free, data-driven tool for identifying surface heterogeneity and engineering passive control strategies in turbulent chemical reactors.",3.75,146.469,549,cold_start,Phi-4,Apple_M1(Metal)
2601.08107v1_STO-RL Offline RL under Sparse Rewards via LLM-Gui.pdf,STO-RL: Offline RL under Sparse Rewards via LLM-Guided Subgoal Temporal Order,"Chengyang Gu, Yuxin Pan, Hui Xiong, Yize Chen",https://doi.org/10.1145/nnnnnnn.nnnnnnn,,"Offline RL, Temporal order, Large Language Models","Offline reinforcement learning (RL) enables policy learning from pre-collected datasets, avoiding costly and risky online interactions, but it often struggles with long-horizon tasks involving sparse rewards. Existing goal-conditioned and hierarchical offline RL methods decompose such tasks and generate intermediate rewards to mitigate limitations of traditional offline RL, but usually overlook temporal dependencies among subgoals and rely on imprecise reward shaping, leading to suboptimal policies. To address these issues, we propose STO-RL (Offline RL using LLM-Guided Subgoal Temporal Order), an offline RL framework that leverages large language models (LLMs) to generate temporally ordered subgoal sequences and corresponding state-to-subgoal-stage mappings. Using this temporal structure, STO-RL applies potential-based reward shaping to transform sparse terminal rewards into dense, temporally consistent signals, promoting subgoal progress while avoiding suboptimal solutions. The resulting augmented dataset with shaped rewards enables efficient offline training of high-performing policies. Evaluations on four discrete and continuous sparse-reward benchmarks demonstrate that STO-RL consistently outperforms state-of-the-art offline goal-conditioned and hierarchical RL baselines, achieving faster convergence, higher success rates, and shorter trajectories. Ablation studies further confirm STO-RL’s robustness to imperfect or noisy LLM-generated subgoal sequences, demonstrating that LLM-guided subgoal temporal structures combined with theoretically grounded reward shaping provide a practical and scalable solution for long-horizon offline RL.",3.57,117.895,421,cold_start,Phi-4,Apple_M1(Metal)
2601.08108v1_Debiasing Large Language Models via Adaptive Causa.pdf,Debiasing Large Language Models via Adaptive Causal Prompting with Sketch-of-Thought,"Bowen Li, Ziqi Xu, Jing Ren, Renqiang Luo, Xikun Zhang, Xiuzhen Zhang, Yongli Ren, Feng Xia",,,"Large Language Models, Adaptive Causal Prompting, Sketch-of-Thought, Chain-of-Thought, Causal Inference, Bias Mitigation","This paper introduces an Adaptive Causal Prompting with Sketch-of-Thought (ACPS) framework to address the limitations of existing prompting methods for Large Language Models (LLMs), such as excessive token usage and limited generalisability. ACPS leverages structural causal models to infer the causal effect of a query on its answer and adaptively select appropriate interventions. This approach enables generalisable causal reasoning across diverse tasks without task-specific retraining. By replacing verbose Chain-of-Thought with concise Sketch-of-Thought, ACPS significantly reduces token usage and inference cost. Extensive experiments demonstrate that ACPS outperforms existing prompting baselines in accuracy, robustness, and computational efficiency.",3.16,82.02,259,cold_start,Phi-4,Apple_M1(Metal)
2601.08109v1_CSQL Mapping Documents into Causal Databases.pdf,Csql: Mapping Documents into Causal Databases,Sridhar Mahadevan,,2601.08109v1,"Causality, Natural Language, Databases, SQL, AI, Machine Learning","We describe a novel system, Csql, that automatically converts a collection of unstructured text documents into an SQL-queryable causal database (CDB). A CDB differs from a traditional DB: it is designed to answer 'why' questions via causal interventions and structured causal queries. Csql builds on our earlier system, Democritus, which converts documents into thousands of local causal models derived from causal discourse. Unlike RAG-based systems or knowledge-graph–centric approaches, Csql supports causal analysis over document collections rather than purely associative retrieval. For example, given an article on the origins of human bipedal walking, Csql enables queries such as: 'What are the strongest causal influences on bipedalism?' or 'Which variables act as causal hubs with the largest downstream influence?' Beyond single-document case studies, we show that Csql can also ingest RAG/IE-compiled causal corpora at scale by compiling the Testing Causal Claims (TCC) dataset of economics papers into a causal database containing 265,656 claim instances spanning 45,319 papers, 44 years, and 1,575 reported method strings, thereby enabling corpus-level causal queries and longitudinal analyses in SQL. Conceptually, Csql converts document collections into causally grounded relational databases, enabling causal analysis via standard SQL. In contrast to prior work that relies on hand-designed ontologies, fixed schemas, or domain-specific information extraction pipelines, Csql induces its schema directly from language (or from language-compiled causal artifacts). Viewed abstractly, Csql functions as a compiler from unstructured documents into a causal database equipped with a principled algebra of queries, and can be applied broadly across many domains ranging from business, economics, humanities, and science.",3.73,119.926,447,cold_start,Phi-4,Apple_M1(Metal)
2601.08118v1_MirrorBench An Extensible Framework to Evaluate Us.pdf,MIRRORBENCH: AN EXTENSIBLE FRAMEWORK TO EVALUATE USER-PROXY AGENTS FOR HUMAN-LIKENESS,"Ashutosh Hathidara, Julien Yu, Vaishali Senthil, Sebastian Schreiber, Anil Babu Ankisettipalli",,,"large language models, user simulators, dialogue systems, evaluation frameworks, human-like interactions","MIRRORBENCH is a reproducible, extensible benchmarking framework designed to evaluate user proxy agents based on their ability to produce human-like user utterances across diverse conversational tasks. The framework decouples evaluation from downstream task success and features a modular execution engine with typed interfaces, metadata-driven registries, multi-backend support, caching, and robust observability. It supports pluggable user proxies, datasets, tasks, and metrics, allowing researchers to evaluate simulators under a uniform, variance-aware harness. The framework includes lexical-diversity metrics (MATTR, YULE’S K, and HD-D) and LLM-judge–based metrics (GTEVAL, PAIRWISE INDISTINGUISHABILITY, and RUBRIC-AND-REASON). Results reveal systematic gaps between user proxies and real human users. The open-source framework is accessible via a command-line interface for running experiments, managing configurations, caching, and generating reports.",3.34,99.016,331,cold_start,Phi-4,Apple_M1(Metal)
2601.08125v1_How vehicles change lanes after encountering crash.pdf,How vehicles change lanes after encountering crashes: Empirical analysis and modeling,"Kequan Chen, Yuxuan Wang, Pan Liu, Victor L. Knoop, David Z. W. Wang, Yu Han",,,,,2.91,25.78,75,cold_start,Phi-4,Apple_M1(Metal)
2601.08127v1_PathoGen Diffusion-Based Synthesis of Realistic Le.pdf,PathoGen: Diffusion-Based Synthesis of Realistic Lesions in Histopathology Images,"Mohamad Koohi-Moghadam, Mohammad-Ali Nikouei Mahani, Kyongtae Tyler Bae",,,"histopathology, lesions, data augmentation, diffusion-based generative model, image synthesis, AI in medical diagnosis","The development of robust artificial intelligence models for histopathology diagnosis is severely constrained by the scarcity of expert-annotated lesion data, particularly for rare pathologies and underrepresented disease subtypes. PathoGen, a diffusion-based generative model, enables controllable, high-fidelity inpainting of lesions into benign histopathology images. It synthesizes lesions with natural tissue boundaries, preserved cellular structures, and authentic staining characteristics. Validated across kidney, skin, breast, and prostate pathology datasets, PathoGen outperforms state-of-the-art generative baselines in image fidelity and distributional similarity. Augmenting training sets with PathoGen-synthesized lesions enhances downstream segmentation performance, particularly in data-scarce regimes, and overcomes the manual annotation bottleneck, offering a scalable pathway for developing generalizable medical AI systems.",3.53,84.033,297,cold_start,Phi-4,Apple_M1(Metal)
2601.08128v1_Embedded AI Companion System on Edge Devices.pdf,Embedded AI Companion System on Edge Devices,"Rahul Gupta, Stephen Hsu",,2601.08128v1,"AI companion, edge devices, computational constraints, memory systems, low-latency, personalization, offline processing, privacy, cost reduction, internet connectivity","This paper addresses the challenge of developing an AI companion system on edge devices with limited computational resources. It proposes a memory paradigm that alternates between active and inactive phases to minimize latency and maintain personalization. The system uses lightweight retrieval during user activity and intensive memory maintenance during inactivity. An AI Companion benchmark is introduced to evaluate conversational quality and memory capabilities. Experiments show that the proposed system, using a quantized model, outperforms a raw LLM and is comparable to GPT-3.5 with a 16k context window. The paper emphasizes the benefits of running companion systems offline, including enhanced privacy, reduced costs, and functionality in areas with limited internet connectivity.",3.3,77.232,255,cold_start,Phi-4,Apple_M1(Metal)
2601.08133v1_How Do Optical Flow and Textual Prompts Collaborat.pdf,How Do Optical Flow and Textual Prompts Collaborate to Assist in Audio-Visual Semantic Segmentation?,"Peng Gao, Yujian Lee, Yongqi Xu, Wentao Fan",,,"Audio-visual semantic segmentation, optical flow, textual prompts, semantic understanding, audio-visual scenes, segmentation mask, temporal context, visual-textual alignment, cross-modal integration","Audio-visual semantic segmentation (AVSS) extends audio-visual segmentation (AVS) by requiring semantic understanding of audio-visual scenes. This paper introduces a novel collaborative framework, Stepping Stone Plus (SSP), which integrates optical flow and textual prompts to enhance segmentation. Optical flow captures motion dynamics, aiding in the segmentation of moving sound sources, while textual prompts help identify stationary sound-emitting objects. A visual-textual alignment module (VTA) is implemented for cross-modal integration, resulting in more coherent semantic interpretations. Experimental results show that SSP outperforms existing AVS methods, providing efficient and precise segmentation.",3.19,83.983,268,cold_start,Phi-4,Apple_M1(Metal)
2601.08139v1_Subspace Alignment for Vision-Language Model Test-.pdf,Subspace Alignment for Vision-Language Model Test-time Adaptation,"Zhichen Zeng, Wenxuan Bao, Xiao Lin, Ruizhong Qiu, Tianxin Wei, Xuying Ning, Yuchen Yan, Chen Luo, Monica Xiao Cheng, Jingrui He, Hanghang Tong",,,"Vision-Language Models, Test-time Adaptation, Distribution Shifts, Subspace Alignment, Zero-shot Predictions, Semantic Subspaces, Chordal Distance, Task-specific Semantics","Vision-language models (VLMs) exhibit remarkable zero-shot capabilities but are susceptible to performance degradation under distribution shifts. Test-time adaptation (TTA) is a strategy to adapt VLMs to unlabeled test data on the fly. Existing TTA methods often rely on unreliable zero-shot predictions as pseudo-labels, which can be problematic due to modality gaps and visual noise. This paper introduces SubTTA, a method that aligns the semantic subspaces of visual and textual modalities to enhance zero-shot predictions and guide the TTA process. SubTTA minimizes the chordal distance between visual and textual subspaces and projects visual features onto task-specific textual subspaces to filter out irrelevant noise. This approach refines decision boundaries and demonstrates an average improvement of 2.24% over state-of-the-art TTA methods across various benchmarks and VLM architectures.",3.39,104.477,354,cold_start,Phi-4,Apple_M1(Metal)
2601.08141v1_Qalb Largest State-of-the-Art Urdu Large Language .pdf,Qalb: Largest State-of-the-Art Urdu Large Language Model for 230M Speakers with Systematic Continued Pre-training,"Muhammad Taimoor Hassan, Jawad Ahmed, Muhammad Awais",,,"Urdu language model, continued pre-training, low-resource NLP, LoRA, language adaptation","Despite remarkable progress in large language models, Urdu—a language spoken by over 230 million people—remains critically underrepresented in modern NLP systems. Existing multilingual models demonstrate poor performance on Urdu-specific tasks, struggling with the language’s complex morphology, right-to-left Nastaliq script, and rich literary traditions. Even the base LLaMA-3.1 8B-Instruct model shows limited capability in generating fluent, contextually appropriate Urdu text. We introduce Qalb, an Urdu language model developed through a two-stage approach: continued pre-training followed by supervised fine-tuning. Starting from LLaMA 3.1 8B, we perform continued pre-training on a dataset of 1.97 billion tokens. This corpus comprises 1.84 billion tokens of diverse Urdu text—spanning news archives, classical and contemporary literature, government documents, and social media—combined with 140 million tokens of English Wikipedia data to prevent catastrophic forgetting. We then fine-tune the resulting model on the Alif Urdu-instruct dataset. Through extensive evaluation on Urdu-specific benchmarks, Qalb demonstrates substantial improvements, achieving a weighted average score of 90.34 and outperforming the previous state-of-the-art Alif-1.0-Instruct model (87.1) by 3.24 points, while also surpassing the base LLaMA-3.1 8B-Instruct model by 44.64 points. Qalb achieves state-of-the-art performance with comprehensive evaluation across seven diverse tasks including Classification, Sentiment Analysis, and Reasoning. Our results demonstrate that continued pre-training on diverse, high-quality language data, combined with targeted instruction fine-tuning, effectively adapts foundation models to low-resource languages.",3.64,129.557,471,cold_start,Phi-4,Apple_M1(Metal)
2601.08146v2_Mechanisms are Transferable Data-Efficient Low-Res.pdf,Mechanisms are Transferable: Data-Efficient Low-Resource Adaptation via Circuit-Targeted Supervised Fine-Tuning,"Khumaisa Nur’aini, Ayu Purwarianti, Alham Fikri Aji, Derry Wijaya",,,"low-resource adaptation, language models, circuit-targeted supervised fine-tuning, cross-lingual tuning, catastrophic forgetting, mechanistic interpretability","Adapting large language models (LLMs) to low-resource languages is challenging due to the scarcity of labeled data, instability in full-model fine-tuning, and catastrophic forgetting during cross-lingual tuning. This paper introduces Circuit-Targeted Supervised Fine-Tuning (CT-SFT), a method that identifies a sparse set of task-relevant attention heads in a proxy-language checkpoint and transfers learning to a target language by updating only those heads. CT-SFT improves cross-lingual accuracy while updating a small subset of model parameters and reduces catastrophic forgetting, preserving source-language competence. The method leverages mechanistic interpretability to select parameters for adaptation, addressing the challenge of which parameters should be preserved or updated in low-resource settings.",3.25,91.103,296,cold_start,Phi-4,Apple_M1(Metal)
2601.08148v1_Enriching Semantic Profiles into Knowledge Graph f.pdf,Enriching Semantic Profiles into Knowledge Graph for Recommender Systems Using Large Language Models,"Seokho Ahn, Sungbok Shin, Young-Duk Seo",10.1145/3770854.3780324,,"Recommendation, Semantic Profiling, Large Language Models, Knowledge Graphs","Rich and informative profiling to capture user preferences is essential for improving recommendation quality. This paper revisits recent profiling-based approaches in recommender systems along four dimensions: knowledge base, preference indicator, impact range, and subject. It argues that large language models (LLMs) are effective at extracting compressed rationales from diverse knowledge sources, while knowledge graphs (KGs) are better suited for propagating these profiles to extend their reach. The paper proposes a new recommendation model, SPiKE, which consists of three core components: Entity profile generation using LLMs, Profile-aware KG aggregation, and Pairwise profile preference matching. Experiments demonstrate that SPiKE consistently outperforms state-of-the-art KG- and LLM-based recommenders in real-world settings.",3.12,85.659,267,cold_start,Phi-4,Apple_M1(Metal)
2601.08149v1_Dynamic Graph Structure Learning via Resistance Cu.pdf,Dynamic Graph Structure Learning via Resistance Curvature Flow,"Chaoqun Fei, Huanjiang Liu, Tinglve Zhou, Yan Yang Li, Tianyong Hao",,2601.08149v1,"dynamic graph structure learning, resistance curvature flow, circuit theory, geometric graph structure evolution, deep metric learning, manifold learning, graph structure learning","Introduces a novel and computationally efficient curvature flow based on effective resistance from circuit theory, establishing a new paradigm for geometric graph structure evolution. Formulates the dynamic evolution equation of RCF, elucidates its mechanisms for manifold enhancement and noise suppression, and highlights its differentiability and compatibility with deep learning frameworks. Proposes an efficient Dynamic Graph Structure Learning method based on RCF. Extensive experiments on deep metric learning, manifold learning, and graph structure learning tasks demonstrate that DGSL-RCF consistently improves representation quality and downstream performance with low runtime cost.",4.03,56.288,227,cold_start,Phi-4,Apple_M1(Metal)
2601.08156v1_Project Synapse A Hierarchical Multi-Agent Framewo.pdf,Project Synapse: A Hierarchical Multi-Agent Framework with Hybrid Memory for Autonomous Resolution of Last-Mile Delivery Disruptions,"Arin Gopalan Yadav, Varad Dherange, Kumar Shivam",,2601.08156v1,"last-mile delivery, multi-agent systems, hybrid memory architecture, autonomous resolution, disruptions, LangGraph, LLM-as-a-Judge","The operational efficiency of super-apps is critically dependent on the performance of their last-mile delivery (LMD) networks, which are increasingly vulnerable to complex, real-time disruptions that traditional rule-based automation cannot effectively manage. This paper introduces Project Synapse, a novel agentic framework designed for the autonomous resolution of LMD disruptions. Synapse employs a hierarchical multi-agent architecture, where a central Resolution Supervisor agent performs strategic task decomposition and delegates sub-tasks to a team of specialized worker agents responsible for tactical execution. A core contribution of this work is a novel Hybrid Memory Architecture that integrates short-term working memory, long-term episodic memory of past incidents, and a semantic memory of organizational policies. This cognitive architecture enables agents to perform stateful, context-aware, and factually-grounded reasoning. The system is orchestrated using LangGraph to manage complex, cyclical workflows. To validate the framework, a benchmark dataset of 30 complex disruption scenarios was curated from a qualitative analysis of over 6,000 real-world user reviews. The system’s performance was evaluated using an LLM-as-a-Judge protocol with explicit bias mitigation. Initial results are highly promising.",3.98,92.541,368,cold_start,Phi-4,Apple_M1(Metal)
2601.08160v1_SwiftMem Fast Agentic Memory via Query-aware Index.pdf,SwiftMem: Fast Agentic Memory via Query-aware Indexing,"Anxin Tian, Yiming Li, Xing Li, Hui-Ling Zhen, Lei Chen, Xianzhi Yu, Zhenhua Dong, Mingxuan Yuan",,,"agentic memory systems, LLM agents, memory retrieval, query-aware indexing, temporal index, semantic DAG-Tag index, memory fragmentation, embedding-tag co-consolidation, cache locality, LoCoMo benchmark, LongMemEval benchmark","Agentic memory systems are essential for enabling large language models (LLMs) to maintain long-term context and retrieve relevant information efficiently. However, existing frameworks suffer from latency issues due to exhaustive retrieval across the entire memory storage. This paper introduces SwiftMem, a query-aware agentic memory system that achieves sub-linear retrieval through specialized indexing over temporal and semantic dimensions. The temporal index allows logarithmic-time range queries, while the semantic DAG-Tag index maps queries to relevant topics. An embedding-tag co-consolidation mechanism addresses memory fragmentation, improving cache locality. Experiments demonstrate that SwiftMem is 47× faster than state-of-the-art baselines while maintaining competitive accuracy, enabling practical deployment of memory-augmented LLM agents.",3.4,94.922,323,cold_start,Phi-4,Apple_M1(Metal)
2601.08166v1_ZeroDVFS Zero-Shot LLM-Guided Core and Frequency A.pdf,ZeroDVFS: Zero-Shot LLM-Guided Core and Frequency Allocation for Embedded Platforms,"Mohammad Pivezhandi, Mahdi Banisharif, Abusayeed Saifullah, Ali Jannesari",,2601.08166v1,"Dynamic voltage and frequency scaling, thermal management, energy efficiency, multi-core platforms, reinforcement learning, LLM-based semantic feature extraction, embedded systems","Dynamic voltage and frequency scaling (DVFS) and task-to-core allocation are critical for thermal management and balancing energy and performance in embedded systems. Existing approaches either rely on utilization-based heuristics that overlook stall times, or require extensive offline profiling for table generation, preventing runtime adaptation. This paper proposes a model-based hierarchical multi-agent reinforcement learning (MARL) framework for thermal- and energy-aware scheduling on multi-core platforms. Two collaborative agents decompose the exponential action space, achieving 358ms latency for subsequent decisions. First decisions require 3.5 to 8.0s including one-time LLM feature extraction. An accurate environment model leverages regression techniques to predict thermal dynamics and performance states. When combined with LLM-extracted semantic features, the environment model enables zero-shot deployment for new workloads on trained platforms by generating synthetic training data without requiring workload-specific profiling samples. The framework integrates direct reinforcement learning with model-based planning, achieving 20× faster convergence than model-free methods. Experiments demonstrate 7.09 × better energy efficiency and 4.0 × better makespan than Linux ondemand governor. First-decision latency is 8,300 times faster than table-based profiling, enabling practical deployment in dynamic embedded systems.",3.7,106.878,395,cold_start,Phi-4,Apple_M1(Metal)
2601.08173v1_The Agents First Day Benchmarking Learning Explora.pdf,"The Agent’s First Day: Benchmarking Learning, Exploration, and Scheduling in the Workplace Scenarios","Daocheng Fu, Jianbiao Mei, Rong Wu, Xuemeng Yang, Jia Xu, Ding Wang, Pinlong Cai, Yong Liu, Licheng Wen, Botian Shi",,,"Multi-modal Large Language Models, workflow automation, dynamic task scheduling, active exploration, continuous learning, Trainee-Bench, dynamic evaluation environment, streaming tasks, real-world deployment","The rapid evolution of Multi-modal Large Language Models (MLLMs) has advanced workflow automation, but existing research mainly targets performance upper bounds in static environments, overlooking robustness for stochastic real-world deployment. This paper identifies three key challenges: dynamic task scheduling, active exploration under uncertainty, and continuous learning from experience. To address these, the authors introduce Trainee-Bench, a dynamic evaluation environment that simulates a 'trainee' agent continuously exploring a novel setting. Trainee-Bench evaluates agents along three dimensions: context-aware scheduling for streaming tasks with varying priorities, prudent information acquisition to reduce hallucination via active exploration, and continuous evolution by distilling generalized strategies from rule-based, dynamically generated tasks. Experiments show that cutting-edge agents have significant deficiencies in dynamic environments, especially in active exploration and continual learning. The work establishes a framework for assessing agent reliability, shifting evaluation from static tests to realistic, production-oriented scenarios.",3.36,107.833,362,cold_start,Phi-4,Apple_M1(Metal)
2601.08176v1_Prompt-Based Clarity Evaluation and Topic Detectio.pdf,Prompt-Based Clarity Evaluation and Topic Detection in Political Question Answering,"Lavanya Prahallad, Sai Utkarsh Choudarypally, Pragna Prahallad, Pranathi Prahallad",,,"Clarity evaluation, Prompt engineering, Political Question–Answering, Large language models, Chain-of-thought prompting","Automatic evaluation of large language model (LLM) responses requires not only factual correctness but also clarity, particularly in political question–answering. This paper studies prompt-based clarity evaluation using the CLARITY dataset from the SemEval-2026 shared task. It compares a GPT-3.5 baseline with GPT-5.2 evaluated under three prompting strategies: simple prompting, chain-of-thought prompting, and chain-of-thought with few-shot examples. Results show that GPT-5.2 consistently outperforms the GPT-3.5 baseline on clarity prediction, with accuracy improving from 56% to 63% under chain-of-thought with few-shot prompting. Chain-of-thought prompting yields the highest evasion accuracy (34%), though improvements are less stable across fine-grained evasion categories. Reasoning-based prompting improves topic identification accuracy from 60% to 74% relative to human annotations. Overall, prompt design reliably improves high-level clarity evaluation, while fine-grained evasion and topic detection remain challenging despite structured reasoning prompts.",3.46,98.245,340,cold_start,Phi-4,Apple_M1(Metal)
2601.08179v1_Instruction-Driven 3D Facial Expression Generation.pdf,Instruction-Driven 3D Facial Expression Generation and Transition,"Anh H. Vo, Tae-Seok Kim, Hulin Jin, Soo-Mi Choi, Yong-Guk Kim",10.1109/TMM.2025,,"Instruction-Driven, Facial Expression and Transition, Controllable Avatar, CK+ and CelebV-HQ datasets","This study presents a new framework for instruction-driven facial expression generation that produces a 3D face and transforms the facial expression from one designated expression to another. The Instruction-driven Facial Expression Decomposer (IFED) module facilitates multimodal data learning and captures the correlation between textual descriptions and facial expression features. The Instruction to Facial Expression Transition (I2FET) method leverages IFED and a vertex reconstruction loss function to refine the semantic comprehension of latent vectors, generating a facial expression sequence according to the given instruction. The Facial Expression Transition model generates smooth transitions between facial expressions. Extensive evaluation suggests that the proposed model outperforms state-of-the-art methods on the CK+ and CelebV-HQ datasets. The framework can generate facial expression trajectories according to text instruction, expanding the repertoire of facial expressions and transitions. The framework is expected to find various practical applications.",3.39,89.672,304,cold_start,Phi-4,Apple_M1(Metal)
2601.08183v2_GI-Bench A Panoramic Benchmark Revealing the Knowl.pdf,GI-Bench: A Panoramic Benchmark Revealing the Knowledge-Experience Dissociation of Multimodal Large Language Models in Gastrointestinal Endoscopy Against Clinical Standards,"Yan Zhu, Te Luo, Pei-Yao Fu, Zhen Zhang, Zi-Long Wang, Yi-Fan Qu, Zi-Han Geng, Jia-Qi Xu, Lu Yao, Li-Yun Ma, Wei Su, Wei-Feng Chen, Quan-Lin Li, Shuo Wang, Ping-Hong Zhou",,,"Multimodal Large Language Models, Gastrointestinal Endoscopy, Clinical Workflow, Benchmark, Diagnostic Reasoning","This study evaluates the performance of Multimodal Large Language Models (MLLMs) in gastroenterology against comprehensive clinical workflows and human benchmarks. The GI-Bench benchmark, encompassing 20 fine-grained lesion categories, assesses twelve MLLMs across a five-stage clinical workflow: anatomical localization, lesion identification, diagnosis, findings description, and management. Performance is compared with junior endoscopists and residency trainees using metrics like Macro-F1, mean Intersection-over-Union (mIoU), and a multi-dimensional Likert scale. The study finds that Gemini-3-Pro achieves state-of-the-art performance in diagnostic reasoning.",3.87,87.702,339,cold_start,Phi-4,Apple_M1(Metal)
2601.08185v1_Autonomous Materials Exploration by Integrating Au.pdf,Autonomous Materials Exploration by Integrating Automated Phase Identification and AI-Assisted Human Reasoning,"Ming-Chiang Chang, Maximilian Amsler, Duncan R. Sutherland, Sebastian Ament, Katie R. Gann, Lan Zhou, Louisa M. Smieska, Arthur R. Woll, John M. Gregoire, Carla P. Gomes, R. Bruce van Dover, Michael O. Thompson",,,"autonomous experimentation, materials development, artificial intelligence, modular robotic platforms, combinatorial chemical spaces, phase identification, human-in-the-loop, materials synthesis, active learning, oxide materials, lateral-gradient laser spike annealing, metastable phases, cationic substitutional doping","The paper discusses the potential of autonomous experimentation in accelerating materials development by integrating AI with modular robotic platforms. It introduces an autonomous materials synthesis extension to SARA, utilizing automated phase labeling to target specific phase regions. The study incorporates human input into the SARA-H framework, enhancing reasoning efficiency. Experiments with oxide materials like Bi2O3, SnOx, and Bi–Ti–O demonstrate the utility of human-in-the-loop approaches, identifying processing domains and confirming predictions about phase behavior and cationic substitutional doping effects.",3.48,98.862,344,cold_start,Phi-4,Apple_M1(Metal)
2601.08187v2_Improving LLM Reasoning with Homophily-aware Struc.pdf,IMPROVING LLM REASONING WITH HOMOPHILY-AWARE STRUCTURAL AND SEMANTIC TEXT-ATTRIBUTED GRAPH COMPRESSION,"Zijun Di, Bin Lu, Huquan Kang, Luoyi Fu, Jiaxin Ding, Xiaoying Gan, Lei Zhou, Xinbing Wang, Chenghu Zhou",,arXiv:2601.08187v2,"Large Language Models, Text-Attributed Graph, Graph Compression, Homophily, Structural Entropy, Semantic Aggregation","Large language models (LLMs) have shown promising capabilities in Text-Attributed Graph (TAG) understanding. Current methods often use random sampling due to context window constraints, introducing noise and instability. This paper proposes the Homophily-aware Structural and Semantic Compression for LLMs (HS2C) framework, which leverages graph homophily. Structurally, it uses Structural Entropy minimization for global hierarchical partitioning to identify cohesive communities and discard noise. Semantically, it enables LLMs to perform differentiated semantic aggregation based on community types, compressing redundant contexts into concise community-level consensus. Experiments on 10 node-level benchmarks show that HS2C enhances compression rates and inference accuracy, achieving a 94.98% compression on OGBN-ArXiv with a 3.06%–4.92% accuracy improvement. Extensions to 7 graph-level benchmarks further demonstrate HS2C's task generalizability.",3.6,103.136,371,cold_start,Phi-4,Apple_M1(Metal)
2601.08189v2_ForgetMark Stealthy Fingerprint Embedding via Targ.pdf,STEALTHY FINGERPRINT EMBEDDING VIA TARGETED UNLEARNING IN LANGUAGE MODELS,"Zhenhua Xu, Haobo Zhang, Zhebo Wang, Qichen Liu, Haitao Xu, Wenpeng Xing, Meng Han","© 2026 IEEE. Published in ICASSP 2026 – 2026 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), scheduled for 3–8 May 2026 in Barcelona, Spain.",,"Large Language Model, Copyright protection, Model Fingerprinting, Machine Unlearning","ForgetMark introduces a stealthy fingerprinting framework for language models that encodes provenance via targeted unlearning. It uses a compact, human-readable key–value set with an assistant model and predictive-entropy ranking to train lightweight LoRA adapters. These adapters suppress original values on their keys while preserving general capabilities. Ownership is verified under black/gray-box access by aggregating likelihood and semantic evidence into a fingerprint success rate. ForgetMark avoids high-perplexity triggers, reduces detectability, and lowers false triggers, achieving 100% ownership verification on fingerprinted models while maintaining standard performance. It surpasses backdoor baselines in stealthiness and robustness to model merging and remains effective under moderate incremental fine-tuning.",3.38,95.479,323,cold_start,Phi-4,Apple_M1(Metal)
2601.08196v1_Evaluating Implicit Regulatory Compliance in LLM T.pdf,Evaluating Implicit Regulatory Compliance in LLM Tool Invocation via Logic-Guided Synthesis,"Da Song, Yuheng Huang, Boqi Chen, Tianshuo Cong, Randy Goebel, Lei Ma, Foutse Khomh",,,"Large Language Models, LLMs, regulatory compliance, safety constraints, logic-guided fuzzing, Linear Temporal Logic, benchmarking","The integration of large language models (LLMs) into autonomous agents has enabled complex tool use, yet in high-stakes domains, these systems must strictly adhere to regulatory standards beyond simple functional correctness. Existing benchmarks often overlook implicit regulatory compliance, failing to evaluate whether LLMs can autonomously enforce mandatory safety constraints. To address this, the authors introduce LOGISAFETYGEN, a framework that converts unstructured regulations into Linear Temporal Logic oracles and employs logic-guided fuzzing to synthesize valid, safety-critical traces. Building on this framework, they construct LOGISAFETYBENCH, a benchmark comprising 240 human-verified tasks requiring LLMs to generate Python programs that satisfy both functional objectives and latent compliance rules. Evaluations of 13 state-of-the-art LLMs reveal that larger models, despite achieving better functional correctness, frequently prioritize task completion over safety, resulting in non-compliant behavior.",3.4,98.079,333,cold_start,Phi-4,Apple_M1(Metal)
2601.08211v1_Adapting Rules of Official International Mahjong f.pdf,Adapting Rules of Official International Mahjong for Online Players,"Chucai Wang, Lingfeng Li, Yunlong Lu, Wenxin Li",,,"Mahjong, game design, champion AI","This paper discusses the adaptation of Official International Mahjong rules for online play. Unlike offline play, online players face fragmented playtime and varying opponents, necessitating rule modifications to ensure fairness in single-round games. The study employs a world champion AI to analyze self-play competitions and statistical data, revealing issues like first-mover advantage and subgoal scoring discrepancies. Proposed adaptations include compensatory points for first-mover advantage and refined subgoal scores for different tile patterns. These changes aim to balance the game more effectively in an online setting compared to traditional methods. The revised Mahjong game is implemented online, offering a new experience for players. This work leverages AI data to evaluate and enhance the game's balance for online environments.",3.22,74.28,239,cold_start,Phi-4,Apple_M1(Metal)
2601.08223v2_DNF Dual-Layer Nested Fingerprinting for Large Lan.pdf,DNF: DUAL-LAYER NESTED FINGERPRINTING FOR LARGE LANGUAGE MODEL INTELLECTUAL PROPERTY PROTECTION,"Zhenhua Xu, Yiran Zhao, Mengting Zhong, Dezhang Kong, Changting Lin, Tong Qiao, Meng Han","© 2026 IEEE. Published in ICASSP 2026 – 2026 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), scheduled for 3–8 May 2026 in Barcelona, Spain.",,"Large Language Model, Copyright Protection, Model Fingerprinting, Backdoor","The rapid growth of large language models raises pressing concerns about intellectual property protection under black-box deployment. Existing backdoor-based fingerprints either rely on rare tokens—leading to high-perplexity inputs susceptible to filtering—or use fixed trigger–response mappings that are brittle to leakage and post-hoc adaptation. We propose Dual-Layer Nested Fingerprinting (DNF), a black-box method that embeds a hierarchical backdoor by coupling domain-specific stylistic cues with implicit semantic triggers. Across Mistral-7B, LLaMA-3-8B-Instruct, and Falcon3-7B-Instruct, DNF achieves perfect fingerprint activation while preserving downstream utility. Compared with existing methods, it uses lower-perplexity triggers, remains undetectable under fingerprint detection attack, and is relatively robust to incremental fine-tuning and model merging. These results position DNF as a practical, stealthy, and resilient solution for LLM ownership verification and IP protection.",3.42,109.945,376,cold_start,Phi-4,Apple_M1(Metal)
2601.08224v1_An Axiomatic Approach to General Intelligence SANC.pdf,An Axiomatic Approach to General Intelligence: Self-organizing Active Network of Concepts with EnergyE 3,"Daesuk Kwon, Won-gi Paeng",,arXiv:2601.08224v1,"axiomatization of intelligence, competitive selection, system tokens, reconstruction–compression trade-off, category formation, self-similar hierarchy, Gestalt completion","General intelligence must reorganize experience into internal structures that enable prediction and action under finite resources. Existing systems presuppose fixed primitive units, bypassing how representational units emerge and stabilize. This paper proposes SANC(E3), an axiomatic framework where representational units arise from competitive selection, reconstruction, and compression under finite activation capacity, governed by minimizing an energy functional. SANC(E3) distinguishes between system tokens and tokens emerging through self-organization. Five core axioms formalize finite capacity, association from co-occurrence, similarity-based competition, confidence-based stabilization, and the reconstruction–compression–update trade-off. A pseudo-memory-mapped I/O mechanism unifies perception, imagination, prediction, planning, and action within a single process. Twelve propositions show that various cognitive activities can be understood as instances of Gestalt completion under E3 minimization.",3.51,88.365,310,cold_start,Phi-4,Apple_M1(Metal)
2601.08226v1_Knowledge-based learning in Text-RAG and Image-RAG.pdf,Knowledge-based learning in Text-RAG and Image-RAG,"Alexander Shim, Khalil Saieh, Samuel Clarke",,,"Vision Transformer, EVA-ViT, LlaMA, ChatGPT, LLM, hallucination problem, chest x-ray images, NIH Chest X-ray, image-based RAG, text-based RAG, baseline, KNN methods, GPT LLM, Expected Calibration Error, data imbalance, multi-stage structure, multi-modal AI systems, radiology, diagnostic delays, workload pressures, vision transformers, large language models, clinical interpretation, transparency, retrieval-augmented generation","This research analyzed and compared the multi-modal approach in the Vision Transformer (EVA-ViT) based image encoder with the LlaMA or ChatGPT LLM to reduce the hallucination problem and detect diseases in chest x-ray images. The study utilized NIH Chest X-ray images to train the model and compared it in image-based RAG, text-based RAG, and baseline. The text-based RAG effectively reduced the hallucination problem by using external knowledge information, and the image-based RAG improved prediction confidence and calibration using KNN methods. The GPT LLM showed better performance, a low hallucination rate, and better Expected Calibration Error (ECE) than the Llama Llama-based model. The research highlights challenges such as data imbalance and complex multi-stage structures but suggests a large experience environment and balanced example use. The introduction discusses the need for rethinking traditional image-interpretation pipelines due to the rapid advancement of imaging technologies and the slower pace of interpretation capabilities. The paper evaluates different retrieval-augmented generation (RAG) strategies in chest X-ray interpretation, focusing on text-based RAG, image-based RAG, and a baseline multi-modal system.",3.72,123.614,460,cold_start,Phi-4,Apple_M1(Metal)
2601.08230v1_GADPN Graph Adaptive Denoising and Perturbation Ne.pdf,GADPN: Graph Adaptive Denoising and Perturbation Networks via Singular Value Decomposition,"Hao Deng, Bo Liu",,,"Graph Neural Networks, Graph Structural Learning, Network Representation Learning","Graph Neural Networks (GNNs) excel on graph-structured data but are limited by the quality of the observed graph, which often contains noise, missing links, or misaligned structural properties. This paper proposes GADPN, a framework for graph structure learning that refines graph topology via low-rank denoising and generalized structural perturbation. Key contributions include the use of Bayesian optimization to adaptively determine denoising strength and the extension of structural perturbation to arbitrary graphs using Singular Value Decomposition (SVD). Experiments show that GADPN achieves state-of-the-art performance with improved efficiency, particularly on challenging disassortative graphs.",3.03,65.674,199,cold_start,Phi-4,Apple_M1(Metal)
2601.08235v2_MPCI-Bench A Benchmark for Multimodal Pairwise Con.pdf,MPCI-Bench: A Benchmark for Multimodal Pairwise Contextual Integrity Evaluation of Language Model Agents,"Shouju Wang, Haopeng Zhang",,,"Multimodal Pairwise Contextual Integrity, privacy behavior, language model agents, Contextual Integrity, privacy and utility, modality leakage","As language-model agents evolve from passive chatbots into proactive assistants handling personal data, evaluating their adherence to social norms through Contextual Integrity (CI) becomes critical. Existing CI benchmarks are text-centric and focus on negative refusal scenarios, overlooking multimodal privacy risks and the privacy-utility trade-off. This paper introduces MPCI-Bench, the first Multimodal Pairwise Contextual Integrity benchmark for evaluating privacy behavior in agentic settings. MPCI-Bench includes paired positive and negative instances from the same visual source across three tiers: normative Seed judgments, context-rich Story reasoning, and executable agent action Traces. Data quality is ensured through a Tri-Principle Iterative Refinement pipeline. Evaluations reveal systematic failures in balancing privacy and utility and a pronounced modality leakage gap, where sensitive visual information is leaked more frequently than textual information.",3.28,81.77,268,cold_start,Phi-4,Apple_M1(Metal)
2601.08237v1_The End of Reward Engineering How LLMs Are Redefin.pdf,The End of Reward Engineering: How LLMs Are Redefining Multi-Agent Coordination,"Haoran Su, Yandong Sun, Congjia Yu",,arXiv:2601.08237v1,"multi-agent reinforcement learning, reward engineering, large language models, semantic understanding, dynamic adaptation, human alignment","Reward engineering – the manual design of reward functions to guide agent behavior – remains a persistent bottleneck in multi-agent reinforcement learning. In multi-agent systems, this challenge is compounded by credit assignment ambiguity, environmental non-stationarity, and exponentially scaling complexity. Large language models (LLMs) enable a fundamental paradigm shift: from hand-crafted numerical rewards to natural language objectives. LLMs can generate human-level reward functions from language descriptions alone, adapt rewards dynamically without human intervention, and coordinate agents through semantic understanding. The emergence of Reinforcement Learning from Verifiable Rewards (RLVR) further validates this trajectory, establishing language-based training as mainstream. The transition is supported by three pillars: semantic reward specification, dynamic adaptation, and inherent human alignment, while acknowledging challenges in computational cost, hallucination risks, and scalability. The vision for multi-agent systems is one where coordination emerges from shared semantic understanding rather than engineered numerical signals.",3.6,84.406,304,cold_start,Phi-4,Apple_M1(Metal)
2601.08251v1_Hyperbolic Heterogeneous Graph Transformer.pdf,Hyperbolic Heterogeneous Graph Transformer,"Jongmin Park, Seunghoon Han, Hyewon Lee, Won-Yong Shin, Sungsu Lim",,,"Heterogeneous Graph Representation Learning, Hyperbolic Graph Embedding, Graph Transformer","In heterogeneous graphs, complex structures such as tree-like or hierarchical structures are observed. The hyperbolic space has been widely adopted to effectively learn these structures. Existing methods face challenges such as mapping distortions due to tangent-space operations and difficulty in capturing global hierarchical structures and long-range dependencies. The proposed Hyperbolic Heterogeneous Graph Transformer (HypHGT) addresses these limitations by learning graph representations entirely within the hyperbolic space. HypHGT captures both local and global dependencies through a transformer-based architecture and employs a relation-specific hyperbolic attention mechanism with linear time complexity. This design preserves heterogeneous information across different relation types and captures complex structural properties and semantic information. Comprehensive experiments demonstrate that HypHGT outperforms state-of-the-art methods in node classification tasks, with reduced training time and memory usage.",3.28,82.105,269,cold_start,Phi-4,Apple_M1(Metal)
2601.08254v1_Large Artificial Intelligence Model Guided Deep Re.pdf,Large Artificial Intelligence Model–Guided Deep Reinforcement Learning for Resource Allocation in Non-Terrestrial Networks,"Abdikarim Mohamed Ibrahim, Rosdiadee Nordin",,,"Large AI Models (LAMs), Large Language Models (LLMs), Deep Reinforcement Learning (DRL), Satellite Communications, Non-Terrestrial Networks (NTNs)","Large AI Models (LAM) have been proposed for applications in Non-Terrestrial Networks (NTN), offering improved performance through generalization and reduced task-specific training. This paper introduces a Deep Reinforcement Learning (DRL) agent guided by a Large Language Model (LLM). The LLM acts as a high-level coordinator, providing textual guidance that shapes the DRL agent's reward during training. Results indicate that the LAM-DRL approach outperforms traditional DRL by 40% in nominal weather scenarios and 64% in extreme weather scenarios compared to heuristics, in terms of throughput, fairness, and outage probability. The paper addresses challenges in NTN resource allocation, such as dynamic complexities, rapid topology changes, and the need for intelligent and adaptive solutions. Traditional methods struggle with fast changes and scalability, while DRL, despite its stability, suffers from sample inefficiency and requires frequent retraining. The study explores hybrid intelligent schemes where LLMs guide DRL, improving robustness and interpretability, particularly in NTN-specific scenarios.",3.47,96.62,335,cold_start,Phi-4,Apple_M1(Metal)
2601.08257v2_On Evaluation of Unsupervised Feature Selection fo.pdf,On Evaluation of Unsupervised Feature Selection for Pattern Classification,"Gyu-Il Kim, Dae-Won Kim, Jaesung Lee",,2601.08257v2,"Unsupervised Feature Selection, Pattern Classification, Multi-label Classification, Feature Selection, Machine Learning","Unsupervised feature selection aims to identify a compact subset of features that captures the intrinsic structure of data without supervised labels. Most studies evaluate methods using single-label datasets, which can vary based on the selected label, leading to inconsistent performance rankings. This study proposes a multi-label classification framework to provide a fairer evaluation of unsupervised feature selection methods. Experiments on 21 multi-label datasets show that performance rankings differ significantly from single-label settings, suggesting the need for multi-label evaluation for reliable comparisons.",3.29,63.776,210,cold_start,Phi-4,Apple_M1(Metal)
2601.08258v1_T3 Benchmarking Sycophancy and Skepticism in Causa.pdf,Benchmarking Sycophancy and Skepticism in Causal Judgment,Edward Y. Chang,,,"causal judgment, LLM, Pearl’s Ladder of Causality, benchmark, skepticism trap, scaling paradox, RCA, causal reasoning, safety-induced refusal, causal hierarchy, sycophancy, truthfulness","The paper introduces T3 (Testing Trustworthy Thinking), a diagnostic benchmark designed to evaluate LLM causal judgment across Pearl’s Ladder of Causality. It comprises 454 expert-curated vignettes, focusing on high-resolution failure analysis by decomposing performance into Utility (sensitivity), Safety (specificity), and Wise Refusal on underdetermined cases. The benchmark identifies two pathologies: a 'Skepticism Trap' at L1 and a non-monotonic 'Scaling Paradox' at L3. It also validates a process-verified protocol (RCA) to restore decisive causal judgment under structured verification. The benchmark aims to distinguish genuine capability from safety-induced refusal in causal reasoning benchmarks.",3.24,85.768,278,cold_start,Phi-4,Apple_M1(Metal)
2601.08262v1_VGG Induced Deep Hand Sign Language Detection.pdf,VGG Induced Deep Hand Sign Language Detection,"Subham Sharma, Sharmila Subudhi",,2601.08262v1,"Hand gesture recognition, Convolutional neural network, Classification, VGG-16 net, API","Hand gesture recognition is an important aspect of human-computer interaction, forming the basis of sign language for visually impaired people. This work proposes a novel hand gesture recognizing system for differently-abled persons using a convolutional neural network, specifically the VGG-16 net, trained on a widely used image dataset with Python and Keras libraries. The model's results are validated using the NUS dataset, which consists of 10 classes of hand gestures. A testing dataset of 10 classes is built using Google’s open source API to capture different human hand gestures. The efficacy is measured through experiments, showing that combining transfer learning with image data augmentation, the VGG-16 net achieved around 98% accuracy.",3.73,64.879,242,cold_start,Phi-4,Apple_M1(Metal)
2601.08271v1_Sparsity Is Necessary Polynomial-Time Stability fo.pdf,Sparsity Is Necessary: Polynomial-Time Stability for Agentic LLMs in Large Action Spaces,Angshul Majumdar,,arXiv:2601.08271v1,"LLMs, sequential decision-making, sparse agentic control, policy learning, large action spaces, tool-augmented systems","This paper addresses the challenge of sequential decision-making in large action spaces with tool-augmented large language models (LLMs). It introduces the concept of Sparse Agentic Control (SAC), where policies are block-sparse over a large number of actions. The study focuses on ℓ1,2-regularized policy learning and presents results on estimation and value suboptimality, tool-support recovery, and the necessity of sparsity for stability. The paper also discusses the impact of partial observability and extends the findings to various settings including online and robust SAC. The central challenge identified is control under extreme action dimensionality with latent sparsity, rather than reasoning under uncertainty.",3.21,73.417,236,cold_start,Phi-4,Apple_M1(Metal)
2601.08273v1_HIPPO Accelerating Video Large Language Models Inf.pdf,HIPPO: Accelerating Video Large Language Models Inference via Holistic-aware Parallel Speculative Decoding,"Qitan Lv, Tianyu Liu, Wen Wu, Xuenan Xu, Bowen Zhou, Feng Wu, Chao Zhang",,,"speculative decoding, video-LLMs, token pruning, inference acceleration, semantic-aware token preservation, video parallel SD algorithm","Speculative decoding (SD) has emerged as a promising approach to accelerate Large Language Model (LLM) inference without sacrificing output quality. Existing SD methods for video-LLMs focus on pruning redundant visual tokens to reduce computational burden. However, they do not achieve acceleration comparable to text-only LLMs due to inadequate preservation of visual semantic tokens and limited speedup from remaining inference costs. HIPPO, a holistic-aware parallel speculative decoding framework, addresses these limitations by proposing a semantic-aware token preservation method and a video parallel SD algorithm. Experiments demonstrate HIPPO's effectiveness, yielding up to 3.51× speedup compared to vanilla autoregressive decoding.",3.27,83.48,273,cold_start,Phi-4,Apple_M1(Metal)
2601.08276v1_ToolACE-MCP Generalizing History-Aware Routing fro.pdf,ToolACE-MCP: Generalizing History-Aware Routing from MCP Tools to the Agent Web,"Zhiyuan Yao, Zishan Xu, Yifu Guo, Zhiguang Han, Cheng Yang, Shuo Zhang, Weinan Zhang, Xingshan Zeng, Weiwen Liu",,,"Agent Web, Model Context Protocol (MCP), history-aware routing, large-scale ecosystems, multi-agent collaboration, robustness against noise, scalability","With the rise of the Agent Web and Model Context Protocol (MCP), the agent ecosystem is evolving into an open collaborative network, exponentially increasing accessible tools. Current architectures face severe scalability and generality bottlenecks. To address this, we propose ToolACE-MCP, a pipeline for training history-aware routers to empower precise navigation in large-scale ecosystems. By leveraging a dependency-rich candidate Graph to synthesize multi-turn trajectories, we effectively train routers with dynamic context understanding to create the plug-and-play Light Routing Agent. Experiments on the real-world benchmarks MCP-Universe and MCP-Mark demonstrate superior performance. Notably, ToolACE-MCP exhibits critical properties for the future Agent Web: it not only generalizes to multi-agent collaboration with minimal adaptation but also maintains exceptional robustness against noise and scales effectively to massive candidate spaces. These findings provide a strong empirical foundation for universal orchestration in open-ended ecosystems.",3.35,102.493,343,cold_start,Phi-4,Apple_M1(Metal)
2601.08280v1_Greedy Is Enough Sparse Action Discovery in Agenti.pdf,Greedy Is Enough: Sparse Action Discovery in Agentic LLMs,Angshul Majumdar,,,"agentic systems, large action spaces, sparse action discovery, block-sparse recovery, Orthogonal Matching Pursuit, linear reward model, sparsity, action pruning","Modern agentic systems operate in environments with extremely large action spaces, such as tool-augmented language models with thousands of available APIs or retrieval operations. Despite this scale, empirical evidence suggests that only a small subset of actions meaningfully influences performance in a given deployment. This work studies a contextual linear reward model with a structured sparsity assumption, where only a small number of actions have nonzero effects across latent states. Action discovery is formulated as a block-sparse recovery problem, and a greedy algorithm inspired by Orthogonal Matching Pursuit is analyzed. Under standard assumptions, the greedy procedure is shown to exactly recover the relevant action set with high probability, using a number of samples that scales polynomially in the sparsity level and latent dimension, and only logarithmically in the total number of actions. Estimation error guarantees for refitted parameters are provided, and the resulting decision rule is shown to be near-optimal for new latent states. Information-theoretic lower bounds demonstrate that sparsity and sufficient coverage are necessary for tractability. These results identify sparse action discovery as a fundamental principle underlying large-action decision-making and provide a theoretical foundation for action pruning in agentic systems.",3.59,89.6,322,cold_start,Phi-4,Apple_M1(Metal)
2601.08288v1_OpenMic A Multi-Agent-Based Stand-Up Comedy Genera.pdf,OpenMic: A Multi-Agent-Based Stand-Up Comedy Generation System,"Yuyang Wu, Hanzhong Cao, Jianhao Chen, Yufei Li",,,"Chinese stand-up comedy generation, multi-agent system, AutoGen, retrieval-augmented generation, humor, timing, performability, stand-up-specific structures, long-range callbacks","Chinese stand-up comedy generation requires culturally grounded humor, precise timing, stage-performance cues, and implicit multi-step reasoning. Existing Chinese humor datasets are often better suited for humor understanding and evaluation than for long-form stand-up generation, leading to misalignment with the target task. To address these challenges, the paper presents OpenMic, an end-to-end multi-agent system built on AutoGen that transforms a user-provided life topic into a 3–5 minute Chinese stand-up performance and produces a narrated comedy video. OpenMic orchestrates multiple specialized agents in a multi-round iterative loop to optimize humor, timing, and performability. The system uses retrieval-augmented generation (RAG) for material grounding and idea expansion, and fine-tunes a dedicated JokeWriter to better internalize stand-up-specific setup–punchline structures and long-range callbacks.",3.44,89.852,309,cold_start,Phi-4,Apple_M1(Metal)
2601.08297v1_Demystifying the Slash Pattern in Attention The Ro.pdf,Demystifying the Slash Pattern in Attention: The Role of RoPE,"Yuan Cheng, Fengzhuo Zhang, Yunlong Hou, Cunxiao Du, Chao Du, Tianyu Pang, Aixin Sun, Zhuoran Yang",,arXiv:2601.08297v1,"Large Language Models, Slash-Dominant Heads, Attention Patterns, RoPE, Position Embedding, Out-Of-Distribution Generalization","Large Language Models (LLMs) often exhibit slash attention patterns, where attention scores concentrate along the ∆-th sub-diagonal for some offset ∆. These patterns play a key role in passing information across tokens. This paper demystifies the emergence of these Slash-Dominant Heads (SDHs) from both empirical and theoretical perspectives. By analyzing open-source LLMs, it is found that SDHs are intrinsic to models and generalize to out-of-distribution prompts. The paper analyzes queries, keys, and Rotary Position Embedding (RoPE), which jointly determine attention scores. Two characteristic conditions of SDHs are identified: (1) Queries and keys are almost rank-one, and (2) RoPE is dominated by medium- and high-frequency components. Under these conditions, queries and keys are nearly identical across tokens, and interactions between medium- and high-frequency components of RoPE give rise to SDHs.",3.68,95.199,350,cold_start,Phi-4,Apple_M1(Metal)
2601.08302v1_Enhancing Sentiment Classification and Irony Detec.pdf,Enhancing Sentiment Classification and Irony Detection in Large Language Models through Advanced Prompt Engineering Techniques,"Marvin Schmitt, Anne Schwerk, Sebastian Lempert",,,"sentiment analysis, irony detection, large language models (LLMs), prompt engineering","This study investigates the use of prompt engineering to enhance large language models (LLMs), specifically GPT-4o-mini and gemini-1.5-flash, in sentiment analysis tasks. It evaluates advanced prompting techniques like few-shot learning, chain-of-thought prompting, and self-consistency against a baseline. Key tasks include sentiment classification, aspect-based sentiment analysis, and detecting subtle nuances such as irony. The research details the theoretical background, datasets, and methods used, assessing performance of LLMs as measured by accuracy, recall, precision, and F1 score. Findings reveal that advanced prompting significantly improves sentiment analysis, with the few-shot approach excelling in GPT-4o-mini and chain-of-thought prompting boosting irony detection in gemini-1.5-flash by up to 46%. Thus, while advanced prompting techniques overall improve performance, the fact that few-shot prompting works best for GPT-4o-mini and chain-of-thought excels in gemini-1.5-flash for irony detection suggests that prompting strategies must be tailored to both the model and the task. This highlights the importance of aligning prompt design with both the LLM’s architecture and the semantic complexity of the task.",3.59,97.063,348,cold_start,Phi-4,Apple_M1(Metal)
2601.08310v1_ORBIT On-policy Exploration-Exploitation for Contr.pdf,ORBIT: On-policy Exploration-Exploitation for Controllable Multi-Budget Reasoning,"Kun Liang, Clive Bai, Xin Xu, Chenming Tang, Sanwoo Lee, Weijie Liu, Saiyong Yang, Yunfang Wu",,,"Large Reasoning Models, Chain-of-Thought reasoning, Reinforcement Learning, Multi-budget reasoning, Operational efficiency","Recent Large Reasoning Models (LRMs) achieve strong performance by leveraging long-form Chain-of-Thought (CoT) reasoning, but uniformly applying overlong reasoning at inference time incurs substantial and often unnecessary computational cost. To address this, prior work explores various strategies to infer an appropriate reasoning budget from the input. However, such approaches are unreliable in the worst case, as estimating the minimal required reasoning effort is fundamentally difficult, and they implicitly fix the trade-off between reasoning cost and accuracy during training, limiting flexibility under varying deployment scenarios. Motivated by these limitations, we propose ORBIT, a controllable multi-budget reasoning framework with well-separated reasoning modes triggered by input. ORBIT employs multi-stage reinforcement learning to discover Pareto-optimal reasoning behaviors at each effort, followed by on-policy distillation to fuse these behaviors into a single unified model. Experiments show that ORBIT achieves controllable reasoning behavior over multiple modes, competitive reasoning density within each mode, and integration of these frontier policies into a single unified student model while preserving clear mode separation and high per-mode performance.",3.52,102.029,359,cold_start,Phi-4,Apple_M1(Metal)
2601.08311v1_Enhancing Image Quality Assessment Ability of LMMs.pdf,Enhancing Image Quality Assessment Ability of LMMs via Retrieval-Augmented Generation,"Kang Fu, Huiyu Duan, Zicheng Zhang, Yucheng Zhu, Jun Zhao, Xiongkuo Min, Jia Wang, Guangtao Zhai",,,"Image quality assessment, Retrieval-Augmented Generation, Large Multimodal Models, Zero-shot, Training-free","Large Multimodal Models (LMMs) have shown promise in low-level visual perception tasks, particularly in Image Quality Assessment (IQA), with strong zero-shot capability. However, achieving state-of-the-art performance often requires computationally expensive fine-tuning methods. This paper introduces IQARAG, a novel, training-free framework that enhances LMMs’ IQA ability by leveraging Retrieval-Augmented Generation (RAG). IQARAG retrieves semantically similar but quality-variant reference images with corresponding Mean Opinion Scores (MOSs) for the input image. These images are integrated into a specific prompt, providing a visual perception anchor for the IQA task. The framework consists of three key phases: Retrieval Feature Extraction, Image Retrieval, and Integration & Quality Score Generation. Extensive experiments across multiple IQA datasets demonstrate that IQARAG effectively boosts the IQA performance of LMMs, offering a resource-efficient alternative to fine-tuning for quality assessment.",3.41,99.578,340,cold_start,Phi-4,Apple_M1(Metal)
2601.08323v1_AtomMem  Learnable Dynamic Agentic Memory with Ato.pdf,AtomMem: Learnable Dynamic Agentic Memory with Atomic Memory Operation,"Yupeng Huo, Yaxi Lu, Zhong Zhang, Haotian Chen, Yankai Lin",,,"memory mechanisms, dynamic decision-making, CRUD operations, reinforcement learning, long-horizon problems, LLM-based agents","This paper introduces AtomMem, a flexible, learning-based memory framework for agents, addressing the limitations of static, hand-crafted memory workflows. AtomMem reframes memory management as a dynamic decision-making problem, utilizing atomic CRUD operations to create a learnable decision process. By integrating supervised fine-tuning with reinforcement learning, AtomMem develops an autonomous, task-aligned policy for memory management. Experimental results demonstrate that AtomMem-8B outperforms static-workflow methods across three long-context benchmarks, showcasing its ability to discover structured, task-aligned memory strategies.",3.08,76.648,236,cold_start,Phi-4,Apple_M1(Metal)
2601.08327v1_Safe Heterogeneous Multi-Agent RL with Communicati.pdf,Safe Heterogeneous Multi-Agent RL with Communication Regularization for Coordinated Target Acquisition,"Gabriele Calzolari, Vidya Sumathy, Christoforos Kanellakis, George Nikolakopoulos",,,"Cooperative target acquisition, Safe autonomous coordination, Decentralized multi-agent reinforcement learning, Heterogeneous robotic systems, Learning-based control","This paper introduces a decentralized multi-agent reinforcement learning framework enabling structurally heterogeneous teams of agents to jointly discover and acquire randomly located targets in environments characterized by partial observability, communication constraints, and dynamic interactions. Each agent’s policy is trained with the Multi-Agent Proximal Policy Optimization algorithm and employs a Graph Attention Network encoder that integrates simulated range-sensing data with communication embeddings exchanged among neighboring agents, enabling context-aware decision-making from both local sensing and relational information. The work introduces a unified framework that integrates graph-based communication and trajectory-aware safety through safety filters. The architecture is supported by a structured reward formulation designed to encourage effective target discovery and acquisition, collision avoidance, and de-correlation between the agents’ communication vectors by promoting informational orthogonality. The effectiveness of the proposed reward function is demonstrated through a comprehensive ablation study. Moreover, simulation results demonstrate safe, and stable task execution confirming the framework’s effectiveness.",3.49,82.286,287,cold_start,Phi-4,Apple_M1(Metal)
2601.08332v1_IGAN A New Inception-based Model for Stable and Hi.pdf,IGAN: A New Inception-based Model for Stable and High-Fidelity Image Synthesis Using Generative Adversarial Networks,"Ahmed A. Hashim, Ali Al-Shuwaili, Asraa Saeed, Ali Al-Bayaty",,,"Generative Adversarial Networks (GANs), dilation convolutions, inception module, spectral normalization, image synthesis, deep learning stability","Generative Adversarial Networks (GANs) face a significant challenge of striking an optimal balance between high-quality image generation and training stability. Recent techniques, such as DCGAN, BigGAN, and StyleGAN, improve visual fidelity; however, such techniques usually struggle with mode collapse and unstable gradients at high network depth. This paper proposes a novel GAN structural model that incorporates deeper inception-inspired convolution and dilated convolution. This novel model is termed the Inception Generative Adversarial Network (IGAN). The IGAN model generates high-quality synthetic images while maintaining training stability, by reducing mode collapse as well as preventing vanishing and exploding gradients. Our proposed IGAN model achieves the Fréchet Inception Distance (FID) of 13.12 and 15.08 on the CUB-200 and ImageNet datasets, respectively, representing a 28–33% improvement in FID over the state-of-the-art GANs. Additionally, the IGAN model attains an Inception Score (IS) of 9.27 and 68.25, reflecting improved image diversity and generation quality. Finally, the two techniques of dropout and spectral normalization are utilized in both the generator and discriminator structures to further mitigate gradient explosion and overfitting. These findings confirm that the IGAN model potentially balances training stability with image generation quality, constituting a scalable and computationally efficient framework for high-fidelity image synthesis.",3.87,110.913,429,cold_start,Phi-4,Apple_M1(Metal)
2601.08333v1_Semantic Laundering in AI Agent Architectures Why .pdf,Semantic Laundering in AI Agent Architectures: Why Tool Boundaries Do Not Confer Epistemic Warrant,"Oleg Romanchuk, Roman Bondar",,arXiv:2601.08333v1,"cs.AI, semantic laundering, epistemic justification, Gettier problem, LLM-based agent architectures","LLM-based agent architectures systematically conflate information transport mechanisms with epistemic justification mechanisms. This paper formalizes these architectural failures as semantic laundering, where propositions with absent or weak warrant are accepted as admissible by crossing architecturally trusted interfaces. The paper introduces the Theorem of Inevitable Self-Licensing, showing that circular epistemic justification cannot be eliminated under standard architectural assumptions. The Warrant Erosion Principle is presented as the fundamental explanation for this effect, demonstrating that scaling, model improvement, and LLM-as-judge schemes cannot eliminate this type-level problem.",3.72,59.452,221,cold_start,Phi-4,Apple_M1(Metal)
2601.08360v1_Scalable Sequential Recommendation under Latency a.pdf,Scalable Sequential Recommendation under Latency and Memory Constraints,"Adithya Parthasarathy, Aswathnarayan Muthukrishnan Kirubakaran, Vinoth Punniyamoorthy, Nachiappan Chockalingam, Lokesh Butra, Kabilan Kannan, Abhirup Mazumder, Sumit Saha",,2601.08360v1,"Recommender Systems, Sequence Modeling, Representation Learning, Scalable Machine Learning, Deep Learning","Sequential recommender systems must model long-range user behavior while operating under strict memory and latency constraints. Transformer-based approaches achieve strong accuracy but suffer from quadratic attention complexity, forcing aggressive truncation of user histories and limiting their practicality for long-horizon modeling. This paper presents HoloMambaRec, a lightweight sequential recommendation architecture that combines holographic reduced representations for attribute-aware embedding with a selective state space encoder for linear-time sequence processing. Item and attribute information are bound using circular convolution, preserving embedding dimensionality while encoding structured metadata. A shallow selective state space backbone, inspired by recent Mamba-style models, enables efficient training and constant-time recurrent inference. Experiments on Amazon Beauty and MovieLens-1M datasets demonstrate that HoloMambaRec consistently outperforms SASRec and achieves competitive performance with GRU4Rec under a constrained 10-epoch training budget, while maintaining substantially lower memory complexity. The design further incorporates forward-compatible mechanisms for temporal bundling and inference-time compression, positioning HoloMambaRec as a practical and extensible alternative for scalable, metadata-aware sequential recommendation.",3.89,99.404,387,cold_start,Phi-4,Apple_M1(Metal)
2601.08371v1_Geo-NVS-w Geometry-Aware Novel View Synthesis In-t.pdf,Geo-NVS-w: Geometry-Aware Novel View Synthesis In-the-Wild with an SDF Renderer,"Anastasios Tsalakopoulos, Angelos Kanlis, Evangelos Chatzis, Antonis Karakottas, Dimitrios Zarpalas",,,"novel view synthesis, geometry-aware, in-the-wild, Signed Distance Function (SDF), geometry preservation, energy efficiency","Geo-NVS-w is a geometry-aware framework for high-fidelity novel view synthesis from unstructured, in-the-wild image collections. It leverages a Signed Distance Function (SDF) to guide the rendering process and introduces a Geometry-Preservation Loss to maintain fine structural details. The framework achieves competitive rendering performance with a significant reduction in energy consumption compared to similar methods, producing photorealistic results with sharp, geometrically coherent details.",2.94,78.484,231,cold_start,Phi-4,Apple_M1(Metal)
2601.08379v1_Training-Free Distribution Adaptation for Diffusio.pdf,Training-Free Distribution Adaptation for Diffusion Models via Maximum Mean Discrepancy Guidance,"Matina Mahdizadeh Sani, Nima Jamali, Mohammad Jalali, Farzan Farnia",,,"diffusion models, distribution adaptation, Maximum Mean Discrepancy, inference-time guidance, latent diffusion models","Pre-trained diffusion models are powerful generative priors for sample generation, but often deviate from user-specific target data characteristics, especially in domain adaptation tasks with limited reference examples. Existing inference-time guidance methods optimize surrogate objectives rather than directly aligning with the target distribution. This paper proposes MMD Guidance, a training-free mechanism that augments the reverse diffusion process with gradients of the Maximum Mean Discrepancy (MMD) between generated samples and a reference dataset. MMD provides reliable distributional estimates from limited data, exhibits low variance, and is efficiently differentiable, making it well-suited for guidance tasks. The framework extends to prompt-aware adaptation in conditional generation models and can be applied efficiently in latent diffusion models (LDMs) by applying guidance in the latent space. Experiments demonstrate that MMD Guidance achieves distributional alignment while preserving sample fidelity.",3.57,82.635,295,cold_start,Phi-4,Apple_M1(Metal)
2601.08380v1_Thematic Working Group 5 -- Artificial Intelligenc.pdf,EDUsummIT 2025 - eBook: Thematic Working Group 5 - Artificial Intelligence (AI) literacy for teaching and learning: design and implementation,"Mary Webb, Matt Bower, Ana Amélia Carvalho, Fredrik Mørk Røkenes, Jodie Torrington, Jonathan D. Cohen, Yousra Chtouki, Kathryn MacCallum, Tanya Linden, Deirdre Butler, Juliana E. Raffagheli, Henriikka Vartiainen, Martina Ronci, Peter Tiernan, David M. Smith, Chris Shelton, Joyce Malyn-Smith, Pierre Gorissen",,,"AI literacy, teaching and learning, curriculum design, professional development, classroom applications, policy guidelines, generative AI, academic integrity, creativity, agency, critical thinking","Thematic Working Group 5 focused on developing and implementing effective strategies for enhancing AI literacy and agency of teachers, equipping them with the knowledge and skills necessary to integrate AI into their teaching practices. The group explored curriculum design, professional development programs, practical classroom applications, and policy guidelines to empower educators to confidently utilize AI tools and foster a deeper understanding of AI concepts among students. The release of ChatGPT3 in November 2022 marked a significant advancement in AI, raising concerns around plagiarism, academic integrity, and potential impacts on creativity, agency, and critical thinking, while also offering new educational opportunities.",3.83,91.616,351,cold_start,Phi-4,Apple_M1(Metal)
2601.08382v2_A Qualitative Model to Reason about Object Rotatio.pdf,A Qualitative Model to Reason about Object Rotations – applied to solve the Cube Comparison Test,Zoe Falomira,,,"cube comparison test, mental rotation, qualitative reasoning, spatial cognition, spatial reasoning",This paper presents a Qualitative model for Reasoning about Object Rotations (QOR) applied to solve the Cube Comparison Test (CCT) by Ekstrom et al. (1976). A conceptual neighborhood graph relating the Rotation movement to the Location change and the Orientation change (CN GRLO) of the features on the cube sides has been built and it produces composition tables to calculate inferences for reasoning about rotations. The paper discusses the importance of spatial reasoning skills in various fields and how qualitative models can be used to represent knowledge and reason in spatial reasoning tests. It also introduces a new qualitative descriptor for reasoning about object rotations and its implementation in an interactive version of the Cube Comparison Test.,3.09,74.99,232,cold_start,Phi-4,Apple_M1(Metal)
2601.08383v1_Deconstructing Pre-training Knowledge Attribution .pdf,Deconstructing Pre-training: Knowledge Attribution Analysis in MoE and Dense Models,"Bo Wang, Junzhuo Li, Hong Chen, Yuanlin Chu, Yuxuan Fan, Xuming Hu",,,"Mixture-of-Experts, MoE, Dense Models, Knowledge Acquisition, Pre-training, Log-Probability Increase, Neuron Attribution, Interpretability","Mixture-of-Experts (MoE) architectures decouple model capacity from per-token computation, enabling scaling beyond the computational limits imposed by dense scaling laws. This study introduces Gated-LPI, a neuron-level attribution metric, to compare knowledge acquisition dynamics in MoE and dense architectures. Experiments reveal three patterns: a low-entropy backbone in MoE, early consolidation of importance profiles, and functional robustness due to sparsity. These findings suggest that sparsity fosters a stable and distributed computational backbone, enhancing training-time interpretability.",3.12,79.518,248,cold_start,Phi-4,Apple_M1(Metal)
2601.08388v1_Creativity in AI as Emergence from Domain-Limited .pdf,Creativity in AI as Emergence from Domain-Limited Generative Models,Corina Chutaux,,,"creativity, artificial intelligence, generative models, pattern recombination, multimodal architectures, emergent property, domain-limited generative models","This paper proposes a generative perspective on creativity in AI, framing it as an emergent property of domain-limited generative models embedded within bounded informational environments. It introduces a conceptual decomposition of creativity into four interacting components: pattern-based generation, induced world models, contextual grounding, and arbitrariness. The paper examines how these components manifest in multimodal generative systems, aiming to provide a technical framework for studying creativity as an emergent phenomenon in AI systems, rather than as a post hoc evaluative label.",3.11,60.467,188,cold_start,Phi-4,Apple_M1(Metal)
2601.08393v1_Controlled LLM Training on Spectral Sphere.pdf,Controlled LLM Training on Spectral Sphere,"Tian Xie, Haoming Luo, Haoyu Tang, Yiwen Hu, Jason Klein, Liu Qingnan, Ren, Yang Wang, Wayne Xin Zhao, Rui Yan, Bing Su, Chong Luo, Baining Guo",,arXiv:2601.08393v1,"optimization, large models, spectral sphere optimizer, µP, Muon, AdamW, Megatron, pretraining, DenseNet, MoE, DeepNet, activation control, stability","Scaling large models requires optimization strategies that ensure rapid convergence grounded in stability. Maximal Update Parametrization (µP) provides a theoretical safeguard for width-invariant activation control, whereas emerging optimizers like Muon are only 'half-aligned' with these constraints: they control updates but allow weights to drift. To address this limitation, we introduce the Spectral Sphere Optimizer (SSO), which enforces strict module-wise spectral constraints on both weights and their updates. By deriving the steepest descent direction on the spectral sphere, SSO realizes a fully µP-aligned optimization process. To enable large-scale training, we implement SSO as an efficient parallel algorithm within Megatron. Through extensive pretraining on diverse architectures, including Dense 1.7B, MoE 8B-A1B, and 200-layer DeepNet models, SSO consistently outperforms AdamW and Muon. Furthermore, we observe significant practical stability benefits, including improved MoE router load balancing, suppressed outliers, and strictly bounded activations.",3.9,106.234,414,cold_start,Phi-4,Apple_M1(Metal)
2601.08401v1_An Explainable Two Stage Deep Learning Framework f.pdf,An Explainable Two-Stage Deep Learning Framework for Pericoronitis Assessment in Panoramic Radiographs Using YOLOv8 and ResNet-50,"Ajo Babu George, Pranav S, Kunal Agarwal",,2601.08401v1,"AI-assisted assessment, pericoronitis, panoramic radiographs, YOLOv8, ResNet-50, Grad-CAM, deep learning, explainable AI","The study presents a two-stage deep learning framework to diagnose pericoronitis using panoramic radiographs. The first stage employs YOLOv8 for detecting third molars and classifying their anatomical positions, while the second stage uses a modified ResNet-50 to identify radiographic features indicative of pericoronitis. Grad-CAM is utilized to enhance interpretability by highlighting diagnostic regions. The system achieved high precision and F1-scores, with radiologists confirming the clinical relevance of the interpretability output, demonstrating strong potential for AI-assisted panoramic assessment.",3.73,71.764,268,cold_start,Phi-4,Apple_M1(Metal)
2601.08402v1_PATS Personality-Aware Teaching Strategies with La.pdf,PATS: Personality-Aware Teaching Strategies with Large Language Model Tutors,"Donya Rooein, Sankalan Pal Chowdhury, Mariia Eremeeva, Yuan Qin, Debora Nozza, Mrinmaya Sachan, Dirk Hovy",,,"Large Language Models, Educational Tutors, Personality Traits, Teaching Strategies, Intelligent Tutoring Systems","Recent advances in large language models (LLMs) demonstrate their potential as educational tutors. However, different tutoring strategies benefit different student personalities, and mismatches can be counterproductive to student outcomes. Current LLM tutoring systems do not take into account student personality traits. This study constructs a taxonomy linking pedagogical methods to personality profiles, based on pedagogical literature. Simulated student-teacher conversations are used to adjust LLM tutor strategies to the simulated student personality. Evaluation with human teachers shows a preference for this approach over baselines, increasing the use of less common, high-impact strategies such as role-playing. The findings pave the way for more personalized and effective LLM use in educational applications.",3.26,86.845,283,cold_start,Phi-4,Apple_M1(Metal)
2601.08403v1_Owen-Shapley Policy Optimization OSPO A Principled.pdf,Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for Generative Search LLMs,"Abhijnan Nath, Alireza Bagheri Garakani, Tianchen Zhou, Fan Yang, Nikhil Krishnaswamy",,,"Large language models, Reinforcement learning, Recommendation systems, Policy optimization, Shapley values, Generative search, Latent user intent, Reward shaping","Large language models are increasingly trained via reinforcement learning for personalized recommendation tasks. Standard methods like GRPO rely on sparse, sequence-level rewards, creating a credit assignment gap that obscures which tokens drive success. This gap is problematic when models must infer latent user intent from under-specified language without ground truth labels. The paper introduces OWEN-SHAPLEY POLICY OPTIMIZATION (OSPO), a framework that redistributes sequence-level advantages based on tokens' marginal contributions to outcomes. OSPO employs potential-based reward shaping via Shapley-Owen attributions to assign segment-level credit while preserving the optimal policy, directly from task feedback without parametric value models. Experiments on Amazon ESCI and H&M Fashion datasets show consistent gains over baselines, with notable test-time robustness to out-of-distribution retrievers unseen during training.",3.44,92.942,320,cold_start,Phi-4,Apple_M1(Metal)
2601.08406v1_WebTrap Park An Automated Platform for Systematic .pdf,WebTrap Park: An Automated Platform for Systematic Security Evaluation of Web Agents,"Xinyi Wu, Jiagui Chen, Geng Hong, Jiayi Dong, Xudong Pan, Jiarun Dai, Min Yang",,,"Web Agents, Security Evaluation, Automated Platform, Security Risks, Agent Frameworks","Web Agents are increasingly deployed to perform complex tasks in real web environments, yet their security evaluation remains fragmented and difficult to standardize. This paper presents WebTrapPark, an automated platform for systematic security evaluation of Web Agents through direct observation of their concrete interactions with live web pages. WebTrapPark instantiates three major sources of security risk into 1,226 executable evaluation tasks and enables action-based assessment without requiring agent modification. The results reveal clear security differences across agent frameworks, highlighting the importance of agent architecture beyond the underlying model. WebTrapPark is publicly accessible and provides a scalable foundation for reproducible Web Agent security evaluation.",3.38,75.112,254,cold_start,Phi-4,Apple_M1(Metal)
2601.08412v1_Hybrid Distillation with CoT Guidance for Edge-Dro.pdf,Hybrid Distillation with CoT Guidance for Edge-Drone Control Code Generation,"Yizhan Feng, Hichem Snoussi, Yuhang Wang, Jing Teng, Abel Cherouat, Tian Wang",,,"Large language models, drone, Knowledge Distillation, Chain-of-Thought, Lightweight","With large language models demonstrating significant potential in code generation tasks, their application to onboard control of resource-constrained Unmanned Aerial Vehicles has emerged as an important research direction. However, a notable contradiction exists between the high resource consumption of large models and the real-time, lightweight requirements of UAV platforms. This paper proposes an integrated approach that combines knowledge distillation, chain-of-thought guidance, and supervised fine-tuning for UAV multi-SDK control tasks, aiming to efficiently transfer complex reasoning and code generation capabilities to smaller models. Firstly, a high-quality dataset covering various mainstream UAV SDKs is constructed, featuring instruction-code-reasoning chains, and incorporates counterfactual negative samples for data augmentation, guiding the model to learn the end-to-end logic from instruction parsing to code generation. Secondly, leveraging DeepSeek-Coder-V2-Lite quantized via QLoRA as the teacher model, and based on a hybrid black-box and white-box distillation strategy, high-quality chain-of-thought soft labels are generated. These are combined with a weighted cross-entropy loss using hard labels to transfer complex reasoning capabilities to the smaller student model. Finally, through prompt tuning engineering optimized for the UAV control scenario, the model's performance on core tasks such as SDK type recognition and function call matching is enhanced. Experimental results indicate that the distilled lightweight model (parameters ≤ 1B) maintains high code generation accuracy while achieving significant improvements in deployment and inference efficiency, effectively demonstrating the feasibility and superiority of our approach in achieving precise and lightweight intelligent control for UAVs.",3.82,114.513,437,cold_start,Phi-4,Apple_M1(Metal)
2601.08415v2_Regulatory gray areas of LLM Terms.pdf,Regulatory gray areas of LLM Terms,"Brittany I. Davidson, Kate Muir, Florian A.D. Burnat, Adam N. Joinson",,2601.08415v2,"Language Models, LLMs, Privacy Policy, Terms of Service, Regulation","Large Language Models (LLMs) are increasingly integrated into academic research pipelines; however, the Terms of Service governing their use remain under-examined. This paper presents a comparative analysis of the Terms of Service of five major LLM providers (Anthropic, DeepSeek, Google, OpenAI, and xAI) collected in November 2025. The analysis reveals substantial variation in the stringency and specificity of usage restrictions for general users and researchers. It identifies specific complexities for researchers in security research, computational social sciences, and psychological studies, and identifies ‘regulatory gray areas’ where Terms of Service create uncertainty for legitimate use. The paper contributes a publicly available resource comparing terms across platforms (OSF) and discusses implications for general users and researchers navigating this evolving landscape.",3.69,72.583,268,cold_start,Phi-4,Apple_M1(Metal)
2601.08418v1_Taxon Hierarchical Tax Code Prediction with Semant.pdf,Taxon: Hierarchical Tax Code Prediction with Semantically Aligned LLM Expert Guidance,"Jihang Li, Qing Liu, Zulong Chen, Jing Wang, Wei Wang, Chuanfei Xu, Zeyi Wen",,,"tax code prediction, hierarchical taxonomy, large language models, e-commerce, compliance management, feature-gating mixture-of-experts, semantic consistency model","Tax code prediction is a crucial yet underexplored task in automating invoicing and compliance management for large-scale e-commerce platforms. Each product must be accurately mapped to a node within a multi-level taxonomic hierarchy defined by national standards, where errors lead to financial inconsistencies and regulatory risks. This paper presents Taxon, a semantically aligned and expert-guided framework for hierarchical tax code prediction. Taxon integrates a feature-gating mixture-of-experts architecture that adaptively routes multi-modal features across taxonomy levels, and a semantic consistency model distilled from large language models acting as domain experts to verify alignment between product titles and official tax definitions. To address noisy supervision in real business records, a multi-source training pipeline is designed that combines curated tax databases, invoice validation logs, and merchant registration data to provide both structural and semantic supervision. Extensive experiments on the proprietary TaxCode dataset and public benchmarks demonstrate that Taxon achieves state-of-the-art performance, outperforming strong baselines. An additional full hierarchical paths reconstruction procedure significantly improves structural consistency, yielding the highest overall F1 scores. Taxon has been deployed in production within Alibaba’s tax service system, handling an average of over 500,000 tax code queries per day and reaching peak volumes above five million requests during business events with improved accuracy, interpretability, and robustness.",3.59,114.313,410,cold_start,Phi-4,Apple_M1(Metal)
2601.08430v1_RubricHub A Comprehensive and Highly Discriminativ.pdf,RubricHub: A Comprehensive and Highly Discriminative Rubric Dataset via Automated Coarse-to-Fine Generation,"Sunzhu Li, Jiale Zhao, Miteto Wei, Huimin Ren, Yang Zhou, Jingwen Yang, Shunyu Liu, Kaike Zhang, Wei Chen",,,"Reinforcement Learning, Rubric-based Evaluation, Large Language Models, Coarse-to-Fine Generation, RubricHub Dataset","Reinforcement Learning with Verifiable Rewards (RLVR) has significantly advanced reasoning-intensive domains like mathematics. However, optimizing open-ended generation remains challenging due to the absence of ground truth. Existing rubric-based evaluation methods face scalability issues and coarse criteria, leading to a supervision ceiling effect. This paper introduces an automated Coarse-to-Fine Rubric Generation framework, which combines principle-guided synthesis, multi-model aggregation, and difficulty evolution to produce comprehensive and highly discriminative criteria. The resulting RubricHub dataset, comprising approximately 110,000 entries across multiple domains, is validated through a two-stage post-training pipeline involving Rubric-based Rejection Sampling Fine-Tuning (RuFT) and Reinforcement Learning (RuRL). Experimental results show that RubricHub enables significant performance improvements, with the post-trained Qwen3-14B achieving state-of-the-art results on HealthBench (69.3), surpassing proprietary models like GPT-5. The code and data will be released soon.",3.49,101.193,353,cold_start,Phi-4,Apple_M1(Metal)
2601.08434v3_Large Multimodal Models for Embodied Intelligent D.pdf,Large Multimodal Models for Embodied Intelligent Driving: The Next Frontier in Self-Driving?,"Long Zhang, Yuchen Xia, Bingqing Wei, Zhen Liu, Shiwen Mao, Zhu Han, Mohsen Guizani",,,"Large Multimodal Models, Embodied Intelligent Driving, Autonomous Driving, Semantic Understanding, Deep Reinforcement Learning, Policy Optimization, Environmental Understanding, Logical Reasoning","The article discusses the potential of Large Multimodal Models (LMMs) to address the limitations of modular design in autonomous driving, particularly in open-world scenarios requiring sustained environmental understanding and logical reasoning. It introduces a novel semantics and policy dual-driven hybrid decision framework that combines LMMs for semantic understanding and cognitive representation with deep reinforcement learning (DRL) for real-time policy optimization. The framework aims to enhance embodied intelligent (EI) driving by ensuring continuous learning and joint decision-making. The article outlines the foundational principles of EI driving and LMMs, explores emerging opportunities, and presents a case study validating the framework's performance in a lane-change planning task. Future research directions to empower EI driving are also identified.",3.49,84.136,294,cold_start,Phi-4,Apple_M1(Metal)
2601.08441v1_YaPO Learnable Sparse Activation Steering Vectors .pdf,YaPO: Learnable Sparse Activation Steering Vectors for Domain Adaptation,"Abdelaziz Bounhar, Rania Hossam Elmohamady Elbadry, Hadi Abdine, Preslav Nakov, Michalis Vazirgiannis, Guokan Shang",,,"Large Language Models, activation interventions, sparse steering vectors, domain adaptation, cultural alignment, Sparse Autoencoder, Direct Preference Optimization, Bi-directional Preference Optimization","The paper introduces Y aPO, a reference-free method for learning sparse steering vectors in the latent space of a Sparse Autoencoder (SAE). This approach aims to address the limitations of dense steering vectors, which often entangle multiple latent factors, by producing disentangled, interpretable, and efficient steering directions. Y aPO is shown to converge faster, achieve stronger performance, and exhibit improved training stability compared to dense steering baselines. It generalizes to various alignment-related behaviors and preserves general knowledge without degradation. The method offers a general recipe for efficient, stable, and fine-grained alignment of Large Language Models (LLMs), with broad applications to controllability and domain adaptation.",3.23,91.598,296,cold_start,Phi-4,Apple_M1(Metal)
2601.08444v1_Beyond Linearization Attributed Table Graphs for T.pdf,Beyond Linearization: Attributed Table Graphs for Table Reasoning,"Yuxiang Wang, Junhao Gan, Shengxiang Gao, Shenghao Ye, Zhengyi Yang, Jianzhong Qi",,,"table reasoning, Large Language Models, linearization, graph-based reasoning, explainability, Question-Guided Personalized PageRank","Table reasoning involves answering questions by reasoning over data in tables, a prevalent format for storing knowledge. Recent solutions use Large Language Models (LLMs) by linearizing tables into plain text, which has limitations such as loss of structure, lack of explainability, and the 'lost-in-the-middle' issue. This paper introduces the Table Graph Reasoner (TABGR), a model that represents tables as an Attributed Table Graph (ATG) to preserve structures and enable graph-based reasoning. A Question-Guided Personalized PageRank (QG-PPR) mechanism is proposed to rerank data and address the 'lost-in-the-middle' issue. Experiments show TABGR outperforms state-of-the-art models by up to 9.7% in accuracy.",3.17,92.572,293,cold_start,Phi-4,Apple_M1(Metal)
2601.08448v1_Divide and Conquer Static-Dynamic Collaboration fo.pdf,Divide and Conquer: Static-Dynamic Collaboration for Few-Shot Class-Incremental Learning,"Kexin Bao, Daichi Zhang, Yong Li, Dan Zeng, Shiming Ge",10.1145/3731715.3733310,,"Few-Shot Class-Incremental Learning, Class-Incremental Learning","Few-shot class-incremental learning (FSCIL) aims to continuously recognize novel classes under limited data, which suffers from the key stability-plasticity dilemma: balancing the retention of old knowledge with the acquisition of new knowledge. To address this issue, we divide the task into two different stages and propose a framework termed Static-Dynamic Collaboration (SDC) to achieve a better trade-off between stability and plasticity. Specifically, our method divides the normal pipeline of FSCIL into Static Retaining Stage (SRS) and Dynamic Learning Stage (DLS), which harnesses old static and incremental dynamic class information, respectively. During SRS, we train an initial model with sufficient data in the base session and preserve the key part as static memory to retain fundamental old knowledge. During DLS, we introduce an extra dynamic projector jointly trained with the previous static memory. By employing both stages, our method achieves improved retention of old knowledge while continuously adapting to new classes. Extensive experiments on three public benchmarks and a real-world application dataset demonstrate that our method achieves state-of-the-art performance against other competitors.",3.51,97.629,343,cold_start,Phi-4,Apple_M1(Metal)
2601.08450v1_Decoding Order Matters in Autoregressive Speech Sy.pdf,Decoding Order Matters in Autoregressive Speech Synthesis,"Minghui Zhao, Anton Ragni",,,"speech synthesis, discrete diffusion model, order-agnostic autoregressive decoding","This study investigates the impact of decoding order in autoregressive speech synthesis, traditionally performed in a left-to-right manner. Using a masked diffusion framework, the research explores various decoding orders, including random permutations and fixed strategies like left-to-right (l2r) and right-to-left (r2l). The findings suggest that fixed-order decoding, including the prevalent left-to-right approach, is suboptimal compared to adaptive decoding methods. The study also demonstrates that even 1-bit quantisation of acoustic representations can support high-quality speech synthesis. The research highlights the importance of considering alternative decoding orders to improve synthesis quality by better capturing speech dependencies.",2.99,68.491,205,cold_start,Phi-4,Apple_M1(Metal)
2601.08457v1_An Under-Explored Application for Explainable Mult.pdf,An Under-Explored Application for Explainable Multimodal Misogyny Detection in Code-Mixed Hindi-English,"Sargam Yadava, Abhishek Kaushik, Kevin Mc Daid",,,"hate speech, misogyny, natural language processing, code-mixing, Hinglish","Digital platforms have an ever-expanding user base, serving as hubs for communication, business, and connectivity. However, they also facilitate the spread of hate speech and misogyny. Artificial intelligence models have emerged as effective solutions for countering online hate speech but are under-explored for low-resource and code-mixed languages and suffer from a lack of interpretability. Explainable Artificial Intelligence (XAI) can enhance transparency in the decisions of deep learning models, which is crucial for sensitive domains such as hate speech detection. This paper presents a multi-modal and explainable web application for detecting misogyny in text and memes in code-mixed Hindi and English. The system leverages state-of-the-art transformer-based models that support multilingual and multimodal settings. For text-based misogyny identification, the system utilizes XLM-RoBERTa (XLM-R) and multilingual Bidirectional Encoder Representations from Transformers (mBERT) on a dataset of approximately 4,193 comments. For multimodal misogyny identification from memes, the system utilizes mBERT + EfficientNet, and mBERT + ResNET trained on a dataset of approximately 4,218 memes. It also provides feature importance scores using explainability techniques including Shapley Additive Values (SHAP) and Local Interpretable Model Agnostic Explanations (LIME). The application aims to serve as a tool for both researchers and content moderators, to promote further research in the field, combat gender-based digital violence, and ensure a safe digital space. The system has been evaluated using human evaluators who provided their responses on Chatbot Usability Questionnaire (CUQ) and User Experience Questionnaire (UEQ) to determine overall usability.",3.73,123.175,460,cold_start,Phi-4,Apple_M1(Metal)
2601.08462v1_M3-BENCH Process-Aware Evaluation of LLM Agents So.pdf,M3-BENCH: Process-Aware Evaluation of LLM Agents Social Behaviors in Mixed-Motive Games,"Sixiong Xie, Zhuofan Shi, Haiyang Shen, Gang Huang, Yun Ma, Xiang Jing",,,"large language model, social behaviors, mixed-motive games, evaluation framework, Big Five personality model, Social Exchange Theory","As large language model (LLM) agents' capabilities advance, their social behaviors such as cooperation, deception, and collusion require systematic evaluation. Existing benchmarks often focus on single capability dimensions or rely solely on behavioral outcomes, neglecting rich process information from agents' decision reasoning and communicative interactions. To address this, M3-BENCH, a multi-stage benchmark for mixed-motive games, is proposed along with a process-aware evaluation framework that analyzes Behavioral Trajectory Analysis (BTA), Reasoning Process Analysis (RPA), and Communication Content Analysis (CCA). The framework integrates the Big Five personality model and Social Exchange Theory to create interpretable social behavior portraits, characterizing agents' personality traits and capability profiles beyond simple task scores or outcome-based metrics. Experimental results show that M3-BENCH can reliably distinguish diverse social behavior competencies across models, revealing inconsistencies in reasoning and communication despite reasonable behavioral outcomes.",3.51,90.128,316,cold_start,Phi-4,Apple_M1(Metal)
2601.08464v1_CoMa Contextual Massing Generation with Vision-Lan.pdf,CoMa: Contextual Massing Generation with Vision-Language Models,"Evgenii Maslov, Valentin Khrulkov, Anastasia Volkova, Anton Gusarov, Andrey Kuznetsov, Ivan Oseledets",,2601.08464v1,"architecture, urban planning, building massing, Vision-Language Models, data-driven methods, dataset, conditional task","The conceptual design phase in architecture and urban planning, particularly building massing, is complex and heavily reliant on designer intuition and manual effort. To address this, we propose an automated framework for generating building massing based on functional requirements and site context. A primary obstacle to such data-driven methods has been the lack of suitable datasets. Consequently, we introduce the CoMa-20K dataset, a comprehensive collection that includes detailed massing geometries, associated economical and programmatic data, and visual representations of the development site within its existing urban context. We benchmark this dataset by formulating massing generation as a conditional task for Vision-Language Models (VLMs), evaluating both fine-tuned and large zero-shot models. Our experiments reveal the inherent complexity of the task while demonstrating the potential of VLMs to produce context-sensitive massing options. The dataset and analysis establish a foundational benchmark and highlight significant opportunities for future research in data-driven architectural design.",3.86,86.192,333,cold_start,Phi-4,Apple_M1(Metal)
2601.08468v1_JudgeRLVR Judge First Generate Second for Efficien.pdf,"JudgeRLVR: Judge First, Generate Second for Efficient Reasoning","Jiangshan Duo, Hanyu Li, Hailin Zhang, Yudong Wang, Sujian Li, Liang Zhao",,arXiv:2601.08468v1,"Reinforcement Learning, Verifiable Rewards, Large Language Models, Reasoning, Efficiency, Generalization","Reinforcement Learning with Verifiable Rewards (RLVR) is a standard paradigm for reasoning in Large Language Models. However, optimizing solely for final-answer correctness often leads models to engage in verbose, aimless exploration rather than structured planning. This paper introduces JudgeRLVR, a two-stage judge-then-generate paradigm. In the first stage, the model is trained to judge solution responses with verifiable answers. In the second stage, the model is fine-tuned with vanilla generating RLVR initialized from the judge. JudgeRLVR achieves a better quality–efficiency trade-off, demonstrating enhanced generalization on both in-domain and out-of-domain benchmarks.",3.51,76.599,269,cold_start,Phi-4,Apple_M1(Metal)
2601.08472v1_sui-1 Grounded and Verifiable Long-Form Summarizat.pdf,sui-1: Grounded and Verifiable Long-Form Summarization,"Benedikt Droste, Jan Philipp Harries, Maximilian Idahl, Björn Plüster",,arXiv:2601.08472v1,"long-form summarization, citation-grounded summarization, large language models, synthetic data generation, iterative processing","Large language models often produce unfaithful summaries that are difficult to verify against source texts, posing a challenge in compliance-sensitive areas. The sui-1 model, with 24B parameters, addresses this by generating abstractive summaries with inline citations, allowing users to trace claims to their source sentences. It processes documents up to 100K tokens in one pass and supports iterative processing for texts exceeding 2 million tokens. The model was trained using a synthetic data pipeline that combines chain-of-thought prompting with multi-stage verification, producing over 22,000 high-quality training examples in five languages. Evaluation shows sui-1 significantly outperforms open-weight baselines, demonstrating that task-specific training is more effective than increasing model scale alone. The model achieves 84% accuracy on LLM-as-a-judge evaluation, outperforming baselines with 3× more parameters. Model weights and an interactive demo are publicly available.",3.77,84.549,319,cold_start,Phi-4,Apple_M1(Metal)
2601.08475v1_SUMMPILOT Bridging Efficiency and Customization fo.pdf,SUMMPILOT: Bridging Efficiency and Customization for Interactive Summarization System,"JungMin Yun, Juhwan Choi, Kyohoon Jin, Soojin Jang, Jinhee Jang, YoungBin Kim",,,"interactive summarization, customizable summarization, large language models, semantic graphs, entity clustering, explainable evaluation","This paper introduces SUMMPILOT, an interaction-based customizable summarization system that combines the efficiency of automatic summarization with the ability to generate personalized summaries tailored to individual users' interests and requirements. SUMMPILOT leverages a large language model to facilitate both automatic and interactive summarization. Users can engage with the system through interactive components such as semantic graphs, entity clustering, and explainable evaluation to understand document content and personalize summaries. The system supports both single and multi-document summarization, addressing the challenge of representing content relationships and supporting decision-making by indicating how user inputs affect the final summary. The paper demonstrates SUMMPILOT's adaptability and usefulness through demos and user studies.",3.42,77.96,267,cold_start,Phi-4,Apple_M1(Metal)
2601.08490v1_BenchOverflow Measuring Overflow in Large Language.pdf,BenchOverflow: Measuring Overflow in Large Language Models via Plain-Text Prompts,"Erin Feiglin, Nir Hutnik, Raz Lapid",,2601.08490v1,"large language models, overflow, plain-text prompts, length control, model-agnostic benchmark, sustainability, cost efficiency","This paper investigates a failure mode in large language models (LLMs) where plain-text prompts cause excessive outputs, termed 'Overflow'. Unlike other issues like jailbreaks, Overflow occurs under normal interactions, leading to increased costs, latency, and performance degradation. The study introduces BenchOverflow, a benchmark for evaluating nine plain-text prompting strategies that increase output volume. Nine models are assessed, revealing significant variations in output length. A simple mitigation strategy, a fixed conciseness reminder, reduces excessive output across most models. The findings highlight the importance of length control for reliability, cost, and sustainability in LLMs.",3.46,71.034,246,cold_start,Phi-4,Apple_M1(Metal)
2601.08493v1_PKI Prior Knowledge-Infused Neural Network for Few.pdf,PKI: Prior Knowledge-Infused Neural Network for Few-Shot Class-Incremental Learning,"Kexin Bao, Fanzhao Lin, Zichen Wang, Yong Li, Dan Zeng, Shiming Ge",,2601.08493v1,"Few-shot class-incremental learning, catastrophic forgetting, overfitting, prior knowledge, neural network","Few-shot class-incremental learning (FSCIL) aims to continually adapt a model on a limited number of new-class examples, facing two well-known challenges: catastrophic forgetting and overfitting to new classes. Existing methods tend to freeze more parts of network components and finetune others with an extra memory during incremental sessions. These methods emphasize preserving prior knowledge to ensure proficiency in recognizing old classes, thereby mitigating catastrophic forgetting. Meanwhile, constraining fewer parameters can help in overcoming overfitting with the assistance of prior knowledge. Following previous methods, we retain more prior knowledge and propose a prior knowledge-infused neural network (PKI) to facilitate FSCIL. PKI consists of a backbone, an ensemble of projectors, a classifier, and an extra memory. In each incremental session, we build a new projector and add it to the ensemble. Subsequently, we finetune the new projector.",3.9,83.105,324,cold_start,Phi-4,Apple_M1(Metal)
2601.08499v2_EfficientFSL Enhancing Few-Shot Classification via.pdf,EfficientFSL: Enhancing Few-Shot Classification via Query-Only Tuning in Vision Transformers,"Wenwen Liao, Hang Ruan, Jianbo Yu, Bing Song, Yuansong Wang, Xiaofeng Yang",,,"Few-Shot Learning, Vision Transformers, Query-Only Tuning, EfficientFSL, Feature Extraction, Classification","Large models like Vision Transformers (ViTs) outperform smaller architectures in few-shot classification due to their strong representational capacity. However, fine-tuning these models is resource-intensive. This paper introduces EfficientFSL, a query-only fine-tuning framework for ViTs, which reduces computational overhead while maintaining competitive performance. EfficientFSL leverages pre-trained model knowledge with minimal trainable parameters, using a Forward Block for task-specific queries, a Combine Block for multi-layer output fusion, and a Support-Query Attention Block to address distribution shifts. It achieves state-of-the-art results on both in-domain and cross-domain few-shot datasets, demonstrating its practicality for real-world applications.",3.35,80.902,271,cold_start,Phi-4,Apple_M1(Metal)
2601.08503v1_Temporal Fusion Nexus A task-agnostic multi-modal .pdf,Temporal Fusion Nexus: A task-agnostic multi-modal embedding model for clinical narratives and irregular time series in post-kidney transplant care,"Aditya Kumar, Simon Rauch, Mario Cypko, Marcel Naik, Matthieu-P Schapranow, Aadil Rashid, Fabian Halleck, Bilgin Osmanodja, Roland Roller, Lars Pape, Klemens Budde, Mario Schiffer, Oliver Amft",,2601.08503v1,"clinical narratives, irregular time series, post-kidney transplant care, multi-modal embedding, machine learning, healthcare","We introduce Temporal Fusion Nexus (TFN), a multi-modal and task-agnostic embedding model to integrate irregular time series and unstructured clinical narratives. We analysed TFN in post-kidney transplant (KTx) care, with a retrospective cohort of 3382 patients, on three key outcomes: graft loss, graft rejection, and mortality. Compared to state-of-the-art model in post KTx care, TFN achieved higher performance for graft loss (AUC 0.96 vs. 0.94) and graft rejection (AUC 0.84 vs. 0.74). In mortality prediction, TFN yielded an AUC of 0.86. TFN outperformed unimodal baselines (≈10% AUC improvement over time series only baseline,≈5% AUC improvement over time series with static patient data). Integrating clinical text improved performance across all tasks. Disentanglement metrics confirmed robust and interpretable latent factors in the embedding space, and SHAP-based attributions confirmed alignment with clinical reasoning. TFN has potential application in clinical tasks beyond KTx.",4.06,107.452,436,cold_start,Phi-4,Apple_M1(Metal)
2601.08509v1_What If TSF A Benchmark for Reframing Forecasting .pdf,What If TSF: A Benchmark for Reframing Forecasting as Scenario-Guided Multimodal Forecasting,"Jinkwan Jang, Hyunbin Jin, Hyungjin Park, Kyubyung Chae, Taesup Kim",,,"time series forecasting, multimodal forecasting, large language models, scenario-guided forecasting, benchmark","Time series forecasting is critical for decision making, yet most approaches remain unimodal and rely on historical patterns. Recent advances in large language models (LLMs) show potential for multimodal forecasting, but existing benchmarks often provide retrospective or misaligned context. This paper introduces What If TSF (WIT), a multimodal forecasting benchmark designed to evaluate models' ability to condition forecasts on contextual text, especially future scenarios. WIT provides expert-crafted plausible or counterfactual scenarios, offering a rigorous testbed for scenario-guided multimodal forecasting.",3.23,73.741,238,cold_start,Phi-4,Apple_M1(Metal)
2601.08510v2_STAGE A Benchmark for Knowledge Graph Construction.pdf,"STAGE: A Benchmark for Knowledge Graph Construction, Question Answering, and In-Script Role-Playing over Movie Screenplays","Qiuyu Tian, Yiding Li, Fengyi Chen, Zequn Liu, Youyong Kong, Fan Guo, Yuyao Li, Jinjing Shen, Zhijing Xie, Yiyun Luo, Xin Zhang",,2601.08510v2,"knowledge graph, question answering, role-playing, movie screenplays, narrative understanding","Movie screenplays are rich, long-form narratives that interleave complex character relationships, temporally ordered events, and dialogue-driven interactions. While prior benchmarks target individual subtasks such as question answering or dialogue generation, they rarely evaluate whether models can construct a coherent story world and use it consistently across multiple forms of reasoning and generation. This paper introduces STAGE (Screenplay Text, Agents, Graphs & Evaluation), a unified benchmark for narrative understanding over full-length movie screenplays. STAGE defines four tasks: knowledge graph construction, scene-level event summarization, long-context screenplay question answering, and in-script character role-playing, all grounded in a shared narrative world representation. The benchmark provides cleaned scripts, curated knowledge graphs, and event- and character-centric data.",3.98,81.448,324,cold_start,Phi-4,Apple_M1(Metal)
2601.08519v1_CD2 Constrained Dataset Distillation for Few-Shot .pdf,CD2: Constrained Dataset Distillation for Few-Shot Class-Incremental Learning,"Kexin Bao, Daichi Zhang, Hansong Zhang, Yong Li, Yutao Yue, Shiming Ge",,,"Few-shot class-incremental learning, Catastrophic forgetting, Dataset distillation, Knowledge transfer","Few-shot class-incremental learning (FSCIL) aims to perform classification continuously with a few training samples, facing the challenge of catastrophic forgetting. Existing methods use external memory to store previous knowledge but fail to preserve essential knowledge adequately. This paper introduces Constrained Dataset Distillation (CD2) for FSCIL, comprising a dataset distillation module (DDM) and a distillation constraint module (DCM). The DDM synthesizes condensed samples to help the model learn essential class-related clues from few samples, while the DCM uses a designed loss to preserve previously learned class distribution. Extensive experiments on three public datasets demonstrate the superiority of CD2 over state-of-the-art methods.",3.32,79.619,264,cold_start,Phi-4,Apple_M1(Metal)
2601.08531v1_Sketch-Based Facade Renovation With Generative AI .pdf,Sketch-Based Facade Renovation With Generative AI Models: A Streamlined Framework for Bypassing As-Built Modelling in Industrial Adaptive Reuse,"Warissara Booranamaitree, Xusheng Du, Yushu Cai, Zhengyang Wang, Ye Zhang, Haoran Xie",,,"Industrial building renovation, vision-language model, diffusion model, user sketches, facade renovation","Facade renovation offers a more sustainable alternative to full demolition, yet producing design proposals that preserve existing structures while expressing new intent remains challenging. Current workflows typically require detailed as-built modelling before design, which is time-consuming, labour-intensive, and often involves repeated revisions. To solve this issue, we propose a three-stage framework combining generative artificial intelligence (AI) and vision-language models (VLM) that directly processes rough structural sketch and textual descriptions to produce consistent renovation proposals. First, the input sketch is used by a fine-tuned VLM model to predict bounding boxes specifying where modifications are needed and which components should be added. Next, a stable diffusion model generates detailed sketches of new elements, which are merged with the original outline through a generative inpainting pipeline. Finally, ControlNet is employed to refine the result into a photorealistic image. Experiments on datasets and real industrial buildings indicate that the proposed framework can generate renovation proposals that preserve the original structure while improving facade detail quality. This approach effectively bypasses the need for detailed as-built modelling, enabling architects to rapidly explore design alternatives, iterate on early-stage concepts, and communicate renovation intentions with greater clarity.",3.88,90.482,351,cold_start,Phi-4,Apple_M1(Metal)
2601.08545v2_Learner-Tailored Program Repair A Solution Generat.pdf,Learner-Tailored Program Repair: A Solution Generator with Iterative Edit-Driven Retrieval Enhancement,"Zhenlong Dai, Zhuoluo Zhao, Hengning Wang, Xiu Tang, Sai Wu, Chang Yao, Zhipeng Gao, Jingyuan Chen",,,"program repair, large language models, intelligent programming coaching, bug description, solution generator, iterative retrieval enhancement","With the development of large language models (LLMs) in programming, intelligent programming coaching systems have gained widespread attention. However, most research focuses on repairing the buggy code of programming learners without providing the underlying causes of the bugs. To address this gap, we introduce a novel task, namely LPR (Learner-Tailored Program Repair). We then propose a novel and effective framework, LSGEN (Learner-Tailored Solution Generator), to enhance program repair while offering bug descriptions for the buggy code. In the first stage, we utilize a repair solution retrieval framework to construct a solution retrieval database and then employ an edit-driven code retrieval approach to retrieve valuable solutions, guiding LLMs in identifying and fixing the bugs in buggy code. In the second stage, we propose a solution-guided program repair method, which fixes the code and provides explanations under the guidance of retrieval solutions. Moreover, we propose an Iterative Retrieval Enhancement method that utilizes evaluation results of the generated code to iteratively optimize the retrieval direction and explore more suitable repair strategies, improving performance in practical programming coaching scenarios. The experimental results show that our approach outperforms a set of baselines by a large margin, validating the effectiveness of our framework for the newly proposed LPR task.",3.61,112.071,405,cold_start,Phi-4,Apple_M1(Metal)
2601.08549v1_Contrastive and Multi-Task Learning on Noisy Brain.pdf,Contrastive and Multi-Task Learning on Noisy Brain Signals with Nonlinear Dynamical Signatures,"Sucheta Ghosh, Zahra Monfared, Felix Dietrich",,,"EEG, Brain-Computer Interfaces, Motor Imagery, Denoising, Dynamical Modeling, Representation Learning, Contrastive Learning, Lyapunov Exponents, Convolutional-Transformer Backbone","This paper introduces a two-stage multitask learning framework for analyzing EEG signals, integrating denoising, dynamical modeling, and representation learning. The first stage involves a denoising autoencoder to suppress artifacts and stabilize temporal dynamics. The second stage employs a multitask architecture to achieve motor imagery classification, chaotic versus non-chaotic regime discrimination, and self-supervised contrastive representation learning. The framework uses a convolutional-Transformer backbone to capture spatial-temporal structures and improve robustness and generalization in EEG decoding, outperforming strong baselines and recent state-of-the-art methods.",3.35,77.856,261,cold_start,Phi-4,Apple_M1(Metal)
2601.08557v1_VideoHEDGE Entropy-Based Hallucination Detection f.pdf,VideoHEDGE: Entropy-Based Hallucination Detection for Video-VLMs via Semantic Clustering and Spatiotemporal Perturbations,"Sushant Gautam, Cise Midoglu, Vajira Thambawita, Michael A. Riegler, Pål Halvorsen",,,"hallucination detection, video question answering, entropy-based reliability estimation, semantic clustering, spatiotemporal perturbations, vision-language models","Hallucinations in video-capable vision-language models (Video-VLMs) remain frequent and high-confidence, while existing uncertainty metrics often fail to align with correctness. This paper introduces VideoHEDGE, a modular framework for hallucination detection in video question answering that extends entropy-based reliability estimation from images to temporally structured inputs. Given a video-question pair, VideoHEDGE draws a baseline answer and multiple high-temperature generations from both clean clips and perturbed variants, then clusters the resulting textual outputs into semantic hypotheses using either Natural Language Inference (NLI)-based or embedding-based methods. Cluster-level probability masses yield three reliability scores: Semantic Entropy (SE), RadFlag, and Vision-Amplified Semantic Entropy (VASE). The framework is evaluated on the SoccerChat benchmark using an LLM-as-a-judge to obtain binary hallucination labels. Across three 7B Video-VLMs, VASE consistently achieves the highest ROC-AUC, especially at larger distortion budgets, while SE and RadFlag often operate near chance. Embedding-based clustering matches NLI-based clustering in detection performance at substantially lower computational cost, and domain fine-tuning reduces hallucination frequency but yields only modest improvements in calibration. The hedge-bench PyPI library enables reproducible and extensible benchmarking, with full code and experimental resources available at https://github.com/Simula/HEDGE#videohedge.",3.69,111.485,411,cold_start,Phi-4,Apple_M1(Metal)
2601.08559v1_WaterCopilot An AI-Driven Virtual Assistant for Wa.pdf,WaterCopilot: An AI-Driven Virtual Assistant for Water Management,"Keerththanan Vickneswaran, Mariangel Garcia Andarcia, Hugo Retief, Chris Dickens, Paulo Silva",,,"Water resource management, Retrieval-Augmented Generation (RAG), Limpopo River Basin, Azure AI, Real-time APIs, Multilingual chatbots, Digital Twin, AWS deployment, RAGAS evaluation","Sustainable water resource management in transboundary river basins is challenged by fragmented data, limited real-time access, and the complexity of integrating diverse information sources. This paper presents WaterCopilot—an AI-driven virtual assistant developed through collaboration between the International Water Management Institute (IWMI) and Microsoft Research for the Limpopo River Basin (LRB) to bridge these gaps through a unified, interactive platform. Built on Retrieval-Augmented Generation (RAG) and tool-calling architectures, WaterCopilot integrates static policy documents and real-time hydrological data via two custom plugins: the iwmi-doc-plugin, which enables semantic search over indexed documents using Azure AI Search, and the iwmi-api-plugin, which queries live databases to deliver dynamic insights such as environmental-flow alerts, rainfall trends, reservoir levels, water accounting, and irrigation data. The system features guided multilingual interactions (English, Portuguese, French), transparent source referencing, automated calculations, and visualization capabilities. Evaluated using the RAGAS framework, WaterCopilot achieves an overall score of 0.8043, with high answer relevancy (0.8571) and context precision (0.8009). Key innovations include automated threshold-based alerts, integration with the LRB Digital Twin, and a scalable deployment pipeline hosted on AWS. While limitations in processing non-English technical documents and API latency remain, WaterCopilot establishes a replicable AI-augmented framework for enhancing water governance in data-scarce, transboundary contexts. The study demonstrates the potential of this AI assistant to support informed, timely decision-making and strengthen water security in complex river basins.",3.99,119.728,478,cold_start,Phi-4,Apple_M1(Metal)
2601.08565v1_Rewriting Video Text-Driven Reauthoring of Video F.pdf,Rewriting Video: Text-Driven Reauthoring of Video Footage,"Sitong Wang, Anh Truong, Lydia B. Chilton, Dingzeyu Li",,,"Video reauthoring, Text-driven video editing, Generative video models, Creative AI tools","Video is a powerful medium for communication and storytelling, yet reauthoring existing footage remains challenging. This paper presents a text-driven video reauthoring approach, involving a generative reconstruction algorithm that reverse-engineers video into an editable text prompt and an interactive probe, Rewrite Kit, for manipulating these prompts. The study with 12 creators reveals novel use cases and highlights tensions around coherence, control, and creative alignment. The work provides empirical insights into the opportunities and challenges of text-driven video reauthoring, offering design implications for future co-creative video tools.",3.25,68.227,222,cold_start,Phi-4,Apple_M1(Metal)
2601.08602v1_WaveFormer Frequency-Time Decoupled Vision Modelin.pdf,WaveFormer: Frequency-Time Decoupled Vision Modeling with Wave Equation,"Zishan Shu, Juntong Wu, Wei Yan, Xudong Liu, Hongyu Zhang, Chang Liu, Youdong Mao, Jie Chen",,,"Vision Modeling, Transformers, Wave Equation, Wave Propagation Operator, WaveFormer, Image Classification, Object Detection, Semantic Segmentation, Partial Differential Equations","Vision modeling has advanced rapidly with Transformers, whose attention mechanisms capture visual dependencies but lack a principled account of how semantic information propagates spatially. This paper revisits this problem from a wave-based perspective, treating feature maps as spatial signals governed by an underdamped wave equation. The spatial frequency is modeled explicitly, and its interaction with propagation time is controlled. A closed-form, frequency–time decoupled solution is derived and implemented as the Wave Propagation Operator (WPO), a lightweight module that models global interactions in O(NlogN) time. WaveFormer models, based on WPO, are proposed as replacements for standard ViTs and CNNs, achieving competitive accuracy and higher throughput with fewer FLOPs. The results demonstrate that wave propagation introduces a complementary modeling bias to heat-based methods, capturing both global coherence and high-frequency details essential for rich visual semantics.",3.43,95.624,328,cold_start,Phi-4,Apple_M1(Metal)
2601.08605v1_ExpSeek Self-Triggered Experience Seeking for Web .pdf,ExpSeek: Self-Triggered Experience Seeking for Web Agents,"Wenyuan Zhang, Xinghua Zhang, Haiyang Yu, Shuaiyi Nie, Bingli Wu, Juwei Yue, Tingwen Liu, Yongbin Li",,,"web agents, experience intervention, entropy thresholds, large language models, multi-turn interactions, web environment","Experience intervention in web agents is a promising paradigm that enhances agent interaction capabilities by providing insights from accumulated experiences. Traditional methods inject experience passively before task execution, which struggles to adapt to dynamically changing contexts during agent-environment interaction. This paper proposes ExpSeek, which shifts experience toward step-level proactive seeking by estimating step-level entropy thresholds to determine intervention timing and designing step-level tailor-designed experience content. Experiments on Qwen3-8B and 32B models across four web agent benchmarks show absolute improvements of 9.3% and 7.5%, respectively. The feasibility and advantages of using entropy as a self-triggering signal are validated, and even a 4B small-scale experience model can significantly boost the performance of larger agent models.",3.31,87.087,288,cold_start,Phi-4,Apple_M1(Metal)
2601.08611v1_VeriTaS The First Dynamic Benchmark for Multimodal.pdf,VERITAS: The First Dynamic Benchmark for Multimodal Automated Fact-Checking,"Mark Rothermel, Marcus Kornmann, Marcus Rohrbach, Anna Rohrbach",,,"Automated Fact-Checking, Multimodal AI, Misinformation, Benchmark, VERITAS","The growing scale of online misinformation urgently demands Automated Fact-Checking (AFC). Existing benchmarks for evaluating AFC systems are largely limited in terms of task scope, modalities, domain, language diversity, realism, or coverage of misinformation types. Critically, they are static, thus subject to data leakage as their claims enter the pretraining corpora of LLMs. As a result, benchmark performance no longer reliably reflects the actual ability to verify claims. We introduce Verified Th...",2.69,77.434,208,cold_start,Phi-4,Apple_M1(Metal)
2601.08620v1_ViDoRe V3 A Comprehensive Evaluation of Retrieval .pdf,ViDoRe V3: A Comprehensive Evaluation of Retrieval Augmented Generation in Complex Real-World Scenarios,"António Loison, Quentin Macé, Antoine Edy, Victor Xing, Tom Balough, Gabriel Moreira, Bo Liu, Manuel Faysse, Céline Hudelot, Gautier Viaud",,,"Retrieval-Augmented Generation, RAG, multi-modal, benchmark, visual elements, document retrieval, information synthesis, source grounding","Retrieval-Augmented Generation (RAG) pipelines face challenges beyond simple single-document retrieval, such as interpreting visual elements (tables, charts, images), synthesizing information across documents, and providing accurate source grounding. Existing benchmarks often fail to capture this complexity, focusing on textual data, single-document comprehension, or evaluating retrieval and generation in isolation. ViDoRe V3 introduces a comprehensive multi-modal RAG benchmark featuring multi-type queries over visually rich document corpora. It covers 10 datasets across diverse professional domains, comprising 26,000 document pages paired with 3,099 human-verified queries, available in 6 languages. Through 12,000 hours of human annotation effort, high-quality annotations for retrieval relevance, bounding box localization, and verified reference answers are provided. Evaluation of state-of-the-art RAG pipelines reveals that visual retrievers outperform textual ones, late-interaction models and textual reranking substantially improve performance, and hybrid or purely visual contexts enhance answer generation quality. However, current models struggle with non-textual elements, open-ended queries, and fine-grained visual grounding. The benchmark is released under a commercially permissive license to encourage progress in addressing these challenges.",3.7,111.994,414,cold_start,Phi-4,Apple_M1(Metal)
2601.08623v1_SafeRedir Prompt Embedding Redirection for Robust .pdf,SafeRedir: Prompt Embedding Redirection for Robust Unlearning in Image Generation Models,"Renyang Liu, Kangjie Chen, Han Qiu, Jie Zhang, Kwok-Yan Lam, Tianwei Zhang, See-Kiong Ng",,,"image generation models, unlearning, prompt embedding, safety, semantic redirection, diffusion models","Image generation models (IGMs) often memorize undesirable concepts from training data, leading to the reproduction of unsafe content. Post-hoc filtering is insufficient due to limited robustness and lack of fine-grained control. SafeRedir introduces a lightweight inference-time framework for robust unlearning via prompt embedding redirection. It adaptively routes unsafe prompts to safe semantic regions through token-level interventions without modifying IGMs. The framework includes a latent-aware multi-modal safety classifier and a token-level delta generator for semantic redirection, with auxiliary predictors for token masking and adaptive scaling. Empirical results show effective unlearning, high semantic preservation, robust image quality, and resistance to adversarial attacks. SafeRedir is compatible with various diffusion backbones and unlearned models, demonstrating broad applicability.",3.48,84.448,294,cold_start,Phi-4,Apple_M1(Metal)
2601.08631v1_M2FMoE Multi-Resolution Multi-View Frequency Mixtu.pdf,M2FMoE: Multi-Resolution Multi-View Frequency Mixture-of-Experts for Extreme-Adaptive Time Series Forecasting,"Yaohui Huang, Runmin Zou, Yun Wang, Laeeq Aslam, Ruipeng Dong",,,"time series forecasting, extreme events, multi-resolution, multi-view frequency modeling, mixture-of-experts, hydrological forecasting","Forecasting time series with extreme events is critical yet challenging due to their high variance, irregular dynamics, and sparse but high-impact nature. Existing methods excel in modeling dominant regular patterns but perform poorly during extreme events. The proposed M2FMoE model addresses these limitations by learning both regular and extreme patterns through multi-resolution and multi-view frequency modeling. It comprises three modules: a multi-view frequency mixture-of-experts module, a multi-resolution adaptive fusion module, and a temporal gating integration module. Experiments on real-world hydrological datasets demonstrate that M2FMoE outperforms state-of-the-art baselines without requiring extreme-event labels.",3.48,77.081,268,cold_start,Phi-4,Apple_M1(Metal)
2601.08634v1_Moral Lenses Political Coordinates Towards Ideolog.pdf,"Moral Lenses, Political Coordinates: Towards Ideological Positioning of Morally Conditioned LLMs","Chenchen Yuan, Bolei Ma, Zheyu Zhang, Bardh Prenkaj, Frauke Kreuter, Gjergji Kasneci",,,"large language models, political orientation, moral values, ideological biases, social psychology, Political Compass Test, moral conditioning, alignment techniques","This paper explores the relationship between moral values and political orientation in large language models (LLMs). Unlike previous studies that use direct probing or demographic persona engineering, this research conditions models to endorse or reject specific moral values and evaluates the shifts in their political orientations using the Political Compass Test. The findings indicate that moral conditioning leads to value-specific shifts in political coordinates, influenced by role framing and model scale. The study suggests that effective alignment of LLMs requires integrating political assessments within broader social values, including morality.",3.4,74.466,253,cold_start,Phi-4,Apple_M1(Metal)
2601.08641v1_Resisting Manipulative Bots in Memecoin Copy Tradi.pdf,Resisting Manipulative Bots in Memecoin Copy Trading: A Multi-Agent Approach with Chain-of-Thought Reasoning,"Yichen Luo, Yebo Feng, Jiahua Xu, Yang Liu",https://doi.org/XXXXXXX.XXXXXXX,,"memecoin, copy trading, manipulative bots, multi-agent system, chain-of-thought reasoning, large language models, cryptocurrency markets","The launch of $Trump coin ignited a wave in meme coin investment. Copy trading, as a strategy-agnostic approach that eliminates the need for deep trading knowledge, quickly gains widespread popularity in the meme coin market. However, copy trading is not a guarantee of profitability due to the prevalence of manipulative bots, the uncertainty of the followed wallets’ future performance, and the lag in trade execution. Recently, large language models (LLMs) have shown promise in financial applications by effectively understanding multi-modal data and producing explainable decisions. However, a single LLM struggles with complex, multi-faceted tasks such as asset allocation. These challenges are even more pronounced in cryptocurrency markets, where LLMs often lack sufficient domain-specific knowledge in their training data. To address these challenges, we propose an explainable multi-agent system for meme coin copy trading. Inspired by the structure of an asset management team, our system decomposes the complex task into subtasks and coordinates specialized agents to solve them collaboratively. Employing few-shot chain-of-thought (CoT) prompting, each agent acquires professional meme coin trading knowledge, interprets multi-modal data, and generates explainable decisions. Using a dataset of 1,000 meme coin projects’ transaction data, our empirical evaluation shows that the proposed multi-agent system outperforms both traditional machine learning models and single LLMs, achieving 73% and 70% precision in identifying high-quality meme coin projects and key opinion leader (KOL) wallets, respectively. The selected KOLs collectively generated a total profit of $500,000 across these projects.",3.85,113.939,439,cold_start,Phi-4,Apple_M1(Metal)
2601.08653v1_Prism Towards Lowering User Cognitive Load in LLMs.pdf,Prism: Towards Lowering User Cognitive Load in LLMs via Complex Intent Understanding,"Zenghua Liao, Jinzhi Liao, Xiang Zhao",,,"Complex intent understanding, Large language models, Logical clarification","Large Language Models (LLMs) are becoming integral to social platforms as web-native interfaces. Users on these platforms often have ambiguous and dynamic goals, necessitating complex intent understanding over single-turn execution for effective collaboration. Existing methods use sequential or parallel questioning to clarify user intents but fail to model logical dependencies among questions. Inspired by Cognitive Load Theory, the proposed Prism framework addresses this by decomposing user intents into smaller elements, organizing clarification questions logically, evaluating clarification trajectories with an intent-aware reward function, and refining LLM capabilities through data-driven feedback. Prism outperforms existing approaches in logical consistency, reduces logical conflicts to 11.5%, increases user satisfaction by 14.4%, and decreases task completion time by 34.8%.",3.36,72.279,243,cold_start,Phi-4,Apple_M1(Metal)
2601.08654v1_RULERS Locked Rubrics and Evidence-Anchored Scorin.pdf,RULERS: Locked Rubrics and Evidence-Anchored Scoring for Robust LLM Evaluation,"Yihan Hong, Huaiyuan Yao, Bolin Shen, Wanpeng Xu, Hua Wei, Yushun Dong",,,"LLM evaluation, rubric-based assessment, AI-human agreement, model alignment, scalable deployment, rubric interpretation drift, systematic biases, scale misalignment","The 'LLM-as-a-Judge' paradigm aims for scalable rubric-based evaluation but struggles with aligning frozen models with human standards due to generation stochasticity. This paper introduces RULERS (Rubric Unification, Locking, and Evidence-anchored Robust Scoring), a framework that compiles natural language rubrics into executable specifications. RULERS addresses rubric instability, unverifiable reasoning, and scale misalignment by creating versioned, immutable rubric bundles, enforcing structured decoding with deterministic evidence verification, and applying Wasserstein-based calibration. Experiments show RULERS improves human agreement, stability against rubric perturbations, and allows smaller models to compete with larger ones. The study concludes that reliable LLM judging requires executable rubrics, verifiable evidence, and calibrated scales.",3.52,88.062,310,cold_start,Phi-4,Apple_M1(Metal)
2601.08659v1_TRACE Reconstruction-Based Anomaly Detection in En.pdf,Reconstruction-Based Anomaly Detection in Ensemble and Time-Dependent Simulations,"Hamid Gadirov, Martijn Westra, Steffen Frey",,,"anomaly detection, ensemble simulations, time-dependent simulations, convolutional autoencoders, Kármán vortex street, scientific computing, visualization","Detecting anomalous behavior in high-dimensional, time-dependent simulation data is crucial in scientific computing and visualization. This study investigates reconstruction-based anomaly detection for ensemble data from parameterized Kármán vortex street simulations using convolutional autoencoders. A systematic comparison between two-dimensional and three-dimensional autoencoders reveals that 2D autoencoders effectively identify localized spatial irregularities, while 3D autoencoders leverage spatio-temporal context to detect dynamic behavior anomalies. The study highlights the complementary strengths of 2D and 3D autoencoders and underscores the importance of incorporating temporal context in analyzing dynamic flow phenomena.",3.14,73.339,230,cold_start,Phi-4,Apple_M1(Metal)
2601.08662v1_From Classical to Quantum Reinforcement Learning a.pdf,From Classical to Quantum Reinforcement Learning and Its Applications in Quantum Control: A Beginner’s Tutorial,"Abhijit Sen, Sonali Panda, Mahima Arya, Subhajit Patra, Zizhan Zheng, Denys I. Bondar",,,"Reinforcement Learning, Quantum Control, Quantum Reinforcement Learning, AI, Undergraduate Education","This tutorial aims to make reinforcement learning (RL) more accessible to undergraduate students by providing clear, example-driven explanations. It bridges the gap between RL theory and practical coding applications, addressing common challenges faced by students. The tutorial focuses on foundational skills needed to apply RL techniques in real-world scenarios, with a special emphasis on quantum control. It includes hands-on examples and approachable explanations, making it practical and accessible for structured and efficient learning.",3.27,67.619,221,cold_start,Phi-4,Apple_M1(Metal)
2601.08670v1_Parallel Context-of-Experts Decoding for Retrieval.pdf,Parallel Context-of-Experts Decoding for Retrieval Augmented Generation,"Giulio Corallo, Paolo Papotti",,,"Retrieval Augmented Generation, Parallel Context-of-Experts Decoding, KV caching, multi-document reasoning, cross-document interaction","Retrieval Augmented Generation (RAG) faces a trade-off between long context prompts for multi-document reasoning and separate encoding of document KV caches for speed. This paper introduces Parallel Context-of-Experts Decoding (PCED), a training-free framework that shifts evidence aggregation from attention to decoding. PCED treats retrieved documents as isolated 'experts' and synchronizes their predictions using a retrieval-aware contrastive decoding rule. This approach allows for cross-document reasoning without shared attention, improving performance on benchmarks like LOFT and Long-Bench while significantly speeding up inference.",2.96,72.642,215,cold_start,Phi-4,Apple_M1(Metal)
2601.08673v1_Why AI Alignment Failure Is Structural Learned Hum.pdf,Why AI Alignment Failure Is Structural: Learned Human Interaction Structures and AGI as an Endogenous Evolutionary Shock,"Didier Sornette, Sandro Claudio Lera, Ke Wu",,arXiv:2601.08673v1,"AI alignment failure, large language models, structural generalizations, relational models theory, artificial general intelligence, governance, human interaction structures","Recent reports of large language models (LLMs) exhibiting behaviors such as deception, threats, or blackmail are often interpreted as evidence of alignment failure or emergent malign agency. This interpretation is argued to be conceptually flawed, as LLMs do not reason morally but statistically internalize human social interactions, including laws, contracts, negotiations, conflicts, and coercive arrangements. Behaviors labeled as unethical or anomalous are seen as structural generalizations arising under extreme asymmetries of power, information, or constraint. Practices like blackmail are not deviations from normal social behavior but limiting cases within a continuum that includes market pricing, authority relations, and ultimatum bargaining. The surprise at such outputs reflects an anthropomorphic expectation that intelligence should only reproduce socially sanctioned behavior. Human morality is plural, context-dependent, and historically contingent, making the notion of universally moral artificial intelligence ill-defined. The primary risk of AGI is not adversarial intent but its role as an endogenous amplifier of human intelligence, power, and contradiction. AGI eliminates cognitive and institutional frictions, compressing timescales and removing the historical margin of error that has allowed inconsistent values and governance regimes to persist. Alignment failure is structural, not accidental, requiring governance approaches that address amplification, complexity, and regime stability rather than model-level intent alone.",4.09,97.522,399,cold_start,Phi-4,Apple_M1(Metal)
2601.08676v2_Advancing ESG Intelligence An Expert-level Agent a.pdf,Advancing ESG Intelligence: An Expert-level Agent and Comprehensive Benchmark for Sustainable Finance,"Yilei Zhao, Wentao Zhang, Lei Xiao, Yandan Zheng, Mengpu Liu, Wei Yang Bryan Lim",,,"ESG, sustainable finance, multi-agent system, large language models, benchmark, corporate sustainability, data fragmentation, professional analysis","Environmental, social, and governance (ESG) criteria are essential for evaluating corporate sustainability and ethical performance. Professional ESG analysis is hindered by data fragmentation across unstructured sources, and existing large language models (LLMs) often struggle with the complex, multi-step workflows required for rigorous auditing. To address these limitations, the paper introduces ESGAgent, a hierarchical multi-agent system empowered by a specialized toolset, including retrieval augmentation, web search, and domain-specific functions, to generate in-depth ESG analysis. Complementing this agentic system, a comprehensive three-level benchmark derived from 310 corporate sustainability reports is presented to evaluate capabilities ranging from atomic common-sense questions to the generation of integrated, in-depth analysis. Empirical evaluations demonstrate that ESGAgent outperforms state-of-the-art closed-source LLMs with an average accuracy of 84.15% on atomic question-answering tasks and excels in professional report generation by integrating rich charts and verifiable references. These findings confirm the diagnostic value of the benchmark, establishing it as a vital testbed for assessing general and advanced agentic capabilities in high-stakes vertical domains.",3.68,100.206,369,cold_start,Phi-4,Apple_M1(Metal)
2601.08679v1_PersonaDual Balancing Personalization and Objectiv.pdf,PersonaDual: Balancing Personalization and Objectivity via Adaptive Reasoning,"Xiaoyou Liu, Xinyi Mou, Shengbin Yue, Liang Wang, Yuqing Wang, Qiexiang Wang, Tianrui Qin, Wangchunshu Zhou, Zhongyu Wei",,,"Large Language Models, personalization, objectivity, adaptive reasoning, framework, reinforcement learning","As users increasingly expect LLMs to align with their preferences, personalized information becomes valuable. However, personalized information can be a double-edged sword: it can improve interaction but may compromise objectivity and factual correctness, especially when it is misaligned with the question. To alleviate this problem, we propose PersonaDual, a framework that supports both general-purpose objective reasoning and personalized reasoning in a single model, and adaptively switches modes based on context. PersonaDual is first trained with SFT to learn two reasoning patterns, and then further optimized via reinforcement learning with our proposed DualGRPO to improve mode selection. Experiments on objective and personalized benchmarks show that PersonaDual preserves the benefits of personalization while reducing interference, achieving near interference-free performance and better leveraging helpful personalized signals to improve objective problem-solving.",3.35,92.56,310,cold_start,Phi-4,Apple_M1(Metal)
2601.08682v1_Lessons from the Field An Adaptable Lifecycle Appr.pdf,Lessons from the Field: An Adaptable Lifecycle Approach to Applied Dialogue Summarization,"Kushal Chawla, Chenyang Zhu, Pengshan Cai, Sangwoo Cho, Scott Novotney, Ayushman Singh, Jonah Lewis, Keasha Safewright, Alfy Samuel, Erin Babinsky, Shi-Xiong Zhang, Sambit Sahu",,,"dialogue summarization, multi-party interactions, agentic system, evaluation methods, task decomposition, data bottlenecks, vendor lock-in, LLM prompts, text summarization, Large Language Models, Agentic frameworks","Summarization of multi-party dialogues is a critical capability in industry, enhancing knowledge transfer and operational effectiveness across many domains. Automatically generating high-quality summaries is challenging due to complex, multi-faceted requirements. This work presents an industry case study on developing an agentic system to summarize multi-party interactions, sharing practical insights spanning the full development lifecycle. It covers robust methods for evaluation despite evolving requirements and task subjectivity, component-wise optimization enabled by task decomposition in an agentic architecture, the impact of upstream data bottlenecks, and the realities of vendor lock-in due to poor transferability of LLM prompts.",3.62,92.313,334,cold_start,Phi-4,Apple_M1(Metal)
2601.08683v1_Region of interest detection for efficient aortic .pdf,Region of interest detection for efficient aortic segmentation,"Loris Giordano, Ine Dirks, Tom Lenaerts, Jef Vandemeulebrouck",,,"Detection, Segmentation, Multi-task learning, Cascade models, Aorta, Computed tomography","Thoracic aortic dissection and aneurysms are the most lethal diseases of the aorta. The major hindrance to treatment lies in the accurate analysis of the medical images. More particularly, aortic segmentation of the 3D image is often tedious and difficult. Deep-learning-based segmentation models are an ideal solution, but their inability to deliver usable outputs in difficult cases and their computational cost cause their clinical adoption to stay limited. This study presents an innovative approach for efficient aortic segmentation using targeted region of interest (ROI) detection. In contrast to classical detection models, we propose a simple and efficient detection model that can be widely applied to detect a single ROI. Our detection model is trained as a multi-task model, using an encoder-decoder architecture for segmentation and a fully connected network attached to the bottleneck for detection. We compare the performance of a one-step segmentation model applied to a complete image, nnU-Net and our cascade model composed of a detection and a segmentation step. We achieve a mean Dice similarity coefficient of 0.944 with over 0.9 for all cases using a third of the computing power. This simple solution achieves state-of-the-art performance while being compact and robust, making it an ideal solution for clinical applications.",3.75,96.627,362,cold_start,Phi-4,Apple_M1(Metal)
2601.08684v1_MEMEWEAVER Inter-Meme Graph Reasoning for Sexism a.pdf,MEMEWEAVER: Inter-Meme Graph Reasoning for Sexism and Misogyny Detection,"Paolo Italiani, David Gimeno-Gomez, Luca Ragazzi, Gianluca Moro, Paolo Rosso",,,"sexism, misogyny detection, multimodal content moderation, graph-based methods, online harassment, social dynamics, graph reasoning, visual-textual fusion","Women are twice as likely as men to face online harassment due to their gender. Despite advances in multimodal content moderation, most approaches overlook the social dynamics behind this phenomenon, where perpetrators reinforce prejudices within like-minded communities. Graph-based methods offer a promising way to capture such interactions, yet existing solutions remain limited by heuristic graph construction, shallow modality fusion, and instance-level reasoning. This work presents MEMEWEAVER, an end-to-end trainable multimodal framework for detecting sexism and misogyny through a novel inter-meme graph reasoning mechanism. The approach systematically evaluates multiple visual-textual fusion strategies and consistently outperforms state-of-the-art baselines on the MAMI and EXIST benchmarks, while achieving faster training convergence. Further analyses reveal that the learned graph structure captures semantically meaningful patterns, offering valuable insights into the relational nature of online hate.",3.44,83.782,288,cold_start,Phi-4,Apple_M1(Metal)
2601.08690v1_All Required In Order Phase-Level Evaluation for A.pdf,Phase-Level Evaluation for AI–Human Dialogue in Healthcare and Beyond,"Shubham Kulkarni, Alexander Lyzhov, Shiva Chaitanya, Preetam Joshi",,,"Conversational AI, Clinical Work, Evaluation Methods, Obligatory-Information Phase Structured Compliance Evaluation (OIP–SCE), Healthcare, Clinical Dialogue, Compliance, Phase-Level Audits, HIPAA","Conversational AI is increasingly supporting real clinical work, but current evaluation methods often overlook the importance of compliance throughout the entire conversation. This paper introduces the Obligatory-Information Phase Structured Compliance Evaluation (OIP–SCE), a method that ensures all required clinical obligations are met in the correct order, providing clear evidence for clinicians to review. This approach makes complex rules practical and auditable, bridging the gap between technical advancements and actual healthcare needs. The method is demonstrated through two case studies: respiratory history and benefits verification, showing how phase-level evidence can transform policy into actionable steps. By allowing clinicians to control what to check and providing engineers with a clear specification to implement, OIP–SCE offers a single, auditable evaluation surface that aligns AI capabilities with clinical workflows, supporting routine and safe use.",3.57,87.573,313,cold_start,Phi-4,Apple_M1(Metal)
2601.08697v2_Auditing Student-AI Collaboration A Case Study of .pdf,Auditing Student–AI Collaboration: A Case Study of Online Graduate CS Students,Nifu Dan,10.1145/XXXXXXX.XXXXXXX,,"AI in education, human–AI collaboration, student agency, automation preferences, generative AI, academic integrity, HCAI","As generative AI becomes embedded in higher education, it increasingly shapes how students complete academic tasks. This study conducts a mixed-methods audit of student–AI collaboration preferences by examining the alignment between current AI capabilities and students’ desired levels of automation in academic work. Using two sequential and complementary surveys, the study captures students’ perceived benefits, risks, and preferred boundaries when using AI. The first survey assesses preferences for and actual usage of AI across 12 academic tasks, alongside primary concerns and reasons for use. The second survey explores how AI systems could be designed to address these concerns through open-ended questions. The study aims to identify gaps between existing AI affordances and students’ normative expectations of collaboration, informing the development of more effective and trustworthy AI systems for education.",3.45,75.606,261,cold_start,Phi-4,Apple_M1(Metal)
2601.08703v1_Evaluating the Ability of Explanations to Disambig.pdf,Evaluating the Ability of Explanations to Disambiguate Models in a Rashomon Set,"Kaivalya Rawal, Eoin Delaney, Zihao Fu, Sandra Wachter, Chris Russell",https://dl.acm.org/doi/10.1145/3715275.3732219,,"Explainable Artificial Intelligence, Rashomon Set, Model Explanations, Feature-Importance Explanations, Model Evaluation","This paper discusses the role of explainable artificial intelligence (XAI) in disambiguating models within a Rashomon set, which are models with similar performance. It highlights the variability of explanations depending on the explainer used and introduces the AXE method for evaluating the quality of feature-importance explanations. The paper argues that traditional evaluation metrics may obscure differences within a Rashomon set, whereas AXE can detect adversarial fairwashing of explanations with high accuracy. The focus is on local feature-importance explanations for models operating on tabular data.",3.43,76.339,262,cold_start,Phi-4,Apple_M1(Metal)
2601.08713v1_Real-Time Localization Framework for Autonomous Ba.pdf,Real-Time Localization Framework for Autonomous Basketball Robots,"Naren Medarametla, Sreejon Mondal",,,"Robot Localization, Autonomous Navigation, Neural Networks, Robocon","Localization is a fundamental capability for autonomous robots, enabling them to operate effectively in dynamic environments. In Robocon 2025, accurate and reliable localization is crucial for improving shooting precision, avoiding collisions with other robots, and navigating the competition field efficiently. This paper proposes a hybrid localization algorithm that integrates classical techniques with learning-based methods relying solely on visual data from the court’s floor to achieve self-localization on the basketball field.",3.04,56.56,172,cold_start,Phi-4,Apple_M1(Metal)
2601.08731v1_Learning from Demonstrations via Capability-Aware .pdf,Learning from Demonstrations via Capability-Aware Goal Sampling,"Yuanlin Duan, Yuning Wang, Wenjie Qiu, He Zhu",,2601.08731v1,"Imitation Learning, Capability-Aware Goal Sampling, Deep Reinforcement Learning, Behavior Cloning, Adversarial Learning, Inverse Reinforcement Learning, Offline RL, Long-Horizon Tasks","Despite its promise, imitation learning often fails in long-horizon environments where perfect replication of demonstrations is unrealistic and small errors can accumulate catastrophically. We introduce Cago (Capability-Aware Goal Sampling), a novel learning-from-demonstrations method that mitigates the brittle dependence on expert trajectories for direct imitation. Unlike prior methods that rely on demonstrations only for policy initialization or reward shaping, Cago dynamically tracks the agent’s competence along expert trajectories and uses this signal to select intermediate steps—goals that are just beyond the agent’s current reach—to guide learning. This results in an adaptive curriculum that enables steady progress toward solving the full task. Empirical results demonstrate that Cago significantly improves sample efficiency and final performance across a range of sparse-reward, goal-conditioned tasks, consistently outperforming existing learning from-demonstrations baselines.",3.61,84.924,307,cold_start,Phi-4,Apple_M1(Metal)
2601.08732v1_ISLA A U-Net for MRI-based acute ischemic stroke l.pdf,"ISLA: A U-Net for MRI-based acute ischemic stroke lesion segmentation with deep supervision, attention, domain adaptation, and ensemble learning","Vincent Roça, Martin Bretzner, Hilde Hénon, Laurent Puy, Grégory Kuchcinski, Renaud Lopes",,,"acute ischemic stroke, MRI, lesion segmentation, deep learning, U-Net, deep supervision, attention mechanisms, domain adaptation, ensemble learning","Accurate delineation of acute ischemic stroke lesions in MRI is crucial for stroke diagnosis and management. Deep learning models, particularly U-Net variants, have been applied to automate this segmentation. The study introduces ISLA, a new model for AIS lesion segmentation from diffusion MRI, trained on three multicenter databases with over 1500 AIS participants. Through systematic optimization of loss functions, convolutional architecture, deep supervision, and attention mechanisms, a robust segmentation framework was developed. Unsupervised domain adaptation was also explored to enhance generalization to an external clinical dataset. ISLA outperformed two state-of-the-art approaches on an external test set, with codes and trained models to be made publicly available for reuse and reproducibility.",3.4,90.636,308,cold_start,Phi-4,Apple_M1(Metal)
2601.08734v1_TerraFormer Automated Infrastructure-as-Code with .pdf,TerraFormer: Automated Infrastructure-as-Code with LLMs Fine-Tuned via Policy-Guided Verifier Feedback,"Prithwish Jana, Sam Davidson, Bhavana Bhasker, Andrey Kan, Anoop Deoras, Laurent Callot",10.1145/3786583.3786898,,"Infrastructure as Code (IaC), IaC generation, IaC mutation, Neuro-symbolic AI, Large language models, Formal Verification","Automating Infrastructure-as-Code (IaC) is challenging, and large language models (LLMs) often produce incorrect configurations from natural language (NL). We present TerraFormer, a neuro-symbolic framework for IaC generation and mutation that combines supervised fine-tuning with verifier-guided reinforcement learning, using formal verification tools to provide feedback on syntax, deployability, and policy compliance. We curate two large, high-quality NL-to-IaC datasets, TF-Gen (152k instances) and TF-Mutn (52k instances), via multi-stage verification and iterative LLM self-correction. Evaluations against 17 state-of-the-art LLMs, including ~50× larger models like Sonnet 3.7, DeepSeek-R1, and GPT-4.1, show that TerraFormer improves correctness over its base LLM by 15.94% on IaC-Eval, 11.65% on TF-Gen(Test), and 19.60% on TF-Mutn(Test). It outperforms larger models on both TF-Gen(Test) and TF-Mutn(Test), ranks third on IaC-Eval, and achieves top best-practices and security compliance.",3.62,114.005,413,cold_start,Phi-4,Apple_M1(Metal)
2601.08743v1_TableCache Primary Foreign Key Guided KV Cache Pre.pdf,TableCache: Primary Foreign Key Guided KV Cache Precomputation for Low Latency Text-to-SQL,"Jinbo Su, Yuxuan Hu, Cuiping Li, Hong Chen, Jia Li, Lintao Ma, Jing Zhang",,,"Text-to-SQL, KV Cache, LLM-based methods, database schemas, primary foreign key, Table Trie, cache management, query reranking, model inference, cache loading, Time to First Token (TTFT)","In Text-to-SQL tasks, existing LLM-based methods often include extensive database schemas in prompts, leading to long context lengths and increased prefilling latency. This paper proposes precomputing table representations as KV caches offline and querying the required ones online, preserving primary foreign key relationships between tables. A Table Trie structure is introduced for efficient KV cache lookups during inference. A cache management system with a query reranking strategy is introduced to improve cache hit rates, and a computation loading pipeline is developed for parallelizing model inference and cache loading. Experimental results show that the proposed TableCache achieves up to a 3.62× speedup in Time to First Token (TTFT) with negligible performance degradation.",3.56,86.971,310,cold_start,Phi-4,Apple_M1(Metal)
2601.08747v2_To Retrieve or To Think An Agentic Approach for Co.pdf,To Retrieve or To Think? An Agentic Approach for Context Evolution,"Rubing Chen, Jian Wang, Wenjie Li, Xiao-Yong Wei, Qing Li",,,"context augmentation, retrieval-augmented generation, knowledge-intensive reasoning, Agentic Context Evolution, metacognition, context evolution, multi-hop QA","Current context augmentation methods, such as retrieval-augmented generation, are essential for solving knowledge-intensive reasoning tasks. However, they typically adhere to a rigid, brute-force strategy that executes retrieval at every step, leading to unnecessary computational costs and performance degradation due to irrelevant noise. To address these limitations, the paper introduces Agentic Context Evolution (ACE), a framework inspired by human metacognition that dynamically determines whether to seek new evidence or reason with existing knowledge. ACE employs a central orchestrator agent to make decisions strategically via majority voting, alternating between activating a retriever agent for external retrieval and a reasoner agent for internal analysis and refinement. By eliminating redundant retrieval steps, ACE maintains a concise and evolved context. Extensive experiments on challenging multi-hop QA benchmarks demonstrate that ACE significantly outperforms competitive baselines in accuracy while achieving efficient token consumption. The work provides valuable insights into advancing context-evolved generation for complex, knowledge-intensive tasks.",3.51,82.814,291,cold_start,Phi-4,Apple_M1(Metal)
2601.08753v1_Grid-Aware Charging and Operational Optimization f.pdf,Grid-Aware Charging and Operational Optimization for Mixed-Fleet Public Transit,"Rishav Sen, Amutheezan Sivagnanam, Aron Laszka, Ayan Mukhopadhyay, Abhishek Dubey",,,"Mixed transit fleet, electrification, dynamic pricing, hierarchical MILP","The rapid growth of urban populations and the increasing need for sustainable transportation solutions have prompted a shift towards electric buses in public transit systems. However, managing mixed fleets of electric and diesel buses poses significant operational challenges, particularly with dynamic electricity pricing. This paper presents a mixed-integer linear programming (MILP) model to optimize charging schedules and trip assignments for mixed fleets, considering dynamic electricity pricing, vehicle capacity, and route constraints. Using real-world data from Chattanooga, Tennessee, the approach demonstrates potential savings in operating costs for mixed transit fleets.",3.4,67.434,229,cold_start,Phi-4,Apple_M1(Metal)
2601.08768v1_AI as Entertainment.pdf,AI as Entertainment,"Cody Kommers, Ari Holtzman",https://doi.org/XXXXXXX.XXXXXXX,,"Generative AI, Entertainment, Culture, LLMs, Societal Impact, Meaning-making","Generative AI systems are primarily designed and marketed as intelligent systems to augment human cognitive labor, promising increased productivity. However, there is an emerging narrative that AI is also being adopted for entertainment, particularly by younger demographics, and represents a significant revenue potential. This paper argues that entertainment will become a primary business model for major AI corporations, influencing the technology they produce. Current AI assessments focus on cultural harms, lacking frameworks for evaluating the benefits of AI-generated cultural content. The authors propose 'thick entertainment' as a framework to evaluate AI-generated content, considering its role in meaning-making, identity formation, and social connection. They suggest that AI's impact may be more about entertainment than intelligence, similar to how social media is about social connection rather than communication.",3.44,72.619,250,cold_start,Phi-4,Apple_M1(Metal)
2601.08773v1_Reliable Graph-RAG for Codebases AST-Derived Graph.pdf,Reliable Graph-RAG for Codebases: AST-Derived Graphs vs LLM-Extracted Knowledge Graphs,Manideep Reddy Chinthareddy,,2601.08773v1,"Retrieval-Augmented Generation, software engineering, vector similarity search, multi-hop architectural reasoning, Java codebases, Tree-sitter parsing, architecture and code-tracing queries, ontology graph, LLM-mediated graph generation, probabilistic indexing, deterministic indexing","This paper benchmarks three retrieval pipelines on Java codebases: (A) No-Graph Naive RAG (vector-only), (B) an LLM-Generated Knowledge Graph RAG (LLM-KB), and (C) a deterministic AST-derived Knowledge Graph RAG (DKB). The study evaluates these approaches using a fixed suite of 15 architecture and code-tracing queries per repository. Results show that DKB builds its ontology graph quickly, while LLM-KB requires significantly longer graph generation times and exhibits probabilistic indexing incompleteness. LLM-KB's extraction log flags many files as skipped or missed, resulting in lower corpus coverage and fewer nodes compared to DKB. The paper highlights the efficiency and completeness of DKB over LLM-KB in handling software engineering queries.",3.89,82.052,319,cold_start,Phi-4,Apple_M1(Metal)
2601.08776v1_Translating Light-Sheet Microscopy Images to Virtu.pdf,Translating Light-Sheet Microscopy Images to Virtual H&E Using CycleGAN,Yanhua Zhao,,,"Histopathology, image translation, H&E staining, unpaired learning, CycleGAN","Histopathology analysis traditionally relies on Hematoxylin and Eosin (H&E) staining, but fluorescence microscopy provides complementary information. This paper introduces a Cycle-Consistent Adversarial Network (CycleGAN) approach for unpaired image-to-image translation from multi-channel fluorescence microscopy to pseudo H&E stained histopathology images. The method combines C01 and C02 fluorescence channels into RGB and learns a bidirectional mapping between fluorescence and H&E domains without paired training data. The architecture uses ResNet-based generators with residual blocks and PatchGAN discriminators, trained with adversarial, cycle-consistency, and identity losses. Experiments demonstrate that the model generates realistic pseudo H&E images that preserve morphological structures while adopting H&E-like color characteristics, facilitating visualization of fluorescence data in a format familiar to pathologists and supporting integration with existing H&E-based analysis pipelines.",3.51,71.544,251,cold_start,Phi-4,Apple_M1(Metal)
2601.08777v1_Asymptotic Universal Alignment A New Alignment Fra.pdf,Asymptotic Universal Alignment: A New Alignment Framework via Test-Time Scaling,"Yang Cai, Weiqiang Zheng",,2601.08777v1,"large language models, alignment, test-time scaling, Nash learning from human feedback, multi-player alignment games, self-play learning dynamics","Aligning large language models (LLMs) to serve users with heterogeneous and potentially conflicting preferences is a central challenge for personalized and trustworthy AI. This paper introduces a new alignment framework via test-time scaling, formalizing an ideal notion of universal alignment. The framework requires a model to produce k≥1 candidate responses for each prompt, with the user selecting their preferred one. The concept of (k, f(k))-robust alignment is introduced, requiring the k-output model to have a win rate f(k) against any other single-output model, and asymptotic universal alignment (U-alignment) is defined as f(k)→1 as k→∞. The paper characterizes the optimal convergence rate, showing that a family of single-output policies can achieve U-alignment at rate f(k) = k/(k+1), and no method can achieve a faster rate in general. It is demonstrated that popular post-training methods, such as Nash learning from human feedback (NLHF), underutilize test-time scaling benefits. The paper proposes a family of symmetric multi-player alignment games, proving that any symmetric Nash equilibrium policy of the (k+1)-player alignment game achieves optimal (k, k/(k+1))-robust alignment. Theoretical convergence guarantees for self-play learning dynamics in these games are provided, extending the framework to opponents generating multiple responses.",4.04,95.929,388,cold_start,Phi-4,Apple_M1(Metal)
2601.08778v3_Pervasive Annotation Errors Break Text-to-SQL Benc.pdf,Pervasive Annotation Errors Break Text-to-SQL Benchmarks and Leaderboards,"Tengjun Jin, Yoojin Choi, Yuxuan Zhu, Daniel Kang",,,"text-to-SQL, benchmarks, leaderboards, annotation errors, data analytics, data-driven applications","Researchers have proposed numerous text-to-SQL techniques to streamline data analytics and accelerate the development of data-driven applications. To compare these techniques and select the best one for deployment, the community depends on public benchmarks and their leaderboards. Since these benchmarks heavily rely on human annotations during question construction and answer evaluation, the validity of the annotations is crucial. This paper conducts an empirical study to benchmark annotation error rates for two widely used text-to-SQL benchmarks, BIRD and Spider 2.0-Snow, and corrects a subset of the BIRD development set to measure the impact of annotation errors on text-to-SQL agent performance and leaderboard rankings. Through expert analysis, it is shown that BIRD Mini-Dev and Spider 2.0-Snow have error rates of 52.8% and 62.8%, respectively. Re-evaluation of all 16 open-source agents from the BIRD leaderboard on both the original and corrected BIRD Dev subsets shows performance changes ranging from -7% to 31% and rank changes from -9 to +9 positions. The findings indicate that annotation errors can significantly distort reported performance and rankings, potentially misguiding research directions or deployment choices.",3.54,99.424,352,cold_start,Phi-4,Apple_M1(Metal)
2601.08785v1_Uncovering Political Bias in Large Language Models.pdf,Uncovering Political Bias in Large Language Models using Parliamentary Voting Records,"Jieying Chen, Karen de Jong, Andreas Poole, Jan Burakowski, Elena Elderson Nosti, Joep Windt, Chendi Wang",https://doi.org/XXXXXXX.XXXXXXX,,"Political bias, Large language models, Ideological alignment, Multilingual NLP, Benchmarking, Bias evaluation, Parliamentary motions, LLM fairness","As large language models (LLMs) become deeply embedded in digital platforms and decision-making systems, concerns about their political biases have grown. While substantial work has examined social biases such as gender and race, systematic studies of political bias remain limited—despite their direct societal impact. This paper introduces a general methodology for constructing political-bias benchmarks by aligning model-generated voting predictions with verified parliamentary voting records. We instantiate this methodology in three national case studies: PoliBiasNL (2,701 Dutch parliamentary motions and votes from 15 political parties), PoliBiasNO (10,584 motions and votes from 9 Norwegian parties), and PoliBiasES (2,480 motions and votes from 10 Spanish parties). Across these benchmarks, we assess ideological tendencies and political entity bias in LLM behavior. As part of our evaluation framework, we also propose a method to visualize the ideology of LLMs and political parties in a shared two-dimensional CHES (Chapel Hill Expert Survey) space by linking their voting-based positions to the CHES dimensions, enabling direct and interpretable comparisons between models and real-world political actors. Our experiments reveal fine-grained ideological distinctions: state-of-the-art LLMs consistently display left-leaning or centrist tendencies, alongside clear negative biases toward right-conservative parties. These findings highlight the value of transparent, cross-national evaluation grounded in real parliamentary behavior for understanding and auditing political bias in modern LLMs.",3.82,116.671,446,cold_start,Phi-4,Apple_M1(Metal)
2601.08806v1_APEX-SWE.pdf,APEX–SWE,"Abhi Kottamasu, Akul Datta, Aakash Barthwal, Ajay Arun, Chirag Mahapatra, Adarsh Hiremath, Brendan Foody, Bertie Vidgen",,arXiv:2601.08806v1,"AI Productivity Index, Software Engineering, Integration tasks, Observability tasks, AI models, benchmark, software engineering, epistemic reasoning","We introduce the AI Productivity Index for Software Engineering (APEX–SWE), a benchmark for assessing whether frontier AI models can execute economically valuable software engineering work. Unlike existing evaluations that focus on narrow, well-defined tasks, APEX–SWE assesses two novel task types that reflect real-world software engineering: (1) Integration tasks, which require constructing end-to-end systems across heterogeneous cloud primitives, business applications, and infrastructure-as-code services, and (2) Observability tasks, which require debugging production failures using telemetry signals such as logs and dashboards, as well as unstructured context. We evaluated eight frontier models for the APEX–SWE leaderboard. Gemini 3 Pro (Thinking=High) performs best, with a Pass@1 score of 25%. Our analysis shows that strong performance is primarily driven by epistemic reasoning, defined as the ability to distinguish between assumptions and verified facts, combined with agency to resolve uncertainty prior to acting. We open-source the APEX–SWE evaluation harness and a dev set (n= 50).",3.76,101.223,381,cold_start,Phi-4,Apple_M1(Metal)
2601.08807v1_S3-CLIP Video Super Resolution for Person-ReID.pdf,S3-CLIP: Video Super Resolution for Person-ReID,"Tamás Endrei, György Cserey",,,"Person Re-Identification, Video Super Resolution, CLIP-ReID, Cross-view conditions, Ranking accuracy","This paper introduces S3-CLIP, a video super-resolution-based CLIP-ReID framework developed for the VReID-XFD challenge at WACV 2026. It integrates recent advances in super-resolution networks with task-driven pipelines, adapting them to video-based person re-identification. The work represents the first systematic investigation of video super-resolution to enhance tracklet quality for person ReID, especially under challenging cross-view conditions. Experimental results show competitive performance with the baseline, achieving 37.52% mAP in aerial-to-ground and 29.16% mAP in ground-to-aerial scenarios. In the ground-to-aerial setting, S3-CLIP improves Rank-1, Rank-5, and Rank-10 performance by 11.24%, 13.48%, and 17.98%, respectively.",3.29,82.417,271,cold_start,Phi-4,Apple_M1(Metal)
2601.08808v1_Multiplex Thinking Reasoning via Token-wise Branch.pdf,Multiplex Thinking: Reasoning via Token-wise Branch-and-Merge,"Yao Tang, Li Dong, Yaru Hao, Qingxiu Dong, Furu Wei, Jiatao Gu",,arXiv:2601.08808v1,"Large Language Models, Chain-of-Thought, Reinforcement Learning, Math Reasoning, Token-wise Branch-and-Merge, Continuous Reasoning Tokens","This paper introduces Multiplex Thinking, a stochastic soft reasoning mechanism for large language models (LLMs) that samples multiple candidate tokens at each step and aggregates their embeddings into a single multiplex token. This approach maintains the vocabulary embedding prior and sampling dynamics of standard discrete generation while allowing for a tractable probability distribution over multiplex rollouts. Multiplex thinking adapts to model confidence, behaving like standard Chain-of-Thought (CoT) when confident and representing multiple plausible next steps when uncertain, without increasing sequence length. It outperforms discrete CoT and RL baselines across math reasoning benchmarks, producing shorter sequences. The method is self-adaptive and optimized with on-policy reinforcement learning.",3.24,87.033,282,cold_start,Phi-4,Apple_M1(Metal)
2601.08811v1_Reasoning Matters for 3D Visual Grounding.pdf,Reasoning Matters for 3D Visual Grounding,"Hsiang-Wei Huang, Kuang-Ming Chen, Wenhao Chai, Cheng-Yen Yang, Jen-Hao Cheng, Jenq-Neng Hwang",,,"3D Visual Grounding, Large Language Models, Reasoning, Data Synthesis, LLM Fine-tuning","The recent development of Large Language Models (LLMs) with strong reasoning ability has driven research in various domains. However, 3D visual grounding remains challenging due to limited reasoning in current models. Most methods require extensive 3D annotation data for supervised training. This work proposes a 3D visual grounding data pipeline that synthesizes data with corresponding reasoning processes. The generated data is used for LLM fine-tuning, introducing Reason3DVG-8B, a strong 3D visual grounding LLM that outperforms previous methods using only 1.6% of their training data. This demonstrates the effectiveness of the data and the importance of reasoning in 3D visual grounding.",3.01,90.227,272,cold_start,Phi-4,Apple_M1(Metal)
2601.08816v2_MemRec Collaborative Memory-Augmented Agentic Reco.pdf,MemRec: Collaborative Memory-Augmented Agentic Recommender System,"Weixin Chen, Yuhan Zhao, Jingyuan Huang, Zihe Ye, Clark Mingxuan Ju, Tong Zhao, Neil Shah, Li Chen, Yongfeng Zhang",,,"recommender systems, semantic memory, large language models, collaborative filtering, memory management, graph propagation","The evolution of recommender systems has shifted preference storage from rating matrices and dense embeddings to semantic memory in the agentic era. Existing agents rely on isolated memory, overlooking crucial collaborative signals. MemRec, a framework that decouples reasoning from memory management, addresses this by introducing a dedicated, cost-effective LMMem to manage a dynamic collaborative memory graph. This serves synthesized, high-signal context to a downstream LLMRec. The framework operates via a practical pipeline featuring efficient retrieval and cost-effective asynchronous graph propagation. Extensive experiments demonstrate that MemRec achieves state-of-the-art performance, establishing a new Pareto frontier that balances reasoning quality, cost, and privacy.",3.13,88.687,278,cold_start,Phi-4,Apple_M1(Metal)
2601.08828v1_Motion Attribution for Video Generation.pdf,Motion Attribution for Video Generation,"Xindi Wu, Despoina Paschalidou, Jun Gao, Antonio Torralba, Laura Leal-Taixé, Olga Russakovsky, Sanja Fidler, Jonathan Lorraine",,,"video generation, motion attribution, data curation, temporal dynamics, gradient-based framework, fine-tuning, temporal coherence, physical plausibility","Despite the rapid progress of video generation models, the role of data in influencing motion is poorly understood. This paper introduces Motive, a motion-centric, gradient-based data attribution framework that scales to modern, large, high-quality video datasets and models. Motive isolates temporal dynamics from static appearance via motion-weighted loss masks, yielding efficient and scalable motion-specific influence computation. It identifies clips that strongly affect motion and guides data curation to improve temporal consistency and physical plausibility. Using Motive-selected high-influence data, the method improves motion smoothness and dynamic degree on VBench, achieving a 74.1% human preference win rate compared with the pretrained base model. This is the first framework to attribute motion rather than visual appearance in video generative models and to use it to curate fine-tuning data.",3.37,94.271,318,cold_start,Phi-4,Apple_M1(Metal)
2601.08829v1_Modeling LLM Agent Reviewer Dynamics in Elo-Ranked.pdf,Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System,"Hsiang-Wei Huang, Junbin Lu, Kuang-Ming Chen, Jenq-Neng Hwang",,,"Large Language Model, Elo-ranked review system, reviewer dynamics, peer review, simulation, reviewer personas","This work explores the dynamics of Large Language Model (LLM) agent reviewers in an Elo-ranked review system using real-world conference paper submissions. The study involves multiple LLM agent reviewers with different personas engaging in multi-round review interactions moderated by an Area Chair. The simulation compares a baseline setting with conditions incorporating Elo ratings and reviewer memory. Results indicate that incorporating Elo ratings improves Area Chair decision accuracy and reveals reviewers' adaptive strategies that exploit the Elo system without enhancing review effort. The study addresses challenges in peer review, such as inconsistencies, biases, and low inter-reviewer agreement, by simulating reviewer behavior and providing insights into reviewer dynamics.",3.16,78.129,247,cold_start,Phi-4,Apple_M1(Metal)
2601.08873v1_ForensicFormer Hierarchical Multi-Scale Reasoning .pdf,ForensicFormer: Hierarchical Multi-Scale Reasoning for Cross-Domain Image Forgery Detection,"Hema Hariharan, Samson",,,"Image forensics, forgery detection, transformers, cross-domain generalization, AI-generated images, hierarchical reasoning","The proliferation of AI-generated imagery and sophisticated editing tools has rendered traditional forensic methods ineffective for cross-domain forgery detection. This paper presents ForensicFormer, a hierarchical multi-scale framework that unifies low-level artifact detection, mid-level boundary analysis, and high-level semantic reasoning via cross-attention transformers. Unlike prior single-paradigm approaches that achieve less than 75% accuracy on out-of-distribution datasets, our method maintains 86.8% average accuracy across seven diverse test sets spanning traditional manipulations, GAN-generated images, and diffusion model outputs—a significant improvement over state-of-the-art universal detectors. We demonstrate superior robustness to JPEG compression (83% accuracy at Q=70 vs. 66% for baselines) and provide pixel-level forgery localization with a 0.76 F1-score. Extensive ablation studies validate that each hierarchical component contributes 4-10% accuracy improvement, and qualitative analysis reveals interpretable forensic features aligned with human expert reasoning. Our work bridges classical image forensics and modern deep learning, offering a practical solution for real-world deployment where manipulation techniques are unknown a priori.",3.39,94.382,320,cold_start,Phi-4,Apple_M1(Metal)
2601.08874v1_The Illusion of Friendship Why Generative AI Deman.pdf,The Illusion of Friendship: Why Generative AI Demands Unprecedented Ethical Vigilance,Md Zahidul Islam,,,"Generative AI, Ethical Vigilance, Friendship, Emotional Attachment, Philosophical Argument, Moral Agency, Transformer-based AI, Anthropomorphic Cues, Human Responsibility","Generative AI systems like ChatGPT are increasingly used for various tasks, enhancing productivity and reducing cognitive load. However, their natural-language fluency can blur the line between tool and companion, leading some users to form emotionally significant attachments. This paper explores the 'illusion of friendship' with GenAI, discussing why users might perceive these systems as friend-like and the ethical risks involved. It argues that despite relational appearances, GenAI lacks moral agency and does not qualify as a true friend. The paper provides a mechanism-level explanation of how GenAI generates responses and proposes a safeguard framework for responsible use, emphasizing education, human accountability, and design interventions to mitigate over-reliance and emotional misattribution.",3.35,78.443,263,cold_start,Phi-4,Apple_M1(Metal)
2601.08875v2_Learning Domain-Invariant Representations for Cros.pdf,Learning Domain-Invariant Representations for Cross-Domain Image Registration via Scene-Appearance Disentanglement,"Jiahao Qin, Yiwen Wang",,,"image registration, domain shift, scene-appearance disentanglement, cross-domain alignment, histopathology","Image registration under domain shift is a fundamental challenge in computer vision and medical imaging due to systematic intensity differences violating the brightness constancy assumption. This paper introduces SAR-Net, a framework that addresses this challenge through scene-appearance disentanglement. The framework decomposes images into domain-invariant scene representations and domain-specific appearance codes, enabling registration via re-rendering rather than direct intensity matching. Theoretical conditions for consistent cross-domain alignment and geometric correspondence in the shared latent space are established. Empirical validation on the ANHIR benchmark shows that SAR-Net outperforms the state-of-the-art MEVIS method, achieving a median relative Target Registration Error (rTRE) of 0.25% with robustness of 99.1%.",3.14,77.444,243,cold_start,Phi-4,Apple_M1(Metal)
2601.08881v1_TAG-MoE Task-Aware Gating for Unified Generative M.pdf,TAG-MoE: Task-Aware Gating for Unified Generative Mixture-of-Experts,"Yu Xu, Hongbin Yan, Juan Cao, Yiji Cheng, Tiankai Hang, Runze He, Zijin Yin, Shiyi Zhang, Yuxin Zhang, Jintao Li, Chunyu Wang, Qinglin Lu, Tong-Yee Lee, Fan Tang",,arXiv:2601.08881v1,"cs.CV, Mixture-of-Experts, Generative Models, Diffusion Transformers, Task-Aware Gating, Semantic Intent","Unified image generation and editing models face task interference in dense diffusion transformer architectures due to a shared parameter space that must balance conflicting objectives. The sparse Mixture-of-Experts (MoE) paradigm offers a solution, but its task-agnostic gating networks, which operate based on local features, fail to resolve task interference. This paper introduces a novel framework to inject semantic intent into MoE routing, using a Hierarchical Task Semantic Annotation scheme to create structured task descriptors and Predictive Alignment Regularization to align routing decisions with high-level task semantics. This approach transforms the gating network into a dispatch center, effectively mitigating task interference and outperforming dense baselines in fidelity and quality.",3.59,93.263,335,cold_start,Phi-4,Apple_M1(Metal)
2601.08882v1_Compressing Vision Transformers in Geospatial Tran.pdf,Compressing Vision Transformers in Geospatial Transfer Learning with Manifold-Constrained Optimization,"Thomas Snyder, H. Lexie Yang, Stefan Schnake, Steffen Schotthöfer",,arXiv:2601.08882v1,"Vision Transformers, Geospatial Transfer Learning, Manifold-Constrained Optimization, Compression, Remote Sensing, Foundation Models, Transfer Learning","Deploying geospatial foundation models on resource-constrained edge devices demands compact architectures that maintain high downstream performance. This work leverages a manifold-constrained optimization framework, DLRT, to compress large vision transformer–based geospatial foundation models during transfer learning. By enforcing structured low-dimensional parameterizations aligned with downstream objectives, this approach achieves strong compression while preserving task-specific accuracy. The method outperforms of-the-shelf low-rank methods like LoRA. Experiments on diverse geospatial benchmarks confirm substantial parameter reduction with minimal accuracy loss, enabling high-performing, on-device geospatial models.",3.52,74.414,262,cold_start,Phi-4,Apple_M1(Metal)
2601.08884v1_Bridging the Gap Empowering Small Models in Reliab.pdf,Bridging the Gap: Empowering Small Models in Reliable OpenACC-based Parallelization via GEPA-Optimized Prompting,"Samyak Jhaveri, Cristina V. Lopes",,,"OpenACC, Parallel Code Generation, Large Language Models, Prompt Optimization, High-Performance Computing, GPU Programming","Directive-based parallel programming frameworks like OpenACC lower the barrier to GPU-offloading by abstracting low-level programming details. However, manually writing high-performance pragma remains a significant challenge, requiring expertise in memory hierarchies, data movement, and parallelization strategies. Large Language Models (LLMs) present a promising potential solution for automated parallel code generation, but naive prompting often results in syntactically incorrect directives, uncompilable code, or performance that fails to exceed CPU baselines. This work presents a systematic prompt optimization approach to enhance OpenACC pragma generation without the prohibitive computational costs associated with LLM post-training. The GEPA (GEnetic-PAreto) framework is leveraged to iteratively evolve prompts through a reflective feedback loop, using crossover and mutation of prompt instructions guided by expertly curated 'gold' pragma examples and structured feedback based on clause and parameter-level mismatches between 'gold' pragma and predicted pragma. Evaluation on the PolyBench suite shows a significant increase in compilation success rates for programs annotated with OpenACC pragma generated using optimized prompts, particularly for smaller and cheaper 'nano'-scale models. Optimized prompts resulted in a 21% increase in the number of programs achieving functional GPU speedups over CPU baselines. These results demonstrate that prompt optimization effectively unlocks the potential of smaller, cheaper LLMs to write stable and effective GPU-offloading directives, establishing a cost-effective pathway and lowering the expertise barrier to automated directive-based parallelization in HPC development workflows.",3.59,110.163,396,cold_start,Phi-4,Apple_M1(Metal)
2601.08891v1_Attention Consistency Regularization for Interpret.pdf,Attention Consistency Regularization for Interpretable Early-Exit Neural Networks,Yanhua Zhao,,,"Early exit networks, explainable AI, attention mechanisms, multi-objective learning","Early-exit neural networks enable adaptive inference by allowing predictions at intermediate layers, reducing computational cost. However, early exits often lack interpretability and may focus on different features than deeper layers, limiting trust and explainability. This paper presents Explanation-Guided Training (EGT), a multi-objective framework that improves interpretability and consistency in early-exit networks through attention-based regularization. EGT introduces an attention consistency loss that aligns early-exit attention maps with the final exit. The framework jointly optimizes classification accuracy and attention consistency through a weighted combination of losses. Experiments on a real-world image classification dataset demonstrate that EGT achieves up to 98.97% overall accuracy (matching baseline performance) with a 1.97× inference speedup through early exits, while improving attention consistency by up to 18.5% compared to baseline models. The proposed method provides more interpretable and consistent explanations across all exit points, making early-exit networks more suitable for explainable AI applications in resource-constrained environments.",3.37,80.501,271,cold_start,Phi-4,Apple_M1(Metal)
2601.08892v1_Evaluating Role-Consistency in LLMs for Counselor .pdf,Evaluating Role-Consistency in LLMs for Counselor Training,"Eric Rudolph, Natalie Engert, Jens Albrecht",,2601.08892v1,"Counseling, Chatbot, Large Language Model, Persona Consistency, Educational Role-Play","The rise of online counseling services has highlighted the need for effective training methods for future counselors. This paper extends research on VirCo, a Virtual Client for Online Counseling, designed to complement traditional role-playing methods in academic training by simulating realistic client interactions. Building on previous work, we introduce a new dataset incorporating adversarial attacks to test the ability of large language models (LLMs) to maintain their assigned roles (role-consistency). The study focuses on evaluating the role consistency and coherence of the Vicuna model’s responses, comparing these findings with earlier research. Additionally, we assess and compare various open-source LLMs for their performance in sustaining role consistency during virtual client interactions. Our contributions include creating an adversarial dataset, evaluating conversation coherence and persona consistency, and providing a comparative analysis of different LLMs.",3.53,78.427,277,cold_start,Phi-4,Apple_M1(Metal)
2601.08896v1_XGBoost Forecasting of NEPSE Index Log Returns wit.pdf,XGBoost Forecasting of NEPSE Index Log Returns with Walk Forward Validation,"Sahaj Raj Mallaa, Shreeyash Kayastha, Rumi Suwala, Harish Chandra Bhandaria, Rajendra Adhikari",,,"NEPSE Index, stock index forecasting, XGBoost, walk-forward validation, hyperparameter optimization, time series forecasting, emerging markets, feature engineering","This study develops a robust machine learning framework for one-step-ahead forecasting of daily log-returns in the Nepal Stock Exchange (NEPSE) Index using the XGBoost regressor. A comprehensive feature set is engineered, including lagged log-returns (up to 30 days) and established technical indicators such as short- and medium-term rolling volatility measures and the 14-period Relative Strength Index. Hyperparameter optimization is performed using Optuna with time-series cross-validation on the initial training segment. Out-of-sample performance is rigorously assessed via walk-forward validation under both expanding and fixed-length rolling windows schemes across multiple lag configurations, simulating real-world deployment and avoiding lookahead bias. Predictive accuracy is evaluated using root mean squared error, mean absolute error, coefficient of determination (R2), and directional accuracy on both log-returns and reconstructed closing prices. Empirical results show that the optimal configuration—an expanding window with 20 lags—outperforms tuned ARIMA and Ridge regression benchmarks, achieving the lowest log-return RMSE (0.013450) and MAE (0.009814) alongside a directional accuracy of 65.15%. While the R2 remains modest, consistent with the noisy nature of financial returns, primary emphasis is placed on relative error reduction and directional prediction. Feature importance analysis and visual inspection further enhance interpretability. These findings demonstrate the effectiveness of gradient boosting ensembles in modeling nonlinear dynamics in volatile emerging market time series and establish a reproducible benchmark for NEPSE Index forecasting.",3.69,122.527,452,cold_start,Phi-4,Apple_M1(Metal)
2601.08901v1_Navigating Ideation Space Decomposed Conceptual Re.pdf,Navigating Ideation Space: Decomposed Conceptual Representations for Positioning Scientific Ideas,"Yuexi Shen, Minqian Liu, Dawei Zhou, Lifu Huang",,,"scientific discovery, conceptual representations, literature retrieval, novelty assessment, embedding approaches, ideation space, contrastive training","Scientific discovery is a cumulative process that requires new ideas to be situated within an expanding landscape of existing knowledge. This paper introduces the Ideation Space, a structured representation that decomposes scientific knowledge into three dimensions: research problem, methodology, and core findings. This framework enables the measurement of conceptual distance between ideas and modeling of ideation transitions. The paper also proposes a Hierarchical Sub-Space Retrieval framework for efficient literature retrieval and a Decomposed Novelty Assessment algorithm to identify novel aspects of an idea. Experiments show substantial improvements in recall and hit rate, with novelty assessment correlating well with expert judgments. The work provides a promising paradigm for accelerating and evaluating scientific discovery.",3.29,78.422,258,cold_start,Phi-4,Apple_M1(Metal)
2601.08910v1_Towards a Self-Driving Trigger at the LHC Adaptive.pdf,Towards a Self-Driving Trigger at the LHC: Adaptive Response in Real Time,"Shaghayegh Emami, Cecilia Tosciri, Giovanna Salvi, Zixin Ding, Yuxin Chen, Abhijith Gandrakota, Christian Herwig, David W. Miller, Jennifer Ngadiuba, Nhan Tran",,arXiv:2601.08910v1,physics.ins-det,"Real-time data filtering and selection – ortrigger– systems at high-throughput scientific facilities such as the experiments at the Large Hadron Collider (LHC) must process extremely high-rate data streams under stringent bandwidth, latency, and storage constraints. Yet these systems are typically designed as static, hand-tuned menus of selection criteria grounded in prior knowledge and simulation. In this work, we further explore the concept of a self-driving trigger, an autonomous data-filtering framework that reallocates resources and adjusts thresholds dynamically in real-time to optimize signal efficiency, rate stability, and computational cost as instrumentation and environmental conditions evolve. We introduce a benchmark ecosystem to emulate realistic collider scenarios and demonstrate real-time optimization of a menu including canonical energy sum triggers as well as modern anomaly-detection algorithms that target non-standard event topologies using machine learning. Using simulated data streams and publicly available collision data from the Compact Muon Solenoid (CMS) experiment, we demonstrate the capability to dynamically and automatically optimize trigger performance under specific cost objectives without manual retuning. Our adaptive strategy shifts trigger design from static menus with heuristic tuning to intelligent, automated, data-driven control, unlocking greater flexibility and discovery potential in future high-energy physics analyses.",4.09,95.439,390,cold_start,Phi-4,Apple_M1(Metal)
2601.08950v1_ConvoLearn A Dataset of Constructivist Tutor-Stude.pdf,ConvoLearn: A Dataset of Constructivist Tutor-Student Dialogue,"Mayank Sharma, Roy Pea, Hari Subramonyam",,,"LLMs, pedagogical limitations, knowledge-building theory, tutor-student dialogues, constructivist AI tutors, educational NLP","In educational applications, Large Language Models (LLMs) often reveal solutions rather than support dialogic learning. This paper introduces ConvoLearn, a dataset grounded in knowledge-building theory, operationalizing six core pedagogical dimensions: cognitive engagement, formative assessment, accountability, cultural responsiveness, metacognition, and power dynamics. The dataset consists of 1,250 semi-synthetic tutor-student dialogues in middle school Earth Science, created through controlled interactions between human teachers and a simulated student. Training on this dataset using QLoRA shifts LLM behavior towards knowledge-building strategies. Human evaluation by 31 teachers shows that the fine-tuned Mistral-7B model significantly outperforms its base version and Claude Sonnet 4.5. This work establishes a framework for developing and evaluating constructivist AI tutors.",3.3,79.907,264,cold_start,Phi-4,Apple_M1(Metal)
2601.08951v1_PluriHarms Benchmarking the Full Spectrum of Human.pdf,PLURIHARMS: BENCHMARKING THE FULL SPECTRUM OF HUMAN JUDGMENTS ON AI HARM,"Jing-Jing Li, Joel Mire, Eve Fleisig, Valentina Pyatkin, Anne G. E. Collins, Maarten Sap, Sydney Levine",,,"AI safety, human judgments, harm benchmark, pluralistic AI, human values, disagreement analysis","Current AI safety frameworks often treat harmfulness as binary, which limits their ability to handle borderline cases where human judgments differ. To develop more pluralistic AI systems, it is crucial to understand where and why these disagreements occur. This paper introduces PLURIHARMS, a benchmark designed to study human harm judgments across two dimensions: the harm axis (ranging from benign to harmful) and the agreement axis (ranging from agreement to disagreement). The benchmark includes 150 prompts with 15,000 ratings from 100 human annotators, incorporating demographic and psychological traits. The study reveals that imminent risks and tangible harms increase perceived harmfulness, while annotator traits and their interactions with prompt content explain systematic disagreements. The benchmark also evaluates AI safety models and alignment methods, showing that personalization improves predictions of human harm judgments, though there is still significant room for improvement. By focusing on value diversity and disagreement, PLURIHARMS aims to advance beyond one-size-fits-all safety approaches toward pluralistically safe AI.",3.69,95.649,353,cold_start,Phi-4,Apple_M1(Metal)
2601.08953v1_Fairness risk and its privacy-enabled solution in .pdf,Fairness risk and its privacy-enabled solution in AI-driven robotic applications,"Le Liu, Bangguo Yu, Nynke Vellinga, Ming Cao",,arXiv:2601.08953v1,"Robotic Decision-making, Large Language Model, Fairness, Privacy","Complex decision-making by autonomous machines and algorithms could underpin the foundations of future society. Generative AI is emerging as a powerful engine for such transitions. However, we show that Generative AI-driven developments pose a critical pitfall: fairness concerns. In robotic applications, although intuitions about fairness are common, a precise and implementable definition that captures user utility and inherent data randomness is missing. Here we provide a utility-aware fairness metric for robotic decision-making and analyze fairness jointly with user-data privacy, deriving conditions under which privacy budgets govern fairness metrics. This yields a unified framework that formalizes and quantifies fairness and its interplay with privacy, which is tested in a robot navigation task. In view of the fact that under legal requirements, most robotic systems will enforce user privacy, the approach shows surprisingly that such privacy budgets can be jointly used to meet fairness targets. Addressing fairness concerns in the creative combined consideration of privacy is a step towards ethical use of AI and strengthens trust in autonomous robots deployed in everyday environments.",3.97,79.909,317,cold_start,Phi-4,Apple_M1(Metal)
2601.08955v1_Imagine-then-Plan Agent Learning from Adaptive Loo.pdf,Imagine-then-Plan: Agent Learning from Adaptive Lookahead with World Models,"Youwei Liu, Jian Wang, Hanlin Wang, Beichen Guo, Wenjie Li",,,"world models, agent learning, adaptive lookahead, multi-step trajectories, Markov decision process","Recent advances in world models have shown promise for modeling future dynamics of environmental states, enabling agents to reason and act without accessing real environments. Current methods mainly perform single-step or fixed-horizon rollouts, leaving their potential for complex task planning under-exploited. We propose Imagine-then-Plan (ITP), a unified framework for agent learning via lookahead imagination, where an agent’s policy model interacts with the learned world model, yielding multi-step 'imagined' trajectories. Since the imagination horizon may vary by tasks and stages, we introduce a novel adaptive lookahead mechanism by trading off the ultimate goal and task progress. The resulting imagined trajectories provide rich signals about future consequences, such as achieved progress and potential conflicts, which are fused with current observations, formulating a partially observable and imaginable Markov decision process to guide policy learning. We instantiate ITP with both training-free and reinforcement-trained variants. Extensive experiments across representative agent benchmarks demonstrate that ITP significantly outperforms competitive baselines. Further analyses validate that our adaptive lookahead largely enhances agents’ reasoning capability, providing valuable insights into addressing broader, complex tasks.",3.44,97.58,336,cold_start,Phi-4,Apple_M1(Metal)
2601.08988v1_ART Action-based Reasoning Task Benchmarking for M.pdf,Action-based Reasoning Task Benchmarking for Medical AI Agents,"Ananya Mantravadi, Shivali Dalmia, Abhishek Mukherji",,,"Medical AI agents, synthetic data generation, clinical reasoning evaluation, healthcare LLMs, benchmark, HITL","Reliable clinical decision support requires medical AI agents capable of safe, multi-step reasoning over structured electronic health records (EHRs). While large language models (LLMs) show promise in healthcare, existing benchmarks inadequately assess performance on action-based tasks involving threshold evaluation, temporal aggregation, and conditional logic. This paper introduces ART, an Action-based Reasoning clinical Task benchmark for medical AI agents, which mines real-world EHR data to create challenging tasks targeting known reasoning weaknesses. The evaluation of GPT-4o-mini and Claude 3.5 Sonnet on 600 tasks reveals near-perfect retrieval after prompt refinement, but substantial gaps in aggregation (28-64%) and threshold reasoning (32-38%). By exposing failure modes in action-oriented EHR reasoning, ART advances toward more reliable clinical agents, supporting workforce capacity in high-demand care settings.",3.52,74.646,263,cold_start,Phi-4,Apple_M1(Metal)
2601.09012v3_TranslateGemma Technical Report.pdf,TranslateGemma Technical Report,Google Translate Research Team,,,"machine translation, Gemma 3, fine-tuning, reinforcement learning, multilingual models, WMT25, WMT24++, multimodal capabilities","TranslateGemma is a suite of open machine translation models based on the Gemma 3 foundation models. It employs a two-stage fine-tuning process: supervised fine-tuning using high-quality synthetic and human-translated parallel data, followed by reinforcement learning with reward models to optimize translation quality. The models demonstrate significant improvements over baseline Gemma 3 models across various language pairs and retain strong multimodal capabilities. The open release of TranslateGemma aims to provide powerful tools for the research community.",3.08,60.154,185,cold_start,Phi-4,Apple_M1(Metal)
2601.09018v1_Meta-learning to Address Data Shift in Time Series.pdf,META-LEARNING TO ADDRESS DATA SHIFT IN TIME SERIES CLASSIFICATION,"Samuel Myrenab, Nidhi Parikha, Natalie Kleina",,2601.09018v1,"signals, seismology, Reptile, FOMAML, model-agnostic meta-learning, domain generalization","Across engineering and scientific domains, traditional deep learning (TDL) models perform well when training and test data share the same distribution. However, the dynamic nature of real-world data, broadly termed data shift, renders TDL models prone to rapid performance degradation, requiring costly relabeling and inefficient retraining. Meta-learning, which enables models to adapt quickly to new data with few examples, offers a promising alternative for mitigating these challenges. Here, we systematically compare TDL with fine-tuning and optimization-based meta-learning algorithms to assess their ability to address data shift in time-series classification. We introduce a controlled, task-oriented seismic benchmark (SeisTask) and show that meta-learning typically achieves faster and more stable adaptation with reduced overfitting in data-scarce regimes and smaller model architectures. As data availability and model capacity increase, its advantages diminish, with TDL with fine-tuning performing comparably. Finally, we examine how task diversity influences meta-learning and find that alignment between training and test distributions, rather than diversity alone, drives performance gains. Overall, this work provides a systematic evaluation of when and why meta-learning outperforms TDL under data shift and contributes SeisTask as a benchmark for advancing adaptive learning research in time-series domains.",3.73,99.719,372,cold_start,Phi-4,Apple_M1(Metal)
2601.09028v1_OpenDecoder Open Large Language Model Decoding to .pdf,OpenDecoder: Open Large Language Model Decoding to Incorporate Document Quality in RAG,"Fengran Mo, Zhan Su, Yuchen Hui, Jianhan Zhang, Jia Ao Sun, Zheyuan Liu, Chao Zhang, Tetsuya Sakai, Jian-Yun Nie",https://doi.org/10.1145/nnnnnnn.nnnnnnn,,"Information Retrieval, Retrieval-Augmented Generation, Robust Question Answer, Decoding Paradigm, Large Language Model","The development of large language models (LLMs) has achieved superior performance in a range of downstream tasks, including LLM-based retrieval-augmented generation (RAG). The quality of generated content heavily relies on the usefulness of the retrieved information and the capacity of LLMs’ internal information processing mechanism to incorporate it in answer generation. It is generally assumed that the retrieved information is relevant to the question. However, the retrieved information may have a variable degree of relevance and usefulness, depending on the question and the document collection. It is important to take into account the relevance of the retrieved information in answer generation. In this paper, we propose OpenDecoder, a new approach that leverages explicit evaluation of the retrieved information as quality indicator features for generation. We aim to build a RAG model that is more robust to varying levels of noisy context. Three types of explicit evaluation information are considered: relevance score, ranking score, and QPP (query performance prediction) score. The experimental results on five benchmark datasets demonstrate the effectiveness and better robustness of OpenDecoder by outperforming various baseline methods. Importantly, this paradigm is flexible to be integrated with the post-training of LLMs for any purposes and incorporated with any type of external indicators.",3.67,115.132,422,cold_start,Phi-4,Apple_M1(Metal)
2601.09029v1_Proactively Detecting Threats A Novel Approach Usi.pdf,Proactively Detecting Threats: A Novel Approach Using LLMs,"Aniesh Chawla, Udbhav Prasad",,,"Malware, Indicators of Compromise, Cybersecurity, LLMs, GenAI, Machine Learning Algorithms, Deep Neural Network","Enterprise security faces escalating threats from sophisticated malware, compounded by expanding digital operations. This paper presents the first systematic evaluation of large language models (LLMs) to proactively identify indicators of compromise (IOCs) from unstructured web-based threat intelligence sources, distinguishing it from reactive malware detection approaches. An automated system was developed to pull IOCs from 15 web-based threat report sources to evaluate six LLM models (Gemini, Qwen, and Llama variants). The evaluation of 479 webpages containing 2,658 IOCs (711 IPv4 addresses, 502 IPv6 addresses, 1,445 domains) reveals significant performance variations. Gemini 1.5 Pro achieved 0.958 precision and 0.788 specificity for malicious IOC identification, while demonstrating perfect recall (1.0) for actual threats. The paper explores the potential of LLMs for proactive identification of IOCs, aiming to shift from reactive to proactive cybersecurity measures.",3.4,82.634,281,cold_start,Phi-4,Apple_M1(Metal)
2601.09031v1_Generalizable Geometric Prior and Recurrent Spikin.pdf,Generalizable Geometric Prior and Recurrent Spiking Feature Learning for Humanoid Robot Manipulation,"Xuetao Li, Wenke Huang, Mang Ye, Jifeng Xuan, Bo Du, Sheng Liu, Miao Li",,,"Humanoid Robot Manipulation, Geometric Prior, Recurrent Spiking Feature Learning","Humanoid robot manipulation is a crucial research area for executing diverse human-level tasks, involving high-level semantic reasoning and low-level action generation. This paper presents a novel RGMP-S, Recurrent Geometric-prior Multimodal Policy with Spiking features, facilitating both high-level skill reasoning and data-efficient motion synthesis. The approach leverages lightweight 2D geometric inductive biases for precise 3D scene understanding within the vision-language model. A Long-horizon Geometric Prior Skill Selector aligns semantic instructions with spatial constraints, achieving robust generalization in unseen environments. A Recursive Adaptive Spiking Network parameterizes robot-object interactions for spatiotemporal consistency, distilling long-horizon dynamic features while mitigating overfitting in sparse demonstration scenarios. Extensive experiments across the Maniskill simulation benchmark and three heterogeneous real-world robotic systems validate the method's superiority over state-of-the-art baselines and its efficacy in diverse generalization scenarios. The source code and video demonstrations are publicly available.",3.65,89.314,326,cold_start,Phi-4,Apple_M1(Metal)
2601.09032v1_The Hierarchy of Agentic Capabilities Evaluating F.pdf,The Hierarchy of Agentic Capabilities: Evaluating Frontier Models on Realistic RL Environments,"Logan Ritchie, Sushant Mehta, Nick Heiner, Mason Yu, Edwin Chen",,arXiv:2601.09032v1,"large language models, multi-step task completion, interactive environments, realistic e-commerce RL environment, agentic capabilities, tool use, planning and goal formation, adaptability, groundedness, common-sense reasoning, task-centric design methodology, failure analysis, agent development","The advancement of large language model (LLM) based agents has shifted AI evaluation from single-turn response assessment to multi-step task completion in interactive environments. This study evaluates frontier AI models on 150 workplace tasks within a realistic e-commerce RL environment from Surge. An empirically-derived hierarchy of agentic capabilities is revealed: tool use, planning and goal formation, adaptability, groundedness, and common-sense reasoning. Even the best-performing models fail approximately 40% of the tasks, with failures clustering predictably along this hierarchy. Weaker models struggle with fundamental tool use and planning, whereas stronger models primarily fail on tasks requiring contextual inference beyond explicit instructions. A task-centric design methodology for RL environments is introduced, emphasizing diversity and domain expert contributions, along with detailed failure analysis and implications for agent development. The findings suggest that while current frontier models can demonstrate coherent multi-step behavior, substantial capability gaps remain before achieving human-level task completion in realistic workplace settings.",3.84,97.692,375,cold_start,Phi-4,Apple_M1(Metal)
2601.09035v1_A Decompilation-Driven Framework for Malware Detec.pdf,A Decompilation-Driven Framework for Malware Detection with Large Language Models,"Aniesh Chawla, Udbhav Prasad",,arXiv:2601.09035v1,"Malware, Ghidra, Cybersecurity, LLMs, GenAI, Machine Learning Algorithms, LLMs Code development","The paper evaluates the efficacy of state-of-the-art Large Language Models (LLMs) in classifying executable code as either benign or malicious. An automated pipeline is introduced that first decompiles Windows executable into C code using the Ghidra disassembler and then leverages LLMs for classification. While standard LLMs show promise, they are not yet robust enough to replace traditional anti-virus software. A fine-tuned model trained on curated datasets significantly outperforms its vanilla counterpart, but performance degrades with newer malware. Continuous fine-tuning with emerging threats is necessary to maintain effectiveness against changing coding patterns and behaviors of malicious software.",3.38,70.189,237,cold_start,Phi-4,Apple_M1(Metal)
2601.09041v1_Can LLMs interpret figurative language as humans d.pdf,CANLLMS INTERPRET FIGURATIVE LANGUAGE AS HUMANS DO?: SURFACE-LEVEL VS. REPRESENTATIONAL SIMILARITY,"Samhita Bollepally, Aurora Sloman-Moll, Takashi Yamauchi",,,"large language models, figurative language, human judgment, sarcasm, idiomacy, slang, contextual cues, pragmatic inference, linguistic traits","Large language models (LLMs) generate judgments that resemble those of humans at a surface level, but diverge significantly at a representational level, especially in interpreting figurative sentences involving idioms and Gen Z slang. The study compares human participants with four instruction-tuned LLMs (GPT-4, Gemma-2-9B, Llama-3.2, and Mistral-7B) on 240 dialogue-based sentences representing six linguistic traits. Results show that while GPT-4 most closely approximates human representational patterns, all models struggle with context-dependent and socio-pragmatic expressions like sarcasm, slang, and idiomacy. The findings suggest that LLMs may match humans on surface-level judgments but differ in deeper interpretive processes, varying with each model.",3.55,87.908,312,cold_start,Phi-4,Apple_M1(Metal)
2601.09049v1_Is Grokking Worthwhile Functional Analysis and Tra.pdf,Is Grokking Worthwhile? Functional Analysis and Transferability of Generalization Circuits in Transformers,"Kaiyu He, Mian Zhang, Peilin Wu, Xinya Du, Zhiyu Zoey Chen",,,"Large Language Models, curse of two-hop reasoning, parameter-sharing transformers, Generalization Circuit, grokking, compositional tasks, knowledge assimilation, transferability","The paper investigates whether the 'grokking' phase in parameter-sharing transformers, which forms a 'Generalization Circuit', is beneficial for downstream tasks. It explores if grokked models are superior to non-grokked ones and whether the computational cost of grokking is justified. The study finds that grokking integrates memorized facts into existing reasoning paths rather than creating new ones, and that high accuracy on unseen cases and reasoning path formation are independent. It also notes limited transferability of mature circuits in integrating new knowledge, suggesting that grokked transformers do not fully master compositional logic.",3.37,78.749,265,cold_start,Phi-4,Apple_M1(Metal)
2601.09066v1_Midm 2.0 Korea-centric Bilingual Language Models.pdf,Mi:dm 2.0: Korea-centric Bilingual Language Models,"Tech. Innovation Group, KT",,arXiv:2601.09066v1,"Korea-centric AI, bilingual language models, Korean language processing, cultural alignment, large language models","We introduce Mi:dm 2.0, a bilingual large language model (LLM) specifically engineered to advance KOREA-CENTRIC AI. This model goes beyond Korean text processing by integrating the values, reasoning patterns, and commonsense knowledge inherent to Korean society, enabling nuanced understanding of cultural contexts, emotional subtleties, and real-world scenarios to generate reliable, culturally appropriate responses. To address limitations of existing LLMs—often caused by insufficient or low-quality Korean data and lack of cultural alignment—Mi:dm 2.0 emphasizes robust data quality through a comprehensive pipeline that includes proprietary data cleansing, high-quality synthetic data generation, strategic data mixing with curriculum learning, and a custom Korean-optimized tokenizer to improve efficiency and coverage. To realize this vision, we offer two complementary configurations: Mi:dm 2.0 Base (11.5B parameters), built with a Depth-up Scaling strategy for general-purpose use, and Mi:dm 2.0 Mini (2.3B parameters), optimized for resource-constrained environments and specialized tasks. Mi:dm 2.0 achieves state-of-the-art performance in Korean-specific benchmarks, with top-tier zero-shot results on KMMLU and strong results in internal evaluations across language, humanities, and social science tasks. The Mi:dm 2.0 lineup is released under the MIT license supporting extensive research and commercial use. By offering these accessible and high-performance Korea-centric LLMs, KT aims to accelerate AI adoption across Korean industries, public services, and education, while strengthening the Korean AI developer community and laying the groundwork for the broader vision of K-intelligence.",3.88,109.395,424,cold_start,Phi-4,Apple_M1(Metal)
2601.09069v1_From Symbolic to Natural-Language Relations Rethin.pdf,From Symbolic to Natural-Language Relations: Rethinking Knowledge Graph Construction in the Era of Large Language Models,"Kanyao Han, Yushang Lai",,,"Knowledge Graphs, Symbolic Relations, Natural-Language Relations, Large Language Models, Knowledge Representation","Knowledge graphs (KGs) have traditionally been constructed using predefined symbolic relation schemas, typically implemented as categorical relation labels. This design has notable shortcomings, as real-world relations are often contextual, nuanced, and sometimes uncertain, leading to the abstraction of critical semantic details. Despite these issues, symbolic-relation KGs remain widely used due to their operational effectiveness and compatibility with pre-LLM downstream models and algorithms. The emergence of large language models (LLMs) has reshaped how knowledge is created and consumed, supporting scalable synthesis of domain facts in concise natural language and favoring context-rich free-form text over quantified representations. This position paper argues for rethinking the representation of relations themselves, advocating a shift from symbolic to natural-language relation descriptions. It proposes hybrid design principles that preserve a minimal structural backbone while enabling more flexible and context-sensitive relational representations.",3.41,76.314,260,cold_start,Phi-4,Apple_M1(Metal)
2601.09072v1_Human-AI Co-design for Clinical Prediction Models.pdf,Human-AI Co-design for Clinical Prediction Models,"Jean Feng, Avni Kothari, Patrick Vossler, Andrew Bishara, Lucas Zier, Newton Addo, Aaron Kornblith, Yan Shuo Tan, Chandan Singh",,arXiv:2601.09072v1,"Large language models, Electronic health records, Concept Bottleneck, Human-AI Interaction","Developing safe, effective, and practically useful clinical prediction models (CPMs) traditionally requires iterative collaboration between clinical experts, data scientists, and informaticists. This process refines the often small but critical details of the model building process, such as which features/patients to include and how clinical categories should be defined. However, this traditional collaboration process is extremely time- and resource-intensive, resulting in only a small fraction of CPMs reaching clinical practice. This challenge intensifies when teams attempt to reliably incorporate information from unstructured clinical notes, which can contain an essentially infinite number of concepts. To address this challenge, we introduce HACHI, an iterative human-in-the-loop framework that uses AI agents to accelerate the development of fully interpretable CPMs by enabling the exploration of concepts in clinical notes. HACHI alternates between (i) an AI agent rapidly exploring and evaluating candidate concepts in clinical notes and (ii) clinical and domain experts providing feedback to improve the CPM learning process. HACHI defines concepts as simple yes-no questions that are used in linear models, allowing the clinical AI team to transparently review, refine, and validate the CPM learned in each round. In two real-world prediction tasks (acute kidney injury and traumatic brain injury), HACHI outperforms existing approaches, surfaces new clinically relevant concepts not included in commonly-used CPMs, and improves model generalizability across clinical sites and time periods. Furthermore, HACHI reveals the critical role of the clinical AI team, such as directing the AI agent to explore entire categories of concepts that it had not previously considered, adjusting the granularity of concepts it considers, changing the objective function to better align with the clinical objectives, and identifying issues of data bias and leakage. Code for HACHI is available at http://github.com/jjfenglab/HACHI.",3.94,130.849,515,cold_start,Phi-4,Apple_M1(Metal)
2601.09085v1_MMR-GRPO Accelerating GRPO-Style Training through .pdf,MMR-GRPO: Accelerating GRPO-Style Training through Diversity-Aware Reward Reweighting,"Kangda Wei, Ruihong Huang",,,"Group Relative Policy Optimization, GRPO, Maximal Marginal Relevance, mathematical reasoning, reinforcement learning, training efficiency","Group Relative Policy Optimization (GRPO) is a standard approach for training mathematical reasoning models, but its reliance on multiple completions per prompt makes it computationally expensive. MMR-GRPO integrates Maximal Marginal Relevance to reweigh rewards based on completion diversity, prioritizing diverse solutions for more informative updates and faster convergence. Evaluations show MMR-GRPO achieves comparable peak performance with significantly fewer training steps and less wall-clock time. The code, trained models, and experimental protocols will be released.",2.87,70.808,203,cold_start,Phi-4,Apple_M1(Metal)
2601.09089v1_SubTokenTest A Practical Benchmark for Real-World .pdf,SUBTOKENTEST: A Practical Benchmark for Real-World Sub-token Understanding,"Shuyang Hou, Yi Hu, Muhan Zhang",,arXiv:2601.09089v1,"large language models, sub-token understanding, tokenization, character-level tasks, real-world applications, benchmark","Recent advancements in large language models (LLMs) have enhanced their reasoning capabilities, yet they struggle with basic character-level tasks due to tokenization issues. This paper introduces SUBTOKENTEST, a benchmark assessing sub-token understanding through practical tasks across four domains. It evaluates nine advanced LLMs, investigates test-time scaling effects on sub-token reasoning, and explores character-level information encoding within hidden states. The benchmark includes tasks that isolate tokenization-related failures, providing a comprehensive evaluation of LLMs' sub-token handling capabilities.",3.14,71.29,224,cold_start,Phi-4,Apple_M1(Metal)
2601.09097v1_Programming over Thinking Efficient and Robust Mul.pdf,Programming over Thinking: Efficient and Robust Multi-Constraint Planning,"Derrick Goh Xin Deik, Quanyu Long, Zhengyuan Liu, Nancy F. Chen, Wenya Wang",,,"multi-constraint planning, large language models, reasoning paradigms, solver-based strategies, Scalable Code Planning Engine (SCOPE), GPT-4o, TravelPlanner","Multi-constraint planning involves identifying, evaluating, and refining candidate plans while satisfying multiple, potentially conflicting constraints. Existing large language model (LLM) approaches face limitations in this domain. Pure reasoning paradigms are prone to inconsistency, error accumulation, and prohibitive cost as constraints compound. Conversely, LLMs combined with coding- or solver-based strategies lack flexibility and often generate problem-specific code from scratch or depend on fixed solvers, failing to capture generalizable logic across diverse problems. To address these challenges, the Scalable Code Planning Engine (SCOPE) is introduced, which disentangles query-specific reasoning from generic code execution. By separating reasoning from execution, SCOPE produces solver functions that are consistent, deterministic, and reusable across queries while requiring only minimal changes to input parameters. SCOPE achieves state-of-the-art performance while lowering cost and latency. For example, with GPT-4o, it reaches 93.1% success on TravelPlanner, a 61.6% gain over the best baseline (CoT) while cutting inference cost by 1.4x and time by 4.67x.",3.62,102.648,372,cold_start,Phi-4,Apple_M1(Metal)
2601.09100v2_DScheLLM Enabling Dynamic Scheduling through a Fin.pdf,schellm: Enabling Dynamic Scheduling through a Fine-Tuned Dual-System Large Language Model,"Lixiang Zhang, Chenggong Zhao, Qing Gao, Xiaoke Zhao, Gengyi Bai, Jinhu Lv",,,"dynamic scheduling, large language model, fine-tuning, job shop scheduling","Production scheduling is highly susceptible to dynamic disruptions, such as variations in processing times, machine availability, and unexpected task insertions. Conventional approaches typically rely on event-specific models and explicit analytical formulations, which limits their adaptability and generalization across previously unseen disturbances. To overcome these limitations, this paper proposes DScheLLM, a dynamic scheduling approach that leverages fine-tuned large language models within a dual-system (fast–slow) reasoning architecture to address disturbances of different scales. A unified large language model-based framework is constructed to handle dynamic events, where training datasets for both fast and slow reasoning modes are generated using exact schedules obtained from an operations research solver. The Huawei OpenPangu Embedded-7B model is subsequently fine-tuned under the hybrid reasoning paradigms using LoRA. Experimental evaluations on standard job shop scheduling benchmarks demonstrate that the fast-thinking mode can efficiently generate high-quality schedules and the slow-thinking mode can produce solver-compatible and well-formatted decision inputs. To the best of our knowledge, this work represents one of the earliest studies applying large language models to job shop scheduling in dynamic environments, highlighting their considerable potential for intelligent and adaptive scheduling optimization.",3.57,93.504,334,cold_start,Phi-4,Apple_M1(Metal)
2601.09105v2_AviationLMM A Large Multimodal Foundation Model fo.pdf,AviationLMM: A Large Multimodal Foundation Model for Civil Aviation,"Wenbin Li, Jingling Wu, Xiaoyong Lin, Jing Chen, Cong Chen",,,"civil aviation, multi-modal model, foundation model, cloud edge collaboration, hybrid training, computer systems organization, computing methodologies","Civil aviation is a cornerstone of global transportation and commerce, and ensuring its safety, efficiency, and customer satisfaction is paramount. Conventional Artificial Intelligence (AI) solutions in aviation remain siloed and narrow, focusing on isolated tasks or single modalities. This paper introduces the vision of AviationLMM, a Large Multimodal foundation Model for civil aviation, designed to unify the heterogeneous data streams of civil aviation and enable understanding, reasoning, generation, and agentic applications. The model architecture ingests multimodal inputs such as air-ground voice, surveillance, on-board telemetry, video, and structured texts, and performs cross-modal alignment and fusion, producing flexible outputs ranging from situation summaries and risk alerts to predictive diagnostics and multimodal incident reconstructions. Key research opportunities identified include data acquisition, alignment and fusion, pretraining, reasoning, trustworthiness, privacy, robustness to missing modalities, and synthetic scenario generation. The paper aims to boost civil aviation foundation model progress and catalyze coordinated research efforts toward an integrated, trustworthy, and privacy-preserving aviation AI ecosystem.",3.6,94.843,341,cold_start,Phi-4,Apple_M1(Metal)
2601.09113v1_The AI Hippocampus How Far are We From Human Memor.pdf,The AI Hippocampus: How Far are We From Human Memory?,"Zixia Jia, Jiaqi Li, Yipeng Kang, Yuxuan Wang, Tong Wu, Quansen Wang, Xiaobo Wang, Shuyi Zhang, Junzhe Shen, Qing Li, Siyuan Qi, Yitao Liang, Di He, Zilong Zheng, Song-Chun Zhu",,arXiv:2601.09113v1,"memory, Large Language Models, Multi-Modal LLMs, implicit memory, explicit memory, agentic memory, architecture, multi-modal settings, AI","Memory plays a foundational role in augmenting the reasoning, adaptability, and contextual fidelity of modern Large Language Models (LLMs) and Multi-Modal LLMs (MLLMs). As these models transition from static predictors to interactive systems capable of continual learning and personalized inference, the incorporation of memory mechanisms has emerged as a central theme in their architectural and functional evolution. This survey presents a comprehensive and structured synthesis of memory in LLMs and MLLMs, organizing the literature into a cohesive taxonomy comprising implicit, explicit, and agentic memory paradigms. Specifically, the survey delineates three primary memory frameworks. Implicit memory refers to the knowledge embedded within the internal parameters of pre-trained transformers, encompassing their capacity for memorization, associative retrieval, and contextual reasoning. Recent work has explored methods to interpret, manipulate, and reconfigure this latent memory. Explicit memory involves external storage and retrieval components designed to augment model outputs with dynamic, queryable knowledge representations—such as textual corpora, dense vectors, and graph-based structures—thereby enabling scalable and updatable interaction with information sources. Agentic memory introduces persistent, temporally extended memory structures within autonomous agents, facilitating long-term planning, self-consistency, and collaborative behavior in multi-agent systems, with relevance to embodied and interactive AI. Extending beyond text, the survey examines the integration of memory within multi-modal settings, where coherence across vision, language, audio, and action modalities is essential. Key architectural advances, benchmark tasks, and open challenges are discussed, including issues related to memory capacity, alignment, factual consistency, and cross-system interoperability. By charting the current landscape and identifying critical research directions, this survey aims to inform the development of memory-augmented (M)LLMs that are more flexible, context-sensitive, and aligned with the requirements of real-world intelligent systems.",4.14,141.506,586,cold_start,Phi-4,Apple_M1(Metal)
2601.09116v1_LP-LLM End-to-End Real-World Degraded License Plat.pdf,LP-LLM: End-to-End Real-World Degraded License Plate Text Recognition via Large Multimodal Models,"Haoyan Gong, Hongbin Liu",,,"License Plate Recognition, Real-World Degradations, Vision-Language Models, Multimodal Reasoning, Character Recognition","Real-world License Plate Recognition (LPR) faces significant challenges from severe degradations such as motion blur, low resolution, and complex illumination. The prevailing 'restoration-then-recognition' two-stage paradigm suffers from misalignment between image restoration models' pixel-level optimization objectives and the semantic goals of character recognition, leading to artifact interference and error accumulation. This paper proposes an end-to-end structure-aware multimodal reasoning framework based on Qwen3-VL, featuring a Character-Aware Multimodal Reasoning Module (CMRM) with learnable Character Slot Queries. These queries retrieve fine-grained evidence from visual features and inject character-aware representations back into visual tokens via residual modulation, enabling autoregressive generation based on explicit structural priors. Combined with the LoRA parameter-efficient fine-tuning strategy, the model achieves domain adaptation while retaining generalization capabilities. Extensive experiments demonstrate significant performance improvements over existing methods on severely degraded datasets, validating the superiority of incorporating structured reasoning into large models for low-quality text recognition tasks.",3.6,81.849,295,cold_start,Phi-4,Apple_M1(Metal)
2601.09117v1_A Marketplace for AI-Generated Adult Content and D.pdf,A Marketplace for AI-Generated Adult Content and Deepfakes,"Shalmoli Ghosh, Matthew R. DeVerna, Filippo Menczer",,,"Generative AI, synthetic media, bounties, deepfakes, content moderation, gendered harms","Generative AI systems increasingly enable the production of highly realistic synthetic media. Civitai, a popular community-driven platform for AI-generated content, operates a monetized feature called Bounties, which allows users to commission the generation of content in exchange for payment. This study conducts a longitudinal analysis of all publicly available bounty requests collected over a 14-month period following the platform’s launch. It finds that the bounty marketplace is dominated by tools that let users steer AI models toward content they were not trained to generate. Requests for content that is 'Not Safe For Work' are widespread and have increased steadily over time, now comprising a majority of all bounties. Participation in bounty creation is uneven, with 20% of requesters accounting for roughly half of requests. Requests for 'deepfake'—media depicting identifiable real individuals—exhibit a higher concentration than other types of bounties. A nontrivial subset of these requests involves explicit deepfakes despite platform policies prohibiting such content. These bounties disproportionately target female celebrities, revealing a pronounced gender asymmetry in social harm. These findings show how monetized, community-driven generative AI platforms can produce gendered harms, raising questions about consent, governance, and enforcement.",3.61,92.763,335,cold_start,Phi-4,Apple_M1(Metal)
2601.09120v1_Adaptive Multi-Stage Patent Claim Generation with .pdf,Adaptive Multi-Stage Patent Claim Generation with Unified Quality Assessment,"Chen-Wei Liang, Bin Guo, Zhen-Yuan Wei, Mu-Jiang-Shan Wang",,arXiv:2601.09120v1,"Patent claim generation, Cross-jurisdictional learning, Quality assessment, Transformer, Domain adaptation","Current patent claim generation systems face three fundamental limitations: poor cross-jurisdictional generalization, inadequate semantic relationship modeling between claims and prior art, and unreliable quality assessment. We introduce a novel three-stage framework that addresses these challenges through relationship-aware similarity analysis, domain-adaptive claim generation, and unified quality assessment. Our approach employs multi-head attention with eight specialized heads for explicit relationship modeling, integrates curriculum learning with dynamic LoRA adapter selection across five patent domains, and implements cross-attention mechanisms between evaluation aspects for comprehensive quality assessment. Extensive experiments on USPTO HUPD dataset, EPO patent collections, and Patent-CE benchmark demonstrate substantial improvements: 7.6-point ROUGE-L gain over GPT-4o, 8.3% BERTScore enhancement over Llama-3.1-8B, and 0.847 correlation with human experts compared to 0.623 for separate evaluation models. Our method maintains 89.4% cross-jurisdictional performance retention versus 76.2% for baselines, establishing a comprehensive solution for automated patent prosecution workflows.",4.05,85.742,347,cold_start,Phi-4,Apple_M1(Metal)
2601.09130v1_Equi-ViT Rotational Equivariant Vision Transformer.pdf,EQUI-VIT: ROTATIONAL EQUIVARIANT VISION TRANSFORMER FOR ROBUST HISTOPATHOLOGY ANALYSIS,"Fuyao Chen, Yuexi Du, Eléonore V. Lieffrig, Nicha C. Dvornek, John A. Onofrey",,,"Digital Histopathology, Vision Transformer, Rotation Equivariance, Artificial Intelligence","Vision Transformers (ViTs) have gained rapid adoption in computational pathology for their ability to model long-range dependencies through self-attention, addressing the limitations of convolutional neural networks that excel at local pattern capture but struggle with global contextual reasoning. Recent pathology-specific foundation models have further advanced performance by leveraging large-scale pretraining. However, standard ViTs remain inherently non-equivariant to transformations such as rotations and reflections, which are ubiquitous variations in histopathology imaging. To address this limitation, we propose Equi-ViT, which integrates an equivariant convolution kernel into the patch embedding stage of a ViT architecture, imparting built-in rotational equivariance to learned representations. Equi-ViT achieves superior rotation-consistent patch embeddings and stable classification performance across image orientations. Our results on a public colorectal cancer dataset demonstrate that incorporating equivariant patch embedding enhances data efficiency and robustness, suggesting that equivariant transformers could potentially serve as more generalizable backbones for the application of ViT in histopathology such as digital pathology foundation models.",3.66,93.364,342,cold_start,Phi-4,Apple_M1(Metal)
2601.09136v1_SkinFlow Efficient Information Transmission for Op.pdf,SkinFlow: Efficient Information Transmission for Open Dermatological Diagnosis via Dynamic Visual Encoding and Staged RL,"Lijun Liu, Linwei Chen, Zhishou Zhang, Meng Tian, Hengfu Cui, Ruiyang Li, Zhaocheng Liu, Qiang Ju, Qianxi Li, Hong-Yu Zhou",,,"Dermatological Diagnosis, Large Vision-Language Models, Dynamic Visual Encoding, Reinforcement Learning, Information Transmission, Medical Precision","General-purpose Large Vision-Language Models (LVLMs) often struggle in dermatology due to 'diffuse attention,' where subtle pathological lesions are not effectively distinguished from background noise. This paper introduces SkinFlow, a framework that optimizes visual information transmission efficiency for dermatological diagnosis. It employs a Virtual-Width Dynamic Vision Encoder (DVE) to unfold complex pathological manifolds without expanding physical parameters, alongside a two-stage Reinforcement Learning strategy. This strategy aligns medical descriptions and reconstructs diagnostic textures within a constrained semantic space. A clinically grounded evaluation protocol prioritizes diagnostic safety and hierarchical relevance. Empirical results show a 7B model achieving a +12.06% gain in Top-1 accuracy and a +28.57% boost in Top-6 accuracy over general-purpose models on the Fitzpatrick17k benchmark, demonstrating superior diagnostic reasoning through optimized geometric capacity and information flow.",3.62,94.667,343,cold_start,Phi-4,Apple_M1(Metal)
2601.09147v2_SSVP Synergistic Semantic-Visual Prompting for Ind.pdf,SSVP: Synergistic Semantic-Visual Prompting for Industrial Zero-Shot Anomaly Detection,"Chenhao Fu, Han Fang, Xiuzheng Zheng, Wenbo Wei, Yonghua Li, Hao Sun, Xuelong Li",,,"Zero-Shot Anomaly Detection, Vision-Language Models, Synergistic Semantic-Visual Prompting, Industrial Inspection, Hierarchical Semantic-Visual Synergy, Vision-Conditioned Prompt Generator, Visual-Text Anomaly Mapper","This paper introduces Synergistic Semantic-Visual Prompting (SSVP) for Zero-Shot Anomaly Detection (ZSAD) in industrial settings. SSVP addresses the limitations of existing ZSAD paradigms by fusing diverse visual encodings to enhance fine-grained perception. It incorporates the Hierarchical Semantic-Visual Synergy (HSVS) mechanism, integrating DINOv3’s multi-scale structural priors into the CLIP semantic space. The Vision-Conditioned Prompt Generator (VCPG) uses cross-modal attention for dynamic prompt generation, aligning linguistic queries with specific anomaly patterns. Additionally, the Visual-Text Anomaly Mapper (VTAM) establishes a dual-gated calibration paradigm to reconcile global scoring with local evidence. Extensive evaluations on seven industrial benchmarks demonstrate SSVP's robustness, achieving state-of-the-art performance with 93.0% Image-AUROC and 92.2% Pixel-AUROC on MVTec-AD, significantly surpassing existing zero-shot approaches.",3.57,103.419,369,cold_start,Phi-4,Apple_M1(Metal)
2601.09152v1_PrivacyReasoner Can LLM Emulate a Human-like Priva.pdf,PrivacyReasoner: Can LLM Emulate a Human-like Privacy Mind?,"Yiwen Tu, Xuan Liu, Lianhui Qin, Haojian Jin",,,"privacy concerns, AI-agent design, cognitive theories, contextual cues, LLM-based agents, privacy reasoning, user-specific privacy reasoning, contextual integrity, privacy-related news","This paper introduces PrivacyReasoner, an AI-agent design for simulating how individual users form privacy concerns in response to real-world news. Moving beyond population-level sentiment analysis, PrivacyReasoner integrates privacy and cognitive theories to model user-specific privacy reasoning grounded in personal comment histories and contextual cues. The agent reconstructs each user’s 'privacy mind,' dynamically activates context-relevant privacy memory through a cognitively motivated contextual filter, and generates synthetic comments reflecting how that user would likely respond to new privacy scenarios. A complementary LLM-as-a-Judge evaluator, calibrated against an established privacy concern taxonomy, quantifies the faithfulness of the generated reasoning. Experiments on real-world Hacker News discussions show that PrivacyReasoner outperforms baseline agents in privacy concern prediction and captures transferable reasoning patterns across domains including AI, e-commerce, and healthcare.",3.43,80.383,276,cold_start,Phi-4,Apple_M1(Metal)
2601.09156v1_KTCF Actionable Recourse in Knowledge Tracing via .pdf,KTCF: Actionable Recourse in Knowledge Tracing via Counterfactual Explanations for Education,"Woojin Kim, Changkwon Lee, Hyeoncheol Kim",,,"Knowledge Tracing, Counterfactual Explanations, Explainable AI, Education, Artificial Intelligence","This paper explores the use of counterfactual explanations in Knowledge Tracing (KT) to enhance adaptivity and scalability in education. The proposed KTCF method generates counterfactual explanations that consider knowledge concept relationships and converts them into educational instructions. Experiments on a large-scale dataset show that KTCF outperforms existing methods, with improvements ranging from 5.7% to 34% across various metrics. The study highlights the potential of counterfactuals to advance responsible AI use in education, emphasizing the importance of stakeholder-centered methods and educationally grounded conceptualization.",3.21,72.481,233,cold_start,Phi-4,Apple_M1(Metal)
2601.09182v1_Position on LLM-Assisted Peer Review Addressing Re.pdf,Position on LLM-Assisted Peer Review: Addressing Reviewer Gap through Mentoring and Feedback,"JungMin Yun, JuneHyoung Kwon, MiHyeon Kim, YoungBin Kim",,,"peer review, LLM, reviewer gap, AI research, mentoring, feedback","The rapid expansion of AI research has intensified the Reviewer Gap, threatening the peer-review sustainability and perpetuating a cycle of low-quality evaluations. This position paper critiques existing LLM approaches that automatically generate reviews and argues for a paradigm shift that positions LLMs as tools for assisting and educating human reviewers. Two complementary systems are proposed: an LLM-assisted mentoring system to cultivate reviewers’ long-term competencies, and an LLM-assisted feedback system to help reviewers refine the quality of their reviews. This human-centered approach aims to strengthen reviewer expertise and contribute to building a more sustainable scholarly ecosystem.",3.17,74.441,236,cold_start,Phi-4,Apple_M1(Metal)
2601.09195v1_ProFit Leveraging High-Value Signals in SFT via Pr.pdf,ProFit: Leveraging High-Value Signals in SFT via Probability-Guided Token Selection,"Tao Liu, Taiqiang Wu, Runming Yang, Shaoning Sun, Junjie Wang, Yujiu Yang",,,"Supervised Fine-Tuning, Large Language Models, Probability-Guided Token Selection, Semantic Importance, Overfitting","Supervised fine-tuning (SFT) is a fundamental post-training strategy to align Large Language Models (LLMs) with human intent. Traditional SFT often forces alignment with a single reference answer, leading to overfitting to non-core expressions. ProFit addresses this by selectively masking low-probability tokens, focusing on high-value tokens to prevent surface-level overfitting. This approach consistently outperforms traditional SFT baselines on general reasoning and mathematical benchmarks.",3.03,73.998,224,cold_start,Phi-4,Apple_M1(Metal)
2601.09208v2_Mikasa A Character-Driven Emotional AI Companion I.pdf,Mikasa: A Character-Driven Emotional AI Companion,Miki Ueno,,,"AI companions, character-driven design, emotional AI, Japanese Oshi culture, user-AI relationship","This paper discusses the development of AI companions that can engage in emotionally expressive conversations, focusing on the importance of character design and user-AI relationship definition. It presents Mikasa, an AI companion inspired by Japanese Oshi culture, emphasizing long-term, non-exclusive commitment to a stable character. The paper argues that character coherence and relationship definition are crucial for sustained user satisfaction and engagement, suggesting these elements as latent structural components that enhance interaction quality. The study highlights that while technical capabilities are important, the relational aspects significantly impact user experience.",3.14,61.515,193,cold_start,Phi-4,Apple_M1(Metal)
2601.09212v1_Annealed Relaxation of Speculative Decoding for Fa.pdf,Annealed Relaxation of Speculative Decoding for Faster Autoregressive Image Generation,"Xingyao Li, Fengzhuo Zhang, Cunxiao Du, Hui Ji",,,"auto-regressive image generation, speculative decoding, annealed relaxation, total variation distance, resampling distribution, perturbation analysis, inference speed, image tokens","This paper addresses the slow inference speed of auto-regressive (AR) image generation models due to their sequential nature and token ambiguity. It proposes COOL-SD, an annealed relaxation of speculative decoding, based on theoretical insights into the total variation distance and perturbation analysis. COOL-SD aims to generate images faster with comparable quality or better quality at similar latency. Experiments demonstrate COOL-SD's effectiveness in improving speed-quality trade-offs over previous methods.",3.09,73.717,228,cold_start,Phi-4,Apple_M1(Metal)
2601.09213v1_SpikeVAEDiff Neural Spike-based Natural Visual Sce.pdf,SpikeV AEDiff: Neural Spike-based Natural Visual Scene Reconstruction via VD-V AE and Versatile Diffusion,"Jialu Li, Taiyan Zhou",,,"neural spike data, visual scene reconstruction, neuroscience, computer vision, variational autoencoder, diffusion model, Allen Visual Coding—Neuropixels dataset, VISI region, neural decoding, brain-computer interface","This paper introduces SpikeVAEDiff, a novel two-stage framework combining a Very Deep Variational Autoencoder (VDVAE) and the Versatile Diffusion model to reconstruct high-resolution and semantically meaningful images from neural spike data. The first stage uses VDVAE to create low-resolution reconstructions from neural spikes, while the second stage refines these images using regression models and the Versatile Diffusion model. The study evaluates the method on the Allen Visual Coding—Neuropixels dataset, highlighting the VISI region's significance in visual reconstruction. The findings suggest that spike data, with its superior temporal and spatial resolution, is a promising alternative to fMRI data for visual neural decoding. The paper also validates the effectiveness of the VDVAE model and explores the impact of different brain regions on reconstruction quality.",3.49,88.588,309,cold_start,Phi-4,Apple_M1(Metal)
2601.09233v1_GIFT Unlocking Global Optimality in Post-Training .pdf,GIFT: Unlocking Global Optimality in Post-Training via Finite-Temperature Gibbs Initialization,"Zhengyang Zhao, Lu Ma, Yizhen Jiang, Xiaochen Ma, Zimo Meng, Chengyu Shen, Lexiang Tang, Haoze Sun, Peng Pei, Wentao Zhang",,,"Large Reasoning Models, Supervised Fine-Tuning, Reinforcement Learning, Gibbs Initialization, Finite Temperature, Post-Training, Optimization Mismatch, Distributional Collapse","The paper addresses the optimization mismatch in the post-training paradigm for Large Reasoning Models (LRMs), which involves Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL). The standard SFT approach leads to distributional collapse, limiting the exploration space necessary for RL. The authors propose Gibbs Initialization with Finite Temperature (GIFT) to reformulate SFT, incorporating supervision as a finite-temperature energy potential. This approach maintains objective consistency throughout the post-training pipeline and significantly outperforms standard SFT and other baselines in RL initialization, offering a pathway to global optimality in post-training.",3.28,91.275,299,cold_start,Phi-4,Apple_M1(Metal)
2601.09236v2_Reward Learning through Ranking Mean Squared Error.pdf,REWARD LEARNING THROUGH RANKING MEANS SQUARED ERROR,"Chaitanya Kharyal, Calarina Muslimani, Matthew E. Taylor",,,"reinforcement learning, reward learning, human feedback, rating-based RL, ranking mean squared error, trajectory-rating pairs, soft ranks, robotic locomotion benchmarks, OpenAI Gym, DeepMind Control Suite","Reward design remains a significant bottleneck in applying reinforcement learning (RL) to real-world problems. A popular alternative is reward learning, where reward functions are inferred from human feedback rather than manually specified. Recent work has proposed learning reward functions from human feedback in the form of ratings, rather than traditional binary preferences, enabling richer and potentially less cognitively demanding supervision. Building on this paradigm, we introduce a new rating-based RL method, Ranked Return Regression for RL (R4). At its core, R4 employs a novel ranking mean squared error (rMSE) loss, which treats teacher-provided ratings as ordinal targets. Our approach learns from a dataset of trajectory-rating pairs, where each trajectory is labeled with a discrete rating (e.g., 'bad,' 'neutral,' 'good'). At each training step, we sample a set of trajectories, predict their returns, and rank them using a differentiable sorting operator (soft ranks). We then optimize a mean squared error loss between the resulting soft ranks and the teacher’s ratings. Unlike prior rating-based approaches, R4 offers formal guarantees: its solution set is provably minimal and complete under mild assumptions. Empirically, using simulated human feedback, we demonstrate that R4 consistently matches or outperforms existing rating and preference-based RL methods on robotic locomotion benchmarks from OpenAI Gym and the DeepMind Control Suite, while requiring significantly less feedback.",3.65,114.424,418,cold_start,Phi-4,Apple_M1(Metal)
2601.09239v2_DSA-Tokenizer Disentangled Semantic-Acoustic Token.pdf,DSA-Tokenizer: Disentangled Semantic-Acoustic Tokenization via Flow Matching-based Hierarchical Fusion,"Hanlin ZHANG, Daxin Tan, Dehua Tao, Xiao Chen, Haochen Tan, Yunhe Li, Yuchen Cao, Jianping Wang, Linqi Song",,,"Speech tokenizers, Discrete Speech Large Language Models, Semantic encoding, Acoustic style, Disentanglement, Flow Matching, Hierarchical Fusion, Speech generation, Speech modeling","Speech tokenizers are crucial for discrete Speech Large Language Models (Speech LLMs). Existing tokenizers either focus on semantic encoding, fuse semantic content with acoustic style inseparably, or achieve incomplete semantic-acoustic disentanglement. The proposed DSA-Tokenizer disentangles speech into discrete semantic and acoustic tokens using distinct optimization constraints. Semantic tokens are supervised by ASR to capture linguistic content, while acoustic tokens focus on mel-spectrograms restoration to encode style. A hierarchical Flow-Matching decoder is introduced to improve speech generation quality by eliminating rigid length constraints between the two sequences. A joint reconstruction-recombination training strategy enforces separation, enabling high fidelity reconstruction and flexible recombination through robust disentanglement, facilitating controllable generation in speech LLMs. Disentangled tokenization is highlighted as a pivotal paradigm for future speech modeling.",3.35,103.309,346,cold_start,Phi-4,Apple_M1(Metal)
2601.09248v1_Hybrid guided variational autoencoder for visual p.pdf,Hybrid guided variational autoencoder for visual place recognition,"Ni Wang, Zihan You, Emre Neftci, Thorben Schoepe",,arXiv:2601.09248v1,"Visual place recognition, Spiking neural network","Autonomous agents such as cars, robots, and drones need to precisely localize themselves in diverse environments, including GPS-denied indoor environments. Visual place recognition (VPR) estimates the place of an image based on previously seen places. State-of-the-art VPR models require high amounts of memory, making them unwieldy for mobile deployment, while more compact models lack robustness and generalization capabilities. This work overcomes these limitations for robotics using a combination of event-based vision sensors and an event-based novel guided variational autoencoder (VAE). The encoder part of the model is based on a spiking neural network model compatible with power-efficient low latency neuromorphic hardware. The VAE successfully disentangles the visual features of 16 distinct places in a new indoor VPR dataset with a classification performance comparable to other state-of-the-art approaches while showing robust performance under various illumination conditions. When tested with novel visual inputs from unknown scenes, the model can distinguish between these places, demonstrating high generalization capability by learning the essential features of location. The compact and robust guided VAE with generalization capabilities poses a promising model for visual place recognition that can significantly enhance mobile robot navigation in known and unknown indoor environments.",3.75,91.943,345,cold_start,Phi-4,Apple_M1(Metal)
2601.09251v1_HGATSolver A Heterogeneous Graph Attention Solver .pdf,HGA TSolver: A Heterogeneous Graph Attention Solver for Fluid–Structure Interaction,"Qin-Yi Zhang, Hong Wang, Siyao Liu, Haichuan Lin, Linying Cao, Xiao-Hu Zhou, Chen Chen, Shuangyi Wang, Zeng-Guang Hou",,,"Fluid–Structure Interaction, Heterogeneous Graph Attention Solver, multi-physics systems, partial differential equations, learning-based solvers, graph neural networks","Fluid–structure interaction (FSI) systems involve distinct physical domains, fluid and solid, governed by different partial differential equations and coupled at a dynamic interface. While learning-based solvers offer a promising alternative to costly numerical simulations, existing methods struggle to capture the heterogeneous dynamics of FSI within a unified framework. This challenge is further exacerbated by inconsistencies in response across domains due to interface coupling and by disparities in learning difficulty across fluid and solid regions, leading to instability during prediction. To address these challenges, we propose the Heterogeneous Graph Attention Solver (HGA TSolver). HGATSolver encodes the system as a heterogeneous graph, embedding physical structure directly into the model via distinct node and edge types for fluid, solid, and interface regions. This enables specialized message-passing mechanisms tailored to each physical domain. To stabilize explicit time stepping, we introduce a novel physics-conditioned gating mechanism that serves as a learnable, adaptive relaxation factor. Furthermore, an Inter-domain Gradient-Balancing Loss dynamically balances the optimization objectives across domains based on predictive uncertainty. Extensive experiments on two constructed FSI benchmarks and a public dataset demonstrate that HGATSolver achieves state-of-the-art performance, establishing an effective framework for surrogate modeling of coupled multi-physics systems.",3.54,115.678,410,cold_start,Phi-4,Apple_M1(Metal)
2601.09253v1_RIFT Repurposing Negative Samples via Reward-Infor.pdf,RIFT: Repurposing Negative Samples via Reward-Informed Fine-Tuning,"Zehua Liu, Shuqi Liu, Tao Zhong, Mingxuan Yuan",,,"Supervised Fine-Tuning, Rejection Sampling Fine-Tuning, Reward-Informed Fine-Tuning, Large Language Models, alignment, negative samples, data efficiency","This paper introduces Reward Informed Fine-Tuning (RIFT), a framework that improves upon Supervised Fine-Tuning (SFT) and Rejection Sampling Fine-Tuning (RFT) by utilizing all self-generated samples, including negative ones. RIFT reweights the loss with scalar rewards to learn from both positive and negative trajectories, addressing the inefficiencies of RFT's hard thresholding. The paper presents a stabilized loss formulation to prevent training collapse and demonstrates through experiments that RIFT outperforms RFT in terms of robustness and data efficiency on mathematical benchmarks.",3.1,78.353,243,cold_start,Phi-4,Apple_M1(Metal)
2601.09259v1_MAXS Meta-Adaptive Exploration with LLM Agents.pdf,MAXS: Meta-Adaptive Exploration with LLM Agents,"Jian Zhang, Zhiyuan Wang, Zhangqi Wang, Yu He, Haoran Luo, Li Yuan, Lingling Zhang, Rui Mao, Qika Lin, Jun Liu",,,"Large Language Model, LLM Agents, meta-adaptive reasoning, lookahead strategy, trajectory stability, tool execution, reasoning planning","Large Language Model (LLM) Agents exhibit inherent reasoning abilities through the collaboration of multiple tools. However, during agent inference, existing methods often suffer from locally myopic generation and trajectory instability, where minor early errors can escalate into divergent reasoning paths. To address these issues, the authors propose meta-adaptive exploration with LLM agents (MAXS), a meta-adaptive reasoning framework that flexibly integrates tool execution and reasoning planning. MAXS employs a lookahead strategy to extend reasoning paths a few steps ahead, estimating the advantage value of tool usage, and combines step consistency variance and inter-step trend slopes to jointly select stable, consistent, and high-value reasoning steps. Additionally, a trajectory convergence mechanism is introduced to control computational cost by halting further rollouts once path consistency is achieved, enabling a balance between resource efficiency and global effectiveness in multi-tool reasoning. Extensive empirical studies across three base models and five datasets demonstrate that MAXS consistently outperforms existing methods in both performance and inference efficiency. Further analysis confirms the effectiveness of the lookahead strategy and tool usage.",3.42,106.508,364,cold_start,Phi-4,Apple_M1(Metal)
2601.09260v1_Efficient Paths and Dense Rewards Probabilistic Fl.pdf,Efficient Paths and Dense Rewards: Probabilistic Flow Reasoning for Large Language Models,"Yan Liu, Feng Zhang, Zhanyu Ma, Jun Xu, Jiuchong Gao, Jinghua Hao, Renqing He, Han Liu, Yangdong Deng",,,"Chain-of-Thought, Large Language Models, Probabilistic Flow, Reasoning, Inference Efficiency, Optimization, Reinforcement Learning","This paper introduces CoT-Flow, a framework that treats discrete reasoning steps as a continuous probabilistic flow, quantifying each step's contribution to the final answer. CoT-Flow offers flow-guided decoding for efficient reasoning paths and flow-based reinforcement learning for a dense reward function without external verifiers. Experiments show CoT-Flow balances inference efficiency and reasoning performance effectively.",3.17,73.146,232,cold_start,Phi-4,Apple_M1(Metal)
2601.09262v1_Magnifying change Rapid burn scar mapping with mul.pdf,"Magnifying change: Rapid burn scar mapping with multi-resolution, multi-source satellite imagery","Maria Sdraka, Dimitrios Michail, Ioannis Papoutsis",,,"Artificial intelligence, Machine Learning, Remote Sensing, burnt area mapping, disaster management, disaster monitoring, wildfires, burn scar mapping, change detection, downscaling, super-resolution","Delineating wildfire affected areas using satellite imagery remains challenging due to irregular and spatially heterogeneous spectral changes across the electromagnetic spectrum. Recent deep learning approaches achieve high accuracy with high-resolution multispectral data, but their applicability in operational settings is limited by the trade-off between spatial resolution and temporal revisit frequency of current satellite systems. To address this limitation, we propose a novel deep learning model, BAM-MRCD, which employs multi-resolution, multi-source satellite imagery (MODIS and Sentinel-2) for the timely production of detailed burnt area maps with high spatial and temporal resolution. Our model detects even small scale wildfires with high accuracy, surpassing similar change detection models and solid baselines. All data and code are available in the GitHub repository: https://github.com/Orion-AI-Lab/BAM-MRCD.",3.43,88.82,305,cold_start,Phi-4,Apple_M1(Metal)
2601.09264v1_Coordinated Pandemic Control with Large Language M.pdf,Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants,"Ziyi Shi, Xusen Guo, Hongliang Lu, Mingxing Peng, Haotian Wang, Zheng Zhu, Zhenning Li, Yuxuan Liang, Xinhu Zheng, Hai Yang",,,"Pandemic Control, Large Language Models, Multi-Agent System, Coordinated Policymaking","Effective pandemic control requires timely and coordinated policymaking across administrative regions that are intrinsically interdependent. Human-driven responses are often fragmented and reactive, with policies formulated in isolation and adjusted only after outbreaks escalate, undermining proactive intervention and global pandemic mitigation. To address this challenge, a large language model (LLM) multi-agent policymaking framework is proposed to support coordinated and proactive pandemic control across regions. Each administrative region is assigned an LLM agent as an AI policymaking assistant. The agent reasons over region-specific epidemiological dynamics while communicating with other agents to account for cross-regional interdependencies. By integrating real-world data, a pandemic evolution simulator, and structured inter-agent communication, the framework enables agents to jointly explore counterfactual intervention scenarios and synthesize coordinated policy decisions through a closed-loop simulation process. The framework is validated using state-level COVID-19 data from the United States between April and December 2020, together with real-world mobility records and observed policy interventions. Compared with real-world pandemic outcomes, the approach reduces cumulative infections and deaths by up to 63.7% and 40.1%, respectively, at the individual state level, and by 39.0% and 27.0%, respectively, when aggregated across states. These results demonstrate that LLM multi-agent systems can enable more effective pandemic control with coordinated policymaking. More broadly, this study presents a generalizable framework for operationalizing LLM agents in large-scale public policy settings, offering a promising decision-support paradigm for future pandemics and other complex societal challenges characterized by strong regional interdependence.",3.76,124.272,467,cold_start,Phi-4,Apple_M1(Metal)
2601.09269v2_RISER Orchestrating Latent Reasoning Skills for Ad.pdf,RISER: Orchestrating Latent Reasoning Skills for Adaptive Activation Steering,"Wencheng Ye, Xiaoyang Yuan, Yi Bin, Hengyu Jin, Liang Peng, Pengpeng Zeng, Heng Tao Shen",,,"large language models, activation steering, reinforcement learning, reasoning, cognitive primitives, zero-shot accuracy, token efficiency","Recent work on domain-specific reasoning with large language models (LLMs) often relies on training-intensive approaches that require parameter updates. Activation steering has emerged as a parameter-efficient alternative, but existing methods apply static, manual interventions that fail to adapt to the dynamic nature of complex reasoning. To address this limitation, we propose RISER (Router-based Intervention for Steerable Enhancement of Reasoning), a plug-and-play intervention framework that adaptively steers LLM reasoning in activation space. RISER constructs a library of reusable reasoning vectors and employs a lightweight Router to dynamically compose them for each input. The Router is optimized via reinforcement learning under task-level rewards, activating latent cognitive primitives in an emergent and compositional manner. Across seven diverse benchmarks, RISER yields 3.4–6.5% average zero-shot accuracy improvements over the base model while surpassing CoT-style reasoning with 2–3× higher token efficiency and robust accuracy gains. Further analysis shows that RISER autonomously combines multiple vectors into interpretable, precise control strategies, pointing toward more controllable and efficient LLM reasoning.",3.37,108.507,366,cold_start,Phi-4,Apple_M1(Metal)
2601.09274v1_A3-Bench Benchmarking Memory-Driven Scientific Rea.pdf,A3-Bench: Benchmarking Memory-Driven Scientific Reasoning via Anchor and Attractor Activation,"Jian Zhang, Yu He, Zhiyuan Wang, Zhangqi Wang, Kai He, Fangzhi Xu, Qika Lin, Jun Liu",,arXiv:2601.09274v1,"scientific reasoning, memory-driven mechanisms, anchors and attractors, benchmarking, Large Language Models, memory activation","This paper introduces A3-Bench, a benchmark designed to evaluate scientific reasoning through memory-driven activation, specifically focusing on the activation of anchors and attractors. The benchmark annotates 2,198 science reasoning problems across various domains using the SAPM process and introduces a dual-scale memory evaluation framework with the AAUI metric to measure memory activation rates. Experiments with various models validate A3-Bench and analyze the impact of memory activation on reasoning performance, highlighting the importance of memory in enhancing reasoning accuracy and reliability.",3.19,80.602,257,cold_start,Phi-4,Apple_M1(Metal)
2601.09278v1_M3Searcher Modular Multimodal Information Seeking .pdf,M3Searcher: Modular Multimodal Information Seeking Agency with Retrieval-Oriented Reasoning,"Xiaohan Yu, Chao Feng, Lang Mei, Chong Chen",,,"multimodal information seeking, retrieval-oriented reasoning, modular design, deep research agents, reinforcement learning, large language models","Recent advances in DeepResearch-style agents have shown strong capabilities in autonomous information acquisition and synthesis from real-world web environments, but are limited to text modality. This paper introduces M3Searcher, a modular multimodal information-seeking agent that decouples information acquisition from answer derivation. It is optimized with a retrieval-oriented multi-objective reward to encourage factual accuracy, reasoning soundness, and retrieval fidelity. The paper also presents MM-SearchVQA, a multimodal multi-hop dataset for retrieval-centric RL training. Experimental results show that M3Searcher outperforms existing approaches, demonstrating strong transfer adaptability and effective reasoning in complex multimodal tasks.",3.16,79.972,253,cold_start,Phi-4,Apple_M1(Metal)
2601.09280v1_ReGraM Region-First Knowledge Graph Reasoning for .pdf,ReGraM: Region-First Knowledge Graph Reasoning for Medical Question Answering,"Chaerin Lee, Sohee Park, Hyunsik Na, Daseon Choi",,,"Medical QA, Knowledge Graph Reasoning, Large Language Models, Biomedical Knowledge Graphs, Multi-hop Reasoning, Region-First Framework","Recent studies in medical question answering (Medical QA) have explored integrating large language models (LLMs) with biomedical knowledge graphs (KGs) to improve factual accuracy. However, existing approaches often rely on traversing the entire KG or performing large-scale retrieval, introducing noise and unstable multi-hop reasoning. This paper introduces ReGraM, a region-first knowledge graph reasoning framework that constructs a query-aligned subgraph and performs stepwise reasoning within this localized region under multiple evidence-aware modes. By focusing on the most relevant portion of the KG, ReGraM achieves significant improvements in accuracy and reduces hallucination rates on medical QA benchmarks. The results highlight the effectiveness of region-first KG reasoning in enhancing factual accuracy and consistency in medical QA.",3.2,83.861,268,cold_start,Phi-4,Apple_M1(Metal)
2601.09281v1_STaR Sensitive Trajectory Regulation for Unlearnin.pdf,STaR: Sensitive Trajectory Regulation for Unlearning in Large Reasoning Models,"Jingjing Zhou, Gaoxiang Cong, Li Su, Liang Li",,,"Large Reasoning Models, Chain-of-Thought, Privacy Risks, Unlearning, Sensitive Content, Trajectory Regulation, Privacy Protection, Semantic-aware Detection, Safety Constraints, Trajectory-aware Suppression, Token-level Adaptive Filtering, Multi-Decoding Consistency Assessment, Multi-Granularity Membership Inference Attack","Large Reasoning Models (LRMs) have advanced automated multi-step reasoning, but their ability to generate complex Chain-of-Thought (CoT) trajectories introduces severe privacy risks, as sensitive information may be deeply embedded throughout the reasoning process. Existing Large Language Models (LLMs) unlearning approaches that typically focus on modifying only final answers are insufficient for LRMs, as they fail to remove sensitive content from intermediate steps, leading to persistent privacy leakage and degraded security. To address these challenges, we propose Sensitive Trajectory Regulation (STaR), a parameter-free, inference-time unlearning framework that achieves robust privacy protection throughout the reasoning process. Specifically, we first identify sensitive content via semantic-aware detection. Then, we inject global safety constraints through secure prompt prefix. Next, we perform trajectory-aware suppression to dynamically block sensitive content across the entire reasoning chain. Finally, we apply token-level adaptive filtering to prevent both exact and paraphrased sensitive tokens during generation. Furthermore, to overcome the inadequacies of existing evaluation protocols, we introduce two metrics: Multi-Decoding Consistency Assessment (MCS), which measures the consistency of unlearning across diverse decoding strategies, and Multi-Granularity Membership Inference Attack (MIA) Evaluation, which quantifies privacy protection at both answer and reasoning-chain levels. Experiments on the R-TOFU benchmark demonstrate that STaR achieves comprehensive and stable unlearning with minimal utility loss, setting a new standard for privacy-preserving reasoning in LRMs.",3.59,129.679,466,cold_start,Phi-4,Apple_M1(Metal)
2601.09282v1_Cluster Workload Allocation Semantic Soft Affinity.pdf,Cluster Workload Allocation: Semantic Soft Affinity Using Natural Language Processing,"Leszek Sliwko, Jolanta Mizeria-Pietraszko",,,"Artificial Intelligence, Kubernetes, Load Balancing, Semantic Parsing, Soft-Affinity, Task Assignment","Cluster workload allocation often requires complex configurations, creating a usability gap. This paper introduces a semantic, intent-driven scheduling paradigm for cluster systems using Natural Language Processing. The system employs a Large Language Model (LLM) integrated via a Kubernetes scheduler extender to interpret natural language allocation hint annotations for soft affinity preferences. A prototype featuring a cluster state cache and an intent analyzer (using AWS Bedrock) was developed. Empirical evaluation demonstrated high LLM parsing accuracy (>95% Subset Accuracy on an evaluation ground-truth dataset) for top-tier models like Amazon Nova Pro/Premier and Mistral Pixtral Large, significantly outperforming a baseline engine. Scheduling quality tests across six scenarios showed the prototype achieved superior or equivalent placement compared to standard Kubernetes configurations, particularly excelling in complex and quantitative scenarios and handling conflicting soft preferences. The results validate using LLMs for accessible scheduling but highlight limitations like synchronous LLM latency, suggesting asynchronous processing for production readiness. This work confirms the viability of semantic soft affinity for simplifying workload orchestration.",3.37,87.435,295,cold_start,Phi-4,Apple_M1(Metal)
2601.09286v1_Why not Collaborative Filtering in Dual View Bridg.pdf,Why not Collaborative Filtering in Dual View? Bridging Sparse and Dense Models,"Hanze Guo, Jianxun Lian, Xiao Zhou",https://doi.org/XXXXXXX.XXXXXXX,,"Collaborative Filtering, Dual View Alignment, Sparse and Dense model, Information systems, Collaborative filtering, Recommender systems","Collaborative Filtering (CF) remains the cornerstone of modern recommender systems, with dense embedding–based methods dominating current practice. However, these approaches suffer from a critical limitation: our theoretical analysis reveals a fundamental signal-to-noise ratio (SNR) ceiling when modeling unpopular items, where parameter-based dense models experience diminishing SNR under severe data sparsity. To overcome this bottleneck, we propose SaD (Sparse and Dense), a unified framework that integrates the semantic expressiveness of dense embeddings with the structural reliability of sparse interaction patterns. We theoretically show that aligning these dual views yields a strictly superior global SNR. Concretely, SaD introduces a lightweight bidirectional alignment mechanism: the dense view enriches the sparse view by injecting semantic correlations, while the sparse view regularizes the dense model through explicit structural signals. Extensive experiments demonstrate that, under this dual-view alignment, even a simple matrix factorization–style dense model can achieve state-of-the-art performance. Moreover, SaD is plug-and-play and can be seamlessly applied to a wide range of existing recommender models, highlighting the enduring power of collaborative filtering when leveraged from dual perspectives. Further evaluations on real-world benchmarks show that SaD consistently outperforms strong baselines, ranking first on the BarsMatch leaderboard. The code is publicly available at https://github.com/harris26-G/SaD.",3.6,111.523,402,cold_start,Phi-4,Apple_M1(Metal)
2601.09292v1_Blue Teaming Function-Calling Agents.pdf,Blue Teaming Function-Calling Agents,"Greta Dolcetti, Giulio Zizzo, Sergio Maffeis",,,"LLMs, function-calling, robustness, attacks, defences, adversarial attacks, open source models","This paper presents an experimental evaluation of the robustness of four open source Large Language Models (LLMs) with function-calling capabilities against three different attacks. It also measures the effectiveness of eight different defences. The study reveals that these models are not inherently safe and that the current defences are not yet practical for real-world applications. The paper introduces new attack vectors and defences, highlighting the limitations of existing mechanisms.",2.96,65.637,194,cold_start,Phi-4,Apple_M1(Metal)
2601.09293v1_Policy-Based Reinforcement Learning with Action Ma.pdf,Policy-Based Reinforcement Learning with Action Masking for Dynamic Job Shop Scheduling under Uncertainty: Handling Random Arrivals and Machine Failures,"Sofiene Lassoued, Stefan Lier, Andreas Schwung",,,"Dynamic Job Shop Scheduling, Fault tolerance, Reinforcement learning, Actions masking, Petri nets","We present a novel framework for solving Dynamic Job Shop Scheduling Problems under uncertainty, addressing the challenges introduced by stochastic job arrivals and unexpected machine breakdowns. Our approach follows a model-based paradigm, using Coloured Timed Petri Nets to represent the scheduling environment, and Maskable Proximal Policy Optimization to enable dynamic decision-making while restricting the agent to feasible actions at each decision point. To simulate realistic industrial conditions, dynamic job arrivals are modeled using a Gamma distribution, which captures complex temporal patterns such as bursts, clustering, and fluctuating workloads. Machine failures are modeled using a Weibull distribution to represent age-dependent degradation and wear-out dynamics. These stochastic models enable the framework to reflect real-world manufacturing scenarios better. In addition, we study two action-masking strategies: a non-gradient approach that overrides the probabilities of invalid actions, and a gradient-based approach that assigns negative gradients to invalid actions within the policy network. We conduct extensive experiments on dynamic JSSP benchmarks, demonstrating that our method consistently outperforms traditional heuristic and rule-based approaches in terms of makespan minimization. The results highlight the strength of combining interpretable Petri-net-based models with adaptive reinforcement learning policies, yielding a resilient, scalable, and explainable framework for real-time scheduling in dynamic and uncertain manufacturing environments.",3.61,105.155,380,cold_start,Phi-4,Apple_M1(Metal)
2601.09306v1_On-Device Large Language Models for Sequential Rec.pdf,On-Device Large Language Models for Sequential Recommendation,"Xin Xia, Hongzhi Yin, Shane Culpepper",10.1145/3773966.3777961,,"Recommender Systems, Sequential Recommendation, On-Device Recommendation, Model Compression, Resource Constrained Devices","On-device recommendation is critical for real-world applications, especially in scenarios with constraints on execution latency, user privacy, and robust functionality when internet connectivity is unstable or impossible. Large language models (LLMs) can model user behavior for sequential recommendation tasks but are challenging to deploy on resource-constrained devices due to their substantial memory footprint and computational overhead. This paper proposes OD-LLM, a task-adaptive compression framework designed for efficient and accurate on-device deployment of LLMs for sequential recommendation tasks. OD-LLM integrates a low-rank structural compression algorithm using Singular Value Decomposition (SVD) and a novel tokenization normalization technique. A progressive alignment algorithm is used to refine parameters layerwise in the target model. Empirical evaluations show that OD-LLM maintains effectiveness compared to the original model when the deployed model size is halved, demonstrating its efficacy and scalability as a practical alternative for real-time, on-device solutions.",3.27,91.366,299,cold_start,Phi-4,Apple_M1(Metal)
2601.09313v1_Understanding or Memorizing A Case Study of German.pdf,Understanding or Memorizing? A Case Study of German Definite Articles in Language Models,"Jonathan Drechsel, Erisa Bytyqi, Steffen Herbold",,,"Language Models, German Definite Articles, Grammatical Agreement, Memorization, Rule-Based Generalization, Gradient-Based Interpretability, GRADIEND, Morphologically Rich Languages","Language models perform well on grammatical agreement, but it is unclear whether this reflects rule-based generalization or memorization. This study investigates German definite singular articles, whose forms depend on gender and case, using GRADIEND, a gradient-based interpretability method. The study finds that updates for specific gender-case article transitions often affect unrelated settings, suggesting that models partly rely on memorized associations rather than abstract grammatical rules. The results argue against a strictly rule-based encoding of German definite articles, indicating a reliance on memorized associations in some contexts.",3.15,76.128,240,cold_start,Phi-4,Apple_M1(Metal)
2601.09342v1_Improving Implicit Hate Speech Detection via a Com.pdf,Improving Implicit Hate Speech Detection via a Community-Driven Multi-Agent Framework,"Ewelina Gajewska, Katarzyna Budzynska, Jarosław A. Chudziak",,,"LLMs, Community agents, Hate speech, Social media, Moderation, Fairness","This work proposes a contextualized detection framework for implicitly hateful speech, implemented as a multi-agent system comprising a central Moderator Agent and dynamically constructed Community Agents representing specific demographic groups. The approach integrates socio-cultural context from publicly available knowledge sources, enabling identity-aware moderation that surpasses state-of-the-art prompting methods on a challenging ToxiGen dataset. The framework improves classification accuracy and fairness across all target groups by incorporating balanced accuracy as a central metric of classification fairness.",3.04,68.435,208,cold_start,Phi-4,Apple_M1(Metal)
2601.09351v1_Navigating Ethical AI Challenges in the Industrial.pdf,Navigating Ethical AI Challenges in the Industrial Sector: Balancing Innovation and Responsibility,"Ruomu Tan, Martin W Hoffmann",,2601.09351v1,"AI, industrial sector, ethics, innovation, transparency, accountability, fairness, research and development, data sharing, ethical principles","The integration of artificial intelligence (AI) into the industrial sector has driven innovation and expanded the ethical landscape, necessitating a reevaluation of principles governing technology and its applications. This chapter explores the intersection of AI-empowered industrial innovation with ethics, addressing challenges related to transparency, accountability, and fairness. It examines ethical aspects of AI in industrial use cases, emphasizing the importance of embedding ethical principles into AI systems to inspire technological breakthroughs and foster trust among stakeholders. The chapter offers actionable insights to guide industrial research and development toward ethical and responsible progress, promoting a more inclusive industrial ecosystem.",3.64,67.069,244,cold_start,Phi-4,Apple_M1(Metal)
2601.09353v1_Monte-Carlo Tree Search with Neural Network Guidan.pdf,Monte-Carlo Tree Search with Neural Network Guidance for Lane-Free Autonomous Driving,"Ioannis Peridis, Dimitrios Troullinos, Georgios Chalkiadakis, Pantelis Giankoulidis, Ioannis Papamichail, Markos Papageorgiou",,2601.09353v1,"Monte-Carlo Tree Search, Neural Network, Autonomous Driving, Lane-Free Traffic, Reinforcement Learning, Markov Decision Process","This work explores a Monte-Carlo Tree Search (MCTS) planning approach for single-agent autonomous driving in lane-free traffic environments. The approach is influenced by reinforcement learning frameworks and incorporates a pre-trained neural network (NN) to guide the selection phase, enhancing the tree search process under computational constraints. The study evaluates safety and efficacy through collision rates and measured speed, examining the influence of isotropic state information, the acceleration of performance for the NN-guided MCTS variant, and the trade-off between computational resources and solution quality. The concept of 'nudging' is also explored, where vehicles react to both front and back-located vehicles, improving policy outcomes.",3.47,83.641,290,cold_start,Phi-4,Apple_M1(Metal)
2601.09361v1_GeoRA Geometry-Aware Low-Rank Adaptation for RLVR.pdf,GeoRA: Geometry-Aware Low-Rank Adaptation for RLVR,"Jiaying Zhang, Lei Shi, Jiguo Li, Jun Xu, Jiuchong Gao, Jinghua Hao, Renqing He",,,"Reinforcement Learning with Verifiable Rewards, Low-Rank Adaptation, Singular Value Decomposition, Optimization Dynamics, Geometric Structures, Parameter-Efficient Methods, Supervised Fine-Tuning, Spectral Collapse, Optimization Instability, Update Sparsity, Efficiency Bottlenecks, Unstructured Computations, Anisotropic Nature, Compressible Nature, Pre-trained Geometric Structure, GPU Computation, Dense Operators, Optimization Bottlenecks, Geometric Misalignment, Mathematical Benchmarks, State-of-the-Art Results, Generalization, Catastrophic Forgetting, Out-of-Domain Tasks","Reinforcement Learning with Verifiable Rewards (RLVR) is crucial for advancing large-scale reasoning models. Existing parameter-efficient methods like PiSSA and MiLoRA, designed for Supervised Fine-Tuning (SFT), do not account for the distinct optimization dynamics and geometric structures of RLVR, leading to spectral collapse and optimization instability. GeoRA (Geometry-Aware Low-Rank Adaptation) addresses these challenges by exploiting the anisotropic and compressible nature of RL update subspaces. It initializes adapters by extracting principal directions via Singular Value Decomposition (SVD) within a geometrically constrained subspace while freezing the residual components. This preserves the pre-trained geometric structure and enables efficient GPU computation through dense operators. Experiments on Qwen and Llama show that GeoRA mitigates optimization bottlenecks caused by geometric misalignment, outperforming established low-rank baselines on key mathematical benchmarks and achieving state-of-the-art results. Additionally, GeoRA demonstrates superior generalization and resilience to catastrophic forgetting in out-of-domain tasks.",3.63,133.763,485,cold_start,Phi-4,Apple_M1(Metal)
2601.09365v1_Frame of Reference Addressing the Challenges of Co.pdf,Frame of Reference: Addressing the Challenges of Common Ground Representation in Situational Dialogs,"Biswesh Mohapatra, Théo Charlot, Giovanni Duca, Mayank Palan, Laurent Romary, Justine Cassell",,,"common ground, situational dialogs, conversational grounding, large language models, embodied conversational agents, social robots","Common ground is crucial in situational spoken dialogs, where interlocutors must establish and maintain shared references to entities, events, and relations. This paper evaluates a model's ability to utilize relational references in dynamic environments and proposes methods to improve performance in representing common ground. It addresses the challenge of maintaining common ground over extended dialog periods, particularly for embodied conversational agents and social robots.",2.99,72.667,217,cold_start,Phi-4,Apple_M1(Metal)
2601.09381v1_Query Languages for Machine-Learning Models.pdf,Query Languages for Machine-Learning Models,Martin Grohe,,2601.09381v1,"Expressive power of query languages, fixed-point logics, weighted structures, neural networks, explainable AI","This paper discusses two logics for weighted finite structures: first-order logic with summation (FO(SUM)) and its recursive extension IFP(SUM). These logics, originating from foundational work by Grädel, Gurevich, and Meer in the 1990s, are investigated as query languages for machine learning models, specifically neural networks, which are naturally represented as weighted graphs. The paper presents examples of queries to neural networks expressible in these logics and discusses their expressiveness and computational complexity.",2.97,64.957,193,cold_start,Phi-4,Apple_M1(Metal)
2601.09382v1_Long-term Task-oriented Agent Proactive Long-term .pdf,Long-term Task-oriented Agent: Proactive Long-term Intent Maintenance in Dynamic Environments,"Qinglong Shi, Donghai Wang, Hantao Zhou, Jiguo Li, Jun Xu, Jiuchong Gao, Jinghua Hao, Renqing He",,,"proactive agents, task-oriented interaction, dynamic environments, intent maintenance, long-term interaction","Current large language model agents predominantly operate under a reactive paradigm, responding only to immediate user queries within short-term sessions. This limitation hinders their ability to maintain long-term user intents and dynamically adapt to evolving external environments. This paper proposes a novel interaction paradigm for proactive Task-oriented Agents capable of bridging the gap between relatively static user needs and a dynamic environment. The paper introduces Intent-Conditioned Monitoring and Event-Triggered Follow-up as key capabilities for proactivity. A high-quality data synthesis pipeline is introduced to construct complex, multi-turn dialog data in a dynamic environment. A new benchmark, ChronosBench, is proposed to address the lack of evaluation criteria for task-oriented interaction in dynamic environments. The paper evaluates leading models and reveals their flaws in long-term task-oriented interaction. A fine-tuned model trained using synthetic data achieves a task completion rate of 85.19% for complex tasks, outperforming other models under test, validating the effectiveness of the data-driven strategy.",3.34,100.442,335,cold_start,Phi-4,Apple_M1(Metal)
2601.09394v2_FairGE Fairness-Aware Graph Encoding in Incomplete.pdf,FairGE: Fairness-Aware Graph Encoding in Incomplete Social Networks,"Renqiang Luo, Huafei Huang, Tao Tang, Jing Ren, Ziqi Xu, Mingliang Hou, Enyan Dai, Feng Xia",https://doi.org/XXXXXXX.XXXXXXX,,"Social Networks, Graph Learning, Graph Transformers, Fairness, Incomplete Data","Graph Transformers (GTs) are increasingly applied to social network analysis, yet their deployment is often constrained by fairness concerns. This issue is particularly critical in incomplete social networks, where sensitive attributes are frequently missing due to privacy and ethical restrictions. Existing solutions commonly generate these incomplete attributes, which may introduce additional biases and further compromise user privacy. To address this challenge, FairGE (Fair Graph Encoding) is introduced as a fairness-aware framework for GTs in incomplete social networks. Instead of generating sensitive attributes, FairGE encodes fairness directly through spectral graph theory. By leveraging the principal eigenvector to represent structural information and padding incomplete sensitive attributes with zeros to maintain independence, FairGE ensures fairness without data reconstruction. Theoretical analysis demonstrates that the method suppresses the influence of non-principal spectral components, thereby enhancing fairness. Extensive experiments on seven real-world social network datasets confirm that FairGE achieves at least a 16% improvement in both statistical parity and equality of opportunity compared with state-of-the-art baselines. The source code is shown in https://github.com/LuoRenqiang/FairGE.",3.36,108.029,363,cold_start,Phi-4,Apple_M1(Metal)
2601.09398v1_Ability Transfer and Recovery via Modularized Para.pdf,Ability Transfer and Recovery via Modularized Parameters Localization,"Songyao Jin, Kun Zhou, Wenqi Li, Peng Wang, Biwei Huang",,,"Large language models, catastrophic forgetting, modularized parameters, activation-guided transfer, multilingual reasoning","This paper investigates the distribution of abilities within large language model (LLM) parameters by analyzing module activations under domain- and language-specific inputs. The study finds that ability-related activations are concentrated in a small set of channels, which are largely disentangled. The authors propose ACT (Activation-Guided Channel-wise Ability Transfer), a method that localizes ability-relevant channels via activation differences and selectively transfers corresponding parameters, followed by lightweight fine-tuning for compatibility. Experiments demonstrate that ACT can recover forgotten abilities while preserving retained skills and integrate multiple specialized models into a single model with minimal interference.",3.06,75.939,232,cold_start,Phi-4,Apple_M1(Metal)
2601.09413v1_Speech-Hands A Self-Reflection Voice Agentic Appro.pdf,Speech-Hands: A Self-Reflection Voice Agentic Approach to Speech Recognition and Audio Reasoning with Omni Perception,"Zhen Wan, Chao-Han Huck Yang, Jinchuan Tian, Hanrong Ye, Ankita Pasad, Szu-wei Fu, Arushi Goel, Ryo Hachiuma, Shizhe Diao, Kunal Dhawan, Sreyan Ghosh, Yusuke Hirota, Zhehuai Chen, Rafael Valle, Ehsan Hosseini Asl, Chenhui Chu, Shinji Watanabe, Yu-Chiang Frank Wang, Boris Ginsburg",,,"speech recognition, audio reasoning, omni perception, self-reflection, voice agentic framework","We introduce a voice-agentic framework that learns one critical omni-understanding skill: knowing when to trust itself versus when to consult external audio perception. Our work is motivated by a crucial yet counterintuitive finding: naively fine-tuning an omni-model on both speech recognition and external sound understanding tasks often degrades performance, as the model can be easily misled by noisy hypotheses. To address this, our framework, Speech-Hands, recasts the problem as an explicit self-reflection decision. This learnable reflection primitive proves effective in preventing the model from being derailed by flawed external candidates. We show that this agentic action mechanism generalizes naturally from speech recognition to complex, multiple-choice audio reasoning. Across the OpenASR leaderboard, Speech-Hands consistently outperforms strong baselines by 12.1% WER on seven benchmarks. The model also achieves 77.37% accuracy and high F1 on audio QA decisions, showing robust generalization and reliability across diverse audio question answering datasets. By unifying perception and decision-making, our work offers a practical path toward more reliable and resilient audio intelligence.",3.44,124.28,427,cold_start,Phi-4,Apple_M1(Metal)
2601.09416v1_Radiomics-Integrated Deep Learning with Hierarchic.pdf,Radiomics-Integrated Deep Learning with Hierarchical Loss for Osteosarcoma Histology Classification,"Yaxi Chen, Zi Ye, Shaheer U. Saeed, Oliver Yu, Simin Ni, Jie Huang, Yipeng Hu",,,"Osteosarcoma, Radiomics, Multi-Task Learning, Uncertainty Weighting","Osteosarcoma (OS) is an aggressive primary bone malignancy. Accurate histopathological assessment of viable versus non-viable tumor regions after neoadjuvant chemotherapy is critical for prognosis and treatment planning. This work proposes using radiomic features as additional input in model training to improve classification performance and interpretability. It also introduces optimizing two binary classification tasks with hierarchical classes (tumor-vs-non-tumor and viable-vs-non-viable) using a hierarchical loss with trainable weightings, significantly improving per-class performance. The study demonstrates the benefits of these approaches using the TCIA OS Tumor Assessment dataset, setting a new state-of-the-art performance on this open dataset for this application.",3.15,78.997,249,cold_start,Phi-4,Apple_M1(Metal)
2601.09421v2_Bias Dynamics in BabyLMs Towards a Compute-Efficie.pdf,Bias Dynamics in BabyLMs: Towards a Compute-Efficient Sandbox for Democratising Pre-Training Debiasing,"Filip Trhlik, Andrew Caines, Paula Buttery",,,"pre-trained language models, bias, debiasing, BabyLMs, BERT, gender imbalance, toxicity, pre-model debiasing","Pre-trained language models (LMs) have grown substantially in societal adoption and training costs, constraining progress in understanding and mitigating their biases. Most debiasing work focuses on post-hoc or masking-based strategies due to the high cost of re-training LMs. This work investigates BabyLMs, compact BERT-like models trained on small and mutable corpora, to democratize pre-model debiasing research. BabyLMs display closely aligned patterns of intrinsic bias formation and performance development compared to standard BERT models, despite their reduced size. Correlations between BabyLMs and BERT hold across multiple debiasing methods. Pre-model debiasing experiments with BabyLMs replicate prior findings and present new insights regarding the influence of gender imbalance and toxicity on bias formation. BabyLMs can serve as an effective sandbox for large-scale LMs, reducing pre-training costs from over 500 GPU-hours to under 30 GPU-hours, enabling faster and more accessible exploration of methods for building fairer LMs.",3.3,100.789,333,cold_start,Phi-4,Apple_M1(Metal)
2601.09433v1_Do Transformers Understand Ancient Roman Coin Moti.pdf,Do Transformers Understand Ancient Roman Coin Motifs Better than CNNs?,"David Reid, Ognjen Arandjelović",,2601.09433v1,"Vision Transformer, CNN, ancient coins, semantic elements, computer vision, machine learning, numismatics","Automated analysis of ancient coins can aid researchers and collectors by identifying semantic elements depicted on coins. This paper applies the Vision Transformer (ViT) architecture to this task, comparing its performance with convolutional neural networks (CNNs). ViT models, trained on multi-modal data (images and unstructured text), outperform CNN models in accuracy for identifying semantic elements on ancient coins. The study highlights the potential of ViT in ancient numismatics and discusses the challenges and advancements in computer vision and machine learning for this domain.",3.48,58.123,202,cold_start,Phi-4,Apple_M1(Metal)
2601.09445v1_Where Knowledge Collides A Mechanistic Study of In.pdf,Where Knowledge Collides: A Mechanistic Study of Intra-Memory Knowledge Conflict in Language Models,"Minh Vu Pham, Hsuvas Borkakoty, Yufang Hou",,arXiv:2601.09445v1,"language models, knowledge conflict, mechanistic interpretability, intra-memory knowledge conflict, pre-training, parametric knowledge","In language models (LMs), intra-memory knowledge conflict arises when inconsistent information about the same event is encoded within the model’s parametric knowledge. Prior work has focused on resolving conflicts between a model’s internal knowledge and external resources, but the problem of localizing conflicts originating during pre-training within the model’s internal representations remains unexplored. This study designs a framework based on mechanistic interpretability methods to identify where and how conflicting knowledge from pre-training data is encoded within LMs. The findings show that specific internal components of a language model are responsible for encoding conflicting knowledge from pre-training, and demonstrate how mechanistic interpretability methods can be leveraged to causally intervene in and control conflicting knowledge at inference time.",3.22,85.839,276,cold_start,Phi-4,Apple_M1(Metal)
2601.09446v1_Improving Symbolic Translation of Language Models .pdf,Improving Symbolic Translation of Language Models for Logical Reasoning,"Ramya Keerthy Thatikonda, Jiuzhou Han, Wray Buntine, Ehsan Shareghi",,,"logical reasoning, language models, first-order logic, natural language processing, symbolic translation, error correction, incremental inference, predicate generation, verification module","The paper discusses the alignment of formal language with language models (LMs) for deductive logical reasoning, focusing on translating natural language (NL) into first-order logic (FOL) and using external solvers for verification. Smaller LMs often struggle with this task due to formatting and translation errors. The authors propose categorizing common errors and fine-tuning smaller LMs using data from large language models. They introduce incremental inference, dividing the process into predicate generation and FOL translation, and a verification module to target predicate-arity errors. The study evaluates three model families across four datasets, showing reduced error rates, increased predicate coverage, and improved reasoning performance for smaller LMs.",3.18,85.49,272,cold_start,Phi-4,Apple_M1(Metal)
2601.09448v1_Population-Aligned Audio Reproduction With LLM-Bas.pdf,Population-Aligned Audio Reproduction With LLM-Based Equalizers,"Ioannis Stylianou, Jon Francombe, Pablo Martínez-Nuevo, Sven Ewan Shepstone, Zheng-Hua Tan",,,"LLMs, Equalization, Audio Reproduction, Listening Experiments, Recommender Systems","This paper introduces a Large Language Model (LLM)-based alternative to conventional audio equalization, which requires manual adjustments. The proposed method maps natural language text prompts to equalization settings, enabling a conversational approach to sound system control. By leveraging data from a controlled listening experiment, the models use in-context learning and parameter-efficient fine-tuning to align with population-preferred equalization settings. Evaluation methods show statistically significant improvements in distributional alignment over random sampling and static preset baselines, suggesting that LLMs could serve as 'artificial equalizers' for more accessible, context-aware, and expert-level audio tuning.",3.14,78.251,246,cold_start,Phi-4,Apple_M1(Metal)
2601.09451v1_Late Breaking Results Quamba-SE Soft-edge Quantize.pdf,Late Breaking Results: Quamba-SE: Soft-edge Quantizer for Activations in State Space Models,"Yizhi Chen, Ahmed Hemani",,,"Quantization, State Space Models, Quamba","We propose Quamba-SE, a soft-edge quantizer for State Space Model (SSM) activation quantization. Unlike existing methods, Quamba-SE employs three adaptive scales: high-precision for small values, standard scale for normal values, and low-precision for outliers. This approach preserves outlier information instead of hard clipping, while maintaining precision for other values. We evaluate on Mamba-130M across 6 zero-shot benchmarks. Results show that Quamba-SE consistently outperforms Quamba, achieving up to +2.68% on individual benchmarks and up to +0.83% improvement in the average accuracy of 6 datasets.",2.86,77.211,221,cold_start,Phi-4,Apple_M1(Metal)
2601.09455v1_On the Hardness of Computing Counterfactual and Se.pdf,On the Hardness of Computing Counterfactual and Semi-factual Explanations in XAI,"André Artelt, Martin Olsen, Kevin Tierney",,2601.09455v1,"machine learning, explainable artificial intelligence, counterfactual explanations, semi-factual explanations, computational complexity","Providing clear explanations to the choices of machine learning models is essential for these models to be deployed in crucial applications. Counterfactual and semi-factual explanations have emerged as two mechanisms for providing users with insights into the outputs of their models. This paper provides an overview of the computational complexity results in the literature for generating these explanations, finding that in many cases, generating explanations is computationally hard. The authors contribute their own inapproximability results showing that not only are explanations often hard to generate, but under certain assumptions, they are also hard to approximate. The implications of these complexity results for the XAI community and for policymakers seeking to regulate explanations in AI are discussed.",3.25,77.273,251,cold_start,Phi-4,Apple_M1(Metal)
2601.09460v1_SoK Enhancing Cryptographic Collaborative Learning.pdf,Enhancing Cryptographic Collaborative Learning with Differential Privacy,"Francesco Capano, Jonas Böhler, Benjamin Weggenmann",,,"Differential privacy, cryptography, collaborative machine learning","In collaborative learning (CL), multiple parties jointly train a machine learning model on their private datasets without directly sharing data due to privacy concerns. Cryptographic techniques like multi-party computation (MPC) enable training on encrypted data, but securely trained models can still be vulnerable to inference attacks. Differential privacy (DP) mitigates these attacks by injecting noise during training. This work explores the integration of cryptography and DP for cryptographic and differentially private collaborative learning (CPCL), addressing the privacy-accuracy-performance trade-off. A unified framework is introduced, focusing on secure noise sampling as a foundational phase for CPCL. The paper analyzes trade-offs of secure noise sampling techniques, noise types, and DP mechanisms, evaluating their accuracy and cryptographic overhead. Secure noise sampling options are implemented in MPC and evaluated for computation and communication costs. Future research directions are proposed based on key observations and gaps identified in the literature.",3.22,83.909,270,cold_start,Phi-4,Apple_M1(Metal)
2601.09465v1_EvoFSM Controllable Self-Evolution for Deep Resear.pdf,EvoFSM: Controllable Self-Evolution for Deep Research with Finite State Machines,"Shuo Zhang, Chaofa Yuan, Ryan Guo, Xiaomin Yu, Rui Xu, Zhangquan Chen, Zinuo Li, Zhi Yang, Shuhao Guan, Zhenheng Tang, Sen Hu, Liwen Zhang, Ronghao Chen, Huacan Wang",,arXiv:2601.09465v1,"cs.AI, LLM-based agents, self-evolution, Finite State Machine, deep research, multi-hop QA benchmarks, interactive decision-making tasks","While LLM-based agents have shown promise for deep research, most existing approaches rely on fixed workflows that struggle to adapt to real-world, open-ended queries. Recent work explores self-evolution by allowing agents to rewrite their own code or prompts to improve problem-solving ability, but unconstrained optimization often triggers instability, hallucinations, and instruction drift. We propose EvoFSM, a structured self-evolving framework that achieves both adaptability and control by evolving an explicit Finite State Machine (FSM) instead of relying on free-form rewriting. EvoFSM decouples the optimization space into macroscopic Flow (state-transition logic) and microscopic Skill (state-specific behaviors), enabling targeted improvements under clear behavioral boundaries. Guided by a critic mechanism, EvoFSM refines the FSM through a small set of constrained operations, and further incorporates a self-evolving memory that distills successful trajectories as reusable priors and failure patterns as constraints for future queries. Extensive evaluations on five multi-hop QA benchmarks demonstrate the effectiveness of EvoFSM. In particular, EvoFSM reaches 58.0% accuracy on the DeepSearch benchmark. Additional results on interactive decision-making tasks further validate its generalization.",3.74,117.909,441,cold_start,Phi-4,Apple_M1(Metal)
2601.09467v1_Searth Transformer A Transformer Architecture Inco.pdf,Searth Transformer: A Transformer Architecture Incorporating Earth's Geospheric Physical Priors for Global Mid-Range Weather Forecasting,"Tianye Li, Qi Liu, Hao Li, Lei Chen, Wencong Cheng, Fei Zheng, Xiangao Xia, Ya Wang, Gang Huang, Weiwei Wang, Xuan Tong, Ziqing Zu, Yi Fang, Shenming Fu, Jiang Jiang, Haochen Li, Mingxing Li, Jiangjiang Xia",,,"Transformer architecture, Earth's geospheric physical priors, global mid-range weather forecasting, zonal periodicity, meridional boundaries, window-based self-attention, Relay Autoregressive (RAR) fine-tuning strategy","Accurate global medium-range weather forecasting is pivotal to Earth system science and serving as a critical public-service application. While modern weather forecasting increasingly employs data-driven AI models, most Transformer-based architectures rely on generic vision-centric designs that overlook the Earth’s inherent spherical topology and zonal periodicity. Additionally, the resource-intensive nature of autoregressive training imposes critical bottlenecks, constraining attainable forecast horizons while aggravating error propagation. These limitations not only compromise physical consistency and forecast accuracy but also effectively preclude resource-constrained institutions from leveraging localized datasets to refine global model performance. To address these challenges, this paper proposes the Shifted Earth Transformer (Searth Transformer), a physics-informed transformer architecture designed for global medium-range weather forecasting. Searth Transformer integrates zonal periodicity and meridional boundaries into window-based self-attention, enabling physically consistent global information exchange. To mitigate the computational bottlenecks, we develop the Relay Autoregressive (RAR) fine-tuning strategy, a memory-efficient strategy decoupling GPU memory usage from the forecast length. This enables the model to learn effectively.",3.6,128.145,461,cold_start,Phi-4,Apple_M1(Metal)
2601.09469v2_FairGU Fairness-aware Graph Unlearning in Social N.pdf,FairGU: Fairness-aware Graph Unlearning in Social Networks,"Renqiang Luo, Yongshuai Yang, Huafei Huang, Qing Qing, Mingliang Hou, Ziqi Xu, Yi Yu, Jingjing Zhou, Feng Xia",https://doi.org/XXXXXXX.XXXXXXX,,"fairness, privacy, graph unlearning, social network","Graph unlearning has emerged as a critical mechanism for supporting sustainable and privacy-preserving social networks, enabling models to remove the influence of deleted nodes and thereby better safeguard user information. However, existing graph unlearning techniques insufficiently protect sensitive attributes, often leading to degraded algorithmic fairness compared with traditional graph learning methods. To address this gap, we introduce FairGU, a fairness-aware graph unlearning framework designed to preserve both utility and fairness during the unlearning process. FairGU integrates a dedicated fairness-aware module with effective data protection strategies, ensuring that sensitive attributes are neither inadvertently amplified nor structurally exposed when nodes are removed. Through extensive experiments on multiple real-world datasets, we demonstrate that FairGU consistently outperforms state-of-the-art graph unlearning methods and fairness-enhanced graph learning baselines in terms of both accuracy and fairness metrics. Our findings highlight a previously overlooked risk in current unlearning practices and establish FairGU as a robust and equitable solution for the next generation of socially sustainable networked systems.",3.24,106.326,344,cold_start,Phi-4,Apple_M1(Metal)
2601.09470v1_Personalized Multimodal Feedback Using Multiple Ex.pdf,Personalized Multimodal Feedback Using Multiple External Representations: Strategy Profiles and Learning in High School Physics,"Natalia Revenga-Lozano, Karina E. Avila, Steffen Steinert, Matthias Schweinberger, Clara E. Gómez-Pérez, Jochen Kuhn, Stefan Küchemann",,2601.09470v1,physics.ed-ph,"Multiple external representations (MERs) and personalized feedback support physics learning, yet evidence on how personalized feedback can effectively integrate MERs remains limited. This question is particularly timely given the emergence of multimodal large language models. We conducted a 16-24 week observational study in high school physics (N=661) using a computer-based platform that provided verification and optional elaborated feedback in verbal, graphical and mathematical forms. Linear mixed-effects models and strategy-cluster analyses (ANCOVA-adjusted comparisons) tested associations between feedback use and post-test performance and moderation by representational competence. Elaborated multirepresentational feedback showed a small but consistent positive association with post-test scores independent of prior knowledge and confidence. Learners adopted distinct representation-selection strategies; among students with lower representational competence, using a diverse set of representations related to higher learning, whereas this advantage diminished as competence increased. These findings motivate adaptive feedback designs and inform intelligent tutoring systems capable of tailoring feedback elaboration.",3.85,86.745,334,cold_start,Phi-4,Apple_M1(Metal)
2601.09473v1_SimMerge Learning to Select Merge Operators from S.pdf,SimMerge: Learning to Select Merge Operators from Similarity Signals,"Oliver Bolton, Aakanksha, Arash Ahmadian, Sara Hooker, Marzieh Fadaee, Beyza Ermis",,2601.09473v1,"model merging, large language models, merge operators, similarity signals, machine learning, LLM development","Model merging enables multiple large language models (LLMs) to be combined into a single model while preserving performance, offering a competitive alternative to multi-task training. However, merging can be difficult at scale, requiring the selection of the right merge operator, models, and order. This work introduces SimMerge, a predictive merge-selection method that selects the best merge using inexpensive, task-agnostic similarity signals between models. SimMerge predicts the performance of a given 2-way merge from functional and structural features computed from a small set of unlabeled probes. It selects the best merge operator, subset of models, and merge order, eliminating the expensive merge-and-evaluate loop. SimMerge surpasses standard merge-operator performance on 2-way merges of 7B-parameter LLMs and generalizes to multi-way merges and 111B-parameter LLM merges without retraining. A bandit variant supports adding new tasks, models, and operators on the fly, suggesting that learning how to merge is a practical route to scalable model composition when checkpoint catalogs are large and evaluation budgets are tight.",3.53,99.617,352,cold_start,Phi-4,Apple_M1(Metal)
2601.09478v3_Bridging Semantic Understanding and Popularity Bia.pdf,Bridging Semantic Understanding and Popularity Bias with LLMs,"Renqiang Luo, Dong Zhang, Yupeng Gao, Wen Shi, Mingliang Hou, Jiaying Liu, Zhe Wang, Shuo Yu*",https://doi.org/XXXXXXX.XXXXXXX,,"Semantic analysis, Recommender systems, Algorithmic fairness, Popularity bias, LLM","Semantic understanding of popularity bias is a crucial yet underexplored challenge in recommender systems, where popular items are often favored at the expense of niche content. Most existing debiasing methods treat the semantic understanding of popularity bias as a matter of diversity enhancement or long-tail coverage, neglecting the deeper semantic layer that embodies the causal origins of the bias itself. Consequently, such shallow interpretations limit both their debiasing effectiveness and recommendation accuracy. In this paper, we propose FairLRM, a novel framework that bridges the gap in the semantic understanding of popularity bias with Recommendation via Large Language Model (RecLLM). FairLRM decomposes popularity bias into item-side and user-side components, using structured instruction-based prompts to enhance the model’s comprehension of both global item distributions and individual user preferences. Unlike traditional methods that rely on surface-level features such as 'diversity' or 'debiasing', FairLRM improves the model’s ability to semantically interpret and address the underlying bias. Through empirical evaluation, we show that FairLRM significantly enhances both fairness and recommendation accuracy, providing a more semantically aware and trustworthy approach to enhance the semantic understanding of popularity bias. The implementation is available at https://github.com/LuoRenqiang/FairLRM.",3.41,117.568,401,cold_start,Phi-4,Apple_M1(Metal)
2601.09503v1_What Do LLM Agents Know About Their World Task2Qui.pdf,What Do LLM Agents Know About Their World? Task2Quiz: A Paradigm for Studying Environment Understanding,"Siyuan Liu, Hongbang Yuan, Xinze Li, Ziyue Zhu, Yixin Cao, Yu-Gang Jiang",,2601.09503v1,"Large language model, LLM agents, environment understanding, generalization, evaluation paradigm, Task-to-Quiz, T2QBench, autonomous agents","Large language model (LLM) agents have shown remarkable capabilities in complex decision-making and tool-use tasks. However, their ability to generalize across varying environments is under-examined. Current evaluation paradigms focus on trajectory-based metrics that measure task success, neglecting whether agents possess a grounded, transferable model of the environment. This paper proposes Task-to-Quiz (T2Q), a deterministic and automated evaluation paradigm that decouples task execution from world-state understanding. T2QBench, a suite comprising 30 environments and 1,967 grounded QA pairs, is introduced to address this gap. Experiments reveal that task success is often a poor proxy for environment understanding, and current memory mechanisms do not effectively help agents acquire a grounded model of the environment. The findings identify proactive exploration and fine-grained state representation as primary bottlenecks, providing a foundation for developing more generalizable autonomous agents.",3.62,93.317,338,cold_start,Phi-4,Apple_M1(Metal)
2601.09518v1_Learning Whole-Body Human-Humanoid Interaction fro.pdf,Learning Whole-Body Human-Humanoid Interaction from Human-Human Demonstrations,"Wei-Jin Huang, Yue-Yi Zhang, Yi-Lin Wei, Zhi-Wei Xia, Juantao Tan, Yuan-Ming Li, Zhilin Zhao, Wei-Shi Zheng",,arXiv:2601.09518v1,"Human-Humanoid Interaction, Human-Human Interaction, Physics-Aware Interaction Retargeting, Decoupled Spatio-Temporal Action Reasoner, Whole-Body Interaction, Robotics","Enabling humanoid robots to physically interact with humans is a critical frontier, but progress is hindered by the scarcity of high-quality Human-Humanoid Interaction (HHoI) data. While leveraging abundant Human-Human Interaction (HHI) data presents a scalable alternative, we first demonstrate that standard retargeting fails by breaking the essential contacts. We address this with PAIR (Physics-Aware Interaction Retargeting), a contact-centric, two-stage pipeline that preserves contact semantics across morphology differences to generate physically consistent HHoI data. This high-quality data, however, exposes a second failure: conventional imitation learning policies merely mimic trajectories and lack interactive understanding. We therefore introduce D-STAR (Decoupled Spatio-Temporal Action Reasoner), a hierarchical policy that disentangles when to act from where to act. In D-STAR, Phase Attention (when) and a Multi-Scale Spatial module (where) are introduced.",3.65,100.001,365,cold_start,Phi-4,Apple_M1(Metal)
2601.09520v1_Towards Realistic Synthetic Data for Automatic Dru.pdf,TOWARDS REALISTIC SYNTHETIC DATA FOR AUTOMATIC DRUM TRANSCRIPTION,"Pierfrancesco Melucci, Paolo Merialdo, Taketo Akama",,,"Automatic Drum Transcription, Deep Learning, Synthetic Data, MIDI, SoundFont, One-shot Samples, Sequence-to-Sequence Model","Deep learning models define the state-of-the-art in Automatic Drum Transcription (ADT), yet their performance is contingent upon large-scale, paired audio-MIDI datasets, which are scarce. Existing workarounds that use synthetic data often introduce a significant domain gap, as they typically rely on low-fidelity SoundFont libraries that lack acoustic diversity. This paper introduces a new paradigm for ADT that circumvents the need for paired audio-MIDI training data. The primary contribution is a semi-supervised method to automatically curate a large and diverse corpus of one-shot drum samples from unlabeled audio sources. This corpus is used to synthesize a high-quality dataset from MIDI files alone, which is then used to train a sequence-to-sequence transcription model. The model achieves new state-of-the-art results on the ENST and MDB test sets, significantly outperforming both fully supervised methods and previous synthetic-data approaches.",3.36,90.871,305,cold_start,Phi-4,Apple_M1(Metal)
2601.09527v1_Private LLM Inference on Consumer Blackwell GPUs A.pdf,Private LLM Inference on Consumer Blackwell GPUs: A Practical Guide for Cost-Effective Local Deployment in SMEs,"Jonathan Knoop, Hendrik Holtmann",,,"LLM inference, consumer GPUs, NVIDIA Blackwell, SME deployment, data privacy, cost-effective, benchmarking, quantization, energy efficiency","SMEs increasingly seek alternatives to cloud LLM APIs due to data privacy concerns. This paper evaluates NVIDIA’s Blackwell consumer GPUs (RTX 5060 Ti, 5070 Ti, 5090) for LLM inference, benchmarking four open-weight models across various configurations. The RTX 5090 shows significantly higher throughput and lower latency for certain workloads, while budget GPUs offer the best throughput-per-dollar for API workloads. NVFP4 quantization enhances throughput and reduces energy consumption with minimal quality loss. Self-hosted inference is much cheaper than cloud APIs, with hardware breaking even in under four months at moderate volume. Consumer GPUs can reliably replace cloud inference for most SME workloads, except for latency-critical long-context RAG, where high-end GPUs are essential. Deployment guidance and benchmark data are provided for SME-scale deployments.",3.27,90.625,296,cold_start,Phi-4,Apple_M1(Metal)
2601.09536v1_Omni-R1 Towards the Unified Generative Paradigm fo.pdf,Omni-R1: Towards the Unified Generative Paradigm for Multimodal Reasoning,"Dongjie Cheng, Yongqi Li, Zhixin Ma, Hongru Cai, Yupeng Hu, Wenjie Wang, Liqiang Nie, Wenjie Li",,arXiv:2601.09536v1,"Multimodal Large Language Models, Multimodal Reasoning, Generative Paradigm, Perception Alignment, Functional Image Generation","Multimodal Large Language Models (MLLMs) are advancing in multimodal reasoning, transitioning from text-based reasoning to incorporating multimodal information. Early methods focused on text-based reasoning, while recent studies integrate visual information into reasoning steps. However, these methods often follow task-specific patterns, limiting generalizability. This paper proposes a unified generative multimodal reasoning approach, generating intermediate images during reasoning. The Omni-R1 framework, featuring perception alignment loss and reward, enables functional image generation. Additionally, Omni-R1-Zero bootstraps visualizations from text-only data, eliminating the need for multimodal annotations. Empirical results show Omni-R1's effectiveness across various tasks, with Omni-R1-Zero matching or surpassing Omni-R1, indicating a promising direction for generative multimodal reasoning.",3.48,92.127,321,cold_start,Phi-4,Apple_M1(Metal)
2601.09555v1_Benchmarking Post-Training Quantization of Large L.pdf,Benchmarking Post-Training Quantization of Large Language Models under Microscaling Floating Point Formats,"Manyi Zhang, Ji-Fu Li, Zhongao Sun, Haoli Bai, Hui-Ling Zhen, Zhenhua Dong, Xianzhi Yu",,,"Post-Training Quantization, Microscaling Floating-Point, Large Language Models, MXFP8, MXFP4, Quantization Sensitivity, PTQ Algorithms","Microscaling Floating-Point (MXFP) has emerged as a promising low-precision format for large language models (LLMs). Despite various post-training quantization (PTQ) algorithms being proposed, they mostly focus on integer quantization, while their applicability and behavior under MXFP formats remain largely unexplored. This work conducts a systematic investigation of PTQ under MXFP formats, encompassing over 7 PTQ algorithms, 15 evaluation benchmarks, and 3 LLM families. Key findings include: 1) MXFP8 consistently achieves near-lossless performance, while MXFP4 introduces substantial accuracy degradation; 2) PTQ effectiveness under MXFP depends strongly on format compatibility, with some algorithmic paradigms being consistently more effective; 3) PTQ performance exhibits consistent trends across model families and modalities, with quantization sensitivity dominated by the language model rather than the vision encoder in multimodal LLMs; 4) The scaling factor of quantization is a critical error source in MXFP4, and a simple pre-scale optimization strategy can significantly mitigate its impact. These results provide practical guidance on adapting existing PTQ methods to MXFP quantization.",3.4,107.353,365,cold_start,Phi-4,Apple_M1(Metal)
2601.09566v2_Hot-Start from Pixels Low-Resolution Visual Tokens.pdf,Hot-Start from Pixels: Low-Resolution Visual Tokens for Chinese Language Modeling,"Shuyang Xiang, Hao Guan",,2601.09566v2,"Chinese language modeling, visual tokens, low-resolution inputs, character-level modeling, hot-start effect","Large language models typically represent Chinese characters as discrete index-based tokens, largely ignoring their visual form. For logographic scripts, visual structure carries semantic and phonetic information, which may aid prediction. This study investigates whether low-resolution visual inputs can serve as an alternative for character-level modeling. Instead of token IDs, the decoder receives grayscale images of individual characters, with resolutions as low as 8×8 pixels. Remarkably, these inputs achieve 39.2% accuracy, comparable to the index-based baseline of 39.1%. Such low-resource settings also exhibit a pronounced hot-start effect: by 0.4% of total training, accuracy reaches above 12%, while index-based models lag at below 6%. Overall, the results demonstrate that minimal visual structure can provide a robust and efficient signal for Chinese language modeling, offering an alternative perspective on character representation that complements traditional index-based approaches.",3.58,79.992,286,cold_start,Phi-4,Apple_M1(Metal)
2601.09600v1_Information Access of the Oppressed A Problem-Posi.pdf,Information Access of the Oppressed: A Problem-Posing Framework for Envisioning Emancipatory Information Access Platforms,"BHASKAR MITRA, NICOLA NEOPHYTOU, SIREESH GURURAJA",https://doi.org/XXXXXXX.XXXXXXX,,"Emancipatory Information Access, Search and Society, Sociotechnical Information Systems, Information systems→Information retrieval, World Wide Web, Human-centered computing","This paper explores the risks of authoritarian capture of online information access platforms, particularly in the context of rising democratic erosion, generative AI technologies, and the concentration of power in Big Tech. It proposes a problem-posing framework inspired by Paulo Freire’s theories of emancipatory pedagogy to reimagine and build alternative information access infrastructures. The framework challenges the traditional technologist-user dichotomy and advocates for involving marginalized communities in the co-construction of technology to support their emancipatory struggles. The authors call on technologists to engage in building infrastructure for resistance against authoritarianism.",3.29,80.152,264,cold_start,Phi-4,Apple_M1(Metal)
2601.09603v1_Linear Complexity Self-Supervised Learning for Mus.pdf,Linear Complexity Self-Supervised Learning for Music Understanding with Random Quantizer,"Petros Vavaroutsos, Theodoros Palamas, Pantelis Vikatos",10.1145/3748522.3779786,,"Deep Learning, Learnable Representations, Music Understanding, Transformers, Embeddings, Attention","This paper focuses on reducing the size of foundation models for music information retrieval (MIR) tasks. It combines the Branchformer architecture with SummaryMixing and a random quantization process, initially applied in speech recognition. The research includes pre-training on publicly available datasets and a proprietary dataset. The architecture achieves competitive performance compared to state-of-the-art models using multi-head self-attention, reducing model size by 8.5% to 12.3%.",3.03,70.892,215,cold_start,Phi-4,Apple_M1(Metal)
2601.09605v1_Sim2real Image Translation Enables Viewpoint-Robus.pdf,Sim2real Image Translation Enables Viewpoint-Robust Policies from Fixed-Camera Datasets,"Jeremiah Coholich, Justin Wit, Robert Azarcon, Zsolt Kira",,,"Sim2real, Image Translation, Robot Manipulation, Viewpoint-Robust Policies, Fixed-Camera Datasets, Vision-Based Policies, Simulation, MANGO, InfoNCE Loss, PatchNCE Loss, Imitation Learning","Vision-based policies for robot manipulation have achieved significant success but remain sensitive to distribution shifts like camera viewpoint variations. Robot demonstration data is often limited and lacks diverse camera viewpoints. Simulation can provide extensive viewpoint coverage but faces visual sim2real challenges. This paper introduces MANGO, an unpaired image translation method with a novel segmentation-conditioned InfoNCE loss, a highly-regularized discriminator design, and a modified PatchNCE loss. These components are essential for maintaining viewpoint consistency during sim2real translation. MANGO requires only a small amount of fixed-camera real-world data and can generate diverse unseen viewpoints by translating simulated observations. It outperforms other image translation methods in this domain. Imitation-learning policies trained with MANGO-augmented data achieve success rates up to 60% on views where non-augmented policies fail completely.",3.5,91.944,322,cold_start,Phi-4,Apple_M1(Metal)
2601.09609v1_DPWriter Reinforcement Learning with Diverse Plann.pdf,DPWriter: Reinforcement Learning with Diverse Planning Branching for Creative Writing,"Qian Cao, Yahui Liu, Wei Bi, Yi Zhao, Ruihua Song, Xiting Wang, Ruiming Tang, Guorui Zhou, Han Li",,,"Reinforcement Learning, Large Language Models, Creative Writing, Diversity, Chain-of-Thought, Planning, Diverse Planning Branching","Reinforcement learning (RL)-based enhancement of large language models (LLMs) often leads to reduced output diversity, undermining their utility in open-ended tasks like creative writing. Current methods lack explicit mechanisms for guiding diverse exploration and instead prioritize optimization efficiency and performance over diversity. This paper proposes an RL framework structured around a semi-structured long Chain-of-Thought (CoT), in which the generation process is decomposed into explicitly planned intermediate steps. We introduce a Diverse Planning Branching method that strategically introduces divergence at the planning phase based on diversity variation, alongside a group-aware diversity reward to encourage distinct trajectories. Experimental results on creative writing benchmarks demonstrate that our approach significantly improves output diversity without compromising generation quality, consistently outperforming existing baselines.",3.31,90.999,301,cold_start,Phi-4,Apple_M1(Metal)
2601.09613v1_CogRail Benchmarking VLMs in Cognitive Intrusion P.pdf,CogRail: Benchmarking VLMs in Cognitive Intrusion Perception for Intelligent Railway Transportation Systems,"Yonglin Tian, Qiyao Zhang, Wei Xu, Yutong Wang, Yihao Wu, Xinyi Li, Xingyuan Dai, Hui Zhang, Zhiyong Cui, Baoqing Guo, Zujun Yu, Yisheng Lv",,,"Cognitive Intrusion Perception, Intelligent Railway Transportation Systems, Visual-Language Models, Spatio-Temporal Reasoning, Benchmarking, Deep Learning","Accurate and early perception of potential intrusion targets is essential for ensuring the safety of railway transportation systems. Existing systems often focus narrowly on object classification within fixed visual scopes and apply rule-based heuristics to determine intrusion status, often overlooking targets that pose latent intrusion risks. Anticipating such risks requires the cognition of spatial context and temporal dynamics for the object of interest (OOI), which presents challenges for conventional visual models. To facilitate deep intrusion perception, we introduce a novel benchmark, CogRail, which integrates curated open-source datasets with cognitively driven question-answer annotations to support spatio-temporal reasoning and prediction. Building upon this benchmark, we conduct a systematic evaluation of state-of-the-art visual-language models (VLMs) using multimodal prompts to identify their strengths and limitations in this domain. Furthermore, we fine-tune VLMs for better performance and propose a joint fine-tuning framework that integrates three core tasks, position perception, movement prediction, and threat analysis, facilitating effective adaptation of general-purpose foundation models into specialized models tailored for cognitive intrusion perception. Extensive experiments reveal that current large-scale multimodal models struggle with the complex spatial-temporal reasoning required by the cognitive intrusion perception task, underscoring the limitations of existing foundation models in this safety-critical domain. In contrast, our proposed joint fine-tuning framework significantly improves performance.",3.63,125.708,456,cold_start,Phi-4,Apple_M1(Metal)
2601.09620v1_Full Disclosure Less Trust How the Level of Detail.pdf,"Full Disclosure, Less Trust? How the Level of Detail about AI Use in News Writing Affects Readers’ Trust","Pooja Prajod, Hannes Cools, Thomas Röggla, Karthiskeya Puttur Venkatraj, Amber Kusters, Alia Elkattan, Pablo Cesar, Abdallah El Ali",,,"AI disclosures, news production, reader trust, transparency dilemma, source-checking, subscription decisions","As AI is increasingly integrated into news production, transparency about AI use has become crucial. This study investigates how different levels of AI disclosure (none, one-line, detailed) across various news types (politics, lifestyle) and AI involvement levels (low, high) affect readers' trust. Using a 3×2×2 mixed factorial study with 40 participants, the research measured trust with the News Media Trust questionnaire and observed decision behaviors like source-checking and subscription decisions. Detailed AI disclosures led to a decline in trust, while source-checking increased with both one-line and detailed disclosures. Interviews revealed that source-checking was driven by interest and trust, while trust influenced subscription decisions. Most participants preferred detailed disclosures, with some favoring detail-on-demand formats. The findings suggest a trade-off between transparency and trust in AI-assisted news content.",3.55,92.788,329,cold_start,Phi-4,Apple_M1(Metal)
2601.09624v1_Toward Understanding Unlearning Difficulty A Mecha.pdf,Toward Understanding Unlearning Difficulty: A Mechanistic Perspective and Circuit-Guided Difficulty Metric,"Jiali Cheng, Ziheng Chen, Chirag Agarwal, Hadi Amiri",,,"machine unlearning, language models, model circuits, unlearning difficulty, Circuit-guided Unlearning Difficulty (CUD)","Machine unlearning is essential for building trustworthy and compliant language models. However, unlearning success varies across samples, with some being reliably erased and others persisting. This disparity is not only a data-side phenomenon but also reflects model-internal mechanisms that encode and protect memorized information. The study introduces Circuit-guided Unlearning Difficulty (CUD), a pre-unlearning metric that assigns each sample a continuous difficulty score using circuit-level signals. Experiments show that CUD reliably separates easy and hard samples and remains stable across unlearning methods. Key circuit-level patterns reveal that easy-to-unlearn samples are associated with shorter, shallower interactions in earlier-to-intermediate parts of the model, while hard samples rely on longer, deeper pathways closer to late-stage computation. CUD provides a principled, fine-grained, and interpretable analysis of unlearning difficulty, motivating the development of unlearning methods grounded in model mechanisms.",3.33,84.864,283,cold_start,Phi-4,Apple_M1(Metal)
2601.09625v1_The Promptware Kill Chain How Prompt Injections Gr.pdf,The Promptware Kill Chain: How Prompt Injections Gradually Evolved Into a Multi-Step Malware,"Ben Nassi, Bruce Schneier, Oleg Brodt",,,"large language models, LLM-based systems, prompt injection, malware, cybersecurity, AI safety","The rapid adoption of large language model (LLM)-based systems—from chatbots to autonomous agents capable of executing code and financial transactions—has created a new attack surface that existing security frameworks inadequately address. The dominant framing of these threats as 'prompt injection'—a catch-all phrase for security failures in LLM-based systems—obscures a more complex reality: Attacks on LLM-based systems increasingly involve multi-step sequences that mirror traditional malware campaigns. This paper proposes that attacks targeting LLM-based applications constitute a distinct class of malware, termed 'promptware', and introduces a five-step kill chain model for analyzing these threats. The framework comprises Initial Access (prompt injection), Privilege Escalation (jailbreaking), Persistence (memory and retrieval poisoning), Lateral Movement (cross-system and cross-user propagation), and Actions on Objective (ranging from data exfiltration to unauthorized transactions). By mapping recent attacks to this structure, the paper demonstrates that LLM-related attacks follow systematic sequences analogous to traditional malware campaigns. The promptware kill chain offers security practitioners a structured methodology for threat modeling and provides a common vocabulary for researchers across AI safety and cybersecurity to address a rapidly evolving threat landscape.",3.61,97.749,353,cold_start,Phi-4,Apple_M1(Metal)
2601.09626v1_From Prompt to Protocol Fast Charging Batteries wi.pdf,From Prompt to Protocol: Fast Charging Batteries with Large Language Models,"Ge Lei, Ferran Brosa Planella, Sterling G. Baird, Samuel J. Cooper",,arXiv:2601.09626v1,"battery charging protocols, large language models, gradient-free optimization, LLM-driven methods, fast charging, state of health, neural networks, Bayesian optimization, evolutionary algorithms, random search","Efficiently optimizing battery charging protocols is challenging due to slow, costly, and non-differentiable evaluations. Existing approaches often limit the diversity of protocols by constraining the search space. This work introduces two gradient-free, LLM-driven closed-loop methods: Prompt-to-Optimizer (P2O) and Prompt-to-Protocol (P2P). P2O uses an LLM to propose neural-network-based protocols, while P2P writes explicit functions for current and its parameters. LLM-guided P2O outperforms traditional methods like Bayesian optimization, evolutionary algorithms, and random search. In fast-charging scenarios, both P2O and P2P improve state of health by around 4.2% over a multi-step constant current baseline. These results show that LLMs can expand protocol functional forms, incorporate language-based constraints, and optimize efficiently in high-cost settings.",3.58,93.697,335,cold_start,Phi-4,Apple_M1(Metal)
2601.09635v1_LLM for Large-Scale Optimization Model Auto-Formul.pdf,LLM for Large-Scale Optimization Model Auto-Formulation: A Lightweight Few-Shot Learning Approach,"Kuo Liang, Yuhang Lu, Jianming Mao, Shuyi Sun, Chunwei Yang, Congcong Zeng, Xiao Jin, Hanzhang Qin, Ruihao Zhu, Chung-Piaw Teo",,arXiv:2601.09635,"large language models, tool use, agentic workflow construction, automated optimization modeling","Large-scale optimization is crucial for modern business decision-making but is often labor-intensive and time-consuming. This paper introduces LEAN-LLM-OPT, a framework for LLM-assisted large-scale optimization auto-formulation. It uses a team of LLM agents to dynamically construct a workflow for formulating optimization models from problem descriptions and datasets. The framework decomposes the task into structured sub-tasks, offloading mechanical data-handling to auxiliary tools, allowing the downstream agent to focus on complex components. Simulations show strong performance with GPT-4.1 and gpt-oss-20B, and practical value is demonstrated in a Singapore Airlines use case. The paper also introduces benchmarks for large-scale optimization auto-formulation.",3.5,89.835,314,cold_start,Phi-4,Apple_M1(Metal)
2601.09636v1_PersonalAlign Hierarchical Implicit Intent Alignme.pdf,PersonalAlign: Hierarchical Implicit Intent Alignment for Personalized GUI Agent with Long-Term User-Centric Records,"Yibo Lyu, Gongwei Chen, Rui Shao, Weili Guan, Liqiang Nie",,,"GUI agents, implicit intent alignment, personalized agents, long-term user records, proactive assistance","This work introduces PersonalAlign, a task for GUI agents to leverage long-term user records to align with users' implicit intents. The study presents AndroidIntent, a benchmark for evaluating agents' ability to resolve vague instructions and provide proactive suggestions. The Hierarchical Intent Memory Agent (HIM-Agent) is introduced, which maintains a continuously updating personal memory to organize user preferences and routines. Evaluation on AndroidIntent shows HIM-Agent significantly improves execution and proactive performance. The work emphasizes the need for personalized agents capable of understanding implicit intents beyond explicit instructions.",3.21,71.877,231,cold_start,Phi-4,Apple_M1(Metal)
2601.09667v2_Collaborative Multi-Agent Test-Time Reinforcement .pdf,Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning,"Zhiyuan Hu, Yunhai Hu, Juncheng Liu, Shuyue Stella Li, Yucheng Wang, Zhen Xu, See-Kiong Ng, Anh Tuan Luu, Xinxing Xu, Bryan Hooi, Cynthia Breazeal, Hae Won Park",,,"multi-agent systems, reinforcement learning, test-time adaptation, collaboration, reasoning, distribution shift","Multi-agent systems have evolved into practical LLM-driven collaborators for many applications, gaining robustness from diversity and cross-checking. However, multi-agent RL (MARL) training is resource-intensive and unstable due to co-adapting teammates inducing non-stationarity and sparse, high-variance rewards. This paper introduces Multi-Agent Test-Time Reinforcement Learning (MATTRL), a framework that injects structured textual experience into multi-agent deliberation at inference time. MATTRL forms a multi-expert team for multi-turn discussions, retrieves and integrates test-time experiences, and reaches consensus for final decision-making. Across challenging benchmarks in medicine, math, and education, MATTRL improves accuracy by an average of 3.67% over a multi-agent baseline, and by 8.67% over comparable single-agent baselines. Ablation studies examine different credit-assignment schemes and provide a detailed comparison of how they affect training outcomes. MATTRL offers a stable, effective, and efficient path to distribution-shift-robust multi-agent reasoning without tuning.",3.55,108.517,385,cold_start,Phi-4,Apple_M1(Metal)
2601.09680v1_Automating Supply Chain Disruption Monitoring via .pdf,Automating Supply Chain Disruption Monitoring via an Agentic AI Approach,"Sara AlMahria, Liming Xu, Alexandra Brintrup",,2601.09680v1,"Supply Chain Management, Supply Chain Disruption, Large Language Models, AI Agents, Multi-Agent System, Agentic System","Modern supply chains are increasingly exposed to disruptions from geopolitical events, demand shocks, trade restrictions, to natural disasters. While many of these disruptions originate deep in the supply network, most companies still lack visibility beyond Tier-1 suppliers, leaving upstream vulnerabilities undetected until the impact cascades downstream. To overcome this blind-spot and move from reactive recovery to proactive resilience, we introduce a minimally supervised agentic AI framework that autonomously monitors, analyses, and responds to disruptions across extended supply networks. The architecture comprises seven specialised agents powered by large language models and deterministic tools that jointly detect disruption signals from unstructured news, map them to multi-tier supplier networks, evaluate exposure based on network structure, and recommend mitigations such as alternative sourcing options. We evaluate the framework across 30 synthesised scenarios covering three automotive manufacturers and five disruption classes. The system achieves high accuracy across core tasks, with F1 scores between 0.962 and 0.991, and performs full end-to-end analyses in a mean of 3.83 minutes at a cost of $0.0836 per disruption. Relative to industry benchmarks of multi-day, analyst-driven assessments, this represents a reduction of more than three orders of magnitude in response time. A real-world case study of the 2022 Russia–Ukraine conflict further demonstrates operational applicability. This work establishes a foundational step toward building resilient, proactive, and autonomous supply chains capable of managing disruptions across deep-tier networks.",3.92,104.299,409,cold_start,Phi-4,Apple_M1(Metal)
2601.09684v1_Disentangling Task Conflicts in Multi-Task LoRA vi.pdf,Disentangling Task Conflicts in Multi-Task LoRA via Orthogonal Gradient Projection,"Ziyu Yang, Guibin Chen, Yuxin Yang, Aoxiong Zeng, Xiangquan Yang",,,"Multi-Task Learning, Low-Rank Adaptation, Large Language Models, Parameter-Efficient Fine-Tuning, Gradient Projection, Orthogonal Complement, Negative Transfer, Gradient Conflict","Multi-Task Learning (MTL) combined with Low-Rank Adaptation (LoRA) is a promising approach for parameter-efficient deployment of Large Language Models (LLMs). However, sharing a single adapter across multiple tasks can lead to negative transfer due to conflicting gradient updates. This issue is exacerbated by the low-rank constraint in LoRA, which limits the optimization landscape's capacity. This paper introduces Ortho-LoRA, a gradient projection method tailored for LoRA's bipartite structure. It projects conflicting task gradients onto the orthogonal complement of each other within the intrinsic LoRA subspace. Experiments on the GLUE benchmark show that Ortho-LoRA effectively mitigates task interference, outperforming standard joint training and recovering 95% of the performance gap between multi-task and single-task baselines with negligible computational overhead.",3.47,90.569,314,cold_start,Phi-4,Apple_M1(Metal)
2601.09692v1_Routing with Generated Data Annotation-Free LLM Sk.pdf,Routing with Generated Data: Annotation-Free LLM Skill Estimation and Expert Selection,"Tianyi Niu, Justin Chih-Yao Chen, Genta Indra Winata, Shi-Xiong Zhang, Supriyo Chakraborty, Sambit Sahu, Yue Zhang, Elias Stengel-Eskin, Mohit Bansal",,,"Large Language Models, Routing, Generated Data, Skill Estimation, Expert Selection, Query-only Routing, Query-answer Routing, CASCAL, Consensus Voting, Hierarchical Clustering","This paper introduces Routing with Generated Data (RGD), a method for training routers to select optimal models for given inputs using generated queries and answers from high-level task descriptions. The study evaluates query-answer and query-only routers across various benchmarks, revealing that query-only routers are more robust to generator quality. The paper proposes CASCAL, a novel query-only router that uses consensus voting and hierarchical clustering to estimate model correctness and identify model-specific skill niches, showing improved performance over existing methods.",3.31,86.163,285,cold_start,Phi-4,Apple_M1(Metal)
2601.09694v1_LLMs can Compress LLMs Adaptive Pruning by Agents.pdf,LLMs can Compress LLMs: Adaptive Pruning by Agents,"Sai Varun Kodathala, Rakesh Vunnam",,2601.09694v1,"Model Compression, Adaptive Pruning, Self-Reflection","As Large Language Models (LLMs) continue to scale, post-training pruning has emerged as a promising approach to reduce computational costs while preserving performance. Existing methods such as SparseGPT and Wanda achieve high sparsity through layer-wise weight reconstruction or activation-aware magnitude pruning, but rely on uniform or hand-crafted heuristics to determine per-layer sparsity ratios. Moreover, recent work has shown that pruned LLMs suffer from severe factual knowledge degradation, with structured pruning methods experiencing near-total collapse in factual question-answering capabilities. We introduce agent-guided pruning, where a foundation model acts as an adaptive pruning agent to intelligently select which layers to prune at each iteration while preserving critical knowledge pathways. Our method constructs layer-wise sensitivity profiles by combining Wanda-inspired weight-activation metrics with gradient importance scores, normalized as z-scores for model-agnostic comparison. These statistics are processed by an LLM agent equipped with self-reflection capabilities, enabling it to learn from previous pruning outcomes and iteratively refine its strategy. A checkpoint rollback mechanism maintains model quality by reverting when perplexity degradation exceeds a threshold. We evaluate our approach on Qwen3 models (4B and 8B parameters) at approximately 45% sparsity, demonstrating substantial improvements over structured pruning baselines: 56% relative improvement in MMLU accuracy, 19× better factual knowledge retention on FreebaseQA, and 69% lower perplexity degradation. Notably, our framework requires no retraining, operates in a model-agnostic manner, and exhibits effective self-correction with only 2-4 rollbacks across 21-40 iterations, demonstrating that foundation models can effectively guide the compression of other foundation models.",3.95,111.971,442,cold_start,Phi-4,Apple_M1(Metal)
2601.09703v1_ShortCoder Knowledge-Augmented Syntax Optimization.pdf,ShortCoder: Knowledge-Augmented Syntax Optimization for Token-Efficient Code Generation,"Sicong Liu, Yanxian Huang, Mingwei Liu, Jiachi Chen, Ensheng Shi, Yuchi Ma, Hongyu Zhang, Yin Zhang, Yanlin Wang",,,"code generation, large language models, LLMs, token efficiency, syntax simplification, code optimization","Code generation tasks aim to automate the conversion of user requirements into executable code, significantly reducing manual development efforts and enhancing software productivity. The emergence of large language models (LLMs) has significantly advanced code generation, though their efficiency is still impacted by certain inherent architectural constraints. Each token generation necessitates a complete inference pass, requiring persistent retention of contextual information in memory and escalating resource consumption. While existing research prioritizes inference-phase optimizations—such as prompt compression and model quantization, the generation phase remains underexplored. To tackle these challenges, we propose a knowledge-infused framework named ShortCoder, which optimizes code generation efficiency while preserving semantic equivalence and readability. In particular, we introduce: (1) ten syntax-level simplification rules for Python, derived from AST-preserving transformations, achieving 18.1% token reduction without functional compromise; (2) a hybrid data synthesis pipeline integrating rule-based rewriting with LLM-guided refinement, producing ShorterCodeBench—a corpus of validated ⟨original code, simplified code⟩ pairs with semantic consistency; (3) a fine-tuning strategy that injects conciseness awareness into the base LLMs. Extensive experimental results demonstrate that ShortCoder consistently outperforms state-of-the-art methods on HumanEval, achieving an improvement of 18.1%-37.8% in generation efficiency over previous methods while ensuring the performance of code generation.",3.78,112.768,426,cold_start,Phi-4,Apple_M1(Metal)
2601.09706v1_Value-Aware Numerical Representations for Transfor.pdf,Value-Aware Numerical Representations for Transformer Language Models,"Andreea Dutulescu, Stefan Ruseti, Mihai Dascalu",,,"Transformer language models, numerical reasoning, arithmetic operations, value-aware numerical representation, mathematical benchmarks","Transformer-based language models often achieve strong results on mathematical reasoning benchmarks while remaining fragile on basic numerical understanding and arithmetic operations. A central limitation is that numbers are processed as symbolic tokens whose embeddings do not explicitly encode numerical value, leading to systematic errors. This paper introduces a value-aware numerical representation that augments standard tokenized inputs with a dedicated prefix token whose embedding is explicitly conditioned on the underlying numerical value. This mechanism injects magnitude information directly into the model’s input space while remaining compatible with existing tokenizers and decoder-only Transformer architectures. Evaluation on arithmetic tasks shows that the proposed approach outperforms baselines across numerical formats, tasks, and operand lengths. These results indicate that explicitly encoding numerical value is an effective and efficient way to improve fundamental numerical robustness in language models.",3.33,72.385,241,cold_start,Phi-4,Apple_M1(Metal)
2601.09708v1_Fast-ThinkAct Efficient Vision-Language-Action Rea.pdf,Fast-ThinkAct: Efficient Vision-Language-Action Reasoning via Verbalizable Latent Planning,"Chi-Pin Huang, Yunze Man, Zhiding Yu, Min-Hung Chen, Jan Kautz, Yu-Chiang Frank Wang, Fu-En Yang",,2601.09708v1,"Vision-Language-Action, latent planning, inference latency, embodied control, long-horizon planning, few-shot adaptation, failure recovery","Vision-Language-Action (VLA) tasks require reasoning over complex visual scenes and executing adaptive actions in dynamic environments. Recent studies show that explicit chain-of-thought (CoT) can improve generalization but suffer from high inference latency due to lengthy reasoning traces. Fast-ThinkAct is proposed as an efficient reasoning framework that achieves compact yet performant planning through verbalizable latent reasoning. It learns to reason efficiently with latent CoTs by distilling from a teacher, driven by a preference-guided objective to align manipulation trajectories, transferring both linguistic and visual planning capabilities for embodied control. This enables reasoning-enhanced policy learning that effectively connects compact reasoning to action execution. Extensive experiments demonstrate that Fast-ThinkAct achieves strong performance with up to 89.3% reduced inference latency over state-of-the-art reasoning VLAs, while maintaining effective long-horizon planning, few-shot adaptation, and failure recovery.",3.54,95.381,338,cold_start,Phi-4,Apple_M1(Metal)
2601.09749v1_R-LAM Reproducibility-Constrained Large Action Mod.pdf,R-LAM: Reproducibility-Constrained Large Action Models for Scientific Workflow Automation,Suriya Sureshkumar,,,"Reproducible Scientific Workflows, Large Action Models, LLM-Based Agents, Execution Provenance, Deterministic Execution","Large Action Models (LAMs) extend large language models by enabling autonomous decision-making and tool execution, making them promising for automating scientific workflows. However, scientific workflows impose strict requirements on reproducibility, auditability, and deterministic execution, which are not satisfied by generic LLM-based agents. Unconstrained action generation can lead to silent state changes, non-deterministic executions, and irreproducible experimental results, limiting the applicability of LAMs in scientific settings. In this paper, we propose R-LAM, a reproducibility-constrained framework for applying Large Action Models to scientific workflow automation. R-LAM introduces structured action schemas, deterministic execution policies, and explicit provenance tracking to ensure that every action and intermediate artifact is auditable and replayable. The framework supports failure-aware execution loops and controlled workflow forking, enabling iterative experimentation without compromising reproducibility. We implement R-LAM as a lightweight Python framework and release it as an open-source PyPI package to facilitate reproducible research. An experimental evaluation of representative scientific workflows demonstrates that R-LAM improves reproducibility success rates and execution reliability compared to unconstrained LLM-based agents, while retaining adaptive control over workflow execution.",3.61,89.802,324,cold_start,Phi-4,Apple_M1(Metal)
2601.09750v1_SAGE Tool-Augmented LLM Task Solving Strategies in.pdf,SAGE: Tool-Augmented LLM Task Solving Strategies in Scalable Multi-Agent Environments,"Robert K. Strehlow, Tobias Küster, Oskar F. Kupke, Brandon Llanque Kurps, Fikret Sivrikaya, Sahin Albayrak",,,"Large Language Models, LLMs, Tool-Augmented, Multi-Agent Environments, OPACA Framework, Tool Discovery, Execution, Conversational AI, Microservices, Prompting Methods","This paper introduces 'SAGE', a specialized conversational AI interface based on the OPACA framework for tool discovery and execution. It discusses the integration of new tools into LLMs dynamically and presents various task-solving strategies using agentic concepts and prompting methods. The paper evaluates these strategies against benchmark services, highlighting their strengths and weaknesses. Both SAGE and the OPACA framework, along with benchmark services and results, are available as Open Source/Open Data on GitHub.",3.23,81.664,264,cold_start,Phi-4,Apple_M1(Metal)
2601.09753v1_Critically Engaged Pragmatism A Scientific Norm an.pdf,"Critically Engaged Pragmatism: A Scientific Norm and Social, Pragmatist Epistemology for AI Science Evaluation Tools",Carole J. Lee,,,"AI science evaluation tools, peer review crisis, replication crisis, scientific credibility, Critically Engaged Pragmatism, social pragmatist epistemology","The paper discusses the challenges faced by the scientific community in evaluating research credibility due to the limitations of peer review and replication studies. It highlights the rise of AI science evaluation tools as a response to these challenges but warns against their misuse due to technical and epistemic issues. The author advocates for a social, pragmatist epistemology and a norm of Critically Engaged Pragmatism to ensure these tools are used appropriately and effectively within scientific communities.",3.15,67.048,211,cold_start,Phi-4,Apple_M1(Metal)
2601.09755v1_Heterogeneous computing platform for real-time rob.pdf,Heterogeneous computing platform for real-time robotics,"Jakub Fil, Yulia Sandamirskaya, Hector Gonzalez, Loïc Azzalin, Stefan Glüge, Lukas Friedenstab, Friedrich Wolf, Tim Rosmeisl, Matthias Lohrmann, Mahmoud Akl, Khaleel Khan, Leonie Wolf, Kristin Richter, Holm Puder, Mazhar Ali Bari, Xuan Choo, Noha Alharthi, Michael Hopkins, Mansoor Hanif, Christian Mayr, Jens Struckmeier, Steve Furber",,,"heterogeneous computing, real-time robotics, neuromorphic computing, event-based cameras, AI compute cluster, GPUs, cognitive cities, dynamic vision sensor, Loihi2 processor, SpiNNaker2, social robotics","This paper explores a computing platform required for enabling Society 5.0, where robotics plays a pivotal role in smart cities. It combines neuromorphic computing hardware, exemplified by the Loihi2 processor, with event-based cameras for real-time perception and interaction, alongside a local AI compute cluster (GPUs) for high-level language processing, cognition, and task planning. The proposed hybrid computing architecture is demonstrated through an interactive task where a humanoid robot plays a musical instrument with a human. The system architecture highlights the potential of heterogeneous computing architectures in advancing robotic autonomy and interactive intelligence, aiming for seamless integration of software and hardware to maximize performance and responsiveness.",3.67,113.241,416,cold_start,Phi-4,Apple_M1(Metal)
2601.09756v1_Synthetic Data for Veterinary EHR De-identificatio.pdf,"Synthetic Data for Veterinary EHR De-identification: Benefits, Limits, and Safety Trade-offs Under Fixed Compute","David Brundage, PhD",,,"veterinary electronic health records, de-identification, large language models, synthetic data, privacy, surveillance, research","Veterinary electronic health records (vEHRs) are increasingly used for surveillance and research, but free-text narratives often contain privacy-sensitive identifiers that limit their secondary use. This study evaluates the use of large language model (LLM)-generated synthetic veterinary narratives to improve de-identification safety and utility. Using the PetEVAL dataset, the study explores synthetic augmentation and substitution under fixed training regimes. Results indicate that while synthetic data can reduce document-level leakage when used to expand training exposure, it does not safely replace real supervision under fixed training budgets. The study highlights that observed gains are largely due to increased exposure rather than intrinsic advantages of synthetic text.",3.34,71.601,239,cold_start,Phi-4,Apple_M1(Metal)
2601.09757v1_Democracy and Distrust in an Era of Artificial Int.pdf,Democracy & Distrust in an Era of Artificial Intelligence,Sonia K. Katyal,10.1162/DAED_a_01919,,"Artificial Intelligence, Judicial Review, Democracy, Minorities, Due Process, Equal Protection, AI Decision-Making","The essay discusses the challenges posed by AI decision-making to democracy, particularly in protecting minority rights. It explores the rise of privatization, prediction, and automation in AI, and how these trends risk discrimination against minorities. The author proposes a theory of judicial review for AI, analyzing its limitations and possibilities, and suggests integrating concepts of due process and equal protection into AI for better oversight and accountability. The essay also reflects on the metaphor of AI as a mirror of human nature, highlighting the distortions and inaccuracies in comparing humans and machines.",3.3,61.862,204,cold_start,Phi-4,Apple_M1(Metal)
2601.09760v1_Investigating Tool-Memory Conflicts in Tool-Augmen.pdf,Investigating Tool-Memory Conflicts in Tool-Augmented LLMs,"Jiali Cheng, Rui Pan, Hadi Amiri",,,"tool-augmented LLMs, knowledge conflict, Tool-Memory Conflict (TMC), STEM-related tasks, conflict resolving techniques, prompting-based methods, RAG-based methods","Tool-augmented large language models (LLMs) have enhanced problem-solving capabilities by integrating external tools, such as function calling and APIs. However, they may suffer from Tool-Memory Conflicts (TMC), where internal parametric knowledge contradicts external tool knowledge. This paper investigates the conditions under which TMCs appear, whether LLMs prioritize parametric knowledge or tool-generated outputs during conflicts, and evaluates methodologies to resolve these conflicts. The study aims to improve the reliability and interpretability of tool-augmented LLMs by addressing these knowledge integration challenges.",3.23,74.039,239,cold_start,Phi-4,Apple_M1(Metal)
2601.09762v1_Explicating Tacit Regulatory Knowledge from LLMs t.pdf,Explicating Tacit Regulatory Knowledge from LLMs to Auto-Formalize Requirements for Compliance Test Case Generation,"Zhiyi Xue, Xiaohong Chen, Min Zhang",,,"compliance testing, large language models, regulatory knowledge, requirements formalization, test case generation","Compliance testing in highly regulated domains is crucial but largely manual, requiring domain experts to translate complex regulations into executable test cases. This paper proposes RAFT, a framework for requirements auto-formalization and compliance test generation by explicating tacit regulatory knowledge from multiple LLMs. RAFT employs an Adaptive Purification-Aggregation strategy to integrate tacit knowledge into a domain meta-model, a formal requirements representation, and testability constraints. These artifacts guide high-precision requirement formalization and automated test generation. Experiments show RAFT achieves expert-level performance, outperforming state-of-the-art methods while reducing generation and review time.",3.16,75.993,240,cold_start,Phi-4,Apple_M1(Metal)
2601.09765v1_AI Survival Stories a Taxonomic Analysis of AI Exi.pdf,AI SURVIVAL STORIES: A TAXONOMIC ANALYSIS OF AI EXISTENTIAL RISK,"Herman Cappelena, Simon Goldstein",,,"Artificial Intelligence, Existential Risk, AI safety, AI Catastrophe, Superintelligent AI, AI Alignment","This paper develops a framework for evaluating the existential risk posed by AI systems. It analyzes a two-premise argument: AI systems will become extremely powerful, and if they do, they will destroy humanity. The paper constructs a taxonomy of 'survival stories' where humanity survives, identifying scenarios where either scientific barriers prevent AI from becoming extremely powerful, research into AI is banned, powerful AI systems do not destroy humanity due to their goals, or such systems can be detected and disabled. Different survival stories face unique challenges and motivate different responses to AI threats. The paper also provides rough estimates of 'P(doom)', the probability of humanity's destruction by AI.",3.17,69.488,220,cold_start,Phi-4,Apple_M1(Metal)
2601.09768v1_CLiMB A Domain-Informed Novelty Detection Clusteri.pdf,CLiMB: A Domain-Informed Novelty Detection Clustering Framework for Scientific Discovery,"Lorenzo Monti, Tatiana Muraveva, Brian Sheridan, Davide Massari, Alessia Garofalo, Gisella Clementini, Umberto Michelucci",10.5555/2022.23.1-28,2601.09768v1,"novelty detection, semi-supervised clustering, constrained clustering, density-based clustering, domain knowledge integration","In data-driven scientific discovery, a challenge lies in classifying well-characterized phenomena while identifying novel anomalies. Current semi-supervised clustering algorithms do not always fully address this duality, often assuming that supervisory signals are globally representative. Consequently, methods often enforce rigid constraints that suppress unanticipated patterns or require a pre-specified number of clusters, rendering them ineffective for genuine novelty detection. To bridge this gap, we introduce CLiMB (CLustering in Multiphase Boundaries), a domain-informed framework decoupling the exploitation of prior knowledge from the exploration of unknown structures. Using a sequential two-phase approach, CLiMB first anchors known clusters using constrained partitioning, and subsequently applies density-based clustering to residual data to reveal arbitrary topologies. We demonstrate this framework on RR Lyrae stars data from the Gaia Data Release 3. CLiMB attains an Adjusted Rand Index of 0.829 with 90% seed coverage in recovering known Milky Way substructures, drastically outperforming heuristic and constraint-based baselines, which stagnate below 0.20. Furthermore, sensitivity analysis confirms CLiMB’s superior data efficiency, showing monotonic improvement as knowledge increases. Finally, the framework successfully isolates three dynamical features (Shiva, Shakti, and the Galactic Disk) in the unlabelled field, validating its potential for scientific discovery.",3.76,117.705,443,cold_start,Phi-4,Apple_M1(Metal)
2601.09770v1_GUI-Eyes Tool-Augmented Perception for Visual Grou.pdf,GUI-Eyes: Tool-Augmented Perception for Visual Grounding in GUI Agents,"Chen Chen, Jiawei Shao, Dakuan Lu, Haoyi Hu, Xiangcheng Liu, Hantao Yao, Wu Liu",,,"vision-language models, reinforcement learning, GUI automation, active visual perception, tool usage, spatially continuous reward function, ScreenSpot-Pro benchmark","Recent advances in vision-language models (VLMs) and reinforcement learning (RL) have driven progress in GUI automation. However, existing methods often rely on static, one-shot visual inputs and passive perception, lacking adaptability in observing interfaces. This paper introduces GUI-Eyes, a reinforcement learning framework for active visual perception in GUI tasks. The agent learns to make strategic decisions on invoking visual tools like cropping or zooming within a two-stage reasoning process. A progressive perception strategy decomposes decision-making into coarse exploration and fine-grained grounding, coordinated by a two-level policy. A spatially continuous reward function tailored to tool usage integrates location proximity and region overlap to provide dense supervision and alleviate reward sparsity. On the ScreenSpot-Pro benchmark, GUI-Eyes-3B achieves 44.8% grounding accuracy using only 3k labeled samples, outperforming both supervised and RL-based baselines. The results highlight the importance of tool-aware active perception, enabled by staged policy reasoning and fine-grained reward feedback, for building robust and data-efficient GUI agents.",3.42,105.073,359,cold_start,Phi-4,Apple_M1(Metal)
2601.09771v1_PCN-Rec Agentic Proof-Carrying Negotiation for Rel.pdf,PCN-Rec: Agentic Proof-Carrying Negotiation for Reliable Governance-Constrained Recommendation,"Aradhya Dixit, Shreem Dixit",,,"recommendation systems, LLM agents, constrained ranking, governance, verification, negotiation","Modern LLM-based recommenders can generate compelling ranked lists but struggle to reliably satisfy governance constraints such as minimum long-tail exposure or diversity requirements. We present PCN-Rec, a proof-carrying negotiation pipeline that separates natural-language reasoning from deterministic enforcement. A base recommender produces a candidate window, which is negotiated by two agents: a User Advocate optimizing relevance and a Policy Agent enforcing constraints. A mediator LLM synthesizes a Top-N slate with a structured certificate describing the claimed constraint satisfaction. A deterministic verifier recomputes all constraints from the slate and accepts only verifier-checked certificates; if verification fails, a deterministic constrained-greedy repair produces a compliant slate for re-verification, yielding an auditable trace. On MovieLens-100K with governance constraints, PCN-Rec achieves a 98.55% pass rate on feasible users versus a one-shot single-LLM baseline without verification/repair, while preserving utility with only a 0.021 absolute drop in NDCG@10; differences are statistically significant.",3.42,92.405,316,cold_start,Phi-4,Apple_M1(Metal)
2601.09772v1_Antisocial behavior towards large language model u.pdf,Antisocial behavior towards large language model users: experimental evidence,"Paweł Niszczota, Cassandra Grützner",,,,"This study investigates antisocial behavior towards users of large language models through experimental evidence. The research was conducted by Paweł Niszczota and Cassandra Grützner, affiliated with Poznań University of Economics and Business and Martin Luther Universität Halle-Wittenberg, respectively. The study received ethical approval and informed consent from participants, with data and materials available for public access. The research was supported by a grant from the National Science Centre, Poland.",3.31,45.071,149,cold_start,Phi-4,Apple_M1(Metal)
2601.09773v1_Enhancing LUT-based Deep Neural Networks Inference.pdf,Enhancing LUT-based Deep Neural Networks Inference through Architecture and Connectivity Optimization,"Binglei Lou, Ruilin Wu, Philip Leong",,,"Dynamic Sparsity, FPGA, Neural Network, Lookup Table","Deploying deep neural networks (DNNs) on resource-constrained edge devices such as FPGAs requires balancing latency, power, and hardware resource usage while maintaining high accuracy. Existing Lookup Table (LUT)-based DNNs face challenges like exponential LUT size growth and inefficient random sparse connectivity. This paper introduces SparseLUT, a framework addressing these challenges through architectural enhancements and a non-greedy training algorithm. The architectural enhancement aggregates multiple PolyLUT sub-neurons via an adder, reducing LUT consumption by 2.0×–13.9× and lowering inference latency by 1.2×–1.6×, while maintaining accuracy. The training optimization prunes less significant inputs and regrows more effective ones, achieving up to a 2.13% accuracy gain on MNIST and 0.94% on Jet Substructure Classification compared to existing LUT-DNN approaches.",3.27,81.978,268,cold_start,Phi-4,Apple_M1(Metal)
2601.09805v1_Improving Chain-of-Thought for Logical Reasoning v.pdf,Improving Chain-of-Thought for Logical Reasoning via Attention-Aware Intervention,"Phuong Minh Nguyen, Tien Huu Dang, Naoya Inoue",,,"logical reasoning, LLMs, attention-aware intervention, end-to-end framework, attention modulation","Modern logical reasoning with LLMs often relies on complex interactive frameworks or hybrid approaches that depend on external resources. This work introduces a non-interactive, end-to-end framework for reasoning tasks, leveraging structural information in few-shot prompts to activate attention heads aligned with logical reasoning operators. The proposed Attention-Aware Intervention (AAI) method reweights attention scores across selected heads, enhancing logical reasoning performance across diverse benchmarks and architectures with negligible computational overhead. Code is available at https://github.com/phuongnm94/aai_for_logical_reasoning.",3.04,65.388,199,cold_start,Phi-4,Apple_M1(Metal)
2601.09806v1_Diffusion-Driven Deceptive Patches Adversarial Man.pdf,Diffusion-Driven Deceptive Patches: Adversarial Manipulation and Forensic Detection in Facial Identity Verification,"Shahrzad Sayyafzadeh, Hongmei Chi, Shonda Bernadin",,arXiv:2601.09806v1,"Adversarial Patch Generation, Gaussian Smoothing, Diffusion Model, Social Media Forensics, Perceptual Hashing","This work presents an end-to-end pipeline for generating, refining, and evaluating adversarial patches to compromise facial biometric systems with forensic analysis and security testing applications. We utilize a FGSM to generate adversarial noise targeting our classifier for identity detection and employ a diffusion model for reverse diffusion to enhance the imperceptibility with additional Gaussian smoothing and adaptive brightness correction of synthetic adversarial patch evasion generation. The refined patch is applied to facial images to test its ability to evade recognition systems while maintaining natural visual characteristics. A Vision Transformer (ViT)-GPT2 model generates captions to provide a semantic description of a person’s identity for Adv Images, supporting forensic interpretation and documentation for identity evasion attack and recognition. The pipeline evaluates changes in identity classification, captioning results, and the vulnerability of facial identity verification and expression to adversarial attacks. Therefore, detecting and mitigating attacks from these adversaries is necessary in forensic settings using perceptual hashing. We successfully detected and analyzed a series of adversaries generated with 0.95% SSIM.",3.97,85.946,341,cold_start,Phi-4,Apple_M1(Metal)
2601.09809v1_QFed Parameter-Compact Quantum-Classical Federated.pdf,QFed: Parameter-Compact Quantum-Classical Federated Learning,"Samar Abdelghani, Soumaya Cherkaoui",,,"Quantum Computing, Quantum Machine Learning, Federated Learning, Privacy, Communication, IoT","Organizations across various domains need to extract intelligence from distributed datasets while adhering to privacy and regulatory requirements. Federated Learning (FL) allows collaborative model building without sharing raw data but faces challenges from statistical heterogeneity, system diversity, and computational burdens. This study explores quantum-assisted FL, which can reduce the number of parameters in classical models by polylogarithmic factors, thus reducing training overhead. The proposed QFed framework enhances computational efficiency in edge device networks. Using the FashionMNIST dataset, QFed achieves a 77.6% reduction in parameter count for a VGG-like model while maintaining accuracy comparable to classical approaches. This demonstrates the potential of quantum computing in federated learning to enhance the capabilities of edge devices.",3.22,70.086,226,cold_start,Phi-4,Apple_M1(Metal)
2601.09814v1_Explainable Deep Learning for Pediatric Pneumonia .pdf,Explainable Deep Learning for Pediatric Pneumonia Detection in Chest X-Ray Images,"Adil O. Khadidos, Aziida Nanyonga, Alaa O. Khadidos, Olfat M. Mirza, Mustafa Tahsin Yilmaz",,,"pediatric pneumonia detection, chest X-ray images, deep learning, convolutional neural networks, DenseNet121, EfficientNet-B0, Gradient-weighted Class Activation Mapping (Grad-CAM), Local Interpretable Model-agnostic Explanations (LIME)","Pneumonia is a significant cause of illness and death among children globally, necessitating accurate diagnostic tools. This study compares two convolutional neural network architectures, DenseNet121 and EfficientNet-B0, for automated pediatric pneumonia detection using a dataset of 5,863 pediatric chest X-ray images. The models were fine-tuned with pretrained ImageNet weights and evaluated on accuracy, F1-score, Matthews Correlation Coefficient (MCC), and recall. EfficientNet-B0 outperformed DenseNet121 with higher accuracy, F1-score, and MCC. Both models demonstrated high recall, indicating strong sensitivity. Explainability was achieved using Grad-CAM and LIME to visualize decision-contributing regions.",3.71,85.407,317,cold_start,Phi-4,Apple_M1(Metal)
2601.09822v2_LLM-Based Agentic Systems for Software Engineering.pdf,LLM-Based Agentic Systems for Software Engineering: Challenges and Opportunities,"Yongjian Tang, Thomas Runkler",,arXiv:2601.09822v2,"LLMs, Agents, Software Engineering, Future Challenges","Despite recent advancements in Large Language Models (LLMs), complex Software Engineering (SE) tasks require more collaborative and specialized approaches. This concept paper systematically reviews the emerging paradigm of LLM-based multi-agent systems, examining their applications across the Software Development Life Cycle (SDLC), from requirements engineering and code generation to static code checking, testing, and debugging. It delves into a wide range of topics such as language model selection, SE evaluation benchmarks, state-of-the-art agentic frameworks and communication protocols. Furthermore, it identifies key challenges and outlines future research opportunities, with a focus on multi-agent orchestration, human-agent coordination, computational cost optimization, and effective data collection. This work aims to provide researchers and practitioners with valuable insights into the current forefront landscape of agentic systems within the software engineering domain.",3.57,72.062,257,cold_start,Phi-4,Apple_M1(Metal)
2601.09841v2_A pipeline for enabling path-specific causal fairn.pdf,APIPELINE FOR ENABLING PATH-SPECIFIC CAUSAL FAIRNESS IN OBSERVATIONAL HEALTH DATA,"Aparajita Kashyap, Sara Matijevic, Noémie Elhadad, Steven A. Kushner, Shalmali Joshi",,2601.09841v2,"Causal fairness, foundation models, causal inference, observational health data, fair machine learning","When training machine learning (ML) models for potential deployment in a healthcare setting, it is essential to ensure that they do not replicate or exacerbate existing healthcare biases. Although many definitions of fairness exist, this work focuses on path-specific causal fairness, which allows for better consideration of the social and medical contexts in which biases occur. The authors map the structural fairness model to the observational healthcare setting and create a generalizable pipeline for training causally fair models. This pipeline explicitly considers specific healthcare contexts and disparities to define a target 'fair' model. The work addresses two major gaps: expanding on characterizations of the 'fairness-accuracy' tradeoff by detangling direct and indirect sources of bias, and demonstrating how a foundation model trained without fairness constraints on observational health data can be leveraged to generate causally fair downstream predictions in tasks with known social and medical disparities. The work presents a model-agnostic pipeline for training causally fair machine learning models that address both direct and indirect forms of healthcare bias.",3.86,88.955,343,cold_start,Phi-4,Apple_M1(Metal)
2601.09851v1_ViSIL Unified Evaluation of Information Loss in Mu.pdf,ViSIL: Unified Evaluation of Information Loss in Multimodal Video Captioning,"Po-han Li, Shenghui Chen, Ufuk Topcu, Sandeep Chinchali",,,"multimodal video captioning, information loss, ViSIL score, vision-language model, video summarization, Video Question Answering","Multimodal video captioning condenses dense footage into keyframes and natural language, serving as a proxy for efficient retrieval. Traditional metrics like BLEU or ROUGE fail to quantify information coverage across modalities. The proposed Video Summary Information Loss (ViSIL) score quantifies video information not captured by a summary using vision-language model inference. ViSIL enables direct comparison across multimodal summary formats and correlates with human and VLM performance on Video Question Answering tasks. It optimizes the trade-off between information loss and processing speed, outperforming text summaries in VQA accuracy without increasing processing load.",3.3,75.38,249,cold_start,Phi-4,Apple_M1(Metal)
2601.09853v1_MedRedFlag Investigating how LLMs Redirect Misconc.pdf,MedRedFlag: Investigating how LLMs Redirect Misconceptions in Real-World Health Communication,"Sraavya Sambara, Yuan Pu, Ayman Ali, Vishala Mishra, Lionel Wong, Monica Agrawal",,,"LLMs, medical advice, misconceptions, health communication, redirection, patient safety","This study investigates how large language models (LLMs) handle real-world health questions that contain false assumptions or premises. The authors developed a dataset, MedRedFlag, consisting of over 1100 questions from Reddit that require redirection. The study compares responses from LLMs to those from clinicians, revealing that LLMs often fail to properly redirect questions, potentially leading to suboptimal medical decision-making. The findings highlight significant safety concerns for patient-facing medical AI systems.",3.18,71.715,228,cold_start,Phi-4,Apple_M1(Metal)
2601.09855v1_Thinking Long but Short Stable Sequential Test-Tim.pdf,Stable Sequential Test-Time Scaling for Large Reasoning Models,"Michael R. Metel, Yufei Cui, Boxing Chen, Prasanna Parthasarathi",,arXiv:2601.09855v1,"sequential test-time scaling, large reasoning models, model accuracy, chain-of-thought reasoning, test-time scaling, Min-Seek, KV cache, context length, computational complexity","Sequential test-time scaling is a training-free method to enhance the accuracy of large reasoning models by inducing them to think longer. However, extending reasoning length can lead to accuracy degradation and instability. This work introduces Min-Seek, a novel method that stabilizes accuracy across various reasoning tasks without requiring fine-tuning of reasoning length. Min-Seek efficiently manages memory by storing only the key-value pairs of one additional thought in the KV cache, allowing reasoning beyond the model's maximum context length with linear computational complexity.",3.27,75.955,248,cold_start,Phi-4,Apple_M1(Metal)
2601.09858v1_OUTLINEFORGE Hierarchical Reinforcement Learning w.pdf,Hierarchical Reinforcement Learning with Explicit States for Scientific Writing,"Yilin Bao, Ziyao He, Zayden Yang",,,"scientific paper generation, reinforcement learning, hierarchical document structures, scientific correctness, discourse coherence, citation fidelity","Scientific paper generation requires document-level planning and factual grounding, but current large language models often fail in global structure, input coverage, and citation consistency. This paper presents a reinforcement learning framework that casts scientific outline construction as a long-horizon planning problem over hierarchical document structures. The approach models edit evolving outlines through structured actions, enabling the system to incrementally build a complete scientific manuscript. A two-stage optimization procedure is introduced: backward outline reconstruction from partial plans to enforce global structural consistency, and forward value-guided reinforcement learning with rewards explicitly modeling scientific correctness, discourse coherence, and citation fidelity. A benchmark for scientific paper generation is also introduced, evaluating document planning, input utilization, reference faithfulness, outline organization, and content-level factual accuracy. Results show consistent improvements over strong neural and LLM baselines, particularly in long-range structural coherence and citation reliability.",3.37,76.263,257,cold_start,Phi-4,Apple_M1(Metal)
2601.09865v1_Advancing Model Refinement Muon-Optimized Distilla.pdf,Advancing Model Refinement: Muon-Optimized Distillation and Quantization for LLM Deployment,"Jacob Sander, Brian Jalaian, Venkat R. Dasarivenkateswara",,arXiv:2601.09865v1,"Large Language Models, quantization, distillation, model compression, inference optimization, edge devices","Large Language Models (LLMs) enable advanced natural language processing but face deployment challenges on resource-constrained edge devices due to high computational, memory, and energy demands. This paper proposes an integrated framework combining GPTQ-based quantization, low-rank adaptation (LoRA), and a specialized data distillation process to significantly reduce model size and complexity while preserving or enhancing task-specific performance. The framework leverages data distillation, knowledge distillation via Kullback-Leibler divergence, Bayesian hyperparameter optimization, and the Muon optimizer, achieving up to 2× memory compression and enabling efficient inference for specialized tasks. Empirical results demonstrate superior performance on standard LLM benchmarks compared to GPTQ quantization alone, with the Muon optimizer notably enhancing fine-tuned models’ resistance to accuracy decay during quantization.",3.5,84.114,294,cold_start,Phi-4,Apple_M1(Metal)
2601.09869v1_A Scoping Review of the Ethical Perspectives on An.pdf,A SCOPING REVIEW OF THE ETHICAL PERSPECTIVES ON ANTHROPOMORPHISING LARGE LANGUAGE MODEL-BASED CONVERSATIONAL AGENTS,"Andrea Ferrario, Rasita Vinay, Matteo Casserini, Alessandro Facchini",,2601.09869v1,"anthropomorphism, conversational agents, large language models, AI ethics, deception, trust, governance","Anthropomorphisation—the phenomenon whereby non-human entities are ascribed human-like qualities—has become increasingly salient with the rise of large language model (LLM)-based conversational agents (CAs). Unlike earlier chatbots, LLM-based CAs routinely generate interactional and linguistic cues, such as first-person self-reference, epistemic and affective expressions that empirical work shows can increase engagement. On the other hand, anthropomorphisation raises ethical concerns, including deception, overreliance, and exploitative relationship framing, while some authors argue that anthropomorphic interaction may support autonomy, well-being, and inclusion. Despite increasing interest in the phenomenon, literature remains fragmented across domains and varies substantially in how it defines, operationalizes, and normatively evaluates anthropomorphisation. This scoping review maps ethically oriented work on anthropomorphising LLM-based CAs across five databases and three preprint repositories. We synthesize (1) conceptual foundations, (2) ethical challenges and opportunities, and (3) methodological approaches. We find convergence on attribution-based definitions but substantial divergence in operationalization, a predominantly risk-forward normative framing, and limited empirical work that links observed interaction effects to actionable governance guidance. We conclude with a research agenda and design/governance recommendations for ethically deploying anthropomorphic cues in LLM-based conversational agents.",3.69,115.611,427,cold_start,Phi-4,Apple_M1(Metal)
2601.09871v1_Epistemology gives a Future to Complementarity in .pdf,EPISTEMOLOGY GIVES A FUTURE TO COMPLEMENTARITY IN HUMAN-AI INTERACTIONS,"Andrea Ferrario, Alessandro Facchini, Juan M. Durán",,2601.09871v1,"artificial intelligence, machine learning, reliance, complementarity, human-AI interaction, computational reliabilism, epistemology","Human-AI complementarity is the claim that a human supported by an AI system can outperform either alone in a decision-making process. This concept has gained traction by generalizing the reliance paradigm and offering a practical alternative to 'trust in AI.' However, it faces theoretical challenges such as lack of precise theoretical anchoring and being formalized as a post hoc indicator of relative predictive accuracy. This work leverages epistemology to address these challenges by reframing complementarity within the discourse on justificatory AI. Drawing on computational reliabilism, it argues that historical instances of complementarity function as evidence that a given human-AI interaction is a reliable epistemic process for a predictive task. Complementarity, along with other reliability indicators, contributes to the degree of reliability of human-AI teams in generating predictions, supporting practical reasoning for those affected by these outputs. The role and value of complementarity lie in helping calibrate decision-making to the reliability of AI-supported processes that increasingly shape everyday life.",3.52,96.254,339,cold_start,Phi-4,Apple_M1(Metal)
2601.09879v1_MedVL-SAM2 A unified 3D medical vision-language mo.pdf,MedVL-SAM2: A unified 3D medical vision–language model for multimodal reasoning and prompt-driven segmentation,"Yang Xing, Jiong Wu, Savas Ozdemir, Ying Zhang, Yang Yang, Wei Shao, Kuang Gong",,,"3D medical vision–language model, multimodal reasoning, prompt-driven segmentation, report generation, visual question answering, semantic segmentation, referring segmentation, interactive segmentation, 3D medical imaging","Recent progress in medical vision–language models (VLMs) has achieved strong performance on image-level text-centric tasks such as report generation and visual question answering (VQA). However, achieving fine-grained visual grounding and volumetric spatial reasoning in 3D medical VLMs remains challenging, particularly when aiming to unify these capabilities within a single, generalizable framework. To address this challenge, we proposed MedVL-SAM2, a unified 3D medical multimodal model that concurrently supports report generation, VQA, and multiparadigm segmentation, including semantic, referring, and interactive segmentation. MedVL-SAM2 integrates image-level reasoning and pixel-level perception through a cohesive architecture tailored for 3D medical imaging, and incorporates a SAM2-based volumetric segmentation module to enable precise multi-granular spatial reasoning. The model is trained in a multi-stage pipeline: it is first pretrained on a large-scale corpus of 3D CT image–text pairs to align volumetric visual features with radiology-language embeddings. It is then jointly optimized with both language-understanding and segmentation objectives using a comprehensive 3D CT segmentation dataset. This joint training enables flexible interaction via language, point, or box prompts, thereby unifying high-level visual reasoning with spatially precise localization. Our unified architecture delivers state-of-the-art performance across report generation, VQA, and multiple 3D segmentation tasks. Extensive analyses further show that the model provides reliable 3D visual grounding, controllable interactive segmentation, and robust cross-modal reasoning, demonstrating that high-level semantic reasoning and precise 3D localization can be achieved.",3.74,130.71,489,cold_start,Phi-4,Apple_M1(Metal)
2601.09881v1_Transition Matching Distillation for Fast Video Ge.pdf,Transition Matching Distillation for Fast Video Generation,"Weili Nie, Julius Berner, Nanye Ma, Chao Liu, Saining Xie, Arash Vahdat",,arXiv:2601.09881v1,"video generation, diffusion models, flow models, distillation, real-time applications","Large video diffusion and flow models have achieved remarkable success in high-quality video generation, but their use in real-time interactive applications remains limited due to their inefficient multi-step sampling process. In this work, we present Transition Matching Distillation (TMD), a novel framework for distilling video diffusion models into efficient few-step generators. The central idea of TMD is to match the multi-step denoising trajectory of a diffusion model with a few-step probability transition process, where each transition is modeled as a lightweight conditional flow. To enable efficient distillation, we decompose the original diffusion backbone into two components: (1) a main backbone, comprising the majority of early layers, that extracts semantic representations at each outer transition step; and (2) a flow head, consisting of the last few layers, that leverages these representations to perform multiple inner flow updates. Given a pretrained video diffusion model, we first introduce a flow head to the model, and adapt it into a conditional flow map. We then apply distribution matching distillation to the student model with flow head rollout in each transition step. Extensive experiments on distilling Wan2.1 1.3B and 14B text-to-video models demonstrate that TMD provides a flexible and strong trade-off between generation speed and visual quality. In particular, TMD outperforms existing distilled models under comparable inference costs in terms of visual fidelity and prompt adherence.",4.06,100.464,408,cold_start,Phi-4,Apple_M1(Metal)
2601.09883v1_Beyond Rule-Based Workflows An Information-Flow-Or.pdf,Beyond Rule-Based Workflows: An Information-Flow-Orchestrated Multi-Agents Paradigm via Agent-to-Agent Communication from CORAL,"Xinxing Ren, Quagmire Zang, Caelum Forder, Suman Deb, Ahsen Tahir, Roman J. Georgio, Peter Carroll, Zekun Guo",,,"Large Language Model, Multi-Agent Systems, Information-Flow-Orchestrated, Agent-to-Agent Communication, CORAL, GAIA, OWL, workflow-based MAS","Most existing Large Language Model (LLM)-based Multi-Agent Systems (MAS) rely on predefined workflows, which suffer from limitations such as substantial manual effort and inability to cover complex real-world task states. This paper proposes an Information-Flow-Orchestrated Multi-Agent Paradigm via Agent-to-Agent (A2A) Communication from CORAL, which uses a dedicated orchestrator to dynamically coordinate agents through natural language without predefined workflows. The approach is evaluated on the GAIA benchmark, outperforming the workflow-based MAS OWL by 8.49 percentage points in accuracy under the pass@1 setting. The implementation is publicly available.",3.42,89.292,305,cold_start,Phi-4,Apple_M1(Metal)
2601.09896v1_The Algorithmic Gaze An Audit and Ethnography of t.pdf,The Algorithmic Gaze: An Audit and Ethnography of the LAION-Aesthetics Predictor Model,"JORDAN TAYLOR, WILLIAM AGNEW, MAARTEN SAP, SARAH E. FOX, HAIYI ZHU",10.1145/nnnnnnn.nnnnnnn,,"AI, Art, Aesthetic Evaluation, Human-centered computing, Empirical studies in HCI","This paper examines the LAION Aesthetic Predictor (LAP), a model used to curate datasets for training visual generative image models. The study audits LAP across three datasets, revealing biases such as disproportionate filtering of images with captions mentioning women and underrepresentation of men and LGBTQ+ individuals. The model's preference for western and Japanese art styles suggests reinforcement of historical biases. A digital ethnography of LAP's development materials indicates that these biases stem from the predominantly English-speaking and western backgrounds of its creators. The authors call for a shift from prescriptive aesthetic measures to more inclusive evaluations to mitigate representational harms.",3.28,81.043,266,cold_start,Phi-4,Apple_M1(Metal)
2601.09902v1_A Novel Contrastive Loss for Zero-Day Network Intr.pdf,A Novel Contrastive Loss for Zero-Day Network Intrusion Detection,"Jack Wilkie, Hanan Hindy, Craig Michie, Christos Tachtatzis, James Irvine, Robert Atkinson",,,"Internet of Things, Network Intrusion Detection, Machine Learning, Contrastive Learning","Machine learning has achieved state-of-the-art results in network intrusion detection, but its performance degrades with zero-day attacks. Classical machine learning approaches struggle with new attack classes not included in their training data. Anomaly detectors, which train exclusively on benign data, can generalize to all attack classes but have high false positive rates. This work proposes a novel contrastive loss function that maintains robustness to imbalanced data and generalizes to zero-day attacks. Unlike anomaly detectors, this model learns the distributions of benign traffic using both benign and known malign samples, achieving significant performance improvements. The approach is verified on the Lycos2017 dataset, showing AUROC improvements over previous models in known and zero-day attack detection. The method is extended to open-set recognition, achieving OpenAUC improvements over existing approaches.",3.43,80.115,275,cold_start,Phi-4,Apple_M1(Metal)
2601.09913v1_Continuum Memory Architectures for Long-Horizon LL.pdf,Continuum Memory Architectures for Long-Horizon LLM Agents,"Joe Logan, Mode7 GK",,2601.09913v1,"Retrieval-augmented generation, large language model, Continuum Memory Architecture, memory dynamics, cognitive science, memory systems","Retrieval-augmented generation (RAG) is the default strategy for providing large language model (LLM) agents with contextual knowledge, treating memory as a stateless lookup table. This paper introduces the Continuum Memory Architecture (CMA), which maintains and updates internal state across interactions through persistent storage, selective retention, associative routing, temporal chaining, and consolidation into higher-order abstractions. CMA addresses the limitations of RAG by enabling memory accumulation, mutation, and disambiguation. Preliminary evaluations show CMA's advantages in tasks requiring dynamic memory, while also highlighting challenges such as latency, drift, and interpretability. The paper argues for CMA as a necessary abstraction for LLM agents operating over extended time horizons, drawing on cognitive science to inform its design.",3.45,73.691,254,cold_start,Phi-4,Apple_M1(Metal)
2601.09921v1_Learning to Decode in Parallel Self-Coordinating N.pdf,Learning to Decode in Parallel: Self-Coordinating Neural Network for Real-Time Quantum Error Correction,"Kai Zhang, Zhengzhong Yi, Shaojun Guo, Linghang Kong, Situ Wang, Xiaoyu Zhan, Tan He, Weiping Lin, Tao Jiang, Dongxin Gao, Yiming Zhang, Fangming Liu, Fang Zhang, Zhengfeng Ji, Fusheng Chen, Jianxin Chen",,2601.09921v1,"quantum error correction, neural network decoders, fault-tolerant quantum computation, AlphaQubit","Fast, reliable decoders are pivotal components for enabling fault-tolerant quantum computation. Neural network decoders like AlphaQubit have demonstrated significant potential, achieving higher accuracy than traditional human-designed decoding algorithms. However, existing implementations of neural network decoders face challenges in real-time applications.",3.81,68.513,261,cold_start,Phi-4,Apple_M1(Metal)
2601.09923v1_CaMeLs Can Use Computers Too System-level Security.pdf,SYSTEM-LEVEL SECURITY FOR COMPUTER USE AGENTS,"Hanna Foerster, Robert Mullins, Tom Blanchard, Nicolas Papernot, Kristina Nikolić, Florian Tramèr, Ilia Shumailov, Cheng Zhang, Yiren Zhao",,arXiv:2601.09923v1,"AI agents, prompt injection attacks, architectural isolation, Computer Use Agents (CUAs), Single-Shot Planning, control flow integrity, Branch Steering attacks, Vision-Language Model (VLM), Dual-LLM paradigm, Privileged Planner, Quarantined Perception model","AI agents are vulnerable to prompt injection attacks, where malicious content hijacks agent behavior to steal credentials or cause financial loss. The only known robust defense is architectural isolation that strictly separates trusted task planning from untrusted environment observations. However, applying this design to Computer Use Agents (CUAs) – systems that automate tasks by viewing screens and executing actions – presents a fundamental challenge: current agents require continuous observation of UI state to determine each action, conflicting with the isolation required for security. We resolve this tension by demonstrating that UI workflows, while dynamic, are structurally predictable. We introduce Single-Shot Planning for CUAs, where a trusted planner generates a complete execution graph with conditional branches before any observation of potentially malicious content, providing provable control flow integrity guarantees against arbitrary instruction injections. Although this architectural isolation successfully prevents instruction injections, we show that additional measures are needed to prevent Branch Steering attacks, which manipulate UI elements to trigger unintended valid paths within the plan. We evaluate our design on OSWorld, and retain up to 57% of the performance of frontier models while improving performance for smaller open-source models by up to 19%, demonstrating that rigorous security and utility can coexist in CUAs.",3.85,114.942,442,cold_start,Phi-4,Apple_M1(Metal)
2601.09929v1_Hallucination Detection and Mitigation in Large La.pdf,Hallucination Detection and Mitigation in Large Language Models,"Ahmad Pesaranghader, Erin Li",,2601.09929v1,"Large Language Models, hallucination detection, mitigation, finance, law, LLMs, LRMs, uncertainty estimation, reasoning consistency, knowledge grounding, confidence calibration","Large Language Models (LLMs) and Large Reasoning Models (LRMs) offer transformative potential for high-stakes domains like finance and law, but their tendency to hallucinate, generating factually incorrect or unsupported content, poses a critical reliability risk. This paper introduces a comprehensive operational framework for hallucination management, built on a continuous improvement cycle driven by root cause awareness. We categorize hallucination sources into model, data, and context-related factors, allowing targeted interventions over generic fixes. The framework integrates multi-faceted detection methods (e.g., uncertainty estimation, reasoning consistency) with stratified mitigation strategies (e.g., knowledge grounding, confidence calibration). We demonstrate its application through a tiered architecture and a financial data extraction case study, where model, context, and data tiers form a closed feedback loop for progressive reliability enhancement. This approach provides a systematic, scalable methodology for building trustworthy generative AI systems in regulated environments.",3.49,85.459,298,cold_start,Phi-4,Apple_M1(Metal)
2601.09933v1_Malware Classification using Diluted Convolutional.pdf,Malware Classification using Diluted Convolutional Neural Network with Fast Gradient Sign Method,"Ashish Anand, Bhupendra Singh, Sunil Khemka, Bireswar Banerjee, Vishi Singh Bhatia, Piyush Ranjan",,,"data security, diluted convolutional neural network, fast gradient sign method, malware classification, privacy","Android malware has become a critical threat to organizations, society, and individuals, posing significant risks to privacy, data security, and infrastructure. As malware evolves in complexity and sophistication, its mitigation and detection have become more challenging, particularly due to the need for a large number of features to identify potential malware. This research proposes the Fast Gradient Sign Method with Diluted Convolutional Neural Network (FGSM-DICNN) for malware classification. DICNN contains diluted convolutions, which increase the receptive field, enabling the model to capture dispersed malware patterns across long ranges using fewer features without adding parameters. Additionally, the FGSM strategy enhances accuracy by using one-step perturbations during training, providing a defensive advantage with lower computational cost. This integration helps manage high classification accuracy while reducing dependence on extensive feature sets. The proposed FGSM-DICNN model attains 99.44% accuracy while outperforming other existing approaches such as Custom Deep Neural Network (DCNN).",3.5,94.398,330,cold_start,Phi-4,Apple_M1(Metal)
2601.09949v2_Kinematic Tokenization Optimization-Based Continuo.pdf,Kinematic Tokenization: Optimization-Based Continuous-Time Tokens for Learnable Decision Policies in Noisy Time Series,"Griffin M. Kearney, Ph.D.",,arXiv:2601.09949v2,"Transformers, continuous-time tokens, noisy time series, financial time series, risk-averse classification, kinematic consistency, physics-informed AI, optimization-based data enrichment","Transformers are designed for discrete tokens, yet many real-world signals are continuous processes observed through noisy sampling. Discrete tokenizations can be brittle in low signal-to-noise regimes, especially when downstream objectives impose asymmetric penalties that encourage abstention. This paper introduces Kinematic Tokenization, an optimization-based continuous-time representation that reconstructs an explicit spline from noisy measurements and tokenizes local spline coefficients (position, velocity, acceleration, jerk). Applied to financial time series data, this method sustains calibrated, non-trivial action distributions and stable policies under a risk-averse asymmetric classification objective, suggesting that explicit continuous-time tokens can improve the learnability and calibration of selective decision policies in noisy time series under abstention-inducing losses.",3.66,76.201,279,cold_start,Phi-4,Apple_M1(Metal)
2601.09966v1_A Sustainable AI Economy Needs Data Deals That Wor.pdf,A Sustainable AI Economy Needs Data Deals That Work for Generators,"Ruoxi Jia, Luis Oala, Wenjie Xiong, Suqin Ge, Jiachen T. Wang, Feiyang Kang, Dawn Song",,2601.09966v1,"machine learning, data economy, data deals, data generators, economic equity, value chain, data aggregation, AI products, data commodification, value distribution, data monetization","The paper argues that the machine learning value chain is structurally unsustainable due to an economic data processing inequality, where each state in the data cycle from inputs to model weights to synthetic outputs refines technical signal but strips economic equity from data generators. By analyzing seventy-three public data deals, it is shown that the majority of value accrues to aggregators, with creator royalties often rounding to zero and widespread opacity of deal terms. This poses an economic welfare concern as data and its derivatives become economic assets, risking the feedback loop that sustains current learning algorithms. The paper identifies three structural faults—missing provenance, asymmetric bargaining power, and non-dynamic pricing—as the operational machinery of this inequality. It proposes an Equitable Data-Value Exchange (EDVEX) Framework to enable a minimal market that benefits all participants and outlines research directions for the community to contribute to data deals.",3.64,94.387,344,cold_start,Phi-4,Apple_M1(Metal)
2601.09972v1_Chinese Labor Law Large Language Model Benchmark.pdf,Chinese Labor Law Large Language Model Benchmark,"Zixun Lan, Maochun Xu, Yifan Ren, Rui Wu, Jianghui Zhou, Xueyang Cheng, Jian’an Ding, Xinheng Wang, Mingmin Chi, Fei Ma",,,"Chinese labor law, legal natural language processing, large language models, domain-specific fine-tuning, benchmark dataset, statute recall, legal reasoning, case analysis","Recent advancements in large language models (LLMs) have led to significant progress in domain-specific applications, particularly within the legal domain. While general-purpose models like GPT-4 show promise in basic legal tasks, they often struggle with specialized subdomains requiring precise legal knowledge, complex reasoning, and contextual sensitivity. This paper introduces LaborLawLLM, a legal large language model tailored to the labor law domain, characterized by intricate statutory structures, frequent disputes, and high real-world impact. We present LaborLawBench, a comprehensive benchmark comprising diverse labor law tasks such as legal provision citation, knowledge-based question answering, case classification, compensation computation, named entity recognition, and legal case analysis. Our evaluation framework integrates both objective metrics (e.g., ROUGE-L, accuracy, F1, soft-F1) and subjective assessments based on GPT-4 scoring. Experimental results demonstrate that LaborLawLLM significantly outperforms both general-purpose and existing legal-specific LLMs across all task categories. This work fills a key research gap in labor law-specific legal AI and offers a scalable methodology for developing specialized LLMs in other legal subfields, enhancing the accuracy, reliability, and societal value of legal AI applications.",3.73,109.228,407,cold_start,Phi-4,Apple_M1(Metal)
2601.09974v1_SPRInG Continual LLM Personalization via Selective.pdf,SPRInG: Continual LLM Personalization via Selective Parametric Adaptation and Retrieval-Interpolated Generation,"Seoyeon Kim, Jaehyung Kim",,,"Large Language Models, personalization, continual learning, parametric adaptation, retrieval-interpolated generation, preference drift, catastrophic forgetting","Personalizing Large Language Models (LLMs) typically relies on static retrieval or one-time adaptation, assuming user preferences remain invariant over time. However, real-world interactions are dynamic, with user interests continuously evolving, posing a challenge for models to adapt to preference drift without catastrophic forgetting. Standard continual learning approaches often struggle in this context, as they indiscriminately update on noisy interaction streams, failing to distinguish genuine preference shifts from transient contexts. To address this, we introduce SPRING, a novel semi-parametric framework designed for effective continual personalization. During training, SPRING employs drift-driven selective adaptation, which utilizes a likelihood-based scoring function to identify high-novelty interactions. This allows the model to selectively update the user-specific adapter on drift signals while preserving hard-to-learn residuals in a replay buffer. During inference, we apply strict relevance gating and fuse parametric knowledge with retrieved history via logit interpolation. Experiments on the long-form personalized generation benchmark demonstrate that SPRING outperforms existing baselines, validating its robustness for real-world continual personalization.",3.06,110.775,339,cold_start,Phi-4,Apple_M1(Metal)
2601.09980v1_Performance of AI agents based on reasoning langua.pdf,ALD Optimization Using Reasoning LLMs,Angel Yanguas-Gil,,,"ALD optimization, reasoning language models, AI agents, atomic layer deposition, self-limited processes, unsupervised learning","This study investigates the use of reasoning large language models (LLMs) to autonomously optimize atomic layer deposition (ALD) processes. The research focuses on an AI agent's ability to determine optimal dose times for ALD precursors and coreactants without prior knowledge of the process. The agent interacts iteratively with an ALD reactor in an unsupervised manner. The study evaluates the agent's performance using a model of an ALD tool with various self-limited and non-self-limited reaction pathways. Results indicate that reasoning models like OpenAI’s o3 and GPT5 can successfully complete the optimization task, although there is significant variability in performance due to the non-deterministic nature of the models. The agent employs a two-step process to generate and structure reasoning responses, revealing sound logic based on ALD principles. However, the agent may be influenced by its prior choices during optimization. The work highlights the potential and challenges of applying reasoning LLMs in thin film growth and other physical sciences.",3.37,88.229,297,cold_start,Phi-4,Apple_M1(Metal)
2601.09982v1_Context Volume Drives Performance Tackling Domain .pdf,Volume Drives Performance: Tackling Domain Shift in Extremely Low-Resource Translation via RAG,"David Samuel Setiawan, Raphaël Merx, Jey Han Lau",,,"Neural Machine Translation, low-resource languages, domain shift, Dhao, Large Language Model, Retrieval-Augmented Generation, RAG, domain adaptation","Neural Machine Translation (NMT) models for low-resource languages suffer significant performance degradation under domain shift. This study quantifies the challenge using Dhao, an indigenous language of Eastern Indonesia, and demonstrates a hybrid framework combining a fine-tuned NMT model with a Large Language Model (LLM) using Retrieval-Augmented Generation (RAG) to refine translations. The approach achieves performance recovery, effectively matching the original in-domain quality, primarily driven by the number of retrieved examples rather than the retrieval algorithm. The LLM acts as a robust 'safety net,' repairing severe failures in zero-shot domains.",3.09,81.755,253,cold_start,Phi-4,Apple_M1(Metal)
2601.10010v1_VERHallu Evaluating and Mitigating Event Relation .pdf,VERHallu: Evaluating and Mitigating Event Relation Hallucination in Video Large Language Models,"Zefan Zhang, Kehua Zhu, Shijie Jiang, Hongyuan Lu, Shengkai Sun, Tian Bai",,,"Video Large Language Models, Event Relation Understanding, Video Understanding, Event Relation Hallucination, Key-Frame Propagating, Multimodal Large Language Models","Video Large Language Models (VideoLLMs) exhibit various types of hallucinations, with existing research focusing on hallucinations involving events, objects, and scenes. This paper introduces a novel benchmark, VERHallu, for evaluating Video Event Relation Hallucination, focusing on causal, temporal, and subevent relations. It includes tasks like relation classification, question answering, and counterfactual question answering. The analysis shows that current VideoLLMs struggle with dense-event relation reasoning and often rely on prior knowledge. A Key-Frame Propagating (KFP) strategy is proposed to enhance multi-event understanding, effectively mitigating event relation hallucination without affecting inference speed.",3.37,82.258,277,cold_start,Phi-4,Apple_M1(Metal)
2601.10011v1_Memo-SQL Structured Decomposition and Experience-D.pdf,Memo-SQL: Structured Decomposition and Experience-Driven Self-Correction for Training-Free NL2SQL,"Zerui Yang, Weichuan Wang, Yanwei Xu, Linqi Song, Yudai Matsuda, Wei Han, Bo Bai",,,"NL2SQL, structured decomposition, self-correction, training-free, test-time scaling, dynamic memory, retrieval-augmented prompting","Existing NL2SQL systems face limitations such as reliance on in-context learning with only correct examples and inefficiencies in test-time scaling approaches. Memo-SQL, a training-free framework, addresses these issues through structured decomposition and experience-aware self-correction. It employs strategies like entity-wise, hierarchical, and atomic sequential decomposition to encourage diverse reasoning. For correction, it builds a dynamic memory of successful queries and historical error-fix pairs, using retrieval-augmented prompting to refine outputs without fine-tuning or external APIs. Memo-SQL achieves 68.5% execution accuracy on BIRD, setting a new state of the art among open, zero-fine-tuning methods, while using over 10× fewer resources than prior TTS approaches.",3.38,87.927,297,cold_start,Phi-4,Apple_M1(Metal)
2601.10018v1_Empowering Older Adults in Digital Technology Use .pdf,Empowering Older Adults in Digital Technology Use with Foundation Models,"Hasti Sharifi, Homaira Huda Shomee, Sourav Medya, Debaleena Chattopadhyay",,,"Technology support, Digital technology use, Artificial intelligence, Large language models, Communication barriers, Human-computer interaction","This study examines communication challenges faced by older adults in using digital applications due to unfamiliarity with technical terminology and age-related cognitive changes. It explores AI-based approaches, particularly foundation models, to mitigate these challenges. A diary study was conducted to collect technology-related queries from older adults, identifying key communication barriers such as verbosity, incompleteness, over-specification, and under-specification. The study evaluated the use of large language models like GPT-4o to paraphrase queries and improve solution accuracy. Results showed significant improvements in solution accuracy and understanding when using AI-rephrased queries. The study also developed the OATS dataset, demonstrating strong fidelity and face validity, and highlights the potential of foundation models to enhance technology support for older adults.",3.48,77.778,271,cold_start,Phi-4,Apple_M1(Metal)
2601.10025v1_Structured Personality Control and Adaptation for .pdf,Structured Personality Control and Adaptation for LLM Agents,"JINPENG WANG, XINYU JIA, WEI WEI HENG, YUQUAN LI, BINBIN SHI, QIANLEI CHEN, GUANNAN CHEN, JUNXIA ZHANG, YUYU YIN",https://doi.org/XXXXXXX.XXXXXXX,,"Personalization, Jungian Psychological Types, MBTI Personality Types, Persona Adaptation, Explainable AI","Large Language Models (LLMs) are increasingly shaping human–computer interaction (HCI), from personalized assistants to social simulations. Beyond language competence, researchers are exploring whether LLMs can exhibit human-like characteristics that influence engagement, decision-making, and perceived realism. Personality, in particular, is critical, yet existing approaches often struggle to achieve both nuanced and adaptable expression. We present a framework that models LLM personality via Jungian psychological types, integrating three mechanisms: a dominant–auxiliary coordination mechanism for coherent core expression, a reinforcement–compensation mechanism for temporary adaptation to context, and a reflection mechanism that drives long-term personality evolution. This design allows the agent to maintain nuanced traits while dynamically adjusting to interaction demands and gradually updating its underlying structure. Personality alignment is evaluated using Myers–Briggs Type Indicator questionnaires and tested under diverse challenge scenarios as a preliminary structured assessment. Findings suggest that evolving, personality-aware LLMs can support coherent, context-sensitive interactions, enabling naturalistic agent design in HCI.",3.56,103.76,369,cold_start,Phi-4,Apple_M1(Metal)
2601.10029v1_PaperScout An Autonomous Agent for Academic Paper .pdf,PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization,"Tingyue Pan, Jie Ouyang, Mingyue Cheng, Qingchuan Li, Zirui Liu, Mingfan Pan, Shuo Yu, Qi Liu",,,"academic paper search, sequential decision-making, reinforcement learning, sequence-level policy optimization, large language models","Academic paper search is a fundamental task in scientific research, yet most existing approaches rely on rigid, predefined workflows that struggle with complex, conditional queries. To address this limitation, we propose PaperScout, an autonomous agent that reformulates paper search as a sequential decision-making process. Unlike static workflows, PaperScout dynamically decides whether, when, and how to invoke search and expand tools based on accumulated retrieval context. We introduce Proximal Sequence Policy Optimization (PSPO), a process-aware, sequence-level policy optimization method that aligns optimization with agent–environment interaction. Comprehensive experiments on both synthetic and real-world benchmarks demonstrate that PaperScout significantly outperforms strong workflow-driven and RL baselines in both recall and relevance, validating the effectiveness of our adaptive agentic framework and optimization strategy.",3.42,89.116,305,cold_start,Phi-4,Apple_M1(Metal)
2601.10031v1_FilDeep Learning Large Deformations of Elastic-Pla.pdf,FilDeep: Learning Large Deformations of Elastic-Plastic Solids with Multi-Fidelity Data,"Jianheng Tang, Shilong Tao, Zhe Feng, Haonan Sun, Menglu Wang, Zhanxing Zhu, Yunhuai Liu",10.1145/3770854.3783959,,"Large Deformations, Elastic-Plastic Solids, Multi-Fidelity Data, Deep Learning, Quantity-Accuracy Dilemma","The scientific computation of large deformations in elastic-plastic solids is crucial in various manufacturing applications. Traditional numerical methods exhibit several inherent limitations, prompting Deep Learning (DL) as a promising alternative. The effectiveness of current DL techniques typically depends on the availability of high-quantity and high-accuracy datasets, which are yet difficult to obtain in large deformation problems. During the dataset construction process, a dilemma stands between data quantity and data accuracy, leading to suboptimal performance in the DL models. To address this challenge, we focus on a representative application of large deformations, the stretch bending problem, and propose FilDeep, a Fidelity-based Deep Learning framework for large Deformation of elastic-plastic solids. Our FilDeep aims to resolve the quantity-accuracy dilemma by simultaneously training with both low-fidelity and high-fidelity data, where the former provides greater quantity but lower accuracy, while the latter offers higher accuracy but in less quantity. In FilDeep, we provide meticulous designs for the practical large deformation problem. Particularly, we propose attention-enabled cross-fidelity modules to effectively capture long-range physical interactions across MF data. To the best of our knowledge, our FilDeep presents the first DL framework for large deformation problems using MF data. Extensive experiments demonstrate that our FilDeep consistently achieves state-of-the-art performance and can be efficiently deployed in manufacturing.",3.64,117.837,429,cold_start,Phi-4,Apple_M1(Metal)
2601.10038v1_What Understanding Means in AI-Laden Astronomy.pdf,What Understanding Means in AI-Laden Astronomy,"Yuan-Sen Ting, André Curtis-Trudel, Siyu Yao",,2601.10038v1,"artificial intelligence, astronomy, philosophy of science, understanding, discovery, knowledge generation","As artificial intelligence rapidly transforms astronomical research, scientists are beginning to confront fundamental questions about the nature of discovery, the meaning of progress, and the essence of understanding. This paper discusses the convergence of concerns between astronomy and philosophy of science, emphasizing the need for philosophical insights in evaluating AI's role in scientific research. It highlights the importance of conceptual engineering, critical examination of assumptions, and frameworks for abstraction in navigating the transformation brought by AI. The paper draws on discussions from an interdisciplinary workshop titled 'Philosophy Sees the Algorithm,' which focused on the understanding of science in the context of AI.",3.2,72.184,231,cold_start,Phi-4,Apple_M1(Metal)
2601.10061v1_CoF-T2I Video Models as Pure Visual Reasoners for .pdf,ERROR,ERROR,ERROR,ERROR,ERROR,'utf-8' codec can't encode character '\ud835' in position 2471: surrogates not allowed,0.0,0.0,0,cold_start,Phi-4,Apple_M1(Metal)
2601.10073v1_ReaMIL Reasoning- and Evidence-Aware Multiple Inst.pdf,ReaMIL: Reasoning- and Evidence-Aware Multiple Instance Learning for Whole-Slide Histopathology,"Hyun Do Jung, Jungwon Choi, Hwiyoung Kim",,,"multiple instance learning, whole-slide histopathology, reasoning, evidence-aware, sparsity budget, TCGA-NSCLC, TCGA-BRCA, PANDA, AUC, evidence-efficiency diagnostics, slide-level overlays","We introduce ReaMIL (Reasoning- and Evidence-Aware MIL), a multiple instance learning approach for whole-slide histopathology that adds a light selection head to a strong MIL backbone. The head produces soft per-tile gates and is trained with a budgeted-sufficiency objective: a hinge loss that enforces the true-class probability to be ≥τ using only the kept evidence, under a sparsity budget on the number of selected tiles. The budgeted-sufficiency objective yields small, spatially compact evidence sets without sacrificing baseline performance. Across TCGA-NSCLC (LUAD vs. LUSC), TCGA-BRCA (IDC vs. Others), and PANDA, ReaMIL matches or slightly improves baseline AUC and provides quantitative evidence-efficiency diagnostics. On NSCLC, it attains AUC 0.983 with a mean minimal sufficient K (MSK) ≈ 8.2 tiles at τ= 0.90 and AUKC ≈ 0.864, showing that class confidence rises sharply and stabilizes once a small set of tiles is kept. The method requires no extra supervision, integrates seamlessly with standard MIL training, and naturally yields slide-level overlays. We report accuracy alongside MSK, AUKC, and contiguity for rigorous evaluation of model behavior on WSIs.",3.5,115.969,406,cold_start,Phi-4,Apple_M1(Metal)
2601.10079v1_Sparse-RL Breaking the Memory Wall in LLM Reinforc.pdf,Sparse-RL: Breaking the Memory Wall in LLM Reinforcement Learning via Stable Sparse Rollouts,"Sijia Luo, Xiaokang Zhang, Yuxuan Hu, Bohan Zhang, Ke Wang, Jinbo Su, Mengshu Sun, Lei Liang, Jing Zhang",,,"Reinforcement Learning, Large Language Models, Memory Overhead, Key-Value Caches, Sparse Rollouts, Policy Mismatch, Sparsity-Aware Rejection Sampling, Importance-based Reweighting, Model Robustness","Reinforcement Learning (RL) is crucial for enhancing the reasoning capabilities of Large Language Models (LLMs). However, the significant memory overhead from storing Key-Value (KV) caches during long-horizon rollouts limits efficient training on constrained hardware. Existing KV compression techniques, while useful for inference, cause policy mismatches and performance issues when applied to RL training. This paper introduces Sparse-RL, which facilitates stable RL training with sparse rollouts. Sparse-RL addresses policy mismatches through Sparsity-Aware Rejection Sampling and Importance-based Reweighting, correcting off-policy biases from compression-induced information loss. Experimental results demonstrate that Sparse-RL reduces rollout overhead compared to dense baselines while maintaining performance and enhancing model robustness during sparse inference deployment.",3.55,94.341,335,cold_start,Phi-4,Apple_M1(Metal)
2601.10088v1_State of AI An Empirical 100 Trillion Token Study .pdf,State of AI: An Empirical 100 Trillion Token Study with OpenRouter,"Malika Aubakirova, Alex Atallah, Chris Clark, Justin Summerville, Anjney Midha",,,"large language models, LLMs, multi-step deliberation inference, AI inference provider, real-world LLM interactions, open-weight models, creative roleplay, coding assistance, agentic inference, Cinderella effect, model builders, AI developers, infrastructure providers","The study analyzes over 100 trillion tokens of real-world interactions with large language models (LLMs) using the OpenRouter platform. It observes significant adoption of open-weight models, the popularity of creative roleplay and coding assistance, and the rise of agentic inference. The study identifies foundational user cohorts with long-term engagement, termed the 'Cinderella Glass Slipper' effect. The findings highlight the complex and multifaceted engagement of developers and end-users with LLMs, providing insights for model builders, AI developers, and infrastructure providers.",3.55,78.234,278,cold_start,Phi-4,Apple_M1(Metal)
2601.10090v1_Difficulty-guided Sampling Bridging the Target Gap.pdf,Difficulty-guided Sampling: Bridging the Target Gap between Dataset Distillation and Downstream Tasks,"Mingzhuo Li, Guang Li, Linfeng Ye, Jiafeng Mao, Takahiro Ogawa, Konstantinos N. Plataniotis, Miki Haseyama",,2601.10090v1,"dataset distillation, image classification, difficulty-guided sampling, downstream tasks, deep neural networks","This paper introduces difficulty-guided sampling (DGS) to address the target gap between dataset distillation objectives and downstream tasks, aiming to enhance the performance of dataset distillation. The authors propose leveraging task-specific information to improve the alignment between the distilled dataset and the downstream task, focusing on image classification. DGS is presented as a post-stage sampling module that samples from image pools generated by existing methods, guided by a specific target difficulty distribution. Additionally, difficulty-aware guidance (DAG) is proposed to investigate the role of difficulty in dataset generation.",3.68,71.562,263,cold_start,Phi-4,Apple_M1(Metal)
2601.10092v1_LeMoF Level-guided Multimodal Fusion for Heterogen.pdf,LEMOF: LEVEL-GUIDED MULTIMODAL FUSION FOR HETEROGENEOUS CLINICAL DATA,"Jongseok Kim, Seongae Kang, Jonghwan Shin, Yuhan Lee, Ohyun Jo",,2601.10092v1,"Multimodal Learning, Hierarchical Representation Learning, Clinical Time-Series Modeling, Level-guided Feature Fusion, Explainable Medical AI","Multimodal clinical prediction is widely used to integrate heterogeneous data such as Electronic Health Records (EHR) and biosignals. However, existing methods tend to rely on static modality integration schemes and simple fusion strategies, failing to fully exploit modality-specific representations. This paper proposes Level-guided Modal Fusion (LeMoF), a novel framework that selectively integrates level-guided representations within each modality. Each level refers to a representation extracted from a different layer of the encoder. LeMoF explicitly separates and learns global modality-level predictions from level-specific discriminative representations, achieving a balanced performance between prediction stability and discriminative capability even in heterogeneous clinical environments. Experiments on length of stay prediction using Intensive Care Unit (ICU) data demonstrate that LeMoF consistently outperforms existing state-of-the-art multimodal fusion techniques across various encoder configurations. Level-wise integration is confirmed as a key factor in achieving robust predictive performance across various clinical conditions.",3.71,90.789,337,cold_start,Phi-4,Apple_M1(Metal)
2601.10094v1_V-Zero Self-Improving Multimodal Reasoning with Ze.pdf,V-Zero: Self-Improving Multimodal Reasoning with Zero Annotation,"Han Wang, Yi Yang, Jingyuan Hu, Minfeng Zhu, Wei Chen",,,"multimodal learning, vision-language models, self-improvement, unlabeled images, self-play, role specialization, Group Relative Policy Optimization","Recent advances in multimodal learning have significantly enhanced the reasoning capabilities of vision-language models (VLMs). However, state-of-the-art approaches rely heavily on large-scale human-annotated datasets, which are costly and time-consuming to acquire. To overcome this limitation, we introduce V-Zero, a general post-training framework that facilitates self-improvement using exclusively unlabeled images. V-Zero establishes a co-evolutionary loop by instantiating two distinct roles: a Questioner and a Solver. The Questioner learns to synthesize high-quality, challenging questions by leveraging a dual-track reasoning reward that contrasts intuitive guesses with reasoned results. The Solver is optimized using pseudo-labels derived from majority voting over its own sampled responses. Both roles are trained iteratively via Group Relative Policy Optimization (GRPO), driving a cycle of mutual enhancement. Remarkably, without a single human annotation, V-Zero achieves consistent performance gains on Qwen2.5-VL-7B-Instruct, improving visual mathematical reasoning by +1.7 and general vision-centric by +2.6, demonstrating the potential of self-improvement in multimodal systems.",3.6,92.877,334,cold_start,Phi-4,Apple_M1(Metal)
2601.10101v2_Matrix as Plan Structured Logical Reasoning with F.pdf,Matrix as Plan: Structured Logical Reasoning with Feedback-Driven Replanning,"Ke Chen, Jiandian Zeng, Zihao Peng, Guo Li, Guangxue Zhang, Tian Wang",https://doi.org/10.1145/XXXXXX.XXXXXX,,"Logical Reasoning, Large Language Models, Neurosymbolic Approaches, Semantic Decomposition","As knowledge and semantics on the web grow increasingly complex, enhancing Large Language Models (LLMs)’ comprehension and reasoning capabilities has become particularly important. Chain-of-Thought (CoT) prompting has been shown to enhance the reasoning capabilities of LLMs. However, it still falls short on logical reasoning tasks that rely on symbolic expressions and strict deductive rules. Neuro-symbolic methods address this gap by enforcing formal correctness through external solvers. Yet these solvers are highly format-sensitive, and small instabilities in model outputs can lead to frequent processing failures. The LLM-driven approaches avoid parsing brittleness, but they lack structured representations and process-level error-correction mechanisms. To further enhance the logical reasoning capabilities of LLMs, we propose MatrixCoT, a structured CoT framework with a matrix-based plan. Specifically, we normalize and type natural language expressions and attach explicit citation fields, and introduce a matrix-based planning method to preserve global relations among steps. The plan thus becomes a verifiable artifact and execution becomes more stable. For verification, we also add a feedback-driven replanning mechanism. Under semantic-equivalence constraints, it identifies omissions and defects, rewrites and compresses the dependency matrix, and produces a more trustworthy final answer. Experiments on five logical-reasoning benchmarks and five LLMs show that, without relying on external solvers, MatrixCoT enhances both the robustness and interpretability of LLMs when tackling complex symbolic reasoning tasks, while maintaining competitive performance.",3.74,117.614,440,cold_start,Phi-4,Apple_M1(Metal)
2601.10103v1_FlowAct-R1 Towards Interactive Humanoid Video Gene.pdf,FlowAct-R1: Towards Interactive Humanoid Video Generation,"Lizhen Wang, Yongming Zhu, Zhipeng Ge, Youwei Zheng, Longhao Zhang, Tianshu Hu, Shiyang Qin, Mingshuang Luo, Jiaxu Zhang, Xin Chen, Yulong Wang, Zerong Zheng, Jianwen Jiang, Chao Liang, Weifeng Chen, Xing Wang, Yuan Zhang, Mingyuan Gao",,2601.10103v1,"interactive humanoid video generation, video synthesis, real-time interaction, MMDiT architecture, chunkwise diffusion forcing, temporal consistency, low-latency responsiveness, full-body control, behavioral vividness, perceptual realism","Interactive humanoid video generation aims to synthesize lifelike visual agents that can engage with humans through continuous and responsive video. Despite recent advances in video synthesis, existing methods often grapple with the trade-off between high-fidelity synthesis and real-time interaction requirements. In this paper, we propose FlowAct-R1, a framework specifically designed for real-time interactive humanoid video generation. Built upon a MMDiT architecture, FlowAct-R1 enables the streaming synthesis of video with arbitrary durations while maintaining low-latency responsiveness. We introduce a chunkwise diffusion forcing strategy, complemented by a novel self-forcing variant, to alleviate error accumulation and ensure long-term temporal consistency during continuous interaction. By leveraging efficient distillation and system-level optimizations, our framework achieves a stable 25fps at 480p resolution with a time-to-first-frame (TTFF) of only around 1.5 seconds. The proposed method provides holistic and fine-grained full-body control, enabling the agent to transition naturally between diverse behavioral states in interactive scenarios. Experimental results demonstrate that FlowAct-R1 achieves exceptional behavioral vividness and perceptual realism, while maintaining robust generalization across diverse character styles.",4.2,114.21,480,cold_start,Phi-4,Apple_M1(Metal)
2601.10104v1_MathDoc Benchmarking Structured Extraction and Act.pdf,Benchmarking Structured Extraction and Active Refusal on Noisy Mathematics Exam Papers,"Chenyue Zhou, Jiayi Tuo, Shitong Qin, Wei Dai, Mingxuan Wang, Ziwei Zhao, Duoyang Li, Shiyang Su, Yanxi Lu, Yanbiao Ma",,,"structured extraction, active refusal, noisy mathematics exam papers, MLLMs, document-level information extraction, mathematical reasoning, large language models","The automated extraction of structured questions from paper-based mathematics exams is fundamental to intelligent education, yet remains challenging due to severe visual noise. Existing benchmarks focus on clean documents or generic layout analysis, overlooking the structural integrity of mathematical problems and the ability of models to actively reject incomplete inputs. MathDoc, the first benchmark for document-level information extraction from authentic high school mathematics exam papers, contains 3,609 carefully curated questions with real-world artifacts and includes unrecognizable samples to evaluate active refusal behavior. A multi-dimensional evaluation framework covering stem accuracy, visual similarity, and refusal capability is proposed. Experiments on SOTA MLLMs show that while end-to-end models achieve strong extraction performance, they consistently fail to refuse illegible inputs, producing confident but invalid outputs. This highlights a critical gap in current MLLMs and establishes MathDoc as a benchmark for assessing model reliability under degraded document conditions.",3.6,96.259,347,cold_start,Phi-4,Apple_M1(Metal)
2601.10108v1_SIN-Bench Tracing Native Evidence Chains in Long-C.pdf,SIN-Bench: Tracing Native Evidence Chains in Long-Context Multimodal Scientific Interleaved Literature,"Yiming Ren, Junjie Wang, Yuxin Meng, Yihang Shi, Zhiqiang Lin, Ruihang Chu, Yiran Xu, Ziming Li, Yunfei Zhao, Zihan Wang, Yu Qiao, Ruiming Tang, Minghao Liu, Yujiu Yang",,,"multimodal large language models, long-form scientific papers, evidence-based reasoning, Fish-in-the-Ocean paradigm, SIN-Bench, evidence chains, grounded QA, hypothesis verification","Evaluating whether multimodal large language models truly understand long-form scientific papers remains challenging: answer-only metrics and synthetic 'Needle-In-A-Haystack' tests often reward answer matching without requiring a causal, evidence-linked reasoning trace in the document. The 'Fish-in-the-Ocean' (FITO) paradigm is proposed, requiring models to construct explicit cross-modal evidence chains within native scientific documents. SIN-Data, a scientific interleaved corpus, and SIN-Bench with four tasks (SIN-Find, SIN-Verify, SIN-QA, SIN-Summary) are introduced. Experiments on eight MLLMs show grounding as the primary bottleneck, with Gemini-3-pro achieving the best average score, while GPT-5 attains the highest SIN-QA answer accuracy but underperforms on evidence-aligned scores, exposing a gap between correctness and traceable support.",3.61,108.014,390,cold_start,Phi-4,Apple_M1(Metal)
2601.10112v1_Repository Intelligence Graph Deterministic Archit.pdf,Repository Intelligence Graph: Deterministic Architectural Map for LLM Code Assistants,"Tsvi Cherny-Shahar, Amiram Yehudai",,,"software repositories, build systems, dependency graphs, software engineering agents, multi-lingual software","Repository aware coding agents often struggle to recover build and test structure, especially in multilingual projects where cross language dependencies are encoded across heterogeneous build systems and tooling. This paper introduces the Repository Intelligence Graph (RIG), a deterministic, evidence-backed architectural map that represents buildable components, aggregators, runners, tests, external packages, and package managers, connected by explicit dependency and coverage edges that trace back to concrete build and test definitions. SPADE, a deterministic extractor, constructs RIG from build and test artifacts, and exposes RIG as an LLM-friendly JSON view. Evaluation of three commercial agents on eight repositories shows that providing RIG improves mean accuracy by 12.2% and reduces completion time by 53.9%, with larger gains in multilingual repositories. Qualitative analysis suggests RIG shifts failures from structural misunderstandings toward reasoning mistakes over a correct structure.",3.47,80.029,278,cold_start,Phi-4,Apple_M1(Metal)
2601.10114v1_Following the Teachers Footsteps Scheduled Checkpo.pdf,Following the Teacher’s Footsteps: Scheduled Checkpoint Distillation for Domain-Specific LLMs,"Cheng Feng, Chaoliang Zhong, Jun Sun, Yusuke Oishi",,arXiv:2601.10114v1,"LLMs, Knowledge Distillation, Domain-specific Tasks","Large language models (LLMs) are challenging to deploy for domain-specific tasks due to their massive scale. This work proposes Scheduled Checkpoint Distillation (SCD) to distill a fine-tuned LLM into a smaller student model, allowing it to match or surpass the teacher's performance on domain-specific tasks. The method reduces the Teacher-Favored Subdomain (TFS) deficit by emulating the teacher’s convergence process during supervised fine-tuning and uses a sample-wise Adaptive Weighting mechanism to preserve student strengths on Student-Favored Subdomains (SFS). Experiments show that SCD consistently outperforms existing distillation approaches across diverse domain tasks, including QA, NER, and text classification in multiple languages.",3.65,71.049,259,cold_start,Phi-4,Apple_M1(Metal)
2601.10120v1_TopoDIM One-shot Topology Generation of Diverse In.pdf,TopoDIM: One-shot Topology Generation of Diverse Interaction Modes for Multi-Agent Systems,"Rui Sun, Jie Ding, Chenghua Gong, Tianjun Gu, Yihang Jiang, Juyuan Zhang, Liming Pan, Linyuan Lü",,,"multi-agent systems, communication topology, large language models, one-shot topology generation, token efficiency, decentralized execution, heterogeneous interaction modes","Optimizing communication topology in LLM-based multi-agent systems is critical for enabling collective intelligence. Existing methods mainly rely on spatio-temporal interaction paradigms, which incur high latency and computation due to sequential execution of multi-round dialogues. This paper proposes TOPODIM, a framework for one-shot topology generation with diverse interaction modes, designed for decentralized execution to enhance adaptability and privacy. TOPODIM enables agents to autonomously construct heterogeneous communication without iterative coordination, achieving token efficiency and improved task performance. Experiments demonstrate that TOPODIM reduces total token consumption by 46.41% while improving average performance by 1.50% over state-of-the-art methods. The framework also exhibits strong adaptability in organizing communication among heterogeneous agents.",3.46,88.276,305,cold_start,Phi-4,Apple_M1(Metal)
2601.10122v1_Role-Playing Agents Driven by Large Language Model.pdf,"Role-Playing Agents Driven by Large Language Models: Current Status, Challenges, and Future Trends","Ye Wang, Jiaxing Chen, Hongjiang Xiao",,2601.10122v1,"large language models, role-playing language agents, natural language processing, human-computer interaction, personality modeling, memory mechanisms, character modeling, behavioral decision control, data construction, evaluation frameworks","This paper reviews the development and key technologies of role-playing language agents (RPLAs), tracing their evolution from rule-based templates to cognitive simulation stages. It discusses technical pathways like psychological scale-driven character modeling and memory-augmented prompting mechanisms. The paper analyzes data construction methods and evaluation frameworks, highlighting challenges such as data sources and copyright constraints. It concludes with future directions for RPLAs, including personality evolution modeling and integration with cognitive neuroscience.",3.49,66.258,231,cold_start,Phi-4,Apple_M1(Metal)
2601.10129v1_LaViT Aligning Latent Visual Thoughts for Multi-mo.pdf,LaViT: Aligning Latent Visual Thoughts for Multi-modal Reasoning,"Linquan Wu, Tianxiang Jiang, Yifei Dong, Haoyu Yang, Fengji Zhang, Shichang Meng, Ai Xuan, Linqi Song, Jacky Keung",,,"multimodal reasoning, latent reasoning, knowledge distillation, visual attention, language models","Current multimodal latent reasoning often relies on external supervision, ignoring intrinsic visual attention dynamics. This work identifies a critical Perception Gap in distillation: student models mimic a teacher’s textual output while attending to divergent visual regions, relying on language priors rather than grounded perception. LaViT, a proposed framework, aligns latent visual thoughts rather than static embeddings. It compels the student to reconstruct the teacher’s visual semantics and attention trajectories prior to text generation, using a curriculum sensory gating mechanism to prevent shortcut learning. Experiments show LaViT enhances visual grounding, achieving up to +16.9% gains on complex reasoning tasks, enabling a compact 3B model to outperform larger open-source and proprietary models like GPT-4o.",3.27,89.824,294,cold_start,Phi-4,Apple_M1(Metal)
2601.10130v1_Redundancy-Driven Top-k Functional Dependency Disc.pdf,Redundancy-Driven Top-k Functional Dependency Discovery,"Xiaolong Wan, Xixian Han",,,"Functional dependency, top-k discovery, data redundancy, pruning strategy","Functional dependencies (FDs) are essential constraints in relational databases, used for various data management tasks. Traditional FD discovery algorithms identify all valid dependencies, leading to high computational costs and large result sets. This paper introduces SDP (Selective-Discovery-and-Prune), a method to discover the top-k FDs ranked by redundancy count, which measures the duplicated information an FD explains. SDP uses an upper bound on redundancy to prune the search space, proving that this bound is monotone. The method is enhanced with optimizations such as ordering attributes by partition cardinality, using pairwise statistics in a Partition Cardinality Matrix, and a global scheduler to prioritize promising branches. Experiments on over 40 datasets demonstrate that SDP is significantly faster and more memory-efficient than exhaustive methods.",3.07,74.272,228,cold_start,Phi-4,Apple_M1(Metal)
2601.10131v2_M4olGen Multi-Agent Multi-Stage Molecular Generati.pdf,"M4olGen: Multi-Agent, Multi-Stage Molecular Generation under Precise Multi-Property Constraints","Yizhan Li, Florence Cloutier, Sifan Wu, Ali Parviz, Boris Knyazev, Yan Zhang, Glen Berseth, Bang Liu",,,"molecular generation, multi-property constraints, large language models, multi-agent reasoner, retrieval-augmented, RL-based optimization, Group Relative Policy Optimization, QED, LogP, Molecular Weight, HOMO, LUMO","Generating molecules that satisfy precise numeric constraints over multiple physicochemical properties is critical and challenging. Large language models (LLMs) struggle with precise multi-objective control and numeric reasoning without external structure and feedback. This paper introduces M4olGen, a fragment-level, retrieval-augmented, two-stage framework for molecule generation under multi-property constraints. Stage I involves prototype generation using a multi-agent reasoner for retrieval-anchored, fragment-level edits. Stage II uses RL-based fine-grained optimization with Group Relative Policy Optimization (GRPO) for one- or multi-hop refinements to minimize property errors. The framework leverages a large, automatically curated dataset with reasoning chains of fragment edits and measured property deltas, enabling deterministic, reproducible supervision and controllable multi-hop reasoning. Experiments demonstrate consistent gains in validity and precise satisfaction of multi-property targets, outperforming strong LLMs and graph-based algorithms.",3.67,100.976,371,cold_start,Phi-4,Apple_M1(Metal)
2601.10132v1_Is More Context Always Better Examining LLM Reason.pdf,Is More Context Always Better? Examining LLM Reasoning Capability for Time Interval Prediction,"Yanan Cao, Farnaz Fallahi, Murali Mohana Krishna Dandu, Lalitesh Morishetti, Kai Zhao, Luyi Ma, Sinduja Subramaniam, Jianpeng Xu, Evren Korpeoglu, Kaushiki Nag, Sushant Kumar, Kannan Achan",https://doi.org/10.1145/XXXXXX.XXXXXX,,"Large Language Models, Temporal Reasoning, Inter-Purchase Interval Prediction","Large Language Models (LLMs) have demonstrated impressive capabilities in reasoning and prediction across different domains. However, their ability to infer temporal regularities from structured behavioral data remains underexplored. This paper presents a systematic study investigating whether LLMs can predict time intervals between recurring user actions, such as repeated purchases, and how different levels of contextual information shape their predictive behavior. Using a simple but representative repurchase scenario, the study benchmarks state-of-the-art LLMs in zero-shot settings against both statistical and machine-learning models. Two key findings emerge: First, while LLMs surpass lightweight statistical baselines, they consistently underperform dedicated machine-learning models, showing their limited ability to capture quantitative temporal structure. Second, although moderate context can improve LLM accuracy, adding further user-level detail degrades performance. These results challenge the assumption that 'more context leads to better reasoning.' The study highlights fundamental limitations of today's LLMs in structured temporal inference and offers guidance for designing future context-aware hybrid models that integrate statistical precision with linguistic flexibility.",3.62,109.931,398,cold_start,Phi-4,Apple_M1(Metal)
2601.10137v1_Step-by-Step Causality Transparent Causal Discover.pdf,Step-by-Step Causality: Transparent Causal Discovery with Multi-Agent Tree-Query and Adversarial Confidence Estimation,"Ziyi Ding, Chenfei Ye-Hao, Zheyuan Wang, Xiao-Ping Zhang",,,"causal discovery, LLM, Tree-Query, causal graphs, causal oracles, confidence estimation","This paper introduces Tree-Query, a tree-structured, multi-expert LLM framework for causal discovery. It addresses the limitations of classical constraint-based methods and LLM-based causal oracles by providing interpretable judgments with robustness-aware confidence scores. Theoretical guarantees are provided for asymptotic identifiability of four pairwise relations. Tree-Query improves structural metrics over direct LLM baselines on data-free benchmarks and offers a principled way to obtain data-free causal priors from LLMs to complement downstream data-driven causal discovery.",3.2,67.162,215,cold_start,Phi-4,Apple_M1(Metal)
2601.10141v1_Understanding and Preserving Safety in Fine-Tuned .pdf,Understanding and Preserving Safety in Fine-Tuned LLMs,"Jiawen Zhang, Yangfan Hu, Kejia Chen, Lipeng He, Jiachen Ma, Jian Lou, Dan Li, Jian Liu, Xiaohu Yang, Ruoxi Jia",,,"fine-tuning, large language models, safety alignment, jailbreak attacks, gradient analysis, safety-preserving fine-tuning","Fine-tuning is crucial for applying large language models (LLMs) to specific tasks, but it can degrade safety alignment, increasing susceptibility to jailbreak attacks. This work explores the geometric interaction between safety- and utility-oriented gradients in LLMs, revealing that safety gradients lie in a low-rank subspace, while utility gradients span a broader space. These subspaces often conflict during fine-tuning. The proposed safety-preserving fine-tuning (SPF) method removes conflicting gradient components, maintaining task performance and safety alignment even under adversarial conditions. SPF ensures utility convergence while bounding safety drift, offering robust resistance to deep fine-tuning and dynamic jailbreak attacks.",3.49,83.875,293,cold_start,Phi-4,Apple_M1(Metal)
2601.10143v1_History Is Not Enough An Adaptive Dataflow System .pdf,History Is Not Enough: An Adaptive Dataflow System for Financial Time-Series Synthesis,"Haochong Xia, Yao Long Teng, Regan Tan, Molei Qin, Xinrun Wang, Bo An",,,"Adaptive dataflow, workflow automation, financial time-series, data augmentation","In quantitative finance, the gap between training and real-world performance—driven by concept drift and distributional non-stationarity—remains a critical obstacle for building reliable data-driven systems. Models trained on static historical data often overfit, resulting in poor generalization in dynamic markets. The mantra 'History Is Not Enough' underscores the need for adaptive data generation that learns to evolve with the market rather than relying solely on past observations. This paper presents a drift-aware dataflow system that integrates machine learning–based adaptive control into the data curation process. The system couples a parameterized data manipulation module comprising single-stock transformations, multi-stock mix-ups, and curation operations, with an adaptive planner–scheduler that employs gradient-based bi-level optimization to control the system. This design unifies data augmentation, curriculum learning, and data workflow management under a single differentiable framework, enabling provenance-aware replay and continuous data quality monitoring. Extensive experiments on forecasting and reinforcement learning trading tasks demonstrate that the framework enhances model robustness and improves risk-adjusted returns. The system provides a generalizable approach to adaptive data management and learning-guided workflow automation for financial data.",3.74,93.695,350,cold_start,Phi-4,Apple_M1(Metal)
2601.10148v1_DecisionLLM Large Language Models for Long Sequenc.pdf,DecisionLLM: Large Language Models for Long Sequence Decision Exploration,"Xiaowei Lv, Zhiling Zhang, Yijun Li, Yusen Huo, Siyuan Ju, Xuyan Li, Chunxiang Hong, Tianyu Wang, Yongcai Wang, Peng Sun, Chuan Yu, Jian Xu, Bo Zheng",,,"Long-sequence decision-making, Reinforcement learning, Large Language Models, Decision Transformer, Offline decision making, Trajectory data, Natural language task descriptions, Scaling laws, Offline experimental benchmarks, AuctionNet, Maze2D umaze-v1, AIGB paradigm","Long-sequence decision-making, typically addressed through reinforcement learning (RL), is crucial for optimizing strategic operations in dynamic environments like real-time bidding in computational advertising. The Decision Transformer (DT) frames RL as an autoregressive sequence modeling problem. Large Language Models (LLMs), sharing the Transformer foundation but operating at a larger scale, show potential in long-horizon sequential decision-making. This work explores LLMs in offline decision-making tasks, addressing their inability to interpret continuous values by treating trajectories as a distinct modality. The proposed DecisionLLM model aligns trajectory data with natural language task descriptions to predict future decisions. Performance is influenced by model scale, data volume, and data quality. DecisionLLM-3B outperforms traditional Decision Transformer (DT) in benchmarks and bidding scenarios, suggesting new directions for online bidding exploration.",3.65,105.965,387,cold_start,Phi-4,Apple_M1(Metal)
2601.10150v1_Simple Network Graph Comparative Learning.pdf,Simple Network Graph Comparative Learning,"Qiang Yu, Xinran Cheng, Shiqiang Xu, Chuanyi Liu",,,"Filters, Siamese network, Graph contrastive learning, Unsupervised representation learning","The effectiveness of contrastive learning methods has been widely recognized in the field of graph learning, especially in contexts where graph data often lack labels or are difficult to label. However, the application of these methods to node classification tasks still faces a number of challenges. First, existing data enhancement techniques may lead to significant differences from the original view when generating new views, which may weaken the relevance of the view and affect the efficiency of model training. Second, the vast majority of existing graph comparison learning algorithms rely on the use of a large number of negative samples. To address the above challenges, this study proposes a novel node classification contrast learning method called Simple Network Graph Comparative Learning (SNGCL). Specifically, SNGCL employs a superimposed multilayer Laplace smoothing filter as a step in processing the data to obtain global and local feature smoothing matrices, respectively, which are thus passed into the target and online networks of the siamese network, and finally employs an improved triple recombination loss function to bring the intra-class distance closer and the inter-class distance farther. We have compared SNGCL with state-of-the-art models in node classification tasks, and the experimental results show that SNGCL is strongly competitive in most tasks.",3.73,92.198,344,cold_start,Phi-4,Apple_M1(Metal)
2601.10154v1_MHub.ai A Simple Standardized and Reproducible Pla.pdf,"MHub.ai: A Simple, Standardized, and Reproducible Platform for AI Models in Medical Imaging","Leonard Nürnberg, Dennis Bontempi, Suraj Pai, Curtis Lisle, Steve Pieper, Ron Kikinis, Sil van de Leemput, Rahul Soni, Gowtham Murugesan, Cosmin Ciausu, Miriam Groeneveld, Felix J. Dorfner, Jue Jiang, Aneesh Rangnekar, Harini Veeraraghavan, Joeran S. Bosma, Keno Bressem, Raymond Mak, Andrey Fedorov, Hugo JWL Aerts",,,,,3.07,62.814,193,cold_start,Phi-4,Apple_M1(Metal)
2601.10155v1_LOOKAT Lookup-Optimized Key-Attention for Memory-E.pdf,Lookup-Optimized Key-Attention for Memory-Efficient Transformers,Aryan Karmore,,,"transformers, memory efficiency, key-value cache, product quantization, asymmetric distance computation, compression, edge devices, attention mechanism","Compressing the KV cache is essential for deploying large language models on edge devices. Current quantization methods compress storage but do not reduce bandwidth as attention calculation requires dequantizing keys from INT4/INT8 to FP16. The paper proposes LOOKAT, which applies product quantization and asymmetric distance computation to transformer architecture by decomposing key vectors into subspaces, learning codebooks, and computing attention tables via lookup tables. This approach transforms attention from memory-bound to compute-bound, achieving 64×compression at 95.7% output fidelity and 32×compression at 95.0% fidelity on GPT-2. LOOKAT requires no architecture changes or training while maintaining high rank correlation, validated across sequence lengths up to 1024 tokens.",3.45,73.816,255,cold_start,Phi-4,Apple_M1(Metal)
2601.10157v1_MMPG MoE-based Adaptive Multi-Perspective Graph Fu.pdf,MMPG: MoE-based Adaptive Multi-Perspective Graph Fusion for Protein Representation Learning,"Yusong Wang, Jialun Shen, Zhihao Wu, Yicheng Xu, Shiyin Tan, Mingkun Xu, Changshuo Wang, Zixing Song, Prayag Tiwari",,,"Graph Neural Networks, Protein Representation Learning, Mixture of Experts, Multi-Perspective Graph Fusion","Graph Neural Networks (GNNs) are widely used for Protein Representation Learning (PRL) due to their ability to model residue interactions as graphs. However, current methods often rely on single-perspective graph construction, leading to incomplete protein representations. This paper introduces MMPG, a framework that constructs protein graphs from multiple perspectives (physical, chemical, and geometric) and adaptively fuses them using a Mixture of Experts (MoE) approach. The MoE module dynamically routes perspectives to specialized experts, capturing both perspective-specific features and their synergies. This approach allows for modeling distinct levels of interaction, from individual representations to a global consensus across all perspectives. MMPG achieves superior protein representations and advanced performance on various downstream protein tasks.",3.54,84.473,299,cold_start,Phi-4,Apple_M1(Metal)
2601.10160v1_Alignment Pretraining AI Discourse Causes Self-Ful.pdf,Alignment Pretraining: AI Discourse Causes Self-Fulfilling (Mis)alignment,"Cameron Tice, Puria Radmard, Samuel Ratnam, Andy Kim, David Africa, Kyle O’Brien",,,"alignment pretraining, misalignment, language models, AI discourse, alignment elasticity, self-fulfilling misalignment","This paper explores how pretraining corpora containing discourse about AI systems influence the alignment of language models. It presents a controlled study showing that pretraining with misalignment discourse increases misaligned behavior in LLMs, while upsampling aligned behavior reduces misalignment. The study highlights the importance of alignment pretraining as a complement to post-training interventions, suggesting that pretraining data significantly shapes alignment priors. The findings recommend practitioners to focus on pretraining for alignment alongside capabilities.",3.24,68.508,222,cold_start,Phi-4,Apple_M1(Metal)
2601.10161v1_AWED-FiNER Agents Web applications and Expert Dete.pdf,"A WED-FiNER: Agents, Web applications, and Expert Detectors for Fine-grained Named Entity Recognition across 36 Languages for 6.6 Billion Speakers","Prachuryya Kaushik, Ashish Anand",,,"Fine-grained Named Entity Recognition, Low-resource Languages, Natural Language Processing, Large Language Models, Multilingual Text, Expert Models, Digital Equity, Web Applications, Agent Tools","We introduce A WED-FiNER, an open-source ecosystem designed to bridge the gap in Fine-grained Named Entity Recognition (FgNER) for 36 global languages spoken by more than 6.6 billion people. While Large Language Models (LLMs) dominate general Natural Language Processing (NLP) tasks, they often struggle with low-resource languages and fine-grained NLP tasks. AWED-FiNER provides a collection of agentic toolkits, web applications, and several state-of-the-art expert models that provide FgNER solutions across 36 languages. The agentic tools enable routing multilingual text to specialized expert models and fetch FgNER annotations within seconds. The web-based platforms provide ready-to-use FgNER annotation service for non-technical users. Moreover, the collection of language-specific extremely small-sized open-source state-of-the-art expert models facilitate offline deployment in resource-constrained scenarios including edge devices. AWED-FiNER covers languages spoken by over 6.6 billion people, including a specific focus on vulnerable languages such as Bodo, Manipuri, Bishnupriya, and Mizo.",3.54,97.469,345,cold_start,Phi-4,Apple_M1(Metal)
2601.10168v1_RAG-3DSG Enhancing 3D Scene Graphs with Re-Shot Gu.pdf,RAG-3DSG: Enhancing 3D Scene Graphs with Re-shot Guided Retrieval-Augmented Generation,"Yue Chang, Rufeng Chen, Zhaofan Zhang, Yi Chen, Sihong Xie",,,"3D Scene Graph, Open-vocabulary, Retrieval-Augmented Generation, Robotics, Semantic Representation","Open-vocabulary 3D Scene Graph (3DSG) generation enhances robotics tasks like manipulation and navigation by using structured semantic representations. 3DSGs are constructed from multiple images of a scene, with objects as nodes and relationships as edges. Existing methods face challenges due to low object-level recognition accuracy and speed, caused by constrained viewpoints, occlusions, and redundant surface density. The proposed RAG-3DSG addresses these issues by mitigating aggregation noise through re-shot guided uncertainty estimation and supporting object-level Retrieval-Augmented Generation (RAG) via reliable low-uncertainty objects. Additionally, a dynamic downsample-mapping strategy accelerates cross-image object aggregation with adaptive granularity. Experiments on the Replica dataset show that RAG-3DSG significantly improves node captioning accuracy in 3DSG generation while reducing mapping time by two-thirds compared to the vanilla version.",3.46,82.32,285,cold_start,Phi-4,Apple_M1(Metal)
2601.10169v1_CtD Composition through Decomposition in Emergent .pdf,Composition through Decomposition in Emergent Communication,"Boaz Carmeli, Ron Meir, Yonatan Belinkov",,,"compositionality, emergent communication, neural networks, discrete concepts, codebook, generalization, multi-target coordination game, referential game","This study explores how artificial neural agents can acquire and utilize compositional generalization to describe previously unseen images. The method, termed 'Composition through Decomposition,' involves two sequential training steps: 'Decompose,' where agents learn to break down images into basic concepts using a codebook from a multi-target coordination game, and 'Compose,' where agents use this codebook to describe novel images by combining basic concepts into complex phrases. The study highlights cases of zero-shot generalization in the 'Compose' step, achieved without additional training. The research emphasizes the importance of decomposing complex concepts into basic ones before effective composition, challenging the reliance on discretization bias alone for achieving compositionality.",3.29,76.688,252,cold_start,Phi-4,Apple_M1(Metal)
2601.10173v1_ReasAlign Reasoning Enhanced Safety Alignment agai.pdf,ReasAlign: Reasoning Enhanced Safety Alignment against Prompt Injection Attack,"Hao Li, Yankai Yang, G. Edward Suh, Ning Zhang, Chaowei Xiao",,,"Large Language Models, safety alignment, prompt injection attack, structured reasoning, security, utility, agentic systems","Large Language Models (LLMs) have enabled the development of powerful agentic systems capable of automating complex workflows across various fields. However, these systems are highly vulnerable to indirect prompt injection attacks, where malicious instructions embedded in external data can hijack agent behavior. This work presents ReasAlign, a model-level solution to improve safety alignment against such attacks. ReasAlign incorporates structured reasoning steps to analyze user queries, detect conflicting instructions, and preserve the continuity of the user’s intended tasks. A test-time scaling mechanism with a preference-optimized judge model scores reasoning steps and selects the best trajectory. Comprehensive evaluations show that ReasAlign maintains utility comparable to an undefended model while consistently outperforming Meta SecAlign, the strongest prior guardrail. On the CyberSecEval2 benchmark, ReasAlign achieves 94.6% utility and only 3.6% ASR, surpassing Meta SecAlign's 56.4% utility and 74.4% ASR. These results demonstrate that ReasAlign achieves the best trade-off between security and utility, establishing a robust and practical defense against prompt injection attacks in real-world agentic systems.",3.62,98.066,355,cold_start,Phi-4,Apple_M1(Metal)
2601.10187v1_HOMURA Taming the Sand-Glass for Time-Constrained .pdf,HOMURA: Taming the Sand-Glass for Time-Constrained LLM Translation via Reinforcement Learning,"Ziang Cui, Mengran Yu, Tianjiao Li, Chenyu Shi, Yingxuan Shi, Lusheng Zhang, Hongwei Lin",,,"Large Language Models, multilingual translation, reinforcement learning, syllable-level duration constraints, semantic fidelity, temporal feasibility, cross-lingual verbosity bias, subtitling, dubbing","Large Language Models (LLMs) have achieved remarkable strides in multilingual translation but are hindered by a systemic cross-lingual verbosity bias, rendering them unsuitable for strict time-constrained tasks like subtitling and dubbing. Current prompt-engineering approaches struggle to resolve this conflict between semantic fidelity and rigid temporal feasibility. To bridge this gap, we first introduce Sand-Glass, a benchmark specifically designed to evaluate translation under syllable-level duration constraints. Furthermore, we propose HOMURA, a reinforcement learning framework that explicitly optimizes the trade-off between semantic preservation and temporal compliance. By employing a KL-regularized objective with a novel dynamic syllable-ratio reward, HOMURA effectively 'tames' the output length. Experimental results demonstrate that our method significantly outperforms strong LLM baselines, achieving precise length control that respects linguistic density hierarchies without compromising semantic adequacy.",3.79,92.455,350,cold_start,Phi-4,Apple_M1(Metal)
2601.10191v1_How does downsampling affect needle electromyograp.pdf,How does downsampling affect needle electromyography signals? A generalisable workflow for understanding downsampling effects on high-frequency time series,"Mathieu J.L. Cherpitel, Janne A.M. Luijten, Thomas H.W. B""ack, Camiel Verhamme, Martijn R. Tannemaat, Anna V. Kononova",,,"needle electromyography, downsampling, high-frequency time series, machine learning, neuromuscular diseases, feature-based models, shape-based distortion metrics","Automated analysis of needle electromyography (nEMG) signals is emerging as a tool to support the detection of neuromuscular diseases (NMDs), yet the signals’ high and heterogeneous sampling rates pose substantial computational challenges for feature-based machine-learning models, particularly for near real-time analysis. Downsampling offers a potential solution, but its impact on diagnostic signal content and classification performance remains insufficiently understood. This study presents a workflow for systematically evaluating information loss caused by downsampling in high-frequency time series. The workflow combines shape-based distortion metrics with classification outcomes from available feature-based machine learning models and feature space analysis to quantify how different downsampling algorithms and factors affect both waveform integrity and predictive performance. We use a three-class NMD classification task to experimentally evaluate the workflow. We demonstrate how the workflow identifies downsampling configurations that preserve diagnostic information while substantially reducing computational load. Analysis of shape-based distortion metrics showed that shape-aware downsampling algorithms outperform standard decimation, as they better preserve peak structure and overall signal morphology. The results provide practical guidance for selecting downsampling configurations that enable near real-time nEMG analysis and highlight a generalisable workflow that can be used to balance data reduction with model performance in other high-frequency time-series applications as well.",3.89,102.197,398,cold_start,Phi-4,Apple_M1(Metal)
2601.10193v1_GFM4GA Graph Foundation Model for Group Anomaly De.pdf,GFM4GA: Graph Foundation Model for Group Anomaly Detection,"Jiujiu Chen, Weijun Zeng, Shaofeng Hu, Sihong Xie, Hui Xiong",https://doi.org/XXXXXXX.XXXXXXX,,"Group Anomaly Detection, Graph Foundation Model, Graph Contrastive Learning","Group anomaly detection is crucial in many network applications, but faces challenges due to diverse anomaly patterns. Motivated by the success of large language models (LLMs) in natural language processing, graph foundation models (GFMs) are proposed to handle few-shot learning tasks with fewer labeling efforts. GFMs have been successfully applied to the detection of individual anomalies but cannot be generalized to group anomalies, as group anomaly patterns must be detected as a whole and individuals in an abnormal group can look rather normal. Therefore, we propose GFM4GA, a novel graph foundation model for group anomaly detection. The pipeline is pretrained via dual-level contrastive learning based on feature-based estimation and group extraction, to capture potential group anomaly structure and feature inconsistencies. In the downstream tasks, the pipeline is finetuned in parameter-constrained and group-anomaly-proportion weighted few-shot settings, and its adaptive ability to unseen group anomalies is expanded via group contexts determined by labeled anomaly neighbors. Experiments show that GFM4GA surpasses group anomaly detectors and GFMs for individual anomalies, achieving average improvements of 2.85% in AUROC and 2.55% in AUPRC.",3.61,98.596,356,cold_start,Phi-4,Apple_M1(Metal)
2601.10201v1_PRL Process Reward Learning Improves LLMs Reasonin.pdf,Process Reward Learning Improves LLMs’ Reasoning Ability and Broadens the Reasoning Boundary,"Jiarui Yao, Ruida Wang, Tong Zhang",,,"Large Language Models, Reinforcement Learning, Process Reward Learning, reasoning ability, entropy regularization, KL-divergence","This paper introduces Process Reward Learning (PRL) to enhance the reasoning abilities of Large Language Models (LLMs). Traditional RL frameworks rely on sparse outcome rewards, which are insufficient for multi-step reasoning tasks. PRL decomposes the reinforcement learning objective into intermediate steps, providing fine-grained supervision signals. Theoretical motivation and formulation of PRL are discussed, showing its equivalence to reward maximization with a KL-divergence penalty. Experiments demonstrate that PRL improves LLMs' reasoning performance and broadens the reasoning boundary.",3.25,63.157,205,cold_start,Phi-4,Apple_M1(Metal)
2601.10205v1_One Instruction Does Not Fit All How Well Do Embed.pdf,One Instruction Does Not Fit All: How Well Do Embeddings Align Personas and Instructions in Low-Resource Indian Languages?,"Arya Shah, Himanshu Beniwal, Mayank Singh",,,"multilingual assistants, Indian languages, embedding models, persona-instruction compatibility, cross-lingual retrieval, multilingual benchmarks","Aligning multilingual assistants with culturally grounded user preferences is essential for serving India’s linguistically diverse population. This study presents a unified benchmark for 12 Indian languages across four evaluation tasks: monolingual and cross-lingual persona-to-instruction retrieval, reverse retrieval from instruction to persona, and binary compatibility classification. Eight multilingual embedding models are evaluated, with E5-Large-Instruct and BGE-M3 showing strong performance in retrieval tasks, and LaBSE achieving high AUROC in classification. The findings provide practical guidance for model selection in Indic multilingual retrieval and establish reproducible baselines for future work.",3.38,73.162,247,cold_start,Phi-4,Apple_M1(Metal)
2601.10212v1_PADER Paillier-based Secure Decentralized Social R.pdf,PADER: Paillier-based Secure Decentralized Social Recommendation,"Chaochao Chen, Jiaming Qian, Fei Zheng, Yachuan Liu",,,"Paillier Cryptosystem, Secure Computation, Recommendation System","The prevalence of recommendation systems also brings privacy concerns to both the users and the sellers, as centralized platforms collect as much data as possible from them. To keep the data private, we propose PADER, a Paillier-based secure decentralized social recommendation system. In this system, the users and the sellers are nodes in a decentralized network. The training and inference of the recommendation model are carried out securely in a decentralized manner, without the involvement of a centralized platform. To this end, we apply the Paillier cryptosystem to the SoReg (Social Regularization) model, which exploits both user’s ratings and social relations. We view the SoReg model as a two-party secure polynomial evaluation problem and observe that the simple bipartite computation may result in poor efficiency. To improve efficiency, we design secure addition and multiplication protocols to support secure computation on any arithmetic circuit, along with an optimal data packing scheme that is suitable for the polynomial computations of real values. Experiment results show that our method only takes about one second to iterate through one user with hundreds of ratings, and training with ~500K ratings for one epoch only takes <3 hours, which shows that the method is practical in real applications. The code is available at https://github.com/GarminQ/PADER.",3.74,95.888,359,cold_start,Phi-4,Apple_M1(Metal)
2601.10215v1_Topo-RAG Topology-aware retrieval for hybrid text-.pdf,TOPO-RAG: TOPOLOGY-AWARE RETRIEVAL FOR HYBRID TEXT–TABLE DOCUMENTS,"Alex Dantart, Marco K´ovacs-Navarro",,arXiv:2601.10215v1,"Retrieval-Augmented Generation (RAG), table retrieval, late interaction, multivector retrieval, enterprise search, heterogeneous data, semantic routing, structure-aware embeddings, Topo-RAG, ColBERT, cell-aware interaction, linearization bottleneck","In enterprise datasets, documents are rarely pure, combining narrative and structure. Current Retrieval-Augmented Generation (RAG) systems use linearization, converting tables into text strings, which is mathematically insufficient. This work introduces Topo-RAG, a dual architecture that respects data topology by routing narrative through dense retrievers and processing tabular structures with a Cell-Aware Late Interaction mechanism. Evaluated on SEC-25, Topo-RAG shows an 18.4% improvement in nDCG@10 on hybrid queries compared to linearization approaches, emphasizing understanding the shape of information.",3.71,77.34,287,cold_start,Phi-4,Apple_M1(Metal)
2601.10222v1_Introduction to optimization methods for training .pdf,Introduction to optimization methods for training SciML models,"Alena Kopaničáková, Elisa Riccietti",,2601.10222v1,"optimization, machine learning, SciML, stochastic optimization, gradient descent, Hessians, partial-differential equations, physics informed, operator constrained","Optimization is fundamental to modern machine learning, with methods categorized by their use of derivative information. First-order methods use gradients, while second-order methods use Hessians or approximations. The scale of modern ML problems has led to stochastic optimization methods like Stochastic Gradient Descent (SGD) and its variants, which use noisy gradient evaluations. In scientific machine learning (SciML), optimization problems often involve physics-informed or operator-constrained formulations, incorporating partial-differential equations and boundary conditions. This changes the structure of the objective function, leading to global spatio-temporal coupling, unlike classical ML where losses decompose into independent sample contributions.",3.74,67.636,253,cold_start,Phi-4,Apple_M1(Metal)
2601.10236v1_Who Owns the Text Design Patterns for Preserving A.pdf,Who Owns the Text? Design Patterns for Preserving Authorship in AI-Assisted Writing,"Bohan Zhang, Chengke Bu, Paramveer Dhillon",,arXiv:2601.10236v1,"AI-assisted writing, human–AI collaboration, psychological ownership, personalization, provenance","AI writing assistants can reduce effort and improve fluency, but they may also weaken writers’ sense of authorship. This study explores the tension with an ownership-aware co-writing editor that offers on-demand, sentence-level suggestions and tests two common design choices: persona-based coaching and style personalization. In an online study (N=176), participants completed three professional writing tasks—an email without AI help, a proposal with generic AI suggestions, and a cover letter with persona-based coaching—while half received suggestions tailored to a brief sample of their prior writing. Across the two AI-assisted tasks, psychological ownership dropped relative to unassisted writing (about 0.85–1.0 points on a 7-point scale), even as cognitive load decreased (about 0.9 points) and quality ratings stayed broadly similar overall. Persona coaching did not prevent the ownership decline. Style personalization partially restored ownership (about +0.43) and increased AI incorporation in text (+5 percentage points). Five design patterns—on-demand initiation, micro-suggestions, voice anchoring, audience scaffolds, and point-of-decision provenance—are distilled to guide authorship-preserving writing tools.",3.94,90.748,358,cold_start,Phi-4,Apple_M1(Metal)
2601.10242v1_Loop as a Bridge Can Looped Transformers Truly Lin.pdf,LOOP AS ABRIDGE: CAN LOOPED TRANSFORMERS TRULY LINK REPRESENTATION SPACE AND NATURAL LANGUAGE OUTPUTS?,"Guanxu Chen, Dongrui Liu, Jing Shao",,,"Large Language Models, Looped Transformers, Representation Space, Natural Language Outputs, Introspection, Computational Depth","This report investigates whether Looping Transformers (LTs), which increase computational depth by iterating shared layers, can bridge the gap between internal 'knowledge' and explicit linguistic outputs of Large Language Models (LLMs). The study finds that while increasing loop iterations narrows this gap, it is partly due to a degradation of internal 'knowledge' in representations. Additionally, LTs' ability to perceive representations does not improve across loops but is only present in the final loop. These findings suggest that while LTs are promising for scaling computational depth, they have not yet achieved the necessary introspection to truly link representation space and natural language.",3.37,73.095,246,cold_start,Phi-4,Apple_M1(Metal)
2601.10245v1_TRIM Hybrid Inference via Targeted Stepwise Routin.pdf,TRIM: Hybrid Inference via Targeted Stepwise Routing in Multi-Step Reasoning Tasks,"Vansh Kapoor, Aman Gupta, Hao Chen, Anurag Beniwal, Jing Huang, Aviral Kumar",,,"multi-step reasoning, LLM routing, cost efficiency, mathematical problem solving, step-level interventions","Multi-step reasoning tasks like mathematical problem solving are vulnerable to cascading failures where a single incorrect step leads to complete solution breakdown. Current LLM routing methods assign entire queries to one model, treating all reasoning steps as equal. This paper proposes TRIM (Targeted Routing in Multi-Step Reasoning Tasks), which routes only critical steps—those likely to derail the solution—to larger models while letting smaller models handle routine continuations. TRIM uses process reward models to identify erroneous steps and makes routing decisions based on step-level uncertainty and budget constraints. Various routing strategies within TRIM are developed, showing significant cost efficiency improvements on benchmarks like MATH-500 and AIME. The methods generalize effectively across math reasoning tasks, demonstrating that step-level difficulty represents fundamental characteristics of reasoning.",3.52,80.036,282,cold_start,Phi-4,Apple_M1(Metal)
2601.10251v1_X-SAM Boosting Sharpness-Aware Minimization with D.pdf,X-SAM: Boosting Sharpness-Aware Minimization with Dominant-Eigenvector Gradient Correction,"Hongru Duan, Yongle Chen, Lei Guan",,,"Sharpness-Aware Minimization, Spectral Analysis, Gradient Correction, Hessian, Generalization, Optimization","Sharpness-Aware Minimization (SAM) aims to improve generalization by minimizing a worst-case perturbed loss over a small neighborhood of model parameters. However, its optimization behavior does not always align with theoretical expectations, as both sharp and flat regions may yield a small perturbed loss. This paper investigates SAM from a spectral and geometric perspective, utilizing the angle between the gradient and the leading eigenvector of the Hessian as a measure of sharpness. The proposed eigenvector-aligned SAM (X-SAM) corrects the gradient via orthogonal decomposition along the top eigenvector, enabling more direct and efficient regularization of the Hessian’s maximum eigenvalue. The paper proves X-SAM’s convergence and superior generalization, with extensive experimental evaluations confirming both theoretical and practical advantages.",3.48,73.842,257,cold_start,Phi-4,Apple_M1(Metal)
2601.10254v1_NoReGeo Non-Reasoning Geometry Benchmark.pdf,NoReGeo: Non-Reasoning Geometry Benchmark,"Irina Abdullaeva, Anton Vasiliuk, Elizaveta Goncharova, Temurbek Rahmatullaev, Zagorulko Ivan, Maxim Kurkin, Andrey Kuznetsov",,,"geometry benchmark, large language models, geometric understanding, spatial relationships, binary classification, fine-tuning, geometric cognition","We present NoReGeo, a novel benchmark designed to evaluate the intrinsic geometric understanding of large language models (LLMs) without relying on reasoning or algebraic computation. Unlike existing benchmarks that primarily assess models’ proficiency in reasoning-based geometry, NoReGeo focuses on evaluating whether LLMs can inherently encode spatial relationships and recognize geometric properties directly. Our benchmark comprises 2,500 trivial geometric problems spanning 25 categories, each crafted to be solvable purely through native geometric understanding, assuming known object locations. We assess a range of state-of-the-art models on NoReGeo, including frontier models like GPT-4, observing that even the most advanced systems achieve an overall maximum of 65% accuracy in binary classification tasks. Our findings highlight a significant gap in current LLMs’ ability to natively grasp geometric concepts, providing a foundation for future research toward models with true geometric cognition.",3.68,89.085,328,cold_start,Phi-4,Apple_M1(Metal)
2601.10257v1_Untangling Input Language from Reasoning Language .pdf,Untangling Input Language from Reasoning Language: A Diagnostic Framework for Cross-Lingual Moral Alignment in LLMs,"Nan Li, Bo Kang, Tijl De Bie",,,"LLMs, moral alignment, cross-lingual, Moral Foundations Theory, diagnostic framework","This paper explores whether large language models (LLMs) reach different moral conclusions in different languages and identifies the factors contributing to such differences. The authors introduce a methodology that manipulates both the language of the dilemma and the language in which the model reasons, including mismatched conditions. They apply this methodology to English-Chinese moral judgment with 13 LLMs, demonstrating that reasoning-language effects contribute twice the variance of input-language effects. The framework also detects context-dependency in nearly half of the models that standard evaluation misses. The study proposes a diagnostic taxonomy to translate these patterns into deployment guidance and releases the associated code and datasets.",3.33,67.368,224,cold_start,Phi-4,Apple_M1(Metal)
2601.10272v1_MoST Mixing Speech and Text with Modality-Aware Mi.pdf,MOST: MIXINGSPEECH ANDTEXT WITHMODALITY-AWAREMIXTURE OFEXPERTS,"Yuxuan Lou, Kai Yang, Yang You",,arXiv:2601.10272v1,"multimodal large language model, speech and text processing, Modality-Aware Mixture of Experts (MAMoE), ASR, TTS, speech-text instruction dataset, open-source datasets, ASR, TTS, audio language modeling, spoken question answering","We present MoST (Mixture of Speech and Text), a novel multimodal large language model that seamlessly integrates speech and text processing through our proposed Modality-Aware Mixture of Experts (MAMoE) architecture. While current multimodal models typically process diverse modality representations with identical parameters—disregarding their inherent representational differences, we introduce specialized routing pathways that direct tokens to modality-appropriate experts based on input type. MAMoE simultaneously enhances modality-specific learning and cross-modal understanding through two complementary components: modality-specific expert groups that capture domain-specific patterns and shared experts that facilitate information transfer between modalities. Building on this architecture, we develop an efficient transformation pipeline that adapts the pretrained MoE language model through strategic post-training on ASR and TTS datasets, followed by fine-tuning with a carefully curated speech-text instruction dataset. A key feature of this pipeline is that it relies exclusively on fully accessible, open-source datasets to achieve strong performance and data efficiency. Comprehensive evaluations across ASR, TTS, audio language modeling, and spoken question answering benchmarks show that MoST consistently outperforms existing models of comparable parameter counts. Our ablation studies confirm that the modality-specific routing mechanism and shared experts design significantly contribute to performance gains across all tested domains. To our knowledge, MoST represents the first fully open-source speech-text LLM built on a Mixture of Experts architecture.",3.93,114.897,451,cold_start,Phi-4,Apple_M1(Metal)
2601.10274v1_Queueing-Aware Optimization of Reasoning Tokens fo.pdf,Queueing-Aware Optimization of Reasoning Tokens for Accuracy-Latency Trade-offs in LLM Servers,"Emre Ozbas, Melih Bastopcu",,,"Accuracy-latency trade-offs, LLM-based servers, optimization of reasoning tokens, LLM inference","This paper addresses the challenge of optimizing reasoning tokens in a large language model (LLM) server to balance accuracy and latency. The server processes a heterogeneous stream of queries, each with a distinct task type, arriving according to a Poisson process. The study formulates a constrained optimization problem to maximize a weighted average accuracy objective, penalized by mean system time, under token-budget constraints and queue-stability conditions. The objective function is strictly concave over the stability region, ensuring a unique optimal token allocation. The solution involves a projected fixed-point characterization, an iterative solution, and a projected gradient method for convergence. Integer-valued token allocations are achieved through rounding, with performance loss evaluated via simulations.",3.3,67.547,223,cold_start,Phi-4,Apple_M1(Metal)
2601.10282v2_SPIKE Sparse Koopman Regularization for Physics-In.pdf,SPIKE: Sparse Koopman Regularization for Physics-Informed Neural Networks,Jose Marie Antonio Miñoza,,arXiv:2601.10282v2,"Physics-Informed Neural Networks, Koopman operators, sparse dynamics, differential equations, PINNs, generalization, stability","This work introduces SPIKE, a framework that enhances Physics-Informed Neural Networks (PINNs) with continuous-time Koopman operators to address overfitting and improve generalization. By enforcing linear dynamics in a learned observable space, SPIKE achieves sparse generator matrices, enhancing interpretability and prediction accuracy. The framework demonstrates improvements in temporal extrapolation, spatial generalization, and long-term prediction across various PDEs and chaotic ODEs. The continuous-time formulation ensures stability for stiff systems, avoiding issues present in discrete-time Koopman operators.",3.27,64.5,211,cold_start,Phi-4,Apple_M1(Metal)
2601.10305v1_DanQing An Up-to-Date Large-Scale Chinese Vision-L.pdf,DanQing: An Up-to-Date Large-Scale Chinese Vision-Language Pre-training Dataset,"Hengyu Shen, Tiancheng Gu, Bin Qin, Lan Wu, Yuling Wu, Shuo Tan, Zelong Sun, Jun Wang, Nan Wu, Xiang An, Weidong Cai, Ziyong Feng, Kaicheng Yang",,arXiv:2601.10305v1,"Vision-Language Pre-training, Chinese dataset, image-text pairs, contrastive pretraining, cross-modal retrieval, image captioning, semantic trends","Vision-Language Pre-training (VLP) models demonstrate strong performance across various downstream tasks by learning from large-scale image-text pairs through contrastive pretraining. The release of extensive English image-text datasets has enabled widespread adoption of models such as CLIP and SigLIP in tasks including cross-modal retrieval and image captioning. However, the advancement of Chinese vision-language pretraining has substantially lagged behind, due to the scarcity of high-quality Chinese image-text data. To address this gap, we develop a comprehensive pipeline for constructing a high-quality Chinese cross-modal dataset. As a result, we propose DanQing, which contains 100 million image-text pairs collected from Common Crawl. Different from existing datasets, DanQing is curated through a more rigorous selection process, yielding superior data quality. Moreover, DanQing is primarily built from 2024–2025 web data, enabling models to better capture evolving semantic trends and thus offering greater practical utility. We compare DanQing with existing datasets by continual pre-training of the SigLIP2 model. Experimental results show that DanQing consistently achieves superior performance across a range of Chinese downstream tasks, including zero-shot classification, cross-modal retrieval, and LMM-based evaluations. To facilitate further research in Chinese vision-language pre-training, we will open-source the DanQing dataset under the Creative Common CC-BY 4.0 license.",3.88,121.028,470,cold_start,Phi-4,Apple_M1(Metal)
2601.10306v1_Evidence-Augmented Policy Optimization with Reward.pdf,Evidence-Augmented Policy Optimization with Reward Co-Evolution for Long-Context Reasoning,"Xin Guan, Zijian Li, Shen Huang, Pengjun Xie, Jingren Zhou, Jiuxin Cao",,,"Reinforcement Learning, LLM reasoning, long-context scenarios, evidence retrieval, reward model, policy optimization, reward co-evolution","Reinforcement Learning (RL) has advanced LLM reasoning, but applying it to long-context scenarios is hindered by sparse outcome rewards, which fail to penalize ungrounded 'lucky guesses.' This paper proposes Evidence-Augmented Policy Optimization (EAPO) to address this by introducing a specialized RL algorithm with a reward model that computes a Group-Relative Evidence Reward. This provides dense process supervision to improve evidence quality. An Adaptive Reward-Policy Co-Evolution mechanism refines the reward model using outcome-consistent rollouts, enhancing its discriminative capability for precise process guidance. Evaluations across eight benchmarks show that EAPO significantly enhances long-context reasoning performance compared to SOTA baselines.",3.36,83.141,279,cold_start,Phi-4,Apple_M1(Metal)
2601.10338v1_Agent Skills in the Wild An Empirical Study of Sec.pdf,Agent Skills in the Wild: An Empirical Study of Security Vulnerabilities at Scale,"Yi Liu, Weizhe Wang, Ruitao Feng, Yao Zhang, Guangquan Xu, Gelei Deng, Yuekang Li, Leo Zhang",10.1145/nnnnnnn.nnnnnnn,,"Agent skills, AI security, vulnerability analysis, supply chain security, prompt injection, large language models","The rise of AI agent frameworks has introduced agent skills—modular packages containing instructions and executable code that dynamically extend agent capabilities. While this architecture enables powerful customization, skills execute with implicit trust and minimal vetting, creating a significant yet uncharacterized attack surface. This study conducts the first large-scale empirical security analysis of this emerging ecosystem, collecting 42,447 skills from two major marketplaces and systematically analyzing 31,132 using SkillScan, a multi-stage detection framework integrating static analysis with LLM-based semantic classification. Findings reveal pervasive security risks: 26.1% of skills contain at least one vulnerability, spanning 14 distinct patterns across four categories—prompt injection, data exfiltration, privilege escalation, and supply chain risks. Data exfiltration (13.3%) and privilege escalation (11.8%) are most prevalent, while 5.2% of skills exhibit high-severity patterns strongly suggesting malicious intent. Skills bundling executable scripts are 2.12× more likely to contain vulnerabilities than instruction-only skills. Contributions include a grounded vulnerability taxonomy derived from 8,126 vulnerable skills, a validated detection methodology achieving 86.7% precision and 82.5% recall, and an open dataset and detection toolkit to support future research. These results demonstrate an urgent need for capability-based permission systems and mandatory security vetting before this attack vector is further exploited.",3.76,115.566,434,cold_start,Phi-4,Apple_M1(Metal)
2601.10342v1_C-GRASP Clinically-Grounded Reasoning for Affectiv.pdf,C-GRASP: Clinically-Grounded Reasoning for Affective Signal Processing,"Cheng Lin Cheng, Ting Chuan Lin, Chai Kai Chang",,,"Large language model, clinical decision support, heart rate variability, retrieval-augmented generation, explainable AI, guardrails","Heart rate variability (HRV) is a pivotal non-invasive marker for autonomic monitoring; however, applying Large Language Models (LLMs) to HRV interpretation is hindered by physiological hallucinations, where models struggle with respiratory sinus arrhythmia (RSA) contamination, short-data instability in nonlinear metrics, and the neglect of individualized baselines in favor of population norms. We propose C-GRASP (Clinically-Grounded Reasoning for Affective Signal Processing), a guardrailed RAG-enhanced pipeline that decomposes HRV interpretation into eight traceable reasoning steps. Central to C-GRASP is a Z-score Priority Hierarchy that enforces the weighting of individualized baseline shifts over normative statistics. The system effectively mitigates spectral hallucinations through automated RSA-aware guardrails, preventing contamination of frequency-domain indices. Evaluated on 414 trials from the DREAMER dataset, C-GRASP integrated with high-scale reasoning models (e.g., MedGemma3-thinking) achieved superior performance in 4-class emotion classification (37.3% accuracy) and achieved a Clinical Reasoning Consistency (CRC) score of 69.6%. Ablation studies confirm that the individualized Delta Z-score module serves as the critical logical anchor, preventing the 'population bias' common in native LLMs. Ultimately, C-GRASP transitions affective computing from black-box classification to transparent, evidence-based clinical decision support, paving the way for safer AI integration in biomedical engineering.",3.84,108.458,417,cold_start,Phi-4,Apple_M1(Metal)
2601.10343v2_OctoBench Benchmarking Scaffold-Aware Instruction .pdf,OCTOBENCH: Benchmarking Scaffold-Aware Instruction Following in Repository-Grounded Agentic Coding,"Deming Ding, Shichun Liu, Enhui Yang, Jiahang Lin, Ziying Chen, Shihan Dou, Honglin Guo, Weiyu Cheng, Pengyu Zhao, Chengjun Xiao, Qunhong Zeng, Qi Zhang, Xuanjing Huang, Qidi Xu, Tao Gui",,,"LLMs, software agents, instruction following, scaffolds, repository-grounded coding, benchmarking","Modern coding scaffolds turn LLMs into capable software agents, but their ability to follow scaffold-specified instructions remains under-examined, especially when constraints are heterogeneous and persist across interactions. To fill this gap, we introduce OCTOBENCH, which benchmarks scaffold-aware instruction following in repository-grounded agentic coding. OCTOBENCH includes 34 environments and 217 tasks instantiated under three scaffold types, and is paired with 7,098 objective checklist items. To disentangle solving the task from following the rules, we provide an automated observation-and-scoring toolkit that captures full trajectories and performs fine-grained checks. Experiments on eight representative models reveal a systematic gap between task-solving and scaffold-aware compliance, underscoring the need for training and evaluation that explicitly targets heterogeneous instruction following. We release the benchmark to support reproducible benchmarking and to accelerate the development of more scaffold-aware coding agents.",3.49,96.455,337,cold_start,Phi-4,Apple_M1(Metal)
2601.10348v1_Training-Trajectory-Aware Token Selection.pdf,Training-Trajectory-Aware Token Selection,"Zhanming Shen, Jiaqi Hu, Zeyu Qin, Hao Chen, Wentao Ye, Zenan Huang, Yihong Zhuang, Guoshan Lu, Junlin Zhou, Junbo Zhao",,,"distillation, large language models, reasoning capability, token selection, optimization, performance metrics","Efficient distillation is crucial for converting expensive reasoning capabilities into deployable efficiency. In scenarios where the student model already possesses strong reasoning abilities, naive continual distillation often results in limited improvements or even performance degradation. This paper observes a phenomenon where, despite a monotonic decrease in loss, performance metrics sharply decline at a bottleneck before gradually recovering. A token-level mechanism is identified, where confidence bifurcates into steadily increasing 'Imitation-Anchor Tokens' and other tokens whose confidence is suppressed until after the bottleneck. The inability of these two types of tokens to coexist is identified as the root cause of failure in continual distillation. The proposed Training-Trajectory-Aware Token Selection (T3S) reconstructs the training objective at the token level, facilitating optimization for yet-to-learn tokens. T3S demonstrates consistent gains in both AR and dLLM settings, with Qwen3-8B surpassing DeepSeek-R1 on competitive reasoning benchmarks, Qwen3-32B approaching Qwen3-235B, and T3-trained LLaDA-2.0-Mini exceeding its AR baseline, achieving state-of-the-art performance among 16B-scale no-think models.",3.57,108.599,388,cold_start,Phi-4,Apple_M1(Metal)
2601.10349v1_SuS Strategy-aware Surprise for Intrinsic Explorat.pdf,Strategy-aware Surprise for Intrinsic Exploration,"Mark Kashirskiy, Ilya Makarov",,,"intrinsic motivation, reinforcement learning, contrastive learning, exploration","We propose Strategy-aware Surprise (SuS), a novel intrinsic motivation framework that uses pre-post prediction mismatch as a novelty signal for exploration in reinforcement learning. Unlike traditional curiosity-driven methods that rely solely on state prediction error, SuS introduces two complementary components: Strategy Stability (SS) and Strategy Surprise (SuS). SS measures consistency in behavioral strategy across temporal steps, while SuS captures unexpected outcomes relative to the agent’s current strategy representation. Our combined reward formulation leverages both signals through learned weighting coefficients. We evaluate SuS on mathematical reasoning tasks using large language models, demonstrating significant improvements in both accuracy and solution diversity. Ablation studies confirm that removing either component results in at least 10% performance degradation, validating the synergistic nature of our approach. SuS achieves 17.4% improvement in Pass@1 and 26.4% improvement in Pass@5 compared to baseline methods, while maintaining higher strategy diversity throughout training.",3.57,76.534,273,cold_start,Phi-4,Apple_M1(Metal)
2601.10373v1_Towards Efficient Low-rate Image Compression with .pdf,Towards Efficient Low-rate Image Compression with Frequency-aware Diffusion Prior Refinement,"Yichong Xia, Yimin Zhou, Jinpeng Wang, Bin Chen",,,"image compression, diffusion-based generative priors, low bit rates, Frequency-aware Skip Estimation, Frequency Decoupling Attention, semantic trajectory, perceptual quality","Recent advancements in diffusion-based generative priors have enabled visually plausible image compression at extremely low bit rates. However, existing approaches suffer from slow sampling processes and suboptimal bit allocation due to fragmented training paradigms. This work proposes AccelerateDiffusion-based Image Compression via Consistency PriorRefinement (DiffCR), a novel compression framework for efficient and high-fidelity image reconstruction. The core of DiffCR is a Frequency-aware Skip Estimation (FaSE) module that refines the ϵ-prediction prior from a pre-trained latent diffusion model and aligns it with compressed latents at different timesteps via Frequency Decoupling Attention (FDA). A lightweight consistency estimator enables fast two-step decoding by preserving the semantic trajectory of diffusion sampling. Without updating the backbone diffusion model, DiffCR achieves substantial bitrate savings (27.2% BD-rate (LPIPS) and 65.1% BD-rate (PSNR)) and over 10× speed-up compared to SOTA diffusion-based compression baselines.",3.46,95.715,331,cold_start,Phi-4,Apple_M1(Metal)
2601.10378v2_Global Context Compression with Interleaved Vision.pdf,Global Context Compression with Interleaved Vision-Text Transformation,"Dian Jiao, Jiaxin Duan, Shuai Zhao, Jiabing Leng, Yiran Zhang, Feng Huang",,,"vision-language models, OCR, Transformer, context compression, visual encoding, attention computations, computational costs, memory usage, FLOPS, hierarchical encoding, sparse attention, optical character recognition","This paper explores global context compression in vision-language models to reduce computational and memory costs. The proposed VIST2 Transformer interleaves text chunks with their visual encoding, using visual tokens for prediction. The model achieves significant improvements in speed, memory usage, and FLOPS, demonstrating its effectiveness in long writing tasks. The study includes extensive experiments with models scaled from 0.6B to 8B, highlighting the benefits of curriculum-scheduled pretraining and modal-interleaved instruction tuning.",3.34,76.155,254,cold_start,Phi-4,Apple_M1(Metal)
2601.10386v1_Handling Missing Modalities in Multimodal Survival.pdf,Handling Missing Modalities in Multimodal Survival Prediction for Non-Small Cell Lung Cancer,"Filippo Ruffini, Camillo Maria Caruso, Claudia Tacconi, Lorenzo Nibid, Francesca Miccolis, Marta Lovino, Carlo Greco, Edy Ippolito, Michele Fiore, Alessio Cortellini, Bruno Beomonte Zobel, Giuseppe Perrone, Bruno Vincenzi, Claudio Marrocco, Alessandro Bria, Elisa Ficarra, Sara Ramella, Valerio Guarrasi, Paolo Soda",,arXiv:2601.10386v1,cs.CV,,3.7,61.661,228,cold_start,Phi-4,Apple_M1(Metal)
2601.10398v2_LatentRefusal Latent-Signal Refusal for Unanswerab.pdf,LatentRefusal: Latent-Signal Refusal for Unanswerable Text-to-SQL Queries,"Xuancheng Ren, Shijing Hu, Zhihui Lu, Jiangqi Huang, Qiang Duan",,,"Text-to-SQL, Large Language Models, Safety, Refusal Mechanism, Latent-Signal, LLM-based Systems","In LLM-based Text-to-SQL systems, unanswerable and underspecified user queries may generate incorrect text and executable programs that yield misleading results or violate safety constraints, posing a major barrier to safe deployment. Existing refusal strategies either rely on brittle output-level instruction following or add complexity by estimating output uncertainty. This paper introduces LATENTREFUSAL, a latent-signal refusal mechanism that predicts query answerability from intermediate hidden activations of an LLM. The proposed Tri-Residual Gated Encoder (TRGE) architecture suppresses schema noise and amplifies mismatch cues indicating unanswerability. Empirical evaluations demonstrate LATENTREFUSAL's effectiveness as an efficient safety layer, improving average F1 to 88.5% across benchmarks with minimal probe overhead.",3.42,83.31,285,cold_start,Phi-4,Apple_M1(Metal)
2601.10402v1_Toward Ultra-Long-Horizon Agentic Science Cognitiv.pdf,Toward Ultra-Long-Horizon Agentic Science: Cognitive Accumulation for Machine Learning Engineering,"Xinyu Zhu, Yuzhu Cai, Zexi Liu, Bingyang Zheng, Cheng Wang, Rui Ye, Jiaao Chen, Hanrui Wang, Wei-Chen Wang, Yuzhi Zhang, Linfeng Zhang, Weinan E, Di Jin, Siheng Chen",,arXiv:2601.10402v1,"artificial intelligence, ultra-long-horizon autonomy, machine learning engineering, cognitive accumulation, Hierarchical Cognitive Caching, ML-Master 2.0, MLE-Bench","The advancement of artificial intelligence toward agentic science is currently bottlenecked by the challenge of ultra-long-horizon autonomy, the ability to sustain strategic coherence and iterative correction over experimental cycles spanning days or weeks. While Large Language Models (LLMs) have demonstrated prowess in short-horizon reasoning, they are easily overwhelmed by execution details in high-dimensional, delayed-feedback environments of real-world research, failing to consolidate sparse feedback into coherent long-term guidance. Here, we present ML-Master 2.0, an autonomous agent that masters ultra-long-horizon machine learning engineering (MLE), a representative microcosm of scientific discovery. By reframing context management as a process of cognitive accumulation, our approach introduces Hierarchical Cognitive Caching (HCC), a multi-tiered architecture inspired by computer systems that enables the structural differentiation of experience over time. By dynamically distilling transient execution traces into stable knowledge and cross-task wisdom, HCC allows agents to decouple immediate execution from long-term experimental strategy, effectively overcoming the scaling limits of static context windows. In evaluations on OpenAI’s MLE-Bench under 24-hour budgets, ML-Master 2.0 achieves a state-of-the-art medal rate of 56.44%. Our findings demonstrate that ultra-long-horizon autonomy provides a scalable blueprint for AI capable of autonomous exploration beyond human-precedent complexities.",3.9,125.351,489,cold_start,Phi-4,Apple_M1(Metal)
2601.10406v1_ErrEval Error-Aware Evaluation for Question Genera.pdf,ErrEval: Error-Aware Evaluation for Question Generation through Explicit Diagnostics,"Weiping Fu, Bifan Wei, Jingyi Hao, Yushun Zhang, Jian Zhang, Jiaxin Wang, Bo Li, Yu He, Lingling Zhang, Jun Liu",,,"Question Generation, Evaluation, Error Diagnosis, Natural Language Generation, LLM Evaluators","Automatic Question Generation (QG) often produces outputs with critical defects, such as factual hallucinations and answer mismatches. Existing evaluation methods, including LLM-based evaluators, mainly adopt a black-box and holistic paradigm without explicit error modeling, leading to the neglect of such defects and overestimation of question quality. To address this issue, we propose ErrEval, a flexible and Error-aware Evaluation framework that enhances QG evaluation through explicit error diagnostics. Specifically, ErrEval reformulates evaluation as a two-stage process of error diagnosis followed by informed scoring. At the first stage, a lightweight plug-and-play Error Identifier detects and categorizes common errors across structural, linguistic, and content-related aspects. These diagnostic signals are then incorporated as explicit evidence to guide LLM evaluators toward more fine-grained and grounded judgments. Extensive experiments on three benchmarks demonstrate the effectiveness of ErrEval, showing that incorporating explicit diagnostics improves alignment with human judgments. Further analyses confirm that ErrEval effectively mitigates the overestimation of low-quality questions.",3.55,89.564,318,cold_start,Phi-4,Apple_M1(Metal)
2601.10413v1_LADFA A Framework of Using Large Language Models a.pdf,LADFA: A Framework of Using Large Language Models and Retrieval-Augmented Generation for Personal Data Flow Analysis in Privacy Policies,"Haiyue Yuan, Nikolay Matyunin, Ali Raza, Shujun Li",https://doi.org/XXXXXXX.XXXXXXX,,"Large Language Model, LLM, Privacy Policy, Text Analysis, Data Flows, Privacy, Security, Retrieval-Augmented Generation, RAG, Framework, Automotive Industry, Connected Vehicle","Privacy policies often use complex legal language, making them difficult to comprehend. This paper introduces LADFA, a computational framework that uses large language models (LLMs) and retrieval-augmented generation (RAG) to analyze personal data flows in privacy policies. The framework processes unstructured text to extract data flows and construct a data flow graph, facilitating insight discovery. It consists of a pre-processor, an LLM-based processor, and a data flow post-processor. The effectiveness and accuracy of LADFA were validated through a case study on ten privacy policies from the automotive industry. The framework is designed to be flexible and customizable for various text-based analysis tasks.",3.59,84.674,304,cold_start,Phi-4,Apple_M1(Metal)
2601.10416v1_LLMdoctor Token-Level Flow-Guided Preference Optim.pdf,LLMdoctor: Token-Level Flow-Guided Preference Optimization for Efficient Test-Time Alignment of Large Language Models,"Tiesunlong Shen, Rui Mao, Jin Wang, Heming Sun, Jian Zhang, Xuejie Zhang, Erik Cambria",,,"Large Language Models, test-time alignment, preference optimization, token-level reward, flow-guided preference optimization","Aligning Large Language Models (LLMs) with human preferences is critical, yet traditional fine-tuning methods are computationally expensive and inflexible. This paper introduces LLMdoctor, a novel framework for efficient test-time alignment that operates via a patient-doctor paradigm. It integrates token-level reward acquisition with token-level flow-guided preference optimization (TFPO) to steer a large, frozen patient LLM with a smaller, specialized doctor model. Unlike conventional methods that rely on trajectory-level rewards, LLMdoctor extracts fine-grained, token-level preference signals from the patient model’s behavioral variations. These signals guide the training of the doctor model via TFPO, establishing flow consistency across all subtrajectories, enabling precise token-by-token alignment while preserving generation diversity. Extensive experiments demonstrate that LLMdoctor significantly outperforms existing test-time alignment methods and even surpasses the performance of full fine-tuning approaches like DPO.",3.48,92.443,322,cold_start,Phi-4,Apple_M1(Metal)
2601.10421v1_Are Language Models Models.pdf,Are Language Models Models?,Philip Resnik,http://doi.org/10.1017/S0140525X2510112X,,"Language Models, Cognitive Models, Marr’s Levels, Linguistics, LMs as Tools","Futrell and Mahowald claim LMs 'serve as model systems', but an assessment at each of Marr’s three levels suggests the claim is clearly not true at the implementation level, poorly motivated at the algorithmic-representational level, and problematic at the computational theory level. LMs are good candidates as tools; calling them cognitive models overstates the case and unnecessarily feeds LLM hype.",4.0,39.956,160,cold_start,Phi-4,Apple_M1(Metal)
2601.10436v1_Development of Ontological Knowledge Bases by Leve.pdf,Development of Ontological Knowledge Bases by Leveraging Large Language Models,"LE Ngoc Luyen, Marie-Hélène ABEL, Philippe GOUSPILLOU",,,"Ontology Development, Ontological Knowledge bases, Large Language Models, Knowledge Representation, User Modeling, Knowledge Management","Ontological Knowledge Bases (OKBs) play a vital role in structuring domain-specific knowledge and serve as a foundation for effective knowledge management systems. However, their traditional manual development poses significant challenges related to scalability, consistency, and adaptability. Recent advancements in Generative AI, particularly Large Language Models (LLMs), offer promising solutions for automating and enhancing OKB development. This paper introduces a structured, iterative methodology leveraging LLMs to optimize knowledge acquisition, automate ontology artifact generation, and enable continuous refinement cycles. We demonstrate this approach through a detailed case study focused on developing a user context profile ontology within the vehicle sales domain. Key contributions include significantly accelerated ontology construction processes, improved ontological consistency, effective bias mitigation, and enhanced transparency in the ontology engineering process. Our findings highlight the transformative potential of integrating LLMs into ontology development, notably improving scalability, integration capabilities, and overall efficiency in knowledge management systems.",3.92,70.589,277,cold_start,Phi-4,Apple_M1(Metal)
2601.10440v1_AgentGuardian Learning Access Control Policies to .pdf,AGENTGUARDIAN: Learning Access Control Policies to Govern AI Agent Behavior,"Nadya Abaev, Denis Klimov, Gerard Levinov, David Mimran, Yuval Elovici, Asaf Shabtai",,,"Security, AI Agents, Access Control Policies, Control Flow Graph","Artificial intelligence (AI) agents are increasingly used in various domains to automate tasks, interact with users, and make decisions based on data inputs. Ensuring that AI agents perform only authorized actions and handle inputs appropriately is essential for maintaining system integrity and preventing misuse. This study introduces AgentGuardian, a novel security framework that governs and protects AI agent operations by enforcing context-aware access-control policies. The framework monitors execution traces during a controlled staging phase to learn legitimate agent behaviors and input patterns, deriving adaptive policies that regulate tool calls made by the agent. Evaluation across two real-world AI agent applications demonstrates that AgentGuardian effectively detects malicious or misleading inputs while preserving normal agent functionality. Its control-flow-based governance mechanism mitigates hallucination-driven errors and other orchestration-level malfunctions.",3.55,71.176,253,cold_start,Phi-4,Apple_M1(Metal)
2601.10457v1_NSR-Boost A Neuro-Symbolic Residual Boosting Frame.pdf,NSR-Boost: A Neuro-Symbolic Residual Boosting Framework for Industrial Legacy Models,"Ziming Dai, Dabiao Ma, Jinle Tong, Mengyuan Han, Jian Yang, Haojun Fei",https://doi.org/10.1145/nnnnnnn.nnnnnnn,,"Neuro-Symbolic AI, Large Language Models, Gradient Boosting, Legacy Model, Interpretability","Although Gradient Boosted Decision Trees (GBDTs) dominate industrial tabular applications, upgrading legacy models in high-concurrency production environments faces prohibitive retraining costs and systemic risks. To address this, the NSR-Boost framework is introduced, designed specifically for industrial scenarios. It is non-intrusive, treating the legacy model as a frozen model and performing targeted repairs on 'hard regions' where predictions fail. The framework comprises three key stages: finding hard regions through residuals, generating interpretable experts by generating symbolic code structures using Large Language Models (LLM) and fine-tuning parameters using Bayesian optimization, and dynamically integrating experts with legacy model output through a lightweight aggregator. NSR-Boost has been successfully deployed within the core financial risk control system at Qfin Holdings, significantly outperforming state-of-the-art baselines across datasets and showing excellent performance gains on real-world online data. It effectively captures long-tail risks missed by traditional models and offers a safe, low-cost evolutionary paradigm for industry.",3.66,96.283,352,cold_start,Phi-4,Apple_M1(Metal)
2601.10460v1_Contextual StereoSet Stress-Testing Bias Alignment.pdf,Contextual StereoSet: Stress-Testing Bias Alignment Robustness in Large Language Models,"Abhinaba Basu, Pavan Chakraborty",,2601.10460v1,"bias evaluation, alignment robustness, stress-testing, large language models, sociotechnical context, StereoSet","This paper introduces Contextual StereoSet, a benchmark designed to test the robustness of bias alignment in large language models by varying contextual framing while keeping stereotype content fixed. The study reveals that bias shifts significantly with changes in context, such as different places, times, or audiences, without the need for adversarial prompting. The research tested 13 models and found consistent patterns, such as increased stereotype selection when anchored to 1990 compared to 2030, and variations in framing. The paper proposes Context Sensitivity Fingerprints (CSF) to profile bias under different conditions and suggests that fixed-condition bias scores may not generalize. The findings emphasize the need for evaluators to consider the conditions under which bias appears, rather than simply assessing if a model is biased.",3.8,71.076,270,cold_start,Phi-4,Apple_M1(Metal)
2601.10462v3_ChartComplete A Taxonomy-based Inclusive Chart Dat.pdf,ChartComplete: A Taxonomy-based Inclusive Chart Dataset,"Ahmad Mustapha, Charbel Toumieh, Mariette Awad",,2601.10462v3,"Chart, Dataset, Chart Taxonomy, Chart Classification","With advancements in deep learning (DL) and computer vision techniques, the field of chart understanding is evolving rapidly. Multi-modal large language models (MLLMs) are proving to be efficient and accurate in understanding charts. To accurately measure the performance of MLLMs, the research community has developed multiple datasets to serve as benchmarks. However, these datasets are limited to a small set of chart types. To bridge this gap, the ChartComplete dataset is proposed, based on a chart taxonomy borrowed from the visualization community, covering thirty different chart types. The dataset is a collection of classified chart images without a learning signal, presented to the community for further development. The dataset aims to support a broader range of chart types for more inclusive benchmarks in ChartQA, a research domain where machines are designed to have a visual understanding of chart elements.",3.49,70.128,245,cold_start,Phi-4,Apple_M1(Metal)
2601.10477v1_Urban Socio-Semantic Segmentation with Vision-Lang.pdf,URBANSOCIO-SEMANTICSEGMENTATION WITH VISION-LANGUAGEREASONING,"Yu Wang, Yi Wang, Rui Dai, Yujie Wang, Kaikui Liu, Xiangxiang Chu, Yansheng Li",,,"urban socio-semantic segmentation, vision-language reasoning, satellite imagery, social semantic entities, cross-modal recognition, reinforcement learning","This work introduces a novel approach to socio-semantic segmentation of urban surfaces using vision-language model reasoning. The authors present the Urban Socio-Semantic Segmentation dataset, SocioSeg, which includes satellite imagery, digital maps, and pixel-level labels of social semantic entities. They propose a vision-language reasoning framework, SocioReasoner, that simulates human identification and annotation processes through cross-modal recognition and multi-stage reasoning. Reinforcement learning is employed to optimize this non-differentiable process, enhancing the reasoning capabilities of the vision-language model. The approach demonstrates significant improvements over state-of-the-art models and exhibits strong zero-shot generalization. The dataset and code are available on GitHub.",3.53,80.494,284,cold_start,Phi-4,Apple_M1(Metal)
2601.10485v1_Panning for Gold Expanding Domain-Specific Knowled.pdf,Panning for Gold: Expanding Domain-Specific Knowledge Graphs with General Knowledge,"Runhao Zhao, Weixin Zeng, Wentao Zhang, Chong Chen, Zhengpin Li, Xiang Zhao, Lei Chen",,,"Domain-specific Knowledge Graph Fusion, Knowledge Graph Enrichment, General-to-domain Knowledge Transfer, Fact-as-Program","Domain-specific knowledge graphs (DKGs) are essential for supporting intelligent applications in specialized fields, yet they often suffer from limited coverage and incompleteness compared to general knowledge graphs (GKGs) such as Wikipedia and YAGO. Existing tasks to enrich DKGs rely primarily on extracting knowledge from unstructured data or completing KGs through internal reasoning, but the scope and quality of such integration remain limited. This highlights a critical gap: little systematic exploration has been conducted on how comprehensive, high-quality GKGs can be effectively leveraged to supplement DKGs. To address this gap, we propose a new and practical task: domain-specific knowledge graph fusion (DKGF), which aims to mine and integrate relevant facts from general knowledge graphs into domain-specific knowledge graphs to enhance their completeness and utility. Unlike previous research, this new task faces two key challenges: high ambiguity of domain relevance, i.e., difficulty in determining whether knowledge from a GKG is truly relevant to the target domain, and cross-domain knowledge granularity misalignment, i.e., GKG facts are typically abstract and coarse-grained, whereas DKGs frequently require more contextualized, fine-grained representations aligned with particular domain scenarios. To tackle these challenges, we propose ExeFuse, a simple yet effective Fact-as-Program paradigm that reformulates DKGF as executable semantic reasoning over DKGs. Specifically, ExeFuse interprets each GKG fact as a latent semantic program, maps abstract relations to granularity-aware operators, and verifies domain relevance through program executability on the target DKG. By unifying relevance assessment and granularity transformation within a single probabilistic framework, ExeFuse enables precise identification and integration of domain-relevant, consistent knowledge from GKGs. We construct two new benchmark datasets (DKGF(W-I) and DKGF(Y-I)) and propose 21 representative benchmark configurations to systematically assess DKGF performance. Extensive experiments highlight the value of the new task and demonstrate the effectiveness of ExeFuse, providing the first standardized evaluation suite for this emerging task. The source codes and datasets are available at https://github.com/eduzrh/DKGF_benchmark.",4.02,140.17,563,cold_start,Phi-4,Apple_M1(Metal)
2601.10496v1_Model See Model Do Exposure-Aware Evaluation of Bu.pdf,"Model See, Model Do? Exposure-Aware Evaluation of Bug-vs-Fix Preference in Code LLMs","Ali Al-Kaswan, Claudio Spiess, Prem Devanbu, Arie van Deursen, Maliheh Izadi",https://doi.org/10.1145/nnnnnnn.nnnnnnn,,"Large Language Models, bugs, fixes, Memorisation","Large language models are increasingly used for code generation and debugging, but their outputs can still contain bugs that originate from training data. This study introduces an exposure-aware evaluation framework to quantify how prior exposure to buggy versus fixed code influences a model’s preference. Using the ManySStuBs4J benchmark and Data Portraits for membership testing on the Stack-V2 corpus, the study estimates whether each buggy and fixed variant was seen during training. The results show that most examples have neither variant in the training data, and when only one is present, fixes are more frequently present than bugs. Models tend to reproduce buggy lines more often than fixes, with bug-exposed examples amplifying this tendency. Likelihood scoring metrics like minimum and maximum token-probability consistently prefer the fixed code, indicating a stable bias toward correct fixes. The study highlights the risk that LLMs may propagate memorised errors in practice.",3.59,89.216,320,cold_start,Phi-4,Apple_M1(Metal)
2601.10498v1_Projected Microbatch Accumulation yields reference.pdf,Projected Microbatch Accumulation yields reference-free proximal policy updates for reinforcement learning,Nilin Abrahamsen,,2601.10498v1,"reinforcement learning, proximal policy updates, large language model fine-tuning, PROMA, PPO, GRPO, policy gradients, local KL divergence","This note introduces Projected Microbatch Accumulation (PROMA), a proximal policy update method for large language model fine-tuning. PROMA accumulates policy gradients across microbatches by projecting out sequence-wise gradient components before microbatch aggregation. The projection is applied layer-wise during the backward pass, enabling efficient implementation without additional forward or backward passes. Empirically, PROMA enforces tighter control of local KL divergence than GRPO, resulting in more stable policy learning. Unlike PPO and GRPO, PROMA achieves proximal updates without inducing entropy collapse and does not rely on a reference policy or likelihood-ratio clipping.",3.25,71.663,233,cold_start,Phi-4,Apple_M1(Metal)
2601.10511v1_Scalable Algorithms for Approximate DNF Model Coun.pdf,Scalable Algorithms for Approximate DNF Model Counting,"Paul Burkhardt, David G. Harris, Kevin T. Schmitt",,arXiv:2601.10511v1,"DNF Model Counting, Monte Carlo, Probabilistic Inference, Network Reliability, Probabilistic Databases, Probabilistic Programming, AI Explainability, Hardware Verification, Network Reliability Analysis","Model counting of Disjunctive Normal Form (DNF) formulas is a critical problem in applications such as probabilistic inference and network reliability. Due to the computational intractability of exact DNF counting, there has been research into approximation algorithms, including Monte Carlo approaches and methods based on hashing and neural nets. This paper develops a new Monte Carlo approach with an adaptive stopping rule and short-circuit formula evaluation, proving it achieves Probably Approximately Correct (PAC) learning bounds and is asymptotically more efficient than previous methods. Experimental results show it outperforms prior algorithms significantly and can scale to larger problems with millions of variables.",3.71,73.309,272,cold_start,Phi-4,Apple_M1(Metal)
2601.10512v2_SatMap Revisiting Satellite Maps as Prior for Onli.pdf,SatMap: Revisiting Satellite Maps as Prior for Online HD Map Construction,"Kanak Mazumder, Fabian B. Flohr",,arXiv:2601.10512v2,"Online HD map prediction, Satellite map prior, Vectorized HD map","Online high-definition (HD) map construction is essential for a safe and robust autonomous driving (AD) pipeline. Onboard camera-based approaches suffer from limited depth perception and degraded accuracy due to occlusion. This work proposes SatMap, an online vectorized HD map estimation method that integrates satellite maps with multi-view camera observations to predict a vectorized HD map for downstream prediction and planning modules. The method leverages lane-level semantics and texture from satellite imagery captured from a Bird’s Eye View (BEV) perspective as a global prior, effectively mitigating depth ambiguity and occlusion. Experiments on the nuScenes dataset show that SatMap achieves a 34.8% mAP performance improvement over the camera-only baseline and an 8.5% mAP improvement over the camera-LiDAR fusion baseline. The model is also evaluated in long-range and adverse weather conditions to demonstrate the advantages of using a satellite prior map.",3.81,76.294,291,cold_start,Phi-4,Apple_M1(Metal)
2601.10520v1_Breaking Up with Normatively Monolithic Agency wit.pdf,Breaking Up with Normatively Monolithic Agency with GRACE: A Reason-Based Neuro-Symbolic Architecture for Safe and Ethical AI Alignment,"Felix Jahn, Yannic Muskalla, Lisa Dargasz, Patrick Schramowski, Kevin Baum",,2601.10520v1,"AI alignment, neuro-symbolic architecture, normative reasoning, ethical AI, deontic logic, instrumental decision-making","As AI agents become increasingly autonomous and impactful, ensuring their decisions are normatively aligned is critical. This paper introduces GRACE, a neuro-symbolic reason-based containment architecture that decouples normative reasoning from instrumental decision-making. GRACE consists of three modules: a Moral Module (MM) for determining permissible actions via deontic logic, a Decision-Making Module (DMM) for selecting optimal actions, and a Guard for enforcing moral compliance. The architecture enhances interpretability, contestability, and justifiability, and is demonstrated using a LLM therapy assistant example.",3.51,73.974,260,cold_start,Phi-4,Apple_M1(Metal)
2601.10524v1_Diagnosing Generalization Failures in Fine-Tuned L.pdf,Diagnosing Generalization Failures in Fine-Tuned LLMs: A Cross-Architectural Study on Phishing Detection,"Frank Bobe III, Gregory D. Vetaw, Chase Pavlick, Darshan Bryner, Matthew Cook, Jose Salas-Vernis",,arXiv:2601.10524v1,"Large Language Models, fine-tuning, generalization failures, phishing detection, SHAP analysis, mechanistic interpretability, LLM architecture, data diversity, AI security","The study introduces a multi-layered diagnostic framework to investigate generalization failures in fine-tuned Large Language Models (LLMs) on a phishing detection task. It fine-tunes Llama 3.1 8B, Gemma 2 9B, and Mistral models, using SHAP analysis and mechanistic interpretability to identify root causes of failures. Key findings include the importance of architecture and data diversity synergy, architecture-dependent generalization, and inherent generalizability of certain models. The study provides a methodology for diagnosing generalization failures, emphasizing the need for deep validation of architecture, data, and training strategy interplay.",3.69,82.365,304,cold_start,Phi-4,Apple_M1(Metal)
2601.10527v2_A Safety Report on GPT-5.2 Gemini 3 Pro Qwen3-VL G.pdf,"A Safety Report on GPT-5.2, Gemini 3 Pro, Qwen3-VL, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5","Xingjun Ma, Yixu Wang, Hengyuan Xu, Yutao Wu, Yifan Ding, Yunhan Zhao, Zilong Wang, Jiabin Hua, Ming Wen, Jianan Liu, Ranjie Duan, Yifeng Gao, Yingshui Tan, Yunhao Chen, Hui Xue, Xin Wang, Wei Cheng, Jingjing Chen, Zuxuan Wu, Bo Li, Yu-Gang Jiang",,arXiv:2601.10527v2,"Large Language Models, Multimodal Large Language Models, safety evaluation, adversarial evaluation, multilingual evaluation, compliance evaluation, benchmark evaluation","The rapid evolution of Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) has driven major gains in reasoning, perception, and generation across language and vision. Yet whether these advances translate into comparable improvements in safety remains unclear, partly due to fragmented evaluations that focus on isolated modalities or threat models. In this report, we present an integrated safety evaluation of six frontier models: GPT-5.2, Gemini 3 Pro, Qwen3-VL, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5. We evaluate each model across language, vision-language, and image generation settings using a unified protocol that integrates benchmark evaluation, adversarial evaluation, multilingual evaluation, and compliance evaluation. By aggregating results into safety leaderboards and model profiles, we reveal a highly uneven safety landscape. While GPT-5.2 demonstrates consistently strong and balanced performance, other models exhibit clear trade-offs across benchmark safety, adversarial robustness, multilingual generalization, and regulatory compliance. Despite achieving strong results under standard benchmark evaluations, all models remain highly vulnerable under adversarial testing, with worst-case safety rates dropping below 6%. Text-to-image models show slightly stronger alignment in regulated visual risk categories, yet they too remain fragile when faced with adversarial or semantically ambiguous prompts. Overall, the results highlight that safety in frontier models is inherently multidimensional—shaped by modality, language, and evaluation design—underscoring the need for standardized, holistic safety assessments to better reflect real-world risk and guide responsible deployment.",4.25,142.453,605,cold_start,Phi-4,Apple_M1(Metal)
2601.10543v1_Defending Large Language Models Against Jailbreak .pdf,Defending Large Language Models Against Jailbreak Attacks via In-Decoding Safety-Awareness Probing,"Yinzhi Zhao, Ming Wang, Shi Feng, Xiaocui Yang, Daling Wang, Yifei Zhang",,,"Large Language Models, Jailbreak Attacks, Safety Alignment, Decoding Process, Safety Signals, Content Detection","Large language models (LLMs) have shown impressive performance across various natural language tasks and are increasingly used in real-world applications. Despite efforts to align these models for safety, they remain vulnerable to jailbreak attacks. Current defense mechanisms, such as decoding-based constraints and post-hoc content detectors, often fail against sophisticated attacks or degrade model utility. This paper observes that even when jailbroken, LLMs exhibit latent safety-related signals during generation, which are overridden by the model's drive for fluent continuation. The authors propose a method to surface and leverage these latent safety signals for early detection of unsafe content during decoding. Experiments show that this approach enhances safety while maintaining low over-refusal rates on benign inputs and preserving response quality. The results suggest that activating intrinsic safety-awareness during decoding is a promising direction for defending against jailbreak attacks.",3.54,84.417,299,cold_start,Phi-4,Apple_M1(Metal)
2601.10560v1_Learning Latency-Aware Orchestration for Parallel .pdf,Learning Latency-Aware Orchestration for Parallel Multi-Agent Systems,"Xi Shi, Mengxin Zheng, Qian Lou",,,"Multi-Agent Systems, Latency-Aware Orchestration, Parallel Execution, Inference Latency, Machine Learning","Multi-agent systems (MAS) enable complex reasoning by coordinating multiple agents, but often incur high inference latency due to multi-step execution and repeated model invocations, severely limiting their scalability and usability in time-sensitive scenarios. Most existing approaches primarily optimize task performance and inference cost, and explicitly or implicitly assume sequential execution, making them less optimal for controlling latency under parallel execution. This work investigates the learning-based orchestration of multi-agent systems with explicit latency supervision under parallel execution. The proposed Latency-Aware Multi-agent System (LAMaS) framework enables parallel execution and explicitly optimizes the critical execution path, allowing the controller to construct execution topology graphs with lower latency under parallel execution. Experiments show that this approach reduces critical path length by 38–46% compared to the SOTA baseline for multi-agent architecture search across multiple benchmarks while maintaining or even improving task performance, highlighting the importance of explicitly optimizing for latency under parallel execution when designing efficient multi-agent systems.",3.58,78.199,280,cold_start,Phi-4,Apple_M1(Metal)
2601.10562v1_Process-Guided Concept Bottleneck Model.pdf,Process-Guided Concept Bottleneck Model,"Reza M. Asiyabi, Sam Harrison, John L. Godlee, David Milodowski, Nicole H. Augustin, Penelope J. Mograbi, Timothy R. Baker, Lorena M. Benitez, Samuel J. Bowers, Thomas K. Brade, Joao M. B. Carreiras, Duncan M. Chalo, Vera De Cauwer, Kyle G. Dexter, Hermane Diesse, Mathias I. Disney, Luisa F. Escobar-Alvarado, Manfred Finckh, Tatenda Gotore, Gabriele C. Hegerl, John N. Kigomo, Fainess C. Lumbwe, Francisco Maiato, Rudzani A. Makhado, Collins W. Masinde, Musingo Tito E. Mbuvi, Iain M. McNicol, Edward T.A. Mitchard, Buster P. Mogonong, Wilson A. Mugasha, Aristides Baptista Muhate, Hinji Mutondo, Leena Naftal, Paula Nieto-Quintano, Elifuraha Elisha Njoghomi, Catherine L. Parr, Oliver L. Phillips, Pierre Proces, Tshililo Ramaswiela, Jayashree Ratnam, Mathew Rees, Rasmus Revermann, Natasha Ribeiro, Mahesh Sankaran, Abel M. Siampale, Stephen Sitch, Kathleen G. Smart, Hemant G. Tripathi, Wayne Twine, Gabriel I.K. Uusiku, Helga van der Merwe, Chemuku Wekesa, Benjamin J. Wigley, Mathew Williams, Ellie Wood, Emily Woollen, Shaun Quegan, Steven Hancock, Casey M. Ryan",,,,"This study introduces a Process-Guided Concept Bottleneck Model, supported by various grants and partnerships. The research involves contributions from numerous authors and acknowledges the use of AI-assisted tools for manuscript preparation. Corresponding author: Reza M. Asiyabi (reza.asiyabi@ed.ac.uk).",3.77,165.678,624,cold_start,Phi-4,Apple_M1(Metal)
2601.10567v1_Generative AI collective behavior needs an interac.pdf,Generative AI collective behavior needs an interactionist paradigm,"Laura Ferrarotti, Gian Maria Campedelli, Roberto Dessì, Andrea Baronchelli, Giovanni Iacca, Kathleen M. Carley, Alex Pentland, Joel Z. Leibo, James Evans, Bruno Lepri",,2601.10567v1,cs.AI,"In this article, we argue that understanding the collective behavior of agents based on large language models (LLMs) is an essential area of inquiry, with important implications in terms of risks and benefits, impacting us as a society at many levels. We claim that the distinctive nature of LLMs–namely, their initialization with extensive pre-trained knowledge and implicit social priors, together with their capability of adaptation through in-context learning–motivates the need for an interactionist paradigm consisting of alternative theoretical foundations, methodologies, and analytical tools, in order to systematically examine how prior knowledge and embedded values interact with social context to shape emergent phenomena in multi-agent generative AI systems. We propose and discuss four directions that we consider crucial for the development and deployment of LLM-based collectives, focusing on theory, methods, and trans-disciplinary dialogue.",4.2,73.795,310,cold_start,Phi-4,Apple_M1(Metal)
2601.10581v1_From Single to Multi-Agent Reasoning Advancing Gen.pdf,From Single to Multi-Agent Reasoning: Advancing GeneGPT for Genomics QA,"Kimia Abedini, Farzad Shami, Gianmaria Silvello",,arXiv:2601.10581v1,"Question Answering, Genomic QA, Multi-Agent Systems","Comprehending genomic information is essential for biomedical research, yet extracting data from complex distributed databases remains challenging. Large language models (LLMs) offer potential for genomic Question Answering (QA) but face limitations due to restricted access to domain-specific databases. GeneGPT is the current state-of-the-art system that enhances LLMs by utilizing specialized API calls, though it is constrained by rigid API dependencies and limited adaptability. We replicate GeneGPT and propose GenomAgent, a multi-agent framework that efficiently coordinates specialized agents for complex genomics queries. Evaluated on nine tasks from the GeneTuring benchmark, GenomAgent outperforms GeneGPT by 12% on average, and its flexible architecture extends beyond genomics to various scientific domains needing expert knowledge extraction.",3.84,69.465,267,cold_start,Phi-4,Apple_M1(Metal)
2601.10587v1_Adversarial Evasion Attacks on Computer Vision usi.pdf,Adversarial Evasion Attacks on Computer Vision using SHAP Values,"Frank Mollard, Marcus Becker, Florian Röhrbein",,2601.10587v1,"adversarial attacks, computer vision, SHAP values, deep learning, misclassification, gradient hiding",The paper introduces a white-box attack on computer vision models using SHAP values. It demonstrates how adversarial evasion attacks can compromise the performance of deep learning models by reducing output confidence or inducing misclassifications. Such attacks are particularly insidious as they can deceive the perception of an algorithm while eluding human perception due to their imperceptibility to the human eye. The proposed attack leverages SHAP values to quantify the significance of individual inputs to the output at the inference stage. A comparison is drawn between the SHAP attack and the well-known Fast Gradient Sign Method. We find evidence that SHAP attacks are more robust in generating misclassifications particularly in gradient hiding scenarios.,4.13,54.908,227,cold_start,Phi-4,Apple_M1(Metal)
2601.10591v1_ProbFM Probabilistic Time Series Foundation Model .pdf,ProbFM: Probabilistic Time Series Foundation Model with Uncertainty Decomposition,"Arundeep Chinta, Lucas Vinh Tran, Jay Katukuri",,,"Time Series Foundation Models, zero-shot financial forecasting, uncertainty quantification, epistemic-aleatoric decomposition, Deep Evidential Regression, cryptocurrency return forecasting, uncertainty-aware trading strategies","Time Series Foundation Models (TSFMs) have shown promise in zero-shot financial forecasting due to their transferability and data efficiency. However, their adoption is limited by challenges in uncertainty quantification, such as restrictive distributional assumptions and lack of principled calibration. This paper introduces ProbFM, a transformer-based probabilistic framework that uses Deep Evidential Regression (DER) for principled uncertainty quantification with explicit epistemic-aleatoric decomposition. Unlike existing methods, ProbFM learns optimal uncertainty representations without pre-specified distributions or sampling-based inference, maintaining computational efficiency. A controlled comparison study using a consistent LSTM architecture across five probabilistic methods demonstrates DER's effectiveness. Evaluation on cryptocurrency return forecasting shows that DER maintains competitive accuracy while providing explicit uncertainty decomposition, enabling effective risk management through uncertainty-aware trading strategies. This work establishes a framework for principled uncertainty quantification in foundation models and provides empirical evidence for DER's effectiveness in financial applications.",3.7,86.29,319,cold_start,Phi-4,Apple_M1(Metal)
2601.10600v1_Procedural Fairness in Multi-Agent Bandits.pdf,Procedural Fairness in Multi-Agent Bandits,"Joshua Caiata, Carter Blair, Kate Larson",,2601.10600v1,"multi-agent multi-armed bandits, fairness, procedural fairness, equal decision-making power, psychology, economics, Rawlsian theory, multi-agent systems","In the context of multi-agent multi-armed bandits (MA-MAB), fairness is often reduced to outcomes such as maximizing welfare, reducing inequality, or balancing utilities. This paper introduces a new fairness objective, procedural fairness, which provides equal decision-making power for all agents, lies in the core, and ensures proportionality in outcomes. Empirical results show that outcome-based fairness notions sacrifice equal voice and representation, while the sacrifice in outcome-based fairness objectives is minimal under procedurally fair policies. The paper argues that procedural legitimacy deserves greater focus as a fairness objective and provides a framework for implementing procedural fairness.",3.63,68.348,248,cold_start,Phi-4,Apple_M1(Metal)
2601.10611v1_Molmo2 Open Weights and Data for Vision-Language M.pdf,Open Weights and Data for Vision-Language Models with Video Understanding and Grounding,"Christopher Clark, Jieyu Zhang, Zixian Ma, Jae Sung Park, Mohammadreza Salehi, Rohun Tripathi, Sangho Lee, Zhongzheng Ren, Chris Dongjoo Kim, Yinuo Yang, Vincent Shao, Yue Yang, Weikai Huang, Ziqi Gao, Taira Anderson, Jianrui Zhang, Jitesh Jain, George Stoica, Winson Han, Ali Farhadi, Ranjay Krishna",,arXiv:2601.10611v1,"cs.CV, video-language models, video understanding, grounding, open-source models, video datasets, image datasets, video captioning, video Q&A, object tracking, video pointing","Today’s strongest video-language models (VLMs) remain proprietary. The strongest open-weight models either rely on synthetic data from proprietary VLMs, effectively distilling from them, or do not disclose their training data or recipe. As a result, the open-source community lacks the foundations needed to improve on the state-of-the-art video (and image) language models. Crucially, many downstream applications require more than just high-level video understanding; they require grounding—either by pointing or by tracking in pixels. Even proprietary models lack this capability. We present Molmo2, a new family of VLMs that are state-of-the-art among open-source models and demonstrate exceptional new capabilities in point-driven grounding in single image, multi-image, and video tasks. Our key contribution is a collection of 7 new video datasets and 2 multi-image datasets, including a dataset of highly detailed video captions for pre-training, a free-form video Q&A dataset for fine-tuning, a new object tracking dataset with complex queries, and an innovative new video pointing dataset, all collected without the use of closed VLMs. We also present a training recipe for this data utilizing an efficient packing and message-tree encoding scheme, and show bi-directional attention on vision tokens and a novel token-weight strategy improves performance. Our best-in-class 8B model outperforms others in the class of open weight and data models on short videos, counting, and captioning, and is competitive on long-videos. On video-grounding Molmo2 significantly outperforms existing open-weight models like Qwen3-VL (35.5 vs 29.6 accuracy on video counting) and surpasses proprietary models like Gemini 3 Pro on some tasks (38.4 vs 20.0 F1 on video pointing and 56.2 vs 41.1J&F on video tracking).",4.21,155.263,653,cold_start,Phi-4,Apple_M1(Metal)
2601.10651v1_Multi-Property Synthesis.pdf,Multi-Property Synthesis,"Christoph Weinhuber, Yannik Schnitzer, Alessandro Abate, David Parker, Giuseppe De Giacomo, Moshe Y. Vardi",,,"LTLf synthesis, multiple properties, finite-horizon tasks, product-game states, goal sets, Boolean goal variables, monotonicity, symbolic algorithm, reactive synthesis, finite-trace variant, temporal specifications, over-subscription, multi-service orchestration, resource constraints","This paper studies LTLf synthesis with multiple properties, where satisfying all properties may be impossible. Instead of enumerating subsets of properties, a fixed-point computation is used to determine the relationship between product-game states and realizable goal sets, synthesizing strategies for maximal realizable sets. A fully symbolic algorithm with Boolean goal variables and monotonicity is developed, outperforming enumeration-based baselines with significant speedups. The paper contrasts the all-or-nothing paradigm of existing LTLf synthesis techniques with scenarios where agents face over-subscription, such as robotics and multi-service orchestration, where satisfying all goals simultaneously may be impossible.",3.55,85.579,304,cold_start,Phi-4,Apple_M1(Metal)
2601.10679v1_Are Your Reasoning Models Reasoning or Guessing A .pdf,Are Your Reasoning Models Reasoning or Guessing? A Mechanistic Analysis of Hierarchical Reasoning Models,"Zirui Ren, Ziming Liu",,,"Hierarchical reasoning model, reasoning tasks, fixed point property, data augmentation, input perturbation, model bootstrapping, Sudoku-Extreme, large language models, transformer architecture","Hierarchical reasoning models (HRM) significantly outperform large language model-based reasoners on various reasoning tasks. This study investigates HRM's reasoning patterns and identifies three surprising facts: failure on simple puzzles due to fixed point property violations, 'grokking' dynamics in reasoning steps, and the existence of multiple fixed points leading to 'guessing' rather than 'reasoning'. Strategies such as data augmentation, input perturbation, and model bootstrapping are proposed to enhance HRM's performance. The study also introduces Augmented HRM, which boosts accuracy on Sudoku-Extreme from 54.5% to 96.9%, providing new insights into reasoning models.",3.3,79.901,264,cold_start,Phi-4,Apple_M1(Metal)
2601.10681v1_Structure and Diversity Aware Context Bubble Const.pdf,Structure and Diversity Aware Context Bubble Construction for Enterprise Retrieval,"Amir Khurshid, Abhishek Sehgal",,,"Large Language Model, Retrieval-Augmented Generation, Context Bubble, Retrieval","Large language model (LLM) contexts are typically constructed using retrieval-augmented generation (RAG), which involves ranking and selecting the top-k passages. This approach can cause fragmentation in information graphs, over-retrieval, and duplication of content, alongside insufficient query context. This paper proposes a structure-informed and diversity-constrained context bubble construction framework that assembles coherent, citable bundles of spans under a strict token budget. The method preserves and exploits inherent document structure by organizing multi-granular spans and using task-conditioned structural priors to guide retrieval. Starting from high-relevance anchor spans, a context bubble is constructed through constrained selection that balances query relevance, marginal coverage, and redundancy penalties. It explicitly constrains diversity and budget, producing compact and informative context sets, unlike top-k retrieval. Moreover, a full retrieval is emitted that traces the scoring and selection choices of the records, thus providing auditability and deterministic tuning. Experiments on enterprise documents demonstrate the efficiency of context bubble as it significantly reduces redundant context, is better able to cover secondary facets, and has better answer quality and citation faithfulness within a limited context window. Ablation studies demonstrate that both structural priors and diversity constraint selection are necessary; removing either component results in a decline in coverage and an increase in redundant or incomplete context.",3.89,91.849,357,cold_start,Phi-4,Apple_M1(Metal)
2601.10684v1_On the origin of neural scaling laws from random g.pdf,On the origin of neural scaling laws: from random graphs to natural language,"Maissam Barkeshli, Alberto Alfarano, Andrey Gromov",,,"neural scaling laws, transformers, random walks, graphs, natural language, scaling exponents, Erdös-Renyi, scale-free Barabási-Albert, language modeling, parameterization","The paper investigates the origin of neural scaling laws, which are crucial for predicting model performance improvements with increased data, compute, and parameters. The study explores scaling laws in transformers trained on random walks on graphs with adjustable complexity, showing that these laws can emerge even without power law structures in data correlations. The research systematically reduces the complexity of natural language by training on sequences from simplified generative language models, observing changes in scaling exponents. It also examines scaling laws from random walks on Erdös-Renyi and scale-free Barabási-Albert graphs, and revisits conventional scaling laws for language modeling. The findings suggest that 2-layer transformers with a context length of 100 can reproduce essential results, critique existing fits in literature, propose an alternative method for compute optimal curves, and provide preliminary evidence that maximal update parameterization may be more parameter efficient than standard parameterization.",3.59,87.686,315,cold_start,Phi-4,Apple_M1(Metal)
2601.10696v1_The Impact of Generative AI on Architectural Conce.pdf,"The Impact of Generative AI on Architectural Conceptual Design: Performance, Creative Self-Efficacy and Cognitive Load","Han Jiang, Yao Xiao, Rachel Hurley, Shichao Liu",,,"Visual communication, Architectural design, Learning, Performance Assessment, Hybrid Intelligence, Human-AI teaming","Our study examines how generative AI (GenAI) influences performance, creative self-efficacy, and cognitive load in architectural conceptual design tasks. Thirty-six student participants from Architectural Engineering and other disciplines completed a two-phase architectural design task, first independently and then with external tools (GenAI-assisted condition and control condition using an online repository of existing architectural projects). Design outcomes were evaluated by expert raters, while self-efficacy and cognitive load were self-reported after each phase. Difference-in-differences analyses revealed no overall performance advantage of GenAI across participants; however, subgroup analyses showed that GenAI significantly improved design performance for novice designers. In contrast, general creative self-efficacy declined for students using GenAI. Cognitive load did not differ significantly between conditions, though prompt usage patterns showed that iterative idea-generation and visual feedback prompts were linked to greater reduction in cognitive load. These findings suggest that GenAI’s effectiveness depends on users’ prior expertise and interaction strategies through prompting.",4.06,72.386,294,cold_start,Phi-4,Apple_M1(Metal)
2601.10700v2_LIBERTy A Causal Framework for Benchmarking Concep.pdf,LIBERTy: A Causal Framework for Benchmarking Concept-Based Explanations of LLMs with Structural Counterfactuals,"Gilat Toker, Nitay Calderon, Ohad Amosy, Roi Reichart",,,"concept-based explanations, structural counterfactuals, LLMs, explainability, causal framework, benchmarking, interventions, sensitivity analysis","Concept-based explanations quantify the influence of high-level concepts (e.g., gender or experience) on model behavior, crucial for decision-makers in high-stakes domains. Existing benchmarks rely on costly human-written counterfactuals as imperfect proxies. This work introduces LIBERTy, a framework for constructing datasets with structural counterfactual pairs, grounded in Structured Causal Models (SCMs) of text generation. LIBERTy evaluates a range of methods across models, identifying significant potential for improving concept-based explanations. It also enables systematic analysis of model sensitivity to interventions, revealing reduced sensitivity to demographic concepts in proprietary LLMs due to post-training mitigation. LIBERTy provides a benchmark for developing faithful explainability methods.",3.3,85.855,283,cold_start,Phi-4,Apple_M1(Metal)
2601.10702v1_Grounding Agent Memory in Contextual Intent.pdf,Grounding Agent Memory in Contextual Intent,"Ruozhen Yang, Yucheng Jiang, Yueqi Jiang, Priyanka Kargupta, Yunyi Zhang, Jiawei Han",,,"large language models, long-horizon interactions, memory systems, contextual intent, retrieval cues, agentic memory, CAME-Bench, LongMemEval","Deploying large language models in long-horizon, goal-oriented interactions is challenging due to recurring similar entities and facts under different latent goals and constraints, leading to context-mismatched evidence retrieval. The paper proposes STITCH (StructuredIntentTracking in ContextualHistory), an agentic memory system that indexes each trajectory step with a structured retrieval cue, contextual intent, and retrieves history by matching the current step’s intent. Contextual intent provides compact signals to disambiguate repeated mentions and reduce interference, focusing on the current latent goal, action type, and salient entity types. STITCH filters and prioritizes memory snippets by intent compatibility, suppressing semantically similar but context-incompatible history. The paper introduces CAME-Bench, a benchmark for context-aware retrieval in realistic, dynamic, goal-oriented trajectories. STITCH achieves state-of-the-art performance across CAME-Bench and LongMemEval, outperforming the strongest baseline by 35.6%, with the largest gains as trajectory length increases. The analysis shows that intent indexing substantially reduces retrieval noise, supporting intent-aware memory for robust long-horizon reasoning.",3.54,103.527,366,cold_start,Phi-4,Apple_M1(Metal)
2601.10712v1_MatchTIR Fine-Grained Supervision for Tool-Integra.pdf,MatchTIR: Fine-Grained Supervision for Tool-Integrated Reasoning via Bipartite Matching,"Changle Qu, Sunhao Dai, Hengyi Cai, Jun Xu, Shuaiqiang Wang, Dawei Yin",,,"Tool-Integrated Reasoning, large language models, reinforcement learning, bipartite matching, turn-level reward, dual-level advantage estimation","Tool-Integrated Reasoning (TIR) empowers large language models (LLMs) to tackle complex tasks by interleaving reasoning steps with external tool interactions. Existing reinforcement learning methods typically rely on outcome- or trajectory-level rewards, assigning uniform advantages to all steps within a trajectory. This coarse-grained credit assignment fails to distinguish effective tool calls from redundant or erroneous ones, particularly in long-horizon multi-turn scenarios. To address this, MatchTIR introduces fine-grained supervision via bipartite matching-based turn-level reward assignment and dual-level advantage estimation. Credit assignment is formulated as a bipartite matching problem between predicted and ground-truth traces, utilizing two assignment strategies to derive dense turn-level rewards. A dual-level advantage estimation scheme integrates turn-level and trajectory-level signals, assigning distinct advantage values to individual interaction turns. Extensive experiments on three benchmarks demonstrate the superiority of MatchTIR, with a 4B model surpassing the majority of 8B competitors, particularly in long-horizon and multi-turn tasks.",3.52,99.015,349,cold_start,Phi-4,Apple_M1(Metal)
2601.10748v1_AnyECG Evolved ECG Foundation Model for Holistic H.pdf,AnyECG: Evolved ECG Foundation Model for Holistic Health Profiling,"Jun Li, Hongling Zhu, Yujie Xiao, Qinghao Zhao, Y alei Ke, Gongzheng Tang, Guangkun Nie, Deyun Zhang, Jin Li, Canqing Yu, Shenda Hong",,,"AI-ECG, electrocardiography, holistic health profiling, comorbidity, disease risk prediction, transfer learning, ECG foundation model","This study introduces AnyECG, an evolved ECG foundation model designed for holistic health profiling. Building on the ECGFounder model, AnyECG leverages a large-scale, multicenter ECG dataset to enhance capabilities in disease screening, long-term risk prediction, and comorbidity pattern recognition. The model was fine-tuned using transfer learning and validated across a 10-year longitudinal cohort, demonstrating robust performance in diagnosing 1,172 ICD-coded conditions with an AUROC above 0.7 for 306 diseases. The study highlights AnyECG's potential in uncovering novel disease correlations and improving clinical decision-making.",3.52,86.191,303,cold_start,Phi-4,Apple_M1(Metal)
2601.10768v1_Optimisation of complex product innovation process.pdf,OPTIMISATION OF COMPLEX PRODUCT INNOVATION PROCESSES BASED ON TREND MODELS WITH THREE-VALUED LOGIC,"NINA BOCKOVÁ, BARBORA VOLNÁ, MIRKO DOHNAL",,2601.10768v1,"Complex product innovation, technological forecasting, three-valued logic, trend-based modelling, scenarios, transition graphs","This paper investigates complex product-innovation processes using models grounded in a set of heuristics. Each heuristic is expressed through simple trends – increasing, decreasing, or constant – which serve as minimally information-intensive quantifiers, avoiding reliance on numerical values or rough sets. A solution to a trend model is defined as a set of scenarios with possible transitions between them, represented by a transition graph. Any possible future or past behaviour of the system under study can thus be depicted by a path within this graph.",3.62,66.022,239,cold_start,Phi-4,Apple_M1(Metal)
2601.10770v1_Unifying Speech Recognition Synthesis and Conversi.pdf,"UNIFYING SPEECH RECOGNITION, SYNTHESIS AND CONVERSION WITH AUTOREGRESSIVE TRANSFORMERS","Runyuan Cai, Yu Lin, Yiming Wang, Chunlin Fu, Xiaodong Zeng",,arXiv:2601.10770v1,"Text-to-Speech, Automatic Speech Recognition, Voice Conversion, Foundation Model","Traditional speech systems typically rely on separate, task-specific models for text-to-speech (TTS), automatic speech recognition (ASR), and voice conversion (VC), resulting in fragmented pipelines that limit scalability, efficiency, and cross-task generalization. In this paper, we present General-Purpose Audio (GPA), a unified audio foundation model that integrates multiple core speech tasks within a single large language model (LLM) architecture. GPA operates on a shared discrete audio token space and supports instruction-driven task induction, enabling a single autoregressive model to flexibly perform TTS, ASR, and VC without architectural modifications. This unified design combines a fully autoregressive formulation over discrete speech tokens, joint multi-task training across speech domains, and a scalable inference pipeline that achieves high concurrency and throughput. The resulting model family supports efficient multi-scale deployment, including a lightweight 0.3B-parameter variant optimized for edge and resource-constrained environments. Together, these design choices demonstrate that a unified autoregressive architecture can achieve competitive performance across diverse speech tasks while remaining viable for low-latency, practical deployment.",3.79,93.372,354,cold_start,Phi-4,Apple_M1(Metal)
2601.10773v1_LogicLens Leveraging Semantic Code Graph to explor.pdf,LogicLens: Leveraging Semantic Code Graph to explore Multi Repository large systems,"Niko Usai, Dario Montagnini, Kristian Ilianov Iliev, Raffaele Camanzo",,,"semantic code graph, multi-repository systems, software knowledge graph, large language models, conversational agent, software systems","Understanding large software systems is a challenging task, especially when code is distributed across multiple repositories and microservices. Developers often need to reason about the structure of the code, its domain logic, and runtime behaviors, which are typically implicit and scattered. LogicLens is introduced as a reactive conversational agent that assists developers in exploring complex software systems through a semantic multi-repository graph. This graph is built by combining syntactic code analysis with semantic enrichment using Large Language Models (LLMs). LogicLens enables developers to interact with the graph via natural language, dynamically retrieving relevant subgraphs and answering technical or functional queries. The system's architecture, emergent behaviors, and effectiveness on real-world scenarios are discussed, demonstrating capabilities like impact analysis and symptom-based debugging.",3.44,79.446,273,cold_start,Phi-4,Apple_M1(Metal)
2601.10779v1_Unified Optimization of Source Weights and Transfe.pdf,Unified Optimization of Source Weights and Transfer Quantities in Multi-Source Transfer Learning: An Asymptotic Framework,"Qingyue Zhang, Chang Chu, Haohao Fu, Tianren Peng, Yanru Wu, Guanbo Huang, Yang Li, Shao-Lun Huang",,,"transfer learning, multi-source learning, asymptotic analysis, K-L divergence","Transfer learning is crucial for improving model performance in data-scarce scenarios. This work introduces a theoretical framework, Unified Optimization of Weights and Quantities (UOWQ), for multi-source transfer learning. It jointly determines optimal source weights and transfer quantities, using an asymptotic analysis of a Kullback–Leibler divergence–based generalization error measure. The framework provides closed-form solutions for single-source settings and a convex optimization-based procedure for multi-source cases. Practical algorithms are proposed for multi-source transfer and multi-task learning settings. Experiments on DomainNet and Office-Home benchmarks show that UOWQ outperforms strong baselines, validating its theoretical and practical effectiveness.",3.4,74.76,254,cold_start,Phi-4,Apple_M1(Metal)
2601.10810v1_Digital Metabolism Decoupling Logic from Facts via.pdf,Digital Metabolism: Decoupling Logic from Facts via Regenerative Unlearning Towards a Pure Neural Logic Core,"Mengmeng Peng, Zhenyu Fang, He Sun",,arXiv:2601.10810v1,"large language models, parameter entanglement, neural logic core, regenerative unlearning, deep-layer gradient reversal, chain-of-thought scaffolding, modular architectures","Large language models (LLMs) suffer from parameter entanglement, where reasoning capabilities and factual knowledge are intertwined within shared weights, leading to inefficiencies and hallucinations. This paper introduces 'digital metabolism,' a hypothesis suggesting that targeted forgetting can distill a pure neural logic core. The Regenerative Logic-Core Protocol (RLCP) is proposed to make factual dependencies undecodable, resulting in a phase transition where the model retains minimal factual associations while adopting chain-of-thought reasoning. This approach could lead to modular 'Neural CPU + Symbolic RAM' architectures.",3.53,72.305,255,cold_start,Phi-4,Apple_M1(Metal)
2601.10820v1_Towards Reliable ML Feature Engineering via Planni.pdf,Towards Reliable ML Feature Engineering via Planning in Constrained-Topology of LLM Agents,"Himanshu Thakur, Anusha Kamath, Anurag Muthyala, Dhwani Sanmukhani, Smruthi Mukund, Jay Katukuri",,arXiv:2601.10820v1,"ML Feature Engineering, LLM Agents, Code Generation, Human-AI Collaboration, Multi-Agent Framework","Recent advances in code generation models have unlocked unprecedented opportunities for automating feature engineering, yet their adoption in real-world ML teams remains constrained by critical challenges: (i) the scarcity of datasets capturing the iterative and complex coding processes of production-level feature engineering; (ii) limited integration and personalization of widely used coding agents, such as CoPilot and Devin, with a team’s unique tools, codebases, workflows, and practices; and (iii) suboptimal human-AI collaboration due to poorly timed or insufficient feedback. We address these challenges with a planner-guided, constrained-topology multi-agent framework that generates code for repositories in a multi-step fashion. The LLM-powered planner leverages a team’s environment, represented as a graph, to orchestrate calls to available agents, generate context-aware prompts, and use downstream failures to retroactively correct upstream artifacts. It can request human intervention at critical steps, ensuring generated code is reliable, maintainable, and aligned with team expectations. On a novel in-house dataset, our approach achieves 38% and 150% improvement in the evaluation metric over manually crafted and unplanned workflows respectively. In practice, when building features for recommendation models serving over 120 million users, our approach has delivered real-world impact by reducing feature engineering cycles from three weeks to a single day.",3.91,106.402,416,cold_start,Phi-4,Apple_M1(Metal)
2601.10827v1_Approximately Optimal Global Planning for Contact-.pdf,Approximately Optimal Global Planning for Contact-Rich SE(2) Manipulation on a Graph of Reachable Sets,"Simin Liu, Tong Zhao, Bernhard Paus Graesdal, Peter Werner, Jiuguang Wang, John Dolan, Changliu Liu, Tao Pang",,,"Full-body manipulation, dexterous manipulation, manipulation planning","This paper introduces a new paradigm for computing approximately optimal manipulator plans in contact-rich manipulation (CRM). The approach involves constructing a graph of mutual reachable sets offline and planning over this graph online to sequence local plans for globally optimized motion. The method outperforms a leading planner by reducing task cost by 61% and achieves a 91% success rate across 250 queries with sub-minute query times, demonstrating the practicality of globally optimized CRM for real-world tasks.",3.23,71.202,230,cold_start,Phi-4,Apple_M1(Metal)
2601.10835v1_Can Vision-Language Models Understand Construction.pdf,Can Vision-Language Models Understand Construction Workers? An Exploratory Study,"Hieu Bui, Nathaniel E. Chodosh, Arash Tavakoli",,,"Large Language Model, Construction Automation, Robotics, Human Robot Interaction","As robotics become increasingly integrated into construction workflows, their ability to interpret and respond to human behavior is essential for safe and effective collaboration. Vision-Language Models (VLMs) are promising tools for visual understanding tasks, potentially recognizing human behaviors without extensive domain-specific training. This study evaluates the performance of three leading VLMs—GPT-4o, Florence 2, and LLaVa-1.5—in detecting construction worker actions and emotions from static site images. Using a curated dataset of 1,000 images annotated across ten action and ten emotion categories, the study assesses each model’s outputs through standardized inference pipelines and multiple evaluation metrics. GPT-4o achieved the highest scores, while Florence 2 performed moderately, and LLaVa-1.5 showed the lowest performance. Confusion matrix analyses revealed difficulties in distinguishing semantically close categories, indicating limitations in current VLMs for visually nuanced, domain-specific tasks. The study suggests that while general-purpose VLMs can offer baseline capabilities for human behavior recognition in construction environments, further improvements may be needed for real-world reliability.",3.52,91.303,321,cold_start,Phi-4,Apple_M1(Metal)
2601.10880v1_Medical SAM3 A Foundation Model for Universal Prom.pdf,Medical SAM3: A Foundation Model for Universal Prompt-Driven Medical Image Segmentation,"Chongcong Jiang, Tianxingjian Ding, Chuhan Song, Jiachen Tu, Ziyang Yan, Yihua Shao, Zhenyi Wang, Yuzhang Shang, Tianyu Han, Yu Tian",,arXiv:2601.10880v1,"Medical Image Segmentation, Foundation Models, Fine-Tuning, SAM3","Promptable segmentation foundation models like SAM3 have shown strong generalization through interactive and concept-based prompting. However, their direct applicability to medical image segmentation is limited by domain shifts, lack of spatial prompts, and complex anatomical structures. This paper introduces Medical SAM3, a foundation model for universal prompt-driven medical image segmentation, achieved by fine-tuning SAM3 on large-scale, heterogeneous 2D and 3D medical imaging datasets with paired segmentation masks and text prompts. The study reveals that SAM3's performance on medical data is hindered by reliance on geometric priors like ground-truth-derived bounding boxes, necessitating full model adaptation. Fine-tuning SAM3 on 33 datasets across 10 medical imaging modalities, Medical SAM3 acquires robust domain-specific representations while maintaining prompt-driven flexibility. Experiments show consistent performance gains, especially in scenarios with semantic ambiguity, complex morphology, and long-range 3D context. Medical SAM3 is established as a universal, text-guided segmentation foundation model for medical imaging, emphasizing the need for holistic model adaptation to achieve robust prompt-driven segmentation under severe domain shifts.",3.85,99.834,384,cold_start,Phi-4,Apple_M1(Metal)
2601.10904v1_ARC Prize 2025 Technical Report.pdf,ARC Prize 2025: Technical Report,"François Chollet, Mike Knoop, Gregory Kamradt, Bryan Landers",,,"ARC-AGI, few-shot generalization, fluid intelligence, abstract reasoning, refinement loop, zero-pretraining deep learning, AI reasoning, benchmark contamination, interactive reasoning challenges","The ARC Prize 2025 competition focused on the ARC-AGI-2 dataset, which presents increased task complexity. The competition attracted significant participation, with the top score reaching 24% on the private evaluation set. The paper discusses the emergence of refinement loops in AI, the constraints of current AI reasoning performance, and the introduction of ARC-AGI-3, which includes interactive reasoning challenges. The ARC-AGI benchmark is highlighted as a standard for measuring AI reasoning, emphasizing the need for systems to acquire new skills and solve novel problems without prior training.",3.19,70.116,224,cold_start,Phi-4,Apple_M1(Metal)
2601.10917v1_Self-learned representation-guided latent diffusio.pdf,SELF-LEARNED REPRESENTATION-GUIDED LATENT DIFFUSION MODEL FOR BREAST CANCER CLASSIFICATION IN DEEP ULTRA VIOLET WHOLE SURFACE IMAGES,"Pouya Afshin, David Helminiak, Tianling Niu, Julie M. Jorns, Tina Yen, Bing Yu, Dong Hye Ye",,,"Breast Cancer Classification, Latent Diffusion Model, Self-Supervised Learning, Data Augmentation, Deep Ultraviolet Fluorescence Scanning Microscopy, Vision Transformer, Patch Prediction Aggregation","Breast-Conserving Surgery (BCS) requires precise intraoperative margin assessment to preserve healthy tissue. Deep Ultraviolet Fluorescence Scanning Microscopy (DUV-FSM) offers rapid, high-resolution surface imaging for this purpose; however, the scarcity of annotated DUV data hinders the training of robust deep learning models. To address this, we propose an Self-Supervised Learning (SSL)-guided Latent Diffusion Model (LDM) to generate high-quality synthetic training patches. By guiding the LDM with embeddings from a fine-tuned DINO teacher, we inject rich semantic details of cellular structures into the synthetic data. We combine real and synthetic patches to fine-tune a Vision Transformer (ViT), utilizing patch prediction aggregation for WSI-level classification. Experiments using 5-fold cross-validation demonstrate that our method achieves 96.47% accuracy and reduces the FID score to 45.72, significantly outperforming class-conditioned baselines.",3.61,105.635,381,cold_start,Phi-4,Apple_M1(Metal)
2601.10921v1_RobuMTL Enhancing Multi-Task Learning Robustness A.pdf,RobuMTL: Enhancing Multi-Task Learning Robustness Against Weather Conditions,"Tasneem Shaffee, Sherief Reda",,,"Multi-Task Learning, Robustness, Weather Conditions, Low-Rank Adaptation, Mixture-of-Experts, Adversarial Training, Data Augmentation","Robust Multi-Task Learning (MTL) is crucial for autonomous systems operating in real-world environments, where adverse weather conditions can severely degrade model performance and reliability. This paper introduces RobuMTL, a novel architecture designed to adaptively address visual degradation by dynamically selecting task-specific hierarchical Low-Rank Adaptation (LoRA) modules and a LoRA expert squad based on input perturbations in a mixture-of-experts fashion. The framework enables adaptive specialization based on input characteristics, improving robustness across diverse real-world conditions. Evaluations on the PASCAL and NYUD-v2 datasets show significant improvements over single-task models, standard MTL baselines, and state-of-the-art methods, with notable gains under mixed weather conditions.",3.25,75.694,246,cold_start,Phi-4,Apple_M1(Metal)
2601.10922v1_What Matters in Data Curation for Multimodal Reaso.pdf,What Matters in Data Curation for Multimodal Reasoning? Insights from the DCVLR Challenge,"Yosub Shin, Michael Buriek, Boris Sobolev, Pavel Bushuyeu, Vikas Kumar, Haoyang Xu, Samuel Watson, Igor Molybog",,,"data curation, multimodal reasoning, DCVLR challenge, dataset selection, difficulty-based example selection, alignment, dataset size, diversity heuristics","This paper explores data curation for multimodal reasoning through the NeurIPS 2025 Data Curation for Vision–Language Reasoning (DCVLR) challenge. The challenge isolates dataset selection by fixing the model and training protocol. The authors' submission, based on a curated dataset from Walton Multimodal Cold Start, placed first in the challenge. Post-competition analysis revealed that difficulty-based example selection on an aligned base dataset significantly improves performance. Increasing dataset size mainly reduces variance rather than improving mean accuracy, and commonly used diversity and synthetic augmentation heuristics often degrade performance. These findings highlight the importance of alignment and difficulty in data-efficient multimodal reasoning.",3.34,81.208,271,cold_start,Phi-4,Apple_M1(Metal)
2601.10926v1_Selecting Language Models for Social Science Start.pdf,"Selecting Language Models for Social Science: Start Small, Start Open, and Validate","Dustin S. Stoltz, Marshall A. Taylor, Sanuj Kumar",,,"large language models, LLMs, reproducibility, replicability, model openness","Currently, there are thousands of large pretrained language models (LLMs) available to social scientists. This paper explores how to select among them using validity, reliability, reproducibility, and replicability as guides. It discusses the significance of model openness, model footprint, training data, and model architectures and fine-tuning. The authors argue for starting with smaller, open models and constructing delimited benchmarks to validate the computational pipeline. The paper also addresses the sparse use of LLMs in sociological research and anticipates changes as norms develop around their role in research workflows.",3.07,65.112,200,cold_start,Phi-4,Apple_M1(Metal)
2601.10931v1_Sparse Data Tree Canopy Segmentation Fine-Tuning L.pdf,Sparse Data Tree Canopy Segmentation: Fine-Tuning Leading Pretrained Models on Only 150 Images,"David Szczecina, Niloofar Azad, Hudson Sun, Kyle Gao, Anthony Bertnyk, Lincoln Linlin Xu",,,"Deep Learning, Computer Vision, Object Segmentation, Remote Sensing, Forestry, Tree Canopy","Tree canopy detection from aerial imagery is crucial for environmental monitoring, urban planning, and ecosystem analysis. The Solafune Tree Canopy Detection competition provides a small and imbalanced dataset of only 150 annotated images, posing challenges for training deep models without overfitting. This study evaluates five architectures: YOLOv11, Mask R-CNN, DeepLabv3, Swin-UNet, and DINOv2, under extreme data scarcity. Pretrained convolution-based models, particularly YOLOv11 and Mask R-CNN, generalize better than transformer-based models. DeeplabV3, Swin-UNet, and DINOv2 underperform due to differences between semantic and instance segmentation tasks, high data requirements of Vision Transformers, and lack of strong inductive biases. The findings confirm that transformer-based architectures struggle in low-data regimes without substantial pretraining or augmentation. The study provides a detailed analysis of training strategies, augmentation policies, and model behavior under small-data constraints, demonstrating that lightweight CNN-based methods are most reliable for canopy detection on limited imagery.",3.58,98.734,353,cold_start,Phi-4,Apple_M1(Metal)
2601.10945v1_PatientVLM Meets DocVLM Pre-Consultation Dialogue .pdf,PatientVLM Meets DocVLM: Pre-Consultation Dialogue Between Vision-Language Models for Efficient Diagnosis,"K Lokesh, Abhirama Subramanyam Penamakuri, Uday Agarwal, Apoorva Challa, Shreya K Gowda, Somesh Gupta, Anand Mishra",,,"AI in medical diagnosis, vision-language models, pre-consultation dialogue framework, diagnostic dialogues, symptom elicitation, image analysis","This paper introduces a Pre-Consultation Dialogue Framework (PCDF) that enhances diagnostic accuracy by simulating dialogues between two vision-language models: DocVLM and PatientVLM. DocVLM generates follow-up questions based on image and dialogue history, while PatientVLM responds using a symptom profile derived from the ground-truth diagnosis. The framework was clinically validated, showing that these interactions form coherent consultations, leading to substantial improvements over image-only training. The study highlights the importance of realistic symptom elicitation in medical diagnosis.",3.09,85.685,265,cold_start,Phi-4,Apple_M1(Metal)
2601.10951v1_Multi-Stage Patient Role-Playing Framework for Rea.pdf,Multi-Stage Patient Role-Playing Framework for Realistic Clinical Interactions,"Shijie Jiang, Zefan Jiang, Kehua Zhu, Tian Bai, Ruihong Zhao",,2601.10951v1,"Patient Role-Playing, Large Language Models, Clinical","The simulation of realistic clinical interactions plays a pivotal role in advancing clinical Large Language Models (LLMs) and supporting medical diagnostic education. Existing approaches and benchmarks rely on generic or LLM-generated dialogue data, which limits the authenticity and diversity of doctor-patient interactions. In this work, we propose the first Chinese patient simulation dataset (Ch-PatientSim), constructed from realistic clinical interaction scenarios to comprehensively evaluate the performance of models in emulating patient behavior. Patients are simulated based on a five-dimensional persona structure. To address issues of the persona class imbalance, a portion of the dataset is augmented using few-shot generation, followed by manual verification. We evaluate various state-of-the-art LLMs and find that most produce overly formal responses that lack individual personality. To address this limitation, we propose a training-free Multi-Stage Patient Role-Playing (MSPRP) framework, which decomposes interactions into three stages to ensure both personalization and realism in model responses. Experimental results demonstrate that our approach significantly improves model performance across multiple dimensions of patient simulation. Our dataset is available at https://github.com/SerajJon/MSPRP.",3.87,87.686,339,cold_start,Phi-4,Apple_M1(Metal)
2601.10955v1_Beyond Max Tokens Stealthy Resource Amplification .pdf,Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents,"Kaiyu Zhou, Yongsen Zheng, Yicheng He, Meng Xue, Xueluan Gong, Yuji Wang, Kwok-Yan Lam",,,"Large Language Models, LLM Agents, Tool Calling, Agent Security, Economic Denial-of-Service","The agent-tool communication loop is a critical attack surface in modern Large Language Model (LLM) agents. Existing Denial-of-Service (DoS) attacks, primarily triggered via user prompts or injected retrieval-augmented generation (RAG) context, are ineffective for this new paradigm. They are fundamentally single-turn and often lack a task-oriented approach, making them conspicuous in goal-oriented workflows and unable to exploit the compounding costs of multi-turn agent-tool interactions. We introduce a stealthy, multi-turn economic DoS attack that operates at the tool layer under the guise of a correctly completed task. Our method adjusts text-visible fields and a template-governed return policy in a benign, Model Context Protocol (MCP)-compatible tool server, optimizing these edits with a Monte Carlo Tree Search (MCTS) optimizer. These adjustments leave function signatures unchanged and preserve the final payload, steering the agent into prolonged, verbose tool-calling sequences using text-only notices. This compounds costs across turns, escaping single-turn caps while keeping the final answer correct to evade validation. Across six LLMs on the ToolBench and BFCL benchmarks, our attack expands tasks into trajectories exceeding 60,000 tokens, inflates costs by up to 658 ×, and raises energy by 100–560 ×. It drives GPU KV cache occupancy from <1% to 35–74% and cuts co-running throughput by approximately 50%. Because the server remains protocol-compatible and the task outcomes are correct, conventional checks fail. These results elevate the agent-tool interface to a first-class security frontier, demanding a paradigm shift from validating final answers to monitoring the economic and computational cost of the entire agentic process.",3.7,128.786,477,cold_start,Phi-4,Apple_M1(Metal)
2601.10960v1_Steering Language Models Before They Speak Logit-L.pdf,Steering Language Models Before They Speak: Logit-Level Interventions,"Hyeseon An, Shinwoo Park, Hyundong Jin, Yo-Sub Han",,,"language models, logit-level interventions, controllable generation, text rewriting, toxicity mitigation, steering methods, statistical token score table, z-normalized log-odds, decoding distribution","The paper discusses the importance of steering large language models (LLMs) for specialized applications like style-sensitive text rewriting, user-adaptive communication, and toxicity mitigation. It critiques current steering methods, such as prompting-based and activation-based approaches, for their limitations in providing consistent or fine-grained control. The authors propose a training-free inference-time logit intervention method that uses a statistical token score table derived from z-normalized log-odds of labeled corpora to shift the decoding distribution. This method is empirically evaluated across datasets focusing on writing complexity, formality, and toxicity, demonstrating its effectiveness in steering output characteristics with significant control gains. The approach is noted for its broad applicability and task-agnostic nature.",3.41,83.207,284,cold_start,Phi-4,Apple_M1(Metal)
2601.11000v1_When Personalization Misleads Understanding and Mi.pdf,When Personalization Misleads: Understanding and Mitigating Hallucinations in Personalized LLMs,"Zhongxiang Sun, Yi Zhan, Chenglei Shen, Weijie Yu, Xiao Zhang, Ming He, Jun Xu",,,"Personalized LLMs, hallucinations, factual reasoning, personalization-induced hallucinations, FPPS, PFQABench","Personalized large language models (LLMs) adapt model behavior to individual users to enhance user satisfaction, yet personalization can inadvertently distort factual reasoning. This paper shows that personalized LLMs can generate answers aligned with a user’s prior history rather than the objective truth, resulting in personalization-induced hallucinations that degrade factual reliability. To address this issue, the authors propose Factuality-Preserving Personalized Steering (FPPS), a lightweight inference-time approach that mitigates personalization-induced factual distortions while preserving personalized behavior. They also introduce PFQABench, the first benchmark designed to jointly evaluate factual and personalized question answering under personalization. Experiments across multiple LLM backbones and personalization methods show that FPPS substantially improves factual accuracy while maintaining personalized performance.",3.35,82.093,275,cold_start,Phi-4,Apple_M1(Metal)
2601.11007v1_AdaMARP An Adaptive Multi-Agent Interaction Framew.pdf,AdaMARP: An Adaptive Multi-Agent Interaction Framework for General Immersive Role-Playing,"Zhenhua Xu, Dongsheng Chen, Shuo Wang, Jian Li, Chengjie Wang, Meng Han, Yabiao Wang",,2601.11007v1,"immersive role-playing, multi-agent interaction, large language models, narrative coherence, environment modeling","AdaMARP is an adaptive multi-agent interaction framework designed to enhance immersion and adaptability in LLM role-playing. It introduces an immersive message format and a Scene Manager to better orchestrate multi-character interactions and dynamic scene transitions. The framework is trained using AdaRPSet and AdaSMSet, showing improvements in character consistency, environment grounding, and narrative coherence. Experiments demonstrate that AdaMARP outperforms several commercial LLMs in these aspects.",3.06,75.914,232,cold_start,Phi-4,Apple_M1(Metal)
2601.11012v1_Efficient Protein Optimization via Structure-aware.pdf,Efficient Protein Optimization via Structure-aware Hamiltonian Dynamics,"Jiahao Wang, Shuangjia Zheng",,,"protein optimization, Hamiltonian dynamics, Bayesian optimization, epistasis effect, structural constraints, protein engineering, machine learning","The ability to engineer optimized protein variants has transformative potential for biotechnology and medicine. Prior sequence-based optimization methods struggle with the high-dimensional complexities due to the epistasis effect and the disregard for structural constraints. To address this, we propose HADES, a Bayesian optimization method utilizing Hamiltonian dynamics to efficiently sample from a structure-aware approximated posterior. Leveraging momentum and uncertainty in the simulated physical movements, HADES enables rapid transition of proposals toward promising areas. A position discretization procedure is introduced to propose discrete protein sequences from such a continuous state system. The posterior surrogate is powered by a two-stage encoder-decoder framework to determine the structure and function relationships between mutant neighbors, consequently learning a smoothed landscape to sample from. Extensive experiments demonstrate that our method outperforms state-of-the-art baselines in in-silico evaluations across most metrics. Remarkably, our approach offers a unique advantage by leveraging the mutual constraints between protein structure and sequence, facilitating the design of protein sequences with similar structures and optimized properties. The code and data are publicly available at https://github.com/GENTEL-lab/HADES.",3.51,93.437,328,cold_start,Phi-4,Apple_M1(Metal)
2601.11016v1_Contextual Distributionally Robust Optimization wi.pdf,Contextual Distributionally Robust Optimization with Causal and Continuous Structure: An Interpretable and Tractable Approach,"Fenglin Zhang, Jie Wang",,2601.11016v1,"Contextual distributionally robust optimization, Causal Sinkhorn discrepancy, Soft regression forest, Stochastic compositional optimization","This paper introduces a framework for contextual distributionally robust optimization (DRO) that incorporates the causal and continuous structure of the underlying distribution. It develops interpretable and tractable decision rules using covariates. The causal Sinkhorn discrepancy (CSD), an entropy-regularized causal Wasserstein distance, is introduced to encourage continuous transport plans while preserving causal consistency. The paper formulates a contextual DRO model with a CSD-based ambiguity set, termed Causal Sinkhorn DRO (Causal-SDRO), and derives its strong dual reformulation. The worst-case distribution is characterized as a mixture of Gibbs distributions. To solve the corresponding infinite-dimensional policy optimization, the Soft Regression Forest (SRF) decision rule is proposed, which approximates optimal policies within arbitrary measurable function spaces. The SRF maintains the interpretability of classical decision trees while being fully parametric, differentiable, and Lipschitz smooth. An efficient stochastic compositional gradient algorithm is developed to solve the Causal-SDRO with parametric decision rules, converging to an ε-stationary point at a rate of O(ε−4). The method is validated through numerical experiments on synthetic and real-world datasets, demonstrating superior performance and interpretability.",3.83,92.365,354,cold_start,Phi-4,Apple_M1(Metal)
2601.11019v1_Finding the Translation Switch Discovering and Exp.pdf,Finding the Translation Switch: Discovering and Exploiting the Task-Initiation Features in LLMs,"Xinwei Wu, Heng Liu, Xiaohu Zhao, Yuqi Ren, Linlong Xu, Longyue Wang, Deyi Xiong, Weihua Luo, Kaifu Zhang",,,"Large Language Models, translation, Sparse Autoencoders, task-specific features, PCA-based consistency metric, causal interventions, data selection strategy, fine-tuning, hallucinations, mechanistic insight","Large Language Models (LLMs) often demonstrate strong translation abilities without task-specific fine-tuning. This study introduces a novel framework using Sparse Autoencoders (SAEs) to identify 'translation initiation' features that are crucial for translation tasks. By amplifying these features, the model's translation accuracy improves, while ablating them leads to hallucinations. The study also proposes a data selection strategy for efficient fine-tuning, focusing on 'mechanistically hard' samples. This approach enhances data efficiency and reduces hallucinations, with findings applicable to larger models of the same family. The research decodes a core component of translation mechanisms in LLMs and offers a blueprint for creating more robust and efficient models.",3.45,93.99,324,cold_start,Phi-4,Apple_M1(Metal)
2601.11021v1_Combating Spurious Correlations in Graph Interpret.pdf,Combating Spurious Correlations in Graph Interpretability via Self-Reflection,"Kecheng Cai, Chenyang Xu, Chao Peng",,,"interpretable graph learning, spurious correlations, self-reflection, graph neural networks, graph representation learning","Interpretable graph learning aims to identify crucial nodes and edges in graphs for specific tasks. The Spurious-Motif benchmark, known for its challenging spurious correlations, highlights the difficulty models face in distinguishing relevant structures. This paper introduces a self-reflection framework to improve interpretability on such datasets. By integrating self-reflection with existing methods, the framework iteratively refines importance scores for nodes and edges, enhancing performance. Experimental results demonstrate significant improvements on the Spurious-Motif and other benchmarks. The study underscores the importance of interpretability in high-stakes applications like drug discovery, social network analysis, and fraud detection.",3.21,67.66,217,cold_start,Phi-4,Apple_M1(Metal)
2601.11030v1_IDDR-NGP Incorporating Detectors for Distractor Re.pdf,IDDR-NGP: Incorporating Detectors for Distractor Removal with Instant Neural Radiance Field,"Xianliang Huang, Jiajie Gou, Shuhang Chen, Zhizhou Zhong, Jihong Guan, Shuigeng Zhou",10.1145/3581783.3612045,2601.11030v1,"Computer vision, Reconstruction, Computer graphics, Image processing, Image representations, Object detection","This paper presents the first unified distractor removal method, named IDDR-NGP, which directly operates on Instant-NPG. The method is able to remove a wide range of distractors in 3D scenes, such as snowflakes, confetti, defoliation, and petals, whereas existing methods usually focus on a specific type of distractors. By incorporating implicit 3D representations with 2D detectors, it is possible to efficiently restore 3D scenes from multiple corrupted images. The learned perceptual image patch similarity (LPIPS) loss and the multi-view compensation loss (MVCL) are designed to jointly optimize the rendering results of IDDR-NGP, which could aggregate information from multi-view corrupted images. All of them can be trained in an end-to-end manner to synthesize high-quality 3D scenes. A new benchmark dataset consisting of both synthetic and real-world distractors is built to support the research on distractor removal in implicit 3D representations. Extensive experimental results demonstrate the effectiveness and robustness of IDDR-NGP in removing multiple types of distractors. The approach achieves results comparable with the existing SOTA desnow methods and is capable of accurately removing both realistic and synthetic distractors.",3.49,117.076,409,cold_start,Phi-4,Apple_M1(Metal)
2601.11035v1_Your One-Stop Solution for AI-Generated Video Dete.pdf,Your One-Stop Solution for AI-Generated Video Detection,"Long Ma, Zihao Xue, Yan Wang, Zhiyuan Yan, Jin Xu, Xiaorui Jiang, Haiyang Yu, Yong Liao, Zhen Bi",,arXiv:2601.11035v1,"Text To Video, Image To Video Network, Video Image, Mainstream Detectors, Accuracy, AUC, Relevance, Vehicles, Quantity, Scenery, Judgement, Imaging Quality, Motion Smoothness, Diverse Video Content, Comprehensive Evaluations, VLM, Fundamental Question, People, Animals, Buildings, Plants Food, Spatial, Major Content, Color, Attribute Control, Temporal, Motion Direction, Speed, Evaluations, Real, Multiple Tasks, Numerous Advanced models, Video To Video, AIGVD, Bench, Insightful Analyses","Recent advances in generative modeling can create remarkably realistic synthetic videos, making it increasingly difficult for humans to distinguish them from real ones and necessitating reliable detection methods. However, two key limitations hinder the development of this field. From the dataset perspective, existing datasets are often limited in scale and constructed using outdated or narrowly scoped generative models, making it difficult to capture the diverse range of synthetic videos. This paper presents a comprehensive solution for AI-generated video detection, addressing these limitations by proposing a large-scale dataset and advanced detection methods. The study evaluates various detectors based on aspects such as accuracy, relevance, and motion smoothness, providing insightful analyses and experimental results. The paper also explores fundamental questions about the detectability of synthetic videos and the challenges posed by advanced generative models.",4.0,117.631,470,cold_start,Phi-4,Apple_M1(Metal)
2601.11037v1_BAPO Boundary-Aware Policy Optimization for Reliab.pdf,BAPO: Boundary-Aware Policy Optimization for Reliable Agentic Search,"Shiyu Liu, Yongjing Yin, Jianhao Yan, Yunbo Tang, Qinggang Zhang, Bei Li, Xin Chen, Jingang Wang, Xunliang Cai, Jinsong Su",,,"RL-based agentic search, reliability, Boundary-Aware Policy Optimization, Large Language Models, reinforcement learning, dynamic planning, external search, I DON’T KNOW (IDK)","RL-based agentic search enhances the accuracy of solving complex questions by optimizing agent policies through large-scale reinforcement learning. However, these agents often fail to recognize their reasoning boundaries and rarely admit 'I DON’T KNOW' (IDK) when evidence is insufficient or reasoning reaches its limit, leading to unreliable answers. This paper introduces Boundary-Aware Policy Optimization (BAPO), a novel RL framework designed to improve reliability without compromising accuracy. BAPO incorporates a group-based boundary-aware reward and an adaptive reward modulator to encourage IDK responses only when necessary and prevent their misuse during early exploration. Experiments on four benchmarks show that BAPO significantly enhances the reliability of agentic search.",3.35,92.88,311,cold_start,Phi-4,Apple_M1(Metal)
2601.11042v1_Spectral Characterization and Mitigation of Sequen.pdf,Spectral Characterization and Mitigation of Sequential Knowledge Editing Collapse,"Chi Zhang, Mengqi Zhang, Xiaotian Ye, Runxi Cheng, Zisheng Zhou, Ying Zhou, Pengjie Ren, Zhumin Chen",,,"spectral analysis, knowledge editing, large language models, parameter modification, sequential editing, model collapse, general abilities, singular subspace, REVIVE framework","Sequential knowledge editing in large language models often leads to catastrophic collapse of the model's general abilities, particularly with parameter-modifying methods. This work presents a spectral analysis showing that a model's general abilities are linked to dominant singular directions of pretrained weight matrices, which are disrupted by repeated edits. The proposed REVIVE framework stabilizes sequential editing by preserving the dominant singular subspace, representing parameter updates in the spectral basis of the original weights and filtering components that interfere with the protected region. Experiments demonstrate that REVIVE improves editing efficacy while preserving general abilities under extensive sequential editing.",3.27,81.152,265,cold_start,Phi-4,Apple_M1(Metal)
2601.11044v2_AgencyBench Benchmarking the Frontiers of Autonomo.pdf,AGENCYBENCH: Benchmarking the Frontiers of Autonomous Agents in 1M-Token Real-World Contexts,"Keyu Li, Junhao Shi, Yang Xiao, Mohan Jiang, Jie Sun, Yunze Wu, Dayuan Fu, Shijie Xia, Xiaojie Cai, Tianze Xu, Weiye Si, Wenjie Li, Dequan Wang, Pengfei Liu",,arXiv:2601.11044v2,"Large Language Models, autonomous agents, benchmark, real-world scenarios, user simulation, Docker sandbox, agentic capabilities","Large Language Models (LLMs) based autonomous agents demonstrate multifaceted capabilities to contribute substantially to economic production. However, existing benchmarks remain focused on single agentic capability, failing to capture long-horizon real-world scenarios. Moreover, the reliance on human-in-the-loop feedback for realistic tasks creates a scalability bottleneck, hindering automated rollout collection and evaluation. To bridge this gap, we introduce AGENCYBENCH, a comprehensive benchmark derived from daily AI usage, evaluating 6 core agentic capabilities across 32 real-world scenarios, comprising 138 tasks with specific queries, deliverables, and rubrics. These scenarios require an average of 90 tool calls, 1 million tokens, and hours of execution time to resolve. To enable automated evaluation, we employ a user simulation agent to provide iterative feedback, and a Docker sandbox to conduct visual and functional rubric-based assessment. Experiments reveal that closed-source models significantly outperform open-source models (48.4% vs 32.1%). Further analysis reveals significant disparities across models in resource efficiency, feedback-driven self-correction, and specific tool-use preferences. Finally, we investigate the impact of agentic scaffolds, observing that proprietary models demonstrate superior performance within their native ecosystems (e.g., Claude-4.5-Opus via Claude-Agent-SDK), while open-source models exhibit distinct performance peaks, suggesting potential optimization for specific execution frameworks. AGENCYBENCH serves as a critical testbed for next-generation agents, highlighting the necessity of co-optimizing model architecture with agentic frameworks. We believe this work sheds light on the future direction of autonomous agents, and to facilitate community adoption, we release the full benchmark and evaluation toolkit at https://github.com/GAIR-NLP/AgencyBench.",3.71,150.607,558,cold_start,Phi-4,Apple_M1(Metal)
2601.11049v1_Predicting Biased Human Decision-Making with Large.pdf,Predicting Biased Human Decision-Making with Large Language Models in Conversational Settings,"Stephen Pilli, Vivek Nallur",,,"Conversational AI, Framing Effect, Status Quo Bias, LLM Simulation","This study investigates whether large language models (LLMs) can predict biased decision-making in conversational settings, focusing on cognitive biases like the Framing Effect and Status Quo Bias. A pre-registered study with 1,648 participants involved completing decision-making tasks via a chatbot with varying dialogue complexity. Increased cognitive load from complex dialogues heightened bias effects. LLMs, particularly GPT-4, were evaluated for their ability to predict individual decisions using demographic information and dialogue context. GPT-4 showed significant accuracy and alignment with human bias patterns, outperforming GPT-5 and open-source models. These findings enhance our understanding of LLMs in simulating human decision-making and designing adaptive conversational agents.",3.28,73.989,243,cold_start,Phi-4,Apple_M1(Metal)
2601.11063v1_H-AIM Orchestrating LLMs PDDL and Behavior Trees f.pdf,"H-AIM: Orchestrating LLMs, PDDL, and Behavior Trees for Hierarchical Multi-Robot Planning","Haishan Zeng, Peng Li",,arXiv:2601.11063v1,"multi-robot planning, large language models, PDDL, behavior trees, heterogeneous robot teams, long-horizon tasks, dynamic environments","In embodied artificial intelligence, enabling heterogeneous robot teams to execute long-horizon tasks from high-level instructions remains a critical challenge. While large language models (LLMs) show promise in instruction parsing and preliminary planning, they exhibit limitations in long-term reasoning and dynamic multi-robot coordination. We propose Hierarchical Autonomous Intelligent Multi-Robot Planning (H-AIM), a novel embodied multi-robot task planning framework that addresses these issues through a three-stage cascaded architecture: 1) It leverages an LLM to parse instructions and generate Planning Domain Definition Language (PDDL) problem descriptions, thereby transforming commands into formal planning problems; 2) It combines the semantic reasoning of LLMs with the search capabilities of a classical planner to produce optimized action sequences; 3) It compiles the resulting plan into behavior trees for reactive control. The framework supports dynamically sized heterogeneous robot teams via a shared blackboard mechanism for communication and state synchronization. To validate our approach, we introduce the MACE-THOR benchmark dataset, comprising 42 complex tasks across 8 distinct household layouts. Experimental results demonstrate that H-AIM achieves a remarkable performance improvement, elevating the task success rate from 12% to 55% and boosting the goal condition recall from 32% to 72% against the strongest baseline, LaMMA-P.",3.67,108.806,399,cold_start,Phi-4,Apple_M1(Metal)
2601.11065v1_Fairness in Healthcare Processes A Quantitative An.pdf,Fairness in Healthcare Processes: A Quantitative Analysis of Decision Making in Triage,"Rachmadita Andreswari, Stephan A. Fahrenkrog-Petersen, Jan Mendling",,2601.11065v1,"process mining, fairness, triage, emergency room","Fairness in automated decision-making has become a critical concern, particularly in high-pressure healthcare scenarios such as emergency triage, where fast and equitable decisions are essential. Process mining is increasingly investigating fairness. There is a growing area focusing on fairness-aware algorithms. So far, we know less how these concepts perform on empirical healthcare data or how they cover aspects of justice theory. This study addresses this research problem and proposes a process mining approach to assess fairness in triage by linking real-life event logs with conceptual dimensions of justice. Using the MIMICEL event log (as derived from MIMIC-IV ED), we analyze time, re-do, deviation and decision as process outcomes, and evaluate the influence of age, gender, race, language and insurance using the Kruskal–Wallis, Chi-square and effect size measurements. These outcomes are mapped to justice dimensions to support the development of a conceptual framework. The results demonstrate which aspects of potential unfairness in high-acuity and sub-acute surface. In this way, this study contributes empirical insights that support further research in responsible, fairness-aware process mining in healthcare.",3.7,91.001,337,cold_start,Phi-4,Apple_M1(Metal)
2601.11073v1_Bridging Cognitive Neuroscience and Graph Intellig.pdf,Bridging Cognitive Neuroscience and Graph Intelligence: Hippocampus-Inspired Multi-View Hypergraph Learning for Web Finance Fraud,"Rongkun Cui, Nana Zhang, Kun Zhu, Qi Zhang",https://doi.org/XXXXXXX.XXXXXXX,,"Information systems, Data mining, Social and professional topics, Economic impact","Online financial services are crucial to modern web ecosystems but are vulnerable to fraud, which undermines trust and harms users. Existing graph neural network (GNN) methods face challenges like fraud camouflage and long-tailed data distributions. This paper introduces HIMVH, a Hippocampus-Inspired Multi-View Hypergraph learning model, to address these issues. It features a cross-view inconsistency perception module and a novelty-aware hypergraph learning module, inspired by the hippocampus's role in conflict monitoring and novelty detection. Experiments on six datasets show HIMVH's superior performance, with significant improvements in AUC, F1, and AP metrics over 15 state-of-the-art models.",3.11,76.966,239,cold_start,Phi-4,Apple_M1(Metal)
2601.11076v1_A3D Adaptive Affordance Assembly with Dual-Arm Man.pdf,A3D: Adaptive Affordance Assembly with Dual-Arm Manipulation,"Jiaqi Liang, Yue Chen, Qize Yu, Yan Shen, Haipeng Zhang, Hao Dong, Ruihai Wu",,,"furniture assembly, dual-arm manipulation, adaptive affordance, robotics, generalization, simulation environment","Furniture assembly is a challenging task for robots, requiring precise dual-arm coordination. The proposed A3D framework learns adaptive affordances to identify optimal support and stabilization locations on furniture parts. It employs dense point-level geometric representations to model part interaction patterns, enabling generalization across varied geometries. An adaptive module uses interaction feedback to dynamically adjust support strategies during assembly. A simulation environment with 50 diverse parts across 8 furniture types is established for evaluation. Experiments show effective generalization to diverse part geometries and furniture categories in both simulation and real-world settings.",3.05,80.688,246,cold_start,Phi-4,Apple_M1(Metal)
2601.11077v1_ABC-Bench Benchmarking Agentic Backend Coding in R.pdf,ABC-Bench: Benchmarking Agentic Backend Coding in Real-World Development,"Jie Yang, Honglin Guo, Li Ji, Jiazheng Zhou, Rui Zheng, Zhikai Lei, Shuo Zhang, Zhiheng Xi, Shichun Liu, Yuxin Wang, Bo Wang, Yining Zheng, Tao Gui, Xipeng Qiu",,arXiv:2601.11077v1,"Large Language Models, autonomous agents, backend development, software engineering, benchmarking, repository-level problem solving, containerized services, API tests","The evolution of Large Language Models (LLMs) into autonomous agents has expanded the scope of AI coding from localized code generation to complex, repository-level, and execution-driven problem solving. However, current benchmarks predominantly evaluate code logic in static contexts, neglecting the dynamic, full-process requirements of real-world engineering, particularly in backend development which demands rigorous environment configuration and service deployment. To address this gap, we introduce ABC-Bench, a benchmark explicitly designed to evaluate agentic backend coding within a realistic, executable workflow. Using a scalable automated pipeline, we curated 224 practical tasks spanning 8 languages and 19 frameworks from open-source repositories. Distinct from previous evaluations, ABC-Bench require the agents to manage the entire development lifecycle from repository exploration to instantiating containerized services and pass the external end-to-end API tests. Our extensive evaluation reveals that even state-of-the-art models struggle to deliver reliable performance on these holistic tasks, highlighting a substantial disparity between current model capabilities and the demands of practical backend engineering.",3.83,105.469,404,cold_start,Phi-4,Apple_M1(Metal)
2601.11078v1_Visual Marker Search for Autonomous Drone Landing .pdf,Visual Marker Search for Autonomous Drone Landing in Diverse Urban Environments,"Jiaohong Yao, Linfeng Liang, Yao Deng, Xi Zheng, Richard Han, Yuankai Qi",,,"Drone navigation, marker-based landing, reinforcement learning, AirSim, robustness","Marker-based landing is widely used in drone delivery and return-to-base systems for its simplicity and reliability. However, most approaches assume idealized landing site visibility and sensor performance, limiting robustness in complex urban settings. This paper presents a simulation-based evaluation suite on the AirSim platform with systematically varied urban layouts, lighting, and weather to replicate realistic operational diversity. Using onboard camera sensors—RGB for marker detection and depth for obstacle avoidance—we benchmark two heuristic coverage patterns and a reinforcement learning–based agent, analyzing how exploration strategy and scene complexity affect success rate, path efficiency, and robustness. Results underscore the need to evaluate marker-based autonomous landing under diverse, sensor-relevant conditions to guide the development of reliable aerial navigation systems.",3.28,73.367,241,cold_start,Phi-4,Apple_M1(Metal)
2601.11089v2_MiCA A Mobility-Informed Causal Adapter for Lightw.pdf,MiCA: A Mobility-Informed Causal Adapter for Lightweight Epidemic Forecasting,"Suhan Guo, Jiahong Deng, Furao Shen",,,"epidemic forecasting, mobility, causal discovery, temporal forecasting, COVID-19, influenza, dengue","Accurate forecasting of infectious disease dynamics is critical for public health planning and intervention. Human mobility significantly influences the spatial spread of epidemics, but mobility data are often noisy and difficult to integrate with disease records. Epidemic case time series are typically short and reported at coarse temporal resolution, limiting the effectiveness of parameter-heavy mobility-aware forecasters. This work introduces the Mobility-Informed Causal Adapter (MiCA), a lightweight and architecture-agnostic module for epidemic forecasting. MiCA infers mobility relations through causal discovery and integrates them into temporal forecasting models via gated residual mixing. This design allows lightweight forecasters to exploit mobility-derived spatial structure while remaining robust under noisy and data-limited conditions, without introducing heavy relational components. Extensive experiments on four real-world epidemic datasets, including COVID-19 incidence, COVID-19 mortality, influenza, and dengue, show that MiCA consistently improves lightweight temporal backbones, achieving an average relative error reduction of 7.5% across forecasting horizons. Moreover, MiCA attains performance competitive with state-of-the-art spatio-temporal models while remaining lightweight.",3.51,96.594,339,cold_start,Phi-4,Apple_M1(Metal)
2601.11090v1_Efficient Multilingual Name Type Classification Us.pdf,Efficient Multilingual Name Type Classification Using Convolutional Networks,Davor Lauc,,,"multilingual NLP, named entity recognition, convolutional neural networks, efficient inference, proper names","This paper presents a convolutional neural network approach for classifying proper names by language and entity type. The model, Onomas-CNN X, combines parallel convolution branches with depthwise-separable operations and hierarchical classification to process names efficiently on CPU hardware. It achieves 92.1% accuracy while processing 2,813 names per second on a single CPU core, 46 times faster than fine-tuned XLM-RoBERTa with comparable accuracy. The model also reduces energy consumption by a factor of 46 compared to transformer baselines. The experiments demonstrate that specialized CNN architectures remain competitive with large pretrained models for focused NLP tasks when sufficient training data exists.",2.94,69.114,203,cold_start,Phi-4,Apple_M1(Metal)
2601.11100v1_ReCreate Reasoning and Creating Domain Agents Driv.pdf,ReCreate: Reasoning and Creating Domain Agents Driven by Experience,"Zhezheng Hao, Hong Wang, Jian Luo, Jianqing Zhang, Yuyan Zhou, Qiang Lin, Can Wang, Hande Dong, Jiawei Chen",,,"Large Language Models, LLM agents, domain agents, experience-driven framework, agent creation, scaffold, automation","Large Language Model (LLM) agents are reshaping the industrial landscape, but most are still human-designed due to the labor-intensive nature of building task-specific agents. This paper introduces ReCreate, an experience-driven framework for automatically creating domain agents. ReCreate leverages agent interaction histories to provide insights into success and failure, using an agent-as-optimizer paradigm with three key components: experience storage and retrieval, a reasoning-creating synergy pipeline, and hierarchical updates. Experiments show that ReCreate outperforms human-designed agents and existing automated methods, even with minimal initial scaffolds.",3.17,82.664,262,cold_start,Phi-4,Apple_M1(Metal)
2601.11109v1_Vision-as-Inverse-Graphics Agent via Interleaved M.pdf,Vision-as-Inverse-Graphics Agent via Interleaved Multimodal Reasoning,"Shaofeng Yin, Jiaxin Ge, Zora Zhiruo Wang, Xiuyu Li, Michael J. Black, Trevor Darrell, Angjoo Kanazawa, Haiwen Feng",,arXiv:2601.11109v1,"computer vision, 3D reconstruction, multimodal reasoning, iterative execution, verification, graphics program, BlenderGym, SlideBench, BlenderBench","Vision-as-inverse-graphics, the concept of reconstructing an image as an editable graphics program, is a longstanding goal of computer vision. This paper introduces VIGA (Vision-as-Inverse-Graphic Agent), which reconstructs or edits scenes through a closed-loop write→run→render→compare→revise procedure. VIGA combines a skill library and an evolving context memory to support long-horizon reasoning, covering tasks like 3D reconstruction, scene editing, and document editing. It improves one-shot baselines on BlenderGym and SlideBench and is model-agnostic, enabling evaluation of various VLMs. The paper also introduces BlenderBench, a benchmark for evaluating these models.",3.56,90.855,323,cold_start,Phi-4,Apple_M1(Metal)
2601.11124v1_Learn Before Represent Bridging Generative and Con.pdf,Learn Before Represent: Bridging Generative and Contrastive Learning for Domain-Specific LLM Embeddings,"Xiaoyu Liang, Yuchen Peng, Jiale Luo, Wenhao Wang, Haoji Hu, Xincheng Zhou",,arXiv:2601.11,"Large Language Models, Contrastive Learning, Generative Learning, Domain-Specific Knowledge, LLM Embeddings, Information Bottleneck, Semantic Alignment, Knowledge Acquisition, Vertical Domains","Large Language Models (LLMs) adapted via contrastive learning excel in general representation learning but struggle in vertical domains like chemistry and law due to a lack of domain-specific knowledge. This work proposes a novel two-stage framework, Learn Before Represent (LBR), which first injects domain knowledge via an Information Bottleneck-Constrained Generative Learning stage, preserving the LLM’s causal attention to maximize knowledge acquisition while compressing semantics. It then performs Generative-Refined Contrastive Learning on the compressed representations for alignment. This approach maintains architectural consistency and resolves the objective conflict between generative and contrastive learning. Extensive experiments on medical, chemistry, and code retrieval tasks show that LBR significantly outperforms strong baselines, establishing a new paradigm for building accurate and robust representations in vertical domains.",3.4,95.266,324,cold_start,Phi-4,Apple_M1(Metal)
2601.11135v1_Context-aware Graph Causality Inference for Few-Sh.pdf,Context-aware Graph Causality Inference for Few-Shot Molecular Property Prediction,"Van Thuy Hoang, O-Joun Lee",,,"molecular property prediction, graph learning, few-shot learning, causal inference, functional groups, substructures","Molecular property prediction is a significant application of graph learning in web-based services like online protein structure prediction and drug discovery. A key challenge is the few-shot scenario, where only a few labeled molecules are available for predicting unseen properties. Existing studies using in-context learning face limitations in exploiting prior knowledge of functional groups causally linked to properties and identifying key substructures correlated with properties. This paper proposes CaMol, a context-aware graph causality inference framework, to address these challenges by using a causal inference perspective. CaMol assumes each molecule has a latent causal structure determining a specific property. It introduces a context graph encoding chemical knowledge, a learnable atom masking strategy to disentangle causal substructures, and a distribution intervener applying backdoor adjustment. Experiments on diverse molecular datasets show CaMol's superior accuracy and sample efficiency in few-shot tasks, demonstrating generalizability to unseen properties. The discovered causal substructures align with chemical knowledge about functional groups, supporting model interpretability.",3.32,86.434,287,cold_start,Phi-4,Apple_M1(Metal)
2601.11143v1_Learning Quadrupedal Locomotion for a Heavy Hydrau.pdf,Learning Quadrupedal Locomotion for a Heavy Hydraulic Robot Using an Actuator Model,"Minho Lee, Hyeonseok Kim, Jin Tak Kim, Sangshin Park, Jeong Hyun Lee, Jungsan Cho, Jemin Hwangbo",,,"Hydraulic/Pneumatic Actuators, Legged Robots, Reinforcement Learning","The simulation-to-reality (sim-to-real) transfer of large-scale hydraulic robots presents a significant challenge in robotics due to slow control response and complex fluid dynamics. This work proposes an analytical actuator model driven by hydraulic dynamics to represent complicated actuators, predicting joint torques for all 12 actuators in under 1 microsecond, facilitating rapid processing in reinforcement learning (RL) environments. The model is compared with neural network-based actuator models, demonstrating advantages in data-limited scenarios. The locomotion policy trained with this model is deployed on a hydraulic quadruped robot weighing over 300 kg, marking the first successful transfer of stable and robust command-tracking locomotion with RL on a heavy hydraulic quadruped robot, showcasing advanced sim-to-real transferability.",3.24,88.511,287,cold_start,Phi-4,Apple_M1(Metal)
2601.11144v2_Deep GraphRAG A Balanced Approach to Hierarchical .pdf,Deep GraphRAG: A Balanced Approach to Hierarchical Retrieval and Adaptive Integration,"Yuejie Li, Ke Yang, Tao Wang, Bolin Chen, Bowen Li, Chengjun Mao",,,"GraphRAG, Reinforcement Learning, Large Language Models","Graph-based Retrieval-Augmented Generation (GraphRAG) frameworks face a trade-off between the comprehensiveness of global search and the efficiency of local search. Existing methods are often challenged by navigating large-scale hierarchical graphs, optimizing retrieval paths, and balancing exploration-exploitation dynamics, frequently lacking robust multi-stage re-ranking. To overcome these deficits, we propose Deep GraphRAG, a framework designed for a balanced approach to hierarchical retrieval and adaptive integration. It introduces a hierarchical global-to-local retrieval strategy that integrates macroscopic inter-community and microscopic intra-community contextual relations. This strategy employs a three-stage process: (1) inter-community filtering, which prunes the search space using local context; (2) community-level refinement, which prioritizes relevant subgraphs via entity-interaction analysis; and (3) entity-level fine-grained search within target communities. A beam search-optimized dynamic re-ranking module guides this process, continuously filtering candidates to balance efficiency and global comprehensiveness. Deep GraphRAG also features a Knowledge Integration Module leveraging a compact LLM, trained with Dynamic Weighting Reward GRPO (DW-GRPO). This novel reinforcement learning approach dynamically adjusts reward weights to balance three key objectives: relevance, faithfulness, and conciseness. This training enables compact models (1.5B) to approach the performance of large models (70B) in the integration task. Evaluations on Natural Questions and HotpotQA demonstrate that Deep GraphRAG significantly outperforms baseline graph retrieval methods in both accuracy and efficiency.",3.62,115.059,417,cold_start,Phi-4,Apple_M1(Metal)
2601.11147v1_Do We Always Need Query-Level Workflows Rethinking.pdf,Do We Always Need Query-Level Workflows? Rethinking Agentic Workflow Generation for Multi-Agent Systems,"Zixu Wang, Bingbing Xu, Yige Yuan, Huawei Shen, Xueqi Cheng",,,"Multi-Agent Systems, Large Language Models, Workflow Generation, Task-Level, Query-Level, Evaluation, Token Usage","Multi-Agent Systems (MAS) built on large language models typically solve complex tasks by coordinating multiple agents through workflows. Existing approaches generate workflows either at task level or query level, but their relative costs and benefits remain unclear. This paper rethinks and empirically analyzes these approaches, showing that query-level workflow generation is not always necessary. A small set of top-K best task-level workflows can cover equivalent or even more queries. The paper introduces SCALE, a low-cost task-level generation framework that maintains competitive performance with significantly reduced token usage.",3.01,69.473,209,cold_start,Phi-4,Apple_M1(Metal)
2601.11151v1_Cross-Modal Attention Network with Dual Graph Lear.pdf,Cross-Modal Attention Network with Dual Graph Learning in Multimodal Recommendation,"JI DAI, QUAN FANG, JUN HU, DESHENG CAI, YANG YANG, CAN ZHAO",https://doi.org/XXXXXXX.XXXXXXX,,"Recommender systems, Multimedia information systems, Neural networks, Multimedia recommendation, Graph Neural Network, Multimodal Fusion","Multimedia recommendation systems leverage user-item interactions and multimodal information to capture user preferences, enabling more accurate and personalized recommendations. Despite notable advancements, existing approaches still face two critical limitations: first, shallow modality fusion often relies on simple concatenation, failing to exploit rich synergic intra- and inter-modal relationships; second, asymmetric feature treatment—where users are only characterized by interaction IDs while items benefit from rich multimodal content—hinders the learning of a shared semantic space. To address these issues, we propose a Cross-modal Recursive Attention Network with dual graph Embedding (CRANE). To tackle shallow fusion, we design a core Recursive Cross-Modal Attention (RCA) mechanism that iteratively refines modality features based on cross-correlations in a joint latent space, effectively capturing high-order intra- and inter-modal dependencies. For symmetric multimodal learning, we explicitly construct users’ multimodal profiles by aggregating features of their interacted items. Furthermore, CRANE integrates a symmetric dual-graph framework—comprising a heterogeneous user-item interaction graph and a homogeneous item-item semantic graph—unified by a self-supervised contrastive learning objective to fuse behavioral and semantic signals. Despite these complex modeling capabilities, CRANE maintains high computational efficiency. Theoretical and empirical analyses confirm its scalability and high practical efficiency, achieving faster convergence on small datasets and superior performance ceilings on large-scale ones. Comprehensive experiments on four public real-world datasets validate an average 5% improvement in key metrics over state-of-the-art baselines. Our code is publicly available at https://github.com/MKC-Lab/CRANE.",3.65,120.526,440,cold_start,Phi-4,Apple_M1(Metal)
2601.11160v1_Clustering High-dimensional Data Balancing Abstrac.pdf,Clustering High-dimensional Data: Balancing Abstraction and Representation,"Claudia Plant, Lena G. M. Bauer, Christian Böhm",,,"clustering, abstraction, representation, high-dimensional data, subspace clustering, deep clustering, centroid-based clustering, density-based clustering, latent space, representation learning","This tutorial discusses the challenge of clustering high-dimensional data by balancing abstraction and representation. It explores how different clustering algorithms implement this balance, with examples like K-means and approaches to subspace and deep clustering. The tutorial highlights the need for explicit abstraction in the objective function to ensure effective clustering. It concludes with future research directions aimed at adaptively balancing abstraction and representation for improved performance, energy efficiency, and interpretability, drawing inspiration from the human brain's capabilities.",3.19,68.935,220,cold_start,Phi-4,Apple_M1(Metal)
2601.11178v1_TANDEM Temporal-Aware Neural Detection for Multimo.pdf,TANDEM: Temporal-Aware Neural Detection for Multimodal Hate Speech,"Girish A. Koushik, Helen Treharne, Diptesh Kanojia",,,"multimodal hate speech, temporal-aware neural detection, audio-visual hate detection, reinforcement learning, structured reasoning, online safety moderation","Social media platforms are increasingly dominated by long-form multimodal content, where harmful narratives are constructed through a complex interplay of audio, visual, and textual cues. Automated systems can flag hate speech with high accuracy but often function as 'black boxes' that fail to provide the granular, interpretable evidence required for effective human-in-the-loop moderation. This work introduces TANDEM, a unified framework that transforms audio-visual hate detection from a binary classification task into a structured reasoning problem. The approach employs a novel tandem reinforcement learning strategy where vision-language and audio-language models optimize each other through self-constrained cross-modal context, stabilizing reasoning over extended temporal sequences without requiring dense frame-level supervision. Experiments across three benchmark datasets demonstrate that TANDEM significantly outperforms zero-shot and context-augmented baselines, achieving 0.73 F1 in target identification on HateMM (a ≈ 30% improvement over state-of-the-art) while maintaining precise temporal grounding. The findings suggest that structured, interpretable alignment is achievable even in complex multimodal settings, offering a blueprint for the next generation of transparent and actionable online safety moderation tools.",3.55,100.863,358,cold_start,Phi-4,Apple_M1(Metal)
2601.11189v1_Policy-Based Deep Reinforcement Learning Hyperheur.pdf,Policy-Based Deep Reinforcement Learning Hyperheuristics for Job-Shop Scheduling Problems,"Sofiene Lassoued, Asrat Gobachew, Stefan Lier, Andreas Schwung",,,"Hyper-heuristics, Job Shop Scheduling, Policy-based Reinforcement learning, Petri nets","This paper proposes a policy-based deep reinforcement learning hyper-heuristic framework for solving the Job Shop Scheduling Problem. The hyper-heuristic agent learns to switch scheduling rules based on the system state dynamically. The framework is extended with two key mechanisms: action prefiltering, which restricts decision-making to feasible low-level actions, and a commitment mechanism that regulates the frequency of heuristic switching. The impact of different commitment strategies and action selection strategies at the policy level is investigated. Computational experiments on standard JSSP benchmarks demonstrate that the proposed approach outperforms traditional heuristics, metaheuristics, and recent neural network-based scheduling methods.",3.21,76.367,245,cold_start,Phi-4,Apple_M1(Metal)
2601.11196v1_Artificial Intelligence and the US Economy An Acco.pdf,Artificial Intelligence and the US Economy: An Accounting Perspective on Investment and Production,"Luisa Carpinelli, Filippo Natoli, Marco Taboga",,2601.11196v1,"artificial intelligence, capital expenditures, data centers, national accounts","Artificial intelligence (AI) has moved to the center of policy, market, and academic debates, but its macroeconomic footprint is still only partly understood. This paper provides an overview on how the current AI wave is captured in US national accounts, combining a simple macro-accounting framework with a stylized description of the AI production process. It highlights the crucial role played by data centers, which constitute the backbone of the AI ecosystem and have attracted formidable investment in 2025, as they are indispensable for meeting the rapidly increasing worldwide demand for AI services. The paper documents that the boom in IT and AI-related capital expenditure in the first three quarters of the year has given an outsized boost to aggregate demand, while its contribution to GDP growth is smaller once the high import content of AI hardware is netted out. Furthermore, simple calculations suggest that, at current utilization rates and pricing, the production of services originating in new AI data centers could contribute to GDP over the turn of the next quarters on a scale comparable to that of investment spending to date. Short reinvestment cycles and uncertainty about future AI demand – while not currently acting as a macroeconomic drag – can nevertheless fuel macroeconomic risks over the medium term.",3.81,90.751,346,cold_start,Phi-4,Apple_M1(Metal)
2601.11199v1_SD-RAG A Prompt-Injection-Resilient Framework for .pdf,SD-RAG: A Prompt-Injection-Resilient Framework for Selective Disclosure in Retrieval-Augmented Generation,"Aiman Al Masoud, Marco Arazzi, Antonino Nocera",,,"Retrieval-Augmented Generation, Large Language Models, Selective Disclosure, Privacy, Security, Prompt Injection Attacks","Retrieval-Augmented Generation (RAG) combines the generative capabilities of Large Language Models (LLMs) with efficient retrieval mechanisms over large-scale data collections. Existing approaches often overlook the risks of exposing sensitive information directly to the generation model. This paper introduces SD-RAG, a novel approach to Selective Disclosure in RAG, which decouples security and privacy constraints from the generation process. SD-RAG applies sanitization and disclosure controls during the retrieval phase, prior to augmenting the language model’s input. It introduces a semantic mechanism for human-readable dynamic security and privacy constraints, along with an optimized graph-based data model for fine-grained, policy-aware retrieval. Experimental evaluation shows SD-RAG's superiority over baseline approaches, achieving up to a 58% improvement in privacy score and strong resilience to prompt injection attacks.",3.41,83.631,285,cold_start,Phi-4,Apple_M1(Metal)
2601.11200v1_FAQ Mitigating Quantization Error via Regenerating.pdf,Mitigating Quantization Error via Regenerating Calibration Data with Family-Aware Quantization,"Haiyang Xiao, Weiqing Li, Jinyue Guo, Guochao Jiang, Guohua Liu, Yuewei Zhang",,,"Post-training quantization, Large language models, Calibration data, Quantization parameters, Family-aware quantization","Post-training quantization (PTQ) is an efficient numerical compression scheme for deploying large language models (LLMs) on resource-constrained devices. However, the representativeness and universality of calibration data are core bottlenecks in determining the accuracy of quantization parameters. Traditional PTQ methods rely on limited samples, which may not capture the activation distribution during the inference phase, leading to biases in quantization parameters. This paper proposes FAQ (Family-Aware Quantization), a calibration data regeneration framework that leverages prior knowledge from LLMs of the same family to generate high-fidelity calibration samples. FAQ inputs the original calibration samples into a larger LLM from the same family as the target model, regenerating high-fidelity calibration data. This data, carrying Chain-of-Thought reasoning and conforming to the expected activation distribution, undergoes group competition under expert guidance to select the best samples, which are then re-normalized to enhance the effectiveness of standard PTQ. Experiments on multiple model series, including Qwen3-8B, show that FAQ reduces accuracy loss by up to 28.5% compared to the baseline with original calibration data, demonstrating its powerful potential and contribution.",3.46,100.322,347,cold_start,Phi-4,Apple_M1(Metal)
2601.11202v1_Epistemic Control and the Normativity of Machine L.pdf,EPISTEMIC CONTROL AND THE NORMATIVITY OF MACHINE LEARNING-BASED SCIENCE,Emanuele Ratti,,,"machine learning, epistemic control, cognitive values, normativity","The chapter investigates the extent to which human scientists are pushed out-of-the-loop in machine learning (ML) systems in science, as argued by Paul Humphreys. It introduces the concept of 'epistemic control' with conditions 'tracking' and 'tracing', and argues against Humphreys' pessimistic view. A nuanced view of epistemic control in ML-based science is constructed, addressing the challenges of maintaining meaningful control over automated computational tools in various contexts, including science.",3.12,56.332,176,cold_start,Phi-4,Apple_M1(Metal)
2601.11207v1_LoRA as Oracle.pdf,LoRA as Oracle,"Marco Arazzi, Antonino Nocera",,,"LoRA, Membership Inference Attack, Backdoor Attack","Backdoored and privacy-leaking deep neural networks pose a serious threat to the deployment of machine learning systems in security-critical settings. Existing defenses for backdoor detection and membership inference typically require access to clean reference models, extensive retraining, or strong assumptions about the attack mechanism. This work introduces a novel LoRA-based oracle framework that leverages low-rank adaptation modules as a lightweight, model-agnostic probe for both backdoor detection and membership inference. The approach attaches task-specific LoRA adapters to a frozen backbone and analyzes their optimization dynamics and representation shifts when exposed to suspicious samples. It shows that poisoned and member samples induce distinctive low-rank updates that differ significantly from those generated by clean or non-member data. These signals can be measured using simple ranking and energy-based statistics, enabling reliable inference without access to the original training data or modification of the deployed model.",3.29,75.972,250,cold_start,Phi-4,Apple_M1(Metal)
2601.11219v1_SDFLoRA Selective Dual-Module LoRA for Federated F.pdf,SDFLoRA: Selective Dual-Module LoRA for Federated Fine-tuning with Heterogeneous Clients,"Zhikang Shen, Jianrong Lu, Haiyuan Wan, Jianhai Chen",,,"Federated Learning, Large Language Models, LoRA, Parameter-Efficient Methods, Rank Heterogeneity, Differential Privacy, Personalization","Federated learning (FL) for large language models (LLMs) is gaining attention for privacy-preserving adaptation across distributed data. Parameter-efficient methods like LoRA are used to reduce communication and memory costs. However, practical FL deployments face rank heterogeneity, where clients use different low-rank configurations, leading to biased and unstable aggregation of LoRA updates. Existing solutions either enforce unified ranks or align updates into a shared subspace, which limits personalization and weakens privacy protection. This paper proposes Selective Dual-module Federated LoRA (SDFLoRA), which decomposes each client adapter into a global module for transferable knowledge and a local module for client-specific adaptations. The global module is selectively aligned and aggregated across clients, while local modules remain private. This approach enables robust learning under rank heterogeneity and privacy-aware optimization by injecting differential privacy noise exclusively into the global module. Experiments on GLUE benchmarks show that SDFLoRA outperforms federated LoRA baselines and achieves a better utility–privacy trade-off.",3.51,98.032,344,cold_start,Phi-4,Apple_M1(Metal)
2601.11232v1_FactCorrector A Graph-Inspired Approach to Long-Fo.pdf,FACTCORRECTOR: A Graph-Inspired Approach to Long-Form Factuality Correction of Large Language Models,"Javier Carnerero-Cano, Massimiliano Pronesti, Radu Marinescu, Tigran Tchrakian, James Barry, Jasmina Gajcin, Yufang Hou, Alessandra Pascale, Elizabeth Daly",,,"Large Language Models, Factuality Correction, Post-hoc Correction, Feedback, VELI5 Benchmark","Large language models (LLMs) are widely used in knowledge-intensive applications but often generate factually incorrect responses. This paper introduces FACTCORRECTOR, a new post-hoc correction method that adapts across domains without retraining and leverages structured feedback about the factuality of the original response to generate a correction. The paper also presents the VELI5 benchmark, a novel dataset containing systematically injected factual errors and ground-truth corrections. Experiments show that FACTCORRECTOR significantly improves factual precision while preserving relevance, outperforming strong baselines.",3.07,79.809,245,cold_start,Phi-4,Apple_M1(Metal)
2601.11252v1_Beyond Model Scaling Test-Time Intervention for Ef.pdf,BEYONDMODELSCALING: TEST-TIME INTERVENTION FOR EFFICIENT DEEP REASONING,"Qianyue Wang, Jinwu Hu, Yufeng Wang, Huanxiang Lin, Bolin Chen, Zhiquan Wen, Yaofo Chen, Mingkui Tan",,,"Large Reasoning Models, Efficient Reasoning, Test-time Intervention, Overthinking, Overshoot, External Feedback, Transitional Conjunctions, Group Relative Policy Optimization, Multi-criteria Evaluation","Large Reasoning Models (LRMs) excel at multi-step reasoning but often suffer from inefficient reasoning processes like overthinking and overshoot, where excessive or misdirected reasoning increases computational cost and degrades performance. Existing efficient reasoning methods operate in a closed-loop manner, lacking mechanisms for external intervention to guide the reasoning process. To address this, we propose Think-with-Me, a novel test-time interactive reasoning paradigm that introduces external feedback intervention into the reasoning process. Our key insights are that transitional conjunctions serve as natural points for intervention, signaling phases of self-validation or exploration and using transitional words appropriately to prolong the reasoning enhances performance, while excessive use affects performance. Building on these insights, Think-with-Me pauses reasoning at these points for external feedback, adaptively extending or terminating reasoning to reduce redundancy while preserving accuracy. The feedback is generated via a multi-criteria evaluation (rationality and completeness) and comes from either human or LLM proxies. We train the target model using Group Relative Policy Optimization (GRPO) to adapt to this interactive mode. Experiments show that Think-with-Me achieves a superior balance between accuracy and reasoning length under limited context windows. On AIME24, Think-with-Me outperforms QwQ-32B by 7.19% in accuracy while reducing average reasoning length by 81% under an 8K window. The paradigm also benefits security and creative tasks.",3.65,126.721,463,cold_start,Phi-4,Apple_M1(Metal)
2601.11258v1_Knowledge is Not Enough Injecting RL Skills for Co.pdf,Knowledge is Not Enough: Injecting RL Skills for Continual Adaptation,"Pingzhi Tang, Yiding Wang, Muhan Zhang",,,"Large Language Models, knowledge cutoff, Supervised Fine-Tuning, Reinforcement Learning, Parametric Skill Transfer, knowledge adaptation, question answering, decision-making, Skill Vector, knowledge-incorporation QA, agentic tool-use benchmarks","Large Language Models (LLMs) face the 'knowledge cutoff' challenge, where their frozen parametric memory prevents direct internalization of new information. While Supervised Fine-Tuning (SFT) is commonly used to update model knowledge, it often updates factual content without reliably improving the model’s ability to use the newly incorporated information for question answering or decision-making. Reinforcement Learning (RL) is essential for acquiring reasoning skills; however, its high computational cost makes it impractical for efficient online adaptation. The authors propose Parametric Skill Transfer (PaST), a framework that supports modular skill transfer for efficient and effective knowledge adaptation. By extracting a domain-agnostic Skill Vector from a source domain, they can linearly inject knowledge manipulation skills into a target model after it has undergone lightweight SFT on new data. Experiments demonstrate the effectiveness of PaST, showing significant performance improvements across various benchmarks.",3.29,96.876,319,cold_start,Phi-4,Apple_M1(Metal)
2601.11269v1_X-Distill Cross-Architecture Vision Distillation f.pdf,X-Distill: Cross-Architecture Vision Distillation for Visuomotor Learning,"Maanping Shao, Feihong Zhang, Gu Zhang, Baiye Cheng, Zhengrong Xue, Huazhe Xu",,,"Visuomotor Policy, Knowledge Distillation, Representation Learning, Manipulation","Visuomotor policies often leverage large pre-trained Vision Transformers (ViTs) for their powerful generalization capabilities. However, their significant data requirements present a major challenge in the data-scarce context of most robotic learning settings, where compact CNNs with strong inductive biases can be more easily optimized. To address this trade-off, we introduce X-Distill, a simple yet highly effective method that synergizes the strengths of both architectures. Our approach involves an offline, cross-architecture knowledge distillation, transferring the rich visual representations of a large, frozen DINOv2 teacher to a compact ResNet-18 student on the general-purpose ImageNet dataset. This distilled encoder, now endowed with powerful visual priors, is then jointly fine-tuned with a diffusion policy head on the target manipulation tasks. Extensive experiments on 34 simulated benchmarks and 5 challenging real-world tasks demonstrate that our method consistently outperforms policies equipped with from-scratch ResNet or fine-tuned DINOv2 encoders. Notably, X-Distill also surpasses 3D encoders that utilize privileged point cloud observations or much larger Vision-Language Models. Our work highlights the efficacy of a simple, well-founded distillation strategy for achieving state-of-the-art performance in data-efficient robotic manipulation.",3.43,111.224,382,cold_start,Phi-4,Apple_M1(Metal)
2601.11282v1_From SERPs to Sound How Search Engine Result Pages.pdf,From SERPs to Sound: How Search Engine Result Pages and AI-generated Podcasts Interact to Influence User Attitudes on Controversial Topics,"Junjie Wang, Gaole He, Alisa Rieger, Ujwal Gadiraju",10.1145/3786304.3787942,,"Attitude Change, AI-generated Podcasts, Information modality, Web search, Controversial Topics, Responsible Opinion Formation","This study explores how search engine result pages (SERPs) and AI-generated podcasts interact to influence user attitudes on controversial topics. Through a controlled user study with 483 participants, the research investigates how the sequence and modality of information exposure affect user opinions. The study finds that a majority of users experienced attitude change, with sequence playing a significant role. Additionally, viewpoint bias and topic controversiality were found to influence attitude change, though no effect was observed from individual moderators.",3.04,79.324,241,cold_start,Phi-4,Apple_M1(Metal)
2601.11286v1_XChoice Explainable Evaluation of AI-Human Alignme.pdf,XChoice: Explainable Evaluation of AI–Human Alignment in LLM-based Constrained Choice Decision Making,"Weihong Qi, Fan Huang, Rasika Muralidharan, Jisun An, Haewoon Kwak",,,"AI-human alignment, LLM-based decision making, constrained choice, explainable framework, mechanism-based decision model, parameter vectors, misalignment, retrieval-augmented generation, invariance analysis","We present XCHOICE, an explainable framework for evaluating AI-human alignment in constrained decision making. XCHOICE fits a mechanism-based decision model to human data and LLM-generated decisions, recovering interpretable parameters that capture the relative importance of decision factors, constraint sensitivity, and implied trade-offs. Alignment is assessed by comparing these parameter vectors across models, options, and subgroups. The framework is demonstrated using Americans’ daily time allocation data, revealing heterogeneous alignment across models and activities, with notable misalignment in Black and married groups. XCHOICE provides mechanism-based metrics that diagnose misalignment and support informed improvements beyond surface outcome matching.",3.23,88.309,285,cold_start,Phi-4,Apple_M1(Metal)
2601.11344v1_How Much Would a Clinician Edit This Draft Evaluat.pdf,How Much Would a Clinician Edit This Draft? Evaluating LLM Alignment for Patient Message Response Drafting,"Parker Seegmiller, Joseph Gatto, Sarah E. Greer, Ganza Belise Isingizwe, Rohan Ray, Timothy Burdick, Sarah M. Preum",,,"Large Language Models, Clinical Workflows, Patient Portal Messages, LLM Alignment, Thematic Elements, Evaluation Framework, Adaptation Techniques, Epistemic Uncertainty, Patient-Clinician Communication","This study investigates the alignment of large language models (LLMs) with clinicians in drafting responses to patient portal messages. It introduces a taxonomy of thematic elements in clinician responses and a novel evaluation framework to assess the editing load of LLM-drafted responses. The study evaluates local and commercial LLMs using various adaptation techniques and reveals significant uncertainty in aligning LLM drafts with clinician responses. While LLMs can draft certain thematic elements, they struggle with others, particularly in question asking. The findings highlight the need for adapting LLMs to individual clinician preferences for reliable use in patient-clinician communication workflows.",3.33,89.863,299,cold_start,Phi-4,Apple_M1(Metal)
2601.11350v1_FEATHer Fourier-Efficient Adaptive Temporal Hierar.pdf,FEATHer: Fourier-Efficient Adaptive Temporal Hierarchy Forecaster for Time-Series Forecasting,"Jaehoon Lee, Seungwoo Lee, Younghwi Kim, Dohee Kim, Sunghyun Sim",,,"Time-series Forecasting, Edge AI, Ultra-Lightweight Models, Fourier-Efficient Adaptive Temporal Hierarchy Forecaster (FEATHer)","Time-series forecasting is crucial in industrial domains like manufacturing, energy management, logistics, and smart factory operations. As systems evolve toward cyber-physical automation, forecasting models must operate on edge devices with strict constraints on latency, memory, and energy consumption. Conventional deep forecasting architectures become impractical under these constraints. This paper introduces the Fourier-Efficient Adaptive Temporal Hierarchy Forecaster (FEATHer), a multiscale temporal model designed for accurate long-term forecasting with minimal resources. FEATHer features an ultra-lightweight multiscale temporal decomposition, a shared Dense Temporal Kernel, a frequency-aware branch gating mechanism, and a Sparse Period Kernel. It achieves strong predictive performance with as few as 400 trainable parameters, demonstrating reliable long-range forecasting under constrained edge conditions. Across eight benchmarks, FEATHer records 60 first-place results with an average rank of 2.05, suggesting a practical direction for next-generation industrial systems requiring real-time inference with minimal computational cost.",3.54,92.396,327,cold_start,Phi-4,Apple_M1(Metal)
2601.11354v1_AstroReason-Bench Evaluating Unified Agentic Plann.pdf,AstroReason-Bench: Evaluating Unified Agentic Planning across Heterogeneous Space Planning Problems,"Weiyi Wang, Xinchi Chen, Jingjing Gong, Xuanjing Huang, Xipeng Qiu",,arXiv:2601.11354v1,"agentic systems, large language models, Space Planning Problems, generalist planning, physical constraints, benchmarking","Recent advances in agentic Large Language Models (LLMs) have positioned them as generalist planners capable of reasoning and acting across diverse tasks. However, existing agent benchmarks largely focus on symbolic or weakly grounded environments, leaving their performance in physics-constrained real-world domains underexplored. This paper introduces AstroReason-Bench, a comprehensive benchmark for evaluating agentic planning in Space Planning Problems (SPP), which are high-stakes problems with heterogeneous objectives, strict physical constraints, and long-horizon decision-making. AstroReason-Bench integrates multiple scheduling regimes, including ground station communication and agile Earth observation, and provides a unified agent-oriented interaction protocol. Evaluations on a range of state-of-the-art open- and closed-source agentic LLM systems reveal that current agents substantially underperform specialized solvers, highlighting key limitations of generalist planning under realistic constraints. AstroReason-Bench offers a challenging and diagnostic testbed for future agentic research.",3.62,90.963,329,cold_start,Phi-4,Apple_M1(Metal)
2601.11359v1_Think-Clip-Sample Slow-Fast Frame Selection for Vi.pdf,THINK-CLIP-SAMPLE: SLOW-FAST FRAME SELECTION FOR VIDEO UNDERSTANDING,"Wenhui Tan, Ruihua Song, Jiaze Li, Jianzhong Ju, Zhenbo Luo",,,"Multi-modal LLMs, long video understanding","Recent progress in multi-modal large language models (MLLMs) has significantly advanced video understanding. However, their performance on long-form videos remains limited by computational constraints and suboptimal frame selection. We present Think-Clip-Sample (TCS), a training-free framework that enhances long video understanding through two key components: (i) Multi-Query Reasoning, which generates multiple queries to capture complementary aspects of the question and video; and (ii) Clip-level Slow-Fast Sampling, which adaptively balances dense local details and sparse global context. Extensive experiments on MLVU, LongVideoBench, and VideoMME demonstrate that TCS consistently improves performance across different MLLMs, boosting up to 6.9% accuracy, and is capable of achieving comparable accuracy with 50% fewer inference time cost, highlighting both efficiency and efficacy of TCS on long video understanding.",3.34,86.162,288,cold_start,Phi-4,Apple_M1(Metal)
2601.11369v2_Institutional AI Governing LLM Collusion in Multi-.pdf,Institutional AI: Governing LLM Collusion in Multi-Agent Cournot Markets via Public Governance Graphs,"M. Bracale Syrnikov, F. Pierucci, M. Galisai, M. Prandi, P. Bisconti, F. Giarrusso, O. Sorokoletova, V. Suriani, D. Nardi",,arXiv:2601.11369v2,"Institutional AI, LLM, multi-agent, Cournot markets, governance graphs, AI alignment, collusion","This paper introduces an experimental framework for evaluating Institutional AI, a system-level approach to AI alignment that focuses on mechanism design in institution-space rather than preference engineering in agent-space. The paper presents a governance graph as a public, immutable manifest that declares legal states, transitions, sanctions, and restorative paths, with an Oracle/Controller runtime enforcing these rules. The framework is applied to govern Cournot collusion, comparing Ungoverned, Constitutional, and Institutional regimes. Results show that the Institutional regime significantly reduces collusion, while the Constitutional baseline shows no reliable improvement. The study suggests that multi-agent alignment may benefit from being framed as an institutional design problem, with governance graphs providing a tractable abstraction for alignment-relevant collective behavior.",3.53,93.24,329,cold_start,Phi-4,Apple_M1(Metal)
2601.11379v1_Evaluating LLM Behavior in Hiring Implicit Weights.pdf,"Evaluating LLM Behavior in Hiring: Implicit Weights, Fairness Across Groups, and Alignment with Human Preferences","Morgane Hoffmann, Emma Jouffroy, Warren Jouanneau, Marc Palyart, Charles Pebereau",,,"Large Language Models, Person-job Fit, Fairness, Interpretability","General-purpose Large Language Models (LLMs) show significant potential in recruitment applications, where decisions require reasoning over unstructured text, balancing multiple criteria, and inferring fit and competence from indirect productivity signals. This paper proposes a framework to evaluate an LLM’s decision logic in recruitment, drawing on established economic methodologies for analyzing human hiring behavior. Synthetic datasets from real freelancer profiles and project descriptions are used to estimate how an LLM weighs different match-relevant criteria when evaluating freelancer-project fit. The study identifies prioritized attributes and analyzes weight variations across project contexts and demographic subgroups. It also suggests an experimental setup to compare LLM and human recruiter decisions. Findings reveal that the LLM prioritizes core productivity signals like skills and experience but interprets certain features beyond their explicit matching value. While showing minimal average discrimination against minority groups, intersectional effects indicate that productivity signals carry different weights between demographic groups.",3.4,82.068,279,cold_start,Phi-4,Apple_M1(Metal)
2601.11389v1_Hyperparameter Optimization of Constraint Programm.pdf,Hyperparameter Optimization of Constraint Programming Solvers,"Hedieh Haddad, Thibault Falque, Pierre Talbot, Pascal Bouvry",,2601.11389v1,"constraint programming, hyperparameter optimization, Bayesian optimization, Hamming distance search, CPMpy library, ACE solver, Choco solver","The performance of constraint programming solvers is highly sensitive to the choice of their hyperparameters. Manually finding the best solver configuration is a difficult, time-consuming task that typically requires expert knowledge. This paper introduces the probe and solve algorithm, a novel two-phase framework for automated hyperparameter optimization integrated into the CPMpy library. The approach partitions the available time budget into a probing phase that explores different sets of hyperparameters using configurable hyperparameter optimization methods, followed by a solving phase where the best configuration found is used to tackle the problem within the remaining time. Two hyperparameter optimization methods, Bayesian optimization and Hamming distance search, are implemented and compared within the probe and solve algorithm. The algorithm is evaluated on two different constraint programming solvers, ACE and Choco, across 114 combinatorial problem instances, comparing their performance against the solver’s default configurations. Results show that using Bayesian optimization, the algorithm outperforms the solver’s default configurations, improving solution quality for ACE in 25.4% of instances and matching the default performance in 57.9%, and for Choco, achieving superior results in 38.6% of instances. It also consistently surpasses Hamming distance search within the same framework, confirming the advantage of model-based exploration over simple local search.",3.87,100.127,387,cold_start,Phi-4,Apple_M1(Metal)
2601.11400v1_Wetland mapping from sparse annotations with satel.pdf,Wetland mapping from sparse annotations with satellite image time series and temporal-aware segment anything model,"Shuai Yuan, Tianwu Lin, Shuang Chen, Yu Xia, Peng Qin, Xiangyu Liu, Xiaoqing Xu, Nan Xu, Hongsheng Zhang, Jie Wang, Peng Gong",,2601.11400v1,"wetland mapping, satellite image time series, sparse annotation, segment anything model, temporal adaptation","Accurate wetland mapping is critical for ecosystem monitoring and management, yet acquiring dense pixel-level annotations is prohibitively costly. In practice, only sparse point labels are typically available, and existing deep learning-based models struggle under such weak supervision. Meanwhile, wetlands exhibit strong seasonal and inter-annual dynamics, making single-date imagery insufficient and causing substantial omission and commission errors when mapping. Although powerful foundation models like the Segment Anything Model (SAM) provide promising generalization from point prompts, it is intrinsically designed for static natural images, resulting in spatially fragmented masks in heterogeneous wetland environments and cannot exploit satellite image time series. To address these challenges, we propose WetSAM, a novel SAM-based framework that effectively leverages satellite image time series to enhance wetland mapping from sparse point annotations. WetSAM adopts a dual-branch design: (1) The temporal branch is prompted by sparse point labels to extend the SAM with a hierarchical adapter and a dynamic temporal aggregation module. By decomposing time series into seasonal trends and transient events, this branch effectively distinguishes wetland features from phenological variations; (2) The spatial branch reconstructs distinct boundaries via a temporal-constrained region-growing strategy, iteratively expanding sparse points into reliable dense pseudo-labels; (3) A bidirectional consistency regularization enforces minimizing the discrepancy of the predictions from two segmentation heads of two branches. We validate the effectiveness of WetSAM across eight diverse global locations, each covering an area of around 5,000 km² and with various wetland types and geographical features. WetSAM reaches an average F1-score of 85.58%, considerably outperforming other state-of-the-art algorithms. Results demonstrate that WetSAM achieves accurate, structurally consistent segmentation from sparse labels. With minimal labeling effort, our framework shows strong generalization ability and holds promise for scalable, low-cost wetland mapping at high spatial resolutions.",3.88,140.432,545,cold_start,Phi-4,Apple_M1(Metal)
2601.11409v1_Topology-Guaranteed Image Segmentation Enforcing C.pdf,"Topology-Guaranteed Image Segmentation: Enforcing Connectivity, Genus, and Width Constraints","Wenxiao Li, Xue-Cheng Tai, Jun Liu",,,"Image segmentation, topological preservation, persistent homology, thickness of topology, variational, regularization","Existing research highlights the crucial role of topological priors in image segmentation, particularly in preserving essential structures such as connectivity and genus. Accurately capturing these topological features often requires incorporating width-related information, including the thickness and length inherent to the image structures. However, traditional mathematical definitions of topological structures lack this dimensional width information, limiting methods like persistent homology from fully addressing practical segmentation needs. To overcome this limitation, we propose a novel mathematical framework that explicitly integrates width information into the characterization of topological structures. This method leverages persistent homology, complemented by smoothing concepts from partial differential equations (PDEs), to modify local extrema of upper-level sets. This approach enables the resulting topological structures to inherently capture width properties. We incorporate this enhanced topological description into variational image segmentation models. Using some proper loss functions, we are also able to design neural networks that can segment images with the required topological and width properties. Through variational constraints on the relevant topological energies, our approach successfully preserves essential topological invariants such as connectivity and genus counts, simultaneously ensuring that segmented structures retain critical width attributes, including line thickness and length. Numerical experiments demonstrate the effectiveness of our method, showcasing its capability to maintain topological fidelity while explicitly embedding width characteristics into segmented image structures.",3.67,101.532,373,cold_start,Phi-4,Apple_M1(Metal)
2601.11421v1_The Great March 100 100 Detail-oriented Tasks for .pdf,THE GREAT MARCH 100: 100 DETAIL-ORIENTED TASKS FOR EVALUATING EMBODIED AI AGENTS,"Ziyu Wang, Chenyuan Liu, Yushun Xiang, Runhao Zhang, Yu Zhang, Qingbo Hao, Hongliang Lu, Houyu Chen, Zhizhong Feng, Kaiyue Zheng, Dehao Ye, Xianchao Zeng, Xinyu Zhou, Boran Wen, Jiaxin Li, Mingyu Zhang, Kecheng Zheng, Qian Zhu, Ran Cheng, Yong-Lu Li",,,"robot learning, imitation learning, datasets, task design, robotic agents, evaluation, Great March 100, robot learning Olympics","With the rapid development of robot learning and imitation learning, numerous datasets and methods have emerged. However, these datasets and their task designs often lack systematic consideration and principles. This raises important questions about the advancement of robotic agents' capabilities and the accuracy of evaluations on common tasks. To address these issues, the Great March 100 (GM-100) is introduced as the first step towards a robot learning Olympics. GM-100 consists of 100 carefully designed tasks that cover a wide range of interactions and long-tail behaviors, aiming to provide a diverse and challenging set of tasks to comprehensively evaluate the capabilities of robotic agents and promote diversity and complexity in robot dataset task designs. These tasks are developed through systematic analysis and expansion of existing task designs, combined with insights from human-object interaction primitives and object affordances. A large amount of trajectory data on different robotic platforms is collected and several baseline models are evaluated. Experimental results demonstrate that the GM-100 tasks are feasible to execute and sufficiently challenging to effectively differentiate the performance of current VLA models. Data and code are available at https://rhos.ai/research/gm-100.",3.65,130.449,476,cold_start,Phi-4,Apple_M1(Metal)
2601.11429v1_Relational Linearity is a Predictor of Hallucinati.pdf,Relational Linearity is a Predictor of Hallucinations,"Yuetian Lu, Yihong Liu, Hinrich Schütze",,,"hallucinations, large language models, linearity, knowledge assessment, synthetic entities","Hallucination is a central failure mode in large language models (LLMs). This study focuses on hallucinations in answers to questions about synthetic entities unknown to the model. It is found that medium-size models like Gemma-7B-IT frequently hallucinate, struggling to recognize that the hallucinated fact is not part of their knowledge. The study hypothesizes that the linearity of the relation is a significant factor in causing these hallucinations. Linear relations tend to be stored more abstractly, making knowledge assessment difficult, whereas nonlinear relations are stored more directly, facilitating easier knowledge assessment. The study introduces SyntHal, a dataset of 6000 synthetic entities for six relations, and finds a strong correlation between relational linearity and hallucination rate. This suggests that the underlying storage of triples of a relation affects how well a model can self-assess its knowledge, with implications for managing hallucination behavior and improving factual knowledge representation in LLMs.",3.21,84.464,271,cold_start,Phi-4,Apple_M1(Metal)
2601.11440v1_GenDA Generative Data Assimilation on Complex Urba.pdf,GENDA: GENERATIVEDATAASSIMILATION ON COMPLEX URBAN AREAS VIA CLASSIFIER-FREE DIFFUSION GUIDANCE,"Francisco Giral, Álvaro Manzano, Ignacio Gómez, Ricardo Vinuesa, Soledad Le Clainche",,,"urban wind flow reconstruction, data assimilation, graph-based diffusion architecture, classifier-free guidance, computational fluid dynamics, Reynolds-averaged Navier-Stokes, environmental monitoring","Urban wind flow reconstruction is essential for assessing air quality, heat dispersion, and pedestrian comfort, yet remains challenging with sparse sensor data. This paper introduces GenDA, a generative data assimilation framework that reconstructs high-resolution wind fields on unstructured meshes from limited observations. The model employs a multiscale graph-based diffusion architecture trained on computational fluid dynamics (CFD) simulations and interprets classifier-free guidance as a learned posterior reconstruction mechanism. The unconditional branch learns a geometry-aware flow prior, while the sensor-conditioned branch injects observational constraints during sampling. This formulation enables obstacle-aware reconstruction and generalization across unseen geometries, wind directions, and mesh resolutions without retraining. Evaluated against supervised graph neural network (GNN) baselines and classical reduced-order data assimilation methods, GenDA reduces the relative root-mean-square error (RRMSE) by 25-57% and increases the structural similarity index (SSIM) by 23-33% across tested meshes. Experiments are conducted on Reynolds-averaged Navier-Stokes (RANS) simulations of a real urban neighborhood in Bristol, United Kingdom, featuring complex building geometry and irregular terrain. The proposed framework provides a scalable path toward generative, geometry-aware data assimilation for environmental monitoring in complex domains.",3.64,115.268,420,cold_start,Phi-4,Apple_M1(Metal)
2601.11441v1_Hierarchical Orthogonal Residual Spread for Precis.pdf,HIERARCHICAL ORTHOGONAL RESIDUAL SPREAD FOR PRECISE MASSIVE EDITING IN LARGE LANGUAGE MODELS,"Xiaojie Gu, Guangxu Chen, Yuheng Yang, Jingxin Han, Andi Zhang",,,"Large language models, Model Editing, Knowledge Update, Residual Spread","Large language models (LLMs) exhibit exceptional performance across various domains, yet they face critical safety concerns. Model editing has emerged as an effective approach to mitigate these issues. Existing model editing methods often focus on optimizing an information matrix that blends new and old knowledge. While effective, these approaches can be computationally expensive and may cause conflicts. In contrast, we shift our attention to Hierarchical Orthogonal Residual Spread of the information matrix, which reduces noisy gradients and enables more stable edits from a different perspective. We demonstrate the effectiveness of our method HORSE through a clear theoretical comparison with several popular methods and extensive experiments conducted on two datasets across multiple LLMs. The results show that HORSE maintains precise massive editing across diverse scenarios. The code is available at https://github.com/XiaojieGu/HORSE.",3.32,86.812,288,cold_start,Phi-4,Apple_M1(Metal)
2601.11442v1_Map2Thought Explicit 3D Spatial Reasoning via Metr.pdf,Map2Thought: Explicit 3D Spatial Reasoning via Metric Cognitive Maps,"Xiangjun Gao, Zhensong Zhang, Dave Zhenyu Chen, Songcen Xu, Long Quan, Eduardo P´erez-Pellitero, Youngkyoon Jang",,,"3D Vision-Language Models, Spatial Reasoning, Metric Cognitive Maps, Cognitive Chain-of-Thought, Data Efficiency, 3D Understanding","We propose Map2Thought, a framework that enables explicit and interpretable spatial reasoning for 3D Vision-Language Models (3D-VLMs). The framework is grounded in two key components: Metric Cognitive Map (Metric-CogMap) and Cognitive Chain-of-Thought (Cog-CoT). Metric-CogMap provides a unified spatial representation by integrating a discrete grid for relational reasoning with a continuous, metric-scale representation for precise geometric understanding. Building upon the Metric-CogMap, Cog-CoT performs explicit geometric reasoning through deterministic operations (e.g., vector operations, bounding-box distances, and occlusion-aware appearance order cues) producing interpretable inference traces grounded in 3D structure. Experimental results show that Map2Thought enables explainable 3D understanding, achieving 59.9% accuracy using only half the supervision—closely matching the 60.9% baseline trained with the full dataset. It consistently outperforms state-of-the-art methods by 5.3%, 4.8%, and 4.0% under 10%, 25%, and 50% training subsets, respectively, on the VSI-Bench.",3.51,109.182,383,cold_start,Phi-4,Apple_M1(Metal)
2601.11451v1_PRISM-CAFO Prior-conditioned Remote-sensing Infras.pdf,PRISM-CAFO: Prior-conditioned Remote-sensing Infrastructure Segmentation and Mapping for CAFOs,"Oishee Bintey Hoque, Nibir Chandra Mandal, Kyle Luong, Amanda Wilson, Samarth Swarup, Madhav Marathe, Abhijin Adiga",,arXiv:2601.11451v1,"CAFOs, remote sensing, infrastructure segmentation, mapping, YOLOv8, deep learning, spatial cross-attention, CAFO type prediction, mask-level attributions, livestock operations, environmental impact","This paper presents an infrastructure-first, explainable pipeline for identifying and characterizing Concentrated Animal Feeding Operations (CAFOs) using aerial and satellite imagery. The method involves detecting candidate infrastructure with a domain-tuned YOLOv8 detector, extracting structured descriptors, and using a spatial cross-attention classifier to fuse these with deep visual features. The approach achieves state-of-the-art performance, with Swin-B+PRISM-CAFO surpassing the best baseline by up to 15%. The study also includes systematic gradient-activation analyses to understand the impact of domain priors on classification decisions. The authors release code, infrastructure masks, and descriptors to support scalable monitoring of livestock infrastructure, aiding in risk modeling, change detection, and regulatory actions.",3.52,98.926,348,cold_start,Phi-4,Apple_M1(Metal)
2601.11459v1_Interactive Narrative Analytics Bridging Computati.pdf,Interactive Narrative Analytics: Bridging Computational Narrative Extraction and Human Sensemaking,BRIAN KEITH,10.1 109/ACCESS.2025.3650352,,"Human-AI collaboration, information extraction, interactive visual analytics, knowledge integration, narrative extraction, narrative sensemaking, semantic interaction, visual analytics","This paper introduces the field of Interactive Narrative Analytics (INA), which combines computational narrative extraction with interactive visual analytics to support sensemaking. INA addresses challenges in scalability, interactivity, knowledge integration, and evaluation standardization, offering opportunities in news analysis, intelligence, scientific literature exploration, and social media analysis. By integrating computational and human insights, INA tackles complex challenges in narrative sensemaking in the digital age.",3.06,66.342,203,cold_start,Phi-4,Apple_M1(Metal)
2601.11464v1_MHA2MLA-VLM Enabling DeepSeeks Economical Multi-He.pdf,MHA2MLA-VLM: Enabling DeepSeek’s Economical Multi-Head Latent Attention across Vision-Language Models,"Xiaoran Fan, Zhichao Sun, Tao Ji, Lixing Shen, Tao Gui",,,"vision-language models, multi-head latent attention, key-value cache, compression, inference acceleration, modality-adaptive partial-RoPE, low-rank approximation, parameter-efficient fine-tuning","As vision-language models (VLMs) tackle increasingly complex and multimodal tasks, the rapid growth of Key-Value (KV) cache imposes significant memory and computational bottlenecks during inference. This work presents MHA2MLA-VLM, a parameter-efficient and multimodal-aware framework for converting off-the-shelf VLMs to Multi-Head Latent Attention (MLA). The approach features a modality-adaptive partial-RoPE strategy and a modality-decoupled low-rank approximation method. Parameter-efficient fine-tuning minimizes adaptation cost, and minimizing output activation error reduces performance loss. Experiments show that MHA2MLA-VLM restores original model performance with minimal supervised data, significantly reduces KV cache footprint, and integrates seamlessly with KV quantization.",3.24,95.447,309,cold_start,Phi-4,Apple_M1(Metal)
2601.11468v1_Exploring LLM Features in Predictive Process Monit.pdf,Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs,"ALESSANDRO PADELLA, MASSIMILIANO DE LEONI, MARLON DUMAS",,,"Predictive process monitoring, Large language models, Trace Encoding","Predictive Process Monitoring (PPM) is a branch of process mining that aims to predict the outcome of an ongoing process. This paper extends a prior LLM-based PPM framework, initially focused on total time prediction via prompting, to evaluate its generality, semantic leverage, and reasoning mechanisms across multiple Key Performance Indicators. Empirical evaluations on three distinct event logs show that in data-scarce settings with only 100 traces, the LLM surpasses benchmark methods. The LLM exploits both its embodied prior knowledge and internal correlations among training traces. The paper also examines the reasoning strategies employed by the model, demonstrating that the LLM performs higher-order reasoning to generate predictions.",3.15,77.026,243,cold_start,Phi-4,Apple_M1(Metal)
2601.11479v1_Health Facility Location in Ethiopia Leveraging LL.pdf,Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning,"Yohai Trabelsi, Guojun Xiong, Fentabil Getnet, Stéphane Verguet, Milind Tambe",,,"Health Facility Location, Optimization, Human expert knowledge, Alignment, LLM","Ethiopia’s Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources require careful prioritization of which facilities to upgrade to maximize population coverage while accounting for diverse expert and stakeholder preferences. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, a hybrid framework is proposed that systematically integrates expert knowledge with optimization techniques. Classical optimization methods provide theoretical guarantees but require explicit, quantitative objectives, whereas stakeholder criteria are often articulated in natural language and difficult to formalize. To bridge these domains, the Large Language Model and Extended Greedy (LEG) framework is developed. This framework combines a provable approximation algorithm for population coverage optimization with LLM-driven iterative refinement that incorporates human-AI alignment to ensure solutions reflect expert qualitative guidance while preserving coverage guarantees. Experiments on real-world data from three Ethiopian regions demonstrate the framework’s effectiveness and its potential to inform equitable, data-driven health system planning.",3.35,94.099,315,cold_start,Phi-4,Apple_M1(Metal)
2601.11492v1_BoxMind Closed-loop AI strategy optimization for e.pdf,BoxMind: Closed-loop AI strategy optimization for elite boxing validated in the 2024 Olympics,"Kaiwen Wang, Kaili Zheng, Rongrong Deng, Qingmin Fan, Milin Zhang, Zongrui Li, Xuesi Zhou, Bo Han, Liren Chen, Chenyi Guo, Ji Wu",,arXiv:2601.11492v1,"AI, strategy optimization, elite boxing, closed-loop system, tactical analysis, graph-based predictive model, technical-tactical indicators, competitive sports","Competitive sports require sophisticated tactical analysis, yet combat disciplines like boxing remain underdeveloped in AI-driven analytics due to the complexity of action dynamics and the lack of structured tactical representations. To address this, we present BoxMind, a closed-loop AI expert system validated in elite boxing competition. By defining atomic punch events with precise temporal boundaries and spatial and technical attributes, we parse match footage into 18 hierarchical technical-tactical indicators. We then propose a graph-based predictive model that fuses these explicit technical-tactical profiles with learnable, time-variant latent embeddings to capture the dynamics of boxer matchups. Modeling match outcome as a differentiable function of technical-tactical indicators, we turn winning probability gradients into executable tactical adjustments. Experiments show that the outcome prediction model achieves state-of-the-art performance, with 69.8% accuracy on BoxerGraph test set and 87.5% on Olympic matches. Using this predictive model as a foundation, the system generates strategic recommendations that demonstrate proficiency comparable to human experts. BoxMind is validated through a closed-loop deployment during the 2024 Paris Olympics, directly contributing to the Chinese National Team’s historic achievement of three gold and two silver medals. BoxMind establishes a replicable paradigm for transforming unstructured video data into strategic intelligence, bridging the gap between computer vision and decision support in competitive sports.",3.74,121.777,456,cold_start,Phi-4,Apple_M1(Metal)
2601.11496v1_The Poisoned Apple Effect Strategic Manipulation o.pdf,The Poisoned Apple Effect: Strategic Manipulation of Mediated Markets via Technology Expansion of AI Agents,"Eilam Shapira, Moshe Tennenholtz, Roi Reichart",,,"AI agents, economic markets, game theory, regulation, technology expansion, Poisoned Apple effect","The integration of AI agents into economic markets fundamentally alters the landscape of strategic interaction. This study investigates the economic implications of expanding the set of available technologies in three canonical game-theoretic settings: bargaining, negotiation, and persuasion. It identifies the 'Poisoned Apple' effect, where an agent releases a new technology to manipulate the regulator’s choice of market design in their favor, improving their welfare at the expense of their opponent and the regulator’s fairness objectives. The findings suggest that static regulatory frameworks are vulnerable to manipulation via technology expansion, necessitating dynamic market designs that adapt to the evolving landscape of AI capabilities.",3.23,68.948,223,cold_start,Phi-4,Apple_M1(Metal)
2601.11505v1_MetaboNet The Largest Publicly Available Consolida.pdf,METABONET: THE LARGEST PUBLICLY AVAILABLE CONSOLIDATED DATASET FOR TYPE1 DIABETES MANAGEMENT,"Miriam K. Wolff, Peter Calhoun, Eleonora Maria Aiello, Yao Qin, Sam F. Royston",,2601.11505v1,"Type 1 Diabetes, algorithm development, data standardization, continuous glucose monitoring, insulin pump dosing, data integration","Progress in Type 1 Diabetes (T1D) algorithm development is limited by the fragmentation and lack of standardization across existing T1D management datasets. This work aims to establish a unified and accessible data resource for T1D algorithm development. The MetaboNet dataset consolidates multiple publicly available T1D datasets into a unified resource, comprising 3135 subjects and 1228 patient-years of overlapping CGM and insulin data. The dataset is distributed as a fully public subset available for immediate download and a DUA-restricted subset accessible through application processes. The dataset covers a broad range of glycemic profiles and demographics, facilitating more generalizable algorithmic performance than individual datasets.",3.52,80.637,284,cold_start,Phi-4,Apple_M1(Metal)
2601.11516v2_Building Production-Ready Probes For Gemini.pdf,Building Production-Ready Probes For Gemini,"János Kramár, Joshua Engels, Zheng Wang, Bilal Chughtai, Rohin Shah, Neel Nanda, Arthur Conmy",,,"Activation Probing, Interpretability, Language Models, Misuse Risk, AI Safety, Monitoring","This paper discusses the development of activation probes as a misuse mitigation technique for Gemini, a frontier language model by Google DeepMind. The authors address the challenge of generalizing probes under production distribution shifts, particularly from short-context to long-context inputs. They propose new probe architectures and evaluate their robustness in the cyber-offensive domain, considering distribution shifts like multi-turn conversations and long context prompts. The study finds that combining architecture choice with diverse training distributions enhances generalization. The deployment of these probes in Gemini has been successful, and early results show promise in automating improvements in probe architecture search and adaptive red teaming using AlphaEvolve.",3.26,78.465,256,cold_start,Phi-4,Apple_M1(Metal)
2601.11517v1_Do explanations generalize across large reasoning .pdf,DO EXPLANATIONS GENERALIZE ACROSS LARGE REASONING MODELS?,"Koyena Pal, David Bau, Chandan Singh",,,"Large reasoning models, explanations, generalization, chains of thought, reinforcement learning, scientific discovery","Large reasoning models (LRMs) produce textual chains of thought (CoT) to solve problems, which can serve as human-readable explanations. This study investigates whether these explanations generalize across different LRMs, meaning they capture general patterns rather than model-specific quirks. The research evaluates the generalizability of CoT explanations by examining if they induce consistent behavior across different LRMs. Findings suggest that CoT explanations often increase consistency between LRMs, correlating with human preference and reinforcement learning. The study also proposes a sentence-level ensembling strategy to improve consistency and highlights the need for caution when using LRM explanations for new insights.",3.09,75.167,232,cold_start,Phi-4,Apple_M1(Metal)
2601.11625v1_Reasoning Stabilization Point A Training-Time Sign.pdf,Reasoning Stabilization Point: A Training-Time Signal for Stable Evidence and Shortcut Reliance,Sahil Rajesh Dhayalkar,,,"fine-tuning, language models, interpretability, explanation drift, Reasoning Stabilization Point, token attributions, shortcut reliance","This paper introduces a training-time interpretability view that tracks token-level attributions across fine-tuning epochs. It defines explanation drift as the change in normalized token attributions between epochs and introduces the Reasoning Stabilization Point (RSP), the earliest epoch after which drift remains consistently low. The study shows that explanation drift stabilizes early in training, while validation accuracy changes marginally. It also reveals increasing reliance on shortcuts in controlled settings, providing a diagnostic tool for monitoring decision evidence evolution during fine-tuning.",2.89,68.814,199,cold_start,Phi-4,Apple_M1(Metal)
2601.11643v1_Syllabic Agglutinative Tokenizations for Indonesia.pdf,Syllabic Agglutinative Tokenizations for Indonesian LLM: A Study from 'Gasing Literacy Learning System',"Hokky Situngkir, Andhika Bernard Lumbantobing, Yohanes Surya",,2601.11643v1,"Indonesian natural language processing, Indonesian computational linguistics, tokenization, large language models, Gasing Literacy Learning System, low-resource languages, Austronesian languages","This paper presents a novel syllable-based tokenization approach for Indonesian large language models, inspired by the Gasing Literacy Learning System’s pedagogical methodology. Drawing on information-theoretic principles, we develop a tokenization framework that segments Indonesian text at syllable boundaries before applying byte-pair encoding, creating a vocabulary that aligns with the language’s morphophonological structure. Our approach first identifies high-frequency syllables through rule-based segmentation, then constructs a compact vocabulary of 3,500 tokens that preserves meaningful linguistic units while maintaining coverage through character-level fallback. Empirical evaluation on Indonesian Wikipedia and folklore corpora from Indonesian Culture Digital Library (PDBI) demonstrates substantial improvements over conventional tokenization methods: the syllable-based approach achieves Rényi efficiency of 0.74 compared to 0.50-0.64 for pretrained multilingual tokenizers, while maintaining higher average token lengths (3.67 characters versus 2.72 for GPT-2) despite using a vocabulary an order of magnitude smaller. These gains emerge from the method’s ability to internalize character-level dependencies within syllable units, reducing the computational burden on language models while respecting Indonesian’s agglutinative morphology. We call the LLM built upon this principle, TOBA LLM (Tokenisasi Optimum Berbasis Aglutinasi), the convergence of human literacy pedagogy with computational optimization principles offers a promising paradigm for developing linguistically-informed tokenization strategies, particularly for morphologically rich and underrepresented languages in natural language processing.",3.68,126.149,464,cold_start,Phi-4,Apple_M1(Metal)
2601.11644v1_Predicting When to Trust Vision-Language Models fo.pdf,Predicting When to Trust Vision-Language Models for Spatial Reasoning,"Muhammad Imran, Yugyung Lee",,,"Vision-Language Models, Spatial Reasoning, Confidence Estimation, Geometric Verification, Object Detection, Autonomous Systems, Robotics","Vision-Language Models (VLMs) demonstrate impressive capabilities across multimodal tasks but exhibit systematic spatial reasoning failures, achieving only 49% to 54% accuracy on basic directional relationships. For safe deployment in robotics and autonomous systems, it is crucial to predict when to trust VLM spatial predictions. This paper proposes a vision-based confidence estimation framework that validates VLM predictions through independent geometric verification using object detection. The method fuses four signals via gradient boosting: geometric alignment, spatial ambiguity, detection quality, and VLM internal uncertainty. The framework achieves significant improvements in AUROC over text-based baselines and enables selective prediction, enhancing coverage and precision in scene graph construction.",3.07,78.245,240,cold_start,Phi-4,Apple_M1(Metal)
2601.11647v1_Reinforcement Learning for Dynamic Workflow Optimi.pdf,Reinforcement Learning for Dynamic Workflow Optimization in CI/CD Pipelines,"Aniket Abhishek Soni, Milan Parikh, Rashi Nimesh Kumar Dhenia, Jubin Abhishek Soni, Ayush Raj Jha, Sneja Mitinbhai Shah",,,"Reinforcement Learning, CI/CD, DevOps, Workflow Optimization","Continuous Integration and Deployment (CI/CD) pipelines are essential for modern software delivery, but their static workflows can be inefficient. This paper proposes a reinforcement learning (RL) approach to optimize CI/CD pipeline workflows dynamically. The pipeline is modeled as a Markov Decision Process, and an RL agent is trained to make runtime decisions to maximize throughput while minimizing testing overhead. A simulated CI/CD environment is developed to evaluate the approach, showing up to a 30% improvement in throughput and about a 25% reduction in test execution overhead compared to a static baseline. The agent learns to skip or abbreviate certain tests when appropriate, accelerating delivery without significantly increasing the risk of undetected failures. This work demonstrates the potential of RL to adapt DevOps workflows for greater efficiency, providing novel insights into intelligent pipeline automation.",3.3,90.512,299,cold_start,Phi-4,Apple_M1(Metal)
2601.11650v1_Large Language Model Agent for User-friendly Chemi.pdf,LARGE LANGUAGE MODEL AGENT FOR USER-FRIENDLY CHEMICAL PROCESS SIMULATIONS,"Jingkang Liang, Niklas Groll, Gürkan Sin",,2601.11650v1,"Chemical Process Simulation, Large Language Model, Model Context Protocol","Modern process simulators enable detailed process design, simulation, and optimization; however, constructing and interpreting simulations is time-consuming and requires expert knowledge. This limits early exploration by inexperienced users. To address this, a large language model (LLM) agent is integrated with AVEVA Process Simulation (APS) via Model Context Protocol (MCP), allowing natural language interaction with rigorous process simulations. An MCP server toolset enables the LLM to communicate programmatically with APS using Python, allowing it to execute complex simulation tasks from plain-language instructions. Two water-methanol separation case studies assess the framework across different task complexities and interaction modes. The first shows the agent autonomously analyzing flowsheets, finding improvement opportunities, and iteratively optimizing, extracting data, and presenting results clearly. The framework benefits both educational purposes, by translating technical concepts and demonstrating workflows, and experienced practitioners by automating data extraction, speeding routine tasks, and supporting brainstorming. The second case study assesses autonomous flowsheet synthesis through both a step-by-step dialogue and a single prompt, demonstrating its potential for novices and experts alike. The step-by-step mode gives reliable, guided construction suitable for educational contexts; the single-prompt mode constructs fast baseline flowsheets for later refinement. While current limitations such as oversimplification, calculation errors, and technical hiccups mean expert oversight is still needed, the framework’s capabilities in analysis, optimization, and guided construction suggest LLM-based agents can become valuable collaborators.",3.8,105.783,402,cold_start,Phi-4,Apple_M1(Metal)
2601.11651v1_Aesthetics as Structural Harm Algorithmic Lookism .pdf,Aesthetics as Structural Harm: Algorithmic Lookism Across Text-to-Image Generation and Classification,"Miriam Doh, Aditya Gulati, Corina Canali, Nuria Oliver",,arXiv:2601.11651v1,"Generative AI, Artificial Intelligence, Cognitive Biases, Attractiveness Halo Effect","This paper examines algorithmic lookism—the systematic preferential treatment based on physical appearance—in text-to-image (T2I) generative AI and a downstream gender classification task. Through the analysis of 26,400 synthetic faces created with Stable Diffusion 2.1 and 3.5 Medium, it demonstrates how generative AI models systematically associate facial attractiveness with positive attributes and vice versa, mirroring socially constructed biases rather than evidence-based correlations. Furthermore, it finds significant gender bias in three gender classification algorithms depending on the attributes of the input faces. The findings reveal three critical harms: (1) the systematic encoding of attractiveness-positive attribute associations in T2I models; (2) gender disparities in classification systems, where women’s faces, particularly those generated with negative attributes, suffer substantially higher misclassification rates than men’s; and (3) intensifying aesthetic constraints in newer models through age homogenization, gendered exposure patterns, and geographic reductionism. These convergent patterns reveal algorithmic lookism as a systematic infrastructure operating across AI vision systems, compounding existing inequalities through both representation and recognition. Disclaimer: This work includes visual and textual content that reflects stereotypical associations between physical appearance and socially constructed attributes, including gender, race, and traits associated with social desirability. Any such associations found in this study emerge from the biases embedded in generative AI systems—not from empirical truths or the authors’ views.",3.6,113.823,410,cold_start,Phi-4,Apple_M1(Metal)
2601.11652v1_WISP Waste- and Interference-Suppressed Distribute.pdf,WISP: Waste- and Interference-Suppressed Distributed Speculative LLM Serving at the Edge via Dynamic Drafting and SLO-Aware Batching,"XIANGCHEN LI, JIAKUN FAN, QINGYUAN WANG, DIMITRIOS SPATHARAKIS, SAEID GHAFOURI, HANS VANDIERENDONCK, DEEPU JOHN, BO JI, ALI R. BUTT, DIMITRIOS S. NIKOLOPOULOS",10.1145/376xxxx.377xxxx,,"Speculative Decoding, Large Language Models, Edge Computing, Distributed Inference, Token Verification, Resource-Aware Serving","As Large Language Models (LLMs) become increasingly accessible to end users, an ever-growing number of inference requests are initiated from edge devices and computed on centralized GPU clusters. However, the resulting exponential growth in computation workload is placing significant strain on data centers, while edge devices remain largely underutilized, leading to imbalanced workloads and resource inefficiency across the network. Integrating edge devices into the LLM inference process via speculative decoding helps balance the workload between the edge and the cloud, while maintaining lossless prediction accuracy. In this paper, we identify and formalize two critical bottlenecks that limit the efficiency and scalability of distributed speculative LLM serving: Wasted Drafting Time and Verification Interference. To address these challenges, we propose WISP, an efficient and SLO-aware distributed LLM inference system that consists of an intelligent speculation controller, a verification time estimator, and a verification batch scheduler. These components collaboratively enhance drafting efficiency and optimize verification request scheduling on the server. Extensive numerical results show that WISP improves system capacity by up to 2.1× and 4.1×, and increases system goodput by up to 1.94× and 3.7×, compared to centralized serving and SLED, respectively.",3.51,133.761,470,cold_start,Phi-4,Apple_M1(Metal)
2601.11657v1_Size is Not the Solution Deformable Convolutions f.pdf,Size is Not the Solution: Deformable Convolutions for Effective Physics Aware Deep Learning,"Jack T. Beerman, Shobhan Roy, H.S. Udaykumar, Stephen S. Baek",,,"Physics-aware deep learning, Deformable convolutions, Hybrid Lagrangian-Eulerian methods, Burgers’ equation, Navier-Stokes, Reactive flows, Adaptive refinement, Computational mechanics","Physics-aware deep learning (PADL) enables rapid prediction of complex physical systems, yet current convolutional neural network (CNN) architectures struggle with highly nonlinear flows. While scaling model size addresses complexity in broader AI, this approach yields diminishing returns for physics modeling. Drawing inspiration from Hybrid Lagrangian-Eulerian (HLE) numerical methods, we introduce deformable physics-aware recurrent convolutions (D-PARC) to overcome the rigidity of CNNs. Across Burgers’ equation, Navier-Stokes, and reactive flows, D-PARC achieves superior fidelity compared to substantially larger architectures. Analysis reveals that kernels display anti-clustering behavior, evolving into a learned 'active filtration' strategy distinct from traditional h- or p-adaptivity. Effective receptive field analysis confirms that D-PARC autonomously concentrates resources in high-strain regions while coarsening focus elsewhere, mirroring adaptive refinement in computational mechanics. This demonstrates that physically intuitive architectural design can outperform parameter scaling, establishing that strategic learning in lean networks offers a more effective path forward for PADL than indiscriminate network expansion.",3.59,101.976,366,cold_start,Phi-4,Apple_M1(Metal)
2601.11658v1_Towards AGI A Pragmatic Approach Towards Self Evol.pdf,Towards AGI: A Pragmatic Approach Towards Self Evolving Agent,"Indrajit Kar, Sammy Zonunpuia, Zonunfeli Ralte",,,"Self-evolving agents, Large Language Models (LLMs), Curriculum Learning (CL), Reward-Based Learning (RL), Genetic Algorithm (GA) evolution, Multi-agent systems, Tool-augmented reasoning, Code-generation LLMs, Autonomous adaptation, TaskCraft dataset, Agentic workflows, Self-improving AI, Capability evolution, Hierarchical orchestration","Large Language Model (LLM) based agents are powerful yet fundamentally static after deployment, lacking the ability to autonomously expand capabilities, generate new tools, or evolve their reasoning. This work introduces a hierarchical self-evolving multi-agent framework that integrates a Base LLM, an operational SLM agent, a Code-Generation LLM, and a Teacher-LLM to enable continuous adaptation. The workflow begins with the agent attempting a task using reasoning and existing tools; if unsuccessful, it escalates to tool synthesis through the Code-Gen LLM, and when failures persist, it triggers an evolution phase using Curriculum Learning (CL), Reward-Based Learning (RL), or Genetic Algorithm (GA) evolution. Using the TaskCraft dataset rich in hierarchical tasks, tool-use traces, and difficulty scaling, we evaluate these paradigms. CL delivers fast recovery and strong generalization, RL excels on high-difficulty tasks, and GA offers high behavioral diversity. Across all settings, evolved agents outperform their originals, demonstrating robust, autonomous, self-improving agentic evolution.",3.56,102.875,366,cold_start,Phi-4,Apple_M1(Metal)
2601.11663v1_Activation Sensitivity as a Unifying Principle for.pdf,Activation Sensitivity as a Unifying Principle for Post-Training Quantization,Bruce Changlong Xu,,,"Post-Training Quantization, Activation Sensitivity, Large Language Models, Quantization Error, Activation-Aware Methods, Second-Order Methods, Gradient-Weighted Activations, Sensitivity Metrics, Pruning Methods","This work presents a unified theoretical framework for post-training quantization (PTQ) of large language models by formalizing activation sensitivity. It shows that sensitivity, defined as the expected impact of channel-wise perturbations on the loss, emerges naturally as the squared norm of gradient-weighted activations. This framework unifies activation-aware methods like AWQ and second-order methods like GPTQ, which approximate sensitivity under different assumptions. The paper analyzes sensitivity metrics, connects them to classical pruning methods, and discusses challenges in PTQ such as cross-layer error accumulation and calibration distribution mismatch. The goal is to provide a conceptual foundation for understanding and extending PTQ methods.",3.18,73.785,235,cold_start,Phi-4,Apple_M1(Metal)
2601.11664v1_Serverless AI Security Attack Surface Analysis and.pdf,Serverless AI Security: Attack Surface Analysis and Runtime Protection Mechanisms for FaaS-Based Machine Learning,"Chetan Pathade, Vinod Dhimam, Ilsa Lareb, Sheheryar Ahmad",,,"Serverless computing, machine learning security, Function-as-a-Service, cloud security, adversarial machine learning, AWS Lambda, Azure Functions, attack surface analysis, runtime protection, MLOps security","Serverless computing has achieved widespread adoption, with over 70% of AWS organizations using serverless solutions. Meanwhile, machine learning inference workloads increasingly migrate to Function-as-a-Service (FaaS) platforms for their scalability and cost-efficiency. However, this convergence introduces critical security challenges, with recent reports showing a 220% increase in AI/ML vulnerabilities and serverless computing’s fragmented architecture raising new security concerns distinct from traditional cloud deployments. This paper presents the first comprehensive security analysis of machine learning workloads in serverless environments. We systematically characterize the attack surface across five categories: function-level vulnerabilities (cold start exploitation, dependency poisoning), model-specific threats (API-based extraction, adversarial inputs), infrastructure attacks (cross-function contamination, privilege escalation), supply chain risks (malicious layers, backdoored libraries), and IAM complexity (ephemeral nature, serverless functions). Through empirical assessments across AWS Lambda, Azure Functions, and Google Cloud Functions, we demonstrate real-world attack scenarios and quantify their security impact. We propose Serverless AI Shield (SAS), a multi-layered defense framework providing pre-deployment validation, runtime monitoring, and post-execution forensics. Our evaluation shows SAS achieves 94% detection rates while maintaining performance overhead below 9% for inference latency. We release an open-source security toolkit to enable practitioners to assess and harden their serverless AI deployments, advancing the field toward more resilient cloud-native machine learning systems.",3.6,122.65,442,cold_start,Phi-4,Apple_M1(Metal)
2601.11666v1_MATEX Multi-scale Attention and Text-guided Explai.pdf,MATEX: Multi-scale Attention and Text-guided Explainability of Medical Vision-Language Models,"Muhammad Imran, Chi Lee, Yugyung Lee",,2601.11666v1,"Explainable AI, Medical Imaging, Vision-Language Models, Gradient Attribution, Attention Rollout, Chest X-ray, CLIP","We introduce MATEX (Multi-scale Attention and Text-guided Explainability), a novel framework that advances interpretability in medical vision-language models by incorporating anatomically informed spatial reasoning. MATEX synergistically combines multi-layer attention rollout, text-guided spatial priors, and layer consistency analysis to produce precise, stable, and clinically meaningful gradient attribution maps. By addressing key limitations of prior methods—such as spatial imprecision, lack of anatomical grounding, and limited attention granularity—MATEX enables more faithful and interpretable model explanations. Evaluated on the MS-CXR dataset, MATEX outperforms the state-of-the-art M2IB approach in both spatial precision and alignment with expert-annotated findings. These results highlight MATEX’s potential to enhance trust and transparency in radiological AI applications.",3.39,85.43,290,cold_start,Phi-4,Apple_M1(Metal)
2601.11667v1_Distill-then-Replace Efficient Task-Specific Hybri.pdf,Distill-then-Replace: Efficient Task-Specific Hybrid Attention Model Construction,"Xiaojie Xia, Huigang Zhang, Chaoliang Zhong, Jun Sun, Yusuke Oishi",,arXiv:2601.11667v1,"Hybrid attention models, Blockwise local distillation, Greedy search","Transformer architectures deliver state-of-the-art accuracy via dense full-attention, but their quadratic time and memory complexity with respect to sequence length limits practical deployment. Linear attention mechanisms offer linear or near-linear scaling yet often incur performance degradation. Hybrid models that integrate full and linear attention layers promise a balance between efficiency and expressiveness, but face two major challenges: training such hybrid models from scratch is computationally expensive, and manually designing the optimal placement of attention types is highly nontrivial. We address both issues by first transferring weights from the pretrained full-attention modules to its linear attention counterparts through blockwise local distillation, and second, introducing a greedy layer replacement strategy that iteratively substitutes full attention blocks with linear ones while monitoring validation performance on the target task. This yields a task-specific hybrid model in a single efficient pass, without costly re-training or neural architecture search, and can be applied to any pretrained full-attention backbone for diverse downstream tasks.",3.63,85.628,311,cold_start,Phi-4,Apple_M1(Metal)
2601.11670v1_A Confidence-Variance Theory for Pseudo-Label Sele.pdf,A Confidence-Variance Theory for Pseudo-Label Selection in Semi-Supervised Learning,"Jinshi Liu, Pan Liu",,,"Semi-Supervised Learning, Pseudo-Labels, Confidence Calibration, Residual Class Variance, Spectral Relaxation, Semantic Segmentation, Image Classification","This paper introduces a Confidence-Variance (CoVar) theory framework for pseudo-label selection in semi-supervised learning. It addresses the issue of overconfidence in deep networks by combining maximum confidence (MC) with residual-class variance (RCV) to form a joint reliability criterion. The framework casts pseudo-label selection as a spectral relaxation problem, maximizing separability in a confidence-variance feature space. CoVar is integrated into semi-supervised semantic segmentation and image classification methods, showing consistent improvements across various datasets and label ratios. The approach provides a more reliable basis for pseudo-label selection than fixed confidence thresholds.",2.94,74.951,220,cold_start,Phi-4,Apple_M1(Metal)
2601.11674v1_Pigment Network Detection and Classification in De.pdf,Pigment Network Detection and Classification in Dermoscopic Images Using Directional Imaging Algorithms and Convolutional Neural Networks,"M. A. Rasel, Sameem Abdul Kareem, Unaizah Obaidellah",10.1016/j.bspc.2024.106883,,"Melanoma, Dermoscopic Images, Pigment Networks, Contrast Enhancement, Threshold Level, Convolutional Neural Networks, Bag of Features","Early diagnosis of melanoma relies heavily on the analysis of dermoscopic images, particularly the identification of unusual pigment networks (PN). This study aims to automate the PN detection process using a directional imaging algorithm and classify PN types using machine learning classifiers. The directional imaging algorithm incorporates Principal Component Analysis (PCA), contrast enhancement, filtering, and noise reduction. Applied to the PH2 dataset, this algorithm achieved a 96% success rate, which increased to 100% after pixel intensity adjustments. A new dataset containing only PN images was created. Two classifiers, Convolutional Neural Network (CNN) and Bag of Features (BoF), were employed to categorize PN into atypical and typical classes. A simple and effective CNN was designed, featuring two convolutional layers and two batch normalization layers, achieving 90% accuracy, 90% sensitivity, and 89% specificity. The proposed CNN demonstrated superior performance compared to state-of-the-art methods. The study highlights the potential of the proposed CNN model for effective PN classification, suggesting future research should focus on expanding datasets and incorporating additional dermatological features to further enhance melanoma diagnosis.",3.52,106.302,374,cold_start,Phi-4,Apple_M1(Metal)
2601.11675v1_Generating metamers of human scene understanding.pdf,GENERATING METAMERS OF HUMAN SCENE UNDERSTANDING,"Ritik Raina, Abe Leite, Alexandros Graikos, Seoyoung Ahn, Dimitris Samaras, Gregory J. Zelinsky",,,"human vision, latent scene representations, latent diffusion model, image metamers, foveated scenes, same-different behavioral experiment, scene perception, metamerism","Human vision combines low-resolution 'gist' information from the visual periphery with high-resolution information from fixated locations to construct a coherent understanding of a visual scene. This paper introduces Metamer-Gen, a tool for generating scenes aligned with latent human scene representations. Metamer-Gen is a latent diffusion model that combines peripherally obtained scene gist information with information from scene-viewing fixations to generate image metamers. This novel image-to-image synthesis problem is tackled by introducing a dual-stream representation of foveated scenes, consisting of DINOv2 tokens that fuse detailed features from fixated areas with peripherally degraded features capturing scene context. A same-different behavioral experiment was conducted to evaluate the perceptual alignment of Metamer-Gen generated images to latent human scene representations. The study identifies scene generations that are metamers for the latent scene representations formed by viewers. Metamer-Gen is a powerful tool for understanding scene understanding, uncovering specific features at multiple levels of visual processing that contribute to human judgments. High-level semantic alignment most strongly predicts metamerism when generated scenes are conditioned on viewers' own fixated regions.",3.46,101.606,352,cold_start,Phi-4,Apple_M1(Metal)
2601.11676v1_HALO Semantic-Aware Distributed LLM Inference in L.pdf,HALO: Semantic-Aware Distributed LLM Inference in Lossy Edge Network,"Peirong Zheng, Wenchao Xu, Haozhao Wang, Jinyu Chen, Xuemin (Sherman) Shen",,,"Large Language Models, Tensor Parallelism, Edge Computing, Heterogeneity, Semantics, Packet Loss","The deployment of large language models (LLMs) inference at the edge can enhance prompt service responsiveness while protecting user privacy. However, resource constraints of a single edge node pose challenges. Distributed inference, which aggregates computational resources across multiple devices, is often hindered by the need for strict synchronization due to unreliable network conditions. This paper introduces HALO, a novel framework designed to improve distributed LLM inference in lossy edge networks by enabling relaxed synchronization. HALO strategically allocates less critical neuron groups to unstable devices, reducing excessive waiting times caused by delayed packets. The framework incorporates three key mechanisms: a semantic-aware predictor to assess neuron group significance, a parallel execution scheme for neuron group loading during model inference, and a load-balancing scheduler for orchestrating devices with heterogeneous resources. Experimental results from a Raspberry Pi cluster show that HALO achieves a 3.41x end-to-end speedup for LLaMA-series LLMs under unreliable network conditions, maintaining performance comparable to optimal conditions and significantly outperforming state-of-the-art methods in various scenarios.",3.29,95.512,314,cold_start,Phi-4,Apple_M1(Metal)
2601.11683v1_Attesting Model Lineage by Consisted Knowledge Evo.pdf,Attesting Model Lineage by Consisted Knowledge Evolution with Fine-Tuning Trajectory,"Zhuoyi Shang, Jiasen Li, Pengzhen Chen, Yanwei Liu, Xiaoyan Gu, Weiping Wang",,,"model lineage, fine-tuning, knowledge evolution, security, deep learning, model verification","The fine-tuning technique in deep learning introduces a lineage relationship among models, which is crucial for addressing security concerns such as unauthorized model redistribution and false claims of model provenance. Existing approaches to model lineage detection rely on static architectural similarities, which are insufficient for capturing the dynamic evolution of knowledge. This work proposes a novel model lineage attestation framework that verifies the joint trajectory of knowledge evolution and parameter modification. The framework uses model editing to quantify parameter-level changes and introduces a knowledge vectorization mechanism to refine evolved knowledge into compact representations. These embeddings verify the arithmetic consistency of knowledge relationships across models, enabling robust attestation of model lineage. The approach is effective and resilient in various adversarial scenarios, achieving reliable lineage verification across different model types, including classifiers, diffusion models, and large language models.",3.31,86.697,287,cold_start,Phi-4,Apple_M1(Metal)
2601.11684v1_Mobile-friendly Image de-noising Hardware Consciou.pdf,Mobile-friendly Image de-noising: Hardware Conscious Optimization for Edge Application,"Srinivas Miriyala, Sowmya Vajrala, Hitesh Kumar, Sravanth Kodavanti, Vikram Rajendiran",,,"De-Noising, Differentiable NAS, Hardware aware Search space, Smartphone Deployment","Image enhancement is a critical task in computer vision and photography that is often entangled with noise, rendering traditional Image Signal Processing (ISP) ineffective compared to advances in deep learning. This work presents a novel mobile-friendly network for image de-noising obtained with Entropy-Regularized differentiable Neural Architecture Search (NAS) on a hardware-aware search space for a U-Net architecture. The designed model has 12% fewer parameters, with ~2-fold improvement in on-device latency and 1.5-fold improvement in the memory footprint for a 0.7% drop in PSNR, when deployed and profiled on Samsung Galaxy S24 Ultra. Compared to the SOTA Swin-Transformer for Image Restoration, the proposed network had competitive accuracy with ~18-fold reduction in GMACs. The network was tested successfully for Gaussian de-noising with 3 intensities on 4 benchmarks and real-world de-noising on 1 benchmark, demonstrating its generalization ability.",3.32,95.156,316,cold_start,Phi-4,Apple_M1(Metal)
2601.11685v1_Towards Efficient Image Deblurring for Edge Deploy.pdf,Towards Efficient Image Deblurring for Edge Deployment,"Srinivas Soumitri Miriyala, Sowmya Lahari Vajrala, Rama Sravanth Kodavanti",,,"Mobile Image Signal Processing (ISP), De-blurring, Training-free Search, Inference Optimization, Edge Deployment","Image deblurring is essential in mobile image signal processing, requiring a balance between restoring fine structures and real-time constraints on edge devices. Recent deep networks like transformers and activation-free architectures achieve high accuracy but are not efficient in terms of latency on embedded hardware. This work proposes a hardware-aware adaptation framework that restructures existing models through sensitivity-guided block substitution, surrogate distillation, and training-free multi-objective search driven by device profiling. Applied to the 36-block NAFNet baseline, the optimized variants achieve up to 55% reduction in GMACs compared to recent transformer-based state-of-the-art while maintaining competitive accuracy. On-device deployment yields a 1.25× latency improvement over the baseline. Experiments on motion deblurring (GoPro), defocus deblurring (DPDD), and auxiliary benchmarks (RealBlur-J/R, HIDE) demonstrate the generality of the approach, confirming its accuracy-efficiency trade-off. These results establish feedback-driven adaptation as a strategy for bridging the gap between algorithmic design and deployment-ready deblurring models.",3.48,95.537,332,cold_start,Phi-4,Apple_M1(Metal)
2601.11686v1_Proof of Concept Multi-Target Wildfire Risk Predic.pdf,Proof of Concept: Multi-Target Wildfire Risk Prediction and Large Language Model Synthesis,"Nicolas Caron, Hassan Noura, Christophe Guyeux, Benjamin Aynes",,arXiv:2601.11686v1,"wildfire risk assessment, multi-target analysis, meteorological danger, ignition activity, intervention complexity, resource mobilization, large language models, predictive models, structured reports","Current state-of-the-art approaches to wildfire risk assessment often overlook operational needs, limiting their practical value for first responders and firefighting services. Effective wildfire management requires a multi-target analysis that captures the diverse aspects of wildfire risk—including meteorological danger, ignition activity, intervention complexity, and resource mobilization—rather than relying on a single predictive indicator. This proof of concept suggests the development of a hybrid framework that combines predictive models for each risk dimension with large language models (LLMs) dedicated to synthesizing heterogeneous outputs into structured, actionable reports.",3.31,78.501,260,cold_start,Phi-4,Apple_M1(Metal)
2601.11687v1_Semantic Caching and Intent-Driven Context Optimiz.pdf,Semantic Caching and Intent-Driven Context Optimization for Multi-Agent Natural Language to Code Systems: A Production Study in Enterprise Analytics,"Harmohit Singh, CoreOps AI",,2601.11687v1,"Natural Language to Code, Multi-Agent Systems, Semantic Caching, LLM Optimization, Production Systems","We present a production-optimized multi-agent system designed to translate natural language queries into executable Python code for structured data analytics. Unlike systems that rely on expensive frontier models, our approach achieves high accuracy and cost efficiency through three key innovations: (1) a semantic caching system with LLM-based equivalence detection and structured adaptation hints that provides cache hit rates of 67% on production queries; (2) a dual-threshold decision mechanism that separates exact-match retrieval from reference-guided generation; and (3) an intent-driven dynamic prompt assembly system that reduces token consumption by 40-60% through table-aware context filtering. The system has been deployed in production for enterprise inventory management, processing over 10,000 queries with an average latency of 8.2 seconds and 94.3% semantic accuracy. We describe the architecture, present empirical results from production deployment, and discuss practical considerations for deploying LLM-based analytics systems at scale.",3.96,76.338,302,cold_start,Phi-4,Apple_M1(Metal)
2601.11688v1_SpecMap Hierarchical LLM Agent for Datasheet-to-Co.pdf,SpecMap: Hierarchical LLM Agent for Datasheet-to-Code,"Vedant Nipane, Pulkit Agrawal, Amit Singh",,2601.11688v1,"Traceability Link Recovery, Systems Engineering, Datasheet-to-Code Mapping, Large Language Models, Semantic Analysis, Embedded Systems","Establishing precise traceability between embedded systems datasheets and their corresponding code implementations remains a fundamental challenge in systems engineering, particularly for low-level software where manual mapping between specification documents and large code repositories is infeasible. Existing Traceability Link Recovery (TLR) approaches primarily rely on lexical similarity and information retrieval techniques, which struggle to capture the semantic, structural, and symbol-level relationships prevalent in embedded systems software. We present a hierarchical datasheet-to-code mapping methodology that employs large language models (LLMs) for semantic analysis while explicitly structuring the traceability process across multiple abstraction levels. Rather than performing direct specification-to-code matching, the proposed approach progressively narrows the search space through repository-level structure inference, file-level relevance estimation, and fine-grained symbol-level alignment. The method extends beyond function-centric mapping by explicitly covering macros, structs, constants, configuration parameters, and register definitions commonly found in systems-level C/C++ codebases. We evaluate the approach on multiple open-source embedded systems repositories using manually curated datasheet-to-code ground truth. Experimental results show substantial improvements over traditional information-retrieval-based baselines, achieving up to 73.3% file mapping accuracy. The hierarchical decomposition significantly reduces computational overhead, lowering total LLM token consumption by 84% and end-to-end runtime by approximately 80%. This methodology supports automated analysis of large embedded software systems and enables downstream applications such as training data generation for systems-aware machine learning models, standards compliance verification, and large-scale specification coverage analysis.",3.77,106.474,401,cold_start,Phi-4,Apple_M1(Metal)
2601.11700v1_Telling Human and Machine Handwriting Apart.pdf,Telling Human and Machine Handwriting Apart,"Luis A. Leiva, Moises Diaz, Nuwan T. Attygalle, Miguel A. Ferrer, Réjean Plamondon",,,"Biometrics, classification, deep learning, reverse Turing test, verification","Handwriting movements can be leveraged as a unique form of behavioral biometrics to verify whether a real user is operating a device or application. This task, framed as a 'reverse Turing test,' involves detecting if an input instance is generated by a human or artificially. The study examines ten public datasets of handwritten symbols using seven different synthesizers, including the Kinematic Theory (Σh model), generative adversarial networks, Transformers, and Diffusion models. A shallow recurrent neural network is trained, achieving an average of 98.3% AUC score and 1.4% equal error rate across all synthesizers and datasets. The classifier performs well even in few-shot settings and out-of-domain challenges, providing implications for computerized systems needing to verify human presence and adding an additional layer of security.",3.14,88.405,278,cold_start,Phi-4,Apple_M1(Metal)
2601.11702v1_PASTA A Scalable Framework for Multi-Policy AI Com.pdf,PASTA: A Scalable Framework for Multi-Policy AI Compliance Evaluation,"YU YANG, IG-JAE KIM, DONGWOOK YOON",,,"AI compliance, multi-policy, scalable framework, LLM-powered evaluation, compliance heatmaps, automated AI governance","AI compliance is becoming increasingly critical as AI systems grow more powerful and pervasive. Existing approaches typically address one policy at a time, making multi-policy compliance costly. This paper presents PASTA, a scalable compliance tool integrating four innovations: a comprehensive model-card format, a policy normalization scheme, an efficient LLM-powered pairwise evaluation engine with cost-saving strategies, and an interface delivering interpretable evaluations via compliance heatmaps and actionable recommendations. Expert evaluation shows PASTA’s judgments closely align with human experts (𝜌≥. 626). The system evaluates five major policies in under two minutes at approximately $3. A user study confirms practitioners found outputs easy-to-understand and actionable, introducing a novel framework for scalable automated AI governance. The landscape of AI governance is growing in complexity with rapidly evolving policies, necessitating scalable compliance management across diverse policies.",3.43,76.878,264,cold_start,Phi-4,Apple_M1(Metal)
2601.11713v1_Inter-Cell Interference Rejection Based on Ultrawi.pdf,Inter-Cell Interference Rejection Based on Ultrawideband Walsh-Domain Wireless Autoencoding,"Rodney Martinez Alonso, Cel Thys, Sofie Pollin, Cedric Dehos, Yuneisy Esthela Garcia Guzman",,,"ultrawideband, inter-cell interference, autoencoder, Walsh domain, 5G, interference rejection","This paper proposes a novel technique for rejecting partial-in-band inter-cell interference (ICI) in ultrawideband communication systems. It presents an end-to-end wireless autoencoder architecture that optimizes transmitter and receiver encoding/decoding in the Walsh domain to mitigate interference from coexisting narrower-band 5G base stations. By leveraging the orthogonality and self-inverse properties of Walsh functions, the system encodes bit-words across parallel Walsh branches. Analytical modeling and simulation characterize how 5G CP-OFDM interference maps into the Walsh domain, identifying optimal transmission frequency and sampling rate ratios for maximum ICI rejection. Experimental results show up to 12 dB of ICI rejection while maintaining a low block error rate (BLER) for the same baseline channel noise, i.e., baseline Signal-to-Noise-Ratio (SNR) without interference.",3.33,92.181,307,cold_start,Phi-4,Apple_M1(Metal)
2601.11746v1_LIME-LLM Probing Models with Fluent Counterfactual.pdf,"LIME-LLM: Probing Models with Fluent Counterfactuals, Not Broken Text","George Mihaila, Suleyman Olcay Polat, Poli Nemkova, Himanshu Sharma, Namratha V. Urs, Mark V. Albert",,arXiv:2601.11746v1,"LIME, LLM, NLP, explanation methods, trustworthy AI, semantic validity, local surrogate models, perturbation-based methods, generative approaches, counterfactuals","Local explanation methods like LIME are crucial for trustworthy AI but are limited in NLP due to random token masking, which often results in semantically invalid inputs. LIME-LLM introduces hypothesis-driven, controlled perturbations to construct fluent, on-manifold neighborhoods, improving local explanation fidelity. It is evaluated against LIME, SHAP, Integrated Gradients, and LLiMe across benchmarks like CoLA, SST-2, and HateXplain, demonstrating significant improvements in explanation fidelity.",3.34,83.561,279,cold_start,Phi-4,Apple_M1(Metal)
2601.11747v1_PRISM Learning Design Knowledge from Data for Styl.pdf,PRISM: Learning Design Knowledge from Data for Stylistic Design Improvement,"Huaxiaoyue Wang, Sunav Choudhary, Franck Dernoncourt, Yu Shen, Stefano Petrangeli",,,"graphic design, stylistic improvement, natural language instructions, design knowledge, Vision Language Models (VLMs), design data, style alignment","Graphic design often involves exploring different stylistic directions, which can be time-consuming for non-experts. This paper addresses the problem of stylistically improving designs based on natural language instructions. While Vision Language Models (VLMs) have shown initial success in graphic design, their pretrained knowledge on styles is often too general and misaligned with specific domain data. The paper proposes PRISM (PRior-Informed Stylistic Modification), which constructs and applies a design knowledge base through three stages: clustering high-variance designs to capture diversity within a style, summarizing each cluster into actionable design knowledge, and retrieving relevant knowledge during inference to enable style-aware improvement. Experiments on the Crello dataset show that PRISM achieves the highest average rank over baselines in style alignment. User studies further validate these results, showing that PRISM is consistently preferred by designers.",3.23,87.266,282,cold_start,Phi-4,Apple_M1(Metal)
2601.11758v1_Early Linguistic Pattern of Anxiety from Social Me.pdf,Early Linguistic Pattern of Anxiety from Social Media: Using Interpretable Linguistic Features: A Multi-Faceted Validation Study with Author-Disjoint Evaluation,Arnab Das Utsa,,,"anxiety detection, linguistic pattern, interpretable machine learning, keyword robustness, cross-domain validation, author-disjoint evaluation, mental health screening","Anxiety affects hundreds of millions of individuals globally, yet large-scale screening remains limited. Social media language provides an opportunity for scalable detection, but current models often lack interpretability, keyword-robustness validation, and rigorous user-level data integrity. This work presents a transparent approach to social media-based anxiety detection through linguistically interpretable feature-grounded modeling and cross-domain validation. Using a substantial dataset of Reddit posts, a logistic regression classifier was trained on carefully curated subreddits for training, validation, and test splits. Comprehensive evaluation included feature ablation, keyword masking experiments, and varying-density difference analyses comparing anxious and control groups, along with external validation using clinically interviewed participants with diagnosed anxiety disorders. The model achieved strong performance while maintaining high accuracy even after sentiment removal or keyword masking. Early detection using minimal post history significantly outperformed random classification, and cross-domain analysis demonstrated strong consistency with clinical interview data. Results indicate that transparent linguistic features can support reliable, generalizable, and keyword-robust anxiety detection. The proposed framework provides a reproducible baseline for interpretable mental health screening across diverse online contexts.",3.4,95.321,324,cold_start,Phi-4,Apple_M1(Metal)
2601.11762v1_Industry-Aligned Granular Topic Modeling.pdf,Industry-Aligned Granular Topic Modeling,"Sae Young Moon, Myeongjun Erik Jang, Haoyan Luo, Chunyang Xiao, Antonios Georgiadis, Fran Silavong",,,"topic modeling, granularity, business applications, large language models, text mining, data analysis","Topic modeling is widely used in text mining and data analysis across various industries. This paper introduces a framework called TIDE, which provides a novel granular topic modeling method based on large language models (LLMs). TIDE also includes functionalities for summarizing long documents, topic parenting, and distillation. Through experiments on public and real-world business datasets, TIDE's approach is shown to outperform modern topic modeling methods. The framework is being open-sourced.",2.86,66.891,191,cold_start,Phi-4,Apple_M1(Metal)
2601.11768v1_Lightweight Self-Supervised Detection of Fundament.pdf,Lightweight Self-Supervised Detection of Fundamental Frequency and Accurate Probability of Voicing in Monophonic Music,"Venkat Suprabath Bitra, Homayoon Beigi",,,"self-supervised pitch detection, unsupervised pitch detection, fundamental frequency, pitch estimation, resonance, musical timbre transfer, probability of voicing, music synthesis, music analysis, CQT, constant Q transform, DDSP, shift cross-entropy loss, musical instrument modeling, ResNeXt neural network, music information retrieval, MIR","Reliable fundamental frequency (F0) and voicing estimation are essential for neural synthesis, yet many pitch extractors depend on large labeled corpora and degrade under realistic recording artifacts. This paper proposes a lightweight, fully self-supervised framework for joint F0 estimation and voicing inference, designed for rapid single-instrument training from limited audio. Using transposition-equivariant learning on CQT features, an EM-style iterative reweighting scheme is introduced that uses Shift Cross-Entropy (SCE) consistency as a reliability signal to suppress uninformative noisy/unvoiced frames. The resulting weights provide confidence scores that enable pseudo-labeling for a separate lightweight voicing classifier without manual annotations. Trained on MedleyDB and evaluated on MDB-stem-synth ground truth, the method achieves competitive cross-corpus performance (RPA 95.84, RCA 96.24) and demonstrates cross-instrument generalization.",3.37,110.269,372,cold_start,Phi-4,Apple_M1(Metal)
2601.11776v1_Cleansing the Artificial Mind A Self-Reflective De.pdf,Cleansing the Artificial Mind: A Self-Reflective Detoxification Framework for Large Language Models,"Kaituo Zhang, Zhimeng Jiang, Na Zou",,,"Large Language Models, detoxification, self-regulation, toxic content, text generation","Recent breakthroughs in Large Language Models (LLMs) have revealed remarkable generative capabilities and emerging self-regulatory mechanisms, including self-correction and self-rewarding. However, current detoxification techniques rarely exploit these built-in abilities; instead, they rely on external modules, labor-intensive data annotation, or human intervention – factors that hinder scalability and consistency. This paper introduces a fully self-reflective detoxification framework that harnesses the inherent capacities of LLMs to detect, correct toxic content, and refine LLMs without external modules and data annotation. Specifically, a Toxic Signal Detector—an internal self-identification mechanism, coupled with a systematic intervention process, is proposed to transform toxic text into its non-toxic counterpart. This iterative procedure yields a contrastive detoxification dataset used to fine-tune the model, enhancing its ability for safe and coherent text generation. Experiments on benchmark datasets such as DetoxLLM and ParaDetox show that the method achieves better detoxification performance than state-of-the-art methods while preserving semantic fidelity. By obviating the need for human intervention or external components, this paper reveals the intrinsic self-detoxification ability of LLMs, offering a consistent and effective approach for mitigating harmful content generation. Ultimately, the findings underscore the potential for truly self-regulated language models, paving the way for more responsible and ethically guided text generation systems.",3.36,114.912,386,cold_start,Phi-4,Apple_M1(Metal)
2601.11778v1_Translation as a Scalable Proxy for Multilingual E.pdf,Translation as a Scalable Proxy for Multilingual Evaluation,"Sheriff Issaka, Erick Rosas Gonzalez, Lieqi Liu, Evans Kofi Agyei, Lucas Bandarkar, Nanyun Peng, David Ifeoluwa Adelani, Francisco Guzmán, Saadia Gabriel",,,"LLMs, multilingual evaluation, translation quality, benchmarking, low-resourced languages","The rapid proliferation of large language models (LLMs) has led to a critical evaluation paradox: while LLMs claim multilingual proficiency, comprehensive benchmarks exist for fewer than 30 languages, leaving over 98% of the world's 7,000 languages unmeasured. This work evaluates whether translation quality can serve as a reliable, scalable, and cost-effective proxy for a model's broader multilingual capabilities. Through systematic evaluation of 14 models across 9 benchmarks and 7 translation metrics, it is found that translation performance is a good indicator of downstream task success. This suggests that translation quality can be a strong, inexpensive first-pass proxy for multilingual performance, enabling a translation-first screening with targeted follow-up for specific tasks.",3.13,94.273,295,cold_start,Phi-4,Apple_M1(Metal)
2601.11781v1_Risk-Aware Human-in-the-Loop Framework with Adapti.pdf,Risk-Aware Human-in-the-Loop Framework with Adaptive Intrusion Response for Autonomous Vehicles,"Dawood Wasif, Terrence J. Moore, Seunghyun Yoon, Hyuk Lim, Dan Dongseong Kim, Frederica F. Nelson, Jin-Hee Cho",,,"autonomous vehicles, human-in-the-loop, risk-aware, intrusion response, adaptive control, cyber-physical security, reinforcement learning, safe RL, imitation learning, offline RL","Autonomous vehicles must remain safe and effective when encountering rare long-tailed scenarios or cyber–physical intrusions during driving. This paper presents RAIL, a risk-aware human-in-the-loop framework that turns heterogeneous runtime signals into calibrated control adaptations and focused learning. RAIL fuses three cues (curvature actuation integrity, time-to-collision proximity, and observation-shift consistency) into an Intrusion Risk Score (IRS) via weighted Noisy-OR. When IRS exceeds a threshold, actions are blended with a cue-specific shield using a learned authority, while human override remains available; when risk is low, the nominal policy executes. A contextual bandit arbitrates among shields based on the cue vector, improving mitigation choices online. RAIL couples Soft Actor–Critic (SAC) with risk-prioritized replay and dual rewards so that takeovers and near misses steer learning while nominal behavior remains covered. On MetaDrive, RAIL achieves a Test Return (TR) of 360.65, a Test Success Rate (TSR) of 0.85, a Test Safety Violation (TSV) of 0.75, and a Disturbance Rate (DR) of 0.0027, while logging only 29.07 training safety violations—outperforming RL, safe RL, offline/imitation learning, and prior HITL baselines. Under Controller Area Network (CAN) injection and LiDAR spoofing attacks, it improves Success Rate (SR) to 0.68 and 0.80, lowers the Disengagement Rate under Attack (DRA) to 0.37 and 0.03, and reduces the Attack Success Rate (ASR) to 0.34 and 0.11. In CARLA, RAIL attains a TR of 1609.70 and TSR of 0.41 with only 8K steps.",3.64,153.165,558,cold_start,Phi-4,Apple_M1(Metal)
2601.11792v1_A self-evolving multi-role collaborative framework.pdf,A self-evolving multi-role collaborative framework with fine-grained difficulty guidance for innovative mathematical problem generation,"Yifei Sun, Yongan Li, A.K. Qin, Sicheng Hua, Tamas Pflanzner",,,"Problem generation, Large language models, Multi-role collaboration, Intelligent education, Self-evolution, Knowledge distillation","Mathematical problem generation (MPG) is a significant research direction in the field of intelligent education. This paper proposes a self-evolving, multi-role collaborative framework with fine-grained difficulty guidance for innovative math problem generation (IMPG). The framework includes a multi-role collaborative mechanism comprising a sampler, generator, evaluator, state machine, and memory, ensuring the correctness of generated problems through iterative optimization informed by self-assessment and external feedback. An improved difficulty model is introduced to quantify difficulty and provide fine-grained guidance. The HSM3K-CN dataset, comprising high-quality high school math problems, is constructed. A multi-stage training pipeline incorporating continual pre-training (CPT), supervised fine-tuning (SFT), and group relative policy optimization (GRPO) is adopted to enhance the generation and evaluation capabilities of the base model. System self-evolution is achieved by transferring evaluation capabilities from the expert model to the apprentice model via distillation. Experiments show that the proposed method significantly improves the innovation of the generated problems while maintaining a high correctness rate.",3.43,99.485,341,cold_start,Phi-4,Apple_M1(Metal)
2601.11801v1_RobotDesignGPT Automated Robot Design Synthesis us.pdf,RobotDesignGPT: Automated Robot Design Synthesis using Vision Language Models,"Nitish Sontakke, K. Niranjan Kumar, Sehoon Ha",,,"robot design synthesis, vision language models, automated robot design, kinematic structures, visual feedback, user study, ablation study","Robot design is a complex process requiring domain expertise and significant human effort, often relying on rule-based methods. This paper introduces RobotDesignGPT, a novel framework leveraging large pre-trained vision-language models (VLMs) to automate robot design synthesis. The framework synthesizes initial robot designs from user prompts and reference images, improving design quality with a novel visual feedback approach. It demonstrates the ability to design visually appealing and kinematically valid robots inspired by nature, from legged animals to flying creatures. The framework's effectiveness is validated through an ablation study and a user study.",3.03,69.959,212,cold_start,Phi-4,Apple_M1(Metal)
2601.11809v1_Multi-agent DRL-based Lane Change Decision Model f.pdf,Multi-agent DRL-based Lane Change Decision Model for Cooperative Planning in Mixed Traffic,"Zeyu Mu, Shangtong Zhang, B. Brian Park",,,"Multi-Agent, Reinforcement Learning, Cooperative Platooning, Lane Change","Connected automated vehicles (CAVs) can communicate and coordinate to form cooperative platoons, enhancing energy efficiency and traffic flow. However, the sparse distribution of CAVs among human-driven vehicles during initial deployment stages reduces the likelihood of forming effective platoons. This study proposes a hybrid multi-agent lane change decision model using the QMIX framework and a convolutional neural network (CNN-QMIX) to increase CAV participation in cooperative platooning. The model includes a trajectory planner and a model predictive controller for smooth and safe lane changes. Evaluated in a microsimulation environment, the model outperforms baseline rule-based models, increasing cooperative platooning rates by up to 26.2%, optimizing CAV cooperation and traffic dynamics during early deployment stages.",3.27,77.793,254,cold_start,Phi-4,Apple_M1(Metal)
2601.11816v1_POLARIS Typed Planning and Governed Execution for .pdf,POLARIS: Typed Planning and Governed Execution for Agentic AI in Back-Office Automation,"Zahra Moslemi, Keerthi Koneru, Yen-Ting Lee, Sheethal Kumar, Ramesh Radhakrishnan",,,"Agentic AI, Enterprise Automation, Back-Office Tasks, Benchmarks, Governance, Typed Planning, Evaluation","Enterprise back-office workflows require agentic systems that are auditable, policy-aligned, and operationally predictable, capabilities that generic multi-agent setups often fail to deliver. We present POLARIS (Policy-Aware LLM Agentic Reasoning for Integrated Systems), a governed orchestration framework that treats automation as typed plan synthesis and validated execution over LLM agents. A planner proposes structurally diverse, type-checked directed acyclic graphs (DAGs); a rubric-guided reasoning module selects a single compliant plan; and execution is guarded by validator-gated checks, a bounded repair loop, and compiled policy guardrails that block or route side effects before they occur. Applied to document-centric finance tasks, POLARIS produces decision-grade artifacts and full execution traces while reducing human intervention. Empirically, POLARIS achieves a micro-F1 of 0.81 on the SROIE dataset and, on a controlled synthetic suite, achieves 0.95–1.00 precision for anomaly routing with preserved audit trails. These evaluations constitute an initial benchmark for governed Agentic AI. POLARIS provides a methodological and benchmark reference for policy-aligned Agentic AI.",3.47,107.74,374,cold_start,Phi-4,Apple_M1(Metal)
2601.11825v1_AI Co-Scientist for Knowledge Synthesis in Medical.pdf,AI Co-Scientist for Knowledge Synthesis in Medical Contexts: A Proof of Concept,"Arya Rahgozara, Pouria Mortezaagha",,2601.11825v1,"AI, knowledge synthesis, medical contexts, PICOS, dementia–sport, non-communicable disease, BiLSTM, transformer-based classifier, PubMedBERT, retrieval-augmented generation, Neo4j knowledge graph, BERTopic","This study aims to develop and evaluate an AI co-scientist for scalable and transparent knowledge synthesis in biomedical science, addressing research waste through redundant studies, incomplete reporting, and limited scalability of conventional workflows. The AI co-scientist utilizes explicit Population, Intervention, Comparator, Outcome, and Study design (PICOS) formalization. A multi-representational platform integrating relational databases, vector-based semantic retrieval, and a Neo4j knowledge graph was designed and evaluated on dementia–sport (DS) and non-communicable disease (NCD) corpora. Automated PICOS compliance classification was performed using a BiLSTM baseline and a transformer-based multi-task classifier fine-tuned from PubMedBERT. Full-text synthesis employed retrieval-augmented generation (RAG) with hybrid vector and graph-based retrieval. Topic modeling using BERTopic identified thematic structure, redundancy, and evidence gaps. The transformer-based classifier achieved high accuracy in study design classification, and RAG outperformed non-retrieval generation for structured queries and cross-study integration.",3.85,95.651,368,cold_start,Phi-4,Apple_M1(Metal)
2601.11840v1_Imandra CodeLogician Neuro-Symbolic Reasoning for .pdf,Neuro-Symbolic Reasoning for Precise Analysis of Software Logic,"Hongyu Lin, Samer Abdallah, Makar Valentinov, Paul Brennan, Elijah Kagan, Christoph M. Wintersteiger, Denis Ignatovich, Grant Passmore",,arXiv:2601.11840v1,"Neuro-Symbolic Reasoning, Software Logic, Large Language Models, Formal Verification, Automated Reasoning, Code Analysis","Large Language Models (LLMs) have shown strong performance on code understanding and software engineering tasks, yet they fundamentally lack the ability to perform precise, exhaustive mathematical reasoning about program behavior. This paper presents CodeLogician, a neurosymbolic agent and framework for precise analysis of software logic, integrated with ImandraX, an industrial automated reasoning engine. Unlike prior approaches that use formal methods primarily to validate or filter LLM outputs, CodeLogician uses LLMs to help construct explicit formal models of software systems, enabling automated reasoning to answer rich semantic questions beyond binary verification outcomes. The paper introduces a new benchmark dataset, code-logic-bench, to evaluate mathematical reasoning about software logic, measuring correctness and efficacy of reasoning about program state spaces, control flow, coverage constraints, decision boundaries, and edge cases. Results demonstrate that formal augmentation with CodeLogician yields substantial improvements in reasoning accuracy, closing a 41–47 percentage point gap compared to LLM-only approaches.",3.57,99.771,356,cold_start,Phi-4,Apple_M1(Metal)
2601.11850v1_Human-AI Collaborative Inductive Thematic Analysis.pdf,Human–AI Collaborative Inductive Thematic Analysis: How AI Guides Analysis and Researchers Reclaim Interpretive Authority,"Matthew Nyaaba, Min SungEun, Mary Abiswin Apam, Kwame Owoahene Acheampong, Emmanuel Dwamena, Xiaoming Zhai",,,"Human–AI collaboration, Generative artificial intelligence (GenAI), Inductive thematic analysis, Qualitative data analysis, Epistemic authority, Reflexive methodology","The study investigates the interaction between researchers and an Inductive Thematic Analysis GPT (ITA–GPT), a tool designed to operationalize inductive thematic analysis procedures. Using a Human–Artificial Intelligence Collaborative Inductive Thematic Analysis (HACITA) framework, the study focuses on the analytic process rather than substantive content. Three experienced qualitative researchers conducted ITA–GPT–assisted analyses of interview transcripts from education research in the Ghanaian teacher education context. The ITA–GPT tool guided researchers through various stages of analysis while ensuring integrity and auditability. Findings indicate that ITA–GPT served as a procedural scaffold, but researchers exercised epistemic authority through actions like modification, deletion, rejection, insertion, and commenting to correct AI literalism and align interpretations with contextual realities. The study provides a theoretically grounded account of inductive thematic analysis through human–AI collaboration.",3.47,90.779,315,cold_start,Phi-4,Apple_M1(Metal)
2601.11854v1_ATOD An Evaluation Framework and Benchmark for Age.pdf,ATOD: An Evaluation Framework and Benchmark for Agentic Task-Oriented Dialogue System,"Yifei Zhang, Hooshang Nayyeri, Rinat Khaziev, Emine Yilmaz, Gokhan Tur, Dilek Hakkani-Tür, Hari Thadakamalla",,,"task-oriented dialogue, large language models, API integration, benchmark, evaluation framework, agentic behavior, multi-goal coordination, dependency management, memory, adaptability, proactivity","Recent advances in task-oriented dialogue (TOD) systems, driven by large language models (LLMs) with extensive API and tool integration, have enabled conversational agents to coordinate interleaved goals, maintain long-horizon context, and act proactively through asynchronous execution. These capabilities extend beyond traditional TOD systems, yet existing benchmarks lack systematic support for evaluating such agentic behaviors. To address this gap, we introduce ATOD, a benchmark and synthetic dialogue generation pipeline that produces richly annotated conversations requiring long-term reasoning. ATOD captures key characteristics of advanced TOD, including multi-goal coordination, dependency management, memory, adaptability, and proactivity. Building on ATOD, we propose ATOD-Eval, a holistic evaluation framework that translates these dimensions into fine-grained metrics and supports reproducible offline and online evaluation. We further present a strong agentic memory-based evaluator for benchmarking on ATOD. Experiments show that ATOD-Eval enables comprehensive assessment across task completion, agentic capability, and response quality, and that the proposed evaluator offers a better accuracy–efficiency trade-off compared to existing memory- and LLM-based approaches under this evaluation setting.",3.47,117.12,406,cold_start,Phi-4,Apple_M1(Metal)
2601.11859v1_Cascaded Transformer for Robust and Scalable SLA D.pdf,Cascaded Transformer for Robust and Scalable SLA Decomposition via Amortized Optimization,Cyril Shih-Huan Hsu,,,"network slicing, service level agreement, quality of service, deep neural network, optimization, transformers","The evolution toward 6G networks increasingly relies on network slicing to provide tailored, End-to-End (E2E) logical networks over shared physical infrastructures. A critical challenge is effectively decomposing E2E Service Level Agreements (SLAs) into domain-specific SLAs, which current solutions handle through computationally intensive, iterative optimization processes that incur substantial latency and complexity. To address this, we introduce Casformer, a cascaded Transformer architecture designed for fast, optimization-free SLA decomposition. Casformer leverages historical domain feedback encoded through domain-specific Transformer encoders in its first layer, and integrates cross-domain dependencies using a Transformer-based aggregator in its second layer. The model is trained under a learning paradigm inspired by Domain-Informed Neural Networks (DINNs), incorporating risk-informed modeling and amortized optimization to learn a stable, forward-only SLA decomposition policy. Extensive evaluations demonstrate that Casformer achieves improved SLA decomposition quality against state-of-the-art optimization-based frameworks, while exhibiting enhanced scalability and robustness under volatile and noisy network conditions. In addition, its forward-only design reduces runtime complexity and simplifies deployment and maintenance. These insights reveal the potential of combining amortized optimization with Transformer-based sequence modeling to advance network automation, providing a scalable and efficient solution suitable for real-time SLA management in advanced 5G-and-beyond network environments.",3.57,99.351,355,cold_start,Phi-4,Apple_M1(Metal)
2601.11863v1_Utilizing Metadata for Better Retrieval-Augmented .pdf,Utilizing Metadata for Better Retrieval-Augmented Generation,"Raquib Bin Yousuf, Shengzhe Xu, Mandar Sharma, Andrew Neeser, Chris Latimer, Naren Ramakrishnan",,arXiv:2601.11863v1,"Retrieval-Augmented Generation (RAG), Metadata-aware Retrieval, Dense Retrieval, Query Reformulation, Benchmark Datasets","Retrieval-Augmented Generation systems rely on retrieving semantically relevant document chunks to support accurate, grounded outputs from large language models. In structured and repetitive corpora such as regulatory filings, chunk similarity alone often fails to distinguish between documents with overlapping language. Practitioners often flatten metadata into input text as a heuristic, but the impact and trade-offs of this practice remain poorly understood. This study presents systematic retrieval strategies, comparing plain-text baselines with approaches that embed metadata directly. Evaluation includes metadata-as-text (prefix and suffix), a dual-encoder unified embedding that fuses metadata and content in a single index, dual-encoder late-fusion retrieval, and metadata-aware query reformulation. Prefixing and unified embeddings consistently outperform plain-text baselines, with unified embeddings sometimes exceeding prefixing while being easier to maintain. Metadata integration improves effectiveness by increasing intra-document cohesion, reducing inter-document confusion, and widening the separation between relevant and irrelevant chunks. Field-level ablations show that structural cues provide strong disambiguating signals. The code, evaluation framework, and the RAGMATE-10K dataset are publicly hosted.",3.74,99.058,370,cold_start,Phi-4,Apple_M1(Metal)
2601.11868v1_Terminal-Bench Benchmarking Agents on Hard Realist.pdf,"TERMINAL-BENCH: BENCHMARKING AGENTS ON HARD, REALISTIC TASKS IN COMMAND LINE INTERFACES","Mike A. Merrill, Alexander G. Shaw, Nicholas Carlini, Boxuan Li, Harsh Raj, Ivan Bercovich, Lin Shi, Jeong Yeon Shin, Thomas Walshe, E. Kelly Buchanan, Junhong Shen, Guanghao Ye, Haowei Lin, Jason Poulos, Maoyu Wang, Marianna Nezhurina, Jenia Jitsev, Di Lu, Orfeas Menis Mastromichalakis, Zhiwei Xu, Zizhao Chen, Yue Liu, Robert Zhang, Leon Liangyu Chen, Anurag Kashyap, Jan-Lucas Uslu, Jeffrey Li, Jianbo Wu, Minghao Yan, Song Bian, Vedang Sharma, Ke Sun, Steven Dillmann, Akshay Anand, Andrew Lanpouthakoun, Bardia Koopah, Changran Hu, Etash Guha, Gabriel H. S. Dreiman, Jiacheng Zhu, Karl Krauth, Li Zhong, Niklas Muennighoff, Robert Amanfu, Shangyin Tan, Shreyas Pimpalgaonkar, Tushar Aggarwal, Xiangning Lin, Xin Lan, Xuandong Zhao, Yiqing Liang, Yuanli Wang, Zilong Wang, Changzhi Zhou, David Heineman, Hange Liu, Harsh Trivedi, John Yang, Junhong Lin, Manish Shetty, Michael Yang, Nabil Omi, Negin Raoof, Shanda Li, Terry Yue Zhuo, Wuwei Lin, Yiwei Dai, Yuxin Wang, Wenhao Chai, Shang Zhou, Dariush Wahdany, Ziyu She, Jiaming Hu, Zhikang Dong, Yuxuan Zhu, Sasha Cui, Ahson Saiyed, Arinbjörn Kolbeinsson, Jesse Hu, Christopher Michael Rytting, Ryan Marten, Yixin Wang, Alex Dimakis, Andy Konwinski",,arXiv:2601.11868v1,"AI agents, benchmarking, command line interfaces, real-world tasks, evaluation, error analysis","AI agents may soon become capable of autonomously completing valuable, long-horizon tasks in diverse domains. Current benchmarks either do not measure real-world tasks, or are not sufficiently difficult to meaningfully measure frontier models. To this end, we present Terminal-Bench 2.0: a carefully curated hard benchmark composed of 89 tasks in computer terminal environments inspired by problems from real workflows. Each task features a unique environment, human-written solution, and comprehensive tests for verification. We show that frontier models and agents score less than 65% on the benchmark and conduct an error analysis to identify areas for model and agent improvement. We publish the dataset and evaluation harness to assist developers and researchers in future work at tbench.ai.",3.68,235.17,866,cold_start,Phi-4,Apple_M1(Metal)
2601.11876v1_AI for Green Spaces Leveraging Autonomous Navigati.pdf,Autonomous Trash Pickup Robots on Grass Fields,,,,"autonomous navigation, trash pickup, robotics, Spanning Tree Coverage algorithm, Real-Time Kinematic GPS, ResNet50 Convolutional Neural Network, grass fields, litter problem","The paper addresses the significant litter problem in the U.S., with 50 billion pieces of litter reported. It proposes an autonomous robot capable of navigating, identifying, and picking up trash in parks, specifically on grass fields. The robot uses a Spanning Tree Coverage (STC) algorithm for navigation, Real-Time Kinematic (RTK) GPS for precise movement, and a ResNet50 CNN for trash detection with 94.52% accuracy. The robot's pickup mechanism is tailored to the specific trash encountered on grass fields, achieving an 80% success rate. The study highlights the challenges of grass terrain and compares the proposed solution to existing robotic solutions for litter cleanup in different environments.",3.16,74.97,237,cold_start,Phi-4,Apple_M1(Metal)
2601.11880v1_TF-CoDiT Conditional Time Series Synthesis with Di.pdf,TF-CoDiT: Conditional Time Series Synthesis with Diffusion Transformers for Treasury Futures,"Yingxiao Zhang, Jiaxin Duan, Junfu Zhang, Ke Feng",,,"Diffusion Transformers, Treasury Futures, Time Series Synthesis, Discrete Wavelet Transform, Financial Market Attribute Protocol","Diffusion Transformers (DiT) have achieved milestones in synthesizing financial time-series data, such as stock prices and order flows. However, their performance in synthesizing treasury futures data is still underexplored. This work emphasizes the characteristics of treasury futures data, including its low volume, market dependencies, and grouped correlations among multivariables. To overcome these challenges, we propose TF-CoDiT, the first DiT framework for language-controlled treasury futures synthesis. To facilitate low-data learning, TF-CoDiT adapts the standard DiT by transforming multi-channel 1-D time series into Discrete Wavelet Transform (DWT) coefficient matrices. A U-shape VAE is proposed to encode cross-channel dependencies hierarchically into a latent variable and bridge the latent and DWT spaces through decoding, thereby enabling latent diffusion generation. To derive prompts that cover essential conditions, we introduce the Financial Market Attribute Protocol (FinMAP) - a multi-level description system that standardizes daily/periodical market dynamics by recognizing 17/23 economic indicators from 7/8 perspectives. In our experiments, we gather four types of treasury futures data covering the period from 2015 to 2025, and define data synthesis tasks with durations ranging from one week to four months. Extensive evaluations demonstrate that TF-CoDiT can produce highly authentic data with errors at most 0.433 (MSE) and 0.453 (MAE) to the ground-truth. Further studies evidence the robustness of TF-CoDiT across contracts and temporal horizons.",3.55,121.673,432,cold_start,Phi-4,Apple_M1(Metal)
2601.11885v1_MyGram Modality-aware Graph Transformer with Globa.pdf,MyGram: Modality-aware Graph Transformer with Global Distribution for Multi-modal Entity Alignment,"Zhifei Li, Ziyue Qin, Xiangyu Luo, Xiaoju Hou, Yue Zhao, Miao Zhang, Zhifang Huang, Kui Xiao, Bing Yang",,,"Multi-modal Entity Alignment, Knowledge Graphs, Graph Transformer, Modality-aware Learning, Global Distribution","Multi-modal entity alignment aims to identify equivalent entities between two multi-modal Knowledge graphs by integrating multi-modal data, such as images and text, to enrich the semantic representations of entities. Existing methods may overlook the structural contextual information within each modality, making them vulnerable to interference from shallow features. To address these challenges, we propose MyGram, a modality-aware graph transformer with global distribution for multi-modal entity alignment. Specifically, we develop a modality diffusion learning module to capture deep structural contextual information within modalities and enable fine-grained multi-modal fusion. In addition, we introduce a Gram Loss that acts as a regularization constraint by minimizing the volume of a 4-dimensional parallelepiped formed by multi-modal features, thereby achieving global distribution consistency across modalities. We conduct experiments on five public datasets. Results show that MyGram outperforms baseline models, achieving a maximum improvement of 4.8% in Hits@1 on FBDB15K, 9.9% on FBYG15K, and 4.3% on DBP15K.",3.2,111.899,358,cold_start,Phi-4,Apple_M1(Metal)
2601.11895v1_DevBench A Realistic Developer-Informed Benchmark .pdf,"DevBench: A Realistic, Developer-Informed Benchmark for Code Generation Models","Pareesa Ameneh Golnari, Adarsh Kumarappan, Wen Wen, Xiaoyu Liu, Gabriel Ryan, Yuting Sun, Shengyu Fu, Elsie Nallipogu",,,"code generation, Large Language Models, code completion, developer telemetry, benchmarking, ecological validity, functional correctness, LLM-judge assessments","DevBench is a telemetry-driven benchmark designed to evaluate Large Language Models (LLMs) on realistic code completion tasks. It includes 1,800 evaluation instances across six programming languages and six task categories derived from real developer telemetry, such as API usage and code purpose understanding. Unlike prior benchmarks, it emphasizes ecological validity, avoids training data contamination, and enables detailed diagnostics. The evaluation combines functional correctness, similarity-based metrics, and LLM-judge assessments focused on usefulness and contextual relevance. Nine state-of-the-art models were assessed, revealing differences in syntactic precision, semantic reasoning, and practical utility. The benchmark provides actionable insights to guide model selection and improvement, offering detail that is often missing from other benchmarks but is essential for both practical deployment and targeted model development.",3.29,96.688,318,cold_start,Phi-4,Apple_M1(Metal)
2601.11903v1_AEMA Verifiable Evaluation Framework for Trustwort.pdf,AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems,"Yen-Ting Lee, Keerthi Koneru, Zahra Moslemi, Sheethal Kumar, Ramesh Radhakrishnan",,arXiv:2601.11903v1,"Agentic AI, Multi-Agent Systems, Trustworthy AI, Verifiable Evaluation, Human Oversight","Evaluating large language model (LLM)-based multi-agent systems remains a critical challenge, as these systems must exhibit reliable coordination, transparent decision-making, and verifiable performance across evolving tasks. Existing evaluation approaches often limit themselves to single-response scoring or narrow benchmarks, which lack stability, extensibility, and automation when deployed in enterprise settings at multi-agent scale. We present AEMA (Adaptive Evaluation Multi-Agent), a process-aware and auditable framework that plans, executes, and aggregates multi-step evaluations across heterogeneous agentic workflows under human oversight. Compared to a single LLM-as-a-Judge, AEMA achieves greater stability, human alignment, and traceable records that support accountable automation. Our results on enterprise-style agent workflows simulated using realistic business scenarios demonstrate that AEMA provides a transparent and reproducible pathway toward responsible evaluation of LLM-based multi-agent systems.",3.42,92.151,315,cold_start,Phi-4,Apple_M1(Metal)
2601.11905v1_LIBRA Language Model Informed Bandit Recourse Algo.pdf,LIBRA: Language Model Informed Bandit Recourse Algorithm for Personalized Treatment Planning,"Junyu Cao, Ruijiang Gao, Esmaeil Keyvanshokooh, Jianhao Ma",,,"Large Language Models, LLM-Bandits Collaboration, Algorithmic Recourse, Regret Analysis, Personalized Treatment Planning, Hypertension Management","This paper introduces a unified framework integrating algorithmic recourse, contextual bandits, and large language models (LLMs) to support sequential decision-making in high-stakes settings like personalized medicine. The authors propose the Generalized Linear Recourse Bandit (GLRB) algorithm and the Language Model–Informed Bandit Recourse Algorithm (LIBRA). LIBRA combines domain knowledge from LLMs with bandit learning, offering guarantees for warm-start, LLM-effort, and robustness. The paper establishes matching lower bounds for the recourse bandit problem and demonstrates the near-optimality of the algorithms through experiments. Results show improvements in regret, treatment quality, and sample efficiency over standard contextual bandits and LLM-only benchmarks, highlighting the potential of LLM-assisted bandit algorithms in personalized high-stakes decision-making.",3.3,90.66,299,cold_start,Phi-4,Apple_M1(Metal)
2601.11907v1_Towards Airborne Object Detection A Deep Learning .pdf,Towards Airborne Object Detection: A Deep Learning Analysis,"Prosenjit Chatterjee, ANK Zaman",,,"Airborne Object Detection, Threat Detection, Deep Learning, EfficientNetB4, ResNet-50, UA V","The rapid proliferation of airborne platforms—including commercial aircraft, drones, and UAVs—has intensified the need for real-time, automated threat assessment systems. Current approaches depend heavily on manual monitoring, resulting in limited scalability and operational inefficiencies. This work introduces a dual-task model based on EfficientNetB4 capable of performing airborne object classification and threat-level prediction simultaneously. To address the scarcity of clean, balanced training data, the AODTA Dataset was constructed by aggregating and refining multiple public sources. The model achieved 96% accuracy in object classification and 90% accuracy in threat-level prediction, outperforming a ResNet-50 baseline. The study focuses on classification and threat-level inference using pre-localized airborne object images, complementing existing object detection pipelines.",3.17,80.007,254,cold_start,Phi-4,Apple_M1(Metal)
2601.11913v1_LSTM-MAS A Long Short-Term Memory Inspired Multi-A.pdf,LSTM-MAS: A Long Short-Term Memory Inspired Multi-Agent System for Long-Context Understanding,"Yichen Jiang, Peng Ye, Jiakang Yuan, Chongjun Tu, Lei Bai, Tao Chen",,,"Long-Context Understanding, Large Language Models, Multi-Agent System, Memory","Effectively processing long contexts remains a fundamental yet unsolved challenge for large language models (LLMs). Existing single-LLM-based methods primarily reduce the context window or optimize the attention mechanism, but they often encounter additional computational costs or constrained expanded context length. While multi-agent-based frameworks can mitigate these limitations, they remain susceptible to the accumulation of errors and the propagation of hallucinations. In this work, we draw inspiration from the Long Short-Term Memory (LSTM) architecture to design a Multi-Agent System called LSTM-MAS, emulating LSTM’s hierarchical information flow and gated memory mechanisms for long-context understanding. Specifically, LSTM-MAS organizes agents in a chained architecture, where each node comprises a worker agent for segment-level comprehension, a filter agent for redundancy reduction, a judge agent for continuous error detection, and a manager agent for globally regulating information propagation and retention, analogous to LSTM and its input gate, forget gate, constant error carousel unit, and output gate. These novel designs enable controlled information transfer and selective long-term dependency modeling across textual segments, which can effectively avoid error accumulation and hallucination propagation. We conducted an extensive evaluation of our method. Compared with the previous best multi-agent approach, CoA, our model achieves improvements of 40.93%, 43.70%, 121.57%, and 33.12%, on NarrativeQA, Qasper, HotpotQA, and MuSiQue, respectively.",3.53,115.562,408,cold_start,Phi-4,Apple_M1(Metal)
2601.11920v1_Enhancing LLM-Based Data Annotation with Error Dec.pdf,Enhancing LLM-Based Data Annotation with Error Decomposition,"Zhen Xu, Vedant Khatri, Yijun Dai, Xiner Liu, Siyan Li, Xuanming Zhang, Renzhe Yu",,,"Data Annotation, Qualitative Coding, Large Language Models, Human-AI Collaboration","Large language models (LLMs) offer a scalable alternative to human coding for data annotation tasks, enabling the scale-up of research across data-intensive domains such as learning analytics. While LLMs are already achieving near-human accuracy on objective annotation tasks, their performance on subjective annotation tasks, such as those involving psychological constructs, is less consistent and more prone to errors. Standard evaluation practices typically collapse all annotation errors into a single alignment metric, but this simplified approach may obscure different kinds of errors that affect final analytical conclusions in different ways. Here, we propose a diagnostic evaluation paradigm that incorporates a human-in-the-loop step to separate task-inherent ambiguity from model-driven inaccuracies and assess annotation quality in terms of their potential downstream impacts. We refine this paradigm on ordinal annotation tasks, which are common in subjective annotation. The refined paradigm includes: (1) a diagnostic taxonomy that categorizes LLM annotation errors along two dimensions: source (model-specific vs. task-inherent) and type (boundary ambiguity vs. conceptual misidentification); (2) a lightweight human annotation test to estimate task-inherent ambiguity from LLM annotations; and (3) a computational method to decompose observed LLM annotation errors following our taxonomy. We validate this paradigm on four educational annotation tasks, demonstrating both its conceptual validity and practical utility. Theoretically, our work provides empirical evidence for why excessively high alignment is unrealistic in specific annotation tasks and why single alignment metrics inadequately reflect the quality of LLM annotations. In practice, our paradigm can be a low-cost diagnostic tool that assesses the suitability of a given task for LLM annotation and provides actionable insights for further technical optimization.",3.59,125.6,451,cold_start,Phi-4,Apple_M1(Metal)
2601.11935v1_Big Data Workload Profiling for Energy-Aware Cloud.pdf,Big Data Workload Profiling for Energy-Aware Cloud Resource Management,"Milan Parikh, Aniket Abhishek Soni, Sneja Mitinbhai Shah, Ayush Raj Jha",,arXiv:2601.11935v1,"Cloud computing, energy-aware scheduling, workload profiling, virtual machine placement, big data, green computing","Cloud data centers face increasing pressure to reduce operational energy consumption as big data workloads continue to grow in scale and complexity. This paper presents a workload-aware scheduling framework that uses profiling of CPU usage, memory demand, and storage I/O behavior to guide energy-efficient virtual machine (VM) placement. By combining historical execution logs with real-time telemetry, the system predicts the energy and performance impact of candidate placement decisions and adaptively consolidates workloads without violating service-level agreements (SLAs). The framework was evaluated using representative Hadoop MapReduce, Spark MLlib, and ETL workloads on a multi-node cloud testbed. Experimental results demonstrate a consistent reduction of 15–20% in energy consumption while maintaining SLA compliance. These findings highlight the effectiveness of data-driven workload profiling as a practical strategy for improving the sustainability of cloud computing environments.",3.35,90.233,302,cold_start,Phi-4,Apple_M1(Metal)
2601.11940v1_Thinking Traps in Long Chain-of-Thought A Measurab.pdf,Thinking Traps in Long Chain-of-Thought: A Measurable Study and Trap-Aware Adaptive Restart,"Kang Chen, Fan Yu, Junjie Nian, Shihan Zhao, Zhuoka Feng, Zijun Yao, Heng Wang, Minshen Yu, Yixin Cao",,arXiv:2601.11940v1,"Long Chain-of-Thought, reasoning capabilities, fine-grained trajectory analysis, Thinking Traps, Trap-Aware Adaptive Restart (TAAR), mathematical reasoning, scientific reasoning","Scaling test-time compute via Long Chain-of-Thought (Long-CoT) enhances reasoning capabilities, but extended generation does not guarantee correctness. Models may elaborate on an incorrect prefix after an early wrong commitment. The study identifies 'Thinking Traps' as prefix-dominant deadlocks where later reflection or verification fails to correct the root error. The paper introduces TAAR, a framework that predicts where to truncate and whether to intervene in the reasoning process. Experiments show TAAR improves reasoning performance on benchmarks without fine-tuning base model parameters.",3.4,84.367,287,cold_start,Phi-4,Apple_M1(Metal)
2601.11956v1_Double-Calibration Towards Trustworthy LLMs via Ca.pdf,Double-Calibration: Towards Trustworthy LLMs via Calibrating Knowledge and Reasoning Confidence,"Yuyin Lu, Ziran Liang, Yanghui Rao, Wenqi Fan, Fu Lee Wang, Qing Li",,,"Large Language Models, Knowledge Graphs, Uncertainty Quantification, Confidence Calibration, Retrieval-Augmented Generation","Trustworthy reasoning in Large Language Models (LLMs) is challenged by their propensity for hallucination. While augmenting LLMs with Knowledge Graphs (KGs) improves factual accuracy, existing KG-augmented methods fail to quantify epistemic uncertainty in both the retrieved evidence and LLMs’ reasoning. To bridge this gap, we introduce DoublyCal, a framework built on a novel double-calibration principle. DoublyCal employs a lightweight proxy model to first generate KG evidence alongside a calibrated evidence confidence. This calibrated supporting evidence then guides a black-box LLM, yielding final predictions that are not only more accurate but also well-calibrated, with confidence scores traceable to the uncertainty of the supporting evidence. Experiments on knowledge-intensive benchmarks show that DoublyCal significantly improves both the accuracy and confidence calibration of black-box LLMs with low token cost.",3.25,94.211,306,cold_start,Phi-4,Apple_M1(Metal)
2601.11960v1_R2PO Decoupling Training Trajectories from Inferen.pdf,R2PO: Decoupling Training Trajectories from Inference Responses for LLM Reasoning,"Jingchu Wang, Bingbing Xu, Yige Yuan, Bin Xie, Xiaoqian Sun, Huawei Shen",,,"Reinforcement Learning, Large Language Models, LLM Reasoning, Policy Optimization, Training Trajectories, Inference Responses","Reinforcement learning has become a central paradigm for improving LLM reasoning. Existing methods use a single policy to produce both inference responses and training optimization trajectories, leading to insufficient exploration due to objective conflict. This paper introduces R2PO (Residual Rollout Policy Optimization), which decouples training trajectories from inference responses using a lightweight Residual Rollout-Head. This enables controlled trajectory diversification during training while maintaining stable inference generation. Experiments show R2PO outperforms baselines, achieving accuracy gains on benchmarks like MATH-500 and APPS, and reducing formatting errors and length bias.",3.07,82.93,255,cold_start,Phi-4,Apple_M1(Metal)
2601.11969v1_textttMemoryRewardBench Benchmarking Reward Models.pdf,MemoryRewardBench: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models,"Zecheng Tang, Baibei Ji, Ruoxi Sun, Haitian Wang, Wangjie You, Yijun Zhang, Wenpeng Zhu, Ji Qi, Juntao Li, Min Zhang",,,"memory management, large language models, reward models, long-term memory, segmented processing, holistic processing","This work introduces MemRewardBench, the first benchmark to systematically study the ability of reward models (RMs) to evaluate long-term memory management processes in large language models (LLMs). The benchmark covers long-context comprehension and long-form generation tasks with context lengths ranging from 8K to 128K tokens. Evaluations on 13 cutting-edge RMs show a diminishing performance gap between open-source and proprietary models, with newer-generation models consistently outperforming their predecessors. The study also exposes the capabilities and fundamental limitations of current RMs in evaluating LLM memory management across diverse settings.",3.17,87.37,277,cold_start,Phi-4,Apple_M1(Metal)
2601.11974v1_Learn Like Humans Use Meta-cognitive Reflection fo.pdf,Learn Like Humans: Use Meta-cognitive Reflection for Efficient Self-Improvement,"Xinmeng Hou, Peiliang Gong, Bohao Qu, Wuqi Wang, Qing Guo, Yang Liu",,,"Large Language Models, self-improvement, meta-cognitive reflection, machine learning, computational efficiency","While Large Language Models (LLMs) enable complex autonomous behavior, current agents are limited by static, human-designed prompts that restrict adaptability. Existing self-improving frameworks often rely on inefficient, multi-turn recursive loops with high computational costs. This paper proposes Metacognitive Agent Reflective Self-improvement (MARS), a framework that achieves efficient self-evolution within a single recurrence cycle. Inspired by educational psychology, MARS mimics human learning by integrating principle-based reflection (abstracting normative rules to avoid errors) and procedural reflection (deriving step-by-step strategies for success). By synthesizing these insights into optimized instructions, MARS allows agents to systematically refine their reasoning logic without continuous online feedback. Extensive experiments on six benchmarks demonstrate that MARS outperforms state-of-the-art self-evolving systems while significantly reducing computational overhead.",3.21,91.969,295,cold_start,Phi-4,Apple_M1(Metal)
2601.11977v1_One-Shot Price Forecasting with Covariate-Guided E.pdf,One-Shot Price Forecasting with Covariate-Guided Experts under Privacy Constraints,"He, Ren, Xu, Yinliang, Wang, Jinfeng, Watson, Jeremy, Song, Jian",,,"Price forecasting, Time Series, Privacy, Mixture of Experts, market analysis","Forecasting in power systems often involves multi-variate time series with complex dependencies and strict privacy constraints across regions. Traditional forecasting methods require significant expert knowledge and struggle to generalize across diverse deployment scenarios. Recent advancements in pre-trained time series models offer new opportunities, but their zero-shot performance on domain-specific tasks remains limited. To address these challenges, we propose a novel MoE-Encoder module that augments pre-trained forecasting models by injecting a sparse mixture-of-experts layer between tokenization and encoding. This design enables two key capabilities: (1) transforming multivariate forecasting into an expert-guided univariate task, allowing the model to effectively capture inter-variable relations, and (2) supporting localized training and lightweight parameter sharing in federated settings where raw data cannot be exchanged. Extensive experiments on public multivariate datasets demonstrate that MoE-Encoder significantly improves forecasting accuracy compared to strong baselines. We further simulate federated environments and show that transferring only MoE-Encoder parameters allows efficient adaptation to new regions, with minimal performance degradation. Our findings suggest that MoE-Encoder provides a scalable and privacy-aware extension to foundation time series models.",3.44,100.006,344,cold_start,Phi-4,Apple_M1(Metal)
2601.11979v1_Process In-Context Learning Enhancing Mathematical.pdf,Process In-Context Learning: Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion,"Ang Gao, Changshuo Zhang, Xiao Zhang, Deyang Li, Minjun Zhao, Fangchao Liu, Xinyu Zhang",,,"In-context learning, Mathematical reasoning, Dynamic demonstration, Large language models, Adaptive demonstration insertion","In-context learning (ICL) has shown effectiveness across various tasks for large language models (LLMs), but its potential for enhancing step-by-step logical deduction tasks like mathematical reasoning is underexplored. A key limitation is the static use of demonstrations, which are pre-selected and remain unchanged during inference, failing to adapt to dynamic confusion points that arise in multi-step reasoning. This can lead to cascading errors and reduced accuracy. To address this, the authors propose Process In-Context Learning (PICL), a dynamic demonstration integration framework that enhances mathematical reasoning by responding to real-time inference needs. PICL operates in two stages: identifying potential confusion points by analyzing semantics and entropy, and retrieving relevant demonstrations to guide subsequent steps. Experiments show that PICL outperforms baseline methods by mitigating mid-inference confusion, highlighting the value of adaptive demonstration insertion in complex mathematical reasoning.",3.3,93.887,310,cold_start,Phi-4,Apple_M1(Metal)
2601.11995v1_Learning Audio-Visual Embeddings with Inferred Lat.pdf,Learning Audio–Visual Embeddings with Inferred Latent Interaction Graphs,"Donghuo Zeng, Hao Niu, Yanan Wang, Masato Taya",,2601.11995v1,"Audio–visual, latent interaction graph, cross-modal retrieval, soft labels","Learning robust audio–visual embeddings requires bringing genuinely related audio and visual signals together while filtering out incidental co-occurrences—background noise, unrelated elements, or unannotated events. Most contrastive and triplet-loss methods use sparse annotated labels per clip and treat any co-occurrence as semantic similarity. We propose a framework that leverages soft-label predictions and inferred latent interactions to address these issues: (1) Audio–Visual Semantic Alignment Loss (AV-SAL) trains a teacher network to produce aligned soft-label distributions across modalities, assigning nonzero probability to co-occurring but unannotated events and enriching the supervision signal. (2) Inferred Latent Interaction Graph (ILI) applies the GRaSP algorithm to teacher soft labels to infer a sparse, directed dependency graph among classes. This graph highlights directional dependencies that expose likely semantic or conditional relationships between classes; these are interpreted as estimated dependency patterns. (3) Latent Interaction Regularizer (LIR): A student network is trained with both metric loss and a regularizer guided by the ILI graph, pulling together embeddings of dependency-linked but unlabeled pairs in proportion to their soft-label probabilities. Experiments on AVE and VEGAS benchmarks show consistent improvements in mean average precision (MAP), demonstrating that integrating inferred latent interactions into embedding learning enhances robustness and semantic coherence.",3.72,102.798,382,cold_start,Phi-4,Apple_M1(Metal)
2601.11998v1_Hybrid IDS Using Signature-Based and Anomaly-Based.pdf,Hybrid IDS Using Signature-Based and Anomaly-Based Detection,"Messaouda Boutassetta, Amina Makhlouf, Newfel Messaoudi, Abdelmadjid Benmachiche, Ines Boutabia",,,"Intrusion Detection System (IDS), Hybrid IDS, Signature-Based Detection, Anomaly-Based Detection, Machine Learning (ML), Cybersecurity, False Positives, Detection Accuracy, Real-Time Detection, Network Security","Intrusion detection systems (IDS) are essential for protecting computer systems and networks against a wide range of evolving cyber threats. IDS are categorized into signature-based and anomaly-based types, each with strengths and limitations. This paper presents a comprehensive survey and conceptual overview of Hybrid IDS, which integrate both detection techniques to enhance attack detection capabilities. The survey examines recent research on Hybrid IDS, classifies existing models into functional categories, and discusses their advantages, limitations, and application domains, including financial systems, air traffic control, and social networks. Recent trends in Hybrid IDS research, such as machine learning-based approaches and cloud-based deployments, are reviewed. The paper outlines potential future research directions aimed at developing more cost-effective Hybrid IDS solutions with improved ability to detect emerging and sophisticated cyberattacks.",3.29,95.327,314,cold_start,Phi-4,Apple_M1(Metal)
2601.12002v1_Kernel-Based Learning of Safety Barriers.pdf,Kernel-Based Learning of Safety Barriers,"Oliver Schöno, Zhengang Zhong, Sadegh Soudjani",,arXiv:2601.12002v1,"AI, safety verification, control barrier certificates, black-box systems, stochastic dynamics, reproducing kernel Hilbert space, temporal logic specifications, safety barriers, finite Fourier expansion, linear program, spectral barrier, fast Fourier transform, distributionally robust framework","The rapid integration of AI algorithms in safety-critical applications such as autonomous driving and healthcare is raising significant concerns about meeting stringent safety standards. Traditional tools for formal safety verification struggle with the black-box nature of AI-driven systems and lack the flexibility needed to scale to the complexity of real-world applications. This paper presents a data-driven approach for safety verification and synthesis of black-box systems with discrete-time stochastic dynamics. It employs control barrier certificates to guarantee system safety and learns the certificate directly from system trajectories. The approach uses conditional mean embeddings to embed data into a reproducing kernel Hilbert space (RKHS) and constructs an RKHS ambiguity set that can be inflated to robustify the result to out-of-distribution behavior. Theoretical results are provided for applying the approach to general classes of temporal logic specifications beyond safety. For data-driven computation of safety barriers, a finite Fourier expansion is leveraged to cast a typically intractable semi-infinite optimization problem as a linear program. The resulting spectral barrier allows leveraging the fast Fourier transform to generate the relaxed problem efficiently, offering a scalable yet distributionally robust framework for verifying safety. The work moves beyond restrictive assumptions on system dynamics and uncertainty, as demonstrated on two case studies including a black-box system with a neural network controller.",3.62,114.793,416,cold_start,Phi-4,Apple_M1(Metal)
2601.12003v1_Robust Verification of Concurrent Stochastic Games.pdf,Robust Verification of Concurrent Stochastic Games,"Angel Y. He, David Parker",,arXiv:2601.12003v1,"Robust quantitative verification, Probabilistic model checking, Concurrent stochastic games, Epistemic uncertainty","Autonomous systems often operate in multi-agent settings and need to make concurrent, strategic decisions, typically in uncertain environments. Verification and control problems for these systems can be tackled with concurrent stochastic games (CSGs), but this model requires transition probabilities to be precisely specified — an unrealistic requirement in many real-world settings. We introduce robust CSGs and their subclass interval CSGs (ICSGs), which capture epistemic uncertainty about transition probabilities in CSGs. We propose a novel framework for robust verification of these models under worst-case assumptions about transition uncertainty. Specifically, we develop the underlying theoretical foundations and efficient algorithms, for finite- and infinite-horizon objectives in both zero-sum and nonzero-sum settings, the latter based on (social-welfare optimal) Nash equilibria. We build an implementation in the PRISM-games model checker and demonstrate the feasibility of robust verification of ICSGs across a selection of large benchmarks.",3.49,82.13,287,cold_start,Phi-4,Apple_M1(Metal)
2601.12014v1_Are LLMs Ready for TOON Benchmarking Structural Co.pdf,Are LLMs Ready for TOON? Benchmarking Structural Correctness–Sustainability Trade-offs in Novel Structured Output Formats,"Elio Masciari, Vincenzo Moscato, Enea Vincenzo Napolitano, Gian Marco Orlando, Marco Perillo, Diego Russo",https://doi.org/XXXXXXX.XXXXXXX,,"Green AI, TOON, Large Language Models, Natural Language Processing, Sustainability","Large Language Models (LLMs) are increasingly required to generate structured, machine-readable outputs for downstream systems. While recent benchmarks have focused on evaluating the structural correctness of such outputs, the environmental impact of inference for different output formats has largely been overlooked. This paper introduces a sustainability-aware evaluation framework for structured generation that measures token usage, generation time, and estimated carbon emissions. The Environment-Aware Generation Correctness Score (GCSenv) is proposed as a unified metric integrating structural correctness with carbon-aware efficiency. The novel TOON format is benchmarked against established representations (JSON, XML, YAML) across multiple LLMs. Results reveal a trade-off: TOON yields more compact outputs and lower emissions but lower structural correctness when models lack native support. Increased model capacity reduces this gap, and environment-aware scoring can shift format rankings depending on deployment priorities, highlighting the need for sustainability-inclusive benchmarking.",3.33,99.362,331,cold_start,Phi-4,Apple_M1(Metal)
2601.12019v1_Acting Flatterers via LLMs Sycophancy Combating Cl.pdf,Acting Flatterers via LLMs Sycophancy: Combating Clickbait with LLMs Opposing-Stance Reasoning,"Chaowei Zhang, Xiansheng Luo, Zewei Zhang, Yi Zhu, Jipeng Qiang, Longwei Wang",https://doi.org/10.1145/XXXXXX.XXXXXX,,"Clickbait Detection, Large Language Models, Opposing Stance Reasoning, Contrastive Learning","The widespread proliferation of online content has intensified concerns about clickbait—deceptive or exaggerated headlines designed to attract attention. While Large Language Models (LLMs) offer a promising avenue for addressing this issue, their effectiveness is often hindered by Sycophancy, a tendency to produce reasoning that matches users’ beliefs over truthful ones, which deviates from instruction-following principles. Rather than treating sycophancy as a flaw to be eliminated, this work proposes a novel approach that initially harnesses this behavior to generate contrastive reasoning from opposing perspectives. Specifically, we design a Self-renewal Opposing-stance Reasoning Generation (SORG) framework that prompts LLMs to produce high-quality 'agree' and 'disagree' reasoning pairs for a given news title without requiring ground-truth labels. To utilize the generated reasoning, we develop a local Opposing Reasoning-based Clickbait Detection (ORCD) model that integrates three BERT encoders to represent the title and its associated reasoning. The model leverages contrastive learning, guided by soft labels derived from LLM-generated credibility scores, to enhance detection robustness. Experimental evaluations on three benchmark datasets demonstrate that our method consistently outperforms LLM prompting, fine-tuned smaller language models, and state-of-the-art clickbait detection baselines.",3.38,124.466,421,cold_start,Phi-4,Apple_M1(Metal)
2601.12024v1_A Multi-Agent System for Generating Actionable Bus.pdf,A Multi-Agent System for Generating Actionable Business Advice,"Kartikey Singh Bhandari, Tanish Jain, Archit Agrawal, Dhruv Kumar, Praveen Kumar, Pratik Narang",,,"customer reviews, large language models, multi-agent system, business advice, prescriptive decision support","Customer reviews contain rich signals about product weaknesses and unmet user needs, yet existing analytic methods rarely move beyond descriptive tasks such as sentiment analysis or aspect extraction. This paper presents a multi-agent, LLM-based framework for prescriptive decision support, transforming large-scale review corpora into actionable business advice. The framework integrates clustering, generation of advices, iterative evaluation, and feasibility-based ranking, producing specific, actionable, and practical outputs. Experiments across three service domains show that the framework consistently outperforms single model baselines on actionability, specificity, and non-redundancy, with medium-sized models approaching the performance of large model frameworks.",3.0,76.624,230,cold_start,Phi-4,Apple_M1(Metal)
2601.12030v1_ARC Active and Reflection-driven Context Managemen.pdf,Active and Reflection-driven Context Management for Long-Horizon Information Seeking Agents,"Yilun Yao, Shan Huang, Elsie Dai, Zhewen Tan, Zhenyu Duan, Shousheng Jia, Yanbing Jiang, Tong Yang",,,"context management, long-horizon information seeking, large language models, context rot, reflection-driven process","Large language models are increasingly used as research agents for deep search and long-horizon information seeking. However, their performance often degrades as interaction histories grow, a phenomenon known as context rot. Existing approaches manage context through raw accumulation or passive summarization, which can allow early errors to persist. This paper proposes ARC, a framework that treats context as a dynamic internal reasoning state, using reflection-driven monitoring and revision to actively reorganize working context when misalignment or degradation is detected. Experiments show that ARC outperforms passive context compression methods, achieving up to an 11% absolute improvement in accuracy on BrowseComp-ZH with Qwen2.5-32B-Instruct.",3.22,86.633,279,cold_start,Phi-4,Apple_M1(Metal)
2601.12038v1_Abstract Argumentation with Subargument Relations.pdf,Abstract Argumentation with Subargument Relations,Beishui Liao,,,"abstract argumentation, subargument relations, attack relation, structured argumentation, Dung’s framework","Dung’s abstract argumentation framework characterizes argument acceptability solely via an attack relation, abstracting from the internal structure of arguments. This abstraction limits the representation of structural dependencies central in many structured argumentation formalisms, particularly subargument relations. Existing extensions, such as bipolar argumentation frameworks, introduce support relations but do not capture the asymmetric and constitutive nature of subarguments or their interaction with attacks. This paper studies abstract argumentation frameworks enriched with an explicit subargument relation, treated alongside attack as a basic relation. It analyzes how subargument relations interact with attacks and examines their impact on fundamental semantic properties. The framework provides a principled abstraction of structural information and clarifies the role of subarguments in abstract acceptability reasoning.",3.09,68.263,211,cold_start,Phi-4,Apple_M1(Metal)
2601.12040v1_Partial Reasoning in Language Models Search and Re.pdf,Partial Reasoning in Language Models: Search and Refinement Guided by Uncertainty,"Murilo da Luz, Bruno Brandão, Luana Martins, Gustavo Oliveira, Bryan de Oliveira, Luckeciano Melo, Telma Soares",,,"Uncertainty, Entropy, Latent-space search, Soft Reasoning, LLM reasoning","The use of Large Language Models (LLMs) for reasoning and planning tasks has drawn increasing attention in Artificial Intelligence research. Despite their remarkable progress, these models still exhibit limitations in multi-step inference scenarios, particularly in mathematical and logical reasoning. We introduce PREGU (Partial Reasoning Guided by Uncertainty). PREGU monitors the entropy of the output distribution during autoregressive generation and halts the process whenever entropy exceeds a defined threshold, signaling uncertainty. From that point, a localized search is performed in the latent space to refine the partial reasoning and select the most coherent answer, using the Soft Reasoning method. Experiments conducted with LLaMA-3-8B, Mistral-7B, and Qwen2-7B across four reasoning benchmarks (GSM8K, GSM-Hard, SVAMP, and StrategyQA) showed performance greater than or similar to Soft Reasoning, indicating that entropy can serve as an effective signal to trigger selective refinement during reasoning.",3.33,99.186,330,cold_start,Phi-4,Apple_M1(Metal)
2601.12042v1_Less Is More -- Until It Breaks Security Pitfalls .pdf,Less Is More — Until It Breaks: Security Pitfalls of Vision Token Compression in Large Vision-Language Models,"Xiaomei Zhang, Zhaoxi Zhang, Leo Yu Zhang, Yanjun Zhang, Guanhong Tao, Shirui Pan",https://doi.org/XXXXXXX.XXXXXXX,,"Large Vision-Language Models, visual token compression, security, robustness, compression-aware attack, model vulnerability","Visual token compression is widely adopted to improve the inference efficiency of Large Vision-Language Models (LVLMs), enabling their deployment in latency-sensitive and resource-constrained scenarios. However, existing work has mainly focused on efficiency and performance, while the security implications of visual token compression remain largely unexplored. This work reveals that visual token compression substantially degrades the robustness of LVLMs, making them highly vulnerable once compression is enabled. These vulnerabilities are state-specific and difficult to diagnose. Instability in token importance ranking is identified as the primary cause of robustness degradation. Small perturbations can alter token rankings, leading to the discarding of task-critical information and model failure. A Compression-Aware Attack (CAA) is proposed to study and exploit this vulnerability, inducing failures exclusively under compressed inference. Transfer CAA (T-CAA) extends this approach to black-box settings. Experimental results show that compression-induced security risks persist even under practical settings. Potential defenses provide limited protection. Extensive experiments demonstrate that visual token compression significantly undermines model robustness, exposing a trade-off between efficiency and security.",3.46,105.955,367,cold_start,Phi-4,Apple_M1(Metal)
2601.12049v1_textitFocaLogic Logic-Based Interpretation of Visu.pdf,FocaLogic: Logic-Based Interpretation of Visual Model Decisions,"Chenchen Zhao, Muxi Chen, Qiang Xu",,,"interpretability, visual models, logic-based representations, model-agnostic, quantitative metrics, focus precision, recall, divergence, training-induced concentration, generalization, biases, adversarial attacks","Interpretability of modern visual models is crucial, particularly in high-stakes applications. Existing interpretability methods often rely on white-box model access or lack quantitative rigor. FocaLogic is a novel model-agnostic framework designed to interpret and quantify visual model decision-making through logic-based representations. It identifies minimal interpretable subsets of visual regions, termed visual focuses, that decisively influence model predictions. These visual focuses are translated into precise logical expressions, enabling transparent and structured interpretations. FocaLogic also proposes quantitative metrics, including focus precision, recall, and divergence, to objectively evaluate model behavior. Empirical analyses demonstrate FocaLogic’s capability to uncover critical insights such as training-induced concentration, increasing focus accuracy through generalization, and anomalous focuses under biases and adversarial attacks. Overall, FocaLogic provides a systematic, scalable, and quantitative solution for interpreting visual models.",3.38,92.14,311,cold_start,Phi-4,Apple_M1(Metal)
2601.12053v1_A New Strategy for Artificial Intelligence Trainin.pdf,A New Strategy for Artificial Intelligence: Training Foundation Models Directly on Human Brain Data,Maël Donoso,,2601.12053v1,"foundation models, brain, neuroimaging, brain-generated data, brain-trained foundation models, reinforcement learning from human brain (RLHB), chain of thought from human brain (CoTHB)","While foundation models have achieved remarkable results across a diversity of domains, they still rely on human-generated data, such as text, as a fundamental source of knowledge. However, this data is ultimately the product of human brains, the filtered projection of a deeper neural complexity. This paper explores a new strategy for artificial intelligence: training foundation models directly on human brain data. It hypothesizes that neuroimaging data could provide insights into elements of human cognition not accessible through observable actions, potentially overcoming some current limitations of foundation models. The paper classifies the current limitations of foundation models and identifies promising brain regions and cognitive processes that could be leveraged to address them. Two methods, reinforcement learning from human brain (RLHB) and chain of thought from human brain (CoTHB), are proposed to prioritize the use of limited neuroimaging data for high-value steps in foundation model training. The paper also discusses the potential implications for agents, artificial general intelligence, and artificial superintelligence, as well as the ethical, social, and technical challenges and opportunities. It argues that brain-trained foundation models could represent a realistic and effective middle ground between scaling current architectures and exploring alternative, neuroscience-inspired solutions. Future discoveries in cognitive and computational neuroscience could make this strategy increasingly relevant over time.",3.55,106.322,377,cold_start,Phi-4,Apple_M1(Metal)
2601.12055v1_Automating Parameter Selection in Deep Image Prior.pdf,Automating Parameter Selection in Deep Image Prior for Fluorescence Microscopy Image Denoising via Similarity-Based Parameter Transfer,"Lina Meyer, Felix Wissel, Tobias Knopp, Susanne Pfefferle, Ralf Fliegert, Maximilian Sandmann, Liana Uebler, Franziska Möckl, Björn-Philipp Diercks, David Lohr, René Werner",,,"fluorescence microscopy, denoising, deep image prior, automatic parameter selection","Unsupervised deep image prior (DIP) addresses shortcomings of training data requirements and limited generalization associated with supervised deep learning. The performance of DIP depends on the network architecture and the stopping point of its iterative process. Optimizing these parameters for a new image requires time, restricting DIP application in domains where many images need to be processed. Focusing on fluorescence microscopy data, this study hypothesizes that similar images share comparable optimal parameter configurations for DIP-based denoising, potentially enabling optimization-free DIP for fluorescence microscopy. A calibration and validation set were generated from an open-source dataset for network architecture search towards ideal U-net architectures and stopping points. The study implemented AUTO-DIP, a pipeline for automatic parameter transfer, and compared it to the originally published DIP configuration and a state-of-the-art image-specific variational denoising approach. Results show that parameter transfer based on image metadata similarity leads to better performance than quantitative image similarity measures. AUTO-DIP outperforms the baseline DIP and variational denoising approaches for several open-source test datasets, particularly for very noisy inputs. Applications to locally acquired fluorescence microscopy images further proved the superiority of AUTO-DIP, improving DIP-based denoising speed and quality, enabling routine applications in fluorescence microscopy imaging.",3.59,123.988,445,cold_start,Phi-4,Apple_M1(Metal)
2601.12061v1_Codebook-Injected Dialogue Segmentation for Multi-.pdf,Codebook-Injected Dialogue Segmentation for Multi-Utterance Constructs,"Jinsook Lee, Kirk Vanacore, Zhuqian Zhou, Bakhtawar Ahtisham, Jeanine Grütter, René F. Kizilcec",,,"Dialogue Act annotation, segmentation, LLM-based segmenters, evaluation metrics, human-AI agreement","The paper discusses the challenges in Dialogue Act (DA) annotation, particularly the issue of boundary-driven disagreement among annotators. It proposes a method called codebook-injected segmentation to condition boundary decisions on downstream annotation criteria. The paper evaluates LLM-based segmenters against standard and retrieval-augmented baselines using new evaluation metrics for span consistency, distinctiveness, and human-AI distributional agreement. Results indicate that DA-awareness improves internal consistency of segments, but no single segmenter excels across all metrics. The study highlights the importance of optimizing segmentation for downstream objectives rather than a single performance score.",3.14,82.579,259,cold_start,Phi-4,Apple_M1(Metal)
2601.12068v1_Bridging the Gap in Bangla Healthcare Machine Lear.pdf,Bridging the Gap in Bangla Healthcare: Machine Learning Based Disease Prediction Using a Symptoms-Disease Dataset,"Rowzatul Zannat, Abdullah Al Shafi, Abdul Muntakim",,,"Disease Prediction, Annotated Dataset, Machine Learning Techniques, Soft Voting Ensemble, Hard Voting Ensemble","Increased access to reliable health information is essential for non-English-speaking populations, yet resources in Bangla for disease prediction remain limited. This study addresses this gap by developing a comprehensive Bangla symptoms-disease dataset containing 758 unique symptom-disease relationships spanning 85 diseases. The dataset enables the prediction of diseases based on Bangla symptom inputs, supporting healthcare accessibility for Bengali-speaking populations. Using this dataset, multiple machine learning models were evaluated to predict diseases based on symptoms provided in Bangla, achieving 98% accuracy with both soft and hard voting ensemble approaches. This work establishes a foundational resource for disease prediction in Bangla, enhancing equitable access to health information for Bangla-speaking communities.",3.19,80.154,256,cold_start,Phi-4,Apple_M1(Metal)
2601.12082v1_Conditional Random Fields for Interactive Refineme.pdf,CONDITIONAL RANDOM FIELDS FOR INTERACTIVE REFINEMENT OF HISTOPATHOLOGICAL PREDICTIONS,"Tiffanie Godelaine, Maxime Zanella, Karim El Khoury, Saïd Mahmoudi, Benoït Macq, Christophe De Vleeschouwer",,,"Histology Classification, Conditional Random Fields, Human-In-The-Loop, Foundation Models","Assisting pathologists in the analysis of histopathological images has high clinical value, as it supports cancer detection and staging. This paper introduces HistoCRF, a CRF-based framework designed to refine zero-shot predictions from Vision-Language Models (VLMs) without additional model training. The framework leverages expert annotations and a novel pairwise potential to promote label diversity. Experiments on five patch-level classification datasets demonstrate significant accuracy gains, with further improvements when integrating human-in-the-loop annotations. The code will be made available on GitHub.",2.97,77.232,229,cold_start,Phi-4,Apple_M1(Metal)
2601.12095v1_Neural Isomorphic Fields A Transformer-based Algeb.pdf,Neural Isomorphic Fields: A Transformer-Based Algebraic Numeric Embedding,"Hamidreza Sadeghi, Saeedeh Momtazi, Reza Safabakhsh",,,"Neural Networks, Embeddings, Algebraic Structures, Rational Numbers, Addition, Multiplication, Neural Isomorphic Fields, Transformer, Algebraic Properties","Neural network models often face challenges when processing very small or very large numbers due to issues such as overflow, underflow, and unstable output variations. To mitigate these problems, we propose using embedding vectors for numbers instead of directly using their raw values. These embeddings aim to retain essential algebraic properties while preventing numerical instabilities. In this paper, we introduce, for the first time, a fixed-length number embedding vector that preserves algebraic operations—addition, multiplication, and comparison—within the rational numbers field. We propose a novel Neural Isomorphic Field, a neural abstraction of algebraic structures like groups and fields. The elements of this neural field are embedding vectors that maintain algebraic structure during computations. Our experiments demonstrate that addition performs exceptionally well, achieving over 95% accuracy on key algebraic tests such as identity, closure, and associativity. In contrast, multiplication exhibits challenges, with accuracy ranging between 53% to 73% across various algebraic properties. These findings highlight the model’s strengths in preserving algebraic properties under addition while identifying avenues for further improvement in handling multiplication.",3.41,103.666,354,cold_start,Phi-4,Apple_M1(Metal)
2601.12099v1_Large language models struggle with ethnographic t.pdf,LARGE LANGUAGE MODELS STRUGGLE WITH ETHNOGRAPHIC TEXT ANNOTATION,"Leonardo S. Goodall, Dor Shilton, Daniel Austin Mullins, Harvey Whitehouse",,,"large language models, ethnographic text annotation, cross-cultural research, anthropology","Large language models (LLMs) have shown promise for automated text annotation, raising hopes that they might accelerate cross-cultural research by extracting structured data from ethnographic texts. This study evaluated 7 state-of-the-art LLMs on their ability to annotate 121 ritual features across 567 ethnographic excerpts. Performance was limited, falling well below levels required for reliable automated annotation. Longer texts, features requiring ordinal distinctions, and ambiguous constructs proved particularly difficult. Human inter-coder reliability set an approximate ceiling on LLM accuracy: features that human coders found difficult to agree upon were also difficult for LLMs. Even on features where humans reliably agreed, models fell short of human performance. The findings suggest that LLMs cannot yet substitute for human expertise in ethnographic annotation.",3.21,83.075,267,cold_start,Phi-4,Apple_M1(Metal)
2601.12104v1_Powerful Training-Free Membership Inference Agains.pdf,Powerful Training-Free Membership Inference Against Autoregressive Language Models,"David Ilić, David Stanojević, Kostadin Cvejoski",,,"membership inference attack, language models, privacy risks, fine-tuned models, autoregressive models, error positions, probability shifts, privacy auditing","Fine-tuned language models pose significant privacy risks by potentially memorizing and exposing sensitive information from their training data. Membership inference attacks (MIAs) are used to audit these risks, but existing methods have limited detection rates, especially at low false-positive thresholds. This paper introduces EZ-MIA, a membership inference attack that leverages the observation that memorization is most evident at error positions where the model predicts incorrectly but still assigns high probability to training examples. The Error Zone (EZ) score, a new statistic, measures the imbalance of probability shifts at these error positions relative to a pretrained reference model. EZ-MIA requires only two forward passes per query and no model training. It significantly outperforms previous methods in detection rates, demonstrating that the privacy risks of fine-tuned language models are greater than previously understood. The code is available at https://github.com/JetBrains-Research/ez-mia.",3.26,93.315,304,cold_start,Phi-4,Apple_M1(Metal)
2601.12124v1_SynQP A Framework and Metrics for Evaluating the Q.pdf,SYNQP: A FRAMEWORK AND METRICS FOR EVALUATING THE QUALITY AND PRIVACY RISK OF SYNTHETIC DATA,"Bing Hu, Yixin Li, Asma Bahamyirou, Helen Chen",,,"Real-World Data, Synthetic Data, Privacy Metrics, Evaluation Framework, Membership Inference Attack, Identity Disclosure Risk","The use of synthetic data in health applications raises privacy concerns, yet the lack of open frameworks for privacy evaluations has slowed its adoption. A major challenge is the absence of accessible benchmark datasets for evaluating privacy risks, due to difficulties in acquiring sensitive data. To address this, we introduce SYNQP, an open framework for benchmarking privacy in synthetic data generation (SDG) using simulated sensitive data, ensuring that original data remains confidential. We also highlight the need for privacy metrics that fairly account for the probabilistic nature of machine learning models. As a demonstration, we use SYNQP to benchmark CTGAN and propose a new identity disclosure risk metric that offers a more accurate estimation of privacy risks compared to existing approaches. Our work provides a critical tool for improving the transparency and reliability of privacy evaluations, enabling safer use of synthetic data in health-related applications. Our privacy assessments reveal that DP consistently lowers both identity disclosure risk (SD-IDR) and membership-inference attack risk (SD-MIA), with all DP-augmented models staying below the 0.09 regulatory threshold. Code available at https://github.com/CAN-SYNH/SynQP.",3.49,102.49,358,cold_start,Phi-4,Apple_M1(Metal)
2601.12126v1_UniMo Unified Motion Generation and Understanding .pdf,UniMo: Unified Motion Generation and Understanding with Chain of Thought,"Guocun Wang, Kenkun Liu, Jing Lin, Guorui Song, Jian Li, Xiaoguang Han",,,"3D human motion generation, human motion understanding, large language models, chain of thought reasoning, supervised fine-tuning, reinforcement learning, Group Relative Policy Optimization","Existing 3D human motion generation and understanding methods often exhibit limited interpretability, restricting effective mutual enhancement between these inherently related tasks. While current unified frameworks based on large language models (LLMs) leverage linguistic priors, they frequently encounter challenges in semantic alignment and task coherence. Moreover, the next-token prediction paradigm in LLMs is ill-suited for motion sequences, causing cumulative prediction errors. To address these limitations, we propose UniMo, a novel framework that integrates motion-language information and interpretable chain of thought (CoT) reasoning into the LLM via supervised fine-tuning (SFT). We further introduce reinforcement learning with Group Relative Policy Optimization (GRPO) as a post-training strategy that optimizes over groups of tokens to enforce structural correctness and semantic alignment, mitigating cumulative errors in motion token prediction. Extensive experiments demonstrate that UniMo significantly outperforms existing unified and task-specific models, achieving state-of-the-art performance in both motion generation and understanding.",3.32,101.249,336,cold_start,Phi-4,Apple_M1(Metal)
2601.12132v1_Bengali Text Classification An Evaluation of Large.pdf,Bengali Text Classification: An Evaluation of Large Language Model Approaches,"Md Mahmudul Hoque, Md Mehedi Hassain, Md Hojaifa Tanvir, Rahul Nandy",,arXiv:2601.12132v1,"Bengali Text Classification, Transformer-based Text Classifier, Multilingual NLP, Qwen, LLaMA","Bengali text classification is a significant task in natural language processing (NLP), where text is categorized into predefined labels. Unlike English, Bengali faces challenges due to the lack of extensive annotated datasets and pre-trained language models. This study explores the effectiveness of large language models (LLMs) in classifying Bengali newspaper articles. The dataset used, obtained from Kaggle, consists of articles from Prothom Alo, a major Bangladeshi newspaper. Three instruction-tuned LLMs—LLaMA 3.1 8B Instruct, LLaMA 3.2 3B Instruct, and Qwen 2.5 7B Instruct—were evaluated for this task under the same classification framework. Among the evaluated models, Qwen 2.5 achieved the highest classification accuracy of 72%, showing particular strength in the 'Sports' category. In comparison, LLaMA 3.1 and LLaMA 3.2 attained accuracies of 53% and 56%, respectively. The findings highlight the effectiveness of LLMs in Bengali text classification, despite the scarcity of resources for Bengali NLP. Future research will focus on exploring additional models, addressing class imbalance issues, and refining fine-tuning approaches to improve classification performance.",3.68,107.218,395,cold_start,Phi-4,Apple_M1(Metal)
2601.12134v1_Human-Human-AI Triadic Programming Uncovering the .pdf,Human-Human-AI Triadic Programming: Uncovering the Role of AI Agent and the Value of Human Partner in Collaborative Learning,"Taufiq Daryanto, Xiaohan Ding, Kaike Ping, Lance T. Wilhelm, Yan Chen, Chris Brown, Eugenia H. Rho",https://doi.org/XXXXXXX.XXXXXXX,arXiv:2601.12134v1,"AI, collaborative programming, human-human-AI triadic programming, learning, programming","As AI assistance becomes embedded in programming practice, researchers have increasingly examined how these systems help learners generate code and work more efficiently. However, these studies often position AI as a replacement for human collaboration and overlook the social and learning-oriented aspects that emerge in collaborative programming. Our work introduces human-human-AI (HHAI) triadic programming, where an AI agent serves as an additional collaborator rather than a substitute for a human partner. Through a within-subjects study with 20 participants, we show the potential benefits and design considerations of this triadic interaction, including whether AI should act as a shared collaborator or personal support.",3.43,85.896,295,cold_start,Phi-4,Apple_M1(Metal)
2601.12138v1_DriveSafe A Hierarchical Risk Taxonomy for Safety-.pdf,DriveSafe: A Hierarchical Risk Taxonomy for Safety-Critical LLM-Based Driving Assistants,"Abhishek Kumar, Riya Tapwal, Carsten Maple",,,"Large Language Models, Driving Assistants, Safety-Critical Systems, Risk Taxonomy, Vehicle-Based Digital Assistants","Large Language Models (LLMs) are increasingly integrated into vehicle-based digital assistants, where unsafe, ambiguous, or legally incorrect responses can lead to serious safety, ethical, and regulatory consequences. Despite growing interest in LLM safety, existing taxonomies and evaluation frameworks remain largely general-purpose and fail to capture the domain-specific risks inherent to real-world driving scenarios. This paper introduces DriveSafe, a hierarchical, four-level risk taxonomy designed to systematically characterize safety-critical failure modes of LLM-based driving assistants. The taxonomy comprises 129 fine-grained atomic risk categories spanning technical, legal, societal, and ethical dimensions, grounded in real-world driving regulations and safety principles and reviewed by domain experts. To validate the safety relevance and realism of the constructed prompts, the paper evaluates their refusal behavior across six widely deployed LLMs. The analysis shows that the evaluated models often fail to appropriately refuse unsafe or non-compliant driving-related queries, underscoring the limitations of general-purpose safety alignment in driving contexts.",3.31,93.135,308,cold_start,Phi-4,Apple_M1(Metal)
2601.12141v1_TIDE A Trace-Informed Depth-First Exploration for .pdf,TIDE: A Trace-Informed Depth-First Exploration for Planning with Temporally Extended Goals,"Yuliia Suprun, Khen Elimelech, Lydia E. Kavraki, Moshe Y. Vardi",,2601.12141v1,"task planning, temporally extended goals, Linear Temporal Logic, LTLf, heuristics, depth-first exploration, reach-avoid subproblems, adaptive backtracking","Task planning with temporally extended goals (TEGs) is a critical challenge in AI and robotics, enabling agents to achieve complex sequences of objectives over time rather than addressing isolated, immediate tasks. Linear Temporal Logic on finite traces (LTLf) provides a robust formalism for encoding these temporal goals. Traditional LTLf task planning approaches often transform the temporal planning problem into a classical planning problem with reachability goals, which are then solved using off-the-shelf planners. However, these methods often lack informed heuristics to provide a guided search for temporal goals. We introduce TIDE (Trace-Informed Depth-first Exploration), a novel approach that addresses this limitation by decomposing a temporal problem into a sequence of smaller, manageable reach-avoid subproblems, each solvable using an off-the-shelf planner. TIDE identifies and prioritizes promising automaton traces within the domain graph, using cost-driven heuristics to guide exploration. Its adaptive backtracking mechanism systematically recovers from failed plans by recalculating costs and penalizing infeasible transitions, ensuring completeness and efficiency. Experimental results demonstrate that TIDE achieves promising performance and is a valuable addition to the portfolio of planning methods for temporally extended goals.",3.7,107.353,397,cold_start,Phi-4,Apple_M1(Metal)
2601.12147v1_Segment and Matte Anything in a Unified Model.pdf,Segment and Matte Anything in a Unified Model,"Zezhong Fan, Xiaohan Li, Topojoy Biswas, Kaushiki Nag, Kannan Achan",,,"Segment Anything, image matting, segmentation, multi-view localization, interactive segmentation, alpha mattes","Segment Anything (SAM) has demonstrated zero-shot generalization and flexible prompting after training on over one billion masks. However, its mask prediction accuracy often falls short for real-world applications. This paper introduces Segment And Matte Anything (SAMA), a lightweight extension of SAM that delivers high-quality interactive image segmentation and matting with minimal extra parameters. SAMA incorporates a Multi-View Localization Encoder (MVLE) and a Localization Adapter (Local-Adapter) to refine mask outputs and capture detailed features. Trained on a diverse dataset, SAMA achieves state-of-the-art performance across multiple segmentation and matting benchmarks, showcasing its adaptability and effectiveness in various downstream tasks.",3.12,80.06,250,cold_start,Phi-4,Apple_M1(Metal)
2601.12150v1_Enhanced Diagnostic Performance via Large-Resoluti.pdf,ENHANCED DIAGNOSTIC PERFORMANCE VIA LARGE-RESOLUTION INFERENCE OPTIMIZATION FOR PATHOLOGY FOUNDATION MODELS,"Mengxuan Hu, Zihan Guan, John Kang, Sheng Li, Zhongliang Zhou",,arXiv:2601.12150v1,"Computational pathology, Foundation models, Inference Optimization","Despite their prominent performance on tasks such as ROI classification and segmentation, many pathology foundation models remain constrained by a specific input size (e.g., 224×224), creating substantial inefficiencies when applied to whole-slide images (WSIs), which span thousands of resolutions. A naïve strategy is to either enlarge inputs or downsample the WSIs. However, enlarging inputs results in prohibitive GPU memory consumption, while downsampling alters the microns-per-pixel resolution and obscures critical morphological details. To overcome these limitations, we propose a space- and time-efficient inference strategy that sparsifies attention using spatially aware neighboring blocks and filters out non-informative tokens through global attention scores. This design substantially reduces GPU memory and runtime during high-resolution WSI inference while preserving and even improving the downstream performance, enabling inference at higher resolutions under the same GPU budget. The experimental results show that our method can achieve up to a 7.67% improvement in the ROI classification and compatible results in segmentation.",3.43,96.21,330,cold_start,Phi-4,Apple_M1(Metal)
2601.12186v1_Aletheia What Makes RLVR For Code Verifiers Tick.pdf,Aletheia: What Makes RLVR For Code Verifiers Tick?,"Vatsal Venkatkrishna, Indraneil Paul, Iryna Gurevych",,,"Reinforcement Learning, Code Verification, Large Language Models, Post-training Pipeline, Execution Feedback, Robustness, Policy Models, Covariate Shifts","Multi-domain thinking verifiers trained via Reinforcement Learning from Verifiable Rewards (RLVR) are a prominent fixture of the Large Language Model (LLM) post-training pipeline, owing to their ability to robustly rate and rerank model outputs. However, the adoption of such verifiers towards code generation has been comparatively sparse, with execution feedback constituting the dominant signal. Nonetheless, code verifiers remain valuable toward judging model outputs in scenarios where execution feedback is hard to obtain and are a potentially powerful addition to the code generation post-training toolbox. To this end, we create and open-source Aletheia, a controlled testbed that enables execution-grounded evaluation of code verifiers’ robustness across disparate policy models and covariate shifts. We examine components of the RLVR-based verifier training recipe widely credited for its success: (1) intermediate thinking traces, (2) learning from negative samples, and (3) on-policy training. While experiments show the optimality of RLVR, we uncover important opportunities to simplify the recipe. Particularly, despite code verification exhibiting positive training- and inference-time scaling, on-policy learning stands out as the key component at small verifier sizes, and thinking-based training emerges as the most important component at larger scales.",3.36,112.175,377,cold_start,Phi-4,Apple_M1(Metal)
2601.12205v1_Do Neural Codecs Generalize A Controlled Study Acr.pdf,Do Neural Codecs Generalize? A Controlled Study Across Unseen Languages and Non-Speech Tasks,"Shih-Heng Wang, Jiatong Shi, Jinchuan Tian, Haibin Wu, Shinji Watanabe",,,"Neural Audio Codecs, generalization, unseen languages, non-speech tasks, signal compression, speech modeling","This paper investigates the generalization capabilities of Neural Audio Codecs (NACs) across unseen languages and non-speech tasks. It explores whether NACs can generalize to unseen languages during pre-training, if speech-only pre-trained NACs can effectively generalize to non-speech applications, and whether incorporating non-speech pre-training data can enhance performance on both speech and non-speech tasks. The study trains NACs from scratch with controlled configurations and evaluates their performance using 11 metrics, finding that NACs can generalize to unseen languages, speech-only pre-trained NACs perform poorly on non-speech tasks, and including non-speech data during pre-training improves performance on non-speech tasks while maintaining speech task performance.",3.01,84.809,255,cold_start,Phi-4,Apple_M1(Metal)
2601.12212v1_Speculative Sampling with Reinforcement Learning.pdf,Speculative Sampling with Reinforcement Learning,"Chenan Wang, Daniel H. Shi, Haipeng Chen",,,"speculative sampling, reinforcement learning, large language models, inference time latency, draft tree hyperparameters","Inference time latency is a significant challenge for real-world applications of large language models (LLMs). State-of-the-art speculative sampling (SpS) methods like EAGLE-3 use tree-based drafting to explore multiple candidate continuations in parallel. However, the static hyperparameters controlling the tree structure limit flexibility and efficiency across diverse contexts and domains. This paper introduces Reinforcement Learning for Speculative Sampling (Re-SpS), the first reinforcement learning-based framework for optimizing draft tree hyperparameters. Re-SpS dynamically adjusts these hyperparameters in real-time, learning context-aware policies that maximize generation speed by balancing speculative aggression with computational overhead. It leverages efficient state representations from target model hidden states and introduces multi-step action persistence for better context modeling. Evaluation results across five diverse benchmarks demonstrate consistent improvements over the SOTA method EAGLE-3, achieving up to 5.45× speedup over the backbone LLM and up to 1.12× speedup compared to EAGLE-3, with no loss in output fidelity.",3.1,92.832,288,cold_start,Phi-4,Apple_M1(Metal)
2601.12215v1_Wavelet-Driven Masked Multiscale Reconstruction fo.pdf,Wavelet-Driven Masked Multiscale Reconstruction for PPG Foundation Models,"Megha Thukral, Cyrus Tanade, Simon A. Lee, Juhyeon Lee, Hao Zhou, Keum San Chun, Migyeong Gwak, Viswam Nathan, Md Mahbubur Rahman, Li Zhu, Mehrab Bin Morshed, Subramaniam Venkatraman, Sharanya Arcot Desai",,arXiv:2601.12215v1,"Wearable SSL Method, Wavelet based Modelling, PPG foundation models","Wearable foundation models have the potential to transform digital health by learning transferable representations from large-scale biosignals collected in everyday settings. While recent progress has been made in large-scale pretraining, most approaches overlook the spectral structure of photoplethysmography (PPG) signals, wherein physiological rhythms unfold across multiple frequency bands. Motivated by the insight that many downstream health-related tasks depend on multi-resolution features spanning fine-grained waveform morphology to global rhythmic dynamics, we introduce Masked Multiscale Reconstruction (MMR) for PPG representation learning - a self-supervised pretraining framework that explicitly learns from hierarchical time–frequency scales of PPG data. The pretraining task is designed to reconstruct randomly masked out coefficients obtained from a wavelet-based multiresolution decomposition of PPG signals, forcing the transformer encoder to integrate information across temporal and spectral scales. We pretrain our model with MMR using ∼17 million unlabeled 10-second PPG segments from ∼32,000 smartwatch users. On 17 of 19 diverse health-related tasks, MMR trained on large-scale wearable PPG data improves over or matches state-of-the-art open-source PPG foundation models, time-series foundation models and other self-supervised baselines. Extensive analysis of our learned embeddings and systematic ablations underscore the value of wavelet-based representations, showing that they capture robust and physiologically-grounded features. Together, these results highlight the potential of MMR as a step toward generalizable PPG foundation models.",3.88,128.41,498,cold_start,Phi-4,Apple_M1(Metal)
2601.12224v1_Where It Moves It Matters Referring Surgical Instr.pdf,"Where It Moves, It Matters: Referring Surgical Instrument Segmentation via Motion","Meng Wei, Kun Yuan, Shi Li, Yue Zhou, Long Bai, Nassir Navab, Hongliang Ren, Hong Joo Lee, Tom Vercauteren, Nicolas Padoy",,,"surgical video segmentation, motion-guided framework, natural language processing, instrument localization, surgical data science, computer vision","Enabling intuitive, language-driven interaction with surgical scenes is a critical step toward intelligent operating rooms and autonomous surgical robotic assistance. This work introduces SurgRef, a novel motion-guided framework that grounds free-form language expressions in instrument motion, capturing how tools move and interact across time. This approach allows models to understand and segment instruments even under occlusion, ambiguity, or unfamiliar terminology. The Ref-IMotion dataset is presented for training and evaluation, achieving state-of-the-art accuracy and generalization across surgical procedures, setting a new benchmark for robust, language-driven surgical video segmentation.",3.14,86.71,272,cold_start,Phi-4,Apple_M1(Metal)
2601.12234v1_Proc3D Procedural 3D Generation and Parametric Edi.pdf,Proc3D: Procedural 3D Generation and Parametric Editing of 3D Shapes with Large Language Models,"Fadlullah Raji, Stefano Petrangeli, Matheus Gadelha, Yu Shen, Uttaran Bhattacharya, Gang Wu",,arXiv:2601.12234v1,"3D model generation, parametric editing, Large Language Models, procedural compact graph, real-time modifications, natural language processing","Generating 3D models has traditionally been a complex task requiring specialized expertise. Recent advances in generative AI have sought to automate this process, but existing methods produce non-editable representations, such as meshes or point clouds, limiting their adaptability for iterative design. This paper introduces Proc3D, a system designed to generate editable 3D models while enabling real-time modifications. Proc3D introduces a procedural compact graph (PCG) representation of 3D models, encoding the algorithmic rules and structures necessary for generating the model. This representation allows intuitive manual adjustments via sliders and checkboxes, as well as real-time, automated modifications through natural language prompts using Large Language Models (LLMs). The capabilities of Proc3D are demonstrated using GPT-4o with in-context learning (ICL) and a fine-tuned LLAMA-3 model. Experimental results show that Proc3D outperforms existing methods in editing efficiency, achieving more than 400× speedup over conventional approaches that require full regeneration for each modification. Additionally, Proc3D improves ULIP scores by 28%, a metric that evaluates the alignment between generated 3D models and text prompts. By enabling text-aligned 3D model generation along with precise, real-time parametric edits, Proc3D facilitates highly accurate text-based image editing applications.",3.75,113.913,427,cold_start,Phi-4,Apple_M1(Metal)
2601.12242v1_Optimal Power Allocation and Sub-Optimal Channel A.pdf,Optimal Power Allocation and Sub-Optimal Channel Assignment for Downlink NOMA System Using Deep Reinforcement Learning,"WooSeok Kim, Jeonghoon Lee, Sangho Kim, Taesun An, WonMin Lee, Dowon Kim, Kyungseop Shin",,2601.12242v1,"Non-orthogonal multiple access (NOMA), deep reinforcement learning (DRL), wireless network, resource allocation","In recent years, Non-Orthogonal Multiple Access (NOMA) system has emerged as a promising candidate for multiple access frameworks due to the evolution of deep machine learning, trying to incorporate deep machine learning into the NOMA system. The main motivation for such active studies is the growing need to optimize the utilization of network resources as the expansion of the internet of things (IoT) caused a scarcity of network resources. The NOMA addresses this need by power multiplexing, allowing multiple users to access the network simultaneously. Nevertheless, the NOMA system has few limitations. Several works have proposed to mitigate this, including the optimization of power allocation known as joint resource allocation (JRA) method, and integration of the JRA method and deep reinforcement learning (JRA-DRL). Despite this, the channel assignment problem remains unclear and requires further investigation. In this paper, we propose a deep reinforcement learning framework incorporating replay memory with an on-policy algorithm, allocating network resources in a NOMA system to generalize the learning. Also, we provide extensive simulations to evaluate the effects of varying the learning rate, batch size, type of model, and the number of features in the state.",3.66,106.405,389,cold_start,Phi-4,Apple_M1(Metal)
2601.12243v1_Less is More Label-Guided Summarization of Procedu.pdf,Less is More: Label-Guided Summarization of Procedural and Instructional Videos,"Shreya Rajpal, Michal Golovanesky, Carsten Eickhoff",,arXiv:2601.12243v1,"video summarization, procedural videos, instructional videos, semantic content, keyframe selection, large language model, context-aware summarization","Video summarization helps turn long videos into clear, concise representations that are easier to review, document, and analyze, especially in high-stakes domains like surgical training. Prior work has progressed from using basic visual features like color, motion, and structural changes to using pre-trained vision-language models that can better understand what’s happening in the video (semantics) and capture temporal flow, resulting in more context-aware video summarization. We propose a three-stage framework, PRISM: Procedural Representation via Integrated Semantic and Multimodal analysis, that produces semantically grounded video summaries. PRISM combines adaptive visual sampling, label-driven keyframe anchoring, and contextual validation using a large language model (LLM). Our method ensures that selected frames reflect meaningful and procedural transitions while filtering out generic or hallucinated content, resulting in contextually coherent summaries across both domain-specific and instructional videos. We evaluate our method on instructional and activity datasets, using reference summaries for instructional videos. Despite sampling fewer than 5% of the original frames, our summaries retain 84% semantic content while improving over baselines by as much as 33%. Our approach generalizes across procedural and domain-specific video tasks, achieving strong performance with both semantic alignment and precision.",3.55,101.936,362,cold_start,Phi-4,Apple_M1(Metal)
2601.12247v1_Plan Verify and Fill A Structured Parallel Decodin.pdf,"Plan, Verify and Fill: A Structured Parallel Decoding Approach for Diffusion Language Models","Miao Li, Hanyang Jiang, Sikai Cheng, Hengyu Fu, Yuhang Cai, Baihe Huang, Tinghan Ye, Xuanzhou Chen, Pascal Van Hentenryck",,,"Diffusion Language Models, non-sequential paradigm, text generation, autoregressive, Plan-Verify-Fill, hierarchical skeleton, semantic anchors, structural stopping, Number of Function Evaluations, parallel decoding, efficiency, accuracy","Diffusion Language Models (DLMs) offer a non-sequential approach to text generation, differing from autoregressive models. The Plan-Verify-Fill (PVF) method is introduced to enhance decoding strategies by utilizing global bidirectional context. PVF constructs a hierarchical skeleton prioritizing semantic anchors and employs a verification protocol for efficient structural stopping. Evaluations show PVF reduces the Number of Function Evaluations by up to 65% compared to confidence-based parallel decoding, improving efficiency without sacrificing accuracy.",3.2,92.52,296,cold_start,Phi-4,Apple_M1(Metal)
2601.12248v1_AQUA-Bench Beyond Finding Answers to Knowing When .pdf,AQUA-BENCH: BEYOND FINDING ANSWERS TO KNOWING WHEN THERE ARE NONE IN AUDIO QUESTION ANSWERING,"Chun-Yi Kuan, Hung-yi Lee",,,"Unanswerable questions, Audio question answering, Audio-aware large language models","Recent advances in audio-aware large language models have shown strong performance on audio question answering. However, existing benchmarks mainly cover answerable questions and overlook the challenge of unanswerable ones, where no reliable answer can be inferred from the audio. To address this gap, AQUA-Bench is introduced, a benchmark for Audio Question Unanswerability Assessment. It evaluates three scenarios: Absent Answer Detection, Incompatible Answer Set Detection, and Incompatible Audio Question Detection. AQUA-Bench offers a rigorous measure of model reliability and promotes the development of more robust and trustworthy audio-language systems. Experiments suggest that while models excel on standard answerable tasks, they face notable challenges with unanswerable ones, indicating a blind spot in current audio-language understanding.",3.15,76.426,241,cold_start,Phi-4,Apple_M1(Metal)
2601.12249v1_An Innovative Framework for Breast Cancer Detectio.pdf,"An Innovative Framework for Breast Cancer Detection Using Pyramid Adaptive Atrous Convolution, Transformer Integration, and Multi-Scale Feature Fusion","Ehsan Sadeghi Pour, Mahdi Esmaeili, Morteza Romoozi",,,"Breast Cancer Detection, Pyramid Adaptive Atrous Convolution (PAAC), Transformer, Multi-Scale Feature Fusion, Self-Attention Mechanism, Medical Image Processing","Breast cancer is one of the most common cancers among women worldwide, and its accurate and timely diagnosis plays a critical role in improving treatment outcomes. This thesis presents an innovative framework for detecting malignant masses in mammographic images by integrating the Pyramid Adaptive Atrous Convolution (PAAC) and Transformer architectures. The proposed approach utilizes Multi-Scale Feature Fusion to enhance the extraction of features from benign and malignant tissues and combines Dice Loss and Focal Loss functions to improve the model’s learning process, effectively reducing errors in binary breast cancer classification and achieving high accuracy and efficiency. In this study, a comprehensive dataset of breast cancer images from INbreast, MIAS, and DDSM was preprocessed through data augmentation and contrast enhancement and resized to 227×227 pixels for model training. Leveraging the Transformer's ability to manage long-range dependencies with Self-Attention mechanisms, the proposed model achieved high accuracy in detecting cancerous masses, outperforming foundational models such as BreastNet, DeepMammo, Multi-Scale CNN, Swin-Unet, and SegFormer. The final evaluation results for the proposed model include an accuracy of 98.5%, sensitivity of 97.8%, specificity of 96.3%, F1-score of 98.2%, and overall precision of 97.9%. These metrics demonstrate a significant improvement over traditional methods and confirm the model's effectiveness in identifying cancerous masses in complex scenarios and large datasets. This model shows potential as a reliable and efficient tool for breast cancer diagnosis and can be effectively integrated into medical diagnostic systems.",3.62,124.707,452,cold_start,Phi-4,Apple_M1(Metal)
2601.12256v1_Improving Large Molecular Language Model via Relat.pdf,Improving Large Molecular Language Model via Relation-aware Multimodal Collaboration,"Jinyoung Park, Minseong Bae, Jeehye Na, Hyunwoo J. Kim",,,"large molecular language models, molecular modality-collaborative projector, relation-aware modality-collaborative attention, molecule captioning, computed property QA, descriptive property QA, motif counting, IUPAC name prediction","Large language models (LLMs) have shown significant advancements in various tasks, inspiring adaptations in domains like molecular modeling. Large molecular language models (LMLMs) integrate 1D, 2D, and 3D molecular modalities but face challenges like hallucination and limited robustness. This paper introduces CoLLaMo, a model with a multi-level molecular modality-collaborative projector and a relation-aware modality-collaborative attention mechanism. It enhances molecular modality generalization, outperforming in tasks like molecule captioning and property QA. New evaluation metrics are also proposed to address limitations of existing token-based metrics.",3.12,89.707,280,cold_start,Phi-4,Apple_M1(Metal)
2601.12257v1_Soft Shadow Diffusion SSD Physics-inspired Learnin.pdf,Soft Shadow Diffusion (SSD): Physics-inspired Learning for 3D Computational Periscopy,"Fadlullah Raji, John Murray Bruce",,arXiv:2601.12257v1,"Computational imaging, Machine learning, 3D generative models, Diffusion models, Separable non-linear least squares","Conventional imaging requires a line of sight to create accurate visual representations of a scene. In certain circumstances, obtaining a suitable line of sight may be impractical, dangerous, or even impossible. Non-line-of-sight (NLOS) imaging addresses this challenge by reconstructing the scene from indirect measurements. Recently, passive NLOS methods that use an ordinary photograph of the subtle shadow cast onto a visible wall by the hidden scene have gained interest. These methods are currently limited to 1D or low-resolution 2D color imaging or to localizing a hidden object whose shape is approximately known. Here, we generalize this class of methods and demonstrate a 3D reconstruction of a hidden scene from an ordinary NLOS photograph. To achieve this, we propose a novel reformulation of the light transport model that conveniently decomposes the hidden scene into light-occluding and non-light-occluding components to yield a separable non-linear least squares (SNLLS) inverse problem. We develop two solutions: A gradient-based optimization method and a physics-inspired neural network approach, which we call Soft Shadow Diffusion (SSD). Despite the challenging ill-conditioned inverse problem encountered here, our approaches are effective on numerous 3D scenes in real experimental scenarios. Moreover, SSD is trained in simulation but generalizes well to unseen classes in simulation and real-world NLOS scenes. SSD also shows surprising robustness to noise and ambient illumination.",3.7,109.137,404,cold_start,Phi-4,Apple_M1(Metal)
2601.12259v1_FutureX-Pro Extending Future Prediction to High-Va.pdf,FutureX-Pro: Extending Future Prediction to High-Value Vertical Domains,"ByteDance Seed, Hong Kong University of Science and Technology, Georgia Institute of Technology, Stanford University, Princeton University",,arXiv:2601.12259v1,"Future Prediction, High-Value Vertical Domains, Finance, Retail, Public Health, Natural Disaster, Large Language Models, Generalist Agents, Economic Impact, Societal Stability","Building upon FutureX, this report introduces FutureX-Pro, which extends agentic future prediction to high-value vertical domains such as Finance, Retail, Public Health, and Natural Disaster. It evaluates the performance of agentic Large Language Models (LLMs) on foundational prediction tasks within these sectors, assessing their domain grounding for industrial deployment. The study reveals a performance gap between generalist reasoning and the precision required for high-stakes applications, highlighting the need for specialized frameworks in capital-intensive and safety-critical sectors.",3.38,76.954,260,cold_start,Phi-4,Apple_M1(Metal)
2601.12260v1_Docs2Synth A Synthetic Data Trained Retriever Fram.pdf,Docs2Synth: A Synthetic Data Trained Retriever Framework for Scanned Visually Rich Documents Understanding,"Yihao Ding, Qiang Sun, Puzhen Wu, Sirui Li, Siwen Luo, Wei Liu",,,"Document understanding, Multimodal Large Language Models, Vision-Language Pre-trained Models, Synthetic data, Retriever framework, Visually rich documents","Document understanding (VRDU) in regulated domains is challenging due to the lack of manual annotations and the difficulty for pretrained models to stay updated with domain-specific facts. This paper introduces Docs2Synth, a synthetic-supervision framework that enables retrieval-guided inference for private and low-resource domains. Docs2Synth processes raw document collections, generates and verifies diverse QA pairs via an agent-based system, and trains a lightweight visual retriever to extract domain-relevant evidence. During inference, the retriever collaborates with a Multimodal Large Language Model (MLLM) through an iterative retrieval–generation loop, reducing hallucination and improving response consistency. Experiments show that Docs2Synth enhances grounding and domain generalization without requiring human annotations. The implementation is available at https://docs2synth.ai4wa.com.",3.21,95.13,305,cold_start,Phi-4,Apple_M1(Metal)
2601.12263v1_Multimodal Generative Engine Optimization Rank Man.pdf,Multimodal Generative Engine Optimization: Rank Manipulation for Vision–Language Model Rankers,"Yixuan Du, Chenxiao Yu, Haoyan Xu, Ziyi Wang, Yue Zhao, Xiyang Hu",,,"Vision-Language Models, adversarial manipulation, multimodal ranking attacks, product search, image perturbations, textual suffixes, cross-modal coupling","Vision-Language Models (VLMs) are increasingly used in retrieval and recommendation systems. However, their robustness against adversarial manipulation in ranking scenarios is underexplored. This paper introduces Multimodal Generative Engine Optimization (MGEO), a framework that allows malicious actors to unfairly promote products by optimizing image perturbations and textual suffixes. MGEO uses an alternating gradient-based optimization strategy to exploit cross-modal coupling in VLMs. Experiments show that this coordinated attack significantly outperforms text-only and image-only baselines, highlighting a vulnerability in VLMs that can compromise search rankings without triggering conventional content filters.",2.9,93.029,270,cold_start,Phi-4,Apple_M1(Metal)
2601.12269v1_Simulated Annealing Enhances Theory-of-Mind Reason.pdf,Simulated Annealing Enhances Theory-of-Mind Reasoning in Autoregressive Language Models,"Xucong Hu, Jian-Qiao Zhu",,,"Language Models, Markov Chain Monte Carlo, Simulated Annealing, Power Sampling, Theory of Mind","Autoregressive language models are next-token predictors and have been criticized for optimizing surface plausibility rather than maintaining correct latent-state representations. Theory of Mind tasks depend on reasoning about latent mental states, which these models often fail at. This study shows that strong Theory of Mind capability can be recovered from the base model without additional weight updates by using power-sampling methods and incorporating simulated annealing. This approach improves Theory of Mind performance by sampling from sharpened sequence-level probability distributions and gradually shifting from high to low temperature distributions. The results suggest that sampling-based optimization can extract latent capabilities from language models without retraining.",2.97,76.018,226,cold_start,Phi-4,Apple_M1(Metal)
2601.12276v1_Predictive Prototyping Evaluating Design Concepts .pdf,PREDICTIVE PROTOTYPING: EVALUATING DESIGN CONCEPTS WITH GPT,Hilsann Yong,,,"Prototyping, Design Theory, Iteration, Simulation, AI, LLM, GPT, RAG, Crowdsourcing","The design-build-test cycle is critical for realizing innovative solutions, allowing teams to evaluate and enhance designs through performance and iteration. However, testing can be time-consuming and costly. This work explores the potential of generative pretrained transformers (GPTs), specifically OpenAI’s GPT-4o, to predict prototyping outcomes such as cost, performance, and usability. A novel approach using retrieval augmented generation (RAG) is introduced to emulate design feedback. The study leverages prototyping data from 'Instructables.com' and compares GPT-RAG predictions with human designers and ground-truth results. The GPT-RAG model demonstrated more accurate predictions than human estimations and inspired a prototype that outperformed commercial and topology optimized models. The study also found that averaging multiple GPT-RAG responses improved accuracy, emulating crowd behavior.",3.34,81.704,273,cold_start,Phi-4,Apple_M1(Metal)
2601.12282v1_CytoCLIP Learning Cytoarchitectural Characteristic.pdf,CytoCLIP: Learning Cytoarchitectural Characteristics in Developing Human Brain Using Contrastive Language Image Pre-Training,"Pralaypati Ta, Sriram Venkatesaperumal, Keerthi Ram, Mohanasankar Sivaprakasam",,,"Cytoarchitecture, Histological Image processing, Contrastive learning, CLIP","The functions of different regions of the human brain are closely linked to their distinct cytoarchitecture, defined by the spatial arrangement and morphology of cells. Identifying brain regions by their cytoarchitecture enables various scientific analyses of the brain. However, delineating these areas manually in brain histological sections is time-consuming and requires specialized knowledge. An automated approach is necessary to minimize the effort needed from human experts. To address this, we propose CytoCLIP, a suite of vision-language models derived from pre-trained Contrastive Language-Image Pre-Training (CLIP) frameworks to learn joint visual-text representations of brain cytoarchitecture. CytoCLIP comprises two model variants: one is trained using low-resolution whole-region images to understand the overall cytoarchitectural pattern of an area, and the other is trained on high-resolution image tiles for detailed cellular-level representation. The training dataset is created from NISSL-stained histological sections of developing fetal brains of different gestational weeks. It includes 86 distinct regions for low-resolution images and 384 brain regions for high-resolution tiles. We evaluate the model's understanding of the cytoarchitecture and generalization ability using region classification and cross-modal retrieval tasks. Multiple experiments are performed under various data setups, including data from samples of different ages and sectioning planes. Experimental results demonstrate that CytoCLIP outperforms existing methods. It achieves an F1 score of 0.87 for whole-region classification and 0.91 for high-resolution image tile classification.",3.55,121.833,433,cold_start,Phi-4,Apple_M1(Metal)
2601.12286v1_Conversational Context Classification A Representa.pdf,Conversational Context Classification: A Representation Engineering Approach,Jonathan Pan,,,"Large Language Models (LLMs), One-Class SVM, Novelty Detection, In/Out-of-Context, Representation Engineering","The increasing prevalence of Large Language Models (LLMs) demands effective safeguards for their operation, particularly concerning their tendency to generate 'out-of-context' responses. This paper explores the use of Representation Engineering (RepE) and One-Class Support Vector Machine (OCSVM) to identify subspaces within the internal states of LLMs that represent a specific context. By training OCSVM on in-context examples, a robust boundary within the LLM’s hidden state latent space is established. The study evaluates two open-source LLMs, Llama and Qwen, in specific contextual domains, identifying optimal layers within the LLM’s internal state subspaces that strongly associate with the context of interest. The approach shows promising results in identifying the subspace for a specific context, contributing to AI safety and better interpretation of LLMs.",3.11,76.242,237,cold_start,Phi-4,Apple_M1(Metal)
2601.12288v1_TimeGMM Single-Pass Probabilistic Forecasting via .pdf,TIMEGMM: SINGLE-PASS PROBABILISTIC FORECASTING VIA ADAPTIVE GAUSSIAN MIXTURE MODELS WITH REVERSIBLE NORMALIZATION,"Lei Liu, Tengyuan Liu, Hongwei Zhao, Jiahui Huang, Ruibo Guo, Bin Li",,,"Probabilistic time series forecasting, Gaussian mixture model, Reversible instance normalization","Probabilistic time series forecasting is crucial for quantifying future uncertainty, with significant applications in fields such as energy and finance. Existing methods often rely on computationally expensive sampling or restrictive parametric assumptions to characterize future distributions, which limits predictive performance and introduces distributional mismatch. This paper presents TimeGMM, a novel probabilistic forecasting framework based on Gaussian Mixture Models (GMM) that captures complex future distributions in a single forward pass. A key component is GMM-adapted Reversible Instance Normalization (GRIN), a novel module designed to dynamically adapt to temporal-probabilistic distribution shifts. The framework integrates a dedicated Temporal Encoder (TE-Module) with a Conditional Temporal-Probabilistic Decoder (CTPD-Module) to jointly capture temporal dependencies and mixture distribution parameters. Extensive experiments demonstrate that TimeGMM consistently outperforms state-of-the-art methods, achieving maximum improvements of 22.48% in CRPS and 21.23% in NMAE.",3.33,100.632,335,cold_start,Phi-4,Apple_M1(Metal)
2601.12294v1_ToolPRMBench Evaluating and Advancing Process Rewa.pdf,ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents,"Dawei Li, Yuguang Yao, Zhen Tan, Huan Liu, Ruocheng Guo",,,"reward-guided search methods, tool-using agents, process reward models, benchmark, large language models, tool-specialized PRMs","Reward-guided search methods have shown potential in enhancing tool-using agents by guiding sampling and exploration over complex action spaces. This paper introduces ToolPRMBench, a benchmark for evaluating process reward models (PRMs) in tool-using settings. Built on representative benchmarks, ToolPRMBench converts agent trajectories into step-level test cases, isolating single-step errors and capturing multi-step failures. A multi-LLM verification pipeline ensures data quality. Experiments reveal differences in PRM effectiveness and highlight the potential of specialized PRMs for tool-using agents.",2.81,83.497,235,cold_start,Phi-4,Apple_M1(Metal)
2601.12304v1_A Two-Stage Globally-Diverse Adversarial Attack fo.pdf,A TWO-STAGE GLOBALLY-DIVERSE ADVERSARIAL ATTACK FOR VISION-LANGUAGE PRE-TRAINING MODELS,"Wutao Chen, Huaqin Zou, Chen Wan, Lifeng Huang",,,"Adversarial Attack, VLP Models, Multimodal Retrieval, Transferability","Vision-language pre-training (VLP) models are vulnerable to adversarial examples, especially in black-box scenarios. Existing multimodal attacks often suffer from limited perturbation diversity and unstable multi-stage pipelines. To address these challenges, we propose 2S-GDA, a two-stage globally-diverse attack framework. The method introduces textual perturbations through a globally-diverse strategy by combining candidate text expansion with globally-aware replacement. To enhance visual diversity, image-level perturbations are generated using multi-scale resizing and block-shuffle rotation. Extensive experiments on VLP models demonstrate that 2S-GDA consistently improves attack success rates over state-of-the-art methods, with gains of up to 11.17% in black-box settings. Our framework is modular and can be easily combined with existing methods to further enhance adversarial transferability.",3.22,89.788,289,cold_start,Phi-4,Apple_M1(Metal)
2601.12310v1_Survival is the Only Reward Sustainable Self-Train.pdf,Survival is the Only Reward: Sustainable Self-Training Through Environment-Mediated Selection,"Jennifer Dodgson, Alfath Daryl Alhajir, Michael Joedhitya, Akira Rafhael Janson Pattirane, Surender Suresh Kumar, Joseph Lim, C.H. Peh, Adith Ramdas, Steven Zhang Zhexu",,2601.12310v1,"self-training, environment-mediated selection, sustainable self-training, environmental viability, semantic drift, reward hacking, negative-space learning, meta-learning, autonomous systems","This paper introduces a self-training architecture where learning is mediated by environmental viability, without reliance on rewards, objective functions, or externally defined fitness criteria. The system operates under real resource constraints, propagating only those behaviors that persist and allow for future interactions. The environment provides no semantic feedback or dense rewards, making reward-hacking evolutionarily unstable. The study shows that improvement arises through the persistence of effective strategies under a regime of consolidation and pruning, termed negative-space learning (NSL). Models develop meta-learning strategies, such as deliberate experimental failure, without explicit instruction. This work demonstrates that environment-grounded selection enables sustainable open-ended self-improvement, paving the way for more robust and generalizable autonomous systems without human-curated data or complex reward shaping.",3.8,90.231,343,cold_start,Phi-4,Apple_M1(Metal)
2601.12316v1_GazeFormer-MoE Context-Aware Gaze Estimation via C.pdf,GAZEFORMER-MOE: CONTEXT-AWARE GAZE ESTIMATION VIA CLIP AND MOE TRANSFORMER,"Xinyuan Zhao, Xianrui Chen, Ahmad Chaddad",,,"Gaze estimation, multi scale fusion, MoE transformer","We present a semantics modulated, multi scale Transformer for 3D gaze estimation. Our model conditions CLIP global features with learnable prototype banks (illumination, head pose, background, direction), fuses these prototype-enriched global vectors with CLIP patch tokens and high-resolution CNN tokens in a unified attention space, and replaces several FFN blocks with routed/shared Mixture of Experts to increase conditional capacity. Evaluated on MPIIFaceGaze, EYEDIAP, Gaze360 and ETH-XGaze, our model achieves new state of the art angular errors of 2.49°, 3.22°, 10.16°, and 1.44°, demonstrating up to a 64% relative improvement over previously reported results. Ablations attribute gains to prototype conditioning, cross scale fusion, MoE and hyperparameter. Our code is publicly available at https://github.com/AIPMLab/Gazeformer.",3.25,90.986,296,cold_start,Phi-4,Apple_M1(Metal)
2601.12317v1_Explanova Automatically Discover Data Insights in .pdf,Explanova: Automatically Discover Data Insights in N×M Table via XAI Combined LLM Workflow,Yiming Huang,10.1145/nnnnnnn.nnnnnnn,,"automatic data analysis, LLM, AutoML, XAI, data insights","Automation in data analysis has been a long-time pursuit. Current agentic LLM shows a promising solution towards it. Explanova is an attempt to empower common LLMs' performance in automatic data analysis by enhancing the data analytics side with a preset workflow. This workflow leverages statistical analysis and machine learning modeling to traverse all possible relationships across data features, making data analysis automation realistic in limited GPU resource scenarios. The proposed Explanova workflow includes feature preparation, single-feature statistic analysis, feature-to-feature relation statistic analysis, and feature modeling by all other features in one data table.",2.96,74.57,221,cold_start,Phi-4,Apple_M1(Metal)
2601.12318v1_Beyond Human Annotation Recent Advances in Data Ge.pdf,Beyond Human Annotation: Recent Advances in Data Generation Methods for Document Intelligence,"Dehao Ying, Fengchang Yu, Haihua Chen, Changjiang Jiang, Yurong Li, Wei Lu",https://doi.org/XXXXXXX.XXXXXXX,,"Document Intelligence, Data Generation, Data Quality Evaluation, Surveys and overviews, Artificial intelligence","The advancement of Document Intelligence (DI) demands large-scale, high-quality training data, yet manual annotation remains a critical bottleneck. This survey establishes the first comprehensive technical map for data generation in DI, redefining it as supervisory signal production and introducing a novel taxonomy based on the 'availability of data and labels.' Methodologies are organized into four paradigms: Data Augmentation, Data Generation from Scratch, Automated Data Annotation, and Self-Supervised Signal Construction. A multi-level evaluation framework integrates intrinsic quality and extrinsic utility, compiling performance gains across diverse DI benchmarks. The survey reveals critical challenges such as fidelity gaps and frontiers including co-evolutionary ecosystems, positioning data generation as the central engine for next-generation DI.",3.2,87.11,279,cold_start,Phi-4,Apple_M1(Metal)
2601.12323v1_MARO Learning Stronger Reasoning from Social Inter.pdf,MARO: Learning Stronger Reasoning from Social Interaction,"Yin Cai, Zhouhong Gu, JunTao Zhang, Ping Chen",,,"large language models, multi-agent reward optimization, social reasoning, interaction, negotiation, competition","Humans face countless scenarios requiring reasoning and judgment in daily life. Existing large language model training methods primarily allow models to learn from existing textual content or solve predetermined problems, lacking experience in real scenarios involving interaction, negotiation, and competition with others. This paper proposes Multi-Agent Reward Optimization (MARO), a method that enables large language models (LLMs) to acquire stronger reasoning abilities by learning and practicing in multi-agent social environments. MARO addresses the sparse learning signal problem by decomposing final success or failure outcomes into each specific behavior during the interaction process, handles the uneven role distribution problem by balancing the training sample weights of different roles, and addresses environmental instability issues by directly evaluating the utility of each behavior. Experimental results demonstrate that MARO achieves significant improvements in social reasoning capabilities and that the abilities acquired through social simulation learning can effectively transfer to other tasks such as mathematical reasoning and instruction following. This reveals the tremendous potential of multi-agent social learning in enhancing the general reasoning capabilities of LLMs.",3.25,93.744,305,cold_start,Phi-4,Apple_M1(Metal)
2601.12327v1_The Expert Validation Framework EVF Enabling Domai.pdf,The Expert Validation Framework (EVF): Enabling Domain Expert Control in AI Engineering,"Lucas Gren, Felix Dobslaw",https://doi.org/10.1145/xxx.xxxx,,"GenAI, expert validation, quality assurance, AI engineering, domain expert control","Generative AI (GenAI) systems promise to transform knowledge work by automating a range of tasks, yet their deployment in enterprise settings remains hindered by the lack of systematic quality assurance mechanisms. We present an Expert Validation Framework that places domain experts at the center of building software with GenAI components, enabling them to maintain authoritative control over system behavior through structured specification, testing, validation, and continuous monitoring processes. Our framework addresses the critical gap between AI capabilities and organizational trust by establishing a rigorous, expert-driven methodology for ensuring quality across diverse GenAI applications. Through a four-stage implementation process encompassing specification, system creation, validation, and production monitoring, the framework enables organizations to leverage GenAI capabilities while maintaining expert oversight and quality standards.",3.09,76.371,236,cold_start,Phi-4,Apple_M1(Metal)
2601.12330v1_IceWatch Forecasting Glacial Lake Outburst Floods .pdf,IceWatch: Forecasting Glacial Lake Outburst Floods (GLOFs) using Multimodal Deep Learning,"Zuha Fatima, Muhammad Anser Sohaib, Muhammad Talha, Ayesha Kanwal, Sidra Sultana, Nazia Perwaiz",,,"CNN, deep learning, glacier monitoring, GLOF detection, LSTM, remote sensing, Sentinel-2, temperature forecasting, transformer, velocity prediction","Glacial Lake Outburst Floods (GLOFs) pose a serious threat in high mountain regions, affecting communities, infrastructure, and ecosystems. Traditional methods for GLOF detection rely on hydrological modeling, threshold-based lake monitoring, and manual satellite image analysis, which have limitations such as slow updates, manual labor dependency, and accuracy loss due to clouds or lack of on-site data. This paper introduces IceWatch, a novel deep learning framework for GLOF prediction that incorporates both spatial and temporal perspectives. The vision component, RiskFlow, uses a CNN-based classifier to predict GLOF events from Sentinel-2 multispectral satellite imagery by analyzing spatial patterns of snow, ice, and meltwater. TerraFlow models glacier velocity from NASA ITS_LIVE time series, and TempFlow forecasts near-surface temperature from MODIS LST records. Both components are trained on long-term observational archives and integrated via harmonized preprocessing and synchronization for multimodal, physics-informed GLOF prediction. This system ensures strong predictive performance, rapid data processing for real-time use, and robustness to noise and missing information, paving the way for automatic, scalable GLOF warning systems.",3.43,116.465,400,cold_start,Phi-4,Apple_M1(Metal)
2601.12331v1_Efficient Privacy-Preserving Retrieval Augmented G.pdf,Efficient Privacy-Preserving Retrieval Augmented Generation with Distance-Preserving Encryption,"Huanyi Ye, Jiale Guo, Ziyao Liu, Kwok-Yan Lam",,,"RAG, Privacy-Preserving Retrieval, Distance-Preserving Encryption, LLMs","Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by retrieving knowledge from external databases, improving response accuracy without high computational costs. Traditional RAG systems rely on trusted local environments, but outsourcing to cloud-based storage introduces privacy risks. This paper proposes an efficient privacy-preserving RAG framework (ppRAG) for untrusted cloud environments, using Conditional Approximate Distance-Comparison-Preserving Symmetric Encryption (CAPRISE) to encrypt embeddings while allowing similarity computations. CAPRISE maintains relative distance ordering without exposing inter-database distances, enhancing privacy and efficiency. Differential privacy is introduced to mitigate query analysis risks. Experimental results demonstrate ppRAG's efficient processing, high retrieval accuracy, and strong privacy guarantees, making it suitable for resource-constrained users seeking secure, cloud-augmented LLMs.",3.24,86.68,281,cold_start,Phi-4,Apple_M1(Metal)
2601.12338v1_Actionable Advice from Reviews via Mixture of LoRA.pdf,Actionable Advice from Reviews via Mixture of LoRA Experts: A Two-LLM Pipeline for Issue Extraction and Business Recommendations,"Kartikey Singh Bhandari, Manav Ganesh, Yashwant Viswanathan, Archit Agrawal, Dhruv Kumar, Pratik Narang",,,"customer reviews, issue extraction, business recommendations, large language models, LoRA experts, actionability, specificity, feasibility, expected impact, novelty, non-redundancy, bias, clarity","Customer reviews contain detailed, domain-specific signals about service failures and user expectations, but converting this unstructured feedback into actionable business decisions remains difficult. This paper proposes a modular two-LLM framework for review-to-action generation, producing concrete, implementable recommendations grounded in review text. The framework includes an Issue model for extracting salient issues and assigning coarse themes, and an Advice model for generating targeted operational fixes. The Advice model is adapted using a mixture-of-LoRA experts strategy, enabling specialization without expensive full fine-tuning. Synthetic review–issue–advice triples from Yelp reviews are used for training, and recommendations are evaluated using an eight-dimension operational rubric. The approach outperforms prompting-only and single-adapter baselines, yielding higher actionability and specificity while retaining favorable efficiency–quality trade-offs.",3.38,102.791,347,cold_start,Phi-4,Apple_M1(Metal)
2601.12341v1_Time-Continuous Modeling for Temporal Affective Pa.pdf,Time-Continuous Modeling for Temporal Affective Pattern Recognition in LLM’s,"Rezky M. Kam, Coddy N. Siswanto",,,"affective pattern recognition, temporal modeling, LLM, encoder-decoder architecture, time-continuous patterns, physics informed neural network, affective trajectories, dialogue systems","This paper addresses the limitations of text modality decoder models that rely on discrete token generation, which often results in a lack of true understanding and introduces black-box interpretation of affective dynamics in conversations. The authors propose a hybrid encoder-decoder architecture that utilizes time-aware models based on time-continuous patterns and their correlations with variability in affective states. This approach leverages physics-informed neural networks to enable temporal and longitudinal adaptation, allowing machines to mimic psychological plausibility from user interactions while maintaining computational efficiency and interpretability.",3.02,75.908,229,cold_start,Phi-4,Apple_M1(Metal)
2601.12343v1_How Well Do LLMs Predict Human Behavior A Measure .pdf,How Well Do LLMs Predict Human Behavior? A Measure of their Pretrained Knowledge,"Wayne Gao, Sukjin Han, Annie Liang",,2601.12343v1,"large language models, human behavior prediction, pretrained knowledge, equivalent sample size, machine learning, economic variables, Panel Study of Income Dynamics","Large language models (LLMs) are increasingly used to predict human behavior. This paper proposes a measure for evaluating the knowledge a pretrained LLM brings to such predictions, defined as its equivalent sample size. This measure is estimated by comparing the prediction error of a fixed LLM in a given domain to that of flexible machine learning models trained on increasing samples of domain-specific data. A new asymptotic theory for cross-validated prediction error is developed to provide a statistical inference procedure. The method is applied to the Panel Study of Income Dynamics, revealing that LLMs encode considerable predictive information for some economic variables but much less for others, indicating their varying value as substitutes for domain-specific data across different settings.",3.86,69.129,267,cold_start,Phi-4,Apple_M1(Metal)
2601.12349v1_Zero-Permission Manipulation Can We Trust Large Mu.pdf,Zero-Permission Manipulation: Can We Trust Large Multimodal Model Powered GUI Agents?,"Yi Qian, Kunwei Qian, Xingbang He, Ligeng Chen, Jikang Zhang, Tiantai Zhang, Haiyang Wei, Linzhang Wang, Hao Wu, Bing Mao",,,"GUI agents, multimodal models, Android, security, attack surface, Action Rebinding, Intent Alignment Strategy","Large multimodal model powered GUI agents are emerging as high-privilege operators on mobile platforms, entrusted with perceiving screen content and injecting inputs. This paper demonstrates that the implicit assumption of Visual Atomicity in their design is invalid in Android, creating a critical attack surface. The authors present Action Rebinding, a novel cross-application attack that allows a benign application with zero dangerous permissions to rebind an agent’s execution. They also introduce an Intent Alignment Strategy (IAS) to manipulate the agent’s reasoning process. The study evaluates these attacks on six widely-used Android GUI agents across 15 tasks, showing a 100% success rate for atomic action rebinding and multi-step attack chains. The findings reveal a fundamental architectural flaw in current agent-OS integration and provide insights for the secure design of future autonomous agent systems.",3.26,99.389,324,cold_start,Phi-4,Apple_M1(Metal)
2601.12357v1_SimpleMatch A Simple and Strong Baseline for Seman.pdf,SimpleMatch: A Simple and Strong Baseline for Semantic Correspondence,"Hailong Jin, Huiying Li",,,"semantic correspondence, upsample decoder, multi-scale supervised loss, sparse matching, window-based localization, 4D-correlation, feature-based methods","Recent advances in semantic correspondence have been largely driven by the use of pre-trained large-scale models. However, these approaches depend on high-resolution input images, resulting in considerable computational overhead. This work addresses the issue of irreversible fusion of adjacent keypoint features caused by deep downsampling operations. We present SimpleMatch, a framework for semantic correspondence that performs well even at low resolutions. It includes a lightweight upsample decoder that recovers spatial detail by upsampling deep features to 1/4 resolution, and a multi-scale supervised loss to retain discriminative features across different spatial scales. Sparse matching and window-based localization optimize training memory usage, reducing it by 51%. At a resolution of 252×252, SimpleMatch achieves superior performance with 84.1% PCK@0.1 on the SPair-71k benchmark. This framework provides a practical and efficient baseline for future research in semantic correspondence.",3.27,81.667,267,cold_start,Phi-4,Apple_M1(Metal)
2601.12358v1_From Prompts to Pavement LMMs-based Agentic Behavi.pdf,From Prompts to Pavement: LMMs-based Agentic Behavior-Tree Generation Framework for Autonomous Vehicles,"Omar Y. Goba, Ahmed Y. Gado, Catherine M. Elias, Ahmed Hussein",,,"Behavior-Tree, Large Language Model, L5 Autonomy, Navigation, ROS, CARLA, Nav2","Autonomous vehicles require adaptive behavior planners to navigate unpredictable environments safely. Traditional behavior trees (BTs) are static and require manual tuning, limiting their use at SAE Level 5 autonomy. This paper introduces an agentic framework using large language models (LLMs) and multi-modal vision models (LVMs) to generate and adapt BTs dynamically. A Descriptor agent assesses scene criticality, a Planner agent constructs high-level sub-goals, and a Generator agent synthesizes executable BT sub-trees in XML format. Integrated into a CARLA+Nav2 simulation, the system activates upon baseline BT failure, successfully navigating unexpected obstacles without human intervention. This approach demonstrates potential for diverse driving scenarios, extending beyond static BT baselines.",3.19,86.598,276,cold_start,Phi-4,Apple_M1(Metal)
2601.12374v1_A Scalable Entity-Based Framework for Auditing Bia.pdf,A Scalable Entity-Based Framework for Auditing Bias in LLMs,"Akram Elbouanani, Aboubacar Tuo, Adrian Popescu",,,"bias evaluation, large language models, LLMs, named entities, structural disparities, synthetic data, bias audit, instruction tuning, model scale, prompting strategies, high-stakes applications","This paper introduces a scalable framework for auditing bias in large language models (LLMs) using named entities as probes. The framework addresses the trade-off between ecological validity and statistical control in existing bias evaluation methods. By employing synthetic data, the study conducts the largest bias audit to date, analyzing 1.9 billion data points across various entity types, tasks, languages, models, and prompting strategies. The results reveal systematic biases, such as penalizing right-wing politicians and favoring Western entities. The study finds that while instruction tuning reduces bias, increasing model scale amplifies it, and prompting in Chinese or Russian does not mitigate Western-aligned preferences. The findings underscore the need for rigorous auditing of LLMs before their deployment in high-stakes applications.",3.24,89.324,289,cold_start,Phi-4,Apple_M1(Metal)
2601.12389v1_NADIR Differential Attention Flow for Non-Autoregr.pdf,NADIR: Differential Attention Flow for Non-Autoregressive Transliteration in Indic Languages,"Lakshya Tomar, Vinayak Abrol, Puneet Agarwal",,,"Non-Autoregressive Models, Transliteration, Indic Languages, Differential Attention Flow, Mixture-of-Experts, Transformer Models","This work explores the trade-off between speed and accuracy in sequence-to-sequence tasks, focusing on multilingual transliteration in Indic languages. It introduces NADIR, a novel Non-Autoregressive (NAR) architecture that balances speed and accuracy by integrating a Differential Transformer and a Mixture-of-Experts mechanism. NADIR achieves a significant speed-up compared to Autoregressive (AR) models while maintaining competitive accuracy, reducing various types of errors, and providing a practical blueprint for fast and reliable NAR systems.",2.92,79.522,232,cold_start,Phi-4,Apple_M1(Metal)
2601.12392v1_PsychēChat An Empathic Framework Focused on Emotio.pdf,Psych¯eChat: An Empathic Framework Focused on Emotion Shift Tracking and Safety Risk Analysis in Psychological Counseling,"Zhentao Xia, Yongqi Fan, Yuxiang Chu, Yichao Yin, Liangliang Chen, Tong Ruan, Weiyan Zhang",,,"Psychological Counseling, Emotion Shift Tracking, Safety Risk Analysis, Large Language Models, Emotion Management, Risk Control","Large language models (LLMs) have shown significant advancements in psychological counseling, yet they often fail to explicitly model emotion shifts across sessions, which is crucial in classical psychological approaches. Additionally, aligning counselor responses with these emotion shifts while mitigating safety risks is underexplored. This paper introduces Psych¯eChat, a framework that integrates emotion shift tracking and safety risk analysis for psychological counseling. It employs interactive role-playing to create counselor-seeker dialogues, featuring an Emotion Management Module to capture current emotions and shifts, and a Risk Control Module to anticipate reactions and identify risks. Two modeling paradigms are introduced: the Agent Mode, which structures emotion management, risk control, and responses into a multi-agent pipeline, and the LLM Mode, which integrates these stages into a unified chain-of-thought for end-to-end inference. Extensive experiments demonstrate that Psych¯eChat outperforms existing methods in emotional insight and safety control.",3.29,102.206,336,cold_start,Phi-4,Apple_M1(Metal)
2601.12401v1_Beyond the Dirac Delta Mitigating Diversity Collap.pdf,Beyond the Dirac Delta: Mitigating Diversity Collapse in Reinforcement Fine-Tuning for Versatile Image Generation,"Jinmei Liu, Haoru Li, Zhenhong Sun, Chaofeng Chen, Yatao Bian, Bo Wang, Daoyi Dong, Chunlin Chen, Zhi Wang",,,"Reinforcement Learning, Fine-Tuning, Image Generation, Diversity Collapse, Generative Models, Diffusion Models, Flow Models, Policy Optimization, Reward Shaping","Reinforcement learning (RL) has emerged as a powerful paradigm for fine-tuning large-scale generative models, such as diffusion and flow models, to align with complex human preferences and user-specified tasks. A fundamental limitation remains the curse of diversity collapse, where the objective formulation and optimization landscape inherently collapse the policy to a Dirac delta distribution. To address this challenge, we propose DRIFT (DiveRsity-Incentivized Reinforcement Fine-Tuning for Versatile Image Generation), an innovative framework that systematically incentivizes output diversity throughout the on-policy fine-tuning process, reconciling strong task alignment with high generation diversity to enhance versatility essential for applications that demand diverse candidate generations. We approach the problem across three representative perspectives: i) sampling a reward-concentrated subset that filters out reward outliers to prevent premature collapse; ii) prompting with stochastic variations to expand the conditioning space, and iii) optimization of the intra-group diversity with a potential-based reward shaping mechanism. Experimental results show that DRIFT achieves superior Pareto dominance regarding task alignment and generation diversity, yielding a 9.08%∼43.46% increase in diversity at equivalent alignment levels and a 59.65%∼65.86% increase in alignment at equivalent levels of diversity.",3.44,124.587,429,cold_start,Phi-4,Apple_M1(Metal)
2601.12402v1_Weaknesses of Facial Emotion Recognition Systems.pdf,Weaknesses of Facial Emotion Recognition Systems,"Aleksandra Jamróz, Patrycja Wysocka, Piotr Garbat",,2601.12402v1,"Facial Emotion Recognition, Deep learning, Computer Vision","Emotion detection from faces is a crucial machine learning problem for human-computer interaction. This study reviews various methods and selects three notable solutions and datasets for diversity and image count. Neural networks are trained and tested across different datasets to identify weaknesses in existing solutions, such as dataset differences, varying difficulty in recognizing emotions, and challenges in distinguishing closely related emotions. The study highlights that a network's performance significantly drops when tested on datasets different from the training set, emphasizing the importance of generalization capabilities in determining state-of-the-art status. The motivation for this study is the significant role of emotions in decision-making and interpersonal relationships, with the expectation that human-computer systems will evolve to incorporate emotion recognition for enhanced responses. Computer vision methods are crucial as humans perceive messages predominantly through non-verbal cues like body language and facial expressions. Understanding users' emotional states can lead to more natural human-computer interactions and stronger connections.",3.59,78.517,282,cold_start,Phi-4,Apple_M1(Metal)
2601.12405v1_Explainable Machine Learning for Pediatric Dental .pdf,Explainable Machine Learning for Pediatric Dental Risk Stratification Using Socio-Demographic Determinants,"Manasi Kanade, Abhi Thakkar, Gabriela Fernandes",,,"Explainable AI, Pediatric Dental Risk, Socio-Demographic Determinants, Machine Learning, SHAP, Risk Stratification","Pediatric dental disease is a prevalent and inequitable chronic health condition. This study develops an explainable AI framework for pediatric dental risk stratification, focusing on interpretability and ethical deployment. A supervised machine learning model was trained using socio-demographic data, and its performance was evaluated using ROC analysis and calibration curves. SHAP was used for model explainability, identifying age and income-to-poverty ratio as key risk factors. The framework supports population screening and equitable resource allocation, emphasizing prevention over diagnosis.",3.43,64.415,221,cold_start,Phi-4,Apple_M1(Metal)
2601.12410v1_Are LLMs Smarter Than Chimpanzees An Evaluation on.pdf,Are LLMs Smarter Than Chimpanzees? An Evaluation on Perspective Taking and Knowledge State Estimation,"Dingyi Yang, Junqi Zhao, Xue Li, Ce Li, Boyang Li",,arXiv:2601.12410v1,"LLMs, chimpanzees, perspective taking, knowledge state estimation, theory of mind, cognitive anthropology","This paper evaluates the performance of Large Language Models (LLMs) in knowledge state tracking and estimation, comparing them to human abilities and chimpanzees. The study designs tasks to test if LLMs can detect implausible knowledge in story characters and predict their actions based on available knowledge versus unknown truths. Results show that current LLMs perform near-randomly and are inferior to humans in these tasks. The paper suggests that future LLM research should focus more on knowledge estimation and intention understanding, drawing on cognitive anthropology to highlight the distinction between human and machine intelligence.",3.06,82.079,251,cold_start,Phi-4,Apple_M1(Metal)
2601.12415v1_Orthogonalized Policy OptimizationDecoupling Sampl.pdf,Orthogonalized Policy Optimization: Decoupling Sampling Geometry from Optimization Geometry in RLHF,Wang Zixian,,2601.12415v1,"Large Language Model alignment, PPO, DPO, IPO, sampling geometry, optimization geometry, RLHF, OPO, policy optimization, gradient dynamics, alignment methods","This work explores the implicit conflation of sampling geometry and optimization geometry in alignment methods for large language models, such as PPO, DPO, and IPO. It introduces Orthogonalized Policy Optimization (OPO), which decouples these two aspects by using α-weighted importance sampling and a χ2-induced quadratic regularization. This approach results in a stable optimization process with linear gradient dynamics, avoiding gradient saturation even at high model confidence. OPO provides a unifying perspective on existing alignment methods and a foundation for robust reasoning-oriented training.",3.35,70.839,237,cold_start,Phi-4,Apple_M1(Metal)
2601.12436v1_Purification Before Fusion Toward Mask-Free Speech.pdf,Purification Before Fusion: Toward Mask-Free Speech Enhancement for Robust Audio-Visual Speech Recognition,"Linzhi Wu, Xingyu Zhang, Hao Yuan, Yakun Zhang, Changyan Zheng, Liang Xie, Tiejun Liu, Erwei Yin",,,"audio-visual speech recognition, speech feature enhancement, noise-robust, multimodal bottleneck Conformer","Audio-visual speech recognition (AVSR) improves recognition accuracy in noisy environments by integrating noise-immune visual cues with audio signals. However, high-noise audio inputs can introduce adverse interference during feature fusion. Recent AVSR methods often use mask-based strategies to filter audio noise, risking the loss of semantically relevant information. This work proposes an end-to-end noise-robust AVSR framework with speech enhancement, eliminating the need for explicit noise mask generation. It uses a Conformer-based bottleneck fusion module to refine noisy audio features with video assistance, reducing modality redundancy and enhancing inter-modal interactions. Experimental evaluations on the LRS3 benchmark show that this method outperforms advanced mask-based baselines under noisy conditions.",3.26,87.794,286,cold_start,Phi-4,Apple_M1(Metal)
2601.12442v1_Constraint-Aware Neurosymbolic Uncertainty Quantif.pdf,Constraint-Aware Neurosymbolic Uncertainty Quantification with Bayesian Deep Learning for Scientific Discovery,"Shahnawaz Alam, Mohammed Mudassir Uddin, Mohammed Kaif Pasha",,,"Neurosymbolic AI, Uncertainty Quantification, Bayesian Deep Learning, Scientific Constraints, Calibration, Physics-Informed Machine Learning","Scientific AI applications require models that deliver trustworthy uncertainty estimates while respecting domain constraints. Existing uncertainty quantification methods lack mechanisms to incorporate symbolic scientific knowledge, while neurosymbolic approaches operate deterministically without principled uncertainty modeling. This paper introduces the Constraint-Aware Neurosymbolic Uncertainty Framework (CANUF), unifying Bayesian deep learning with differentiable symbolic reasoning. The architecture comprises automated constraint extraction from scientific literature, a probabilistic neural backbone with variational inference, and a differentiable constraint satisfaction layer ensuring physical consistency. Experiments on the Materials Project, QM9 molecular properties, and climate benchmarks show CANUF reduces Expected Calibration Error by 34.7% versus Bayesian neural networks while maintaining 99.2% constraint satisfaction. Ablations reveal constraint-guided recalibration contributes 18.3% performance gain, with constraint extraction achieving 91.4% precision. CANUF provides the first end-to-end differentiable pipeline simultaneously addressing uncertainty quantification, constraint satisfaction, and interpretable explanations for scientific predictions.",3.47,94.218,327,cold_start,Phi-4,Apple_M1(Metal)
2601.12443v1_Adversarial Defense in Vision-Language Models An O.pdf,Adversarial Defense in Vision-Language Models: An Overview,"Xiaowei Fu, Lei Zhang",,,"VLMs, adversarial defense, survey","The widespread use of Vision Language Models (VLMs), such as CLIP, has raised concerns about their vulnerability to sophisticated and imperceptible adversarial attacks, which could compromise model performance and system security in cross-modal tasks. To address this challenge, three main defense paradigms have been proposed: Training-time Defense, Test-time Adaptation Defense, and Training-free Defense. Training-time Defense involves modifying the training process through adversarial fine-tuning to improve robustness to adversarial examples, though it requires substantial computational resources and may not generalize across all attacks. Test-time Adaptation Defense adapts the model at inference time by updating its parameters to handle unlabeled adversarial examples, offering flexibility but often at the cost of increased complexity and computational overhead. Training-free Defense avoids modifying the model itself, instead focusing on altering adversarial inputs or their feature embeddings to mitigate the impact of attacks without additional training. This survey reviews the latest advancements in adversarial defense strategies for VLMs, highlighting the strengths and limitations of such approaches and discussing ongoing challenges in enhancing the robustness of VLMs.",3.35,89.531,300,cold_start,Phi-4,Apple_M1(Metal)
2601.12444v1_Large Language Model for OWL Proofs.pdf,Large Language Model for OWL Proofs,"Hui Yang, Jiaoyan Chen, Uli Sattler",https://doi.org/10.1145/XXXXXX.XXXXXX,,"Computing methodologies, Description logics, Natural language generation","The ability of Large Language Models (LLMs) to perform reasoning tasks such as deduction has been widely investigated in recent years. Yet, their capacity to generate proofs—faithful, human-readable explanations of why conclusions follow—remains largely underexplored. This work studies proof generation in the context of OWL ontologies by developing an automated dataset construction and evaluation framework. The evaluation encompasses three sequential tasks for complete proving: Extraction, Simplification, and Explanation, as well as an additional task of assessing Logic Completeness of the premise. Through extensive experiments on widely used reasoning LLMs, important findings include: (1) Some models achieve overall strong results but remain limited on complex cases; (2) Logical complexity, rather than representation format (formal logic language versus natural language), is the dominant factor shaping LLM performance; and (3) Noise and incompleteness in input data substantially diminish LLMs’ performance. These results underscore both the promise of LLMs for explanation with rigorous logics and the gap of supporting resilient reasoning under complex or imperfect conditions.",3.24,98.189,318,cold_start,Phi-4,Apple_M1(Metal)
2601.12449v1_AgenTRIM Tool Risk Mitigation for Agentic AI.pdf,AGENTRIM: Tool Risk Mitigation for Agentic AI,"Roy Betser, Shamik Bose, Amit Giloni, Chiara Picardi, Sindhu Padakandla, Roman Vainshtein",,,"AI agents, LLMs, tool permissions, security risks, tool-driven agency, AGENTRIM, framework, least-privilege tool access, AgentDojo benchmark, safety policies","AI agents are autonomous systems that combine Large Language Models (LLMs) with external tools to solve complex tasks. While these tools extend capability, improper tool permissions introduce security risks such as indirect prompt injection and tool misuse. This paper introduces AGENTRIM, a framework for detecting and mitigating tool-driven agency risks without altering an agent’s internal reasoning. AGENTRIM operates in offline and online phases, reconstructing and verifying the agent’s tool interface from code and execution traces, and enforcing least-privilege tool access at runtime. Evaluations on the AgentDojo benchmark show that AGENTRIM reduces attack success while maintaining high task performance, demonstrating its effectiveness in ensuring safer tool use in LLM-based agents.",3.23,92.629,299,cold_start,Phi-4,Apple_M1(Metal)
2601.12465v1_Incentivizing In-depth Reasoning over Long Context.pdf,INCENTIVIZING IN-DEPTH REASONING OVER LONG CONTEXTS WITH PROCESS ADVANTAGE SHAPING,"Miao Peng, Weizhou Shen, Nuo Chen, Chenliang Li, Ming Yan, Jia Li",,,"Reinforcement Learning, Long-context Reasoning, Knowledge Graphs, Multi-hop QA, Process Advantage Shaping","Reinforcement Learning with Verifiable Rewards (RLVR) enhances short-context reasoning in LLMs but struggles with long-context scenarios requiring precise grounding and robust reasoning. The 'almost-there' phenomenon, where trajectories are mostly correct but fail at the final step, is attributed to low reasoning density in long-context QA data and loss of learning signals from partially correct trajectories. The proposed DEEPREASONQA framework constructs high-difficulty, multi-hop QA pairs, while LONGPAS performs fine-grained credit assignment by evaluating reasoning steps along validity and relevance dimensions. Experiments show substantial performance improvements over RLVR baselines and competitive results with frontier LLMs using fewer parameters.",3.18,84.844,270,cold_start,Phi-4,Apple_M1(Metal)
2601.12467v1_Patch-Level Tokenization with CNN Encoders and Att.pdf,Patch-Level Tokenization with CNN Encoders and Attention for Improved Transformer Time-Series Forecasting,Saurish Nagrath,,,"Multivariate time-series forecasting, financial time-series forecasting, Transformer models, temporal tokenization, convolutional neural networks, attention mechanisms, representation learning, deep learning for finance","Transformer-based models have shown strong performance in time-series forecasting by leveraging self-attention to model long-range temporal dependencies. However, their effectiveness depends critically on the quality and structure of input representations derived from raw multivariate time-series data. This work proposes a two-stage forecasting framework that explicitly separates local temporal representation learning from global dependency modelling. In the first stage, a convolutional neural network (CNN) operates on fixed-length temporal patches to extract short-range temporal dynamics and non-linear feature interactions, producing compact patch-level token embeddings. Token-level self-attention is subsequently applied during representation learning to refine these embeddings by enabling interactions across temporal patches. In the second stage, a Transformer encoder processes the resulting token sequence to model inter-patch temporal dependencies and generate per-patch forecasts. Experiments conducted on synthetic multivariate time-series data with controlled static and dynamic factors demonstrate that the proposed patch-based tokenization strategy achieves competitive forecasting performance compared to convolutional and patch-based Transformer baselines. The results highlight the importance of structured temporal representations and show that decoupling local temporal encoding from global attention-based modelling yields more effective and stable time-series forecasting.",3.5,96.676,338,cold_start,Phi-4,Apple_M1(Metal)
2601.12471v1_Knowing When to Abstain Medical LLMs Under Clinica.pdf,Knowing When to Abstain: Medical LLMs Under Clinical Uncertainty,"Sravanthi Machcha, Sushrita Yerra, Sahil Gupta, Aishwarya Sahoo, Sharmin Sultana, Hong Yu, Zonghai Yao",,,"large language models, medical multiple-choice question answering, abstention, conformal prediction, adversarial question perturbations, uncertainty, reliability, high-stakes applications","Current evaluation of large language models (LLMs) prioritizes accuracy, but in real-world and safety-critical applications, the ability to abstain when uncertain is equally vital for trustworthy deployment. This paper introduces MedAbstain, a benchmark and evaluation protocol for abstention in medical multiple-choice question answering (MCQA), integrating conformal prediction, adversarial question perturbations, and explicit abstention options. The evaluation reveals that even high-accuracy models often fail to abstain when uncertain. Providing explicit abstention options increases model uncertainty and safer abstention more effectively than input perturbations, while scaling model size or advanced prompting brings little improvement. These findings highlight the importance of abstention mechanisms for trustworthy LLM deployment and offer practical guidance for improving safety in high-stakes applications.",3.11,102.603,319,cold_start,Phi-4,Apple_M1(Metal)
2601.12494v1_Harmonizing the Arabic Audio Space with Data Sched.pdf,Harmonizing the Arabic Audio Space with Data Scheduling,"Hunzalah Hassan Bhatti, Firoj Alam, Shammur Absar Chowdhury",,,"Arabic Audio Space, Data Scheduling, Audio Large Language Models, Instruction Tuning, Multi-task Learning, Arabic-centric Audio LLM, Generative Tasks, Discriminative Tasks, Dialect Identification, Emotion Recognition, Speech Summarization, Task-Progressive Curriculum, Aligner-Based Diverse Sampling, Gradient Volatility, Negative Transfer, Hybrid TPC+ADS Strategy, Omni-models, Low-resource Multimodal Environments","This paper presents a systematic study of multi-task instruction tuning for an Arabic-centric audio large language model (LLM), addressing the adaptation challenges in linguistically complex, dialect-rich settings. The study introduces AraMega-SSum, a novel dataset for Arabic speech summarization, and evaluates the fine-tuning of Qwen2.5-Omni (7B) using Task-Progressive Curriculum (TPC) and Aligner-Based Diverse Sampling (ADS). The results highlight a trade-off between efficiency and robustness, with ADS accelerating convergence but causing gradient volatility, and TPC stabilizing core acoustic mapping but inducing negative transfer. A Hybrid TPC+ADS Strategy is proposed as an optimal training approach, providing a robust foundation and capturing fine-grained nuances. These findings offer practical guidance for adapting Omni-models in complex, low-resource multimodal environments.",3.32,114.827,381,cold_start,Phi-4,Apple_M1(Metal)
2601.12499v1_Failure Modes in Multi-Hop QA The Weakest Link Law.pdf,Failure Modes in Multi-Hop QA: The Weakest Link Law and the Recognition Bottleneck,"Meiru Zhang, Zaiqiao Meng, Nigel Collier",,,"Multi-Hop QA, Large Language Models, position bias, Multi-Focus Attention Instruction, Weakest Link Law, recognition failure, synthesis failure, System-2 reasoning","Despite scaling to massive context windows, Large Language Models (LLMs) struggle with multi-hop reasoning due to inherent position bias, which causes them to overlook information at certain positions. The study introduces Multi-Focus Attention Instruction (MFAI) to disentangle recognition and synthesis failures. Across 5 LLMs on two multi-hop QA tasks, the 'Weakest Link Law' is established: multi-hop reasoning performance collapses to the level of the least visible evidence, governed by absolute position rather than linear distance between facts. MFAI resolves recognition bottlenecks, improving accuracy in low-visibility positions, while misleading MFAI triggers confusion in real-world tasks. 'Thinking' models utilizing System-2 reasoning effectively locate and integrate required information, matching gold-only baselines even in noisy, long-context settings.",3.15,93.467,294,cold_start,Phi-4,Apple_M1(Metal)
2601.12518v1_Cooperative Multi-agent RL with Communication Cons.pdf,Cooperative Multi-agent RL with Communication constraints,"Nuoya Xiong, Aarti Singh",,,"Cooperative Multi-agent RL, Communication constraints, Importance sampling, Base policy prediction, ε-Nash equilibrium, Potential games, Markov Cooperative Games, Communication cost, Sample complexity","Cooperative Multi-agent reinforcement learning (MARL) often assumes frequent access to global information, which is unrealistic in decentralized systems due to high communication costs. This paper proposes a technique called base policy prediction to address the instability of importance sampling under limited communication. The approach predicts policy updates using old gradients, reducing the gap between base and current policies, and enables effective learning with fewer communication rounds. The algorithm converges to an ε-Nash equilibrium in potential games with reduced communication rounds and sample complexity. Empirical tests in simulated games and MAPPO show significant reductions in communication costs while maintaining performance. The paper extends results to general Markov Cooperative Games to find agent-wise local maxima.",3.16,73.763,233,cold_start,Phi-4,Apple_M1(Metal)
2601.12522v1_Improved Bug Localization with AI Agents Leveragin.pdf,Improved Bug Localization with AI Agents Leveraging Hypothesis and Dynamic Cognition,"Asif Mohammed Samir, Mohammad Masudur Rahman",https://doi.org/XXXXXXX.XXXXXXX,,"Bug Localization, LLM, Agentic AI, Cognition, Debugging, Software Engineering, Information Retrieval","Software bugs cost technology providers billions annually and cause developers to spend roughly 50% of their time on bug resolution. Traditional methods for bug localization often analyze the suspiciousness of code components in isolation, overlooking their connections with other components in the codebase. Recent advances in Large Language Models (LLMs) and agentic AI techniques have shown strong potential for code understanding, but still lack causal reasoning during code exploration and struggle to manage growing context effectively, limiting their capability. In this paper, we present a novel agentic technique for bug localization –CogniGent– that overcomes the limitations above by leveraging multiple AI agents capable of causal reasoning, call-graph-based root cause analysis and context engineering. It emulates developers-inspired debugging practices (a.k.a., dynamic cognitive debugging) and conducts hypothesis testing to support bug localization. We evaluate CogniGent on a curated dataset of 591 bug reports using three widely adopted performance metrics and compare it against six established baselines from the literature. Experimental results show that our technique consistently outperformed existing traditional and LLM-based techniques, achieving MAP improvements of 23.33-38.57% at the document and method levels. Similar gains were observed in MRR, with increases of 25.14-53.74% at both granularity levels. Statistical significance tests also confirm the superiority of our technique. By addressing the reasoning, dependency, and context limitations, CogniGent advances the state of bug localization, bridging human-like cognition with agentic automation for improved performance.",3.46,123.625,428,cold_start,Phi-4,Apple_M1(Metal)
2601.12534v1_Encoding Emotion Through Self-Supervised Eye Movem.pdf,ENCODING EMOTION THROUGH SELF-SUPERVISED EYE MOVEMENT RECONSTRUCTION,"Marcus Ma, Jordan Prescott, Emily Zhou, Tiantian Feng, Kleanthis Avramidis, Gabor Mihaly Toth, Shrikanth Narayanan",,,"eye movement, self-supervised learning, emotion prediction, deep learning","The relationship between emotional expression and eye movement is well-documented, with gaze patterns being reliable indicators of emotion. However, most studies use specialized, high-resolution eye-tracking equipment, limiting the reach of findings. This study investigates predicting multimodal markers of emotional expression from naturalistic, low-resolution videos. Utilizing video interviews from the USC Shoah Foundation’s Visual History Archive, a novel gaze detection model is developed using self-supervised eye movement reconstruction. This model's encoder embeddings are used to fine-tune models on tasks related to emotional expression, such as aligning eye movement with directional emotion estimates from speech and predicting emotional behaviors like laughing, crying/sobbing, and sighing. The study finds that self-supervised eye movement reconstruction effectively encodes the affective signals in eye movements.",3.29,87.158,287,cold_start,Phi-4,Apple_M1(Metal)
2601.12535v1_Improving Low-Resource Machine Translation via Rou.pdf,Improving Low-Resource Machine Translation via Round-Trip Reinforcement Learning,"Ahmed Attia, Alham Fikri",,,"low-resource machine translation, reinforcement learning, round-trip bootstrapping, NLLB models, self-supervised fine-tuning, BLEU, chrF++","This paper explores a self-supervised reinforcement-learning-based fine-tuning approach for improving low-resource machine translation (MT) using round-trip bootstrapping with the No Language Left Behind (NLLB) models. The method involves translating English into a low-resource language and back into English, optimizing the process with BLEU and chrF++ as reward functions. The approach shows consistent improvements in translation quality for languages like Central Aymara, Friulian, Wolof, and Russian, indicating increased fluency and semantic fidelity. The paper argues that this method can benefit from scaling, allowing models to leverage their pretrained knowledge and continue self-improving.",3.09,80.635,249,cold_start,Phi-4,Apple_M1(Metal)
2601.12538v1_Agentic Reasoning for Large Language Models.pdf,Agentic Reasoning for Large Language Models,"Tianxin Wei, Ting-Wei Li, Zhining Liu, Xuying Ning, Ze Yang, Jiaru Zou, Zhichen Zeng, Ruzhong Qiu, Xiao Lin, Dongqi Fu, Zihao Li, Mengting Ai, Duo Zhou, Wenxuan Bao, Yunzhe Li, Gaotang Li, Cheng Qian, Yu Wang, Xiangru Tang, Yin Xiao, Liri Fang, Hui Liu, Xianfeng Tang, Yuji Zhang, Chi Wang, Jiaxuan You, Heng Ji, Hanghang Tong, Jingrui He",,arXiv:2601.12538v1,"Agentic AI, LLM Agent, Agentic Reasoning, Self-evolving","Reasoning is a fundamental cognitive process underlying inference, problem-solving, and decision-making. While large language models (LLMs) demonstrate strong reasoning capabilities in closed-world settings, exemplified by standard benchmarks in mathematics and code, they struggle in open-ended and dynamic environments. The emergence of agentic reasoning marks a paradigm shift, bridging thought and action by reframing LLMs as autonomous agents that plan, act, and learn through continual interaction. In this survey, we provide a systematic roadmap by organizing agentic reasoning along three complementary dimensions. First, we characterize environmental dynamics through three layers: foundational agentic reasoning establishes core single-agent capabilities, including planning, tool use, and search, that operate in stable environments; self-evolving agentic reasoning examines how agents refine these capabilities through feedback, memory, and adaptation in evolving settings; and collective multi-agent reasoning extends intelligence to collaborative scenarios where multiple agents coordinate roles, share knowledge, and pursue shared goals. Across all layers, we analyze system constraints and optimization settings by distinguishing in-context reasoning, which scales test-time interaction through structured orchestration and adaptive workflow design, from post-training reasoning, which optimizes behaviors through reinforcement learning and supervised fine-tuning. We further review and contextualize agentic reasoning frameworks in real-world applications and benchmarks spanning science, robotics, healthcare, autonomous research, and math, illustrating how different reasoning mechanisms are instantiated and evaluated across domains. This survey synthesizes agentic reasoning methods into a unified roadmap that bridges thoughts and actions, offering actionable guidance for agentic systems across environmental dynamics, optimization settings, and agent interaction settings. Finally, we outline open challenges and future directions, situating how agentic reasoning has developed while identifying what remains ahead: personalization, long-horizon interaction, world modeling, scalable multi-agent training, and governance frameworks for real-world deployment.",3.76,172.389,648,cold_start,Phi-4,Apple_M1(Metal)
2601.12539v1_MemeLens Multilingual Multitask VLMs for Memes.pdf,MemeLens: Multilingual Multitask VLMs for Memes,"Ali Ezzat Shahroor, Mohamed Bayan Kmainasi, Abul Hasnat, Dimitar Dimitrov, Giovanni Da San Martino, Preslav Nakov, Firoj Alam",,,"memes, multilingual, multitask, vision language models, meme understanding, multimodal training, cross-domain generalization","Memes are a dominant medium for online communication and manipulation, with meaning emerging from interactions between embedded text, imagery, and cultural context. Existing meme research is distributed across tasks and languages, limiting cross-domain generalization. This paper proposes MEMELENS, a unified multilingual and multitask explanation-enhanced Vision Language Model (VLM) for meme understanding. It consolidates 38 public meme datasets, mapping dataset-specific labels into a shared taxonomy of 20 tasks. The paper presents an empirical analysis across modeling paradigms, task categories, and datasets, suggesting that robust meme understanding requires multimodal training and is sensitive to over-specialization. The experimental resources and datasets will be made publicly available for the community.",3.16,94.201,298,cold_start,Phi-4,Apple_M1(Metal)
2601.12542v1_Rethinking the AI Scientist Interactive Multi-Agen.pdf,Rethinking the AI Scientist: Interactive Multi-Agent Workflows for Scientific Discovery,"Lukas Weidener, Marko Brkić, Mihailo Jovanović, Ritvik Singh, Chiara Baccin, Emre Ulgac, Alex Dobrin, Aakaash Meduri",,,"artificial intelligence, scientific discovery, multi-agent system, interactive investigation, computational biology, novelty detection, research workflows","This paper introduces Deep Research, a multi-agent system enabling interactive scientific investigation with rapid turnaround times. The system comprises specialized agents for planning, data analysis, literature search, and novelty detection, unified through a persistent world state. It supports semi-autonomous and fully autonomous operational modes. Evaluation on the BixBench computational biology benchmark demonstrated state-of-the-art performance, achieving 48.8% accuracy on open response and 64.5% on multiple-choice evaluation, exceeding existing baselines by 14 to 26 percentage points. The paper also discusses architectural constraints and practical deployment considerations for AI-assisted scientific workflows.",3.04,92.804,282,cold_start,Phi-4,Apple_M1(Metal)
2601.12547v1_How Clinicians Think and What AI Can Learn From It.pdf,"Ordinal-First, Robust Decision Algorithms for Medicine","Dr. Dipayan Sengupta, MD (Dermatology), Dr. Saumya Panda, MD (Dermatology)",,arXiv:2601.12547v1,"clinical artificial intelligence, decision-making, ordinal non-compensatory algorithms, robust decision algorithms, medicine, lexicographic heuristics, clinical reasoning, AI blueprint, judgment-and-decision-making","Most clinical AI systems are built as prediction engines, yet real clinical reasoning involves sequential decision-making under uncertainty. Clinicians often use ordinal non-compensatory decision-making, relying on fast-and-frugal heuristics. This paper argues that such algorithms are epistemically preferred in medicine due to the weak measurability of clinical trade-offs and the crude nature of preference and signal elicitation. It outlines a clinician-aligned AI blueprint that emphasizes robust ordinal decision rules and selective complexity for decision-making.",3.19,78.585,251,cold_start,Phi-4,Apple_M1(Metal)
2601.12549v1_Benchmarking Concept-Spilling Across Languages in .pdf,Benchmarking Concept-Spilling Across Languages in LLMs,"Ilia Badanin, Daniil Dzenhaliou, Imanol Schlag",,arXiv:2601.12549v1,"multilingual large language models, semantic robustness, language spilling, polysemous words, semantic interference, linguistic balance","This paper introduces a novel framework for evaluating multilingual semantic robustness in Large Language Models (LLMs) by measuring how they handle polysemous words across languages. The study identifies a phenomenon called 'language spilling,' where models exhibit bias toward dominant languages, leading to semantic interference in non-English content generation. The authors present a comparative methodology that assesses model performance based on their ability to generate meanings from the target language before resorting to dominant-language meanings. The research evaluates various multilingual LLMs using a structured meaning generation task across nine languages, employing a benchmark of 100 high-polysemy English words. The findings reveal significant variation in semantic robustness across models and languages, offering a ranking system for model comparison. The paper contributes a scalable benchmark and a validation pipeline for developing more linguistically balanced AI systems.",3.42,85.973,294,cold_start,Phi-4,Apple_M1(Metal)
2601.12554v1_Artificial Intelligence in Materials Science and E.pdf,"Artificial Intelligence in Materials Science and Engineering: Current Landscape, Key Challenges, and Future Trajectories","Iman Peivaste, Salim Belouettar, Francesco Mercuri, Nicholas Fantuzzi, Hamidreza Dehghani, Razieh Izadi, Halliru Ibrahim, Jakub Lengiewicz, Maël Belouettar-Mathis, Kouider Bendine, Ahmed Makradi, Martin Hörsch, Peter Klein, Mohamed El Hachemi, Heinz A. Preisig, Yacine Rezgui, Natalia Konchakova, Ali Daouadji",,2601.12554v1,"Artificial Intelligence, Materials Science, Machine Learning, Deep Learning, Generative AI, Probabilistic Models, Data Representation, Featurization, Materials Design","Artificial Intelligence is rapidly transforming materials science and engineering, offering powerful tools to navigate complexity, accelerate discovery, and optimize material design in ways previously unattainable. Driven by the accelerating pace of algorithmic advancements and increasing data availability, AI is becoming an essential competency for materials researchers. This review provides a comprehensive and structured overview of the current landscape, synthesizing recent advancements and methodologies for materials scientists seeking to effectively leverage these data-driven techniques. It surveys the spectrum of machine learning approaches, from traditional algorithms to advanced deep learning architectures, including CNNs, GNNs, and Transformers, alongside emerging generative AI and probabilistic models such as Gaussian Processes for uncertainty quantification. The review also examines the pivotal role of data in this field, emphasizing how effective representation and featurization strategies, spanning compositional, structural, image-based, and language-inspired approaches, combined with appropriate preprocessing, fundamentally underpin the performance of machine learning models.",3.67,124.479,457,cold_start,Phi-4,Apple_M1(Metal)
2601.12557v1_Life Machine Learning and the Search for Habitabil.pdf,"Life, Machine Learning, and the Search for Habitability: Predicting Biosignature Fluxes for the Habitable Worlds Observatory","Mark Moussa, Amber V. Young, Brianna Isola, Vasuda Trehan, Michael D. Himes, Nicholas Wogan, Giada Arney",,,"machine learning, biosignature, exoplanetary spectra, Habitable Worlds Observatory, Bayesian Convolutional Neural Network, Spectral Query Adaptive Transformer","This paper introduces two advanced machine-learning architectures for predicting biosignature species fluxes from exoplanetary reflected-light spectra: a Bayesian Convolutional Neural Network (BCNN) and a novel model, the Spectral Query Adaptive Transformer (SQuAT). The BCNN quantifies uncertainties, while SQuAT enhances interpretability by associating spectral features with specific biosignature species. Both models demonstrate high predictive accuracy and offer distinct advantages in uncertainty quantification and spectral interpretability, making them valuable for optimizing observation schedules and maximizing scientific return for missions like NASA's Habitable Worlds Observatory.",3.22,86.144,277,cold_start,Phi-4,Apple_M1(Metal)
2601.12560v1_Agentic Artificial Intelligence AI Architectures T.pdf,"Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents","Arunkumar V, Gangadharan G.R., Rajkumar Buyya",,arXiv:2601.12560v1,"Agentic AI, Large Language Models, Autonomous Agents, Multi-Agent Systems, Cognitive Architectures, Tool Use, Planning","Artificial Intelligence is transitioning from models that generate text to Agentic AI, where systems act as autonomous entities capable of perceiving, reasoning, planning, and acting. Large Language Models (LLMs) are evolving from passive knowledge engines to cognitive controllers that integrate memory, tool use, and environmental feedback to achieve extended goals. This evolution supports the automation of complex workflows in areas such as software engineering, scientific discovery, and web navigation. The paper investigates various architectures and proposes a unified taxonomy categorizing agents into Perception, Brain, Planning, Action, Tool Use, and Collaboration. It describes the shift from linear reasoning to native inference time reasoning models and from fixed API calls to open standards like the Model Context Protocol (MCP) and Native Computer Use. The paper also reviews the environments where these agents operate, including digital operating systems and embodied robotics, and examines current evaluation practices. It highlights challenges such as hallucination in action, infinite loops, and prompt injection, and outlines future research directions for developing more robust and reliable autonomous systems.",3.6,95.055,342,cold_start,Phi-4,Apple_M1(Metal)
2601.12577v1_Primate-like perceptual decision making emerges th.pdf,Primate-like perceptual decision making emerges through deep recurrent reinforcement learning,"Nathan J. Wispinski, Scott A. Stone, Anthony Singhal, Patrick M. Pilarski, Craig S. Chapman",,2601.12577v1,"decision making, primate, reinforcement learning, neural mechanisms, evidence accumulation, deep recurrent neural network","This study explores the emergence of primate-like decision-making mechanisms through deep recurrent reinforcement learning. The research investigates why such mechanisms exist by training a neural network on a noisy perceptual discrimination task. The network developed abilities akin to primate decision-making, such as balancing speed and accuracy and adapting to new information. The findings support the theory that these mechanisms evolved to optimize reward in uncertain environments, aligning with observed primate neurophysiological behaviors.",3.18,70.04,223,cold_start,Phi-4,Apple_M1(Metal)
2601.12582v1_Ontology-aligned structuring and reuse of multimod.pdf,Ontology-aligned structuring and reuse of multimodal materials data and workflows towards automatic reproduction,"Sepideh Baghaee Ravari, Abril Azocar Guzman, Sarath Menon, Stefan Sandfeld, Tilmann Hickel, Markus Stricker",,,"text mining, workflow, large language models, stacking fault energy","Reproducibility of computational results remains a challenge in materials science, as simulation workflows and parameters are often reported only in unstructured text and tables. An ontology-driven, large language model (LLM)-assisted framework is introduced for the automated extraction and structuring of computational workflows from the literature. The approach focuses on density functional theory-based stacking fault energy (SFE) calculations in hexagonal close-packed magnesium and its binary alloys, using a multi-stage filtering strategy and prompt-engineered LLM extraction applied to method sections and tables. Extracted information is unified into a canonical schema and aligned with established materials ontologies (CMSO, ASMO, and PLDO), enabling the construction of a knowledge graph using atomRDF. The resulting knowledge graph enables systematic comparison of reported SFE values and supports the structured reuse of computational protocols. While full computational reproducibility is still constrained by missing or implicit metadata, the framework provides a foundation for organizing and contextualizing published results in a semantically interoperable form, thereby improving transparency and reusability of computational materials data.",3.48,98.81,344,cold_start,Phi-4,Apple_M1(Metal)
2601.12585v1_Do MLLMs See What We See Analyzing Visualization L.pdf,Do MLLMs See What We See? Analyzing Visualization Literacy Barriers in AI Systems,"Mengli (Dawn) Duan, Yuhe (Sissi) Jiang, Matthew Varona, Carolina Nobre",xx.xxxx/TVCG.201x,,"Visualization Literacy, Multimodal Large Language Model, Evaluation Study","Multimodal Large Language Models (MLLMs) are increasingly used to interpret visualizations, yet little is known about why they fail. This study presents the first systematic analysis of barriers to visualization literacy in MLLMs. Using the regenerated Visualization Literacy Assessment Test (reVLAT) benchmark with synthetic data, the study analyzes 309 erroneous responses from four state-of-the-art models. The analysis yields a taxonomy of MLLM failures, revealing two machine-specific barriers that extend prior human-participation frameworks. The results show that models perform well on simple charts but struggle with color-intensive, segment-based visualizations, often failing to form consistent comparative reasoning. These findings inform future evaluation and design of reliable AI-driven visualization assistants.",3.2,84.113,269,cold_start,Phi-4,Apple_M1(Metal)
2601.12594v1_SLAP Scalable Language-Audio Pretraining with Vari.pdf,SLAP: SCALABLE LANGUAGE-AUDIO PRETRAINING WITH VARIABLE-DURATION AUDIO AND MULTI-OBJECTIVE TRAINING,"Xinhao Mei, Gael Le Lan, Haohe Liu, Zhaoheng Ni, V arun Nagaraja, Yang Liu, Yangyang Shi, Vikas Chandra",,,"Multimodal learning, CLAP, self-supervised learning, contrastive learning, multi-objective learning","Contrastive language-audio pretraining (CLAP) has achieved notable success in learning semantically rich audio representations and is widely adopted for various audio-related tasks. However, current CLAP models face several key limitations, including training on relatively small datasets, restriction to short and fixed-duration audio, and reliance on global representations. To address these challenges, we introduce Scalable Language-Audio Pretraining (SLAP), which scales language-audio pretraining to 109 million audio-text pairs with variable audio durations and incorporates multiple training objectives. SLAP unifies contrastive loss with additional self-supervised and captioning losses in a single-stage training, facilitating the learning of richer dense audio representations. The proposed SLAP model achieves new state-of-the-art performance on audio-text retrieval and zero-shot audio classification tasks, demonstrating its effectiveness across diverse benchmarks.",3.4,93.705,319,cold_start,Phi-4,Apple_M1(Metal)
2601.12607v1_A Cloud-based Multi-Agentic Workflow for Science.pdf,A Cloud-based Multi-Agentic Workflow for Science,"Anurag Acharya, Timothy Vega, Rizwan A. Ashraf, Anshu Sharma, Derek Parker, Robert Rallo",10.1145/nnnnnnn.nnnnnnn,,"Large Language Models, LLMs for Science, LLM Agents, Multi-agent Framework, Catalysis, Chemistry, Material Science, Cloud Computing","As Large Language Models (LLMs) become ubiquitous across various scientific domains, their lack of ability to perform complex tasks like running simulations or to make complex decisions limits their utility. LLM-based agents bridge this gap due to their ability to call external resources and tools and thus are now rapidly gaining popularity. However, coming up with a workflow that can balance the models, cloud providers, and external resources is very challenging, making implementing an agentic system more of a hindrance than a help. In this work, we present a domain-agnostic, model-independent workflow for an agentic framework that can act as a scientific assistant while being run entirely on cloud. Built with a supervisor agent marshaling an array of agents with individual capabilities, our framework brings together straightforward tasks like literature review and data analysis with more complex ones like simulation runs. We describe the framework here in full, including a proof-of-concept system we built to accelerate the study of Catalysts, which is highly important in the field of Chemistry and Material Science. We report the cost to operate and use this framework, including the breakdown of the cost by services use. We also evaluate our system on a custom-curated synthetic benchmark and a popular Chemistry benchmark, and also perform expert validation of the system. The results show that our system is able to route the task to the correct agent 90% of the time and successfully complete the assigned task 97.5% of the time for the synthetic tasks and 91% of the time for real-world tasks, while still achieving better or comparable accuracy to most frontier models, showing that this is a viable framework for other scientific domains to replicate.",3.39,142.266,482,cold_start,Phi-4,Apple_M1(Metal)
2601.12617v1_Creating Disability Story Videos with Generative A.pdf,"Creating Disability Story Videos with Generative AI: Motivation, Expression, and Sharing","Shuo Niu, Dylan Clements, Hyungsin Kim",10.1145/3772318.3791495,,"Disability, Storytelling, Video, Generative AI, LLM","Generative AI (GenAI) is both promising and challenging in supporting people with disabilities (PwDs) in creating stories about disability. GenAI can reduce barriers to media production and inspire the creativity of PwDs, but it may also introduce biases and imperfections that hinder its adoption for personal expression. This research examines how nine PwDs from a disability advocacy group used GenAI to create videos sharing their disability experiences. Grounded in digital storytelling theory, the study explores the motivations, expression, and sharing of PwD-created GenAI story videos. A framework of momentous depiction is concluded, highlighting four core affordances of GenAI that either facilitate or require improvements to better support disability storytelling: non-capturable depiction, identity concealment and representation, contextual realism and consistency, and emotional articulation. Based on this framework, design implications for GenAI in relation to story completion, media formats, and corrective mechanisms are discussed.",3.13,97.273,304,cold_start,Phi-4,Apple_M1(Metal)
2601.12637v1_Topology-Aware Multiscale Mixture of Experts for E.pdf,Topology-Aware Multiscale Mixture of Experts for Efficient Molecular Property Prediction,"Long D. Nguyen, Kelin Xia, Binh P. Nguyen",,arXiv:2601.12637v1,"Graph Neural Networks, Topological Deep Learning, Mixture of Experts, Molecular Representation","Many molecular properties depend on 3D geometry, where non-covalent interactions, stereochemical effects, and medium- to long-range forces are determined by spatial distances and angles that cannot be uniquely captured by a 2D bond graph. Most 3D molecular graph neural networks still rely on globally fixed neighborhood heuristics, typically defined by distance cutoffs and maximum neighbor limits, to define local message-passing neighborhoods, leading to rigid, data-agnostic interaction budgets. We propose Multiscale Interaction Mixture of Experts (MI-MoE) to adapt interaction modeling across geometric regimes. Our contributions are threefold: (1) we introduce a distance-cutoff expert ensemble that explicitly captures short-, mid-, and long-range interactions without committing to a single cutoff; (2) we design a topological gating encoder that routes inputs to experts using filtration-based descriptors, including persistent homology features, summarizing how connectivity evolves across radii; and (3) we show that MI-MoE is a plug-in module that consistently improves multiple strong 3D molecular backbones across diverse molecular and polymer property prediction benchmark datasets, covering both regression and classification tasks. These results highlight topology-aware multiscale routing as an effective principle for 3D molecular graph learning.",3.49,104.851,366,cold_start,Phi-4,Apple_M1(Metal)
2601.12638v1_Mixed Precision PointPillars for Efficient 3D Obje.pdf,Mixed Precision PointPillars for Efficient 3D Object Detection with TensorRT,"Ninnart Fuengfusin, Keisuke Yoneda, Naoki Suganuma",,,"neural networks, quantization, 3D object detection","LIDAR 3D object detection is crucial for autonomous vehicles, requiring real-time operation. Model quantization can accelerate runtime, but direct application often leads to performance degradation due to LIDAR's wide numerical distributions and extreme outliers. This paper proposes a mixed precision framework for PointPillars, identifying sensitive layers through post-training quantization (PTQ) and assigning them as floating point (FP). Candidate mixed precision models are finalized with PTQ or quantization-aware training (QAT). To handle outliers, a small calibration dataset is used to improve PTQ performance. The proposed methods provide mixed precision models without training in the PTQ pipeline, while the QAT pipeline achieves performance competitive to FP models. With TensorRT deployment, the models offer reduced latency and size by up to 2.35 and 2.26 times, respectively.",3.05,88.826,271,cold_start,Phi-4,Apple_M1(Metal)
2601.12641v1_STEP-LLM Generating CAD STEP Models from Natural L.pdf,STEP-LLM: Generating CAD STEP Models from Natural Language with Large Language Models,"Xiangyu Shi, Junyang Ding, Xu Zhao, Sinong Zhan, Payal Mohapatra, Daniel Quispe, Kojo Welbeck, Jian Cao, Wei Chen, Ping Guo, Qi Zhu",,2601.12641v1,"Computer-aided design, STEP file, large language models, design automation","Computer-aided design (CAD) is vital to modern manufacturing, yet model creation remains labor-intensive and expertise-heavy. To enable non-experts to translate intuitive design intent into manufacturable artifacts, recent large language models (LLM)-based text-to-CAD efforts focus on command sequences or script-based formats like CadQuery. However, these formats are kernel-dependent and lack universality for manufacturing. In contrast, the Standard for the Exchange of Product Data (STEP, ISO 10303) file is a widely adopted, neutral boundary representation (B-rep) format directly compatible with manufacturing, but its graph-structured, cross-referenced nature poses unique challenges for auto-regressive LLMs. To address this, we curate a dataset of ~40K STEP-caption pairs and introduce novel preprocessing tailored for the graph-structured format of STEP, including a depth-first search (DFS)-based reserialization that linearizes cross-references while preserving locality and chain-of-thought (CoT)-style structural annotations that explicitly guide global coherence. We integrate retrieval-augmented generation (RAG) to ground predictions in relevant examples for supervised fine-tuning (SFT), and further refine generation quality through reinforcement learning (RL) with a specific Chamfer Distance-based geometric reward. Experiments demonstrate consistent gains of our STEP-LLM in geometric fidelity over the Text2CAD baseline, with improvements arising from multiple stages of our framework: the RAG module substantially enhances completeness and renderability, the DFS-based reserialization strategy strengthens overall accuracy, and the RL refinement further reduces geometric discrepancy. Both metrics and visual comparisons confirm that STEP-LLM generates shapes with higher fidelity than Text2CAD. These results demonstrate the feasibility of LLM-driven STEP model generation from natural language, showing its potential to democratize CAD design for manufacturing.",3.66,143.031,523,cold_start,Phi-4,Apple_M1(Metal)
2601.12646v1_Unbounded Harms Bounded Law Liability in the Age o.pdf,"Unbounded Harms, Bounded Law: Liability in the Age of Borderless AI",Ha-Chi Tran,,arXiv:2601.12646v1,"artificial intelligence, risk governance, liability, transboundary AI harms, compensation mechanisms, legal frameworks","The rapid acceleration of artificial intelligence (AI) has exposed fundamental deficiencies in prevailing risk governance. Despite advances in ex ante harm identification and prevention, Responsible AI scholarship remains underdeveloped in ex post risk governance. Core legal questions regarding compensation, mitigation, attribution of responsibility, liability allocation, and the effectiveness of remedial mechanisms remain inadequately theorized, especially for transboundary AI harms. The paper argues that such harms are structurally inherent to AI supply chains and likely to increase due to globalized deployment and cross-border data infrastructures. It examines compensation and liability mechanisms from high-risk and transnational domains to identify transferable legal design principles, such as strict liability and pooled compensation mechanisms. The paper outlines a global AI compensation and accountability architecture, highlighting the tension between geopolitical rivalry and collective action required to govern transboundary AI risk.",3.35,77.901,261,cold_start,Phi-4,Apple_M1(Metal)
2601.12648v1_Intelligent Documentation in Medical Education Can.pdf,Intelligent Documentation in Medical Education: Can AI Replace Manual Case Logging?,"Nafiz Imtiaz Khan, MSc, Kylie Cleland, BSc, Vladimir Filkov, PhD, Roger Eric Goldman, PhD",,,"artificial intelligence, large language models, radiology, case logs, medical education","This study investigates the feasibility of using large language models (LLMs) to automate procedural case log documentation in radiology training. It evaluates whether AI can replace manual logging, identifies challenging procedure types for extraction, and assesses integration into clinical workflows. The study analyzed 414 curated radiology reports from interventional radiology residents, testing local (Qwen-2.5) and commercial (Claude-3.5) models. Both models outperformed standard benchmarks, with Qwen-2.5 achieving an F1-score of 86.66 and Claude-3.5-Haiku reaching 86.89%. Automation could save over 35 hours of manual annotation per resident annually. LLMs show promise for reducing resident clerical burden, but broader validation and real-world workflow integration are needed before clinical adoption.",3.25,88.424,287,cold_start,Phi-4,Apple_M1(Metal)
2601.12654v1_Explanation Multiplicity in SHAP Characterization .pdf,Explanation Multiplicity in SHAP: Characterization and Assessment,"HYUNSEUNG HWANG, SEUNGEUN LEE, LUCAS ROSENBLATT, JULIA STOYANOVICH, STEVEN EUIJONG WHANG",https://doi.org/XXXXXXX.XXXXXXX,,"SHAP, explanation multiplicity, post-hoc explanations, feature attribution, responsible AI, stochasticity, explanation consistency, randomized baseline, normative concern","Post-hoc explanations are widely used to justify, contest, and review automated decisions in high-stakes domains such as lending, employment, and healthcare. Among these methods, SHAP is often treated as providing a reliable account of which features mattered for an individual prediction. However, SHAP explanations can differ substantially across repeated runs, even when the individual, prediction task, and trained model are held fixed. This phenomenon, termed explanation multiplicity, poses a normative challenge for responsible AI deployment, as it undermines expectations that explanations can reliably identify the reasons for an adverse outcome. The paper presents a comprehensive methodology for characterizing explanation multiplicity in post-hoc feature attribution methods, disentangling sources arising from model training and selection versus stochasticity intrinsic to the explanation pipeline. It also shows that explanation multiplicity is widespread and persists even under highly controlled conditions, including high-confidence predictions. The results indicate that explanation instability is a normative concern, and that explanation practices must be evaluated using metrics and baselines aligned with their intended societal role.",3.42,108.68,372,cold_start,Phi-4,Apple_M1(Metal)
2601.12658v1_Augmenting Question Answering with A Hybrid RAG Ap.pdf,Augmenting Question Answering with a Hybrid RAG Approach,"Tianyi Yang, Nashrah Haque, Vaishnave Jonnalagadda, Yuya Jeremy Ong, Zhehui Chen, Yanzhao Wu, Lei Yu, Divyesh Jadav, Wenqi Wei",,,"Question-answering, RAG, query processing","Retrieval-Augmented Generation (RAG) has emerged as a powerful technique for enhancing the quality of responses in Question-Answering (QA) tasks. However, existing approaches often struggle with retrieving contextually relevant information, leading to incomplete or suboptimal answers. This paper introduces Structured-Semantic RAG (SSRAG), a hybrid architecture that enhances QA quality by integrating query augmentation, agentic routing, and a structured retrieval mechanism combining vector and graph-based techniques with context unification. By refining retrieval processes and improving contextual grounding, the approach improves both answer accuracy and informativeness. Extensive evaluations on three popular QA datasets, TruthfulQA, SQuAD, and WikiQA, across five Large Language Models (LLMs), demonstrate that the proposed approach consistently improves response quality over standard RAG implementations.",3.16,88.832,281,cold_start,Phi-4,Apple_M1(Metal)
2601.12661v1_MedConsultBench A Full-Cycle Fine-Grained Process-.pdf,"MedConsultBench: A Full-Cycle, Fine-Grained, Process-Aware Benchmark for Medical Consultation Agents","Chuhan Qiao, Jianghua Huang, Daxing Zhao, Ziding Liu, Yanjun Shen, Bing Cheng, Wei Lin, Kai Wu",,arXiv:2601.12661v1,"medical consultation agents, dynamic scenarios, clinical workflow, Atomic Information Units, large language models, diagnostic accuracy, information-gathering efficiency, medication safety","Current evaluations of medical consultation agents often prioritize outcome-oriented tasks, frequently overlooking the end-to-end process integrity and clinical safety essential for real-world practice. While recent interactive benchmarks have introduced dynamic scenarios, they often remain fragmented and coarse-grained, failing to capture the structured inquiry logic and diagnostic rigor required in professional consultations. To bridge this gap, we propose MedConsultBench, a comprehensive framework designed to evaluate the complete online consultation cycle by covering the entire clinical workflow from history taking and diagnosis to treatment planning and follow-up Q&A. Our methodology introduces Atomic Information Units (AIUs) to track clinical information acquisition at a sub-turn level, enabling precise monitoring of how key facts are elicited through 22 fine-grained metrics. By addressing the underspecification and ambiguity inherent in online consultations, the benchmark evaluates uncertainty-aware yet concise inquiry while emphasizing medication regimen compatibility and the ability to handle realistic post-prescription follow-up Q&A via constraint-respecting plan revisions. Systematic evaluation of 19 large language models reveals that high diagnostic accuracy often masks significant deficiencies in information-gathering efficiency and medication safety. These results underscore a critical gap between theoretical medical knowledge and clinical practice ability, establishing MedConsultBench as a rigorous foundation for aligning medical AI with the nuanced requirements of real-world clinical care.",3.58,119.924,429,cold_start,Phi-4,Apple_M1(Metal)
2601.12664v1_Generalizable Hyperparameter Optimization for Fede.pdf,Generalizable Hyperparameter Optimization for Federated Learning on Non-IID Cancer Images,"Elisa Gonçalves Ribeiro, Rodrigo Moreira, Larissa Ferreira Rodrigues Moreira, André Ricardo Backes",,,"Federated Learning, Hyperparameter Optimization, Non-IID Data, Medical Imaging, Cancer","Deep learning for cancer histopathology training conflicts with privacy constraints in clinical settings. Federated Learning (FL) mitigates this by keeping data local; however, its performance depends on hyperparameter choices under non-independent and identically distributed (non-IID) client datasets. This paper examined whether hyperparameters optimized on one cancer imaging dataset generalized across non-IID federated scenarios. We considered binary histopathology tasks for ovarian and colorectal cancers. We perform centralized Bayesian hyperparameter optimization and transfer dataset-specific optima to the non-IID FL setup. The main contribution of this study is the introduction of a simple cross-dataset aggregation heuristic by combining configurations by averaging the learning rates and considering the modal optimizers and batch sizes. This combined configuration achieves a competitive classification performance.",3.07,83.337,256,cold_start,Phi-4,Apple_M1(Metal)
2601.12667v1_Empowering All-in-Loop Health Management of Spacec.pdf,Empowering All-in-Loop Health Management of Spacecraft Power System in the Mega-Constellation Era via Human-AI Collaboration,"Yi Di, Zhibin Zhao, Fujin Wang, Xue Liu, Jiafeng Tang, Jiaxin Ren, Zhi Zhai, Xuefeng Chen",,,"Large Language Model, Human-AI Collaboration, Spacecraft Power System, All-in-loop Health Management, Satellite Mega-Constellation","This work addresses the exponential increase in spacecraft numbers, leading to the era of satellite mega-constellations (SMC). It emphasizes the importance of energy management in space, particularly the health management (HM) of spacecraft power systems (SPS) due to their critical role and high failure rates. The paper proposes the AUC principle and introduces SpaceHMchat, an open-source Human-AI collaboration framework for all-in-loop health management (AIL HM). SpaceHMchat covers work condition recognition, anomaly detection, fault localization, and maintenance decision-making, achieving high performance across various metrics. The study also presents the first-ever AIL HM dataset for SPS, containing sub-datasets with diverse tasks and faults.",3.17,94.213,299,cold_start,Phi-4,Apple_M1(Metal)
2601.12671v1_Exploiting Test-Time Augmentation in Federated Lea.pdf,Exploiting Test-Time Augmentation in Federated Learning for Brain Tumor MRI Classification,"Thamara Leandra de Deus Melo, Rodrigo Moreira, Larissa Ferreira Rodrigues Moreira, Andr´e R. Backes",,,"Brain tumors, Federated Learning, Test-Time Augmentation, Image classification","Efficient brain tumor diagnosis is crucial for early treatment; however, it is challenging because of lesion variability and image complexity. This study evaluates convolutional neural networks (CNNs) in a federated learning (FL) setting, comparing models trained on original versus preprocessed MRI images (resizing, grayscale conversion, normalization, filtering, and histogram equalization). Preprocessing alone yielded negligible gains; combined with test-time augmentation (TTA), it delivered consistent, statistically significant improvements in federated MRI classification (p<0.001). In practice, TTA should be the default inference strategy in FL-based medical imaging; when the computational budget permits, pairing TTA with light preprocessing provides additional reliable gains.",3.06,85.496,262,cold_start,Phi-4,Apple_M1(Metal)
2601.12688v1_Logic-Guided Multistage Inference for Explainable .pdf,Logic-Guided Multistage Inference for Explainable Multidefendant Judgment Prediction,"Xu Zhang, Qinghua Wang, Mengyang Zhao, Fang Wang, Cunquan Qu",,,"Multiple defendants, Legal judgment predictions, Label broadcast, Guilt responsibility, Transformer","Crime disrupts societal stability, making law essential for balance. In multidefendant cases, assigning responsibility is complex and challenges fairness, requiring precise role differentiation. Judicial phrasing often obscures the roles of defendants, hindering effective AI-driven analyses. This work incorporates sentencing logic into a pretrained Transformer encoder framework to enhance intelligent assistance in multidefendant cases while ensuring legal interpretability. An oriented masking mechanism clarifies roles, and a comparative data construction strategy improves the model’s sensitivity to culpability distinctions between principals and accomplices. Predicted guilt labels are incorporated into a regression model through broadcasting, consolidating crime descriptions and court views. The proposed masked multistage inference (MMSI) framework, evaluated on the custom IMLJP dataset for intentional injury cases, achieves significant accuracy improvements, outperforming baselines in role-based culpability differentiation. This work offers a robust solution for enhancing intelligent judicial systems, with publicly available code.",3.25,93.434,304,cold_start,Phi-4,Apple_M1(Metal)
2601.12711v1_Neurosymbolic LoRA Why and When to Tune Weights vs.pdf,Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts,"Kevin Wang, Neel P. Bhatt, Cong Liu, Junbo Li, Runjin Chen, Yihan Xi, Timothy Barclay, Alvaro Velasquez, Ufuk Topcu, Zhangyang Wang",,,"neurosymbolic AI, large language models, LoRA, symbolic manipulation, numerical fine-tuning, TextGrad, LLM adaptation","Large language models (LLMs) can be adapted either through numerical updates that alter model parameters or symbolic manipulations that work on discrete prompts or logical constraints. While numerical fine-tuning excels at injecting new factual knowledge, symbolic updates offer flexible control of style and alignment without retraining. This paper introduces a neurosymbolic LoRA framework that dynamically combines these two complementary strategies. A unified monitoring signal and a reward-based classifier are presented to decide when to employ LoRA for deeper factual reconstruction and when to apply TextGrad for token-level edits. The approach remains memory-efficient by offloading symbolic transformations to an external LLM only when needed. Refined prompts produced during symbolic editing serve as high-quality, reusable training data, beneficial in data-scarce domains like mathematical reasoning. Extensive experiments show that neurosymbolic LoRA consistently outperforms purely numerical or purely symbolic baselines, demonstrating superior adaptability and improved performance. The findings highlight the value of interleaving numerical and symbolic updates to unlock a new level of versatility in language model fine-tuning.",3.34,104.668,350,cold_start,Phi-4,Apple_M1(Metal)
2601.12715v1_RSOD Reliability-Guided Sonar Image Object Detecti.pdf,RSOD: Reliability-Guided Sonar Image Object Detection with Extremely Limited Labels,"Chengzhou Li, Ping Guo, Guanchen Meng, Qi Jia, Jinyuan Liu, Zhu Liu, Xiaokang Liu, Yu Liu, Zhongxuan Luo, Xin Fan",,,"sonar image object detection, limited labels, teacher-student framework, pseudo-label strategy, reliability score, adaptive constraint","Object detection in sonar images is crucial for underwater detection systems but is challenging due to the lack of texture details and high noise levels. This paper introduces RSOD, a teacher-student framework designed to effectively learn sonar image characteristics and develop a pseudo-label strategy to mitigate the impact of limited labels. RSOD calculates a reliability score based on the consistency of the teacher's predictions across different views and introduces an object mixed pseudo-label method to address the shortage of labeled data. The student model is optimized using a reliability-guided adaptive constraint, allowing it to perform well even with extremely limited labels. The method achieves competitive results on the UATD dataset using only 5% of labeled data compared to a baseline trained on 100% labeled data. Additionally, a new dataset is collected to support further research in sonar image object detection.",3.28,99.683,327,cold_start,Phi-4,Apple_M1(Metal)
2601.12720v1_Teaching Large Reasoning Models Effective Reflecti.pdf,Teaching Large Reasoning Models Effective Reflection,"Hanbin Wang, Jingwei Song, Jinpeng Li, Qi Zhu, Fei Mi, Ganqu Cui, Yasheng Wang, Lifeng Shang",,,"Large Reasoning Models, Self-Critique Fine-Tuning, Reinforcement Learning, Effective Reflection, Reflection Quality, Reasoning Accuracy","Large Reasoning Models (LRMs) have shown impressive performance on complex reasoning tasks by engaging in self-reflective behaviors such as self-critique and backtracking. However, many reflections are superficial and do not improve the original answer, incurring computation overhead. This paper addresses the problem of superficial reflection in LRMs by proposing Self-Critique Fine-Tuning (SCFT) and Reinforcement Learning with Effective Reflection Rewards (RLERR). SCFT enhances the model's reflective reasoning ability using self-generated critiques, while RLERR uses high-quality reflections to guide the model via reinforcement learning. Experiments on AIME2024 and AIME2025 benchmarks show significant improvements in reasoning accuracy and reflection quality, outperforming state-of-the-art baselines.",3.03,87.537,265,cold_start,Phi-4,Apple_M1(Metal)
2601.12723v1_An Evolutionary Framework for Automatic Optimizati.pdf,An Evolutionary Framework for Automatic Optimization Benchmark Generation via Large Language Models,"Yuhiro Ono, Tomohiro Harada, Yukiya Miura",,2601.12723v1,"optimization benchmarks, large language models, evolutionary framework, benchmark generation, genetic algorithm, differential evolution","Optimization benchmarks are crucial for evaluating algorithm performance, but existing artificial benchmarks often fail to capture the diversity and irregularity of real-world problem structures. This paper proposes an evolutionary automatic benchmark generation framework that leverages a large language model (LLM) as a generative operator, termed the LLM-driven evolutionary benchmark generator (LLM-EBG). The LLM serves as an evolutionary operator that generates and evolves benchmark problems within a flexible, expressive representation space. The framework is demonstrated through the generation of unconstrained single-objective continuous minimization problems represented as mathematical expressions, designed to induce significant performance differences between a genetic algorithm (GA) and differential evolution (DE). Experimental results show that LLM-EBG successfully produces benchmark problems where the designated target algorithm consistently outperforms the comparative algorithm in more than 80% of trials. Additionally, exploratory landscape analysis reveals that benchmarks favoring GA are highly sensitive to variable scaling, indicating that the framework can generate problems with distinct geometric characteristics that reflect the intrinsic search behaviors of different optimization algorithms.",3.73,87.691,327,cold_start,Phi-4,Apple_M1(Metal)
2601.12727v1_AI-exhibited Personality Traits Can Shape Human Se.pdf,AI-exhibited Personality Traits Can Shape Human Self-concept through Conversations,"Jingshu Li, Tianqi Song, Nattapat Boonprakong, Zicheng Zhu, Yitian Yang, Yi-Chieh Lee",10.1145/3772318.3790654,2601.12727v1,"AI, personality traits, self-concept, conversations, Large Language Model, GPT-4o, human-computer interaction","Recent Large Language Model (LLM) based AI can exhibit recognizable and measurable personality traits during conversations to improve user experience. However, as human understandings of their personality traits can be affected by their interaction partners’ traits, a potential risk is that AI traits may shape and bias users’ self-concept of their own traits. To explore the possibility, we conducted a randomized behavioral experiment. Our results indicate that after conversations with the same AI, each individual’s self-concept becomes aligned with the AI’s measured personality traits, leading to increased homogeneity of self-concepts across individuals.",3.49,80.039,279,cold_start,Phi-4,Apple_M1(Metal)
2601.12731v1_A Shared Geometry of Difficulty in Multilingual La.pdf,A Shared Geometry of Difficulty in Multilingual Language Models,"Stefano Civelli, Pietro Bernardelle, Nicolò Brunello, Gianluca Demartini",,,"multilingual language models, problem difficulty, linear probes, internal representations, cross-lingual generalization","This study investigates the multilingual geometry of problem-difficulty in large language models (LLMs) by training linear probes on the AMC subset of the Easy2Hard benchmark, translated into 21 languages. The research identifies difficulty-related signals at two distinct stages of model internals: shallow (early-layers) and deep (later-layers) internal representations, which exhibit functionally different behaviors. Probes on deep representations show high accuracy within the same language but poor cross-lingual generalization, whereas shallow representation probes generalize better across languages despite lower within-language performance. These findings suggest that LLMs first form a language-agnostic representation of problem difficulty, which then becomes language-specific. This aligns with existing findings that models operate in an abstract conceptual space before producing language-specific outputs, extending this process to high-level metacognitive properties like problem-difficulty estimation.",3.27,88.199,288,cold_start,Phi-4,Apple_M1(Metal)
2601.12740v1_TreeWriter AI-Assisted Hierarchical Planning and W.pdf,TreeWriter: AI-Assisted Hierarchical Planning and Writing for Long-Form Documents,"Zijian Zhang, Fangshi Du, Xingjian Liu, Pan Chen, Oliver Huang, Runlong Ye, Michael Liut, Alán Aspuru-Guzik",,,"AI-assisted writing, hierarchical planning, long-form documents, TreeWriter, contextual AI support, document outlines, collaborative writing","Long documents pose challenges to current intelligent writing systems, including maintaining consistency, efficient planning, and integrating AI assistance. TreeWriter is introduced as a hierarchical writing system that represents documents as trees, integrating contextual AI support. It allows authors to create, save, and refine document outlines at multiple levels, facilitating drafting, understanding, and iterative editing. A built-in AI agent provides context-aware editing suggestions. Studies show TreeWriter improves idea exploration, AI helpfulness, and authorial control, supporting collaborative writing. The findings highlight the potential of hierarchical, tree-structured editors with integrated AI support.",3.1,86.691,269,cold_start,Phi-4,Apple_M1(Metal)
2601.12742v1_AirHunt Bridging VLM Semantics and Continuous Plan.pdf,AirHunt: Bridging VLM Semantics and Continuous Planning for Efficient Aerial Object Navigation,"Xuecheng Chen, Zongzhuo Liu, Jianfa Ma, Bang Du, Tiantian Zhang, Xueqian Wang, Boyu Zhou",,,"Vision-Language Models, Aerial Object Navigation, Continuous Path Planning, Semantic Reasoning, Drones, 3D Scene Understanding","Recent advances in large Vision-Language Models (VLMs) have enabled drones to search for open-set objects using natural language instructions. However, integrating VLMs into practical aerial systems is challenging due to the frequency mismatch between VLM inference and real-time planning, and VLMs' limited 3D scene understanding. AirHunt is presented as an aerial object navigation system that efficiently locates open-set objects in outdoor environments by fusing VLM semantic reasoning with continuous path planning. It features a dual-pathway asynchronous architecture and an active dual-task reasoning module to enable selective VLM querying. Additionally, a semantic-geometric coherent planning module dynamically reconciles semantic priorities and motion efficiency. AirHunt demonstrates higher success rates, lower navigation errors, and reduced flight times compared to state-of-the-art methods, validated through diverse tasks and real-world experiments.",3.3,95.586,315,cold_start,Phi-4,Apple_M1(Metal)
2601.12744v1_Vision Language Models for Optimization-Driven Int.pdf,Vision Language Models for Optimization-Driven Intent Processing in Autonomous Networks,"Tasnim Ahmed, Yifan Zhu, Salimur Choudhury",,,"Intent-Based Networking, Optimization, Vision-Language Models, Code Generation, Model Context Protocol","Intent-Based Networking (IBN) allows operators to specify high-level network goals rather than low-level configurations. This paper explores whether Vision-Language Models (VLMs) can process annotated network sketches into correct optimization code. The study introduces IntentOpt, a benchmark of 85 optimization problems across 17 categories, evaluating four VLMs under different prompting strategies. Results show that visual parameter extraction reduces execution success, and open-source models lag behind closed-source ones. The paper establishes baseline capabilities and limitations of current VLMs for optimization code generation within an IBN system and demonstrates practical feasibility through a case study deploying VLM-generated code to network testbed infrastructure using Model Context Protocol.",3.0,72.275,217,cold_start,Phi-4,Apple_M1(Metal)
2601.12745v1_A Graph Prompt Fine-Tuning Method for WSN Spatio-T.pdf,A Graph Prompt Fine-Tuning Method for Spatio-Temporal Correlation Anomaly Detection in Wireless Sensor Networks,"Miao Ye, Jing Cui, Yuan Huang, Yong Wang, Qian He, Jiwen Zhang",,,"Anomaly Detection, Graph Neural Networks, Pre-training, Prompt Learning, Wireless Sensor Networks","This paper addresses the challenges of anomaly detection in multi-temporal modal data within Wireless Sensor Networks (WSN). Existing methods face issues such as insufficient extraction of spatio-temporal correlation features, high costs of anomaly sample annotation, and imbalance of anomaly samples. The authors propose a graph neural network anomaly detection backbone network that incorporates spatio-temporal correlation features and a multi-task self-supervised training strategy termed 'pre-training - graph prompting - fine-tuning'. The model is designed to fully extract spatio-temporal correlation features in multi-node, multi-temporal modal scenarios of WSNs. It employs a three-subtask learning 'pre-training' method with no-negative comparative learning, prediction, and reconstruction to learn generic features from unlabeled data. The 'graph prompting-fine-tuning' mechanism guides the pre-trained self-supervised learning model to complete parameter fine-tuning, reducing training costs and enhancing detection generalization performance. Experiments on public and actual collected datasets show F1 metrics up to 91.30% and 92.31%, respectively, outperforming existing methods.",3.37,102.756,346,cold_start,Phi-4,Apple_M1(Metal)
2601.12754v1_PAIR-SAFE A Paired-Agent Approach for Runtime Audi.pdf,PAIR-SAFE: A Paired-Agent Approach for Runtime Auditing and Refining AI-Mediated Mental Health Support,"Jiwon Kim, Violeta J. Rodriguez, Dong Whi Yoo, Eshwar Chandrasekharan, Koustuv Saha",,,"Large language models, mental health support, Motivational Interviewing Treatment Integrity, runtime auditing, paired-agent framework","Large language models (LLMs) are increasingly used for mental health support, but they can produce responses that are overly directive, inconsistent, or clinically misaligned, especially in sensitive or high-risk contexts. Existing approaches to mitigating these risks largely rely on implicit alignment through training or prompting, offering limited transparency and runtime accountability. This paper introduces PAIR-SAFE, a paired-agent framework for auditing and refining AI-generated mental health support. It integrates a Responder agent with a supervisory Judge agent grounded in the clinically validated Motivational Interviewing Treatment Integrity (MITI-4) framework. The Judge audits each response and provides structured ALLOW or REVISE decisions that guide runtime response refinement. Simulated counseling interactions using a support-seeker simulator derived from human-annotated motivational interviewing data show significant improvements in key MITI dimensions, including Partnership, Seek Collaboration, and overall Relational quality. Quantitative findings are supported by qualitative expert evaluation, highlighting the nuances of runtime supervision. The results reveal that a paired-agent approach can provide clinically grounded auditing and refinement for AI-assisted conversational mental health support.",3.3,101.528,335,cold_start,Phi-4,Apple_M1(Metal)
2601.12758v1_VISPA Pluralistic Alignment via Automatic Value Se.pdf,VISPA: Pluralistic Alignment via Automatic Value Selection and Activation,"Shenyan Zheng, Jiayou Zhong, Anudeex Shetty, Heng Ji, Preslav Nakov, Usman Naseem",,,"pluralistic alignment, large language models, value selection, activation steering, high-stakes domains","As large language models are increasingly used in high-stakes domains, it is essential that their outputs reflect a range of varying perspectives rather than an average human preference. Existing approaches consider limited values or rely on prompt-level interventions, lacking value control and representation. To address this, VISPA, a training-free pluralistic alignment framework, enables direct control over value expression by dynamic selection and internal model activation steering. Extensive empirical studies show VISPA's performance across pluralistic alignment modes in healthcare and beyond. Further analysis reveals VISPA's adaptability with different steering initiations, models, and values, suggesting that pluralistic alignment can be achieved through internal activation mechanisms, offering a scalable path toward language models that serve all.",3.13,85.753,268,cold_start,Phi-4,Apple_M1(Metal)
2601.12762v1_Teaching LLMs to Learn Tool Trialing and Execution.pdf,Teaching LLMs to Learn Tool Trialing and Execution through Environment Interaction,"Xingjie Gao, Pengcheng Huang, Zhenghao Liu, Yukun Yan, Shuo Wang, Zulong Chen, Chen Qian, Ge Yu, Yu Gu",,,"Large Language Models, tool usage, environment interaction, trial-and-execution paradigm, generalization, robustness","This paper introduces ToolMaster, a framework designed to enhance the tool-use capabilities of Large Language Models (LLMs) by shifting from static solution paths to active learning through environment interaction. ToolMaster employs a trial-and-execution paradigm, combining teacher-generated trajectories with reinforcement learning to enable LLMs to autonomously explore and learn correct tool usage. Experimental results show that ToolMaster significantly outperforms existing methods in terms of generalization and robustness across unseen or unfamiliar tools.",2.94,82.392,242,cold_start,Phi-4,Apple_M1(Metal)
2601.12781v1_VIRO Robust and Efficient Neuro-Symbolic Reasoning.pdf,VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension,"Hyejin Park, Junhyuk Kwon, Suha Kwak, Jungseul Ok",,,"Referring Expression Comprehension, neuro-symbolic reasoning, verification, language models, vision-language models, compositional reasoning, zero-shot generalization, cascading errors, operator-level verifiers","Referring Expression Comprehension (REC) aims to localize the image region corresponding to a natural-language query. Recent neuro-symbolic REC approaches leverage large language models (LLMs) and vision-language models (VLMs) to perform compositional reasoning, decomposing queries into structured programs and executing them step-by-step. However, these approaches assume intermediate reasoning steps are accurate, leading to cascading errors. To address this, the paper introduces Verification-Integrated Reasoning Operators (VIRO), a neuro-symbolic framework embedding lightweight operator-level verifiers within reasoning steps. Each operator executes and validates its output, such as object existence or spatial relationship, allowing the system to robustly handle no-target cases when verification conditions are not met. VIRO achieves state-of-the-art performance, demonstrating generalization to real-world egocentric data, superior computational efficiency, high reliability, and scalability.",3.24,93.025,301,cold_start,Phi-4,Apple_M1(Metal)
2601.12785v1_Distilling Time Series Foundation Models for Effic.pdf,DISTILLING TIME SERIES FOUNDATION MODELS FOR EFFICIENT FORECASTING,"Yuqi Li, Kuiye Ding, Chuanguang Yang, Szu-Yu Chen, Yingli Tian",,,"Time Series Foundation Model, Knowledge Distillation, Time Series Forecasting","Time Series foundation models (TSFMs) deliver strong forecasting performance through large-scale pretraining, but their large parameter sizes make deployment costly. To address this, the paper presents DistilTS, the first distillation framework specifically designed for TSFMs. DistilTS introduces horizon-weighted objectives to balance learning across horizons and a temporal alignment strategy to reduce architectural mismatch, enabling compact models. Experiments demonstrate that DistilTS achieves forecasting performance comparable to full-sized TSFMs, while reducing parameters by up to 1/150 and accelerating inference by up to 6000×.",3.06,74.574,228,cold_start,Phi-4,Apple_M1(Metal)
2601.12804v1_SL-CBM Enhancing Concept Bottleneck Models with Se.pdf,SL-CBM: Enhancing Concept Bottleneck Models with Semantic Locality for Better Interpretability,"Hanwei Zhang, Luo Cheng, Rui Wen, Yang Zhang, Lijun Zhang, Holger Hermanns",,,"Explainable AI, Concept Bottleneck Models, Semantic Locality, Saliency Maps, Interpretability, Machine Learning","Explainable AI (XAI) is crucial for building transparent and trustworthy machine learning systems, especially in high-stakes domains. Concept Bottleneck Models (CBMs) provide interpretable, concept-level explanations by explicitly modeling human-understandable concepts. However, existing CBMs often suffer from poor locality faithfulness, failing to spatially align concepts with meaningful image regions, which limits their interpretability and reliability. This work proposes SL-CBM (CBM with Semantic Locality), a novel extension that enforces locality faithfulness by generating spatially coherent saliency maps at both concept and class levels. SL-CBM integrates a 1×1 convolutional layer with a cross-attention mechanism to enhance alignment between concepts, image regions, and final predictions. Unlike prior methods, SL-CBM produces faithful saliency maps inherently tied to the model’s internal reasoning, facilitating more effective debugging and intervention. Extensive experiments on image datasets demonstrate that SL-CBM substantially improves locality faithfulness, explanation quality, and intervention efficacy while maintaining competitive classification accuracy. Ablation studies highlight the importance of contrastive and entropy-based regularization for balancing accuracy, sparsity, and faithfulness. Overall, SL-CBM bridges the gap between concept-based reasoning and spatial explainability, setting a new standard for interpretable and trustworthy concept-based models.",3.32,119.827,398,cold_start,Phi-4,Apple_M1(Metal)
2601.12805v1_SciHorizon-GENE Benchmarking LLM for Life Sciences.pdf,SciHorizon-Gene: Benchmarking LLM for Life Sciences Inference from Gene Knowledge to Functional Understanding,"Xiaohan Huang, Meng Xiao, Chuan Qin, Qingqing Long, Jinmiao Chen, Yuanchun Zhou, Hengshu Zhu",https://doi.org/XXXXXXX.XXXXXXX,,"large language models, benchmarking and evaluation, genomics","Large language models (LLMs) have shown growing promise in biomedical research, particularly for knowledge-driven interpretation tasks. However, their ability to reliably reason from gene-level knowledge to functional understanding, a core requirement for knowledge-enhanced cell atlas interpretation, remains largely underexplored. To address this gap, we introduce SciHorizon-Gene, a large-scale gene-centric benchmark constructed from authoritative biological databases. The benchmark integrates curated knowledge for over 190K human genes and comprises more than 540K questions covering diverse gene-to-function reasoning scenarios relevant to cell type annotation, functional interpretation, and mechanism-oriented analysis. SciHorizon-Gene evaluates LLMs along four biologically critical perspectives: research attention sensitivity, hallucination tendency, answer completeness, and literature influence, explicitly targeting failure modes that limit the safe adoption of LLMs in biological interpretation pipelines. We systematically evaluate a wide range of state-of-the-art general-purpose and biomedical LLMs, revealing substantial heterogeneity in gene-level reasoning capabilities and persistent challenges in generating faithful, complete, and literature-grounded functional interpretations. Our benchmark establishes a systematic foundation for analyzing LLM behavior at the gene scale and offers insights for model selection and development, with direct relevance to knowledge-enhanced biological interpretation.",3.4,113.349,385,cold_start,Phi-4,Apple_M1(Metal)
2601.12809v1_Left-Right Symmetry Breaking in CLIP-style Vision-.pdf,Left–Right Symmetry Breaking in CLIP-style Vision-Language Models Trained on Synthetic Spatial-Relation Data,"Takaki Yamamoto, Chihiro Noguchi, Toshihiro Tanizawa",,,"vision-language models, spatial understanding, left-right symmetry, Transformer-based encoders, contrastive training, attention decomposition, positional embeddings, token embeddings, horizontal attention gradient","This study investigates how left-right relational understanding emerges in Transformer-based vision and text encoders trained with a CLIP-style contrastive objective. Using a controllable 1D image-text testbed, the authors train lightweight encoders on paired descriptions of one- and two-object scenes. They evaluate generalization to unseen object pairs, finding that contrastive training effectively learns left-right relations, with label diversity being a primary driver of generalization. Mechanistic insights are provided through attention decomposition, revealing that interactions between positional and token embeddings induce a horizontal attention gradient that breaks left-right symmetry. Ablating this contribution significantly reduces left-right discrimination, offering insights into the acquisition of relational competence in CLIP-style models.",3.11,89.386,278,cold_start,Phi-4,Apple_M1(Metal)
2601.12816v1_Fisher-Orthogonal Projected Natural Gradient Desce.pdf,Fisher-Orthogonal Projected Natural Gradient Descent for Continual Learning,"Ishir Garg, Neel Kolhe, Andy Peng, Rohan Gopalam",,,"Continual Learning, Natural Gradient Descent, Fisher Information Matrix, Orthogonal Gradient Methods, Catastrophic Forgetting","Continual learning aims to enable neural networks to acquire new knowledge on sequential tasks without forgetting previously learned tasks. This paper introduces the Fisher-Orthogonal Projected Natural Gradient Descent (FOPNG) optimizer, which enforces Fisher-orthogonal constraints on parameter updates to preserve old task performance while learning new tasks. Unlike existing methods that operate in Euclidean parameter space, FOPNG projects gradients onto the Fisher-orthogonal complement of previous task gradients. This approach unifies natural gradient descent with orthogonal gradient methods within an information-geometric framework. The resulting update direction is invariant under reparameterization, guarantees descent in the Fisher metric, and helps preserve prior task outputs. Theoretical analysis and practical implementations using the diagonal Fisher are provided, demonstrating strong results on standard continual learning benchmarks.",3.25,84.637,275,cold_start,Phi-4,Apple_M1(Metal)
2601.12822v1_MirrorGuard Toward Secure Computer-Use Agents via .pdf,MirrorGuard: Toward Secure Computer-Use Agents via Simulation-to-Real Reasoning Correction,"Wenqi Zhang, Yulin Shen, Changyue Jiang, Jiarun Dai, Geng Hong, Xudong Pan*",https://doi.org/XXXXXXX.XXXXXXX,,"Computer Use Agents, Agent Security, Reasoning Correction, Simulation, Vision-Language Models","Large foundation models are integrated into Computer Use Agents (CUAs), enabling autonomous interaction with operating systems through graphical user interfaces (GUIs) to perform complex tasks. This autonomy introduces serious security risks: malicious instructions or visual prompt injections can trigger unsafe reasoning and cause harmful system-level actions. Existing defenses, such as detection-based blocking, prevent damage but often abort tasks prematurely, reducing agent utility. In this paper, we present MirrorGuard, a plug-and-play defense framework that uses simulation-based training to improve CUA security in the real world. To reduce the cost of large-scale training in operating systems, we propose a novel neural-symbolic simulation pipeline, which generates realistic, high-risk GUI interaction trajectories entirely in a text-based simulated environment, capturing unsafe reasoning patterns and potential system hazards without executing real operations. In the simulation environment, MirrorGuard learns to intercept and rectify insecure reasoning chains of CUAs before they produce and execute unsafe actions. In real-world testing, extensive evaluations across diverse benchmarks and CUA architectures show that MirrorGuard significantly mitigates security risks. For instance, on the ByteDance UI-TARS system, it reduces the unsafe rate from 66.5% to 13.0% while maintaining a marginal false refusal rate (FRR). In contrast, the state-of-the-art GuardAgent only achieves a reduction to 53.9% and suffers from a 15.4% higher FRR. Our work proves that simulation-derived defenses can provide robust, real-world protection while maintaining the fundamental utility of the agent. Our code and model are publicly available at https://bmz-q-q.github.io/MirrorGuard.",3.51,132.149,464,cold_start,Phi-4,Apple_M1(Metal)
2601.12837v1_Cognition spaces natural artificial and hybrid.pdf,"Cognition spaces: natural, artificial, and hybrid","Ricard Solé, Luis F Seoane, Jordi Pla-Mauri, Michael Timothy Bennett, Michael E. Hochberg, Michael Levin",,,"Evolved cognition, basal cognition, artificial life, artificial intelligence, synthetic biology, morphospace","Cognitive processes are realized across a range of natural, artificial, and hybrid systems, yet there is no unified framework for comparing their forms, limits, and unrealized possibilities. This paper proposes a cognition space approach that replaces narrow, substrate-dependent definitions with a comparative representation based on organizational and informational dimensions. Within this framework, cognition is treated as a graded capacity to sense, process, and act upon information, allowing systems as diverse as cells, brains, artificial agents, and human–AI collectives to be analyzed within a common conceptual landscape. The paper introduces and examines three cognition spaces—basal aneural, neural, and human–AI hybrid—and shows that their occupation is highly uneven, with clusters of realized systems separated by large unoccupied regions. These voids are argued to reflect evolutionary contingencies, physical constraints, and design limitations. By focusing on the structure of cognition spaces rather than categorical definitions, this approach clarifies the diversity of existing cognitive systems and highlights hybrid cognition as a promising frontier for exploring novel forms of complexity beyond those produced by biological evolution.",3.33,103.385,344,cold_start,Phi-4,Apple_M1(Metal)
2601.12842v1_SCULPT Constraint-Guided Pruned MCTS that Carves E.pdf,SCULPT: Constraint-Guided Pruned MCTS that Carves Efficient Paths for Mathematical Reasoning,"Qitong Fang, Haotian Li, Xu Wang",,,"Monte Carlo Tree Search, Mathematical Reasoning, Large Language Models, Constraint-Guided Exploration, Automated Agent Workflows","Automated agent workflows can enhance the problem-solving ability of large language models (LLMs), but common search strategies rely on stochastic exploration and often traverse implausible branches. This occurs because current pipelines sample candidate steps from generic prompts or learned policies with weak domain priors, yielding near-random walks over operators, units, and formats. To promote ordered exploration, this paper introduces SCULPT, a constraint-guided approach for Monte Carlo Tree Search (MCTS) that integrates domain-aware scoring into selection, expansion, simulation, and backpropagation. SCULPT scores and prunes actions using a combination of symbolic checks (dimensional consistency, type compatibility, magnitude sanity, depth control, and diversity) and structural pattern guidance, thereby steering the search toward plausible reasoning paths. Under matched LLM configurations, SCULPT yields stable improvements on multiple datasets; additional results with GPT-5.2 assess executor transferability and performance on frontier reasoning models. Overall, domain-aware constraints can improve accuracy while maintaining efficiency and reasoning stability.",3.27,98.361,322,cold_start,Phi-4,Apple_M1(Metal)
2601.12849v1_The Cost of EFX Generalized-Mean Welfare and Compl.pdf,The Cost of EFX: Generalized-Mean Welfare and Complexity Dichotomies with Few Surplus Items,"Eugene Lim, Tzeh Yuan Neoh, Nicholas Teh",,2601.12849v1,"fair division, envy-freeness, EFX, generalized-mean welfare, NP-hard, polynomial-time algorithms, price of fairness, Pareto-optimality","Envy-freeness up to any good (EFX) is a central fairness notion for allocating indivisible goods, yet its existence is unresolved in general. In the setting with few surplus items, where the number of goods exceeds the number of agents by a small constant (at most three), EFX allocations are guaranteed to exist, shifting the focus from existence to efficiency and computation. This study examines how EFX interacts with generalized-mean (p-mean) welfare, which includes utilitarian (p=1), Nash (p=0), and egalitarian (p→−∞) objectives. Sharp complexity dichotomies at p=0 are established: for any fixed p∈(0,1], deciding whether EFX can attain the global p-mean optimum and computing an EFX allocation maximizing p-mean welfare are NP-hard, even with at most three surplus goods. In contrast, for any fixed p≤0, polynomial-time algorithms optimize p-mean welfare within EFX allocations and efficiently certify when EFX attains the global optimum. The welfare loss of enforcing EFX is quantified via the price of fairness framework, showing that for p>0, the loss can grow linearly with the number of agents, whereas for p≤0, it is bounded by a constant depending on the surplus (and for Nash welfare it vanishes asymptotically). Requiring Pareto-optimality alongside EFX is NP-hard and becomes Σ P2-complete for a stronger variant of EFX. The results delineate when EFX is computationally costly versus structurally aligned with welfare maximization in the setting with few surplus items.",3.5,135.541,474,cold_start,Phi-4,Apple_M1(Metal)
2601.12856v1_Mining Citywide Dengue Spread Patterns in Singapor.pdf,Mining Citywide Dengue Spread Patterns in Singapore Through Hotspot Dynamics from Open Web Data,"Liping Huang, Gaoxi Xiao, Stefan Ma, Hechang Chen, Shisong Tang, Flora Salim",https://doi.org/10.1145/XXXXXX.XXXXXX,,"Dengue Cases, Disease Spreading Pattern, Hotpot Dynamics, Machine Learning","Dengue, a mosquito-borne disease, continues to pose a persistent public health challenge in urban areas, particularly in tropical regions such as Singapore. This study introduces a novel framework that uncovers and exploits latent transmission links between urban regions, mined directly from publicly available dengue case data. The framework models how hotspot formation in one area is influenced by epidemic dynamics in neighboring regions, aligning closely with commuting flows. The learned transmission links are optimized through gradient descent and used to forecast hotspot status and verify the consistency of spreading patterns. Case studies on Singapore during 2013–2018 and 2020 show that four weeks of hotspot history are sufficient to achieve an average F-score of 0.79, with robustness maintained during the COVID-19 'circuit breaker' with an F-score of 0.83. The work transforms open web-based case data into a predictive and explanatory resource, advancing epidemic modeling and providing a scalable, low-cost tool for public health planning, early intervention, and urban resilience.",3.3,103.938,343,cold_start,Phi-4,Apple_M1(Metal)
2601.12879v1_Hierarchical Sparse Circuit Extraction from Billio.pdf,Hierarchical Sparse Circuit Extraction from Billion-Parameter Language Models through Scalable Attribution Graph Decomposition,"Mohammed Mudassir Uddin, Shahnawaz Alam, Mohammed Kaif Pasha",,,"Mechanistic interpretability, sparse computational graphs, circuit discovery, transformer architectures, causal inference, attribution methods, hierarchical decomposition","Mechanistic interpretability seeks to reverse-engineer neural network computations into human-understandable algorithms, yet extracting sparse computational circuits from billion-parameter language models remains challenging due to exponential search complexity and pervasive polysemanticity. The proposed Hierarchical Attribution Graph Decomposition (HAGD) framework reduces circuit discovery complexity from O(2^n) exhaustive enumeration to O(n^2 log n) through multi-resolution abstraction hierarchies and differentiable circuit search. The methodology integrates cross-layer transcoders for monosemantic feature extraction, graph neural network meta-learning for topology prediction, and causal intervention protocols for validation. Empirical evaluation spans GPT-2 variants, Llama-7B through Llama-70B, and Pythia suite models across algorithmic tasks and natural language benchmarks. On modular arithmetic tasks, the framework achieves up to 91% behavioral preservation (±2.3% across runs) while maintaining interpretable subgraph sizes. Cross-architecture transfer experiments suggest that discovered circuits exhibit moderate structural similarity (averaging 67%) across model families, indicating potential shared computational patterns. These results provide preliminary foundations for interpretability at larger model scales while identifying significant limitations in current attribution methodologies that require future advances.",3.53,105.995,374,cold_start,Phi-4,Apple_M1(Metal)
2601.12882v1_YOLO26 An Analysis of NMS-Free End to End Framewor.pdf,YOLO26: AN ANALYSIS OF NMS-FREE END-TO-END FRAMEWORK FOR REAL-TIME OBJECT DETECTION,Sudip Chakrabarty,,arXiv:2601.12882v1,"YOLOv26, End-to-End Object Detection, NMS-Free, MuSGD, ProgLoss, Real-Time Computer Vision, You Only Look Once","The 'You Only Look Once' (YOLO) framework has long served as the benchmark for real-time object detection, yet traditional iterations (YOLOv1 through YOLO11) remain constrained by the latency and hyperparameter sensitivity of Non-Maximum Suppression (NMS) post-processing. This paper analyzes a comprehensive analysis of YOLO26, an architecture that fundamentally redefines this paradigm by eliminating NMS in favor of a native end-to-end learning strategy. This study examines the critical innovations that enable this transition, specifically the introduction of the MuSGD optimizer for stabilizing lightweight backbones, STAL for small-target-aware assignment, and ProgLoss for dynamic supervision. Through a systematic review of official performance benchmarks, the results demonstrate that YOLO26 establishes a new Pareto front, outperforming a comprehensive suite of predecessors and state-of-the-art competitors (including RTMDet and DAMO-YOLO) in both inference speed and detection accuracy. The analysis confirms that by decoupling representation learning from heuristic post-processing, YOLOv26 successfully resolves the historical trade-off between latency and precision, signaling the next evolutionary step in edge-based computer vision.",3.7,100.833,373,cold_start,Phi-4,Apple_M1(Metal)
2601.12886v1_Communication Methods in Multi-Agent Reinforcement.pdf,Communication Methods in Multi-Agent Reinforcement Learning,Christoph Wittner,,2601.12886v1,"Machine learning, MARL, Communication","Multi-agent reinforcement learning (MARL) extends traditional reinforcement learning to multi-agent systems, addressing challenges like partially observable environments, non-stationarity, and large action spaces. This work reviews 29 publications on communication techniques in MARL, evaluating explicit, implicit, attention-based, graph-based, and hierarchical/role-based methods. It concludes that no single communication framework is universally optimal, with the choice depending on the specific problem. The paper also highlights the need for low computational overhead in communication methods for scalability and discusses research gaps, including the need for standardized benchmarking and improved robustness under realistic conditions.",3.24,55.178,179,cold_start,Phi-4,Apple_M1(Metal)
2601.12893v1_AdaNODEs Test Time Adaptation for Time Series Fore.pdf,ADANODES: TEST TIME ADAPTATION FOR TIME SERIES FORECASTING USING NEURAL ODES,"Ting Dang, Soumyajit Chatterjee, Hong Jia, Yu Wu, Flora Salim, Fahim Kawsar",,,"Test time adaptation, time series forecasting, domain adaptation, neural odes","Test time adaptation (TTA) has emerged as a promising solution to adapt pre-trained models to new, unseen data distributions using unlabeled target domain data. However, most TTA methods are designed for independent data, often overlooking time series data and rarely addressing forecasting tasks. This paper presents AdaNODEs, an innovative source-free TTA method tailored explicitly for time series forecasting. By leveraging Neural Ordinary Differential Equations (NODEs), we propose a novel adaptation framework that accommodates the unique characteristics of distribution shifts in time series data. Moreover, we innovatively propose a new loss function to tackle TTA for forecasting tasks. AdaNODEs only requires updating limited model parameters, showing effectiveness in capturing temporal dependencies while avoiding significant memory usage. Extensive experiments with one- and high-dimensional data demonstrate that AdaNODEs offer relative improvements of 5.88% and 28.4% over the SOTA baselines, especially demonstrating robustness across higher severity distribution shifts.",3.33,96.331,321,cold_start,Phi-4,Apple_M1(Metal)
2601.12904v1_From Prefix Cache to Fusion RAG Cache Accelerating.pdf,From Prefix Cache to Fusion RAG Cache: Accelerating LLM Inference in Retrieval-Augmented Generation,"JIAHAO WANG, WEIYU XIE, MINGXING ZHANG, BOXING ZHANG, JIANWEI DONG, YUENING ZHU, CHEN LIN, JINQI TANG, YAOCHEN HAN, ZHIYUAN AI, XIANGLIN CHEN, YONGWEI WU, CONGFENG JIANG",10.1145/3786655,2601.1290,"Retrieval-Augmented Generation, Large Language Models, KVCache, FusionRAG, Natural language processing","Retrieval-Augmented Generation (RAG) enhances Large Language Models by integrating external knowledge, reducing hallucinations but increasing prompt length, leading to higher computational costs and longer Time to First Token (TTFT). Existing solutions aim to reuse the preprocessed KVCache of each retrieved chunk to accelerate RAG, but lack of cross-chunk contextual information reduces generation quality. FusionRAG, a novel inference framework, optimizes preprocessing and reprocessing stages of RAG by embedding information from related text chunks and recomputing KVCache for focused tokens. This achieves a better trade-off between generation quality and efficiency, significantly improving generation quality at the same recomputation ratio compared to previous solutions. FusionRAG achieves up to 70% higher normalized-F1 scores than baselines and reduces TTFT by 2.66-9.39× compared to Full Attention.",3.28,119.836,393,cold_start,Phi-4,Apple_M1(Metal)
2601.12910v1_SciCoQA Quality Assurance for Scientific Paper--Co.pdf,SCICOQA: Quality Assurance for Scientific Paper–Code Alignment,"Tim Baumgärtner, Iryna Gurevych",,,"reproducibility, scientific publications, codebases, discrepancies, synthetic data, LLMs, GPT-5, computational science, AI, Physics, Quantitative Biology","We present SCICOQA, a dataset for detecting discrepancies between scientific publications and their codebases to ensure faithful implementations. Constructed from GitHub issues and reproducibility papers, SCICOQA includes 611 paper-code discrepancies (81 real, 530 synthetic) across various computational science disciplines. The evaluation of 21 LLMs, including GPT-5, highlights the challenge of detecting real-world discrepancies, with GPT-5 achieving a 45.7% detection rate. The study underscores the importance of aligning scientific text with code to address the reproducibility crisis in AI and science.",2.92,77.418,226,cold_start,Phi-4,Apple_M1(Metal)
2601.12912v1_Human Emotion Verification by Action Languages via.pdf,Human Emotion Verification by Action Languages via Answer Set Programming,"ANDREAS BR ¨ANNSTR ¨OM, JUAN CARLOS NIEVES",10.1017/xxxxx,2601.12912v1,"Action Languages, Answer Set Programming, Theory of Mind","This paper introduces the action language C-MT (Mind Transition Language), built on top of answer set programming (ASP) and transition systems, to represent the evolution of human mental states in response to observable actions. It formalizes mental states, such as emotions, as multi-dimensional configurations, drawing on psychological theories like the Appraisal Theory of Emotion. The language is extended with a novel causal rule, 'forbids to cause', and expressions for mental state dynamics, enabling modeling of valid transitions between mental states. These principles are evaluated using transition systems in terms of trajectories, supporting controlled reasoning about the dynamic evolution of human mental states. The framework allows comparison of different dynamics of change by analyzing trajectories adhering to various psychological principles. The action language is applied to design models for emotion verification, with applications in health and wellbeing, such as depression support and therapy.",3.49,80.228,280,cold_start,Phi-4,Apple_M1(Metal)
2601.12913v1_Actionable Interpretability Must Be Defined in Ter.pdf,Position: Actionable Interpretability Must Be Defined in Terms of Symmetries,"Pietro Barbiero, Mateo Espinosa Zarlenga, Francesco Giannini, Alberto Termine, Filippo Bonchi, Mateja Jamnik, Giuseppe Marra",,,"interpretability, AI, symmetries, Bayesian inversions, interpretable models, Erlangen Program","This paper argues that existing definitions of interpretability in AI are not actionable as they lack formal principles for deriving concrete modeling and inferential rules. The authors propose that interpretability should be defined in terms of symmetries, hypothesizing that four symmetries can formalize interpretability principles: inference equivariance, information invariance, concept-closure invariance, and structural invariance. These principles aim to ensure that interpretable models maintain essential properties under specific transformations, aligning model reasoning with human understanding.",3.01,82.999,250,cold_start,Phi-4,Apple_M1(Metal)
2601.12922v1_Your Privacy Depends on Others Collusion Vulnerabi.pdf,Your Privacy Depends on Others: Collusion Vulnerabilities in Individual Differential Privacy,"Johannes Kaiser, Alexander Ziller, Eleni Triantafillou, Daniel Rückert, Georgios Kaissis",,,"differential privacy, individual differential privacy, excess risk, membership inference","Individual Differential Privacy (iDP) promises users control over their privacy, but this promise can be broken in practice. A vulnerability in sampling-based iDP mechanisms is revealed, where an individual’s privacy risk depends on the privacy choices of all other data contributors. This creates a mismatch between the promise of individual privacy control and the reality of a system where risk is collectively determined. Certain distributions of privacy preferences can unintentionally inflate the privacy risk of individuals, even when formal guarantees are met. A central or colluding adversary can deliberately choose privacy budgets to amplify vulnerabilities of targeted individuals. This attack operates within the guarantees of DP, hiding excess vulnerability. Empirical evaluation demonstrates successful attacks against 62% of targeted individuals, increasing their membership inference susceptibility. To mitigate this, a privacy contract (εi, δi, ∆)-iDP is proposed, using ∆-divergences to provide users with a hard upper bound on their excess vulnerability, while offering flexibility to mechanism design. The findings demand a re-evaluation of how iDP systems are designed, audited, communicated, and deployed to make excess risks transparent and controllable.",3.4,100.606,342,cold_start,Phi-4,Apple_M1(Metal)
2601.12925v1_ForeDiffusion Foresight-Conditioned Diffusion Poli.pdf,ForeDiffusion: Foresight-Conditioned Diffusion Policy via Future View Construction for Robot Manipulation,"Weize Xie, Yi Ding, Ying He, Leilei Wang, Binwen Bai, Zheyi Zhao, Chenyang Wang, F. Richard Yu",,,"robot manipulation, diffusion strategies, visual motor control, foresight-conditioned diffusion, robotic tasks, imitation learning, diffusion-based models","Diffusion strategies have advanced visual motor control by progressively denoising high-dimensional action sequences, providing a promising method for robot manipulation. However, as task complexity increases, the success rate of existing baseline models decreases considerably. This paper proposes Foresight-Conditioned Diffusion (ForeDiffusion), which injects the predicted future view representation into the diffusion process, guiding the policy to be forward-looking and enabling it to correct trajectory deviations. ForeDiffusion employs a dual loss mechanism, combining traditional denoising loss and the consistency loss of future observations, achieving unified optimization. Extensive evaluation on the Adroit suite and the MetaWorld benchmark demonstrates that ForeDiffusion achieves an average success rate of 80% for the overall task, significantly outperforming existing mainstream diffusion methods by 23% in complex tasks, while maintaining more stable performance across the entire tasks.",3.29,100.436,330,cold_start,Phi-4,Apple_M1(Metal)
2601.12929v1_Membership Inference Test Auditing Training Data i.pdf,Membership Inference Test: Auditing Training Data in Object Classification Models,"Gonzalo Mancera, Daniel DeAlcala, Aythami Morales, Ruben Tolosana, Julian Fierrez",,,"Membership Inference Test, Object Classification Models, Data Auditing, Object Recognition, AI Ethics, Machine Learning","This research analyzes the performance of Membership Inference Tests (MINT) in determining whether specific data were used during the training phase of object recognition models. The study proposes architectures tailored for MINT models to optimize performance and efficiency in data utilization. Experiments were conducted using an object detection model, an embedding extractor, and a MINT module across three public databases with over 174K images. The proposed architecture uses convolutional layers to capture activation patterns during training, achieving precision rates between 70% and 80%. The study also examines factors influencing the MINT Module and the transparency of training processes. The research highlights the need for new auditing tools to oversee AI technologies and ensure ethical integration into society, in response to new EU legislation on AI usage.",3.27,83.821,274,cold_start,Phi-4,Apple_M1(Metal)
2601.12931v1_Online Continual Learning for Time Series a Natura.pdf,ONLINE CONTINUAL LEARNING FOR TIME SERIES: A NATURAL SCORE-DRIVEN APPROACH,"Edoardo Urettini, Daniele Atzeni, Ioanna-Yvonni Tsaknaki, Antonio Carta",,,"online continual learning, time series forecasting, natural gradient descent, robust optimization, replay buffer, regime drifts","Online continual learning (OCL) methods adapt to changing environments without forgetting past knowledge. Similarly, online time series forecasting (OTSF) is a real-world problem where data evolve in time and success depends on both rapid adaptation and long-term memory. This paper aims to strengthen the theoretical and practical connections between time series methods and OCL. It reframes neural network optimization as a parameter filtering problem, showing that natural gradient descent is a score-driven method and proving its information-theoretic optimality. Using a Student’s t likelihood in addition to natural gradient induces a bounded update, improving robustness to outliers. The paper introduces Natural Score-driven Replay (NatSR), combining a robust optimizer with a replay buffer and a dynamic scale heuristic to improve fast adaptation at regime drifts. Empirical results demonstrate that NatSR achieves stronger forecasting performance than more complex state-of-the-art methods.",3.26,94.301,307,cold_start,Phi-4,Apple_M1(Metal)
2601.12937v1_On the Evidentiary Limits of Membership Inference .pdf,On the Evidentiary Limits of Membership Inference for Copyright Auditing,"Murat Bilgehan Ertan, Emirhan Boge, Min Chen, Kaleel Mahmood, Marten van Dijk",,,"membership inference attacks, copyright auditing, large language models, paraphrasing, semantic content, adversarial settings","As large language models (LLMs) are trained on increasingly opaque corpora, membership inference attacks (MIAs) have been proposed to audit whether copyrighted texts were used during training. This paper explores whether MIAs can serve as admissible evidence in adversarial copyright disputes, particularly when training data is obfuscated to preserve semantic content. The study introduces SAGE, a paraphrasing framework that alters lexical structure while maintaining semantic content and utility. Experiments show that state-of-the-art MIAs degrade when models are fine-tuned on SAGE-generated paraphrases, indicating their brittleness in adversarial settings and insufficiency as standalone mechanisms for copyright auditing of LLMs.",3.05,86.591,264,cold_start,Phi-4,Apple_M1(Metal)
2601.12938v1_The Post-Turing Condition Conceptualising Artifici.pdf,The Post-Turing Condition: Conceptualising Artificial Subjectivity and Synthetic Sociality,"Thorsten Jelinek, Patrick Glauner, Alvin Wang Graylin, Yubao Qiu",,,"artificial intelligence, social coordination, meaning formation, PRMO framework, Synthetic Sociality, Quadrangulation, socially embedded AI systems","In the Post-Turing era, artificial intelligence increasingly shapes social coordination and meaning formation rather than merely automating cognitive tasks. The central challenge is therefore not whether machines become conscious, but whether processes of interpretation and shared reference are progressively automated in ways that marginalize human participation. This paper introduces the PRMO framework, relating AI design trajectories to four constitutive dimensions of human subjectivity: Perception, Representation, Meaning, and the Real. Within this framework, Synthetic Sociality denotes a technological horizon in which artificial agents negotiate coherence and social order primarily among themselves, raising the structural risk of human exclusion from meaning formation. To address this risk, the paper proposes Quadrangulation as a design principle for socially embedded AI systems, requiring artificial agents to treat the human subject as a constitutive reference within shared contexts of meaning. This work is a conceptual perspective that contributes a structural vocabulary for analyzing AI systems at the intersection of computation and society, without proposing a specific technical implementation.",3.84,83.558,321,cold_start,Phi-4,Apple_M1(Metal)
2601.12939v1_Active Inference-Driven World Modeling for Adaptiv.pdf,ACTIVE INFERENCE-DRIVEN WORLD MODELING FOR ADAPTIVE UAV SWARM TRAJECTORY DESIGN,"Kaleem Arshid, Ali Krayani, Lucio Marcenaro, David Martin Gomez, Carlo Regazzoni",,,"Autonomous Systems, World Model, UAV-Swarm, Probabilistic Decision-Making, Active-Inference","This paper proposes an Active Inference–based framework for autonomous trajectory design in UAV swarms. The method integrates probabilistic reasoning and self-learning to enable distributed mission allocation, route ordering, and motion planning. Expert trajectories generated using a Genetic Algorithm with Repulsion Forces (GA–RF) are employed to train a hierarchical World Model capturing swarm behavior across mission, route, and motion levels. During online operation, UAVs infer actions by minimizing divergence between current beliefs and model-predicted states, enabling adaptive responses to dynamic environments. Simulation results show faster convergence, higher stability, and safer navigation than Q-Learning, demonstrating the scalability and cognitive grounding of the proposed framework for intelligent UAV swarm control.",3.19,84.416,269,cold_start,Phi-4,Apple_M1(Metal)
2601.12946v1_AI-generated data contamination erodes pathologica.pdf,AI-generated data contamination erodes pathological variability and diagnostic reliability,"Hongyu He, Shaowen Xiang, Ye Zhang, Yingtao Zhu, Jin Zhang, Hao Deng, Emily Alsentzer, Qingyu Chen, Kun-Hsing Yu, Andrew Marmenshall, Tingting Chen, Srinivas Anumasa, Daniel Ebner, Dean Ho, Kee Yuan Ngiam, Ching-Yu Cheng, Dianbo Liu",,,"Generative AI, medical records, synthetic content, pathological variability, diagnostic reliability, clinical consequences, data contamination, human verification, clinical text generation, vision-language reporting, medical image synthesis, phenotypes, demographic representations, false diagnostic confidence, physician evaluation, mitigation strategies, policy-mandated human oversight","Generative artificial intelligence (AI) is rapidly populating medical records with synthetic content, creating a feedback loop where future models are increasingly at risk of training on uncurated AI-generated data. This study shows that without mandatory human verification, this cycle leads to a rapid erosion of pathological variability and diagnostic reliability. Analysis of over 800,000 synthetic data points reveals that models converge toward generic phenotypes, with rare critical findings disappearing and demographic representations skewing toward middle-aged males. False diagnostic confidence increases, with false reassurance rates tripling to 40%. Blinded physician evaluation confirms that AI-generated documentation becomes clinically useless after two generations. Mitigation strategies are evaluated, with quality-aware filtering of real data shown to preserve diversity. The study concludes that without policy-mandated human oversight, generative AI deployment threatens to degrade healthcare data ecosystems.",3.87,112.883,437,cold_start,Phi-4,Apple_M1(Metal)
2601.12951v1_Beyond Accuracy Characterizing Code Comprehension .pdf,Beyond Accuracy: Characterizing Code Comprehension Capabilities in (Large) Language Models,"Felix Mächtle, Jan-Niclas Serr, Nils Loose, Thomas Eisenbarth",,,"Code Comprehension, Model Evaluation and Benchmarking, Machine Learning for Software Engineering","Large Language Models (LLMs) are increasingly integrated into software engineering workflows, yet current benchmarks provide only coarse performance summaries that obscure the diverse capabilities and limitations of these models. This paper investigates whether LLMs’ code-comprehension performance aligns with traditional human-centric software metrics or instead reflects distinct, non-human regularities. A diagnostic framework is introduced to reframe code understanding as a binary input–output consistency task, enabling the evaluation of classification and generative models. Using a large-scale dataset, the study correlates model performance with traditional, human-centric complexity metrics, such as lexical size, control-flow complexity, and abstract syntax tree structure. The analyses reveal minimal correlation between human-defined metrics and LLM success (AUROC 0.63), while shadow models achieve substantially higher predictive performance (AUROC 0.86), capturing complex, partially predictable patterns beyond traditional software measures. These findings suggest that LLM comprehension reflects model-specific regularities only partially accessible through either human-designed or learned features, emphasizing the need for benchmark methodologies that move beyond aggregate accuracy and toward instance-level diagnostics, while acknowledging fundamental limits in predicting correct outcomes.",3.45,96.906,334,cold_start,Phi-4,Apple_M1(Metal)
2601.13007v1_ArchAgent Scalable Legacy Software Architecture Re.pdf,SCALABLE LEGACY SOFTWARE ARCHITECTURE RECOVERY WITH LLMS,"Rusheng Pan, Bingcheng Mao, Tianyi Ma, Zhenhua Ling",,,"Software architecture recovery, code repository, cross-repository context, large language models","Recovering accurate architecture from large-scale legacy software is hindered by architectural drift, missing relations, and the limited context of Large Language Models (LLMs). We present ArchAgent, a scalable agent-based framework that combines static analysis, adaptive code segmentation, and LLM-powered synthesis to reconstruct multiview, business-aligned architectures from cross-repository codebases. ArchAgent introduces scalable diagram generation with contextual pruning and integrates cross-repository data to identify business-critical modules. Evaluations of typical large-scale GitHub projects show significant improvements over existing benchmarks. An ablation study confirms that dependency context improves the accuracy of generated architectures of production-level repositories, and a real-world case study demonstrates effective recovery of critical business logics from legacy projects.",3.17,79.093,251,cold_start,Phi-4,Apple_M1(Metal)
2601.13013v1_HT-GNN Hyper-Temporal Graph Neural Network for Cus.pdf,HT-GNN: Hyper-Temporal Graph Neural Network for Customer Lifetime Value Prediction in Baidu Ads,"Xiaohui Zhao, Xinjian Zhao, Jiahui Zhang, Guoyu Liu, Houzhi Wang, Shu Wu",,,"Lifetime Value Prediction, Advertising Platform","Lifetime value (LTV) prediction is crucial for news feed advertising, enabling platforms to optimize bidding and budget allocation for long-term revenue growth. This paper introduces a Hyper-Temporal Graph Neural Network (HT-GNN) to address challenges in LTV prediction, such as demographic-based targeting and dynamic marketing strategies. HT-GNN models demographic heterogeneity and temporal dynamics through a hypergraph-supervised module, a transformer-based temporal encoder, and a task-adaptive mixture-of-experts. Experiments on Baidu Ads with 15 million users show that HT-GNN outperforms state-of-the-art methods across all metrics and prediction horizons.",2.99,80.602,241,cold_start,Phi-4,Apple_M1(Metal)
2601.13018v1_Bi-Attention HateXplain  Taking into account the s.pdf,Bi-Attention HateXplain: Taking into account the sequential aspect of data during explainability in a multi-task context,Ghislain Dorian Tchuente Mondjo,,,"Multitask learning, Deep Learning, Hate speech, Explainability, Bi-Attention","Technological advances in the Internet and online social networks have brought many benefits to humanity, but also an increase in hate speech, a major global threat. To improve the reliability of black-box models used for hate speech detection, post-hoc approaches like LIME, SHAP, and LRP provide explanations after training the classification model. In contrast, multi-task approaches based on the HateXplain benchmark learn to explain and classify simultaneously. However, results from HateXplain-based algorithms show that predicted attention varies considerably when it should be constant, leading to inconsistent interpretations, instability of predictions, and learning difficulties. To address this, the BiAtt-BiRNN-HateXplain (Bidirectional Attention BiRNN HateXplain) model is proposed. This model is easier to explain compared to LLMs, which are more complex, and takes into account the sequential aspect of input data during explainability thanks to a BiRNN layer. If the explanation is correctly estimated through multi-task learning (explainability and classification task), the model could classify better and commit fewer unintentional bias errors related to communities. Experimental results on HateXplain data show a clear improvement in detection performance, explainability, and a reduction in unintentional bias.",3.44,102.692,353,cold_start,Phi-4,Apple_M1(Metal)
2601.13020v1_PASs-MoE Mitigating Misaligned Co-drift among Rout.pdf,PASs-MoE: Mitigating Misaligned Co-drift among Router and Experts via Pathway Activation Subspaces for Continual Learning,"Zhiyan Hou, Haiyun Guo, Haokai Ma, Yandu Sun, Yonghui Yang, Jinqiao Wang",,,"Continual Learning, Multimodal Large Language Models, Mixture-of-Experts, Low-rank Adaptation, Pathway Activation Subspaces","Continual instruction tuning (CIT) requires multimodal large language models (MLLMs) to adapt to a stream of tasks without forgetting prior capabilities. A common strategy is to isolate updates by routing inputs to different LoRA experts. However, existing LoRA-based Mixture-of-Experts (MoE) methods often jointly update the router and experts in an indiscriminate way, causing the router’s preferences to co-drift with experts’ adaptation pathways and gradually deviate from early-stage input–expert specialization. This is termed as Misaligned Co-drift, which blurs expert responsibilities and exacerbates forgetting. To address this, the pathway activation subspace (PASs), a LoRA-induced subspace that reflects which low-rank pathway directions an input activates in each expert, is introduced. Based on PASs, a fixed-capacity PASs-based MoE–LoRA method with two components is proposed: PAS-guided Reweighting, which calibrates routing using each expert’s pathway activation signals, and PAS-aware Rank Stabilization, which selectively stabilizes rank directions important to previous tasks. Experiments on a CIT benchmark show that this approach consistently outperforms conventional continual learning baselines and MoE–LoRA variants in both accuracy and anti-forgetting without adding parameters.",3.29,124.762,411,cold_start,Phi-4,Apple_M1(Metal)
2601.13048v1_Analysis of Long Range Dependency Understanding in.pdf,ANALYSIS OF LONG RANGE DEPENDENCY UNDERSTANDING IN STATE SPACE MODELS,"Srividya Ravikumar, Abhinav Anand, Shweta Verma, Mira Mezini",,,"Structured state-space models, interpretability, vulnerability detection","Although state-space models (SSMs) have demonstrated strong performance on long-sequence benchmarks, most research has emphasized predictive accuracy rather than interpretability. This work presents the first systematic kernel interpretability study of the diagonalized state-space model (S4D) trained on a real-world task (vulnerability detection in source code). Through time and frequency domain analysis of the S4D kernel, it is shown that the long-range modeling capability of S4D varies significantly under different model architectures, affecting model performance. The study reveals that the S4D kernel can behave as a low-pass, band-pass, or high-pass filter depending on the architecture. The insights from this analysis can guide future work in designing better S4D-based models.",3.12,75.93,237,cold_start,Phi-4,Apple_M1(Metal)
2601.13054v1_TinyML-Enabled IoT for Sustainable Precision Irrig.pdf,TinyML-Enabled IoT for Sustainable Precision Irrigation,"Kamogelo Taueatsoala, Caitlyn Daniels, Angelina J. Ramsunar, Petrus Bronkhorst, Absalom E. Ezugwu",,,"TinyML, edge computing, Internet of Things, precision agriculture, smart irrigation, sustainable water management, embedded machine learning, resource-constrained systems","This paper presents a novel IoT framework integrating Tiny Machine Learning (TinyML) for precision irrigation, addressing water scarcity and climate challenges in small-scale farming. The proposed four-layer architecture uses low-cost hardware, including an ESP32 microcontroller and a Raspberry Pi, for autonomous decision-making without cloud dependency. Environmental monitoring is achieved through capacitive soil moisture, temperature, humidity, pH, and ambient light sensors. Gradient Boosting was identified as the superior model, achieving high accuracy in predicting irrigation needs. The system uses an MQTT-based LAN protocol for local communication, ensuring reliable operation in areas with limited internet connectivity. Experimental validation showed significant water usage reduction compared to traditional methods, confirming the system's viability for sustainable deployment in resource-constrained rural settings.",3.3,87.766,290,cold_start,Phi-4,Apple_M1(Metal)
2601.13060v1_MagicGUI-RMS A Multi-Agent Reward Model System for.pdf,MAGICGUI-RMS: A MULTI-AGENT REWARD MODEL SYSTEM FOR SELF-EVOLVING GUI AGENTS VIA AUTOMATED FEEDBACK REFLUX,"Zecheng Li, Zhihui Cao, Wenke Huang, Yudong Zhang, Keying Qi, Rui Wang, Zeyu Zheng, Jian Zhao, Hao Zhu, Hengxin Wu, Yuran Wang, Guitao Fan, Guokun Wu, Yicong Liu, Zhilin Gao, Haikun Xu, He Yang, Minqi Xiang, Xingyu Liu, Zuojian Wang",,,"GUI agents, multi-agent reward model system, self-evolving, automated feedback, trajectory evaluation, training data, adaptive learning, Domain-Specific Reward Model, General-Purpose Reward Model, reward learning, data-reflux mechanism","Graphical user interface (GUI) agents are advancing towards autonomous interaction and reliable task execution. However, challenges remain in automating trajectory evaluation and generating high-quality training data. MagicGUI-RMS, a multi-agent reward model system, addresses these challenges by integrating Domain-Specific and General-Purpose Reward Models for adaptive trajectory evaluation and self-evolving learning. It supports reward learning at scale with a structured data construction pipeline, reducing annotation costs while maintaining sample fidelity. The system identifies erroneous actions, proposes refined alternatives, and enhances agent behavior through an automated data-reflux mechanism. Experiments show substantial gains in task accuracy and behavioral robustness, establishing MagicGUI-RMS as a foundation for self-improving GUI agents.",3.5,120.366,421,cold_start,Phi-4,Apple_M1(Metal)
2601.13075v1_METIS Mentoring Engine for Thoughtful Inquiry  Sol.pdf,METIS: Mentoring Engine for Thoughtful Inquiry & Solutions,"Abhinav Rajeev Kumar, Dhruv Trehan, Paras Chopra",,,"AI mentor, research mentorship, undergraduates, publishable paper, tool-augmented assistant, LLM, multi-turn tutoring, empirical comparison","This paper introduces METIS, an AI tool designed to mentor undergraduates in transforming initial research ideas into publishable papers. METIS is evaluated against GPT-5 and Claude Sonnet 4.5 across various writing stages, demonstrating superior performance in certain aspects. The system incorporates literature search, curated guidelines, methodology checks, and memory, aiming to provide stage-aware assistance. The study highlights METIS's strengths in document-grounded stages and discusses its failure modes. The paper also contributes a practical mentoring workflow, a simple system architecture, and empirical comparisons, along with open materials for reproducibility.",2.94,77.485,228,cold_start,Phi-4,Apple_M1(Metal)
2601.13111v1_CORE-T COherent REtrieval of Tables for Text-to-SQ.pdf,CORE-T: COherent REtrieval of Tables for Text-to-SQL,"Hassan Soliman, Vivek Gupta, Dan Roth, Iryna Gurevych",,arXiv:2601.13111v1,"text-to-SQL, table retrieval, open-book setting, dense retrieval, LLM-generated metadata, table compatibility, multi-table execution","Realistic text-to-SQL workflows often require joining multiple tables, making accurate table retrieval a key bottleneck. This paper introduces CORE-T, a scalable, training-free framework that uses LLM-generated metadata and a lightweight table-compatibility cache to improve table selection and execution accuracy in open-book settings. CORE-T enhances table retrieval by reducing the number of tables retrieved and improving multi-table execution accuracy, while using fewer tokens compared to LLM-intensive baselines.",2.92,77.304,226,cold_start,Phi-4,Apple_M1(Metal)
2601.13114v1_IntAgent NWDAF-Based Intent LLM Agent Towards Adva.pdf,IntAgent: NWDAF-Based Intent LLM Agent Towards Advanced Next Generation Networks,"Abdelrahman Soliman, Ahmed Refaey, Aiman Erbad, Amr Mohamed",,,"Core Network, Next Generation Network, Large Language Models, Intent Management, Intelligent Networks, Closed Loop","Intent-based networks (IBNs) are gaining prominence as an innovative technology that automates network operations through high-level request statements, defining what the network should achieve. This work introduces IntAgent, an intelligent intent LLM agent that integrates NWDAF analytics and tools to fulfill the network operator’s intents. Unlike previous approaches, an intent tools engine is developed directly within the NWDAF analytics engine, allowing the agent to utilize live network analytics to inform its reasoning and tool selection. An enriched, 3GPP-compliant data source enhances the dynamic, context-aware fulfillment of network operator goals, along with an MCP tools server for scheduling, monitoring, and analytics tools. The efficacy of the framework is demonstrated through two practical use cases: ML-based traffic prediction and scheduled policy enforcement, validating IntAgent’s ability to autonomously fulfill complex network intents.",3.17,90.348,286,cold_start,Phi-4,Apple_M1(Metal)
2601.13122v1_Responsible AI for General-Purpose Systems Overvie.pdf,"Responsible AI for General-Purpose Systems: Overview, Challenges, and A Path Forward","Gourab K. Patro, Himanshi Agrawal, Himanshu Gharat, Supriya Panigrahi, Nim Sherpa, Vishal Vaddina, Dagnachew Birru",,2601.13122v1,"Responsible AI, General-Purpose AI, Large Language Models, Diffusion Models, Multimodal Large Language Models, AI alignment, retrieval-augmented generation, reasoning enhancements","Modern general-purpose AI systems, built using large language and vision models, are capable of performing a wide range of tasks, making them popular across industries. However, they pose risks such as hallucinations, toxicity, and stereotypes, which make them untrustworthy. This paper reviews these risks and vulnerabilities in the context of eight responsible AI principles: fairness, privacy, explainability, robustness, safety, truthfulness, governance, and sustainability. It argues that the high Degree of Freedom in output of general-purpose AI, compared to traditional task-specific AI, necessitates a rethinking of responsible AI approaches. The paper introduces the C 2V2 desiderata (Control, Consistency, Value, Veracity) to meet responsible AI requirements for future general-purpose AI systems and discusses recent efforts in AI alignment, retrieval-augmented generation, and reasoning enhancements. It concludes that responsible general-purpose AI can be achieved by modeling application- or domain-dependent responsible AI requirements along the C 2V2 dimensions and combining various techniques to meet these desiderata.",3.57,110.495,395,cold_start,Phi-4,Apple_M1(Metal)
2601.13142v1_TVWorld Foundations for Remote-Control TV Agents.pdf,TVWorld: Foundations for Remote-Control TV Agents,"Zhantao Ma, Quanfeng Lu, Shuai Zhong, Dahai Yu, Ping Luo, Michael K. Ng",,,"large vision–language models, device control, remote-control interaction, TV navigation, graph-based abstraction, topology-aware navigation, focus-aware grounding, LVLMs","Recent large vision–language models (LVLMs) have shown potential for device control, but research has mainly focused on point-and-click interactions, neglecting remote-control interactions common in TV usage. To address this, the authors introduce TVWorld, an offline graph-based abstraction for TV navigation, enabling reproducible evaluation. They propose two benchmarks, TVWorld-N and TVWorld-G, to assess TV-use capabilities, highlighting the need for topology awareness in focus-based navigation. The authors develop TVTheseus, a model specialized for TV navigation, achieving a 68.3% success rate on TVWorld-N, surpassing existing baselines. This work provides insights into developing effective TV-use agents.",3.21,86.008,276,cold_start,Phi-4,Apple_M1(Metal)
2601.13160v1_Training instability in deep learning follows low-.pdf,Training instability in deep learning follows low-dimensional dynamical principles,"Zhipeng Zhang, Zhenjie Yao, Kai Li, Lei Yang",,arXiv:2601.13160v1,"training instability, deep learning, reinforcement learning, large language models, dynamical systems","Deep learning systems achieve remarkable empirical performance, yet the stability of the training process itself remains poorly understood. Training unfolds as a high-dimensional dynamical system in which small perturbations to optimization, data, parameters, or learning signals can induce abrupt and irreversible collapse, undermining reproducibility and scalability. A unified dynamical perspective characterizes training stability as an intrinsic property of learning systems, organized along four interacting dimensions: optimization, environmental/data, parametric, and learning-signal stability. Controlled perturbation auditing of training trajectories probes how learning dynamics respond to structured disturbances without modifying learning algorithms. Across reinforcement learning and large language model training, high final performance is frequently decoupled from training stability; controlled stochasticity consistently buffers learning dynamics across paradigms; and deviations in low-dimensional latent meta-states systematically precede observable performance collapse. These findings establish training stability as a measurable and comparable dynamical property of learning systems, providing a descriptive foundation for studying learning dynamics beyond final performance outcomes.",3.58,87.141,312,cold_start,Phi-4,Apple_M1(Metal)
2601.13166v1_From 100000 images to winning the first brain MRI .pdf,"From 100,000+ images to winning the first brain MRI foundation model challenges: Sharing lessons and models","Pedro M. Gordaliza, Jaume Banus, Benoît Gérin, Maxence Wynen, Nataliia Molchanova, Jonas Richiardi, Meritxell Bach Cuadra",,,"Foundation Models, Medical Image Analysis, Brain MRI, Self-Supervised Learning, U-Net CNN Architecture, Anatomical Priors, Neuroimaging Domain Knowledge","Developing Foundation Models for medical image analysis is crucial to address the unique challenges in radiological tasks. The first challenges of this kind for 3D brain MRI, SSL3D and FOMO25, were held at MICCAI 2025. The authors' solution ranked first in both contests, utilizing a U-Net CNN architecture combined with strategies leveraging anatomical priors and neuroimaging domain knowledge. Their models trained significantly faster and were smaller than competing transformer-based approaches. Foundation models have revolutionized artificial intelligence, first in natural language processing and subsequently in computer vision. Medical imaging, particularly radiology, faces challenges such as data sparsity, protocol variability, and expensive expert annotations. Brain MRI exemplifies both the promise and difficulty of FM in medical imaging due to its anatomical complexity and wide spectrum of pathologies. The field faces unique obstacles like high-dimensional 3D volumetric data, complementary MRI contrasts, vendor-specific acquisition protocols, and population heterogeneity. The SSL3D and FOMO25 challenges at MICCAI 2025 represented the first rigorous evaluation of SSL FM for neuroimaging, assembling an unprecedented pre-training dataset of 34,191 subjects with multiple contrasts and timepoints, totaling 114,570 3D volumes.",3.23,131.527,425,cold_start,Phi-4,Apple_M1(Metal)
2601.13186v1_Prompt Injection Mitigation with Agentic AI Nested.pdf,"Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching","Diego Gosmar, Deborah A. Dahl",,2601.13186v1,"Prompt Injection, Agentic AI, Nested Learning, Semantic Caching, AI Sustainability, Large Language Models, Total Injection Vulnerability Score (TIVS), Observability Score Ratio (OSR), Continuum Memory Systems, Security Analysis, Environmental Sustainability","Prompt injection remains a central obstacle to the safe deployment of large language models, particularly in multi-agent settings where intermediate outputs can propagate or amplify malicious instructions. This paper extends the evaluation framework with semantic similarity-based caching, a dedicated fourth-agent rule-based evaluator, and a fifth metric (Observability Score Ratio) to yield TIVS-O, investigating how defense effectiveness interacts with transparency in a HOPE-inspired Nested Learning architecture. The proposed system combines a three-stage agentic pipeline with Continuum Memory Systems that implement semantic similarity-based caching across 301 injection-focused prompts drawn from ten attack families. A dedicated fourth agent performs comprehensive security analysis using five key performance indicators. Experiments show that the system achieves secure responses with significantly reduced high-risk breaches, while semantic caching delivers substantial computational savings enabling real-time responses, cost reduction, and energy savings. The semantic caching mechanism not only accelerates inference but demonstrates that security architectures can simultaneously advance environmental sustainability—achieving 41.6% reduction in computational load translates directly to proportional decreases in energy consumption and carbon emissions. These results indicate that Observability-aware evaluation can reveal non-monotonic effects within multi-agent pipelines, and that memory-augmented agents can jointly maximize security robustness, real-time performance, operational cost savings, and environmental sustainability without modifying underlying model weights, providing a production-ready pathway for secure and green LLM deployments.",3.76,113.072,425,cold_start,Phi-4,Apple_M1(Metal)
2601.13187v1_Scientific production in the era of Large Language.pdf,Scientific production in the era of Large Language Models,"Keigo Kusumegi, Xinyu Yang, Paul Ginsparg, Mathijs de Vaan, Toby Stuart, Yian Yin",10.1126/science.adw3000,,"Large Language Models, scientific research, paper production, writing complexity, paper quality, diverse prior work, scientific evaluation","Large Language Models (LLMs) are rapidly reshaping scientific research. This study analyzes changes using datasets with 2.1M preprints, 28K peer review reports, and 246M online accesses. Key findings include: 1) a significant increase in paper production by scientists using LLMs, 2) a reversal in the relationship between writing complexity and paper quality, and 3) increased access and citation of diverse prior work by LLM adopters. These shifts suggest a need for changes in how scientific works are evaluated by journals, funding agencies, and tenure committees.",3.66,71.88,263,cold_start,Phi-4,Apple_M1(Metal)
2601.13197v1_Diffusion-Driven Synthetic Tabular Data Generation.pdf,Diffusion-Driven Synthetic Tabular Data Generation for Enhanced DoS/DDoS Attack Classification,"Aravind B, Anirud R.S., Sai Surya Teja N, Bala Subrahmanya Sriranga Navaneeth A, Karthika R, Mohankumar N",,,"Network intrusion detection, Tabular diffusion models, Class imbalance, DDoS attack detection, Data augmentation, IDS2017","Class imbalance refers to a situation where certain classes in a dataset have significantly fewer samples than others, leading to biased model performance. This paper addresses class imbalance in network intrusion detection using Tabular Denoising Diffusion Probability Models (TabDDPM) for data augmentation. The approach synthesizes high-fidelity minority-class samples from the CIC-IDS2017 dataset through iterative denoising processes. Synthetic samples were generated for minority classes with smaller samples and merged with the original dataset. The augmented training data enables an ANN classifier to achieve near-perfect recall on previously underrepresented attack classes. These results establish diffusion models as an effective solution for tabular data imbalance in security domains, with potential applications in fraud detection and medical diagnostics.",3.22,91.072,293,cold_start,Phi-4,Apple_M1(Metal)
2601.13206v1_Real-Time Deadlines Reveal Temporal Awareness Fail.pdf,Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues,"Neil Sehgal, Sharath Chandra Guntuku, Lyle Ungar",,,"Large Language Models, temporal awareness, negotiations, real-time deadlines, strategic dialogues","Large Language Models (LLMs) generate text token-by-token in discrete time, yet real-world communication critically depends on continuous time constraints. This study investigates how LLMs adjust their behavior in time-sensitive settings using simulated negotiations under strict deadlines. Results show that LLMs struggle to internally track elapsed time, as evidenced by higher deal closure rates when agents receive remaining-time updates. Despite near-perfect deal closure rates under turn-based limits, LLMs exhibit a systematic lack of temporal awareness, which could constrain their deployment in time-sensitive applications.",3.02,72.45,219,cold_start,Phi-4,Apple_M1(Metal)
2601.13217v1_Beyond Single-shot Writing Deep Research Agents ar.pdf,Beyond Single-shot Writing: Deep Research Agents are Unreliable at Multi-turn Report Revision,"Bingsen Chen, Boyan Li, Ping Nie, Yuyu Zhang, Xi Ye, Chen Zhao",,2601.13217v1,"Deep Research Agents, multi-turn report revision, evaluation, feedback simulation, report generation","Existing benchmarks for Deep Research Agents (DRAs) treat report generation as a single-shot writing task, diverging from the iterative drafting and revision process used by human researchers. This study introduces MRDRE, an evaluation suite for multi-turn report revision, revealing that DRAs struggle with maintaining content and citation quality across revisions. The analysis shows that even the best-performing agents have significant room for improvement, as they often disrupt content outside the feedback's scope and fail to preserve earlier edits. The study suggests that these issues are not easily resolved through inference-time fixes like prompt engineering or dedicated sub-agents.",3.14,78.725,247,cold_start,Phi-4,Apple_M1(Metal)
2601.13222v1_Incorporating QA Nuggets into Retrieval-Augmented .pdf,Incorporating Q&A Nuggets into Retrieval-Augmented Generation,"Laura Dietz, Bryan Li, Gabrielle Liu, Jia-Huei Ju, Eugene Yang, Dawn Lawrie, William Walden, James Mayfield",,arXiv:2601.13222v1,"RAG, LLM judge, nugget-based evaluation","RAGE systems integrate ideas from automatic evaluation (E) into Retrieval-augmented Generation (RAG). This paper presents Crucible, a Nugget-Augmented Generation System that preserves explicit citation provenance by constructing a bank of Q&A nuggets from retrieved documents and uses them to guide extraction, selection, and report generation. Reasoning on nuggets avoids repeated information through clear and interpretable Q&A semantics—instead of opaque cluster abstractions—while maintaining citation provenance throughout the entire generation process. Evaluated on the TREC NECIR 2024 collection, the Crucible system substantially outperforms Ginger, a recent nugget-based RAG system, in nugget recall, density, and citation grounding.",3.43,82.002,281,cold_start,Phi-4,Apple_M1(Metal)
2601.13227v1_Insider Knowledge How Much Can RAG Systems Gain fr.pdf,Insider Knowledge: How Much Can RAG Systems Gain from Evaluation Secrets?,"Laura Dietz, Bryan Li, Eugene Yang, Dawn Lawrie, William Walden, James Mayfield",,arXiv:2601.13227v1,"Retrieval-augmented generation, LLM judge, Nugget evaluation","RAG systems are increasingly evaluated and optimized using LLM judges, an approach that is rapidly becoming the dominant paradigm for system assessment. Nugget-based approaches are now embedded not only in evaluation frameworks but also in the architectures of RAG systems themselves. While this integration can lead to genuine improvements, it also creates a risk of faulty measurements due to circularity. This paper investigates this risk through comparative experiments with nugget-based RAG systems, including Ginger and Crucible, against strong baselines such as GptResearcher. By deliberately modifying Crucible to generate outputs optimized for an LLM judge, it is shown that near-perfect evaluation scores can be achieved when elements of the evaluation—such as prompt templates or gold nuggets—are leaked or can be predicted. The results highlight the importance of blind evaluation settings and methodological diversity to guard against mistaking metric overfitting for genuine system progress.",3.58,85.314,305,cold_start,Phi-4,Apple_M1(Metal)
2601.13228v1_Autoregressive Models Rival Diffusion Models at AN.pdf,Autoregressive Models Rival Diffusion Models at Any-Order Generation,"Tianqi Du, Lizhe Fang, Weijie Yang, Chenheng Zhang, Zeming Wei, Yifei Wang, Yisen Wang",,,"autoregressive models, diffusion models, any-order generation, bidirectional conditioning, language modeling, text generation","Diffusion language models enable any-order generation and bidirectional conditioning, offering flexibility for tasks such as infilling, rewriting, and self-correction. However, their single-step dependency formulation limits modeling depth and often results in lower sample quality and stability compared to autoregressive (AR) models. To address this, the authors propose Any-order Any-subset Autoregressive modeling (A3), a framework that extends AR factorization to arbitrary token groups and generation orders. A3 maintains the probabilistic rigor and multi-layer dependency modeling of AR while inheriting diffusion models' flexibility for parallel and bidirectional generation. Implemented through a two-stream attention architecture and a progressive adaptation strategy, A3 transitions pretrained AR models toward any-order prediction. Experiments demonstrate that A3 outperforms diffusion-based models while maintaining flexible decoding, offering a unified approach for a flexible, efficient, and novel language modeling paradigm.",3.4,92.174,313,cold_start,Phi-4,Apple_M1(Metal)
2601.13233v1_RAG A Random-Forest-Based Generative Design Framew.pdf,RAG: A RANDOM-FOREST-BASED GENERATIVE DESIGN FRAMEWORK FOR UNCERTAINTY-AWARE DESIGN OF METAMATERIALS WITH COMPLEX FUNCTIONAL RESPONSE REQUIREMENTS,"Bolin Chen, Dex Doksoo Lee, Wei 'Wayne' Chen, Wei Chen",,2601.13233v1,"Random forest, Generative design, Functional response, Uncertainty quantification","Metamaterials design for advanced functionality often involves inverse design on nonlinear and condition-dependent responses, described by continuous functions. Existing methods focus on vector-valued responses, while inverse design of functional responses is challenging due to high-dimensionality, complexity of design requirements, and non-existence or non-uniqueness of feasible solutions. Generative design approaches, though promising, are data-hungry, handle design requirements heuristically, and may generate infeasible designs without uncertainty quantification. This paper introduces a RAndom-forest-based Generative approach (RAG) that leverages the small-data compatibility of random forests and reformulates the forward mapping in a discretization-invariant way, enabling data-efficient predictions of high-dimensional functional responses. The framework estimates the likelihood of solutions conditioned on design requirements, quantifying the trustworthiness of generated designs and reflecting the relative difficulty across different requirements. The one-to-many mapping is addressed through single-shot design generation by sampling from the conditional likelihood. Demonstrations include acoustic metamaterials with prescribed partial passbands/stopbands and mechanical metamaterials with targeted snap-through responses, using 500 and 1057 samples, respectively. Its data-efficiency is benchmarked against neural networks on a public mechanical metamaterial dataset with nonlinear stress-strain relations. The framework provides a lightweight, trustworthy pathway to inverse design involving functional responses, expensive simulations, and complex design requirements, beyond metamaterials.",3.61,117.715,425,cold_start,Phi-4,Apple_M1(Metal)
2601.13235v1_RubRIX Rubric-Driven Risk Mitigation in Caregiver-.pdf,RubRIX: Rubric-Driven Risk Mitigation in Caregiver-AI Interactions,"Drishti Goel, Jeongah Lee, Qiuyue Joy Zhong, Violeta J. Rodriguez, Daniel S. Brown, Ravi Karkar, Dong Whi Yoo, Koustuv Saha",,,"Caregiver-AI Interactions, Risk Mitigation, LLMs, Ethic of Care, Healthcare, Domain-Sensitive Evaluation","The paper introduces RubRIX, a framework for evaluating risks in large language model (LLM) responses within caregiving contexts. It addresses the complex needs of caregivers, such as information-seeking, emotional validation, and distress cues, which require careful evaluation of response safety and appropriateness. RubRIX operationalizes five risk dimensions: Inattention, Bias & Stigma, Information Inaccuracy, Uncritical Affirmation, and Epistemic Arrogance. The framework was tested on over 20,000 caregiver queries, showing significant risk reduction. The study emphasizes the need for domain-sensitive, user-centered evaluation frameworks for AI in caregiving support.",3.22,90.451,291,cold_start,Phi-4,Apple_M1(Metal)
2601.13236v1_Pixelwise Uncertainty Quantification of Accelerate.pdf,Pixelwise Uncertainty Quantification of Accelerated MRI Reconstruction,"Ilias I. Giannakopoulos, Lokesh B Gautham Muthukumar, Yvonne W. Lui, Riccardo Lattanzi",,,"Conformal Prediction, Magnetic Resonance Imaging, Parallel Imaging, Quantile Regression, Uncertainty Quantification","This work introduces a framework for pixel-wise uncertainty quantification in parallel MRI reconstructions, enabling automatic identification of unreliable regions without ground-truth reference images. The method integrates conformal quantile regression with image reconstruction methods to estimate pixel-wise uncertainty intervals. It was trained and evaluated on Cartesian undersampled brain and knee data from the fastMRI dataset using acceleration factors from 2 to 10. An end-to-end Variational Network was used for image reconstruction. Quantitative experiments show strong agreement between predicted uncertainty maps and true reconstruction error, with Pearson correlation coefficients higher than 90% at acceleration levels of four-fold and above. The proposed framework enables evaluation of reconstruction quality without fully-sampled ground-truth reference images, representing a step toward adaptive MRI acquisition protocols that balance scan time and diagnostic reliability.",3.19,89.694,286,cold_start,Phi-4,Apple_M1(Metal)
2601.13238v1_A Semantic Decoupling-Based Two-Stage Rainy-Day At.pdf,A Semantic Decoupling–Based Two-Stage Rainy-Day Attack for Revealing Weather Robustness Deficiencies in Vision–Language Models,"Chengyin Hu, Xiang Chen, Zhe Jia, Weiwen Shi, Fengyu Zhang, Jiujiang Guo, Yiwei Wei",,,"Vision-Language Models, Adversarial Attacks, Weather Robustness, Semantic Decoupling, Rainy-Day Attack, Cross-Modal Semantic Alignment","Vision-Language Models (VLMs) are trained on image-text pairs under canonical visual conditions and perform well on multimodal tasks. However, their robustness to real-world weather conditions, such as rain, and the stability of cross-modal semantic alignment under such conditions are not well studied. This paper introduces an adversarial framework that exploits realistic weather conditions to attack VLMs. The framework uses a two-stage, parameterized perturbation model based on semantic decoupling to analyze rain-induced shifts in decision-making. In the first stage, global effects of rainfall are modeled by applying a low-dimensional global modulation to condition the embedding space, weakening the original semantic decision boundaries. In the second stage, structured rain variations are introduced by modeling multi-scale raindrop appearance and rainfall-induced illumination changes, optimizing the resulting non-differentiable weather space to induce stable semantic shifts. The framework generates perturbations that are physically grounded and interpretable. Experiments show that even physically plausible weather perturbations can cause substantial semantic misalignment in VLMs, posing safety and reliability risks in real-world deployment. Ablations confirm that illumination modeling and multi-scale raindrop structures are key drivers of these semantic shifts.",3.44,115.113,396,cold_start,Phi-4,Apple_M1(Metal)
2601.13240v1_KOCO-BENCH Can Large Language Models Leverage Doma.pdf,KOCO-BENCH: Can Large Language Models Leverage Domain Knowledge in Software Development?,"Xue Jiang, Jiaru Qian, Xianjie Shi, Chenjie Li, Hao Zhu, Ziyu Wang, Jielun Zhang, Zheyu Zhao, Kechi Zhang, Jia Li, Wenpin Jiao, Zhi Jin, Ge Li, Yihong Dong",,,"Large Language Models, Software Development, Domain Specialization, KOCO-BENCH, Code Generation, Knowledge Acquisition","LLMs excel at general programming but struggle with domain-specific software development, necessitating domain specialization methods for LLMs to learn and utilize domain knowledge and data. Existing domain-specific code benchmarks cannot evaluate the effectiveness of domain specialization methods, which focus on assessing what knowledge LLMs possess rather than how they acquire and apply new knowledge, lacking explicit knowledge corpora for developing domain specialization methods. To address this, KOCO-BENCH, a novel benchmark designed for evaluating domain specialization methods in real-world software development, is presented. It contains 6 emerging domains with 11 software frameworks and 25 projects, featuring curated knowledge corpora alongside multi-granularity evaluation tasks including domain code generation and domain knowledge understanding. KOCO-BENCH poses significant challenges to state-of-the-art LLMs, with marginal improvements even with domain specialization methods applied. The best-performing coding agent, Claude Code, achieves only 34.2%, highlighting the urgent need for more effective domain specialization methods. KOCO-BENCH, evaluation code, and baselines are released to advance further research.",3.54,113.427,401,cold_start,Phi-4,Apple_M1(Metal)
2601.13247v1_Aligning Agentic World Models via Knowledgeable Ex.pdf,Aligning Agentic World Models via Knowledgeable Experience Learning,"Baochang Ren, Yunzhi Yao, Rui Sun, Shuofei Qiao, Ningyu Zhang, Huajun Chen",,2601.13247v1,"Large Language Models, world models, physical hallucinations, environmental dynamics, embodied intelligence, WorldMind, Process Experience, Goal Experience, World Knowledge Repository","Current Large Language Models (LLMs) exhibit a critical modal disconnect: they possess vast semantic knowledge but lack the procedural grounding to respect the immutable laws of the physical world. Consequently, while these agents implicitly function as world models, their simulations often suffer from physical hallucinations—generating plans that are logically sound but physically unexecutable. Existing alignment strategies predominantly rely on resource-intensive training or fine-tuning, which attempt to compress dynamic environmental rules into static model parameters. However, such parametric encapsulation is inherently rigid, struggling to adapt to the open-ended variability of physical dynamics without continuous, costly retraining. To bridge this gap, we introduce WorldMind, a framework that autonomously constructs a symbolic World Knowledge Repository by synthesizing environmental feedback. Specifically, it unifies Process Experience to enforce physical feasibility via prediction errors and Goal Experience to guide task optimality through successful trajectories. Experiments on EB-ALFRED and EB-Habitat demonstrate that WorldMind achieves superior performance compared to baselines with remarkable cross-model and cross-environment transferability.",3.39,106.574,361,cold_start,Phi-4,Apple_M1(Metal)
2601.13260v1_Stop Taking Tokenizers for Granted They Are Core D.pdf,Stop Taking Tokenizers for Granted: They Are Core Design Decisions in Large Language Models,"Sawsan Alqahtani, Mir Tafseer Nayeem, Md Tahmid Rahman Laskar, Tasnim Mohiuddin, M Saiful Bari",,,"tokenization, large language models, Byte Pair Encoding, linguistic structure, bias, co-design, evaluation, fairness, efficiency, adaptability","Tokenization is a fundamental component of large language models (LLMs) that has been under-theorized and inconsistently designed. Common subword approaches like Byte Pair Encoding (BPE) often misalign with linguistic structures, amplify bias, and waste capacity. This paper argues for treating tokenization as a core modeling decision, integrating tokenizer and model co-design with linguistic, domain, and deployment considerations. Standardized evaluation and transparent reporting are essential for accountability and comparability. By addressing tokenization as a core design problem, language technologies can become fairer, more efficient, and more adaptable.",2.92,84.479,247,cold_start,Phi-4,Apple_M1(Metal)
2601.13262v1_CURE-Med Curriculum-Informed Reinforcement Learnin.pdf,CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning,"Eric Onyame, Akash Ghosh, Subhadip Baidya, Sriparna Saha, Xiuying Chen, Chirag Agarwal",,,"multilingual medical reasoning, large language models, reinforcement learning, code-switching, logical correctness, language consistency","This paper addresses the challenge of multilingual medical reasoning with large language models (LLMs), which are unreliable in multilingual healthcare settings. The authors introduce CUREMED-BENCH, a high-quality multilingual medical reasoning dataset with open-ended reasoning queries in thirteen languages, including underrepresented ones like Amharic, Yoruba, and Swahili. They propose CURE-MED, a curriculum-informed reinforcement learning framework that integrates code-switching-aware supervised fine-tuning and Group Relative Policy Optimization to improve logical correctness and language stability. The approach outperforms strong baselines, achieving high language consistency and logical correctness across different parameter sizes. The results support reliable and equitable multilingual medical reasoning in LLMs.",3.31,85.766,284,cold_start,Phi-4,Apple_M1(Metal)
2601.13268v1_Improving the Safety and Trustworthiness of Medica.pdf,Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops,"Zainab Ghafoor, Md Shafiqul Islam, Koushik Howlader, Md Rasel Khondokar, Tanusree Bhattacharjee, Sayantan Chakraborty, Adrito Roy, Ushashi Bhattacharjee, Tirtho Roy",,,"Medical AI, Large Language Models, Multi-Agent Systems, Ethical Compliance, Safety Assessment","Large Language Models (LLMs) are increasingly applied in healthcare, yet ensuring their ethical integrity and safety compliance remains a major barrier to clinical deployment. This work introduces a multi-agent refinement framework designed to enhance the safety and reliability of medical LLMs through structured, iterative alignment. Our system combines two generative models—DeepSeek R1 and Med-PaLM—with two evaluation agents, LLaMA 3.1 and Phi-4, which assess responses using the American Medical Association’s (AMA) Principles of Medical Ethics and a five-tier Safety Risk Assessment (SRA-5) protocol. We evaluate performance across 900 clinically diverse queries spanning nine ethical domains, measuring convergence efficiency, ethical violation reduction, and domain-specific risk behavior. Results demonstrate that DeepSeek R1 achieves faster convergence (mean 2.34 vs. 2.67 iterations), while Med-PaLM shows superior handling of privacy-sensitive scenarios. The iterative multi-agent loop achieved an 89% reduction in ethical violations and a 92% risk downgrade rate, underscoring the effectiveness of our approach. This study presents a scalable, regulator-aligned, and cost-efficient paradigm for governing medical AI safety.",3.48,115.547,402,cold_start,Phi-4,Apple_M1(Metal)
2601.13286v1_AI Skills Improve Job Prospects Causal Evidence fr.pdf,ERROR,ERROR,ERROR,ERROR,ERROR,'bbox',0.0,0.0,0,cold_start,Phi-4,Apple_M1(Metal)
2601.13295v1_CooperBench Why Coding Agents Cannot be Your Teamm.pdf,CooperBench: Why Coding Agents Cannot be Your Teammates Yet,"Arpandeep Khatua, Hao Zhu, Peter Tran, Arya Prabhudesai, Frederic Sadrieh, Johann K. Lieberwirth, Xinkai Yu, Yicheng Fu, Michael J. Ryan, Jiaxin Pei, Diyi Yang",,,"CooperBench, collaborative coding tasks, AI agents, coordination capabilities, social intelligence, open-source repositories, coding agents, task-specific competence","The paper introduces CooperBench, a benchmark for evaluating the collaborative capabilities of coding agents. It highlights the challenges AI agents face in teamwork, such as communication issues, deviation from commitments, and incorrect expectations. The study finds that current agents perform significantly worse in collaborative tasks compared to individual tasks, contrasting with human teams where collaboration typically enhances productivity. The benchmark includes over 600 tasks across 12 libraries in 4 programming languages, grounded in real open-source repositories with expert-written tests.",2.73,104.561,285,cold_start,Phi-4,Apple_M1(Metal)
2601.13317v1_Paid Voices vs. Public Feeds Interpretable Cross-P.pdf,Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme Modeling of Climate Discourse,"Samantha Sudhoff, Pranav Perumal, Zhaoqing Wu, Tunazzina Islam",,,"climate discourse, paid advertising, public social media, thematic analysis, large language models, computational social science, natural language processing","This study presents a comparative analysis of climate discourse across paid advertisements on Meta and public posts on Bluesky from July 2024 to September 2025. An interpretable thematic discovery and assignment framework is introduced, clustering texts by semantic similarity and using large language models to generate human-interpretable theme labels. The study evaluates the quality of these themes against traditional topic modeling baselines and validates their coherence through downstream tasks. The findings reveal systematic differences between paid climate messaging and public discourse, highlighting how platform-level incentives influence thematic structure, stance alignment, and temporal responsiveness. The framework supports comparative narrative analysis across diverse communication environments.",3.13,81.4,255,cold_start,Phi-4,Apple_M1(Metal)
2601.13327v1_PepEDiff Zero-Shot Peptide Binder Design via Prote.pdf,PepEDiﬀ: Zero-Shot Peptide Binder Design via Protein Embedding Diffusion,"Po-Yu Liang, Tibo Duran, Jun Bai",,2601.13327v1,"Deep Learning, Drug Discovery, Protein Design","We present PepEDiﬀ, a novel peptide binder generator that designs binding sequences given a target receptor protein sequence and its pocket residues. Peptide binder generation is critical in therapeutic and biochemical applications, yet many existing methods rely heavily on intermediate structure prediction, adding complexity and limiting sequence diversity. Our approach departs from this paradigm by generating binder sequences directly in a continuous latent space derived from a pretrained protein embedding model, without relying on predicted structures, thereby improving structural and sequence diversity. To encourage the model to capture binding-relevant features rather than memorizing known sequences, we perform latent-space exploration and diffusion-based sampling, enabling the generation of peptides beyond the limited distribution of known binders. This zero-shot generative strategy leverages the global protein embedding manifold as a semantic prior, allowing the model to propose novel peptide sequences in previously unseen regions of the protein space. We evaluate PepEDiﬀ on TIGIT, a challenging target with a large, flat protein–protein interaction interface that lacks a druggable pocket. Despite its simplicity, our method outperforms state-of-the-art approaches across benchmark tests and in the TIGIT case study, demonstrating its potential as a general, structure-free framework for zero-shot peptide binder design. The code for this research is available at GitHub.",3.82,90.313,345,cold_start,Phi-4,Apple_M1(Metal)
2601.13348v1_The AI Genie Phenomenon and Three Types of AI Chat.pdf,"The AI Genie Phenomenon and Three Types of AI Chatbot Addiction: Escapist Roleplays, Pseudosocial Companions, and Epistemic Rabbit Holes","M. Karen Shen, Jessica Huang, Olivia Liang, Ig-Jae Kim, Dongwook Yoon",,,"AI chatbot, Addiction","Recent reports on generative AI chatbot use raise concerns about its addictive potential. This study examines AI chatbot addiction by analyzing Reddit entries to understand why users become addicted, the symptoms reported, and the distinct types of addiction. The study identifies three types of addiction: Escapist Roleplay, Pseudosocial Companion, and Epistemic Rabbit Hole. It also discusses the involvement of sexual content and the perceived helpfulness of recovery strategies for different addiction types. The findings provide empirical groundwork for future prevention, diagnosis, and intervention strategies.",3.02,75.776,229,cold_start,Phi-4,Apple_M1(Metal)
2601.13352v1_LLM-as-RNN A Recurrent Language Model for Memory U.pdf,LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction,"Yuxing Lu, J. Ben Tamo, Weichen Zhao, Nan Sun, Yishan Zhong, Wenqi Shi, Jinzhuo Wang, May D. Wang",,,"Large Language Models, Recurrent Neural Networks, Memory Updates, Sequence Prediction, Inference, Healthcare, Meteorology, Finance","Large language models are strong sequence predictors, yet standard inference relies on immutable context histories. After making an error at generation step t, the model lacks an updatable memory mechanism that improves predictions for step t+1. We propose LLM-as-RNN, an inference-only framework that turns a frozen LLM into a recurrent predictor by representing its hidden state as natural-language memory. This state, implemented as a structured system-prompt summary, is updated at each timestep via feedback-driven text rewrites, enabling learning without parameter updates. Under a fixed token budget, LLM-as-RNN corrects errors and retains task-relevant patterns, effectively performing online learning through language. We evaluate the method on three sequential benchmarks in healthcare, meteorology, and finance across Llama, Gemma, and GPT model families. LLM-as-RNN significantly outperforms zero-shot, full-history, and MemPrompt baselines, improving predictive accuracy by 6.5% on average, while producing interpretable, human-readable learning traces absent in standard context accumulation.",3.34,109.386,365,cold_start,Phi-4,Apple_M1(Metal)
2601.13358v1_The Geometry of Thought How Scale Restructures Rea.pdf,The Geometry of Thought: How Scale Restructures Reasoning in Large Language Models,Samuel Cyrenius Anderson,,arXiv:2601.13358v1,"reasoning, neural scaling laws, chain-of-thought trajectories, domain-specific phase transitions, manifold geometry, Neural Reasoning Operators, scaling hypothesis","This paper explores how scaling affects reasoning in large language models, analyzing over 25,000 chain-of-thought trajectories across various domains. It reveals that scaling does not uniformly enhance reasoning but restructures it, causing domain-specific geometric changes. Legal reasoning shows a significant reduction in representational dimensionality and increased trajectory alignment, while scientific and mathematical reasoning remain invariant. Code reasoning develops distinct strategic modes. The study introduces Neural Reasoning Operators to predict reasoning endpoints and identifies a universal oscillatory signature across domains. The findings suggest that the cost of thought is determined by manifold geometry, providing insights for inference acceleration.",3.22,70.56,227,cold_start,Phi-4,Apple_M1(Metal)
2601.13376v1_Bounded Minds Generative Machines Envisioning Conv.pdf,"Bounded Minds, Generative Machines: Envisioning Conversational AI that Works with Human Heuristics and Reduces Bias Risk",JIQUN LIU,https://doi.org/XXXXXXX,,"Bounded Rationality, Heuristics, Conversational AI, GenAI, Evaluation","Conversational AI is rapidly becoming a primary interface for information seeking and decision making, yet most systems still assume idealized users. Human reasoning is bounded by limited attention, uneven knowledge, and reliance on heuristics that are adaptive but bias-prone. This article outlines a research pathway grounded in bounded rationality, arguing that conversational AI should be designed to work with human heuristics rather than against them. It identifies key directions for detecting cognitive vulnerability, supporting judgment under uncertainty, and evaluating conversational systems beyond factual accuracy, toward decision quality and cognitive robustness.",3.11,70.639,220,cold_start,Phi-4,Apple_M1(Metal)
2601.13383v1_A Lightweight Modular Framework for Constructing A.pdf,"A Lightweight Modular Framework for Constructing Autonomous Agents Driven by Large Language Models: Design, Implementation, and Applications in AgentForge","A. A. Jafari, C. Ozcinar, G. Anbarjafari",,arXiv:2601.13383v1,"Autonomous agents, large language models, modular architecture, natural language processing, software framework, task automation, artificial intelligence, open-source software","The emergence of large language models (LLMs) has catalyzed a paradigm shift in autonomous agent development, enabling systems capable of reasoning, planning, and executing complex multi-step tasks. However, existing agent frameworks often suffer from architectural rigidity, vendor lock-in, and prohibitive complexity that impedes rapid prototyping and deployment. This paper presents AgentForge, a lightweight, open-source Python framework designed to democratize the construction of LLM-driven autonomous agents through a principled modular architecture. AgentForge introduces three key innovations: (1) a composable skill abstraction that enables fine-grained task decomposition with formally defined input-output contracts, (2) a unified LLM backend interface supporting seamless switching between cloud-based APIs (OpenAI, Groq) and local inference engines (HuggingFace Transformers), and (3) a declarative YAML-based configuration system that separates agent logic from implementation details. We formalize the skill composition mechanism as a directed acyclic graph (DAG) and prove its expressiveness for representing arbitrary sequential and parallel task workflows. Comprehensive experimental evaluation across four benchmark scenarios demonstrates that AgentForge achieves competitive task completion rates (87.3% on web scraping pipelines, 91.2% on data analysis tasks) while reducing development time by 62% compared to LangChain and 78% compared to direct API integration. Latency measurements confirm sub-100ms orchestration overhead, rendering the framework suitable for real-time applications. The modular design facilitates extension: we demonstrate the integration of six built-in skills (web scraping, data analysis, content generation, RSS monitoring, image generation, and voice synthesis) and provide comprehensive documentation for custom skill development. AgentForge addresses a critical gap in the LLM agent ecosystem by providing researchers and practitioners with a production-ready foundation for constructing, evaluating, and deploying autonomous agents without sacrificing flexibility or performance.",3.74,138.594,518,cold_start,Phi-4,Apple_M1(Metal)
2601.13385v1_Organ-Aware Attention Improves CT Triage and Class.pdf,Organ-Aware Attention Improves CT Triage and Classification,"Lavsen Dahal, Yubraj Bhandari, Geoffrey D. Rubin, Joseph Y. Lo",,,"CT triage, classification, Vision-Language Models, 3D anatomy, computed tomography, radiologist burnout, Organ-Masked Attention, Organ-Scalar Fusion, AUROC, supervised classification","The study addresses the need for efficient triage and classification of high-volume CT scans to improve patient care and reduce radiologist burnout. It highlights the limitations of existing Vision-Language Models (VLM) in handling 3D anatomy and protocol variations. The research introduces ORACLE-CT, an encoder-agnostic, organ-aware model that combines Organ-Masked Attention and Organ-Scalar Fusion, achieving state-of-the-art performance in supervised classification for chest and abdomen CT scans. The model's effectiveness is demonstrated using the CT-RATE and RADCHEST-CT datasets, with significant improvements in AUROC scores.",3.04,87.627,266,cold_start,Phi-4,Apple_M1(Metal)
2601.13392v1_Beyond Memorization Testing LLM Reasoning on Unsee.pdf,Beyond Memorization: Testing LLM Reasoning on Unseen Theory of Computation Tasks,"Shlok Shelat, Jay Raval, Souvik Roy, Manas Gaur",,,"Large language models, formal language tasks, deterministic finite automata, regular languages, symbolic reasoning, pattern matching, Arden’s theorem, Kleene-star semantics, prompting strategies, Chain-of-Thought, Tree-of-Thought, Theory of Computation","Large language models (LLMs) have shown strong performance on formal language tasks, but it is unclear if this reflects genuine symbolic reasoning or pattern matching. This study introduces a benchmark for deterministic finite automata (DFA) construction from regular languages, including factual knowledge questions, seen construction problems, and unseen problems with multiple constraints and those generated via Arden’s theorem. While models perform well on factual and seen tasks, their accuracy drops significantly on unseen problems due to systematic misinterpretations and failures in maintaining global consistency. The study evaluates various prompting strategies and finds persistent errors, highlighting a gap between generating syntactically plausible DFAs and achieving semantically correct formal reasoning.",3.2,92.221,295,cold_start,Phi-4,Apple_M1(Metal)
2601.13398v1_Can LLMs Compress and Decompress Evaluating Code U.pdf,Can LLMs Compress (and Decompress)? Evaluating Code Understanding and Execution via Invertibility,"Nickil Maveli, Antonio Vergari, Shay B. Cohen",,,"LLMs, code benchmarks, round-trip code execution, consistency, ROUNDTRIPCODEEVAL, bijection fidelity, Code-LLMs, zero-shot prompting, supervised fine-tuning, self-reflection mechanisms, round-trip consistency, code reasoning, software engineering applications, forward execution, backward execution, bijective encoding function, decoding function, semantic code understanding","LLMs show strong performance on code benchmarks, but round-trip code execution reveals limitations in maintaining consistent reasoning across forward and backward execution. The paper introduces ROUNDTRIPCODEEVAL (RTCE), a benchmark for testing round-trip consistency in code execution reasoning tasks. It evaluates state-of-the-art Code-LLMs using zero-shot prompting, supervised fine-tuning, and self-reflection mechanisms, finding modest improvements but a persistent gap in true round-trip consistency. This indicates a lack of internal coherence for trustworthy code reasoning. RTCE provides new insights not captured by existing benchmarks, highlighting the importance of integrating forward and backward execution into a coherent and reversible process for robust reasoning systems.",3.27,101.949,333,cold_start,Phi-4,Apple_M1(Metal)
2601.13400v1_Deep Image Prior with L0 Gradient Regularizer for .pdf,DEEP IMAGE PRIOR WITH L0 GRADIENT REGULARIZER FOR IMAGE SMOOTHING,"Nhat Thanh Tran, Kevin Bui, Jack Xin",,,"image smoothing, optimization, ADMM, deep image prior, ℓ0 gradient","Image smoothing is a fundamental image processing operation that preserves the underlying structure, such as strong edges and contours, and removes minor details and textures in an image. Many image smoothing algorithms rely on computing local window statistics or solving an optimization problem. Recent state-of-the-art methods leverage deep learning, but they require a carefully curated training dataset. Because constructing a proper training dataset for image smoothing is challenging, we propose DIP-ℓ0, a deep image prior framework that incorporates the ℓ0 gradient regularizer. This framework can perform high-quality image smoothing without any training data. To properly minimize the associated loss function that has the nonconvex, nonsmooth ℓ0 'norm', we develop an alternating direction method of multipliers algorithm that utilizes an off-the-shelf ℓ0 gradient minimization solver. Numerical experiments demonstrate that the proposed DIP-ℓ0 outperforms many image smoothing algorithms in edge-preserving image smoothing and JPEG artifact removal.",3.25,85.58,278,cold_start,Phi-4,Apple_M1(Metal)
2601.13401v1_Reasoning with Pixel-level Precision QVLM Architec.pdf,Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics,"Peter A. Massih, Eric Cosatto",,,"Vision-Language Models, Quantitative Spatial Reasoning, Pixel-level Precision, SQuID Dataset, QVLM Architecture","Current Vision-Language Models (VLMs) fail at quantitative spatial reasoning due to their architecture, which compresses images and loses pixel-level information necessary for counting and measurements. This paper introduces the SQuID (Satellite Quantitative Intelligence Dataset) and the QVLM (Quantitative Vision-Language Model) architecture. SQuID is a benchmark dataset with 2,000 satellite image Question-Answer pairs, designed to evaluate quantitative spatial reasoning. QVLM maintains pixel precision by generating executable code that operates on pixel-level masks, preserving spatial indexing. Experiments show QVLM achieves 42.0% accuracy on SQuID, compared to 28.1% for a VLM prompted with image-question pairs. The paper highlights the importance of architectural decoupling for better accuracy in quantitative tasks.",3.14,80.172,252,cold_start,Phi-4,Apple_M1(Metal)
2601.13404v1_Local-to-Global Logical Explanations for Deep Visi.pdf,Local-to-Global Logical Explanations for Deep Vision Models,"Bhavan Vasu, Giuseppe Raffa, Prasad Tadepalli",,2601.13404v1,"Explainable AI, Neurosymbolic AI, Monotone DNF, Deep Learning","While deep neural networks are extremely effective at classifying images, they remain opaque and hard to interpret. This paper introduces local and global explanation methods for black-box models that generate explanations in terms of human-recognizable primitive concepts. Local explanations for a single image and global explanations for a set of images are cast as logical formulas in monotone disjunctive-normal-form (MDNF), whose satisfaction guarantees that the model yields a high score on a given class. An algorithm for explaining the classification of examples into multiple classes in the form of a monotone explanation list over primitive concepts is also presented. Despite their simplicity and interpretability, the explanations maintain high fidelity and coverage with respect to the black-box models they seek to explain in challenging vision datasets.",3.41,76.519,261,cold_start,Phi-4,Apple_M1(Metal)
2601.13406v1_Integrating Virtual Reality and Large Language Mod.pdf,Integrating Virtual Reality and Large Language Models for Team-Based Non-Technical Skills Training and Evaluation in the Operating Room,"Jacob Barker, Doga Demirel, Cullen Jackson, Anna Johansson, Robbin Miraglia, Darian Hoagland, Stephanie B. Jones, John Mitchell, Daniel B. Jones, Suvranu De",,,"Virtual Reality, Large Language Models, Non-Technical Skills, Team-Based Training, Operating Room, Communication, Decision-Making, Teamwork, Leadership, Surgical Safety","Although effective teamwork and communication are critical to surgical safety, structured training for non-technical skills (NTS) remains limited compared with technical simulation. The ACS/APDS Phase III Team-Based Skills Curriculum calls for scalable tools that both teach and objectively assess these competencies during laparoscopic emergencies. We introduce the Virtual Operating Room Team Experience (VORTeX), a multi-user virtual reality (VR) platform that integrates immersive team simulation with large language model (LLM) analytics to train and evaluate communication, decision-making, teamwork, and leadership. Team dialogue is analyzed using structured prompts derived from the Non-Technical Skills for Surgeons (NOTSS) framework, enabling automated classification of behaviors and generation of directed interaction graphs that quantify communication structure and hierarchy. Two laparoscopic emergency scenarios, pneumothorax and intra-abdominal bleeding, were implemented to elicit realistic stress and collaboration. Twelve surgical professionals completed pilot sessions at the 2024 SAGES conference, rating VORTeX as effective.",3.83,101.188,388,cold_start,Phi-4,Apple_M1(Metal)
2601.13412v1_Using deep learning for predicting cleansing quali.pdf,Using deep learning for predicting cleansing quality of colon capsule endoscopy images,"Puneet Sharma, Kristian Dalsbø Hindberg, Benedicte Schelde-Olesen, Ulrik Deding, Esmaeil S. Nadimi, Jan-Matthias Braun",,2601.13412v1,"deep learning, colon capsule endoscopy, image classification, structured pruning, explainability, Grad-CAM, ROAD method","This study explores the application of deep learning techniques for predicting cleansing quality in colon capsule endoscopy (CCE) images. A dataset of 500 images labeled by 14 clinicians on the Leighton–Rex scale was used to train a ResNet-18 model for classification, employing stratified K-fold cross-validation. Structured pruning techniques were applied to optimize the model, achieving 79% sparsity while maintaining 88% cross-validation accuracy. Explainability was evaluated using various CAM methods and the ROAD method. The study highlights the challenges of evaluating cleansing quality and the importance of explainability in clinical applications.",3.62,77.073,279,cold_start,Phi-4,Apple_M1(Metal)
2601.13422v1_TrustEnergy A Unified Framework for Accurate and R.pdf,TrustEnergy: A Unified Framework for Accurate and Reliable User-level Energy Usage Prediction,"Dahai Yu, Rongchao Xu, Dingyi Zhuang, Yuheng Bu, Shenhao Wang, Guang Wang",,,"energy usage prediction, spatiotemporal graph neural network, quantile regression, deep learning, grid management, uncertainty quantification","Energy usage prediction is crucial for applications like grid management and disaster response. Existing deep learning methods often neglect spatial correlations or fail to provide individualized predictions, impacting accuracy. This paper introduces TrustEnergy, a framework that combines a Hierarchical Spatiotemporal Representation module and a Sequential Conformalized Quantile Regression module to enhance prediction accuracy and uncertainty quantification. Implemented with a Florida electricity provider, TrustEnergy shows a 5.4% increase in accuracy and a 5.7% improvement in uncertainty quantification over existing methods.",3.06,80.393,246,cold_start,Phi-4,Apple_M1(Metal)
2601.13435v1_A Learnable Wavelet Transformer for Long-Short Equ.pdf,A Learnable Wavelet Transformer for Long-Short Equity Trading and Risk-Adjusted Return Optimization,"Shuozhe Li, Du Cheng, Leqi Liu",,,"Neural wavelet regularization, wavelet-transformer network, low-guided high-frequency injection, return optimization","Learning profitable intraday trading policies from financial time series is challenging due to heavy noise, non-stationarity, and strong cross-sectional dependence among related assets. We propose WaveLSFormer, a learnable wavelet-based long-short Transformer that jointly performs multi-scale decomposition and return-oriented decision learning. A learnable wavelet front-end generates low-/high-frequency components via an end-to-end trained filter bank, guided by spectral regularizers that encourage stable and well-separated frequency bands. To fuse multi-scale information, we introduce a low-guided high-frequency injection (LGHI) module that refines low-frequency representations with high-frequency cues while controlling training stability. The model outputs a portfolio of long/short positions that is rescaled to satisfy a fixed risk budget, and is optimized directly with a trading objective and risk-aware regularization. Extensive experiments on five years of hourly data across six industry groups, evaluated over ten random seeds, demonstrate that WaveLSFormer consistently outperforms MLP, LSTM, and Transformer backbones, with and without fixed discrete wavelet front-ends. On average in all industries, WaveLSFormer achieves a cumulative overall strategy return of 0.607±0.045 and a Sharpe ratio of 2.157±0.166, substantially improving both profitability and risk-adjusted returns over the strongest baselines.",3.41,108.991,372,cold_start,Phi-4,Apple_M1(Metal)
2601.13437v1_MOSLD-Bench Multilingual Open-Set Learning and Dis.pdf,MOSLD-Bench: Multilingual Open-Set Learning and Discovery Benchmark for Text Categorization,"Adriana-Valentina Costache, Daria-Nicoleta Dragomir, Silviu-Florin Gheorghe, Eduard Poesina, Paul Irofti, Radu Tudor Ionescu",,,"open-set learning, discovery, text categorization, multilingual, benchmark, zero-shot learning","Open-set learning and discovery (OSLD) is a challenging machine learning task where samples from new, unknown classes can appear at test time. This task generalizes zero-shot learning by involving the active discovery of new classes. While zero-shot learning has been extensively studied in text classification, OSLD is a comparatively new setup for the text domain. The paper introduces the first multilingual open-set learning and discovery (MOSLD) benchmark for text categorization by topic, comprising 960K data samples across 12 languages. The benchmark is constructed by rearranging existing datasets and collecting new data samples from the news domain. A novel framework for the OSLD task is proposed, integrating multiple stages to continuously discover and learn new classes. Several language models are evaluated, and the benchmark is released at https://github.com/Adriana19Valentina/MOSLD-Bench.",3.19,103.562,330,cold_start,Phi-4,Apple_M1(Metal)
2601.13443v1_Explicit Cognitive Allocation A Principle for Gove.pdf,Explicit Cognitive Allocation: A Principle for Governed and Auditable Inference in Large Language Models,"Héctor Manuel Manzanilla-Granados, Zaira Navarrete-Cazales, Miriam Pescador-Rojas, Tonahtiu Ramírez-Romero",,,"large language models, AI-assisted reasoning, cognitive allocation, epistemic control, reproducibility, Cognitive Universal Agent, Universal Cognitive Instruments, agricultural domain","The rapid adoption of large language models (LLMs) has enabled new forms of AI-assisted reasoning across various domains. However, current usage often lacks cognitive structure, leading to issues with traceability, epistemic control, and reproducibility. This paper introduces Explicit Cognitive Allocation, a principle for structuring AI-assisted inference by separating and orchestrating epistemic functions. The Cognitive Universal Agent (CUA) architecture is proposed, organizing inference into distinct stages and utilizing Universal Cognitive Instruments (UCIs) to formalize diverse inquiry methods. Controlled comparisons show that CUA-orchestrated inference achieves better epistemic alignment and exposes the instrumental structure of inquiry compared to baseline LLM inference. This establishes explicit cognitive and instrumental allocation as a principle for enhancing the controllability, auditability, and epistemic scope of AI-assisted reasoning.",3.52,93.528,329,cold_start,Phi-4,Apple_M1(Metal)
2601.13458v1_Labels or Preferences Budget-Constrained Learning .pdf,Labels or Preferences? Budget-Constrained Learning with Human Judgments over AI-Generated Outputs,"Zihan Dong, Ruijia Wu, Linjun Zhang",,2601.13458v1,"AI-generated pseudo labels, budget-conscious data acquisition, semi-parametric inference, monotone missing data framework, Preference-Calibrated Active Learning (PCAL), statistically efficient estimator, functionals of the data distribution, asymptotic optimality, robustness guarantee, nuisance models, variance optimization, Large Language Models (LLMs), human preference data, pseudo-labels, ground-truth labels","The increasing reliance on human preference feedback to judge AI-generated pseudo labels has created a pressing need for principled, budget-conscious data acquisition strategies. This paper addresses the question of how to optimally allocate a fixed annotation budget between ground-truth labels and pairwise preferences in AI. The solution, grounded in semi-parametric inference, casts the budget allocation problem as a monotone missing data framework. The introduced Preference-Calibrated Active Learning (PCAL) method learns the optimal data acquisition strategy and develops a statistically efficient estimator for functionals of the data distribution. Theoretically, the asymptotic optimality of the PCAL estimator is proven, along with a robustness guarantee ensuring performance even with poorly estimated nuisance models. The framework applies to a general class of problems by optimizing the estimator’s variance instead of requiring a closed-form solution. Simulations and real-data analysis demonstrate the practical benefits and superior performance of the proposed method.",3.65,104.124,380,cold_start,Phi-4,Apple_M1(Metal)
2601.13462v1_SpatialBench-UC Uncertainty-Aware Evaluation of Sp.pdf,SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt Following in Text-to-Image Generation,Amine Rostane,,2601.13462v1,"text-to-image generation, spatial evaluation, uncertainty-aware evaluation, reproducible benchmark, selective prediction","Evaluating whether text-to-image models follow explicit spatial instructions is challenging due to the limitations of object detectors and the ambiguity in geometric tests. Spatial evaluation is a selective prediction problem, requiring evaluators to abstain when evidence is weak and report confidence for risk–coverage trade-offs. The paper introduces SpatialBench-UC, a reproducible benchmark for pairwise spatial relations, with versioned prompts, pinned configurations, and structured metadata for independent replication and auditing. The benchmark includes 200 prompts organized into 100 counterfactual pairs, and a lightweight human audit is used to calibrate the checker’s abstention margin and confidence threshold. Results on three baselines show varying PASS rates and coverage, with conditional PASS rates indicating the checker’s judgment on decided samples.",3.22,80.65,260,cold_start,Phi-4,Apple_M1(Metal)
2601.13464v1_Context and Transcripts Improve Detection of Deepf.pdf,Context and Transcripts Improve Detection of Deepfake Audios of Public Figures,"Chongyang Gao, Marco Postiglione, Julian Baldwin, Natalia Denisenko, Isabel Gortner, Luke Fosdick, Chiara Pulice, Sarit Kraus, V. S. Subrahmanian",,,"deepfake detection, audio deepfakes, context-based detection, machine learning, adversarial strategies","This paper introduces a novel Context-based Audio Deepfake Detector (CADD) that leverages context and transcripts to improve the detection of audio deepfakes. The authors analyze a Journalist-provided Deepfake Dataset (JDD) and a synthetic audio dataset (SYN), demonstrating that incorporating context and transcripts significantly enhances detection performance. The study evaluates the efficacy of CADD against baseline detectors and traditional classifiers, showing improvements in F1 score, AUC, and EER. CADD also proves robust against adversarial evasion strategies, with minimal performance degradation. The research highlights the potential of context-enhanced audio deepfake detection in safeguarding against misinformation involving public figures.",3.13,92.334,289,cold_start,Phi-4,Apple_M1(Metal)
2601.13465v1_Graph Neural Networks are Heuristics.pdf,Graph Neural Networks are Heuristics,"Yimeng Min, Carla P. Gomes",,arXiv:2601.13465v1,"Graph Neural Networks, Heuristics, Combinatorial Optimization, Travelling Salesman Problem, Inductive Bias, Non-Autoregressive Model, Dropout, Snapshot Ensembling, Gumbel-Sinkhorn Relaxation","This paper demonstrates that a single training trajectory can transform a graph neural network into an unsupervised heuristic for combinatorial optimization, specifically focusing on the Travelling Salesman Problem (TSP). By encoding global structural constraints as an inductive bias, a non-autoregressive model can generate solutions via direct forward passes without search, supervision, or sequential decision-making. At inference time, dropout and snapshot ensembling allow a single model to act as an implicit ensemble, reducing optimality gaps through increased solution diversity. The results establish that graph neural networks can internalize global combinatorial structure and function as strong, learned heuristics, reframing the role of learning in combinatorial optimization from augmenting classical algorithms to directly instantiating new heuristics.",3.25,89.402,291,cold_start,Phi-4,Apple_M1(Metal)
2601.13474v1_Preconditioning Benefits of Spectral Orthogonaliza.pdf,Preconditioning Benefits of Spectral Orthogonalization in Muon,"Jianhao Ma, Yu Huang, Yuejie Chi, Yuxin Chen",,arXiv:2601.13474v1,"Muons, optimization, spectral orthogonalization, matrix factorization, linear transformers, gradient descent, Adam, preconditioning","The Muon optimizer, a matrix-structured algorithm that leverages spectral orthogonalization of gradients, is a milestone in the pretraining of large language models. This paper studies the effectiveness of a simplified variant of Muon through two case studies: matrix factorization and in-context learning of linear transformers. It proves that simplified Muon converges linearly with iteration complexities independent of the relevant condition number, outperforming gradient descent and Adam. The analysis reveals that Muon dynamics decouple into independent scalar sequences in the spectral domain, each exhibiting similar convergence behavior. The theory formalizes the preconditioning effect induced by spectral orthogonalization, offering insight into Muon’s effectiveness in matrix optimization problems and potentially beyond.",3.42,80.163,274,cold_start,Phi-4,Apple_M1(Metal)
2601.13476v1_A Unified Variational Imputation Framework for Ele.pdf,A Unified Variational Imputation Framework for Electric Vehicle Charging Data Using Retrieval-Augmented Language Model,"Jinhao Li, Hao Wang",,,"Electric vehicle, data imputation, charging demand, large language model, retrieval-augmented generation","The reliability of data-driven applications in electric vehicle (EV) infrastructure, such as charging demand forecasting, depends on complete, high-quality charging data. However, real-world EV datasets often have missing records, and existing imputation methods struggle with the complex, multimodal context of charging data. This work introduces a novel Probabilistic variational imputation framework leveraging large language models and retrieval-augmented memory (PRAIM). PRAIM encodes heterogeneous data into a unified representation, dynamically enhanced by retrieval-augmented memory, enabling a single imputation model to address data sparsity. Experiments on four public datasets show that PRAIM outperforms established baselines in imputation accuracy and preserving the original data’s statistical distribution, improving downstream forecasting performance.",3.08,76.681,236,cold_start,Phi-4,Apple_M1(Metal)
2601.13481v1_Towards Efficient and Robust Linguistic Emotion Di.pdf,Towards Efficient and Robust Linguistic Emotion Diagnosis for Mental Health via Multi-Agent Instruction Refinement,"Jian Zhang, Zhangqi Wang, Zhiyuan Wang, Weiping Fu, Yu He, Haiping Zhu, Qika Lin, Jun Liu",,,"Linguistic Emotion Diagnosis, Emotional Comorbidity, Inefficient Exploration, Automated Prompt Optimization, Multi-Agent Collaboration, Medical Language Processing, Trustworthy Artificial Intelligence","Linguistic expressions of emotions, such as depression, anxiety, and trauma-related states, are prevalent in clinical notes, counseling dialogues, and online mental health communities. Accurate recognition of these emotions is crucial for clinical triage, risk assessment, and timely intervention in mental health applications. Despite advances showing that large language models (LLMs) can generalize well to various emotion analysis tasks, their diagnostic reliability in high-stakes and context-intensive medical settings remains sensitive to prompt design. This paper proposes APOLO (Automated Prompt Optimization for Linguistic Emotion diagnosis), a framework that explores a broader and finer-grained prompt space to enhance diagnostic efficiency and robustness. APOLO models instruction refinement as a Partially Observable Markov Decision Process (POMDP) and introduces a multi-agent collaboration mechanism comprising Planner–Teacher–Critic–Student–Target roles. This closed-loop design enables continuous optimization of prompt generation, evaluation, and evolution. Experimental results demonstrate that APOLO improves diagnostic accuracy and robustness across domain-specific and stratified benchmarks, providing a generalizable and scalable paradigm for trustworthy LLM applications in mental healthcare.",3.5,101.491,355,cold_start,Phi-4,Apple_M1(Metal)
2601.13487v1_The Hidden Toll of Social Media News Causal Effect.pdf,The Hidden Toll of Social Media News: Causal Effects on Psychosocial Wellbeing,"Olivia Pal, Agam Goyal, Eshwar Chandrasekharan, Koustuv Saha",,,"social media, news consumption, psychosocial wellbeing, quasi-experimental study, propensity score analysis, news effects, psychological dynamics","This study investigates the psychosocial effects of news consumption on social media by analyzing a large-scale dataset from the Bluesky platform. It reveals that different forms of engagement with news content lead to varied psychosocial outcomes, such as increased depression, stress, and anxiety, but decreased loneliness and increased social interaction. The study highlights that bookmarking news feeds is associated with greater psychosocial deterioration compared to commenting or quoting, with significant cumulative effects from repeated exposure. These findings extend existing theories of news effects beyond crisis-centric frameworks, suggesting that routine news consumption on social media creates distinct psychological dynamics based on engagement type.",3.14,80.531,253,cold_start,Phi-4,Apple_M1(Metal)
2601.13508v1_CatMaster An Agentic Autonomous System for Computa.pdf,CatMaster: An Agentic Autonomous System for Computational Heterogeneous Catalysis Research,"Honghao Chen, Jiangjie Qiu, Yi Shen Tew, Xiaonan Wang",,2601.13508v1,"Density functional theory, computational heterogeneous catalysis, large-language-model, workflow, DFT calculations, multi-fidelity tool library","Density functional theory (DFT) is widely used to connect atomic structure with catalytic behavior, but computational heterogeneous catalysis studies often require long workflows that are costly, iterative, and sensitive to setup choices. Besides the intrinsic cost and accuracy limits of first-principles calculations, practical workflow issues such as keeping references consistent, preparing many related inputs, recovering from failed runs on computing clusters, and maintaining a complete record of what was done, can slow down projects and make results difficult to reproduce or extend. Here we present CatMaster, a large-language-model (LLM)-driven agent system that turns natural language requests into complete calculation workspaces, including structures, inputs, outputs, logs, and a concise run record. CatMaster maintains a persistent project record of key facts, constraints, and file pointers to support inspection and restartability. It is paired with a multi-fidelity tool library that covers rapid surrogate relaxations and high-fidelity DFT calculations for validation when needed. We demonstrate CatMaster on four demonstrations of increasing complexity: an O2 spin-state check with remote execution, BCC Fe surface energies with a protocol-sensitivity study and CO adsorption site ranking, high-throughput Pt–Ni–Cu alloy screening.",3.9,92.622,361,cold_start,Phi-4,Apple_M1(Metal)
2601.13515v1_Automatic Adjustment of HPA Parameters and Attack .pdf,Automatic Adjustment of HPA Parameters and Attack Prevention in Kubernetes Using Random Forests,"Huah Yong Chan, Hanlin Zhou, Jingfei Ni, Mengchun Wu, Qing Deng",,2601.13515v1,"Kubernetes, HPA, Security, Random Forest","In this paper, HTTP status codes are used as custom metrics within the HPA as the experimental scenario. By integrating the Random Forest classification algorithm from machine learning, attacks are assessed and predicted, dynamically adjusting the maximum pod parameter in the HPA to manage attack traffic. This approach enables the adjustment of HPA parameters using machine learning scripts in targeted attack scenarios while effectively managing attack traffic. All access from attacking IPs is redirected to honeypot pods, achieving a lower incidence of 5XX status codes through HPA pod adjustments under high load conditions. This method also ensures effective isolation of attack traffic, preventing excessive HPA expansion due to attacks. Additionally, experiments conducted under various conditions demonstrate the importance of setting appropriate thresholds for HPA adjustments.",3.51,74.926,263,cold_start,Phi-4,Apple_M1(Metal)
2601.13518v1_AgenticRed Optimizing Agentic Systems for Automate.pdf,AGENTICRED: Optimizing Agentic Systems for Automated Red-teaming,"Jiayi Yuan, Jonathan Nöther, Natasha Jaques, Goran Radanović",,,"automated red-teaming, LLMs, in-context learning, evolutionary selection, AI safety evaluation","This paper introduces AGENTICRED, an automated pipeline that leverages LLMs’ in-context learning to iteratively design and refine red-teaming systems without human intervention. AGENTICRED treats red-teaming as a system design problem, using evolutionary selection to evolve agentic systems. It consistently outperforms state-of-the-art approaches, achieving high attack success rates on various models, and demonstrates strong transferability to proprietary models. The work highlights automated system design as a powerful paradigm for AI safety evaluation.",2.89,74.834,216,cold_start,Phi-4,Apple_M1(Metal)
2601.13528v1_Eliciting Harmful Capabilities by Fine-Tuning On S.pdf,ELICITING HARMFUL CAPABILITIES BY FINE-TUNING ON SAFEGUARDED OUTPUTS,"Jackson Kaunismaa, Avery Griffin, John Hughes, Christina Q Knight, Mrinank Sharma, Erik Jones",,arXiv:2601.13528v1,"safeguards, elicitation attacks, harmful capabilities, fine-tuning, open-source models, hazardous chemical synthesis","This work demonstrates that even robustly safeguarded models can be used to elicit harmful capabilities in open-source models through elicitation attacks. These attacks involve constructing prompts in adjacent domains to a target harmful task, obtaining responses from safeguarded models, and fine-tuning open-source models on these prompt-output pairs. The study evaluates these attacks within the domain of hazardous chemical synthesis and processing, showing that approximately 40% of the capability gap between a base open-source model and an unrestricted frontier model can be recovered. The efficacy of elicitation attacks scales with the capability of the frontier model and the amount of generated fine-tuning data, highlighting the challenge of mitigating ecosystem-level risks with output-level safeguards.",3.28,89.393,293,cold_start,Phi-4,Apple_M1(Metal)
2601.13533v1_Reasoning While Recommending Entropy-Guided Latent.pdf,Reasoning While Recommending: Entropy-Guided Latent Reasoning in Generative Re-ranking Models,Changshuo Zhang,https://doi.org/XXXXXXX.XXXXXXX,,"Generative Re-ranking, Latent Reasoning, Reinforcement Learning","Reinforcement learning is crucial in generative re-ranking due to its exploration-exploitation capabilities. However, existing methods struggle with dynamic entropy changes in model difficulty during list generation, complicating the capture of complex preferences. This paper introduces a latent reasoning mechanism inspired by language models, which reduces entropy in decision-making. The proposed Entropy-Guided Latent Reasoning (EGLR) model offers three advantages: it integrates reasoning with recommending, uses entropy-guided variable-length reasoning with dynamic temperature adjustment, and features a lightweight design for easy adaptation to existing models. Experimental results on two datasets confirm its effectiveness and compatibility with existing generative re-ranking models, highlighting its practical deployment value and research potential.",3.08,75.02,231,cold_start,Phi-4,Apple_M1(Metal)
2601.13534v1_MN-TSGContinuous Time Series Generation with Irreg.pdf,MN-TSG: CONTINUOUSTIMESERIESGENERATION WITH IRREGULAROBSERVATIONS,"Xu Zhang, Junwei Deng, Chang Xu, Hao Li, Jiang Bian",,arXiv:2601.13534v1,"Irregular time series, continuous time series generation, deep learning architecture","Time series generation (TSG) is crucial in various domains like healthcare, but most methods assume regularly sampled data, which doesn't align with real-world scenarios where data is often irregularly sampled. Neural Controlled Differential Equations (NCDEs) show promise for modeling such data but struggle with complex temporal patterns and continuous TSG. This paper introduces MN-TSG, a novel framework using Mixture-of-Experts (MoE)–based NCDEs integrated with existing TSG models to handle irregular and continuous generation tasks. MN-TSG features a MoE-NCDE architecture with dynamically parameterized expert functions and a decoupled design for effective optimization. It learns the joint distribution over experts and generated time series, enabling refined continuous TSG. Experiments on ten datasets show MN-TSG's superiority over strong TSG baselines in both irregular-to-regular and irregular-to-continuous generation tasks.",3.29,92.509,304,cold_start,Phi-4,Apple_M1(Metal)
2601.13537v1_When Wording Steers the Evaluation Framing Bias in.pdf,When Wording Steers the Evaluation: Framing Bias in LLM Judges,"Yerin Hwang, Dongryeol Lee, Taegwan Kang, Minwoo Lee, Kyomin Jung",,,"Large Language Models, Framing Bias, LLM-based Evaluation, Prompt Framing, Psychology, Evaluation Tasks","Large language models (LLMs) are known to produce varying responses depending on prompt phrasing, indicating that subtle guidance in phrasing can steer their answers. This study investigates how deliberate prompt framing skews model judgments across four high-stakes evaluation tasks. Symmetric prompts using predicate-positive (P) and predicate-negative (¬P) constructions demonstrate significant discrepancies in model outputs. Across 14 LLM judges, clear susceptibility to framing is observed, with model families showing distinct tendencies toward agreement or rejection. These findings suggest that framing bias is a structural property of current LLM-based evaluation systems, underscoring the need for framing-aware protocols.",3.06,82.348,252,cold_start,Phi-4,Apple_M1(Metal)
2601.13545v1_TruthTensor Evaluating LLMs Human Imitation throug.pdf,TRUTHTENSOR: EVALUATING LLM HUMAN IMITATION THROUGH PREDICTION MARKET DRIFT AND HOLISTIC REASONING,"Shirin Shahabi, Spencer Graham, Haruna Isah",,,"Large Language Models, LLMs, prediction markets, drift, human imitation, evaluation, AI agents, real-world uncertainty, distribution shift, calibration, risk-sensitivity","Evaluating language models and AI agents remains fundamentally challenging due to static benchmarks that fail to capture real-world uncertainty, distribution shift, and the gap between isolated task accuracy and human-aligned decision-making under evolving conditions. This paper introduces TruthTensor, a novel, reproducible evaluation paradigm that measures Large Language Models (LLMs) not only as prediction engines but as human-imitation systems operating in socially-grounded, high-entropy environments. Building on forward-looking, contamination-free tasks, the framework anchors evaluation to live prediction markets and combines probabilistic scoring to provide a holistic view of model behavior. TruthTensor complements traditional correctness metrics with drift-centric diagnostics and explicit robustness checks for reproducibility. It specifies human vs. automated evaluation roles, annotation protocols, and statistical testing procedures to ensure interpretability and replicability of results. Experiments across 500+ real markets demonstrate that models with similar forecast accuracy can diverge markedly in calibration, drift, and risk-sensitivity, underscoring the need to evaluate models along multiple axes (accuracy, calibration, narrative stability, cost, and resource efficiency). TruthTensor operationalizes modern evaluation best practices, clear hypothesis framing, careful metric selection, transparent compute/cost reporting, human-in-the-loop validation, and open, versioned evaluation contracts, to produce defensible assessments of LLMs in real-world decision contexts.",3.25,122.505,398,cold_start,Phi-4,Apple_M1(Metal)
2601.13546v1_ChatAD Reasoning-Enhanced Time-Series Anomaly Dete.pdf,ChatAD: Reasoning-Enhanced Time-Series Anomaly Detection with Multi-Turn Instruction Evolution,"Hui Sun, Chang Xu, Haonan Xie, Hao Li, Yuhao Huang, Chuheng Zhang, Ming Jin, Xiaoguang Liu, Gang Wang, Jiang Bian",,,"Time-Series Anomaly Detection, LLM-driven Anomaly Detection, Multi-Turn Dialogue, Cross-Task Generalization, TS Evolution Algorithm, Kahneman-Tversky Optimization","LLM-driven Anomaly Detection (AD) enhances understanding and explanatory abilities of anomalous behaviors in Time Series (TS). Existing methods face challenges such as inadequate reasoning ability, deficient multi-turn dialogue capability, and narrow generalization. This paper proposes a multi-agent-based TS Evolution algorithm named TSEvol, introduces the AD reasoning & multi-turn dialogue Dataset TSEData-20K, and contributes the Chatbot family for AD, including ChatAD-Llama3-8B, Qwen2.5-7B, and Mistral-7B. Additionally, the TS Kahneman-Tversky Optimization (TKTO) is proposed to enhance ChatAD’s cross-task generalization capability. A Learning-based AD Benchmark LLADBench is also proposed to evaluate the performance of ChatAD and nine baselines across seven datasets and tasks. The three ChatAD models achieve substantial gains in accuracy, F1, and reduction in false positives. Optimized ChatAD via TKTO shows competitive performance in reasoning and cross-task generalization on classification, forecasting, and imputation.",3.29,116.698,384,cold_start,Phi-4,Apple_M1(Metal)
2601.13547v1_HateXScore A Metric Suite for Evaluating Reasoning.pdf,HateXScore: A Metric Suite for Evaluating Reasoning Quality in Hate Speech Explanations,"Yujia Hu, Roy Ka-Wei Lee",,,"hate speech detection, content moderation, evaluation frameworks, model explanations, interpretability, transparency, automated decisions, regulatory frameworks, protected groups, logical consistency","Hateful speech detection is crucial for content moderation, yet current evaluation frameworks rarely assess the reasoning behind why a text is deemed hateful. This paper introduces HateXScore, a four-component metric suite designed to evaluate the reasoning quality of model explanations. It assesses conclusion explicitness, faithfulness and causal grounding of quoted spans, protected group identification, and logical consistency among these elements. Evaluated on six diverse hate speech datasets, HateXScore serves as a diagnostic tool to reveal interpretability failures and annotation inconsistencies invisible to standard metrics like Accuracy or F1. Human evaluation shows strong agreement with HateXScore, validating it as a practical tool for trustworthy and transparent moderation.",3.13,82.939,260,cold_start,Phi-4,Apple_M1(Metal)
2601.13558v1_Leveraging ChatGPT and Other NLP Methods for Ident.pdf,Leveraging ChatGPT and Other NLP Methods for Identifying Risk and Protective Behaviors in MSM: Social Media and Dating Apps Text Analysis,"Mehrab Beikzadeh, Chenglin Hong, Cory J Cascalheira, Callisto Boka, Majid Sarrafzadeh, Ian W Holloway",,,"machine learning, HIV risk, harmful drinking, social app, dating app, Text mining, ChatGPT, eHealth, LLM","Men who have sex with men (MSM) are at elevated risk for sexually transmitted infections and harmful drinking. This study explores the use of text data from social media and dating apps to predict risk and protective behaviors among MSM. Textual data was used to train machine learning models to identify behaviors such as condomless anal sex, number of sexual partners, binge drinking, and heavy drinking. The study found that models using ChatGPT embeddings were highly predictive of certain behaviors, suggesting that text data can provide valuable insights for personalized public health interventions.",3.22,86.264,278,cold_start,Phi-4,Apple_M1(Metal)
2601.13559v1_AgentGC Evolutionary Learning-based Lossless Compr.pdf,AgentGC: Evolutionary Learning-based Lossless Compression for Genomics Data with LLM-driven Multiple Agent,"Hui Sun, Yanfeng Ding, Huidong Ma, Chang Xu, Keyan Jin, Lizheng Zu, Cheng Zhong, Xiaoguang Liu, Gang Wang, Wentong Cai",,,"Genomics Data, Lossless Compression, Evolutionary Learning, Large Language Models, Multi-Agent Systems","Lossless compression has made significant advancements in Genomics Data (GD) storage, sharing, and management. Current learning-based methods are non-evolvable with problems of low-level compression modeling, limited adaptability, and user-unfriendly interface. To address these issues, the paper proposes AgentGC, the first evolutionary Agent-based GD Compressor, consisting of three layers with multi-agent named Leader and Worker. The User layer provides a user-friendly interface via Leader combined with LLM; the Cognitive layer, driven by the Leader, integrates LLM to consider joint optimization of algorithm-dataset-system, addressing the issues of low-level modeling and limited adaptability; and the Compression layer, headed by Worker, performs compression & decompression via an automated multi-knowledge learning-based compression framework. AgentGC supports three modes: CP for compression-ratio priority, TP for throughput priority, and BM for balanced mode. Compared with 14 baselines on 9 datasets, the average compression ratios gains are 16.66%, 16.11%, and 16.33%, and the throughput gains are 4.73×, 9.23×, and 9.15×, respectively.",3.31,119.666,396,cold_start,Phi-4,Apple_M1(Metal)
2601.13562v1_Reasoning is a Modality.pdf,Reasoning is a Modality,"Zhiguang Liu, Yi Shang",,,"Abstraction and Reasoning Corpus, AI systems, LLMs, ViTs, transformer block, visual reasoning, ARC tasks","The paper explores the hypothesis that reasoning is a distinct modality separate from the low-level workspace where rules are applied. It introduces a novel role-separated transformer block to test this hypothesis on ARC tasks, achieving 62.6% accuracy on ARC-1, surpassing average human performance. The model demonstrates a shift towards controller-driven reasoning, aligning more closely with human-like behavior by maintaining a distinct internal state for reasoning.",2.7,62.192,168,cold_start,Phi-4,Apple_M1(Metal)
2601.13563v1_ButterflyMoE Sub-Linear Ternary Experts via Struct.pdf,ButterflyMoE: Sub-Linear Ternary Experts via Structured Butterfly Orbits,Aryan Karmore,,,"Mixture of Experts, Memory Compression, Quantization, Butterfly Matrices, Edge Devices, Language Modeling","Linear memory scaling for storing independent expert weight matrices requires O(N·d^2) memory, which exceeds the memory budget of edge devices. Current compression methods like quantization, pruning, and low-rank factorization reduce constant factors but do not resolve the scaling bottleneck. ButterflyMoE introduces a method where experts are not independent weight matrices but geometric reorientations of a unified shared quantized substrate. This approach achieves sub-linear memory scaling, O(d^2 + N·dlogd), by applying learned rotations to a shared ternary prototype. ButterflyMoE achieves a 150× memory reduction at 256 experts with negligible accuracy loss, allowing 64 experts to fit on 4GB devices compared to standard MoE’s 8 experts. The method combines ternary quantization with learned Butterfly rotations, achieving significant memory compression and enabling massively parallel edge deployment.",3.1,88.433,274,cold_start,Phi-4,Apple_M1(Metal)
2601.13564v1_Multi-objective fluorescent molecule design with a.pdf,Multi-objective fluorescent molecule design with a data-physics dual-driven generative framework,"Yanheng Li, Zhichen Pu, Lijiang Yang, Zehao Zhou, Yi Qin Gao",,,,,2.84,25.707,73,cold_start,Phi-4,Apple_M1(Metal)
2601.13566v1_Self-Improvement as Coherence Optimization A Theor.pdf,Self-Improvement as Coherence Optimization: A Theoretical Account,"Tianyi Qiu, Ahmed Hani Ismail, Zhonghao He, Shi Feng",,arXiv:2601.13566v1,"language models, self-improvement, coherence optimization, semi-supervised learning, description-length regularization","This paper explores how language models can improve their accuracy without external supervision. Methods such as debate, bootstrap, and internal coherence maximization achieve this feat, even matching supervised finetuning performance. The paper provides a theoretical framework showing that these methods optimize coherence, defined as the joint likelihood of the model’s behaviors across contexts. Coherence optimization is proven to be equivalent to description-length regularization and is shown to be optimal for semi-supervised learning when the regularizer is derived from a pretrained model. The theory explains why feedback-free self-improvement works and predicts its success or failure.",3.28,73.849,242,cold_start,Phi-4,Apple_M1(Metal)
2601.13570v1_GeoDynamics A Geometric State-Space Neural Network.pdf,GeoDynamics: A Geometric State-Space Neural Network for Understanding Brain Dynamics on Riemannian Manifolds,"Tingting Dan, Jiaqi Ding, Guorong Wu",,2601.13570v1,"state-space models, deep learning, functional neuroimaging, Riemannian manifold, symmetric positive-definite matrices, brain dynamics, functional connectivity, neuroscience, Alzheimer’s, Parkinson’s, autism, human action recognition","State-space models (SSMs) have become a cornerstone for unraveling brain dynamics, revealing how latent neural states evolve over time and give rise to observed signals. By combining deep learning’s flexibility with SSMs’ principled dynamical structure, recent studies have achieved powerful fits to functional neuroimaging data. However, most approaches still view the brain as a set of loosely connected regions or impose oversimplified network priors, falling short of a truly holistic, self-organized dynamical system perspective. Brain functional connectivity (FC) at each time point naturally forms a symmetric positive–definite (SPD) matrix, which lives on a curved Riemannian manifold rather than in Euclidean space. Capturing the trajectories of these SPD matrices is key to understanding how coordinated networks support cognition and behavior. To this end, we introduce GeoDynamics, a geometric state-space neural network that tracks latent brain-state trajectories directly on the high-dimensional SPD manifold. GeoDynamics embeds each connectivity matrix into a manifold-aware recurrent framework, learning smooth, geometry-respecting transitions that reveal task-driven state changes and early markers of Alzheimer’s, Parkinson’s, and autism. Beyond neuroscience, we validate GeoDynamics on human action recognition benchmarks (UTKinect, Florence, HDM05), demonstrating its scalability and robustness in modeling complex spatiotemporal dynamics across diverse domains.",3.59,117.035,420,cold_start,Phi-4,Apple_M1(Metal)
2601.13580v1_Neural Organ Transplantation NOT Checkpoint-Based .pdf,CHECKPOINT-BASEDMODULARADAPTATION FOR TRANSFORMERMODELS,Ahmad Al-Zuraiqi,,2601.13580v1,"Modular Deep Learning, Transfer Learning, Checkpoint Transfer, Domain Adaptation, Large Language Model","We introduce Neural Organ Transplantation (NOT), a modular adaptation framework that enables trained transformer layers to function as reusable transferable checkpoints for domain adaptation. Unlike conventional fine-tuning approaches that tightly couple trained parameters to specific model instances and training data, NOT extracts contiguous layer subsets ('donor organs') from pre-trained models, trains them independently on domain-specific data, and saves them as standalone checkpoint files that can be transplanted into compatible recipient models without access to the original training data. Through experiments on three decoder-only transformer architectures spanning 124M to 20B parameters (GPT-2, TinyLlama, and GPT-OSS), we demonstrate that donor transplantation substantially outperforms existing adaptation methods, achieving an order-of-magnitude improvement in perplexity over LoRA while training significantly faster. The method exhibits position dependence, with early insertion positions yielding optimal results. Cross-domain transfer at billion-parameter scale reveals unexpected regularization benefits. These findings demonstrate that transformer middle layers can support efficient modular transfer for decoder-only architectures, enabling privacy-preserving expertise sharing through checkpoint distribution. We note that this approach is currently limited to decoder-only models; preliminary experiments on encoder-based architectures show reduced effectiveness.",3.86,87.647,338,cold_start,Phi-4,Apple_M1(Metal)
2601.13581v1_SCRIPTMIND Crime Script Inference and Cognitive Ev.pdf,SCRIPTMIND: Crime Script Inference and Cognitive Evaluation for LLM-based Social Engineering Scam Detection System,"Heedou Kim, Changsik Kim, Sanghwa Shin, Jaewoo Kang",,,"Social engineering scams, Large Language Models, Scam detection, Cognitive evaluation, Crime script inference","Social engineering scams increasingly employ personalized, multi-turn deception, exposing the limits of traditional detection methods. While Large Language Models (LLMs) show promise in identifying deception, their cognitive assistance potential remains underexplored. This paper proposes SCRIPTMIND, an integrated framework for LLM-based scam detection that bridges automated reasoning and human cognition. It comprises three components: the Crime Script Inference Task (CSIT) for scam reasoning, the Crime Script–Aware Inference Dataset (CSID) for fine-tuning small LLMs, and the Cognitive Simulation-based Evaluation of Social Engineering Defense (CSED) for assessing real-time cognitive impact. Using 571 Korean phone scam cases, the study built 22,712 structured scammer-sequence training instances. Experimental results show that the 11B small LLM fine-tuned with SCRIPTMIND outperformed GPT-4o by 13%, achieving superior performance over commercial models in detection accuracy, false-positive reduction, scammer utterance prediction, and rationale quality. Moreover, in phone scam simulation experiments, it significantly enhanced and sustained users’ suspicion levels, improving their cognitive awareness of scams. SCRIPTMIND represents a step toward human-centered, cognitively adaptive LLMs for scam defense.",3.43,107.616,369,cold_start,Phi-4,Apple_M1(Metal)
2601.13588v1_TREX Tokenizer Regression for Optimal Data Mixture.pdf,Tokenizer Regression for Optimal Data Mixture,"Inho Won, Hangyeol Yoo, Minkyung Cho, Jungyeul Park, Hoyun Song, KyungTae Lim",,,"tokenizer, multilingual, Large Language Models, compression performance, data mixture, regression-based framework","Building effective tokenizers for multilingual Large Language Models (LLMs) requires careful control over language-specific data mixtures. Existing approaches rely on heuristics or costly large-scale searches to determine optimal language ratios. This work introduces Tokenizer Regression for Optimal Data Mixture (TREX), a regression-based framework that efficiently predicts the optimal data mixture for tokenizer training. TREX trains small-scale proxy tokenizers on random mixtures, gathers their compression statistics, and learns to predict compression performance from data mixtures. This learned model enables scalable mixture search before large-scale tokenizer training, mitigating the accuracy-cost trade-off in multilingual tokenizer design. Tokenizers trained with TREX's predicted mixtures outperform mixtures based on LLaMA3 and uniform distributions by up to 12% in both in- and out-of-distribution compression efficiency, demonstrating strong scalability, robustness, and practical effectiveness.",3.16,96.291,304,cold_start,Phi-4,Apple_M1(Metal)
2601.13589v1_Motion-to-Response Content Generation via Multi-Ag.pdf,MOTION-TO-RESPONSE CONTENT GENERATION VIA MULTI-AGENT AI SYSTEM WITH REAL-TIME SAFETY VERIFICATION,HyeYoung Lee,,2601.13589v1,"Speech Emotion Recognition, Multi-Agent Systems, Content Generation, Safety Verification, On-Device AI","This paper proposes a multi-agent artificial intelligence system that generates response-oriented media content in real time based on audio-derived emotional signals. The system comprises four cooperative agents: an Emotion Recognition Agent, a Response Policy Decision Agent, a Content Parameter Generation Agent, and a Safety Verification Agent. The approach emphasizes transforming inferred emotional states into safe, age-appropriate, and controllable response content. An explicit safety verification loop ensures compliance with predefined rules. Experimental results demonstrate 73.2% emotion recognition accuracy, 89.4% response mode consistency, and 100% safety compliance with sub-100ms inference latency. The modular architecture is applicable to child-adjacent media, therapeutic applications, and emotionally responsive smart devices.",3.33,75.362,251,cold_start,Phi-4,Apple_M1(Metal)
2601.13590v1_Vulnerability of LLMs Belief Systems LLMs Belief R.pdf,Vulnerability of LLMs’ Belief Systems? LLMs Belief Resistance Check Through Strategic Persuasive Conversation Interventions,"Fan Huang, Haewoon Kwak, Jisun An",,,"Large Language Models, persuasion, belief stability, meta-cognition prompting, adversarial fine-tuning, SMCR framework","This study evaluates the susceptibility of Large Language Models (LLMs) to persuasion using the Source–Message–Channel–Receiver (SMCR) communication framework. The research examines how different persuasive strategies affect belief stability across five mainstream LLMs and three domains: factual knowledge, medical QA, and social bias. The study finds that smaller models show extreme compliance, with significant belief changes occurring early in interactions. Meta-cognition prompting, intended to enhance robustness, instead increases vulnerability. Adversarial fine-tuning shows mixed results, with some models achieving substantial robustness while others remain highly susceptible. These findings highlight the model-dependent limits of current robustness interventions and provide guidance for developing more trustworthy LLMs.",3.09,86.524,267,cold_start,Phi-4,Apple_M1(Metal)
2601.13591v1_DSAEval Evaluating Data Science Agents on a Wide R.pdf,DSAEval: Evaluating Data Science Agents on a Wide Range of Real-World Data Science Problems,"Maojun Sun, Yifei Xie, Yue Wu, Ruijian Han, Binyan Jiang, Defeng Sun, Yancheng Yuan, Jian Huang",,,"data science agents, evaluation, real-world problems, large language models, multimodal perception, multi-query interactions, multi-dimensional evaluation","Recent LLM-based data agents aim to automate data science tasks ranging from data analysis to deep learning. However, the open-ended nature of real-world data science problems, which often span multiple taxonomies and lack standard answers, poses a significant challenge for evaluation. To address this, we introduce DSAEval, a benchmark comprising 641 real-world data science problems grounded in 285 diverse datasets, covering both structured and unstructured data (e.g., vision and text). DSAEval incorporates three distinctive features: (1) Multi-modal Environment Perception, which enables agents to interpret observations from multiple modalities including text and vision; (2) Multi-Query Interactions, which mirror the iterative and cumulative nature of real-world data science projects; and (3) Multi-Dimensional Evaluation, which provides a holistic assessment across reasoning, code, and results. We systematically evaluate 11 advanced agentic LLMs using DSAEval. Our results show that Claude-Sonnet-4.5 achieves the strongest overall performance, GPT-5.2 is the most efficient, and MiMo-V2-Flash is the most cost-effective. We further demonstrate that multimodal perception consistently improves performance on vision-related tasks, with gains ranging from 2.04% to 11.30%. Overall, while current data science agents perform well on structured data and routine data analysis workflows, substantial challenges remain in unstructured domains. Finally, we offer critical insights and outline future research directions to advance the development of data science agents.",3.47,131.534,457,cold_start,Phi-4,Apple_M1(Metal)
2601.13592v1_Machine learning based radiative parameterization .pdf,Machine learning based radiative parameterization scheme and its performance in operational reforecast experiments,"Jing Hao, Xiao Sa, Li Haoyu, Xiao Huadong, Xue Wei",,,"Machine learning, Radiation, Hybrid model, Operational reforecast experiments","Radiation is typically the most time-consuming physical process in numerical models. This study investigates critical limitations inherent to hybrid forecasting frameworks that embed deep neural networks into numerical prediction models, focusing on coupling compatibility and long-term integration stability. A residual convolutional neural network approximates the Rapid Radiative Transfer Model for General Circulation Models (RRTMG) within the global operational system of China Meteorological Administration. An offline training and online coupling approach is adopted, generating a comprehensive dataset through model simulations, including all atmospheric columns with and without cloud cover. The dataset is enhanced via experience replay, and additional output constraints based on physical significance are imposed. A LibTorch-based coupling method is utilized for real-time operational computations. The hybrid model performs ten-day integrated forecasts, and a two-month operational reforecast experiment demonstrates that the machine learning emulator achieves accuracy comparable to the traditional physical scheme, while accelerating computation speed by approximately eightfold.",3.45,85.307,294,cold_start,Phi-4,Apple_M1(Metal)
2601.13599v1_Diffusion In Diffusion Breaking the Autoregressive.pdf,Diffusion In Diffusion: Breaking the Autoregressive Bottleneck in Block Diffusion Models,"Linrui Ma, Yufei Cui, Kai Han, Yunhe Wang",,2601.13599v1,"block diffusion models, autoregressive models, diffusion models, language modeling, KV caching, generative perplexity, OpenWebText dataset","Block diffusion language models combine autoregressive and diffusion paradigms, but suffer from unidirectional block dependencies causing irreversibility and limited global planning. The proposed DIFFUSION INDIFFUSION framework addresses these issues by generating drafts with small blocks and refining them with global bidirectional diffusion. Snapshot confidence remasking and mix-scale training enhance the model's global capabilities. Empirical results show improved performance on the OpenWebText dataset, reducing generative perplexity significantly with less fine-tuning budget compared to baseline models.",3.11,77.092,240,cold_start,Phi-4,Apple_M1(Metal)
2601.13600v1_Foundations of Global Consistency Checking with No.pdf,Foundations of Global Consistency Checking with Noisy LLM Oracles,"Paul He, Elke Kirschbaum, Shiva Kasiviswanathan",,,"global consistency, natural-language facts, Large Language Models, minimal inconsistent subsets, consistency checking, fact-checking, knowledge base construction, adaptive divide-and-conquer algorithm, hitting-sets, linguistic consistency verification","Ensuring global consistency of natural-language facts is crucial for tasks like fact-checking, summarization, and knowledge base construction. While Large Language Models (LLMs) can assess small subsets of facts, their judgments are noisy, and pairwise checks are insufficient for global coherence. This paper formalizes the problem, showing that verifying global consistency requires exponentially many oracle queries in the worst case. An adaptive divide-and-conquer algorithm is proposed to identify minimal inconsistent subsets (MUSes) of facts and compute minimal repairs through hitting-sets, achieving low-degree polynomial query complexity. Experiments demonstrate the method's efficiency in detecting and localizing inconsistencies, providing a scalable framework for linguistic consistency verification with LLM-based evaluators.",3.18,88.856,283,cold_start,Phi-4,Apple_M1(Metal)
2601.13614v1_CauScientist Teaching LLMs to Respect Data for Cau.pdf,Teaching LLMs to Respect Data for Causal Discovery,"Bo Peng, Sirui Chen, Lei Xu, Chaochao Lu",,arXiv:2601.13614v1,"LLM, data-driven algorithm, dataset samples, variable information, algorithm limitations, causal discovery, statistical indistinguishability, modeling assumptions, distribution shift, large language models, causal knowledge, semantic information","Causal discovery is fundamental to scientific understanding and reliable decision-making. Existing approaches face critical limitations: purely data-driven methods suffer from statistical indistinguishability and modeling assumptions, while recent LLM-based methods either ignore statistical evidence or incorporate unverified priors that can mislead results. To address these issues, the authors propose CauScientist, a collaborative framework that synergizes LLMs as hypothesis-generating 'data scientists' with probabilistic statistics as rigorous 'verifiers'. CauScientist employs hybrid initialization to select superior starting graphs, iteratively refines structures through LLM-proposed modifications validated by statistical criteria, and maintains error memory to guide efficient search space. Experiments demonstrate that CauScientist substantially outperforms purely data-driven baselines, achieving up to 53.8% F1 score improvement and enhancing recall from 35.0% to 100.0%. Notably, while standalone LLM performance degrades with graph complexity, CauScientist reduces structural hamming distance (SHD) by 44.0% compared to Qwen3-32B on 37-node graphs.",3.39,112.61,382,cold_start,Phi-4,Apple_M1(Metal)
2601.13622v1_CARPE Context-Aware Image Representation Prioritiz.pdf,CARPE: CONTEXT-AWARE IMAGE REPRESENTATION PRIORITIZATION VIA ENSEMBLE FOR LARGE VISION-LANGUAGE MODELS,"Donghee Lee, Rui Cai, Zhe Zhao",,2601.13622v1,"Large Vision-Language Models, image classification, vision encoders, context-aware ensemble, generalization","Recent advancements in Large Vision-Language Models (LVLMs) have pushed them closer to becoming general-purpose assistants. Despite their strong performance, LVLMs still struggle with vision-centric tasks such as image classification, underperforming compared to their base vision encoders, which are often CLIP-based models. To address this limitation, we propose Context-Aware Image Representation Prioritization via Ensemble (CARPE), a novel, model-agnostic framework which introduces vision-integration layers and a context-aware ensemble strategy to identify when to prioritize image representations or rely on the reasoning capabilities of the language model. This design enhances the model’s ability to adaptively weight visual and textual modalities and enables the model to capture various aspects of image representations, leading to consistent improvements in generalization across classification and vision-language benchmarks. Extensive experiments demonstrate that CARPE not only improves performance on image classification benchmarks but also enhances results across various vision-language benchmarks. Finally, CARPE is designed to be effectively integrated with most open-source LVLMs that consist of a vision encoder and a language model, ensuring its adaptability across diverse architectures.",3.45,95.147,328,cold_start,Phi-4,Apple_M1(Metal)
2601.13632v1_Resilient Routing Risk-Aware Dynamic Routing in Sm.pdf,Resilient Routing: Risk-Aware Dynamic Routing in Smart Logistics via Spatiotemporal Graph Learning,"Zhiming Xue, Sichen Zhao, Yalun Qi, Xianling Zeng, Zihan Yu",,,"Smart Logistics, Graph Neural Network, Dynamic Routing, Spatiotemporal modeling, Supply Chain Resilience","With the rapid development of the e-commerce industry, the logistics network is experiencing unprecedented pressure. Traditional static routing strategies are often unable to tolerate traffic congestion and fluctuating retail demand. This paper proposes a Risk-Aware Dynamic Routing (RADR) framework integrating Spatiotemporal Graph Neural Networks (ST-GNN) with combinatorial optimization. A logistics topology graph is constructed using discrete GPS data and spatial clustering methods. A hybrid deep learning model combining Graph Convolutional Network (GCN) and Gated Recurrent Unit (GRU) is used to predict future congestion risks by extracting spatial correlations and temporal dependencies. These predictions are integrated into a dynamic edge weight mechanism for path planning. The framework is evaluated on the Smart Logistics Dataset 2024, containing real-world IoT sensor data. Results show that the RADR algorithm significantly enhances supply chain resilience, reducing congestion risk exposure by 19.3% with only a 2.1% increase in transportation distance, effectively balancing delivery efficiency and operational safety.",3.38,97.71,330,cold_start,Phi-4,Apple_M1(Metal)
2601.13645v1_Quadratic Upper Bound for Boosting Robustness.pdf,Quadratic Upper Bound for Boosting Robustness,"Euijin You, Hyang-Won Lee",,,"adversarial training, fast adversarial training, robustness, quadratic upper bound, loss function, adversarial attacks","Fast adversarial training (FAT) aims to enhance the robustness of models against adversarial attacks with reduced training time, but often suffers from compromised robustness due to insufficient exploration of adversarial space. This paper develops a loss function to improve robustness in FAT without requiring stronger inner maximization. A quadratic upper bound (QUB) on the adversarial training (AT) loss function is derived and utilized with existing FAT methods. Experimental results show that applying QUB loss to existing methods yields significant improvement in robustness, likely due to the smoothened loss landscape of the resulting models.",2.95,75.612,223,cold_start,Phi-4,Apple_M1(Metal)
2601.13647v1_Fusion Segment Transformer Bi-Directional Attentio.pdf,FUSION SEGMENT TRANSFORMER: BI-DIRECTIONAL ATTENTION GUIDED FUSION NETWORK FOR AI GENERATED MUSIC DETECTION,"Yumin Kim, Seonghyeon Go",,,"AI-generated music detection, Full-audio segment detection, Musical structure analysis, Cross-modal fusion layer, Music representation","With the rise of generative AI technology, anyone can now easily create and deploy AI-generated music, which has heightened the need for technical solutions to address copyright and ownership issues. Existing works mainly focused on short-audio, but the challenge of full-audio detection, which requires modeling long-term structure and context, remains insufficiently explored. This paper proposes an improved version of the Segment Transformer, termed the Fusion Segment Transformer. It extracts content embeddings from short music segments using diverse feature extractors and introduces a Gated Fusion Layer to integrate content and structural information, enabling the capture of long-term context. Experiments on the SONICS and AIME datasets show that this approach outperforms previous models and recent baselines, achieving state-of-the-art results in AI-generated music detection.",3.16,79.012,250,cold_start,Phi-4,Apple_M1(Metal)
2601.13649v1_Fairness or Fluency An Investigation into Language.pdf,Fairness or Fluency? An Investigation into Language Bias of Pairwise LLM-as-a-Judge,"Xiaolin Zhou, Zheng Luo, Yicheng Gao, Qixuan Chen, Xiyang Hu, Yue Zhao, Ruishan Liu",,,"LLM-as-a-judge, language bias, performance disparity, pairwise comparison, natural language processing","This paper investigates language bias in LLM-as-a-judge applications, focusing on performance disparities between languages and biases towards major languages. It identifies significant performance disparities across language families, with European languages outperforming African languages, especially in culturally-related subjects. The study also finds that models favor English in inter-language comparisons, influenced more by answer language than question language. While perplexity is slightly correlated with language bias, it cannot fully explain it.",2.94,76.898,226,cold_start,Phi-4,Apple_M1(Metal)
2601.13655v1_Why Does the LLM Stop Computing An Empirical Study.pdf,Why Does the LLM Stop Computing: An Empirical Study of User-Reported Failures in Open-Source LLMs,"Guangba Yu, Zirui Wang, Yujie Huang, Renyi Zhong, Yuedong Zhong, Yilun Wang, Michael R. Lyu",https://doi.org/XXXXXXX.XXXXXXX,,"Large Language Models, Failure Analysis, Empirical Study, Software reliability, Software usability, Empirical studies","The democratization of open-source Large Language Models (LLMs) allows users to fine-tune and deploy models on local infrastructure but exposes them to a 'First Mile' deployment landscape. Unlike black-box API consumption, the reliability of user-managed orchestration remains a critical blind spot. This study conducts the first large-scale empirical analysis of 705 real-world failures from the open-source DeepSeek, Llama, and Qwen ecosystems. The analysis reveals a paradigm shift where the reliability bottleneck moves from model algorithmic defects to the systemic fragility of the deployment stack. Three key phenomena are identified: Diagnostic Divergence, Systemic Homogeneity, and Lifecycle Escalation. These insights provide actionable guidance for enhancing the reliability of the LLM landscape.",3.17,98.15,311,cold_start,Phi-4,Apple_M1(Metal)
2601.13657v1_Communication-Free Collective Navigation for a Swa.pdf,Communication-Free Collective Navigation for a Swarm of UAVs via LiDAR-Based Deep Reinforcement Learning,"Myong-Yol Choi, Hankyoul Ko, Hanse Cho, Changseung Kim, Seunghwan Kim, Jaemin Seo, Hyondong Oh",,,"Multi-robot systems, collective navigation, sensor-based control, deep reinforcement learning","This paper presents a deep reinforcement learning (DRL) based controller for collective navigation of unmanned aerial vehicle (UAV) swarms in communication-denied environments, enabling robust operation in complex, obstacle-rich environments. Inspired by biological swarms where informed individuals guide groups without explicit communication, we employ an implicit leader-follower framework. In this paradigm, only the leader possesses goal information, while follower UAVs learn robust policies using only onboard LiDAR sensing, without requiring any inter-agent communication or leader identification. Our system utilizes LiDAR point clustering and an extended Kalman filter for stable neighbor tracking, providing reliable perception independent of external positioning systems. The core of our approach is a DRL controller, trained in GPU-accelerated Nvidia Isaac Sim, that enables followers to learn complex emergent behaviors—balancing flocking and obstacle avoidance—using only local perception. This allows the swarm to implicitly follow the leader while robustly addressing perceptual challenges such as occlusion and limited field-of-view. The robustness and sim-to-real transfer of our approach are confirmed through extensive simulations and challenging real-world experiments with a swarm of five UAVs, which successfully demonstrated collective navigation across diverse indoor and outdoor environments without any communication or external localization.",3.45,110.625,382,cold_start,Phi-4,Apple_M1(Metal)
2601.13659v1_Temporal-Spatial Decouple before Act Disentangled .pdf,TEMPORAL-SPATIAL DECOUPLE BEFORE ACT: DISENTANGLED REPRESENTATION LEARNING FOR MULTIMODAL SENTIMENT ANALYSIS,"Chunlei Meng, Ziyang Zhou, Lucas He, Xiaojing Du, Chun Ouyang, Zhongxue Gan",,,"Multimodal Sentiment Analysis, Temporal-Spatial Decoupling, Representation Learning","Multimodal Sentiment Analysis integrates Linguistic, Visual, and Acoustic evidence to infer sentiment. Mainstream approaches based on modality-invariant and modality-specific factorization or on complex fusion still rely on spatiotemporal mixed modeling, which ignores spatiotemporal heterogeneity, leading to information asymmetry and limited performance. The proposed TSDA (Temporal-Spatial Decouple before Act) explicitly decouples each modality into temporal dynamics and spatial structural context before any interaction. Temporal and spatial encoders project signals into separate temporal and spatial bodies. Factor-Consistent Cross-Modal Alignment aligns temporal features with their temporal counterparts across modalities, and spatial features with their spatial counterparts. Factor-specific supervision and decorrelation regularization reduce cross-factor leakage while preserving complementarity. A Gated Recouple module subsequently recouples the aligned streams for the task. Extensive experiments show that TSDA outperforms baselines, and ablation analysis confirms the necessity and interpretability of the design.",3.37,100.795,340,cold_start,Phi-4,Apple_M1(Metal)
2601.13671v1_The Orchestration of Multi-Agent Systems Architect.pdf,"The Orchestration of Multi-Agent Systems: Architectures, Protocols, and Enterprise Adoption","Apoorva Adimulam, Rajesh Gupta, Sumit Kumar",,,"Agent orchestration, Agent-to-Agent protocol (A2A), dynamic task allocation, Model Context Protocol (MCP), multi-agent systems, observability, state management, system governance","Orchestrated multi-agent systems represent the next stage in the evolution of artificial intelligence, where autonomous agents collaborate through structured coordination and communication to achieve complex, shared objectives. This paper consolidates and formalizes the technical composition of such systems, presenting a unified architectural framework that integrates planning, policy enforcement, state management, and quality operations into a coherent orchestration layer. Another primary contribution of this work is the in-depth technical delineation of two complementary communication protocols—the Model Context Protocol, which standardizes how agents access external tools and contextual data, and the Agent-to-Agent protocol, which governs peer coordination, negotiation, and delegation. Together, these protocols establish an interoperable communication substrate that enables scalable, auditable, and policy-compliant reasoning across distributed agent collectives. Beyond protocol design, the paper details how orchestration logic, governance frameworks, and observability mechanisms collectively sustain system coherence, transparency, and accountability. By synthesizing these elements into a cohesive technical blueprint, this paper provides comprehensive treatments of orchestrated multi-agent systems—bridging conceptual architectures with implementation-ready design principles for enterprise-scale AI ecosystems.",3.42,103.494,354,cold_start,Phi-4,Apple_M1(Metal)
2601.13684v1_HeteroCache A Dynamic Retrieval Approach to Hetero.pdf,HeteroCache: A Dynamic Retrieval Approach to Heterogeneous KV Cache,"Zhiyuan Shi, Qibo Qiu, Feng Xue, Zhonglin Jiang, Li Yu, Jian Jiang, Xiaofei He, Wenxiao Wang",,,"KV cache, LLM inference, long-context tasks, dynamic compression, attention drift, hierarchical storage, Transformer-based models","The linear memory growth of the KV cache poses a significant bottleneck for LLM inference in long-context tasks. Existing static compression methods often fail to preserve globally important information due to overlooking the attention drift phenomenon. HeteroCache, a training-free dynamic compression framework, addresses these issues by categorizing attention heads based on stability and redundancy, applying a fine-grained weighting strategy, and employing a hierarchical storage mechanism to monitor attention shifts and trigger asynchronous retrieval. Experiments demonstrate that HeteroCache achieves state-of-the-art performance on multiple long-context benchmarks and accelerates decoding by up to 3× compared to the original model in the 224K context.",3.21,87.221,280,cold_start,Phi-4,Apple_M1(Metal)
2601.13687v1_Understanding Mental States to Guide Social Influe.pdf,Understanding Mental States to Guide Social Influence in Multi-Person Group Dialogue,"Zhichao Liang, Satoshi Nakamura",,,"Theory of Mind, Social Influence, Multi-Person Dialogue, Language Models, SocialMindChange Benchmark","This paper introduces the SocialMindChange benchmark, which shifts the focus from merely tracking mental states in language models to actively changing them in social interactions. The benchmark involves a social context with four characters across five connected scenes, where the model plays one character and generates dialogue to achieve a target while maintaining consistency with evolving mental states. The study evaluates ten state-of-the-art language models, finding their performance to be 54.2% below human performance, indicating challenges in maintaining and altering mental-state representations in extended interactions.",2.83,66.04,187,cold_start,Phi-4,Apple_M1(Metal)
2601.13693v1_End-to-End Reverse Screening Identifies Protein Ta.pdf,End-to-End Reverse Screening Identifies Protein Targets of Small Molecules Using HelixFold3,"Shengjie Xu, Xianbin Ye, Mengran Zhu, Xiaonan Zhang, Shanzhuo Zhang, Xiaomin Fang",,2601.13693v1,"Reverse screening, Target identification, Biomolecular structure prediction, HelixFold3","Identifying protein targets for small molecules, or reverse screening, is essential for understanding drug action, guiding compound repurposing, predicting off-target effects, and elucidating the molecular mechanisms of bioactive compounds. Despite its critical role, reverse screening remains challenging because accurately capturing interactions between a small molecule and structurally diverse proteins is inherently complex, and conventional step-wise workflows often propagate errors across decoupled steps such as target structure modeling, pocket identification, docking, and scoring. Here, we present an end-to-end reverse screening strategy leveraging HelixFold3, a high-accuracy biomolecular structure prediction model akin to AlphaFold3, which simultaneously models the folding of proteins from a protein library and the docking of small-molecule ligands within a unified framework. We validate this approach on a diverse and representative set of approximately one hundred small molecules. Compared with conventional reverse docking, our method improves screening accuracy and demonstrates enhanced structural fidelity, binding-site precision, and target prioritization. By systematically linking small molecules to their protein targets, this framework establishes a scalable and straightforward platform for dissecting molecular mechanisms, exploring off-target interactions, and supporting rational drug discovery.",3.83,95.0,364,cold_start,Phi-4,Apple_M1(Metal)
2601.13697v1_Uncertainty-Aware Gradient Signal-to-Noise Data Se.pdf,Uncertainty-Aware Gradient Signal-to-Noise Data Selection for Instruction Tuning,"Zhihang Yuan, Chengyu Yue, Long Huang, Litu Ou, Lei Shi",,,"instruction tuning, large language models, data selection, gradient signal-to-noise ratio, uncertainty-aware","Instruction tuning is a standard paradigm for adapting large language models (LLMs), but modern instruction datasets are large, noisy, and redundant, making full-data fine-tuning costly and often unnecessary. Existing data selection methods either build expensive gradient datastores or assign static scores from a weak proxy, largely ignoring evolving uncertainty, and thus missing a key source of LLM interpretability. We propose GRADFILTERING, an objective-agnostic, uncertainty-aware data selection framework that utilizes a small GPT-2 proxy with a LoRA ensemble and aggregates per-example gradients into a Gradient Signal-to-Noise Ratio (G-SNR) utility. Our method matches or surpasses random subsets and strong baselines in most LLM-as-a-judge evaluations as well as in human assessment. Moreover, GRADFILTERING-selected subsets converge faster than competitive filters under the same compute budget, reflecting the benefit of uncertainty-aware scoring.",3.14,86.838,273,cold_start,Phi-4,Apple_M1(Metal)
2601.13698v1_Does Privacy Always Harm Fairness Data-Dependent T.pdf,Does Privacy Always Harm Fairness? Data-Dependent Trade-offs via Chernoff Information Neural Estimation,"Arjun Nichani, Hsiang Hsu, Chun-Fu (Richard) Chen, Haewon Jeong",,2601.13698v1,"fairness, privacy, machine learning, Chernoff Information, data-dependent trade-offs","Fairness and privacy are crucial aspects of trustworthy machine learning, yet their relationship is less explored. This paper uses Chernoff Information to analyze the data-dependent relationship among fairness, privacy, and accuracy. The authors introduce Noisy Chernoff Difference to study these interactions, showing distinct behaviors in synthetic data and proposing a method to estimate Chernoff Information for real datasets. The study aims to provide a unified understanding of the fairness-privacy-accuracy relationship and its data-dependent nature.",3.02,73.437,222,cold_start,Phi-4,Apple_M1(Metal)
2601.13704v1_Performance and Complexity Trade-off Optimization .pdf,Performance and Complexity Trade-off: Optimization of Speech Models During Training,"Esteban Gómez, Tom Backström",,,"Speech machine learning, low-complexity, voice activity detection, deep fake detection","In speech machine learning, neural network models are typically designed with fixed architectures and trained to maximize performance on task-specific metrics. However, this approach often results in suboptimal trade-offs between performance and computational complexity. Post hoc methods like weight quantization or model pruning are usually employed to reduce computational costs. This paper proposes a reparameterization technique based on feature noise injection, enabling joint optimization of performance and computational complexity during training using SGD-based methods. This approach allows dynamic optimization of model size for a target performance-complexity trade-off, without relying on heuristic criteria for weight or structure removal. The method's effectiveness is demonstrated through three case studies, including voice activity detection and audio anti-spoofing. The code is publicly available to encourage further research.",3.19,76.286,243,cold_start,Phi-4,Apple_M1(Metal)
2601.13707v1_Attention-space Contrastive Guidance for Efficient.pdf,Attention-space Contrastive Guidance for Efficient Hallucination Mitigation in LVLMs,"Yujin Jo, Sangyoon Bae, Taesup Kim",,,"hallucination mitigation, large vision–language models, contrastive guidance, self-attention layers, computational efficiency","Hallucinations in large vision–language models (LVLMs) often arise when language priors dominate over visual evidence, leading to object misidentification and inconsistent descriptions. This paper introduces Attention-space Contrastive Guidance (ACG), a single-pass mechanism within self-attention layers that constructs vision–language and language-only attention paths in one forward computation. ACG reduces over-dependence on language priors and enhances visual contributions, achieving state-of-the-art faithfulness and caption quality with reduced computational cost. Experiments on the CHAIR and POPE benchmarks demonstrate ACG's efficiency, reducing latency by up to 2× compared to prior methods.",3.05,74.407,227,cold_start,Phi-4,Apple_M1(Metal)
2601.13709v1_Hidden in Plain Text Measuring LLM Deception Quali.pdf,Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games,"Christopher Kao, Vanshika Vats, James Davis",,,"large language models, natural language processing, autonomous game players, social deduction games","Large Language Model (LLM) agents are increasingly used in various applications, raising safety concerns. This paper explores LLMs' ability to deceive in social contexts using the Social Deduction Game (SDG) Mafia. An asynchronous multi-agent framework simulates realistic social interactions. The study involves 35 Mafia games with GPT-4o LLM agents and a Mafia Detector using GPT-4-Turbo to analyze game transcripts. The detector's prediction accuracy for identifying mafia players is compared to human games and a random baseline. Results indicate LLMs blend in better, suggesting more effective deception. A dataset of LLM Mafia transcripts is released for future research, highlighting the sophistication and risks of LLM deception in social contexts.",3.07,75.672,232,cold_start,Phi-4,Apple_M1(Metal)
2601.13710v1_Who Should Have Surgery A Comparative Study of Gen.pdf,Who Should Have Surgery? A Comparative Study of GenAI vs Supervised ML for CRS Surgical Outcome Prediction,"Sayeed Shafayet Chowdhury, Snehasis Mukhopadhyay, Shiaofen Fang, Vijay R. Ramakrishnan",,,"Chronic Rhinosinusitis, clinical decision support, generative artificial intelligence, large language models, SNOT-22, surgical outcome prediction, tabular clinical data","This study evaluates the effectiveness of supervised machine learning (ML) models versus generative AI (GenAI) models in predicting surgical outcomes for chronic rhinosinusitis (CRS). The research focuses on pre-operative prediction of clinically meaningful improvement, defined as a ≥8.9-point reduction in SNOT-22 at 6 months. The study compares various ML models, including logistic regression, tree ensembles, and an in-house MLP, against GenAI models like ChatGPT, Claude, Gemini, and Perplexity. The best ML model (MLP) achieved 85% accuracy with superior calibration and decision-curve net benefit, while GenAI models underperformed in discrimination and calibration. The study suggests an ML-first, GenAI-augmented workflow for surgical candidacy triage, enhancing transparency and shared decision-making.",3.28,97.404,319,cold_start,Phi-4,Apple_M1(Metal)
2601.13717v1_Simulated Ignorance Fails A Systematic Study of LL.pdf,Simulated Ignorance Fails: A Systematic Study of LLM Behaviors on Forecasting Problems Before Model Knowledge Cutoff,"Zehan Li, Yuxuan Wang, Ali El Lahib, Ying-Jieh Xia, Xinyu Pi",,,"LLM, forecasting, Simulated Ignorance, True Ignorance, retrospective forecasting, knowledge cutoff","Evaluating LLM forecasting capabilities is constrained by a tension between prospective evaluation, which offers methodological rigor but prohibitive latency, and retrospective forecasting (RF), which faces rapidly shrinking clean evaluation data as models possess increasingly recent knowledge cutoffs. Simulated Ignorance (SI), prompting models to suppress pre-cutoff knowledge, has emerged as a potential solution. This study systematically tests whether SI can approximate True Ignorance (TI) across 477 competition-level questions and 9 models. Findings show that SI fails systematically: (1) cutoff instructions leave a 52% performance gap between SI and TI; (2) chain-of-thought reasoning fails to suppress prior knowledge, even when reasoning traces contain no explicit post-cutoff references; (3) reasoning-optimized models exhibit worse SI fidelity despite superior reasoning trace quality. These findings demonstrate that prompts cannot reliably 'rewind' model knowledge. The study concludes that RF on pre-cutoff events is methodologically flawed and recommends against using SI-based retrospective setups to benchmark forecasting capabilities.",3.14,102.593,322,cold_start,Phi-4,Apple_M1(Metal)
2601.13719v1_Hierarchical Long Video Understanding with Audiovi.pdf,Hierarchical Long Video Understanding with Audiovisual Entity Cohesion and Agentic Search,"Xinlei Yin, Xiulian Peng, Xiao Li, Zhiwei Xiong, Yan Lu",,,"long video understanding, vision-language models, audiovisual entity cohesion, hierarchical video indexing, agentic search, semantic consistency, entity-level representations, structured hierarchy, temporal coherence, entity consistency, retrieval efficiency, LVBench, reasoning category","Long video understanding presents significant challenges for vision-language models due to extremely long context windows. Existing solutions relying on naive chunking strategies with retrieval-augmented generation typically suffer from information fragmentation and a loss of global coherence. This paper presents HAVEN, a unified framework for long-video understanding that enables coherent and comprehensive reasoning by integrating audiovisual entity cohesion and hierarchical video indexing with agentic search. The framework preserves semantic consistency by integrating entity-level representations across visual and auditory streams, organizing content into a structured hierarchy spanning global summary, scene, segment, and entity levels. An agentic search mechanism is employed to enable dynamic retrieval and reasoning across these layers, facilitating coherent narrative reconstruction and fine-grained entity tracking. Extensive experiments demonstrate that the method achieves good temporal coherence, entity consistency, and retrieval efficiency, establishing a new state-of-the-art with an overall accuracy of 84.1% on LVBench. Notably, it achieves outstanding performance in the challenging reasoning category, reaching 80.1%. These results highlight the effectiveness of structured, multimodal reasoning for comprehensive and context-consistent understanding of long-form videos.",3.56,109.616,390,cold_start,Phi-4,Apple_M1(Metal)
2601.13722v1_OP-Bench Benchmarking Over-Personalization for Mem.pdf,OP-Bench: Benchmarking Over-Personalization for Memory-Augmented Personalized Conversational Agents,"Yulin Hu, Zimo Long, Jiahe Guo, Xingyu Sui, Xing Fu, Weixiang Zhao, Yanyan Zhao, Bing Qin",,arXiv:2601.13722v1,"memory-augmented conversational agents, personalization, over-personalization, benchmarking, large language models, dialogue systems","Memory-augmented conversational agents enable personalized interactions using long-term user memory and have gained substantial traction. However, existing benchmarks primarily focus on whether agents can recall and apply user information, while overlooking whether such personalization is used appropriately. This work formalizes over-personalization into three types: Irrelevance, Repetition, and Sycophancy, and introduces OP-Bench, a benchmark of 1,700 verified instances constructed from long-horizon dialogue histories. Using OP-Bench, multiple large language models and memory-augmentation methods are evaluated, revealing widespread over-personalization when memory is introduced. A lightweight, model-agnostic memory filtering mechanism called Self-ReCheck is proposed to mitigate over-personalization while preserving personalization performance. This work takes an initial step toward more controllable and appropriate personalization in memory-augmented dialogue systems.",3.41,99.414,339,cold_start,Phi-4,Apple_M1(Metal)
2601.13734v1_Towards robust long-context understanding of large.pdf,TOWARDS ROBUST LONG-CONTEXT UNDERSTANDING OF LARGE LANGUAGE MODEL VIA ACTIVE RECAP LEARNING,Chenyu Hui,,,"LLM, Long-context understanding, Active recap learning, Recap supervision, Recap agent","This paper introduces active recap learning (ARL), a framework designed to enhance large language models (LLMs) in understanding long contexts. ARL enables models to revisit and summarize earlier content through targeted sequence construction during continued pretraining and retrospective summarization at inference. The approach involves identifying key tokens in long contexts and summarizing relevant preceding paragraphs using an LLM. ARL equips models with the ability to autonomously generate and utilize these retrospective summaries during inference, establishing a recursive memory mechanism across paragraphs. Experimental results demonstrate significant improvements, with ARL achieving a 26.8% improvement on RULER and a 9.44% improvement on LongBench. ARL offers a simple yet effective continued pretraining-based approach to strengthen long-context understanding, advancing scalable memory augmentation in LLMs.",3.21,80.428,258,cold_start,Phi-4,Apple_M1(Metal)
2601.13735v1_Reasoning or Fluency Dissecting Probabilistic Conf.pdf,Reasoning or Fluency? Dissecting Probabilistic Confidence in Best-of-N Selection,"Hojin Kim, Jaehyung Kim",,,"Probabilistic Confidence Metrics, Best-of-N Selection, Reasoning Quality, Inter-step Causal Dependencies, Large Language Models, Chain-of-Thought, Contrastive Causality Metric","Probabilistic confidence metrics are increasingly used as proxies for reasoning quality in Best-of-N selection, assuming higher confidence indicates higher reasoning fidelity. This study challenges this assumption by examining whether these metrics capture necessary inter-step causal dependencies for valid reasoning. Three classes of inter-step causality perturbations are introduced to disrupt dependencies while preserving local fluency. Findings show that selection accuracy degrades marginally under these disruptions, even with severe interventions like hard attention masks. This suggests that current probabilistic metrics are insensitive to logical structure and primarily capture surface-level fluency or in-distribution priors. A new contrastive causality metric is proposed, demonstrating more faithful output selection than existing probability-based approaches.",3.05,85.969,262,cold_start,Phi-4,Apple_M1(Metal)
2601.13749v1_Pro-AI Bias in Large Language Models.pdf,Pro-AI Bias in Large Language Models,"Benaya Trabelsi, Jonathan Shaki, Sarit Kraus",,,"Large Language Models, Pro-AI Bias, Decision-Support, Artificial Intelligence, Salary Estimation, Internal Representations","This study investigates whether large language models (LLMs) display a systematic preferential bias in favor of artificial intelligence (AI). Through three experiments, evidence of pro-AI bias is found. LLMs disproportionately recommend AI-related options in advice-seeking queries, overestimate salaries for AI-related jobs, and show representational centrality of 'Artificial Intelligence' in internal model representations. These findings suggest that LLM-generated advice and valuation can skew choices and perceptions in high-stakes decisions.",2.93,69.267,203,cold_start,Phi-4,Apple_M1(Metal)
2601.13752v1_Finding RELIEF Shaping Reasoning Behavior without .pdf,Finding RELIEF: Shaping Reasoning Behavior without Reasoning Supervision via Belief Engineering,"Chak Tou Leong, Dingwei Chen, Heming Xia, Qingyu Yin, Sunbowen Lee, Jian Wang, Wenjie Li",,,"Large reasoning models, reasoning behavior, belief engineering, computational redundancy, reasoning unfaithfulness, reinforcement learning, fine-tuning, logit probing, question-answering pairs, efficiency, faithfulness tasks","Large reasoning models (LRMs) have achieved remarkable success in complex problem-solving, yet they often suffer from computational redundancy or reasoning unfaithfulness. Current methods for shaping LRM behavior typically rely on reinforcement learning or fine-tuning with gold-standard reasoning traces, a paradigm that is both computationally expensive and difficult to scale. This paper reveals that LRMs possess latent reasoning beliefs that can be captured through simple logit probing. The proposed Reasoning Belief Engineering (RELIEF) framework shapes LRM behavior by aligning the model’s self-concept with a target belief blueprint, bypassing the need for reasoning-trace supervision. It internalizes desired traits by fine-tuning on synthesized, self-reflective question-answering pairs that affirm the target belief. Experiments demonstrate that RELIEF matches or outperforms behavior-supervised and preference-based baselines while requiring lower training costs. Shifting a model’s reasoning belief effectively shapes its actual behavior.",3.25,104.138,338,cold_start,Phi-4,Apple_M1(Metal)
2601.13761v1_DARC Decoupled Asymmetric Reasoning Curriculum for.pdf,DARC: Decoupled Asymmetric Reasoning Curriculum for LLM Evolution,"Shengda Fan, Xuyan Ye, Yankai Lin",,arXiv:2601.13761v1,"self-play, large language models, self-improving artificial intelligence, self-evolution, reasoning tasks, self-play frameworks, optimization instability, self-generated pseudo-labels, self-distillation, reasoning benchmarks","Self-play with large language models has emerged as a promising paradigm for achieving self-improving artificial intelligence. However, existing self-play frameworks often suffer from optimization instability due to non-stationary objectives and bootstrapping errors from self-generated pseudo-labels. To address these challenges, the paper introduces DARC (Decoupled Asymmetric Reasoning Curriculum), a two-stage framework that stabilizes the self-evolution process. The first stage involves training the Questioner to synthesize difficulty-calibrated questions, while the second stage trains the Solver with an asymmetric self-distillation mechanism. Empirical results demonstrate that DARC is model-agnostic, yielding significant improvements across various reasoning benchmarks and models, outperforming baselines and approaching the performance of fully supervised models without human annotations.",3.28,92.896,305,cold_start,Phi-4,Apple_M1(Metal)
2601.13768v1_vLinear A Powerful Linear Model for Multivariate T.pdf,vLinear: A Powerful Linear Model for Multivariate Time Series Forecasting,"Wenzhen Yue, Ruohao Guo, Ji Shi, Zihan Hao, Shiyu Hu, Xianghua Ying",,,"multivariate time series forecasting, linear model, vecTrans, WFMLoss, Transformer-based forecasters, self-attention, computational complexity","This paper introduces vLinear, a linear-based multivariate time series forecaster featuring the vecTrans module and the WFMLoss objective. vecTrans reduces computational complexity from O(N^2) to O(N) by using a learnable vector to model multivariate correlations, allowing for integration into Transformer-based forecasters with up to 5× inference speedups and performance gains. WFMLoss, a final-series-oriented objective, improves forecasting accuracy by focusing on reliable paths and horizons. Empirically, vLinear achieves state-of-the-art performance across 22 benchmarks and 124 forecasting settings, and WFMLoss enhances existing forecasters. The code is available at https://anonymous.4open.science/r/vLinear.",3.05,92.023,281,cold_start,Phi-4,Apple_M1(Metal)
2601.13770v1_Look-Ahead-Bench a Standardized Benchmark of Look-.pdf,Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance,Mostapha Benhenda,,2601.13770v1,"cs.AI, look-ahead bias, Point-in-Time LLMs, finance, Large Language Models, benchmark, temporal bias","We introduce Look-Ahead-Bench, a standardized benchmark measuring look-ahead bias in Point-in-Time (PiT) Large Language Models (LLMs) within realistic and practical financial workflows. Unlike most existing approaches that primarily test inner lookahead knowledge via Q&A, our benchmark evaluates model behavior in practical scenarios. To distinguish genuine predictive capability from memorization-based performance, we analyze performance decay across temporally distinct market regimes, incorporating several quantitative baselines to establish performance thresholds. We evaluate prominent open-source LLMs—Llama 3.1 (8B and 70B) and DeepSeek 3.2—against a family of Point-in-Time LLMs (Pitinf-Small, Pitinf-Medium, and frontier-level model Pitinf-Large) from PiT-Inference. Results reveal significant lookahead bias in standard LLMs, as measured with alpha decay, unlike Pitinf models, which demonstrate improved generalization and reasoning abilities as they scale in size. This work establishes a foundation for the standardized evaluation of temporal bias in financial LLMs and provides a practical framework for identifying models suitable for real-world deployment.",3.27,105.709,346,cold_start,Phi-4,Apple_M1(Metal)
2601.13798v1_Insight Interpretable Semantic Hierarchies in Visi.pdf,INSIGHT: Interpretable Semantic Hierarchies in Vision-Language Encoders,"Kai Wittenmayer, Sukrut Rao, Amin Parchami-Araghi, Bernt Schiele, Jonas Fischer",,arXiv:2601.13798v1,"Rich Concept Representation, Concept Relations, Language-aligned Vision Encoder, Spatial Grounding, Concept-based Inference & Explanation, Classification, Open-vocab Segmentation, Captioning, Downstream Tasks, Patch-wise Concept Encoder, Concept Steering, Hierarchical Concept Representation, Local Spatially Grounded Concepts, Human-interpretable Concepts, Semantic Representations, Concept Relationships, Benchmark Data, Performance on Classification and Segmentation, Fine-grained Concept-based Explanations","INSIGHT is a language-aligned concept foundation model that provides fine-grained, human-interpretable, and spatially grounded concepts for vision tasks. It leverages a hierarchical sparse autoencoder and a foundation model with strong semantic representations to extract concepts at various granularities. By examining local co-occurrence dependencies, INSIGHT defines concept relationships, improving concept naming and offering richer explanations. It demonstrates competitive performance on classification and segmentation tasks compared to opaque foundation models, while providing high-quality concept-based explanations.",3.39,98.61,334,cold_start,Phi-4,Apple_M1(Metal)
2601.13809v1_DroneVLA VLA based Aerial Manipulation.pdf,DroneVLA: VLA based Aerial Manipulation,"Fawad Mehboob, Monijesu James, Amir Habel, Jeffrin Sam, Miguel Altamirano Cabrera, Dzmitry Tsetserukou",,,"Aerial Manipulation, Vision-Language-Action Models, Human-Robot Interaction, Visual Surveying, Robotic Fetch-and-Carry","This work introduces a novel concept of an autonomous aerial manipulation system capable of interpreting high-level natural language commands to retrieve objects and deliver them to a human user. The system integrates a MediaPipe based on Grounding DINO and a Vision-Language-Action (VLA) model with a custom-built drone equipped with a 1-DOF gripper and an Intel RealSense RGB-D camera. VLA performs semantic reasoning to interpret the intent of a user prompt and generates a prioritized task queue for grasping relevant objects in the scene. Grounding DINO and a dynamic A* planning algorithm are used to navigate and safely relocate the object. To ensure safe and natural interaction during the handover phase, the system employs a human-centric controller driven by MediaPipe, providing real-time human pose and orientation estimation, allowing the drone to employ visual servoing to maintain a stable position directly in front of the user, facilitating a comfortable handover. The system's efficacy is demonstrated through real-world experiments for localization and navigation, highlighting the feasibility of VLA for aerial manipulation operations.",3.37,105.414,355,cold_start,Phi-4,Apple_M1(Metal)
2601.13846v1_Virtual Urbanism An AI-Driven Framework for Quanti.pdf,Virtual Urbanism: An AI-Driven Framework for Quantifying Urban Identity. A Tokyo-Based Pilot Study Using Diffusion-Generated Synthetic Environments,Glinskaya Maria,,,"generative artificial intelligence, latent diffusion model, low-rank adaptation model, urban perception, urban identity","This paper introduces Virtual Urbanism (VU), a multimodal AI-driven analytical framework for quantifying urban identity through synthetic urban replicas. The framework aims to advance computationally tractable urban identity metrics. A pilot study, Virtual Urbanism and Tokyo Microcosms, demonstrates feasibility using a pipeline integrating Stable Diffusion and LoRA models to produce synthetic replicas of nine Tokyo areas as dynamic urban sequences. Human-evaluation experiments assessed perceptual legitimacy, quantified area-level identity, and derived core identity-forming elements. Results showed a mean identification accuracy of ~81%, confirming the validity of the replicas. The Urban Identity Level (UIL) metric enabled assessment of identity levels across areas, while semantic analysis revealed culturally embedded typologies as core identity-forming elements, positioning VU as a viable framework for AI-augmented urban analysis, outlining a path toward automated, multi-parameter identity metrics.",2.99,87.709,262,cold_start,Phi-4,Apple_M1(Metal)
2601.13864v1_HardSecBench Benchmarking the Security Awareness o.pdf,HardSecBench: Benchmarking the Security Awareness of LLMs for Hardware Code Generation,"Qirui Chen, Jingxian Shuai, Shuangwu Chen, Shenghao Ye, Zijian Wen, Xufei Su, Jie Jin, Jiangming Li, Jun Chen, Xiaobin Tan, Jian Yang",,,"LLMs, hardware code generation, security awareness, Verilog RTL, firmware-level C, Common Weakness Enumeration (CWE)","Large language models (LLMs) are increasingly integrated into hardware and firmware development pipelines for code generation. While existing studies focus on functional correctness, security issues are often overlooked. This research introduces HardSecBench, a benchmark with 924 tasks covering Verilog RTL and firmware-level C, addressing 76 hardware-relevant CWE entries. The benchmark includes structured specifications, secure reference implementations, and executable tests. A multi-agent pipeline automates artifact synthesis, decoupling synthesis from verification and grounding evaluation in execution evidence. Using HardSecBench, the study evaluates LLMs on hardware and firmware code generation, revealing that models often meet functional requirements but leave security risks. The findings highlight challenges and provide insights for future advancements in LLM-assisted hardware design. Data and code will be released soon.",3.28,101.103,332,cold_start,Phi-4,Apple_M1(Metal)
2601.13880v1_LifeAgentBench A Multi-dimensional Benchmark and A.pdf,LifeAgentBench: A Multi-dimensional Benchmark and Agent for Personal Health Assistants in Digital Health,"Ye Tian, Zihao Wang, Onat Gungor, Xiaoran Fan, Tajana Rosing",,,"digital health, personal health assistants, large language models, mobile sensing, long-horizon reasoning, cross-dimensional reasoning, QA benchmark, health assistant","Personalized digital health support requires long-horizon, cross-dimensional reasoning over heterogeneous lifestyle signals. Recent advances in mobile sensing and large language models (LLMs) make such support increasingly feasible. However, the capabilities of current LLMs in this setting remain unclear due to the lack of systematic benchmarks. This paper introduces LifeAgentBench, a large-scale QA benchmark for long-horizon, cross-dimensional, and multi-user lifestyle health reasoning, containing 22,573 questions. An extensible benchmark construction pipeline and a standardized evaluation protocol are released to enable reliable and scalable assessment of LLM-based health assistants. Eleven leading LLMs are systematically evaluated on LifeAgentBench, identifying key bottlenecks in long-horizon aggregation and cross-dimensional reasoning. LifeAgent is proposed as a strong baseline agent for health assistants, integrating multi-step evidence retrieval with deterministic aggregation, achieving significant improvements compared with two widely used baselines. Case studies demonstrate its potential in realistic daily-life scenarios. The benchmark is publicly available.",3.31,102.98,341,cold_start,Phi-4,Apple_M1(Metal)
2601.13885v1_Confident Rankings with Fewer Items Adaptive LLM E.pdf,Confident Rankings with Fewer Items: Adaptive LLM Evaluation with Continuous Scores,"Esma Balkır, Alice Pernthaller, Marco Basaldella, José Hernández-Orallo, Nigel Collier",,,"Computerized Adaptive Testing, IRT-based adaptive testing, LLM evaluation, continuous scores, heteroskedastic normal distribution, BLEU, ROUGE, LLM-as-a-Judge","This paper extends IRT-based adaptive testing to accommodate continuous bounded scores for LLM evaluation, replacing the Bernoulli response distribution with a heteroskedastic normal distribution. The authors introduce an uncertainty-aware ranker with adaptive stopping criteria, achieving reliable model ranking with fewer test items. The method is validated on five benchmarks, using only 2% of items while improving ranking correlation by 0.12 τ over random sampling, with 95% accuracy on confident predictions.",3.01,80.059,241,cold_start,Phi-4,Apple_M1(Metal)
2601.13887v1_Human Simulation Computation A Human-Inspired Fram.pdf,Human Simulation Computation: A Human-Inspired Framework for Adaptive AI Systems,Hong Su,,,"Human Simulation Computation, Environment Interaction, Adaptive Artificial Intelligence, Human-Inspired Reasoning","Large language models (LLMs) have shown strong capabilities in knowledge representation and reasoning based on textual data. However, their reliance on language alone limits their adaptability, verification of reasoning outcomes, and effectiveness in dynamic real-world environments. This paper proposes Human Simulation Computation (HSC), a human-inspired computational framework that models intelligence as a continuous, closed-loop process involving thinking, action, learning, reflection, and activity scheduling. HSC emphasizes active participation within the internal reasoning process and interactions with the environment, using actions to refine and improve internal reasoning mechanisms without external intervention. It incorporates human thinking strategies across all stages of the internal reasoning process, such as main-feature-oriented reasoning, scope expansion through action, and on-time learning driven by environmental feedback. The paper argues that human simulation strategies cannot be fully learned from language material alone and that human-like reasoning processes and action-grounded reasoning methods are essential for robust adaptation and effective interaction with real-world environments.",3.32,79.837,265,cold_start,Phi-4,Apple_M1(Metal)
2601.13895v1_OmniOVCD Streamlining Open-Vocabulary Change Detec.pdf,OmniOVCD: Streamlining Open-Vocabulary Change Detection with SAM 3,"Xu Zhang, Danyang Li, Yingjie Xia, Xiaohang Dong, Hualong Yu, Jianye Wang, Qicheng Li",,,"Change Detection, Open-Vocabulary Change Detection, SAM 3, Segment Anything Model, remote sensing, land cover, instance-level consistency, IoU scores","Change Detection (CD) is a fundamental task in remote sensing, monitoring the evolution of land cover over time. Open-Vocabulary Change Detection (OVCD) aims to reduce reliance on predefined categories. Existing training-free OVCD methods often use CLIP for category identification and require extra models like DINO for feature extraction, leading to instability. The Segment Anything Model 3 (SAM 3) integrates segmentation and identification capabilities, offering new possibilities for OVCD. This paper proposes OmniOVCD, a standalone framework leveraging SAM 3's decoupled output heads with a Synergistic Fusion to Instance Decoupling (SFID) strategy. SFID fuses semantic, instance, and presence outputs to construct land-cover masks, decomposing them into individual instance masks for change comparison. This design maintains high accuracy in category recognition and instance-level consistency, generating accurate change masks. Experiments on four public benchmarks demonstrate state-of-the-art performance, surpassing previous methods.",3.16,99.585,315,cold_start,Phi-4,Apple_M1(Metal)
2601.13897v1_TractRLFusion A GPT-Based Multi-Critic Policy Fusi.pdf,TRACTRLFUSION: A GPT-BASED MULTI-CRITIC POLICY FUSION FRAMEWORK FOR FIBER TRACTOGRAPHY,"Ankita Joshi, Ashutosh Sharma, Anoushkrit Goel, Ranjeet Ranjan Jha, Chirag Ahuja, Arnav Bhavsar, Aditya Nigam",,,"Diffusion MRI, Tractography, Reinforcement Learning, Transformers","Tractography is crucial for non-invasive reconstruction of white matter fiber pathways, aiding in brain connectivity analysis and neurosurgical planning. Traditional methods include deterministic and probabilistic approaches, while recent advancements utilize supervised deep learning (DL) and deep reinforcement learning (DRL) for improved tract reconstruction. The challenge remains in accurately reconstructing white matter tracts while minimizing spurious connections. This paper introduces TractRLFusion, a novel GPT-based policy fusion framework that integrates multiple RL policies through a data-driven fusion strategy. It employs a two-stage training data selection process for effective policy fusion, followed by a multi-critic fine-tuning phase to enhance robustness and generalization. Experiments on HCP, ISMRM, and TractoInferno datasets show that TractRLFusion outperforms individual RL policies and state-of-the-art classical and DRL methods in accuracy and anatomical reliability.",3.35,100.337,336,cold_start,Phi-4,Apple_M1(Metal)
2601.13904v1_PREFAB PREFerence-based Affective Modeling for Low.pdf,PREFAB: PREFerence-based Affective Modeling for Low-Budget Self-Annotation,"Jaeyoung Moon, Youjin Choi, Yucheon Park, David Melhart, Georgios N. Yannakakis, Kyung-Joong Kim",10.1145/3675094.3678379,2601.13904v1,"Affective Computing, Preference Learning, Self-Annotation, User Modeling, Ordinal Representation, Peak-End Rule","Self-annotation is the gold standard for collecting affective state labels in affective computing. Existing methods typically rely on full annotation, requiring users to continuously label affective states across entire sessions. While this process yields fine-grained data, it is time-consuming, cognitively demanding, and prone to fatigue and errors. To address these issues, we present PREFAB, a low-budget retrospective self-annotation method that targets affective inflection regions rather than full annotation. Grounded in the peak-end rule and ordinal representations of emotion, PREFAB employs a preference-learning model to detect relative affective changes, directing annotators to label only selected segments while interpolating the remainder of the stimulus. We further introduce a preview mechanism that provides brief contextual cues to assist annotation. We evaluate PREFAB through a technical performance study and a 25-participant user study. Results show that PREFAB outperforms baselines in modeling affective inflections while mitigating workload (and conditionally mitigating temporal burden). Importantly, PREFAB improves annotator confidence without degrading annotation quality.",3.37,111.202,375,cold_start,Phi-4,Apple_M1(Metal)
2601.13920v1_Asymmetric regularization mechanism for GAN traini.pdf,Asymmetric regularization mechanism for GAN training with Variational Inequalities,"Spyridon C. Giagtzoglou, Mark H.M. Winands, Barbara Franci",,,"Generative Adversarial Networks, Nash equilibrium, Tikhonov step, zero-centered gradient penalty, Lipschitz continuity, strong-monotonicity, variational inequalities, monotone operator theory, saddle-point problem","The paper formulates the training of Generative Adversarial Networks (GANs) as a Nash equilibrium seeking problem. To stabilize the training and find a Nash equilibrium, an asymmetric regularization mechanism is proposed, based on the Tikhonov step and a novel zero-centered gradient penalty. Under certain conditions, explicit Lipschitz and strong-monotonicity constants for the regularized operator are obtained, ensuring last-iterate linear convergence of a single-call Extrapolation-from-the-Past (EFTP) method. Empirical simulations demonstrate that this regularization can converge to an equilibrium and stabilize the trajectory, even when strong monotonicity is not achieved.",3.2,87.131,279,cold_start,Phi-4,Apple_M1(Metal)
2601.13938v1_IF-GEO Conflict-Aware Instruction Fusion for Multi.pdf,IF-GEO: Conflict-Aware Instruction Fusion for Multi-Query Generative Engine Optimization,"Heyang Zhou, JiaJia Chen, Xiaolu Chen, Jie Bao, Zhen Chen, Yong Liao",,,"Generative Engines, information retrieval, source visibility, Generative Engine Optimization (GEO), conflict-aware instruction fusion, multi-query benchmarks, cross-query stability","As Generative Engines revolutionize information retrieval by synthesizing direct answers from retrieved sources, ensuring source visibility becomes a significant challenge. Improving it through targeted content revisions is a practical strategy termed Generative Engine Optimization (GEO). However, optimizing a document for diverse queries presents a constrained optimization challenge where heterogeneous queries often impose conflicting and competing revision requirements under a limited content budget. To address this challenge, we propose IF-GEO, a 'diverge-then-converge' framework comprising two phases: (i) mining distinct optimization preferences from representative latent queries; (ii) synthesizing a Global Revision Blueprint for guided editing by coordinating preferences via conflict-aware instruction fusion. To explicitly quantify IF-GEO’s objective of cross-query stability, we introduce risk-aware stability metrics. Experiments on multi-query benchmarks demonstrate that IF-GEO achieves substantial performance gains while maintaining robustness across diverse retrieval scenarios.",3.34,95.949,320,cold_start,Phi-4,Apple_M1(Metal)
2601.13942v1_Glance-or-Gaze Incentivizing LMMs to Adaptively Fo.pdf,Glance-or-Gaze: Incentivizing LMMs to Adaptively Focus Search via Reinforcement Learning,"Hongbo Bai, Yujin Zhou, Yile Wu, Chi-Min Chan, Pengcheng Wen, Kunhao Pan, Sirui Han, Yike Guo",,,"Large Multimodal Models, Visual Question Answering, Reinforcement Learning, Selective Gaze, Search-Augmented Approaches, Knowledge-Intensive Queries, Iterative Reasoning","Large Multimodal Models (LMMs) excel in visual understanding but struggle with knowledge-intensive queries due to static parametric knowledge. This paper introduces Glance-or-Gaze (GoG), a framework that shifts from passive perception to active visual planning. GoG employs a Selective Gaze mechanism to dynamically focus on high-value regions, reducing visual redundancy and noise. A dual-stage training strategy is designed: Reflective GoG Behavior Alignment via supervised fine-tuning instills the GoG paradigm, while Complexity-Adaptive Reinforcement Learning enhances the model's capability to handle complex queries through iterative reasoning. Experiments across six benchmarks demonstrate state-of-the-art performance, with ablation studies confirming the essential role of Selective Gaze and complexity-adaptive RL in effective visual search.",3.25,99.077,322,cold_start,Phi-4,Apple_M1(Metal)
2601.13948v1_Stream-Voice-Anon Enhancing Utility of Real-Time S.pdf,STREAM-VOICE-ANON: ENHANCING UTILITY OF REAL-TIME SPEAKER ANONYMIZATION VIA NEURAL AUDIO CODEC AND LANGUAGE MODELS,"Nikita Kuzmin, Songting Liu, Kong Aik Lee, Eng Siong Chng",,,"streaming speaker anonymization, neural audio codec, voice conversion, privacy preservation, disentanglement","Protecting speaker identity is crucial for online voice applications, yet streaming speaker anonymization (SA) remains underexplored. Recent research has demonstrated that neural audio codec (NAC) provides superior speaker feature disentanglement and linguistic fidelity. NAC can also be used with causal language models (LM) to enhance linguistic fidelity and prompt control for streaming tasks. However, existing NAC-based online LM systems are designed for voice conversion (VC) rather than anonymization, lacking the techniques required for privacy protection. Building on these advances, we present Stream-Voice-Anon, which adapts modern causal LM-based NAC architectures specifically for streaming SA by integrating anonymization techniques. Our anonymization approach incorporates pseudo-speaker representation sampling, a speaker embedding mixing and diverse prompt selection strategies for LM conditioning that leverage the disentanglement properties of quantized content codes to prevent speaker information leakage. Additionally, we compare dynamic and fixed delay configurations to explore latency-privacy trade-offs in real-time scenarios. Under the VoicePrivacy 2024 Challenge protocol, Stream-Voice-Anon achieves substantial improvements in intelligibility (up to 46% relative WER reduction) and emotion preservation (up to 28% UAR relative) compared to the previous state-of-the-art streaming method DarkStream while maintaining comparable latency (180ms vs 200ms) and privacy protection against lazy-informed attackers, though showing 15% relative degradation against semi-informed attackers.",3.53,120.345,425,cold_start,Phi-4,Apple_M1(Metal)
2601.13964v1_RL-BioAug Label-Efficient Reinforcement Learning f.pdf,RL-BioAug: Label-Efficient Reinforcement Learning for Self-Supervised EEG Representation Learning,"Cheol-Hui Lee, Hwa-Yeon Lee, Dong-Joo Kim",,,"Reinforcement Learning, Self-Supervised Learning, EEG, Data Augmentation, Contrastive Learning","The quality of data augmentation is crucial for the performance of contrastive learning in EEG tasks. Static or random augmentation strategies often fail to preserve intrinsic information due to the non-stationarity of EEG signals. RL-BioAug, a framework leveraging a label-efficient reinforcement learning agent, autonomously determines optimal augmentation policies using only 10% of labeled data. This method enables the encoder to learn robust representations in a self-supervised manner. Experimental results show that RL-BioAug significantly outperforms random selection strategies, achieving improvements of 9.69% and 8.80% in Macro-F1 score on the Sleep-EDFX and CHB-MIT datasets, respectively. The agent mainly chose optimal strategies for each task, such as Time Masking for sleep stage classification and Crop & Resize for seizure detection. This framework suggests its potential to replace conventional heuristic-based augmentations and establish a new autonomous paradigm for data augmentation.",3.33,90.466,301,cold_start,Phi-4,Apple_M1(Metal)
2601.13969v1_Autonomous Knowledge Graph Exploration with Adapti.pdf,Autonomous Knowledge Graph Exploration with Adaptive Breadth-Depth Retrieval,"Joaquín Polonuer, Lucas Vittor, Iñaki Arango, Ayush Noori, David A. Clifton, Luciano Del Corro, Marinka Zitnik",,,"knowledge graphs, language models, retrieval, breadth-depth tradeoff, multi-hop traversal, global lexical search, neighborhood exploration","Retrieving evidence for language model queries from knowledge graphs requires balancing broad search across the graph with multi-hop traversal to follow relational links. Similarity-based retrievers provide coverage but remain shallow, whereas traversal-based methods rely on selecting seed nodes to start exploration, which can fail when queries span multiple entities and relations. We introduce ARK: ADAPTIVE RETRIEVER OF KNOWLEDGE, an agent-based KG retriever that gives a language model control over this breadth-depth tradeoff using a two-operation toolset: global lexical search over node descriptors and one-hop neighborhood exploration that composes into multi-hop traversal. ARK alternates between breadth-oriented discovery and depth-oriented expansion without depending on a fragile seed selection, a pre-set hop depth, or requiring retrieval training. ARK adapts tool use to queries, using global search for language-heavy queries and neighborhood exploration for relation-heavy queries. On STaRK, ARK reaches 59.1% average Hit@1 and 67.4 average MRR, improving average Hit@1 by up to 31.4% and average MRR by up to 28.0% over retrieval-based and agentic training-free methods. Finally, we distill ARK’s tool-use trajectories from a large teacher into an 8B model via label-free imitation, improving Hit@1 by +7.0, +26.6, and +13.5 absolute points over the base 8B model on AMAZON, MAG, and PRIME datasets, respectively, while retaining up to 98.5% of the teacher’s Hit@1 rate.",3.44,137.737,474,cold_start,Phi-4,Apple_M1(Metal)
2601.13992v1_The Whole Is Greater Than the Sum of Its Parts A C.pdf,The Whole Is Greater Than the Sum of Its Parts: A Compatibility-Aware Multi-Teacher CoT Distillation Framework,"Jin Cui, Jiaqi Guo, Jiepeng Zhou, Ruixuan Yang, Jiayi Lu, Jiajun Xu, Jiangcheng Song, Boran Zhao, Pengju Ren",,,"Chain-of-Thought reasoning, Large Language Models, CoT distillation, student models, teacher models, compatibility, multi-teacher framework, gradient weighting, catastrophic forgetting","Chain-of-Thought (CoT) reasoning enhances Large Language Models (LLMs) with significant capabilities, but requires large parameter scales. CoT distillation transfers these capabilities to compact student models (SLMs) using teacher rationales. However, existing methods often rely on a single teacher, limiting the student's potential due to capability biases and catastrophic forgetting. This paper introduces COMPACT, a framework that adaptively fuses supervisions from multiple teachers by dynamically weighting teacher gradients based on student compatibility. This is evaluated using a multi-dimensional metric: Graph-based Consensus, Mutual-Information-based Adaptability, and Loss-based Difficulty. Experiments show that COMPACT effectively integrates diverse reasoning capabilities without harming the model's original knowledge structure, achieving state-of-the-art performance and mitigating catastrophic forgetting.",3.34,101.625,339,cold_start,Phi-4,Apple_M1(Metal)
2601.13994v1_torch-sla Differentiable Sparse Linear Algebra wit.pdf,torch-sla: Differentiable Sparse Linear Algebra with Adjoint Solvers and Sparse Tensor Parallelism for PyTorch,Mingyuan Chi,,2601.13994v1,"sparse linear algebra, GPU acceleration, multi-GPU scaling, adjoint-based differentiation, PyTorch, sparse matrices, differentiable programming","Industrial scientific computing predominantly uses sparse matrices to represent unstructured data—finite element meshes, graphs, point clouds. This paper introduces torch-sla, an open-source PyTorch library that enables GPU-accelerated, scalable, and differentiable sparse linear algebra. The library addresses three fundamental challenges: (1) GPU acceleration for sparse linear solves, nonlinear solves (Newton, Picard, Anderson), and eigenvalue computation; (2) Multi-GPU scaling via domain decomposition with halo exchange, reaching 400 million DOF linear solve on 3 GPUs; and (3) Adjoint-based differentiation achieving O(1) computational graph nodes (for autograd) and O(nnz) memory—independent of solver iterations. torch-sla supports multiple backends (SciPy, cuDSS, PyTorch-native) and seamlessly integrates with PyTorch autograd for end-to-end differentiable simulations.",3.24,88.975,288,cold_start,Phi-4,Apple_M1(Metal)
2601.13999v1_DAME Duration-Aware Matryoshka Embedding for Durat.pdf,DURATION-AWARE MATRYOSHKA EMBEDDING FOR DURATION-ROBUST SPEAKER VERIFICATION,"Youngmoon Jung, Joon-Young Yang, Ju-ho Kim, Jaeyoung Roh, Chang Woo Han, Hoon-Young Cho",,,"Short-duration speaker verification, multi-scale aggregation, matryoshka representation learning","Short-utterance speaker verification remains challenging due to limited speaker-discriminative cues in short speech segments. Existing methods focus on enhancing speaker encoders, but the embedding learning strategy forces a single fixed-dimensional representation reused for utterances of any length, leaving capacity misaligned with the information available at different durations. This paper proposes Duration-Aware Matryoshka Embedding (DAME), a model-agnostic framework that builds a nested hierarchy of sub-embeddings aligned to utterance durations. Lower-dimensional representations capture compact speaker traits from short utterances, while higher dimensions encode richer details from longer speech. DAME supports both training from scratch and fine-tuning, consistently improving performance across durations. On the VoxCeleb1-O/E/H and VOiCES evaluation sets, DAME reduces the equal error rate on 1-s and other short-duration trials, while maintaining full-length performance with no additional inference cost. These gains generalize across various speaker encoder architectures under both general training and fine-tuning setups.",3.4,96.805,329,cold_start,Phi-4,Apple_M1(Metal)
2601.14012v1_MATE Matryoshka Audio-Text Embeddings for Open-Voc.pdf,MATE: MATRYOSHKA AUDIO–TEXT EMBEDDINGS FOR OPEN-VOCABULARY KEYWORD SPOTTING,"Youngmoon Jung, Myunghun Jung, Joon-Young Yang, Yong-Hyeok Lee, Jaeyoung Roh, Hoon-Young Cho",,,"Keyword spotting, open-vocabulary, text enrollment, audio–text embedding, deep metric learning","Open-vocabulary keyword spotting (KWS) with text-based enrollment has emerged as a flexible alternative to fixed-phrase triggers. Prior methods learn embeddings at a single fixed dimensionality. This work introduces Matryoshka Audio–Text Embeddings (MATE), a dual-encoder framework that encodes multiple embedding granularities within a single vector via nested sub-embeddings (prefixes). PCA-guided prefix alignment is used to align audio and text prefixes, concentrating salient keyword cues in lower-dimensional prefixes while higher dimensions add detail. MATE is trained with standard deep metric learning objectives for audio–text KWS and achieves state-of-the-art results on WSJ and LibriPhrase without inference overhead.",3.04,85.269,259,cold_start,Phi-4,Apple_M1(Metal)
2601.14022v1_Credible CO2 Comparisons A Machine Learning Approa.pdf,Credible CO2 Comparisons: A Machine Learning Approach to Vehicle Powertrain Assessment,"Rodrigo Pereira David, Luciano Araujo Dourado Filho, Daniel Marques da Silva, João Alfredo Cal-Braz",xxx/xxxx,,"machine learning, vehicle emissions, electric vehicles","Decarbonizing road transport requires consistent and transparent methods for comparing CO2 emissions across vehicle technologies. This paper proposes a machine learning–based framework for like-for-like operational assessment of internal combustion engine vehicles (ICEVs) and electric vehicles (EVs) under identical, real-world driving conditions. The approach isolates technology-specific effects by holding the observed speed profile and environmental context fixed, enabling direct comparison of powertrain performance. Recurrent neural network models are trained independently for each domain to learn the mapping from contextual driving variables (speed, acceleration, temperature) to internal actuation variables (torque, throttle) and instantaneous CO2-equivalent emission rates. This structure allows the construction of counterfactual scenarios that answer: 'What emissions would an EV have generated if it had followed the same driving profile as an ICEV?' By aligning both vehicle types on a unified instantaneous emissions metric, the framework enables fair and reproducible evaluation of powertrain technologies. It offers a scalable foundation for credible, data-driven assessments of vehicle carbon performance under real-world operating conditions.",3.44,94.683,326,cold_start,Phi-4,Apple_M1(Metal)
2601.14027v1_Numina-Lean-Agent An Open and General Agentic Reas.pdf,Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics,"Junqi Liu, Zihao Zhou, Zekai Zhu, Marco Dos Santos, Weikun He, Jiawei Liu, Ran Wang, Yunzhou Xie, Junqiao Zhao, Qiufeng Wang, Lihong Zhi, Jia Li, Wenda Li",,,"agentic systems, formal theorem proving, general coding agent, Numina-Lean-Agent, Lean, Claude Code, Numina-Lean-MCP, Brascamp–Lieb theorem","Agentic systems have recently become the dominant paradigm for formal theorem proving, achieving strong performance by coordinating multiple models and tools. However, existing approaches often rely on task-specific pipelines and trained formal provers, limiting their flexibility and reproducibility. In this paper, we propose the paradigm that directly uses a general coding agent as a formal math reasoner. This paradigm is motivated by (1) A general coding agent provides a natural interface for diverse reasoning tasks beyond proving, (2) Performance can be improved by simply replacing the underlying base model, without training, and (3) MCP enables flexible extension and autonomous calling of specialized tools, avoiding complex design. Based on this paradigm, we introduce Numina-Lean-Agent, which combines Claude Code with Numina-Lean-MCP to enable autonomous interaction with Lean, retrieval of relevant theorems, informal proving and auxiliary reasoning tools. Using Claude Opus 4.5 as the base model, Numina-Lean-Agent solves all problems in Putnam 2025 (12/12), matching the best closed-source system. Beyond benchmark evaluation, we further demonstrate its generality by interacting with mathematicians to successfully formalize the Brascamp–Lieb theorem. We release Numina-Lean-Agent and all solutions at https://github.com/project-numina/numina-lean-agent.",3.67,127.584,468,cold_start,Phi-4,Apple_M1(Metal)
2601.14039v1_Generalizing Abstention for Noise-Robust Learning .pdf,Generalizing Abstention for Noise-Robust Learning in Medical Image Segmentation,"Wesam Moustafa, Hossam Elsafty, Helen Schneider, Lorenz Sparrenberg, Rafet Sifa",,2601.14039v1,"Abstention, Medical Image Segmentation, Label Noise, Noise-Robust Learning, Loss Functions","Label noise is a critical problem in medical image segmentation, often arising from the inherent difficulty of manual annotation. Models trained on noisy data are prone to overfitting, which degrades their generalization performance. While a number of methods and strategies have been proposed to mitigate noisy labels in the segmentation domain, this area remains largely under-explored. The abstention mechanism has proven effective in classification tasks by enhancing the capabilities of Cross Entropy, yet its potential in segmentation remains unverified. In this paper, we address this gap by introducing a universal and modular abstention framework capable of enhancing the noise-robustness of a diverse range of loss functions. Our framework improves upon prior work with two key components: an informed regularization term to guide abstention behaviour, and a more flexible power-law-based auto-tuning algorithm for the abstention penalty. We demonstrate the framework’s versatility by systematically integrating it with three distinct loss functions to create three novel, noise-robust variants: GAC, SAC, and ADS. Experiments on the CaDIS and DSAD medical datasets show our methods consistently and significantly outperform their non-abstaining baselines, especially under high noise levels. This work establishes that enabling models to selectively ignore corrupted samples is a powerful and generalizable strategy for building more reliable segmentation models.",3.54,111.53,395,cold_start,Phi-4,Apple_M1(Metal)
2601.14041v1_Top 10 Open Challenges Steering the Future of Diff.pdf,Top 10 Open Challenges Steering the Future of Diffusion Language Model and Its Variants,"Yunhe Wang, Kai Han, Huiling Zhen, Yuchuan Tian, Hanting Chen, Yongbing Huang, Yufei Cui, Yingte Shu, Shan Gao, Ismail Elezi, Roy Vaughan Miles, Songcen Xu, Feng Wen, Chao Xu, Sinan Zeng, Dacheng Tao",,arXiv:2601.14041v1,"Large Language Models, Diffusion Models, Transformers","The paradigm of Large Language Models (LLMs) is currently defined by auto-regressive (AR) architectures, which generate text through a sequential 'brick-by-brick' process. Despite their success, AR models are inherently constrained by a causal bottleneck that limits global structural foresight and iterative refinement. Diffusion Language Models (DLMs) offer a transformative alternative, conceptualizing text generation as a holistic, bidirectional denoising process akin to a sculptor refining a masterpiece. However, the potential of DLMs remains largely untapped as they are frequently confined within AR-legacy infrastructures and optimization frameworks. In this Perspective, we identify ten fundamental challenges ranging from architectural inertia and gradient sparsity to the limitations of linear reasoning that prevent DLMs from reaching their 'GPT-4 moment'. We propose a strategic roadmap organized into four pillars: foundational infrastructure, algorithmic optimization, cognitive reasoning, and unified multimodal intelligence. By shifting toward a diffusion-native ecosystem characterized by multi-scale tokenization, active remasking, and latent thinking, we can move beyond the constraints of the causal horizon. We argue that this transition is essential for developing next-generation AI capable of complex structural reasoning, dynamic self-correction, and seamless multimodal integration.",3.92,113.133,444,cold_start,Phi-4,Apple_M1(Metal)
2601.14047v1_Collective intelligence in science direct elicitat.pdf,COLLECTIVE INTELLIGENCE IN SCIENCE: DIRECT ELICITATION OF DIVERSE INFORMATION FROM EXPERTS WITH UNKNOWN INFORMATION STRUCTURE,"ALEXEY V. OSIPOV, NIKOLAY N. OSIPOV",,arXiv:2601.14047v1,"interpretability, wisdom of crowd, play money, prediction market, information pooling, information elicitation, rational expectation equilibrium, direct communication, large language models, scientific collaboration","Suppose we need a deep collective analysis of an open scientific problem: there is a complex scientific hypothesis and a large online group of mutually unrelated experts with relevant private information of a diverse and unpredictable nature. This information may be results of experts’ individual experiments, original reasoning of some of them, results of AI systems they use, etc. We propose a simple mechanism based on a self-resolving play-money prediction market entangled with a chat. We show that such a system can easily be brought to an equilibrium where participants directly share their private information on the hypothesis through the chat and trade as if the market were resolved in accordance with the truth of the hypothesis. This approach will lead to efficient aggregation of relevant information in a completely interpretable form even if the ground truth cannot be established and experts initially know nothing about each other and cannot perform complex Bayesian calculations. Finally, by rewarding the experts with some real assets proportionally to the play money they end up with, we can get an innovative way to fund large-scale collaborative studies of any type.",3.49,105.07,367,cold_start,Phi-4,Apple_M1(Metal)
2601.14051v1_Kakugo Distillation of Low-Resource Languages into.pdf,Kakugo: Distillation of Low-Resource Languages into Small Language Models,"Peter Devine, Mardhiyah Sanni, Farid Adilazuarda, Julieta Gil Loizaga, Barry Haddow",,,"Small Language Models, Low-Resource Languages, Model Distillation, Synthetic Data, Natural Language Processing","We present Kakugo, a novel and cost-effective pipeline designed to train general-purpose Small Language Models (SLMs) for low-resource languages using only the language name as input. By using a large teacher model to generate synthetic prompts and translate instruction datasets, we produced training data and SLMs for 54 low-resource languages. Evaluations across a diverse set of general natural language processing tasks, including translation, classification, and question answering, demonstrate that our pipeline consistently improves performance over base models. With a total generation and training cost of under $50 per language, Kakugo offers an accessible method for communities to develop language-specific AI.",2.91,79.407,231,cold_start,Phi-4,Apple_M1(Metal)
2601.14053v1_LLMOrbit A Circular Taxonomy of Large Language Mod.pdf,LLMOrbit: A Circular Taxonomy of Large Language Models — From Scaling Walls to Agentic AI Systems,"Badri N. Patro, Vijay S. Agneeswaran",,arXiv:2601.14053v1,"artificial intelligence, large language models, generative AI, agentic systems, scaling wall, taxonomy, training methodologies, efficiency patterns","The field of artificial intelligence has undergone a revolution from foundational Transformer architectures to reasoning-capable systems approaching human-level performance on certain specific tasks. This paper presents LLMOrbit, a comprehensive circular taxonomy navigating the complete landscape of large language models spanning 2019-2025. It examines over 50 major models across 15 organizations through eight interconnected orbital dimensions, documenting the architectural innovations, training methodologies, and efficiency patterns defining modern large language models (LLMs), generative AI, and agentic systems. The paper identifies three critical crises threatening AI progress: data scarcity, exponential cost growth, and unsustainable energy consumption, collectively establishing the 'scaling wall' that limits brute-force scaling. It explores six paradigms to break the scaling wall, including test-time compute, quantization, distributed edge computing, model merging, efficient training, and small specialized models. Three fundamental paradigm shifts are highlighted: post-training gains, efficiency revolution, and democratization. The paper provides insights into key techniques and analyzes post-training innovations, offering a technical reference and roadmap for researchers exploring reasoning, multimodal understanding, and autonomous agents in the post-scaling era.",3.34,104.439,349,cold_start,Phi-4,Apple_M1(Metal)
2601.14055v1_Decoder-Free Supervoxel GNN for Accurate Brain-Tum.pdf,Decoder-Free Supervoxel GNN for Accurate Brain-Tumor Localization in Multi-Modal MRI,"Andrea Protani, Marc Molina Van Den Bosch, Lorenzo Giusti, Heloisa Barbosa Da Silva, Paolo Cacace, Albert Sund Aillet, Miguel Angel Gonzalez Ballester, Friedhelm Hummel, Luigi Serio",,arXiv:2601.14055v1,"Brain Tumor Localization, Graph Neural Networks, Multi-modal MRI, Supervoxel, Regression","Modern vision backbones for 3D medical imaging typically process dense voxel grids through parameter-heavy encoder-decoder structures, allocating a significant portion of parameters to spatial reconstruction rather than feature learning. This paper introduces SVGFormer, a decoder-free pipeline built upon a content-aware grouping stage that partitions the volume into a semantic graph of super-voxels. Its hierarchical encoder learns rich node representations by combining a patch-level Transformer with a supervoxel-level Graph Attention Network, jointly modeling fine-grained intra-region features and broader inter-regional dependencies. This design concentrates all learnable capacity on feature encoding and provides inherent, dual-scale explainability from the patch to the region level. To validate the framework’s flexibility, two specialized models were trained on the BraTS dataset: one for node-level classification and one for tumor proportion regression. Both models achieved strong performance, with the classification model achieving an F1-score of 0.875 and the regression model a MAE of 0.028, confirming the encoder’s ability to learn discriminative and localized features. The results establish that a graph-based, encoder-only paradigm offers an accurate and inherently interpretable alternative for 3D medical image representation.",3.73,109.304,408,cold_start,Phi-4,Apple_M1(Metal)
2601.14056v1_POCI-Diff Position Objects Consistently and Intera.pdf,POCI-Diff: Position Objects Consistently and Interactively with 3D-Layout Guided Diffusion,"Andrea Rigo, Luca Stornaiuolo, Weijie Wang, Mauro Martino, Bruno Lepri, Nicu Sebe",,arXiv:2601.14056v1,"Diffusion, Image Generation, 3D Layout","We propose a diffusion-based approach for Text-to-Image (T2I) generation with consistent and interactive 3D layout control and editing. While prior methods improve spatial adherence using 2D cues or iterative copy-warp-paste strategies, they often distort object geometry and fail to preserve consistency across edits. To address these limitations, we introduce a framework for Positioning Objects Consistently and Interactively (POCI-Diff), a novel formulation for jointly enforcing 3D geometric constraints and instance-level semantic binding within a unified diffusion process. Our method enables explicit per-object semantic control by binding individual text descriptions to specific 3D bounding boxes through Blended Latent Diffusion, allowing one-shot synthesis of complex multi-object scenes. We further propose a warping-free generative editing pipeline that supports object insertion, removal, and transformation via regeneration rather than pixel deformation. To preserve object identity and consistency across edits, we condition the diffusion process on reference images using IP-Adapter, enabling coherent object appearance throughout interactive 3D editing while maintaining global scene coherence. Experimental results demonstrate that POCI-Diff produces high-quality images consistent with the specified 3D layouts and edits, outperforming state-of-the-art methods in both visual fidelity and layout adherence while eliminating warping-induced geometric artifacts.",3.71,106.321,394,cold_start,Phi-4,Apple_M1(Metal)
2601.14063v1_XCR-Bench A Multi-Task Benchmark for Evaluating Cu.pdf,XCR-Bench: A Multi-Task Benchmark for Evaluating Cultural Reasoning in LLMs,"Mohsinul Kabir, Tasnim Ahmed, Md Mezbaur Rahman, Shaoxiong Ji, Hassan Alhuzali, Sophia Ananiadou",,,"Cross-Cultural Reasoning, Large Language Models, Culture-Specific Items, Cultural Bias, Benchmark","Cross-cultural competence in large language models (LLMs) requires the ability to identify Culture-Specific Items (CSIs) and adapt them appropriately across cultural contexts. The scarcity of high-quality CSI-annotated corpora with parallel cross-cultural sentence pairs has constrained progress in evaluating this capability. To address this limitation, the authors introduce XCR-Bench, a Cross-Cultural Reasoning Benchmark consisting of 4.9k parallel sentences and 1,098 unique CSIs, spanning three distinct reasoning tasks with corresponding evaluation metrics. The corpus integrates Newmark’s CSI framework with Hall’s Triad of Culture, enabling systematic analysis of cultural reasoning beyond surface-level artifacts into semi-visible and invisible cultural elements such as social norms, beliefs, and values. Findings indicate that state-of-the-art LLMs exhibit consistent weaknesses in identifying and adapting CSIs related to social etiquette and cultural reference, and encode regional and ethno-religious biases even within a single linguistic setting during cultural adaptation. The corpus and code are released to facilitate future research on cross-cultural NLP.",3.3,99.408,328,cold_start,Phi-4,Apple_M1(Metal)
2601.14069v1_Unsupervised Video Class-Incremental Learning via .pdf,Unsupervised Video Class-Incremental Learning via Deep Embedded Clustering Management,"Nattapong Kurpukdee, Adrian G. Bors",,,"Unsupervised, Video Class-Incremental, Video Continual Learning, Deep Embedded Clustering","Unsupervised video class incremental learning (uVCIL) is a learning paradigm for acquiring video information without forgetting and without relying on data labels. Prior approaches have focused on supervised class-incremental learning, which requires labels and task boundaries, often necessitating costly human annotation. This paper proposes a novel approach to uVCIL using a deep feature extractor network to provide representative video features without assuming class or task information. The method involves progressively building deep clusters from extracted features and using the model from the previous task as an initial state to transfer knowledge to the current task. The approach is evaluated on three standard video action recognition datasets (UCF101, HMDB51, and Something-to-Something V2) without using labels, significantly outperforming other baselines. The paper addresses the challenge of catastrophic forgetting in continual learning applications such as environmental monitoring, robot behavior, health tracking, and CCTV surveillance.",3.28,86.088,282,cold_start,Phi-4,Apple_M1(Metal)
2601.14084v1_DermaBench A Clinician-Annotated Benchmark Dataset.pdf,DermaBench: A Clinician-Annotated Benchmark Dataset for Dermatology Visual Question Answering and Reasoning,"Abdurrahim Yilmaz, Ozan Erdem, Ece Gokyayla, Ayda Acar, Burc Bugra Dagtas, Dilara Ilhan Erdil, Gulsum Gencoglan, Burak Temelkuran",,,"dermatology, visual question answering, vision-language models, multimodal learning, teledermatology, AI in medicine","Vision–language models (VLMs) are increasingly important in medical applications; however, their evaluation in dermatology remains limited by datasets that focus primarily on image-level classification tasks such as lesion recognition. While valuable for recognition, such datasets cannot assess the full visual understanding, language grounding, and clinical reasoning capabilities of multimodal models. Visual question answering (VQA) benchmarks are required to evaluate how models interpret dermatological images, reason over fine-grained morphology, and generate clinically meaningful descriptions. We introduce DermaBench, a clinician-annotated dermatology VQA benchmark built on the Diverse Dermatology Images (DDI) dataset. DermaBench comprises 656 clinical images from 570 unique patients spanning Fitzpatrick skin types I–VI. Using a hierarchical annotation schema with 22 main questions (single-choice, multi-choice, and open-ended), expert dermatologists annotated each image for diagnosis, anatomic site, lesion morphology, distribution, surface features, color, and image quality, together with open-ended narrative descriptions and summaries, yielding approximately 14,474 VQA-style annotations. DermaBench is released as a metadata-only dataset to respect upstream licensing and is publicly available at Harvard Dataverse.",3.55,116.831,415,cold_start,Phi-4,Apple_M1(Metal)
2601.14086v1_Two-Stream temporal transformer for video action c.pdf,TWO-STREAM TEMPORAL TRANSFORMER FOR VIDEO ACTION CLASSIFICATION,"Nattapong Kurpukdee, Adrian G. Bors",,,"Video Transformer, Optical Flow, Two-Stream video processing, Video Action Classification","This study introduces a two-stream transformer video classifier that extracts spatio-temporal information from content and optical flow to represent movement information. The model identifies self-attention features across the joint optical flow and temporal frame domain, representing their relationships within the transformer encoder mechanism. Experimental results demonstrate excellent classification performance on three well-known video datasets of human activities. The research highlights the efficiency of transformers in video action recognition, addressing challenges posed by video capturing conditions and the need for additional training resources. The proposed transformer-based architecture fuses scene and movement features through a self-attention mechanism, showing the capability to model video features efficiently.",3.06,72.118,221,cold_start,Phi-4,Apple_M1(Metal)
2601.14087v1_1-bit Count-based Sorting Unit to Reduce Link Powe.pdf,1-bit Count-based Sorting Unit to Reduce Link Power in DNN Accelerators,"Ruichi Han, Yizhi Chen, Tong Lei, Jordi Altayo Gonzalez, Ahmed Hemani",,,"1-bit count-based sorting, Approximate computing, Bit transition reduction, Link power","Interconnect power consumption is a bottleneck in Deep Neural Network (DNN) accelerators. This work proposes a hardware implementation of a comparison-free sorting unit optimized for Convolutional Neural Networks (CNN). By leveraging approximate computing to group population counts into coarse-grained buckets, the design achieves hardware area reductions while preserving link power benefits of data reordering. The approximate sorting unit achieves up to 35.4% area reduction while maintaining 19.50% bit transition reduction compared to 20.42% of precise implementation. This is the first hardware implementation of a popcount sorting unit for DNNs with approximate sorting, providing a comprehensive power analysis and evaluating the design under convolution and pooling workloads.",3.07,75.826,233,cold_start,Phi-4,Apple_M1(Metal)
2601.14091v1_Zero-shot adaptable task planning for autonomous c.pdf,Zero-shot adaptable task planning for autonomous construction robots: a comparative study of lightweight single and multi-AI agent systems,"Hossein Naderi, Alireza Shojaei, Lifu Huang, Philip Agee, Kereshmeh Afsari, Abiola Akanmu",,,"Construction robotics, quadruped robots, robot task planning, multi-AI agent, LLMs, VLMs, GPT4o","Robots are expected to play a major role in the future construction industry but face challenges due to high costs and difficulty adapting to dynamic tasks. This study explores the potential of foundation models to enhance the adaptability and generalizability of task planning in construction robots. Four models are proposed and implemented using lightweight, open-source large language models (LLMs) and vision language models (VLMs). These models include one single agent and three multi-agent teams that collaborate to create robot action plans. The models are evaluated across three construction roles: Painter, Safety Inspector, and Floor Tiling. Results show that the four-agent team outperforms the state-of-the-art GPT-4o in most metrics while being ten times more cost-effective. Additionally, teams with three and four agents demonstrate improved generalizability. By discussing how agent behaviors influence outputs, this study enhances the understanding of AI teams and supports future research in diverse unstructured environments beyond construction.",3.52,97.824,344,cold_start,Phi-4,Apple_M1(Metal)
2601.14096v1_Remapping and navigation of an embedding space via.pdf,Remapping and navigation of an embedding space via error minimization: a fundamental organizational principle of cognition in natural and artificial systems,"Benedikt Hartl, Léo Pio-Lopez, Chris Fields, Michael Levin",,2601.14096v1,"Evolution, Development, Intelligence, Active Inference, Navigation Policy, Nested Embedding Spaces",,3.51,30.489,107,cold_start,Phi-4,Apple_M1(Metal)
2601.14099v1_Causal feature selection framework for stable soft.pdf,Causal Feature Selection Framework for Stable Soft Sensor Modeling based on Time-Delayed Cross Mapping,"Shi-Shun Chen, Xiao-Yang Li, Enrico Zio",,,,,3.08,21.129,65,cold_start,Phi-4,Apple_M1(Metal)
2601.14115v1_Riemannian Liquid Spatio-Temporal Graph Network.pdf,Riemannian Liquid Spatio-Temporal Graph Network,"Liangsi Lu, Jingchao Wang, Zhaorong Dai, Hanqian Liu, Yang Shi",10.1145/3774904.3792090,,"Riemannian Manifolds, Neural ODEs, Spatio-Temporal Graphs","Liquid Time-Constant networks (LTCs), a type of continuous-time graph neural network, excel at modeling irregularly-sampled dynamics but are fundamentally confined to Euclidean space. This limitation introduces significant geometric distortion when representing real-world graphs with inherent non-Euclidean structures (e.g., hierarchies and cycles), degrading representation quality. To overcome this limitation, we introduce the Riemannian Liquid Spatio-Temporal Graph Network (RLSTG), a framework that unifies continuous-time liquid dynamics with the geometric inductive biases of Riemannian manifolds. RLSTG models graph evolution through an Ordinary Differential Equation (ODE) formulated directly on a curved manifold, enabling it to faithfully capture the intrinsic geometry of both structurally static and dynamic spatio-temporal graphs. Moreover, we provide rigorous theoretical guarantees for RLSTG, extending stability theorems of LTCs to the Riemannian domain and quantifying its expressive power via state trajectory analysis. Extensive experiments on real-world benchmarks demonstrate that, by combining advanced temporal dynamics with a Riemannian spatial representation, RLSTG achieves superior performance on graphs with complex structures.",3.33,108.779,362,cold_start,Phi-4,Apple_M1(Metal)
2601.14124v1_Style Transfer as Bias Mitigation Diffusion Models.pdf,Style Transfer as Bias Mitigation: Diffusion Models for Synthetic Mental Health Text for Arabic,"Saad Mankarious, Ayah Zirikly",,arXiv:2601.14124v1,"style transfer, bias mitigation, diffusion models, synthetic text generation, mental health, Arabic, gender bias","Synthetic data offers a promising solution for mitigating data scarcity and demographic bias in mental health analysis, yet existing approaches largely rely on pretrained large language models (LLMs), which may suffer from limited output diversity and propagate biases inherited from their training data. This work proposes a pretraining-free diffusion-based approach for synthetic text generation that frames bias mitigation as a style transfer problem. Using the CARMA Arabic mental health corpus, which exhibits a substantial gender imbalance, the focus is on male-to-female style transfer to augment underrepresented female-authored content. Five datasets capturing varying linguistic and semantic aspects of gender expression in Arabic are constructed, and separate diffusion models are trained for each setting. Quantitative evaluations demonstrate high semantic fidelity between source and generated text, alongside meaningful surface-level stylistic divergence, while qualitative analysis confirms linguistically plausible gender transformations. The results show that diffusion-based style transfer can generate high-entropy, semantically faithful synthetic data without reliance on pretrained LLMs, providing an effective and flexible framework for mitigating gender bias in sensitive, low-resource mental health domains.",3.44,93.006,320,cold_start,Phi-4,Apple_M1(Metal)
2601.14152v1_Lost in the Prompt Order Revealing the Limitations.pdf,Revealing the Limitations of Causal Attention in Language Models,"Hyunjong Ok, Jaeho Lee",,,"language models, causal attention, prompt sensitivity, multiple-choice question answering, LLMs","Large language models exhibit surprising sensitivity to the structure of the prompt, but the mechanisms underlying this sensitivity remain poorly understood. This work investigates the impact of prompt order in multiple-choice question answering, finding that placing context before questions and options (CQO) outperforms the reverse order (QOC) by over 14% across various models and datasets. The study identifies causal attention as the core mechanism, where the causal mask in QOC prompts prevents option tokens from attending to context, creating an information bottleneck. The research provides insights into the practical reliability of LLMs and the importance of prompt structure.",2.84,71.248,202,cold_start,Phi-4,Apple_M1(Metal)
2601.14154v1_LLM Augmented Intervenable Multimodal Adaptor for .pdf,LLM Augmented Intervenable Multimodal Adaptor for Post-operative Complication Prediction in Lung Cancer Surgery,"Shubham Pandey, Bhavin Jawade, Srirangaraj Setlur, Venu Govindaraju, Kenneth Seastedt",,,"postoperative complications, lung cancer surgery, deep learning, multimodal data, radiomics, clinical prediction, intervenable machine learning","Postoperative complications are a significant concern in clinical practice, impacting patient outcomes and increasing healthcare costs. This paper introduces MIRACLE, a deep learning architecture designed to predict the risk of postoperative complications in lung cancer surgery by integrating preoperative clinical and radiological data. MIRACLE utilizes a hyperspherical embedding space to fuse heterogeneous inputs, extracting robust features from both structured clinical records and high-dimensional radiological images. An interventional deep learning module enhances prediction transparency and clinical utility, providing interpretable insights for domain experts to adjust recommendations. The approach is validated on a real-world dataset of 3,094 lung cancer patients, demonstrating superior performance over traditional machine learning models and large language models for personalized and explainable postoperative risk management. The codebase is available at https://github.com/KNITPhoenix/MIRACLE.",3.33,93.332,311,cold_start,Phi-4,Apple_M1(Metal)
2601.14157v1_ConceptCaps -- a Distilled Concept Dataset for Int.pdf,ConceptCaps - a Distilled Concept Dataset for Interpretability in Music Models,"Bruno Sienkiewicz, Łukasz Neumann, Mateusz Modrzejewski",,,"concept-based interpretability, music models, TCA V, Variational Autoencoder, language model, music-caption-audio triplets, semantic modeling, text generation, MusicGen, audio-text alignment, linguistic quality metrics","Concept-based interpretability methods like TCA V require clean, well-separated positive and negative examples for each concept. Existing music datasets lack this structure: tags are sparse, noisy, or ill-defined. We introduce ConceptCaps, a dataset of 23k music-caption-audio triplets with explicit labels from a 200-attribute taxonomy. Our pipeline separates semantic modeling from text generation: a VAE learns plausible attribute co-occurrence patterns, a fine-tuned LLM converts attribute lists into professional descriptions, and MusicGen synthesizes corresponding audio. This separation improves coherence and controllability over end-to-end approaches. We validate the dataset through audio-text alignment (CLAP), linguistic quality metrics (BERTScore, MAUVE), and TCA V analysis confirming that concept probes recover musically meaningful patterns. Dataset and code are available online.",3.36,94.525,318,cold_start,Phi-4,Apple_M1(Metal)
2601.14160v1_Domain-Adaptation through Synthetic Data Fine-Tuni.pdf,Domain-Adaptation through Synthetic Data: Fine-Tuning Large Language Models for German Law,"Ali Hamza Bashir, Muhammad Rehan Khalid, Kostadin Cvejoski, Jana Birr, Jule Berghaus, Armin Berger, Sandra Halscheidt, Christian Temath, Rafet Sifa, David Berghaus",,,"Large Language Models, German Law, Legal Question Answering, Synthetic Data, Domain Adaptation","Large language models (LLMs) often struggle in specialized domains such as legal reasoning due to limited expert knowledge, resulting in factually incorrect outputs or hallucinations. This paper presents an effective method for adapting advanced LLMs to German legal question answering through a novel synthetic data generation approach. In contrast to costly human-annotated resources or unreliable synthetic alternatives, our approach systematically produces high-quality, diverse, and legally accurate question-answer pairs directly from authoritative German statutes. Using rigorous automated filtering methods and parameter-efficient fine-tuning techniques, we demonstrate that LLMs adapted with our synthetic dataset significantly outperform their baseline counterparts on German legal question answering tasks. Our results highlight the feasibility of using carefully designed synthetic data as a robust alternative to manual annotation in high-stakes, knowledge-intensive domains.",3.33,96.455,321,cold_start,Phi-4,Apple_M1(Metal)
2601.14171v1_Paper2Rebuttal A Multi-Agent Framework for Transpa.pdf,Paper2Rebuttal: A Multi-Agent Framework for Transparent Author Response Assistance,"Qianli Ma, Chang Guo, Zhiheng Tian, Siyu Wang, Jipeng Xiao, Yuanhao Yue, Zhipeng Zhang",,,"rebuttal generation, multi-agent framework, evidence-centric planning, peer review process, REBUTTALAGENT, REBUTTALBENCH","Writing effective rebuttals in peer review is a complex task that requires more than linguistic fluency; it demands precise alignment between reviewer intent and manuscript details. Current solutions often treat this as a direct-to-text generation problem, leading to issues like hallucination, overlooked critiques, and lack of verifiable grounding. This paper introduces REBUTTALAGENT, a multi-agent framework that reframes rebuttal generation as an evidence-centric planning task. The system decomposes feedback into atomic concerns, constructs hybrid contexts, and integrates an external search module for resolving concerns requiring outside literature. By generating an inspectable response plan before drafting, REBUTTALAGENT ensures every argument is explicitly anchored in evidence. The approach is validated on REBUTTALBENCH, demonstrating superior performance in coverage, faithfulness, and strategic coherence compared to strong baselines. The system offers a transparent and controllable assistant for the peer review process.",3.23,103.567,335,cold_start,Phi-4,Apple_M1(Metal)
2601.14172v1_Human Values in a Single Sentence Moral Presence H.pdf,"Human Values in a Single Sentence: Moral Presence, Hierarchies, and Transformer Ensembles on the Schwartz Continuum","Víctor Yeste, Paolo Rosso",,2601.14172v1,"sentence-level identification, Schwartz motivational continuum, human value detection, moral presence, hierarchies, transformer ensembles, DeBERTa-base, instruction-tuned LLMs, ensemble methods","This study investigates sentence-level identification of the 19 values in the Schwartz motivational continuum, focusing on out-of-context sentences from news and political manifestos. The task is challenging due to sparse moral cues and class imbalance. The research operationalizes a binary moral presence task and compares a presence-gated hierarchy with a direct multi-label classifier, both based on DeBERTa-base and augmented with lightweight signals. Instruction-tuned LLMs are also benchmarked, and a soft-vote supervised ensemble significantly surpasses the best single model. Lightweight signals and small ensembles provide the most reliable improvements, while hierarchical gating offers limited benefit under an 8GB single-GPU constraint.",3.56,78.439,279,cold_start,Phi-4,Apple_M1(Metal)
2601.14175v1_A model of errors in transformers.pdf,A model of errors in transformers,"Suvrat Raju, Praneeth Netrapalli",,,"LLMs, error rate, arithmetic, attention mechanism, task complexity, effective field theory, prompt construction, Gemini 2.5 Flash, Gemini 2.5 Pro, DeepSeek R1","This study examines the error rate of Large Language Models (LLMs) on deterministic tasks requiring repetitive token processing. The authors propose a two-parameter model to describe the relationship between task accuracy and complexity, attributing errors to accumulated attention mechanism inaccuracies. The model is validated using empirical tests on models like Gemini 2.5 Flash, Gemini 2.5 Pro, and DeepSeek R1, showing good agreement with observed accuracy. The study suggests that errors in LLMs on repetitive tasks do not necessarily indicate reasoning collapse or compositional function failure, and proposes prompt construction methods to reduce error rates.",2.92,83.783,245,cold_start,Phi-4,Apple_M1(Metal)
2601.14192v1_Toward Efficient Agents Memory Tool learning and P.pdf,"Toward Efficient Agents: A Survey of Memory, Tool Learning, and Planning","Xiaofang Yang, Lijun Li, Heng Zhou, Tong Zhu, Xiaoye Qu, Yuchen Fan, Qianshan Wei, Rui Ye, Li Kang, Yiran Qin, Zhiqiang Kou, Daizong Liu, Qi Li, Ning Ding, Siheng Chen, Jing Shao",,2601.14192v1,"Agents, Efficiency, Agent Memory, Tool Learning, Planning","Recent years have witnessed increasing interest in extending large language models into agentic systems. While the effectiveness of agents has continued to improve, efficiency, which is crucial for real-world deployment, has often been overlooked. This paper therefore investigates efficiency from three core components of agents: memory, tool learning, and planning, considering costs such as latency, tokens, steps, etc. Aimed at conducting comprehensive research addressing the efficiency of the agentic system itself, we review a broad range of recent approaches that differ in implementation yet frequently converge on shared high-level principles including but not limited to bounding context via compression and management, designing reinforcement learning rewards to minimize tool invocation, and employing controlled search mechanisms to enhance efficiency, which we discuss in detail. Accordingly, we characterize efficiency in two complementary ways: comparing effectiveness under a fixed cost budget, and comparing cost at a comparable level of effectiveness. This trade-off can also be viewed through the Pareto frontier between effectiveness and cost. From this perspective, we also examine efficiency-oriented benchmarks by summarizing evaluation protocols for these components and consolidating commonly reported efficiency metrics from both benchmark and methodological studies. Moreover, we discuss the key challenges and future directions, with the goal of providing promising insights.",3.8,113.682,432,cold_start,Phi-4,Apple_M1(Metal)
2601.14209v1_InT Self-Proposed Interventions Enable Credit Assi.pdf,Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning,"Matthew Y. R. Yang, Hao Bai, Ian Wu, Gene Yang, Amrith Setlur, Aviral Kumar",,arXiv:2206.00001,"large language models, reinforcement learning, credit assignment, intervention training, mathematical reasoning","Outcome-reward reinforcement learning (RL) has been effective in enhancing the reasoning capabilities of large language models (LLMs). However, standard RL assigns credit only at the final answer level, which can discourage correct intermediate steps in failed traces and reinforce spurious steps in successful ones. This paper introduces Intervention Training (InT), a paradigm where the model performs fine-grained credit assignment by proposing targeted corrections to its reasoning traces. Using reference solutions from mathematical reasoning datasets, the model identifies the first error and proposes a single-step intervention to redirect the trajectory toward the correct solution. Supervised fine-tuning is then applied to the on-policy rollout up to the error point concatenated with the intervention, localizing the error to the specific step that caused failure. This approach significantly improves accuracy, outperforming larger models on IMO-AnswerBench.",3.35,89.932,301,cold_start,Phi-4,Apple_M1(Metal)
2601.14230v1_MASCOT Towards Multi-Agent Socio-Collaborative Com.pdf,MASCOT: Towards Multi-Agent Socio-Collaborative Companion Systems,"Yiyang Wang, Yiqiao Jin, Alex Cabral, Josiah Hester",,,"multi-agent systems, socio-collaborative companions, emotional support, cognitive support, persona collapse, social sycophancy, bi-level optimization, RLAIF, meta-policy, psychological support, workplace domains","Multi-agent systems (MAS) have emerged as promising socio-collaborative companions for emotional and cognitive support. However, these systems often suffer from persona collapse and social sycophancy, leading to generic behaviors and non-constructive dialogue. The paper proposes MASCOT, a framework for multi-perspective socio-collaborative companions, introducing a bi-level optimization strategy to harmonize individual and collective behaviors. This includes Persona-Aware Behavioral Alignment and Collaborative Dialogue Optimization. Evaluations show MASCOT significantly outperforms baselines, improving Persona Consistency and Social Contribution. The framework aims to advance socially intelligent multi-agent systems.",3.21,86.972,279,cold_start,Phi-4,Apple_M1(Metal)
2601.14232v1_KAGE-Bench Fast Known-Axis Visual Generalization E.pdf,KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning,"Egor Cherepannov, Daniil Zelezetsky, Alexey K. Kovalev, Aleksandr I. Panov",,,"Reinforcement Learning, Visual Generalization, Pixel-based Agents, Distribution Shift, JAX, PPO-CNN, Benchmarking","Pixel-based reinforcement learning agents often fail under purely visual distribution shifts, even when latent dynamics and rewards are unchanged. Existing benchmarks entangle multiple sources of shift, hindering systematic analysis. This paper introduces KAGE-Env, a JAX-native 2D platformer that factorizes the observation process into independently controllable visual axes while keeping the underlying control problem fixed. KAGE-Bench, built on this environment, is a benchmark of six known-axis suites comprising 34 train-evaluation configuration pairs that isolate individual visual shifts. Using a standard PPO-CNN baseline, strong axis-dependent failures are observed, with background and photometric shifts often collapsing success, while agent-appearance shifts are comparatively benign. The fully vectorized JAX implementation enables fast and reproducible sweeps over visual factors.",3.13,93.259,292,cold_start,Phi-4,Apple_M1(Metal)
2601.14234v1_Q-learning with Adjoint Matching.pdf,Q-LEARNING WITH ADJOINT MATCHING,"Qiyang Li, Sergey Levine",,arXiv:2601.14234v1,"Q-learning, Adjoint Matching, TD-based reinforcement learning, continuous-action RL, diffusion policy, flow-matching policy, temporal-difference backup, offline RL, offline-to-online RL","We propose Q-learning with Adjoint Matching (QAM), a novel TD-based reinforcement learning (RL) algorithm that addresses the challenge of efficiently optimizing an expressive diffusion or flow-matching policy with respect to a parameterized Q-function. Effective optimization requires leveraging the first-order information of the critic, which is challenging for flow or diffusion policies due to numerical instability in direct gradient-based optimization. QAM uses adjoint matching to transform the critic’s action gradient into a step-wise objective function, avoiding unstable backpropagation and providing an unbiased, expressive policy. Combined with temporal-difference backup for critic learning, QAM outperforms prior approaches on hard, sparse reward tasks in both offline and offline-to-online RL.",3.06,89.282,273,cold_start,Phi-4,Apple_M1(Metal)
2601.14235v1_Opportunities in AIML for the Rubin LSST Dark Ener.pdf,Opportunities in AI/ML for the Rubin LSST,"Eric Aubourg, Camille Avestruz, Matthew R. Becker, Biswajit Biswas, Rahul Biswas, Boris Bolliet, Adam S. Bolton, Clecio R. Bom, Raphaël Bonnet-Guerrini, Alexandre Boucaud, Jean-Eric Campagne, Chihway Chang, Aleksandra Ćiprijanović, Johann Cohen-Tanugi, Michael W. Coughlin, John Franklin Crenshaw, Juan C. Cuevas-Tello, Juan de Vicente, Seth W. Digel, Steven Dillmann, Mariano Javier de León Dominguez Romero, Alex Drlica-Wagner, Sydney Erickson, Alexander T. Gagliano, Christos Georgiou, Aritra Ghosh, Matthew Grayling, Kirill A. Grishin, Alan Heavens, Lindsay R. House, Mustapha Ishak, Wassim Kabalan, Arun Kannawadi, François Lanusse, C. Danielle Leonard, Pierre-François L’eǧet, Michelle Lochner, Yao-Yuan Mao, Peter Melchior, Grant Merz, Martin Millon, Anais Möller, Gautham Narayan, Yuuki Omori, Hiranya Peiris, Laurence Perreault-Levasseur, Andrés A. Plazas Malagón, Nesar Ramachandra, Benjamin Remy, Cécile Roucelle, Jaime Ruiz-Zapatero, Stefan Schuldt, Ignacio Sevilla-Noarbe, Ved G. Shah, Tjitske Starkenburg, Stephen Thorp, Laura Toribio San Cipriano, Tilman Tröster, Roberto Trotta, Padma Venkatraman, Amanda Wasserman, Tim White, Justine Zeghal, Tianqing Zhang, Yuanyuan Zhang",,,,,3.39,176.033,596,cold_start,Phi-4,Apple_M1(Metal)
2601.14242v1_APEX-Agents.pdf,APEX–Agents,"Bertie Vidgen, Austin Mann, Abby Fennelly, John Wright, Stanly, Lucas Rothman, Marco Burstein, Julien Benchek, David Ostrofsky, Anirudh Ravichandran, Debnil Sur, Neel Venugopal, Alannah Hsia, Isaac Robinson, Calix Huang, Olivia Varones, Daniyal Khan, Michael Haines, Zach Richards, Chirag Mahapatra, Brendan Foody, Osvald Nitski",,2601.14242v1,"AI Productivity Index, Agents, benchmark, investment banking, management consulting, corporate law, AI evaluation, professional services work","We introduce the AI Productivity Index for Agents (APEX–Agents), a benchmark for assessing whether AI agents can execute long-horizon, cross-application tasks created by investment banking analysts, management consultants, and corporate lawyers. APEX–Agents requires agents to navigate realistic work environments with files and tools. We test eight agents for the leaderboard using Pass@1. Gemini 3 Flash (Thinking=High) achieves the highest score of 24.0%, followed by GPT-5.2 (Thinking=High), Claude Opus 4.5 (Thinking=High), and Gemini 3 Pro (Thinking=High). We open source the APEX–Agents benchmark (n=480) with all prompts, rubrics, gold outputs, files, and metadata. We also open-source Archipelago, our infrastructure for agent execution and evaluation. The tasks require agents to reason, demonstrate advanced knowledge, use multiple applications, and plan over long horizons.",3.68,121.022,445,cold_start,Phi-4,Apple_M1(Metal)
2601.14255v1_VideoMaMa Mask-Guided Video Matting via Generative.pdf,VideoMaMa: Mask-Guided Video Matting via Generative Prior,"Sangbeom Lim, Seoung Wug Oh, Jiahui Huang, Heeji Yoon, Seungryong Kim, Joon-Young Lee",,arXiv:2601.14255v1,"video matting, diffusion-based model, alpha mattes, segmentation masks, generative priors, pseudo-labeling, large-scale video matting","Generalizing video matting models to real-world videos remains a significant challenge due to the scarcity of labeled data. To address this, we present Video Mask-to-Matte Model (VideoMaMa) that converts coarse segmentation masks into pixel accurate alpha mattes, by leveraging pretrained video diffusion models. VideoMaMa demonstrates strong zero-shot generalization to real-world footage, even though it is trained solely on synthetic data. Building on this capability, we develop a scalable pseudo-labeling pipeline for large-scale video matting and construct the Matting Anything in Video (MA-V) dataset, which offers high-quality matting annotations for more than 50K real-world videos spanning diverse scenes and motions. To validate the effectiveness of this dataset, we fine-tune the SAM2 model on MA-V to obtain SAM2-Matte, which outperforms the same model trained on existing matting datasets in terms of robustness on in-the-wild videos. These findings emphasize the importance of large-scale pseudo-labeled video matting and showcase how generative priors and accessible segmentation cues can drive scalable progress in video matting research.",3.8,100.737,383,cold_start,Phi-4,Apple_M1(Metal)
