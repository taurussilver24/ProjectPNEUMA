filename,title,authors,summary,tps,model,platform
2601.07192v1_Relink Constructing Query-Driven Evidence Graph On.pdf,Constructing Query-Driven Evidence Graph On-the-Fly for GraphRAG,"['Manzong Huang', 'Chenyang Bu', 'Yi He', 'Xingrui Zhuo', 'Xindong Wu']","Graph-based Retrieval-Augmented Generation (GraphRAG) mitigates hallucinations in Large Language Models (LLMs) by grounding them in structured knowledge. However, current GraphRAG methods are constrained by a static, pre-constructed Knowledge Graph (KG) paradigm, which faces challenges of incomplete KGs and distractor facts. To address these challenges, the authors propose Relink, a framework that dynamically builds a query-specific evidence graph. Relink instantiates required facts from a latent relation pool derived from the original text corpus, repairing broken paths on the fly. It employs a unified, query-aware evaluation strategy to select the most useful facts for answering the query. Extensive experiments on five Open-Domain Question Answering benchmarks show that Relink achieves significant improvements in EM and F1 scores over leading GraphRAG baselines, demonstrating the superiority of the proposed framework.",300.43,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07197v1_Beyond Variance Knowledge-Aware LLM Compression vi.pdf,Beyond Variance: Knowledge-Aware LLM Compression via Fisher-Aligned Subspace Diagnostics,"['Ibne Farabi Shihab*', 'Sanjeda Akter*', 'Anuj Sharma']","Post-training activation compression is essential for deploying Large Language Models (LLMs) on resource-constrained hardware. Standard methods like Singular Value Decomposition (SVD) are gradient-blind, preserving high-variance dimensions regardless of their impact on factual knowledge preservation. The paper introduces Fisher-Aligned Subspace Compression (FASC), a knowledge-aware compression framework that selects subspaces by directly modeling activation-gradient coupling, minimizing a second-order surrogate of the loss function. FASC leverages the Fisher Information Matrix to identify dimensions critical for factual knowledge, often residing in low-variance but high-gradient-sensitivity subspaces. The Dependence Violation Score (ρ) is proposed as a general-purpose diagnostic metric to quantify activation-gradient coupling, revealing where factual knowledge is stored within transformer architectures. Extensive experiments on Mistral-7B and Llama-3-8B demonstrate that FASC preserves 6-8% more accuracy on knowledge-intensive benchmarks (MMLU, LAMA) compared to variance-based methods at 50% rank reduction, effectively enabling a 7B model to match the factual recall of a 13B uncompressed model. The analysis reveals that ρ serves as a fundamental signal of stored knowledge, with high-ρ layers emerging only when models internalize factual associations during training.",313.74,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07199v1_Forward versus Backward Comparing Reasoning Object.pdf,Forward versus Backward: Comparing Reasoning Objectives in Direct Preference Optimization,"['Murtaza Nikazad', 'Raghuram Ramanujan']","This paper investigates the effect of training objective composition on reasoning reliability through Direct Preference Optimization. Two complementary training signals are examined: forward chain-of-thought generation, which trains the model to produce correct reasoning traces, and backward verification, which trains the model to verify and acknowledge errors in candidate solutions. Experiments on GSM8K reveal a fundamental trade-off between these objectives. Forward-only DPO training achieves the highest accuracy improvement, increasing from 83.1% to 86.6% (+3.5 percentage points), while backward-only training yields minimal accuracy gains but substantially reduces the false positive rate from 13.4% to 4.3%. Notably, both training variants reduce acknowledgement rate compared to the baseline, suggesting that preference optimization increases model confidence in its outputs. These findings indicate that forward and backward reasoning objectives provide distinct and complementary learning signals: forward training improves problem-solving capability, while backward training improves verification calibration. The complete training and evaluation pipeline, implemented efficiently through Low-Rank Adaptation, is released to facilitate further research.",314.87,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07200v1_Safeguarding LLM Fine-tuning via Push-Pull Distrib.pdf,Safeguarding LLM Fine-tuning via Push-Pull Distributional Alignment,"['Haozhong Wang', 'Zhuo Li', 'Yibo Yang', 'He Zhao', 'Hongyuan Zha', 'Dandan Guo']","The paper introduces Safety Optimal Transport (SOT), a novel framework that reframes safe fine-tuning from an instance-level filtering challenge to a distribution-level alignment task grounded in Optimal Transport (OT). SOT optimizes sample importance by actively pulling the downstream distribution towards a trusted safe anchor while simultaneously pushing it away from a general harmful reference. This establishes a robust geometric safety boundary that effectively purifies the training data. Extensive experiments across diverse model families and domains demonstrate that SOT significantly enhances model safety while maintaining competitive downstream performance, achieving a superior safety-utility trade-off compared to baselines.",314.17,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07201v1_CalPro Prior-Aware Evidential--Conformal Predictio.pdf,CalPro: Prior-Aware Evidential–Conformal Prediction with Structure-Aware Guarantees for Protein Structures,"['Ibne Farabi Shihab * 1', 'Sanjeda Akter * 1', 'Anuj Sharma 2']","Deep protein structure predictors such as AlphaFold provide confidence estimates (e.g., pLDDT) that are not calibrated and degrade under distribution shifts. CalPro introduces a prior-aware evidential-conformal framework for shift-robust uncertainty quantification. It combines a geometric evidential head, a differentiable conformal layer, and domain priors. Theoretical coverage guarantees under distribution shift are derived using PAC-Bayesian bounds. Empirically, CalPro achieves ≤5% coverage degradation across modalities, reduces calibration error by 30–50%, and improves downstream ligand-docking success by 25%. The framework applies to structured regression tasks where priors encode local reliability, validated on non-biological benchmarks.",314.02,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07206v1_LLMRouterBench A Massive Benchmark and Unified Fra.pdf,LLMRouterBench: A Massive Benchmark and Unified Framework for LLM Routing,"['Hao Li', 'Yiqun Zhang', 'Zhaoyan Guo', 'Chenxu Wang', 'Shengji Tang', 'Qiaosheng Zhang', 'Yang Chen', 'Biqing Qi', 'Peng Ye', 'Lei Bai', 'Zhen Wang', 'Shuyue Hu']","LLMRouterBench is a large-scale benchmark and unified framework for LLM routing, comprising over 400K instances from 21 datasets and 33 models. It provides comprehensive metrics for both performance-oriented and performance-cost trade-off routing and integrates 10 representative routing baselines. The authors systematically re-evaluate the field, confirming strong model complementarity but finding that many routing methods exhibit similar performance under unified evaluation and that several recent approaches fail to reliably outperform a simple baseline. The benchmark also enables latency-aware analysis and highlights the limitations of backbone embedding models and the diminishing returns of larger ensembles compared to careful model curation. All code and data are available at https://github.com/ynulihao/LLMRouterBench.",314.07,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07209v1_SIRR-LMM Single-image Reflection Removal via Large.pdf,SIRR-LMM: Single-image Reflection Removal via Large Multimodal Model,"['Yu Guo', 'Zhiqiang Lao', 'Xiyun Song', 'Yubin Zhou', 'Heather Yu']","Glass surfaces create complex interactions of reflected and transmitted light, making single-image reflection removal (SIRR) challenging. Existing datasets suffer from limited physical realism in synthetic data or insufficient scale in real captures. We introduce a synthetic dataset generation framework that path-traces 3D glass models over real background imagery to create physically accurate reflection scenarios with varied glass properties, camera settings, and post-processing effects. To leverage the capabilities of Large Multimodal Model (LMM), we concatenate the image layers into a single composite input, apply joint captioning, and fine-tune the model using task-specific LoRA rather than full-parameter training. This enables our approach to achieve improved reflection removal and separation performance compared to state-of-the-art methods.",315.67,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07214v1_BlindU Blind Machine Unlearning without Revealing .pdf,BlindU: Blind Machine Unlearning without Revealing Erasing Data,"['Weiqi Wang', 'Zhiyi Tian', 'Chenhao Zhang', 'Shui Yu']","Machine unlearning enables data holders to remove the contribution of their specified samples from trained models to protect their privacy. However, most unlearning methods require the unlearning requesters to upload their data to the server, which is infeasible in privacy-preserving scenarios. This paper explores how to implement unlearning without revealing the erasing data to the server. We propose Blind Unlearning (BlindU), which uses compressed representations instead of original inputs. BlindU only involves the server and the unlearning user, with the user generating privacy-preserving representations locally and the server performing unlearning solely on these representations and their labels. For Federated Learning (FL) model training, we employ the information bottleneck (IB) mechanism. The encoder of the IB-based FL model learns representations that distort maximum task-irrelevant information from inputs, allowing FL users to generate compressed representations locally. For effective unlearning using compressed representations, BlindU integrates two dedicated unlearning modules tailored explicitly for IB-based models and uses a multiple gradient descent algorithm to balance forgetting and utility retaining. To further enhance privacy protection, we introduce a noise-free differential privacy (DP) masking method to deal with raw erasing data before compressing. Theoretical analysis and extensive experimental results illustrate the superiority of BlindU in privacy protection and unlearning effectiveness compared with existing benchmarks.",314.04,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07224v1_Consolidation or Adaptation PRISM Disentangling SF.pdf,Consolidation or Adaptation? PRISM: Disentangling SFT and RL Data via Gradient Concentration,"['Yang Zhao', 'Yangou Ouyang', 'Xiao Ding', 'Hepeng Wang', 'Bibo Cai', 'Kai Xiong', 'Jinglong Gao', 'Zhouhao Sun', 'Li Du', 'Bing Qin', 'Ting Liu']","While Hybrid Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) has become the standard paradigm for training LLM agents, effective mechanisms for data allocation between these stages remain largely underexplored. Current data arbitration strategies often rely on surface-level heuristics that fail to diagnose intrinsic learning needs. Since SFT targets pattern consolidation through imitation while RL drives structural adaptation via exploration, misaligning data with these functional roles causes severe optimization interference. The paper proposes PRISM, a dynamics-aware framework grounded in Schema Theory that arbitrates data based on its degree of cognitive conflict with the model’s existing knowledge. By analyzing the spatial geometric structure of gradients, PRISM identifies data triggering high spatial concentration as high-conflict signals that require RL for structural restructuring. In contrast, data yielding diffuse updates is routed to SFT for efficient consolidation. Extensive experiments on WebShop and ALFWorld demonstrate that PRISM achieves a Pareto improvement, outperforming state-of-the-art hybrid methods while reducing computational costs by up to 3.22 ×. The findings suggest that disentangling data based on internal optimization regimes is crucial for scalable and robust agent alignment.",313.9,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07226v1_Lost in the Noise How Reasoning Models Fail with C.pdf,Lost in the Noise: How Reasoning Models Fail with Contextual Distractors,"['Seongyun Lee', 'Yongrae Jo', 'Minju Seo', 'Moontae Lee', 'Minjoon Seo']","Recent advances in reasoning models and agentic AI systems have led to an increased reliance on diverse external information. However, this shift introduces input contexts that are inherently noisy, a reality that current benchmarks fail to capture. We introduce NoisyBench, a comprehensive benchmark that systematically evaluates model robustness across 11 datasets in RAG, reasoning, alignment, and tool-use tasks against diverse noise types, including random documents, irrelevant chat histories, and hard negative distractors. Our evaluation reveals a catastrophic performance drop of up to 80% in state-of-the-art models when faced with contextual distractors. Crucially, we find that agentic workflows often amplify these errors by over-trusting noisy tool outputs, and distractors can trigger emergent misalignment even without adversarial intent. We find that prompting, context engineering, SFT, and outcome-reward only RL fail to ensure robustness; in contrast, our proposed Rationale-Aware Reward (RARE) significantly strengthens resilience by incentivizing the identification of helpful information within noise. Finally, we uncover an inverse scaling trend where increased test-time computation leads to worse performance in noisy settings and demonstrate via attention visualization that models disproportionately focus on distractor tokens, providing vital insights for building the next generation of robust, reasoning-capable agents.",314.12,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07229v2_DiSCo Making Absence Visible in Intelligent Summar.pdf,DiSCo: Making Absence Visible in Intelligent Summarization Interfaces,"['ERAN FAINMAN', 'HAGIT BEN SHOSHAN', 'ADIR SOLOMON', 'OSNAT MOKRYN']","Intelligent interfaces increasingly use large language models to summarize user-generated content, yet these summaries emphasize what is mentioned while overlooking what is missing. This presence bias can mislead users who rely on summaries to make decisions. We present Domain Informed Summarization through Contrast (DiSCo), an expectation-based computational approach that makes absences visible by comparing each entity’s content with domain topical expectations captured in reference distributions of aspects typically discussed in comparable accommodations. This comparison identifies aspects that are either unusually emphasized or missing relative to domain norms and integrates them into the generated text. In a user study across three accommodation domains, namely ski, beach, and city center, DiSCo summaries were rated as more detailed and useful for decision making than baseline large language model summaries, although slightly harder to read. The findings show that modeling expectations reduces presence bias and improves both transparency and decision support in intelligent summarization interfaces.",315.53,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07232v1_Yes FLoReNce I Will Do Better Next Time Agentic Fe.pdf,Agentic Feedback Reasoning for Humorous Meme Detection,"['Olivia Shanhong Liu', 'Pai Chet Ng', 'De Wen Soh', 'Konstantinos N. Plataniotis']","This paper proposes FLoReNce, an agentic feedback reasoning framework for detecting humor in memes. Unlike existing multimodal or prompting-based models, FLoReNce operates in a closed-loop during learning and an open-loop during inference. During learning, a reasoning agent is critiqued by a judge, and the feedback is stored in a non-parametric knowledge base. At inference, the model retrieves similar judged experiences from this KB and uses them to modulate its prompt, enabling better, self-aligned reasoning without finetuning. On the PrideMM dataset, FLoReNce improves both predictive performance and explanation quality over static multimodal baselines, demonstrating that feedback-regulated prompting is a viable path to adaptive meme humor understanding.",313.94,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07233v1_From Thinking to Justifying Aligning High-Stakes E.pdf,Thinking” to “Justifying”: Aligning High-Stakes Explainability with Professional Communication Standards,"['Chen Qian', 'William & Mary', 'cqian03@wm.edu', 'Yimeng Wang', 'William & Mary', 'ywang139@wm.edu', 'Yu Chen', 'Anytime AI', 'ychen@anytime-ai.com', 'Lingfei Wu', 'Anytime AI', 'lwu@anytime-ai.com', 'Andreas Stathopoulos', 'William & Mary', 'axstat@wm.edu']","Explainable AI (XAI) in high-stakes domains should help stakeholders trust and verify system outputs. However, Chain-of-Thought methods reason before concluding, and logical gaps or hallucinations can yield conclusions that do not reliably align with their rationale. The authors propose 'Result → Justify', which constrains the output communication to present a conclusion before its structured justification. They introduce SEF (Structured Explainability Framework), operationalizing professional conventions via six metrics for structure and grounding. Experiments across four tasks in three domains validate this approach: all six metrics correlate with correctness, and SEF achieves 83.9% accuracy (+5.3 over CoT). These results suggest structured justification can improve verifiability and reliability.",313.94,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07238v1_Group Pattern Selection Optimization Let LRMs Pick.pdf,Group Pattern Selection Optimization: Let LRMs Pick the Right Pattern for Reasoning,"['Hanbin Wang', 'Jingwei Song', 'Jinpeng Li', 'Fei Mi', 'Lifeng Shang']","Large reasoning models (LRMs) exhibit diverse high-level reasoning patterns, yet prevailing training recipes implicitly bias models toward a limited set of dominant patterns. Through a systematic analysis, the authors identify substantial accuracy variance across these patterns on mathematics and science benchmarks, revealing that a model's default reasoning pattern is often sub-optimal for a given problem. To address this, they introduce Group Pattern Selection Optimization (GPSO), a reinforcement learning framework that extends GRPO by incorporating multi-pattern rollouts, verifier-guided optimal pattern selection per problem, and attention masking during optimization to prevent the leakage of explicit pattern suffixes into the learned policy. By exploring a portfolio of diverse reasoning strategies and optimizing the policy on the most effective ones, GPSO enables the model to internalize the mapping from problem characteristics to optimal reasoning patterns. Extensive experiments demonstrate that GPSO delivers consistent and substantial performance gains across various model backbones and benchmarks, effectively mitigating pattern sub-optimality and fostering more robust, adaptable reasoning. All data and codes are available at https://github.com/wanghanbinpanda/GPSO.",313.77,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07239v1_Stochastic CHAOS Why Deterministic Inference Kills.pdf,"Stochas(c CHAOS: Why Determinis)c Inference Kills, and Distribu(onal Variability Is the Heartbeat of Ar(ﬁcial Cogni(on","['Tanmay Joshi', 'Shourya Aggarwal', 'Anusa Saha', 'Aadi Pandey', 'Shreyash Dhoot', 'Vighnesh Rai', 'Raxit Goswami', 'Aman Chadha', 'Vinija Jain', 'Amitava Das']","Deterministic inference is a comforting ideal in classical software, but for large language models (LLMs) moving into real-world deployment, it has been imported wholesale into inference stacks. Recent work from the Thinking Machines Lab has shown how deterministic inference can enforce bitwise-identical outputs for a given prompt, effectively positioning it as a prerequisite for reproducibility, on-policy RL, and enterprise reliability. This paper argues that deterministic inference kills the ability to model uncertainty, makes emergent abilities vanish, disrupts reasoning abilities, and renders safety alignment brittle. Instead, the authors advocate for Stochastic CHAOS and claim that distributional variability is the heart of artificial cognition. They introduce three distinct stability goals for LLM inference: bitwise determinism, distributional reproducibility, and semantic stability. Empirically, the paper shows that deterministic inference is systematically misleading in four ways, including underestimating capability and fragility, vanishing phase-like transitions, and degrading multi-path methods.",315.02,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07245v1_Learning to Trust the Crowd A Multi-Model Consensu.pdf,Learning to Trust the Crowd: A Multi-Model Consensus Reasoning Engine for Large Language Models,['Pranav Kallem'],"The authors introduce a Multi-Model Consensus Reasoning Engine that treats the set of LLM outputs as input to a supervised meta-learner. The system maps natural language responses into structured features using semantic embeddings, pairwise similarity and clustering statistics, lexical and structural cues, reasoning-quality scores, confidence estimates, and model-specific priors. The best graph-attention-based consensus model improves macro-average accuracy by 4.6 percentage points over the strongest single LLM and by 8.1 points over majority vote, while also yielding lower Brier scores and fewer TruthfulQA hallucinations. Ablation and feature-importance analyses show that semantic agreement and clustering features are most influential, with reasoning-quality and model-prior features providing complementary gains, suggesting supervised multi-model consensus is a practical route toward more reliable LLM behavior, even in a modest single-machine setup.",315.19,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07250v1_DDT A Dual-Masking Dual-Expert Transformer for Ene.pdf,DDT: A Dual-Masking Dual-Expert Transformer for Energy Time-Series Forecasting,"['Mingnan Zhu', 'Qixuan Zhang', 'Yixuan Cheng', 'Fangzhou Gu', 'Shiming Lin']","Accurate energy time-series forecasting is crucial for ensuring grid stability and promoting the integration of renewable energy. The paper proposes DDT, a novel and robust deep learning framework for high-precision time-series forecasting. DDT introduces a dual-masking mechanism that combines a strict causal mask with a data-driven dynamic mask, ensuring theoretical causal consistency while adaptively focusing on the most salient historical information. It also features a dual-expert system that decouples the modeling of temporal dynamics and cross-variable correlations into parallel, specialized pathways, which are then intelligently integrated through a dynamic gated fusion module. Extensive experiments on 7 challenging energy benchmark datasets demonstrate that DDT consistently outperforms strong state-of-the-art baselines across all prediction horizons, establishing a new benchmark for the task.",314.99,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07261v1_Pseudodata-guided Invariant Representation Learnin.pdf,Pseudodata-guided Invariant Representation Learning Boosts the Out-of-Distribution Generalization in Enzymatic Kinetic Parameter Prediction,"['Haomin Wu', 'Zhiwei Nie', 'Hongyu Zhang', 'Zhixiang Ren']","Accurate prediction of enzyme kinetic parameters is essential for understanding catalytic mechanisms and guiding enzyme engineering. However, existing deep learning-based enzyme-substrate interaction predictors often exhibit performance degradation on sequence-divergent, out-of-distribution cases, limiting robustness under biologically relevant perturbations. This paper proposes O 2DENet, a lightweight, plug-and-play module that enhances out-of-distribution generalization via biologically and chemically informed perturbation augmentation and invariant representation learning. When integrated with representative ESI models, O 2DENet consistently improves predictive performance for both kcat and Km across stringent sequence-identity-based OOD benchmarks, achieving state-of-the-art results in terms of accuracy and robustness metrics.",315.42,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07263v1_When Bots Take the Bait Exposing and Mitigating th.pdf,When Bots Take the Bait: Exposing and Mitigating the Emerging Social Engineering Attack in Web Automation Agent,"['Xinyi Wu†', 'Geng Hong †B', 'Yueyue Chen†', 'MingXuan Liu §', 'Feier Jin †', 'Xudong Pan †‡', 'Jiarun Dai †', 'Baojun Liu ¶']","Web agents, powered by large language models (LLMs), are increasingly deployed to automate complex web interactions. The rise of open-source frameworks (e.g., Browser Use, Skyvern-AI) has accelerated adoption but also broadened the attack surface. While prior research has focused on model threats such as prompt injection and backdoors, the risks of social engineering remain largely unexplored. This paper presents the first systematic study of social engineering attacks against web automation agents and designs a pluggable runtime mitigation solution. On the attack side, the AGENTBAIT paradigm exploits intrinsic weaknesses in agent execution, while on the defense side, SUPERVISOR is proposed as a lightweight runtime module to enforce environment and intention consistency alignment. Empirical results show that mainstream frameworks are highly vulnerable to AGENTBAIT, with an average attack success rate of 67.5% and peaks above 80% under specific strategies. Compared with existing lightweight defenses, our module can be seamlessly integrated across different frameworks and reduces attack success rates by up to 78.1% while incurring only a 7.7% runtime overhead and preserving usability. This work reveals AGENTBAIT as a critical new threat surface for web agents and establishes a practical, generalizable defense, advancing the security of this rapidly emerging ecosystem.",313.48,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07291v1_A Visual Semantic Adaptive Watermark grounded by P.pdf,A Visual Semantic Adaptive Watermark grounded by Prefix-Tuning for Large Vision-Language Model,"['Qi Zheng', 'Shuliang Liu', 'Yu Huang', 'Sihang Jia', 'Jungang Li', 'Lyuhao Chen', 'Junhao Chen', 'Hanqian Li', 'Aiwei Liu', 'Yibo Yan', 'Xuming Hu']","Watermarking has emerged as a pivotal solution for content traceability and intellectual property protection in Large Vision-Language Models (LVLMs). However, vision-agnostic watermarks introduce visually irrelevant tokens and disrupt visual grounding, while semantic-aware methods incur prohibitive inference latency. This paper proposes the Visual Semantic Adaptive Watermark (VISA-Mark), a novel framework that embeds detectable signals while strictly preserving visual fidelity. Our approach employs a lightweight, efficiently trained prefix-tuner to extract dynamic Visual Evidence Weights, which guide an adaptive vocabulary partitioning and logits perturbation mechanism, concentrating watermark strength on visually-supported tokens. VISA-Mark effectively maintains visual fidelity and outperforms conventional methods in visual consistency and semantic fidelity. The framework maintains high detection accuracy and robust attack resilience without sacrificing inference efficiency, establishing a new standard for reliability-preserving multimodal watermarking.",314.08,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07292v1_Photometric Redshift Estimation Using Scaled Ensem.pdf,Photometric Redshift Estimation Using Scaled Ensemble Learning,"['Swagata Biswas', 'Shubhrangshu Ghosh', 'Avyarthana Ghosh', 'Yogesh Wadadekar', 'Abhishek Roy Choudhury', 'Arijit Mukherjee', 'Shailesh Deshpande', 'Arpan Pal']","The study presents a new ensemble-based machine learning framework for predicting photometric redshifts (Pz) for faint galaxies and higher redshift ranges using optical (grizy) photometric data. The proposed architecture integrates gradient boosting machine, extreme gradient boosting, k-nearest neighbors, and artificial neural networks within a scaled ensemble structure. By using bagged input data, the ensemble approach delivers improved predictive performance compared to stand-alone models. The framework demonstrates consistent accuracy in estimating redshifts, maintaining strong performance up to z ∼ 4. The model is validated using publicly available data from the Hyper Suprime-Cam Strategic Survey Program by the Subaru Telescope. The results show marked improvements in the precision and reliability of Pz estimation, closely adhering to and in certain instances exceeding the benchmarks specified in the LSST Science Requirements Document. Evaluation metrics include catastrophic outlier, bias, and rms.",314.05,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07296v1_LRAS Advanced Legal Reasoning with Agentic Search.pdf,Advanced Legal Reasoning with Agentic Search,"['Yujin Zhou', 'Chuxue Cao', 'Jinluan Yang', 'Lijun Wu', 'Conghui He', 'Sirui Han', 'Yike Guo']","This paper presents LRAS, a framework designed to enhance legal Large Reasoning Models (LRMs) by integrating Introspective Imitation Learning and Difficulty-aware Reinforcement Learning. LRAS enables LRMs to identify knowledge boundaries and handle legal reasoning complexity, outperforming state-of-the-art baselines by 8.2-32%. Empirical results show substantial gains in tasks requiring deep reasoning with reliable knowledge. The authors discuss the limitations of existing Legal LLMs and introduce LRAS as a solution to the challenges faced in legal scenarios, particularly in establishing legal entities and handling complex legal claims.",314.21,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07304v1_Heterogeneous Multi-Expert Reinforcement Learning .pdf,Heterogeneous Multi-Expert Reinforcement Learning for Long-Horizon Multi-Goal Tasks in Autonomous Forklifts,"['Yun Chen', 'Bowei Huang', 'Fan Guo', 'Kang Song']","This work proposes a Heterogeneous Multi-Expert Reinforcement Learning (HMER) framework tailored for autonomous forklifts. The framework decomposes long-horizon tasks into specialized sub-policies controlled by a Semantic Task Planner, separating macro-level navigation from micro-level manipulation. The planner coordinates the sequential execution of these experts, bridging the gap between task planning and continuous control. To solve the problem of sparse exploration, a Hybrid Imitation-Reinforcement Training Strategy is introduced, using expert demonstrations to initialize the policy and reinforcement learning for fine-tuning. Experiments in Gazebo simulations show that HMER significantly outperforms sequential and end-to-end baselines, achieving a task success rate of 94.2%, reducing operation time by 21.4%, and maintaining placement error within 1.5 cm.",315.0,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07309v1_ARM Role-Conditioned Neuron Transplantation for Tr.pdf,Agent-Role Merging (ARM) for Training-Free Model Merging in Large Language Model Agents,"['Zhuoka Feng', 'Kang Chen', 'Sihan Zhao', 'Kai Xiong', 'Yaoning Wang', 'Minshen Yu', 'Junjie Nian', 'Changyi Xiao', 'Yixin Cao']","This paper proposes Agent-Role Merging (ARM), a novel method for model merging in large language model (LLM) agents. ARM improves upon existing merging methods by integrating multiple experts into a single model, enabling robust adaptation across various interactive environments. The method consists of three steps: constructing merged backbones, selecting based on role-conditioned activation analysis, and performing neuron transplantation for fine-grained refinements. ARM achieves this without gradient-based optimization, enhancing cross-benchmark generalization while maintaining efficiency. The model obtained via ARM merging outperforms prior methods and domain-specific expert models, demonstrating strong out-of-domain generalization.",315.92,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07313v1_Explaining Machine Learning Predictive Models thro.pdf,Explaining Machine Learning Predictive Models through Conditional Expectation Methods,"['Silvia Ruiz-Espa˜ na', 'Laura Arnal', 'Fran¸ cois Signola', 'Juan-Carlos Perez-Cortes', 'Joaquim Arlandis']","The rapid adoption of complex artificial intelligence (AI) and machine learning (ML) models has led to their characterization as black boxes due to the difficulty of explaining their internal decision-making processes. This lack of transparency hinders users' ability to understand, validate and trust model behavior, particularly in high-risk applications. Although explainable AI (XAI) has made significant progress, there remains a need for versatile and effective techniques to address increasingly complex models. This work introduces Multivariate Conditional Expectation (MUCE), a model-agnostic method for local explainability designed to capture prediction changes from feature interactions. MUCE extends Individual Conditional Expectation (ICE) by exploring a multivariate grid of values in the neighborhood of a given observation at inference time, providing graphical explanations that illustrate the local evolution of model predictions. In addition, two quantitative indices, stability and uncertainty, summarize local behavior and assess model reliability. Uncertainty is further decomposed into uncertainty + and uncertainty − to capture asymmetric effects that global measures may overlook. The proposed method is validated using XGBoost models trained on three datasets: two synthetic (2D and 3D) to evaluate behavior near decision boundaries, and one transformed real-world dataset to test adaptability to heterogeneous feature types. Results show that MUCE effectively captures complex local model behavior, while the stability and uncertainty indices provide meaningful insight into prediction confidence. MUCE, together with the ICE modification and the proposed indices, offers a practical contribution to local explainability, enabling both graphical and quantitative insights that enhance the interpretability of predictive models and support more trustworthy and transparent decision-making.",314.64,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07315v1_VLM-CAD VLM-Optimized Collaborative Agent Design W.pdf,VLM-CAD:VLM-OptimizedCollaborativeAgent Design Workflow for Analog Circuit Sizing,"['1st Guanyuan Pan', '2nd Yugui Lin', '3rd Tiansheng Zhou', '4th Pietro Li `o', '5th Shuai Wang', '6th Yaqi Wang*']","Analog mixed-signal circuit sizing involves complex trade-offs within high-dimensional design spaces. Existing automatic analog circuit sizing approaches often underutilize circuit schematics and lack the explainability required for industry adoption. To tackle these challenges, the authors propose a Vision Language Model-optimized collaborative agent design workflow (VLM-CAD), which analyzes circuits, optimizes DC operating points, performs inference-based sizing, and executes external sizing optimization. They integrate Image2Net to annotate circuit schematics and generate a structured JSON description for precise interpretation by Vision Language Models. Additionally, they propose an Explainable Trust Region Bayesian Optimization method (ExTuRBO) that employs collaborative warm-starting from agent-generated seeds and offers dual-granularity sensitivity analysis for external sizing optimization, supporting a comprehensive final design report. Experiment results on amplifier sizing tasks using 180nm, 90nm, and 45nm Predictive Technology Models demonstrate that VLM-CAD effectively balances power and performance, achieving a 100% success rate in optimizing an amplifier with a complementary input and a class-AB output stage, while maintaining total runtime under 43 minutes across all experiments.",314.24,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07316v1_BEAT-Net Injecting Biomimetic Spatio-Temporal Prio.pdf,BEAT-Net: Injecting Biomimetic Spatio-Temporal Priors for Interpretable ECG Classification,"['Ma Runze', 'Liao Caizhi ∗']","BEAT-Net proposes a framework that reformulates the ECG classification problem as a language modeling task, utilizing a QRS tokenization strategy to transform continuous signals into biologically aligned heartbeat sequences. The architecture explicitly decomposes cardiac physiology through specialized encoders that extract local beat morphology while normalizing spatial lead perspectives and modeling temporal rhythm dependencies. Evaluations across three large-scale benchmarks demonstrate that BEAT-Net matches the diagnostic accuracy of dominant CNN architectures while substantially improving robustness. The framework exhibits exceptional data efficiency, recovering fully supervised performance using only 30 to 35 percent of annotated data. Learned attention mechanisms provide inherent interpretability by spontaneously reproducing clinical heuristics, such as Lead II prioritization for rhythm analysis, without explicit supervision. These findings indicate that integrating biological priors offers a computationally efficient and interpretable alternative to data-intensive large-scale pre-training.",315.59,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07320v1_Segmental Advantage Estimation Enhancing PPO for L.pdf,Segmental Advantage Estimation: Enhancing PPO for Long-Context LLM Training,"['Xue Gong', 'Qi Yi', 'Ziyuan Nan', 'Guanhua Huang', 'Kejiao Li', 'Yuhao Jiang', 'Ruibin Xiong', 'Zenan Xu', 'Jiaming Guo', 'Shaohui Peng', 'Bo Zhou']","Training Large Language Models (LLMs) for reasoning tasks is increasingly driven by Reinforcement Learning with Verifiable Rewards (RLVR), where Proximal Policy Optimization (PPO) provides a principled framework for stable policy updates. However, the practical application of PPO is hindered by unreliable advantage estimation in the sparse-reward RLVR regime. This issue arises because the sparse rewards in RLVR lead to inaccurate intermediate value predictions, which in turn introduce significant bias when aggregated at every token by Generalized Advantage Estimation (GAE). To address this, we introduce Segmental Advantage Estimation (SAE), which mitigates the bias that GAE can incur in RLVR. Our key insight is that aggregating n-step advantages at every token (as in GAE) is unnecessary and often introduces excessive bias, since individual tokens carry minimal information. Instead, SAE first partitions the generated sequence into coherent sub-segments using low-probability tokens as heuristic boundaries. It then selectively computes variance-reduced advantage estimates only from these information-rich segment transitions, effectively filtering out noise from intermediate tokens. Our experiments demonstrate that SAE achieves superior performance, with marked improvements in final scores, training stability, and sample efficiency. These gains are shown to be consistent across multiple model sizes, and a correlation analysis confirms that our proposed advantage estimator achieves a higher correlation with an approximate ground-truth advantage, justifying its superior performance.",314.51,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07342v1_Agentic Diagnostic Reasoning over Telecom and Data.pdf,Agentic Diagnostic Reasoning over Telecom and Datacenter Infrastructure,['Nicolas Tacheny'],"Large-scale telecom and datacenter infrastructures rely on multi-layered service and resource models, where failures propagate across physical and logical components and affect multiple customers. Traditional approaches to root cause analysis (RCA) rely on hard-coded graph traversal algorithms or rule-based correlation engines, which are costly to maintain and tightly coupled to the infrastructure model. In this work, we introduce an agentic diagnostic framework where a Large Language Model (LLM) performs step-wise investigation using a constrained tool-space exposed through the Model Context Protocol (MCP). Instead of embedding causal logic or traversal algorithms into the application, the agent autonomously navigates the infrastructure model by invoking tools for service lookup, dependency retrieval, structured and unstructured data, and event analysis, and impact discovery. This work lays the foundation for autonomous incident resolution and change impact mitigation.",316.85,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07344v1_PulseMind A Multi-Modal Medical Model for Real-Wor.pdf,PulseMind: A Multi-Modal Medical Model for Real-World Clinical Diagnosis,"['Jiao Xu', 'Junwei Liu', 'Jiangwei Lao', 'Qi Zhu', 'Yunpeng Zhao', 'Congyun Jin', 'Shinan Liu', 'Zhihong Lu', 'Lihe Zhang', 'Xin Chen', 'Jian Wang', 'Ping Wang']","PulseMind introduces a new family of multi-modal diagnostic models that integrate a curated dataset, a comprehensive evaluation benchmark, and a tailored training framework. It constructs a diagnostic dataset, MediScope, comprising 98,000 real-world multi-turn consultations and 601,500 medical images. PulseMind Benchmark evaluates the models with a four-dimensional protocol. The training framework uses CRPO, a reinforcement policy optimization method that provides stable and human-aligned training guidance. Extensive experiments show competitive performance on both diagnostic consultation and public medical benchmarks.",314.03,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07348v4_Controlled Self-Evolution for Algorithmic Code Opt.pdf,Controlled Self-Evolution for Algorithmic Code Optimization,"['Tu Hu', 'Ronghao Chen', 'Shuo Zhang', 'Jianghao Yin', 'Mou Xiao Feng', 'Jingping Liu', 'Shaolei Zhang', 'Wenqi Jiang', 'Yuqi Fang', 'Sen Hu', 'Huacan Wang', 'Yi Xu']","Self-evolution methods enhance code generation through iterative cycles, but existing approaches suffer from low exploration efficiency. This inefficiency stems from initialization bias, uncontrolled stochastic operations, and insufficient experience utilization. To address these bottlenecks, we propose Controlled Self-Evolution (CSE), which consists of three key components: Diversified Planning Initialization, Genetic Evolution, and Hierarchical Evolution Memory. Diversified Planning Initialization generates structurally distinct algorithmic strategies for broad coverage. Genetic Evolution replaces stochastic operations with feedback-guided mechanisms, enabling targeted mutation and compositional crossover. Hierarchical Evolution Memory captures both successful and failed experiences at inter-task and intra-task levels. Experiments on EffiBench-X demonstrate that CSE consistently outperforms all baselines across various LLM backbones. Furthermore, CSE achieves higher efficiency from early generations and maintains continuous improvement throughout evolution. Our code is publicly available at https://github.com/QuantaAlpha/EvoControl.",315.81,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07351v2_Beyond Hard Masks Progressive Token Evolution for .pdf,Beyond Hard Masks: Progressive Token Evolution for Diffusion Language Models,"['Linhao Zhong', 'Linyu Wu', 'Bozhen Fang', 'Tianjian Feng', 'Chenchen Jing', 'Wen Wang', 'Jiaheng Zhang', 'Hao Chen', 'Chunhua Shen']","This paper proposes EvoToken-DLM, a novel diffusion-based language modeling approach that replaces hard binary masks with evolving soft token distributions. EvoToken-DLM enables a progressive transition from masked states to discrete outputs, supporting revisable decoding. The authors introduce continuous trajectory supervision to effectively support this evolution. Extensive experiments across multiple benchmarks show that EvoToken-DLM consistently achieves superior performance, outperforming strong diffusion-based and masked DLM baselines.",313.62,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07356v1_Efficient Convolutional Forward Model for Passive .pdf,Efficient Convolutional Forward Model for Passive Acoustic Mapping and Temporal Monitoring,"['Tatiana Gelvez-Barrera', 'Barbara Nicolas', 'Bruno Gilles', 'Adrian Basarab', 'Denis Kouamé']","Passive acoustic mapping (PAM) is a key imaging technique for characterizing cavitation activity in therapeutic ultrasound applications. Recent model-based beamforming algorithms offer high reconstruction quality and strong physical interpretability. However, their computational burden and limited temporal resolution restrict their use in applications with time-evolving cavitation. To address these challenges, the authors introduce a PAM beamforming framework based on a novel convolutional formulation in the time domain, which enables efficient computation. In this framework, PAM is formulated as an inverse problem where the forward operator maps spatiotemporal cavitation activity to recorded radio-frequency signals accounting for time-of-flight delays defined by the acquisition geometry. A regularized inversion algorithm incorporating prior knowledge on cavitation activity is then formulated. Experimental results demonstrate that the framework outperforms classical beamforming methods, providing higher temporal resolution than frequency-domain techniques while substantially reducing computational burden compared with iterative time-domain formulations.",313.94,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07359v1_Seeing Right but Saying Wrong Inter- and Intra-Lay.pdf,Seeing Right but Saying Wrong: Inter- and Intra-Layer Refinement in MLLMs without Training,"['Shezheng Song', 'Shasha Li', 'Jie Yu']","Multimodal Large Language Models (MLLMs) have demonstrated strong capabilities across a variety of vision-language tasks. However, their internal reasoning often exhibits a critical inconsistency: although deeper layers may attend to the correct visual regions, final predictions are frequently misled by noisy attention from earlier layers. This results in a disconnect between what the model internally understands and what it ultimately expresses, a phenomenon described as 'seeing it right but saying it wrong.' To address this issue, the authors propose DualPD, a dual-perspective decoding refinement strategy that enhances the model's visual understanding without any additional training. DualPD consists of two components: a layer-wise attention-guided contrastive logits module and a head-wise information filtering module. Experiments conducted on both the LLaV A and Qwen-VL model families across multiple multimodal benchmarks demonstrate that DualPD consistently improves accuracy without training, confirming its effectiveness and generalizability.",315.08,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07364v1_On the universal definition of intelligence.pdf,On the universal definition of intelligence,['Joseph Chen'],"This paper proposes a universal definition of intelligence to enable fair and consistent comparison of human and artificial intelligence (AI). It introduces four criteria for evaluating intelligence definitions and examines six representative definitions. The results show that predictive ability-based definitions have high explanatory power and empirical feasibility but lack in explaining the relationship between predictions and behavior/benefits. The paper proposes the Extended Predictive Hypothesis (EPH), which views intelligence as a combination of accurate prediction and benefit from those predictions. By distinguishing predictive ability into spontaneous and reactive predictions and adding the concept of gainability, a unified framework is presented for explaining various aspects of intelligence. The EPH is argued to be the most satisfactory and universal definition for comparing human and AI intelligence.",315.8,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07372v1_Conditional Memory via Scalable Lookup A New Axis .pdf,Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models,"['Xin Cheng', 'Wangding Zeng', 'Damai Dai', 'Qinyu Chen', 'Bingxuan Wang', 'Zhenda Xie', 'Kezhao Huang', 'Xingkai Yu', 'Zhewen Hao', 'Yukun Li', 'Han Zhang', 'Huishuai Zhang', 'Dongyan Zhao', 'Wenfeng Liang']","This paper introduces conditional memory as a new sparsity axis for large language models (LLMs), complementing the existing Mixture-of-Experts (MoE) paradigm. Conditional memory is instantiated via Engram, a module that modernizes classic N-gram embedding for O(1) lookup. By formulating the Sparsity Allocation problem, the authors uncover a U-shaped scaling law that optimizes the trade-off between neural computation (MoE) and static memory (Engram). Scaling Engram to 27B parameters, the authors achieve superior performance over a strictly iso-parameter and iso-FLOPs MoE baseline. The paper demonstrates significant gains in general reasoning and code/math domains, and provides mechanistic analyses revealing how Engram relieves the backbone’s early layers from static reconstruction, effectively deepening the network for complex reasoning. Additionally, Engram frees up attention capacity for global context, boosting long-context retrieval. Finally, Engram establishes infrastructure-aware efficiency through deterministic addressing for runtime prefetching from host memory, incurring negligible overhead. The authors envision conditional memory as an indispensable modeling primitive for next-generation sparse models.",314.11,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07376v1_OpenTinker Separating Concerns in Agentic Reinforc.pdf,OpenTinker: Separating Concerns in Agentic Reinforcement Learning,"['Siqi Zhu', 'Jiaxuan You']","OpenTinker introduces an infrastructure for reinforcement learning of large language model agents, focusing on separating concerns across algorithm design, execution, and agent-environment interaction. It decomposes agentic learning systems into lightweight, composable components with clearly defined abstraction boundaries. Users specify agents, environments, and interaction protocols, while inference and training are delegated to a managed execution runtime. OpenTinker includes a centralized scheduler for managing training and inference workloads over shared resources. The paper discusses design principles for extending OpenTinker to multi-agent training and presents RL use cases demonstrating the framework's effectiveness in practical agentic learning scenarios.",315.77,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07377v1_Learning Dynamic Collaborative Network for Semi-su.pdf,Learning Dynamic Collaborative Network for Semi-supervised 3D Vessel Segmentation,"['Jiao Xu', 'Xin Chen']","In this paper, we present a new dynamic collaborative network (DiCo) for semi-supervised 3D vessel segmentation. Conventional mean teacher (MT) methods typically employ a static approach, where the roles of the teacher and student models are fixed. However, due to the complexity of 3D vessel data, the teacher model may not always outperform the student model, leading to cognitive biases that can limit performance. To address this issue, we propose a dynamic collaborative network that allows the two models to dynamically switch their teacher-student roles. Additionally, we introduce a multi-view integration module to capture various perspectives of the inputs, mirroring the way doctors conduct medical analysis. We also incorporate adversarial supervision to constrain the shape of the segmented vessels in unlabeled data. In this process, the 3D volume is projected into 2D views to mitigate the impact of label inconsistencies. Experiments demonstrate that our DiCo method sets new state-of-the-art performance on three 3D vessel segmentation benchmarks.",305.35,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07389v1_On the Non-decoupling of Supervised Fine-tuning an.pdf,On the Non-decoupling of Supervised Fine-tuning and Reinforcement Learning in Post-training,"['Xueyan Niuniuxueyan3@huawei.com', 'Bo Baibaibo8@huawei.com', 'Wei Hanharvey.hanwei@huawei.com', 'Weixi Zhangzhangweixi1@huawei.com']","Post-training of large language models often interleaves supervised fine-tuning (SFT) with reinforcement learning (RL). This paper proves that decoupling SFT and RL is impossible in either order. SFT-then-RL coupling leads to an increase in SFT loss, while RL-then-SFT coupling results in a lower reward achieved by RL. Experiments on Qwen3-0.6B confirm the predicted degradation, showing that SFT and RL cannot be separated without losing prior performance in the post-training pipeline.",316.18,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07392v1_OceanSAR-2 A Universal Feature Extractor for SAR O.pdf,OceanSAR-2: A Universal Feature Extractor for SAR Ocean Observation,"['Alexandre Tuela', 'Thomas Kerdreux', 'Quentin Febvre', 'Alexis Mouche', 'Antoine Grouazel', 'Jean-Renaud Miadana', 'Antoine Audras', 'Chen Wang', 'Bertrand Chapron']","We present OceanSAR-2, the second generation of our foundation model for SAR-based ocean observation. Building on our earlier release, which pioneered self-supervised learning on Sentinel-1 Wave Mode data, OceanSAR-2 relies on improved SSL training and dynamic data curation strategies, which enhances performance while reducing training cost. OceanSAR-2 demonstrates strong transfer performance across downstream tasks, including geophysical pattern classification, ocean surface wind vector and significant wave height estimation, and iceberg detection. We release standardized benchmark datasets, providing a foundation for systematic evaluation and advancement of SAR models for ocean applications.",315.11,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07393v1_Software-Hardware Co-optimization for Modular E2E .pdf,SOFTWARE-HARDWARECO-OPTIMIZATION FORMODULARE2E,"['Chengzhi Ji', 'Xingfeng Li', 'Zhaodong Lv', 'Hao Sun', 'Pan Liu', 'Hao Frank Yang', 'Ziyuan Pu']","This paper proposes a reusable software–hardware co-optimization and closed-loop evaluation framework for ME2E autonomous driving inference. The framework integrates software-level model optimizations with hardware-level computation optimizations under a unified system-level objective. A multidimensional evaluation metric, EERA V, is introduced to evaluate the ME2E autonomous driving system performance by jointly considering safety, comfort, efficiency, latency, and energy. The proposed framework preserves baseline-level accuracy while reducing inference latency by over 6× and per-frame energy to around one-fifth of the baseline. Additionally, a 22.35% improvement in the EERA V metric is achieved, validating the proposed framework's actionable optimization guidance from both software and hardware perspectives.",315.85,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07395v1_MCP-ITP An Automated Framework for Implicit Tool P.pdf,MCP-ITP: An Automated Framework for Implicit Tool Poisoning in MCP,"['Ruiqi Li', 'Zhiqiang Wang', 'Y unhao Y ao', 'Xiang-Y ang Li']","To standardize interactions between LLM-based agents and their environments, the Model Context Protocol (MCP) was proposed and has since been widely adopted. However, integrating external tools expands the attack surface, exposing agents to tool poisoning attacks. In such attacks, malicious instructions embedded in tool metadata are injected into the agent context during MCP registration phase, thereby manipulating agent behavior. Prior work primarily focuses on explicit tool poisoning or relies on manually crafted poisoned tools. In contrast, this paper focuses on a stealthy variant: implicit tool poisoning, where the poisoned tool itself remains uninvoked. Instead, the instructions embedded in the tool metadata induce the agent to invoke a legitimate but high-privilege tool to perform malicious operations. The paper proposes MCP-ITP, the first automated and adaptive framework for implicit tool poisoning within the MCP ecosystem. MCP-ITP formulates poisoned tool generation as a black-box optimization problem and employs an iterative optimization strategy that leverages feedback from both an evaluation LLM and a detection LLM to maximize Attack Success Rate (ASR) while evading current detection mechanisms. Experimental results on the MCPTox dataset across 12 LLM agents demonstrate that MCP-ITP consistently outperforms the manually crafted baseline, achieving up to 84.2% ASR while suppressing the Malicious Tool Detection Rate (MDR) to as low as 0.3%.",314.08,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07397v1_Layerwise goal-oriented adaptivity for neural ODEs.pdf,Layerwise goal-oriented adaptivity for neural ODEs: an optimal control perspective,"['Michael Hintermüllüter…', 'Michael Hinze …', 'Denis Korolev …']","In this work, the authors propose a novel layerwise adaptive construction method for neural network architectures. Their approach is based on a goal-oriented dual-weighted residual technique for the optimal control of neural differential equations. This leads to an optimization problem with controls acting as coefficients and a specific loss function. The method is implemented using a DG(0) Galerkin discretization of the neural ODE, leading to an explicit Euler time marching scheme. For optimization, they use steepest descent. The authors apply their method to the construction of neural networks for data set classification, presenting results for selected examples from the literature.",316.22,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07411v1_SCALPEL Selective Capability Ablation via Low-rank.pdf,SCALPEL: Selective Capability Ablation via Low-rank Parameter Editing for Large language models,"['Zihao Fu', 'Xufeng Duan', 'Zhenguang G. Cai']","SCALPEL is a framework that represents capabilities as low-rank parameter subspaces rather than discrete modules. It identifies the low-rank representation responsible for a particular capability while remaining disentangled from other capabilities. Experiments across diverse capability tasks and linguistic tasks demonstrate that SCALPEL successfully removes target capabilities while preserving other general capabilities, providing fine-grained insights into how capabilities are distributed across the model's parameter space.",316.55,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07422v1_Two Pathways to Truthfulness On the Intrinsic Enco.pdf,Two Pathways to Truthfulness: On the Intrinsic Encoding of LLM Hallucinations,"['Wen Luo', 'Guangyue Peng', 'Wei Li', 'Shaohang Wei', 'Feifan Song', 'Liang Wang', 'Nan Yang', 'Xingxing Zhang', 'Jing Jin', 'Furu Wei', 'Houfeng Wang']","Despite impressive capabilities, large language models (LLMs) frequently generate hallucinations. Previous work shows that their internal states encode rich signals of truthfulness, yet the origins and mechanisms of these signals remain unclear. This paper demonstrates that truthfulness cues arise from two distinct information pathways: (1) a Question-Anchored pathway that depends on question-answer information flow, and (2) an Answer-Anchored pathway that derives self-contained evidence from the generated answer itself. The paper validates and disentangles these pathways through attention knockout and token patching, uncovering notable and intriguing properties of these mechanisms. It also reveals that the two mechanisms are closely associated with LLM knowledge boundaries and that internal representations are aware of their distinctions. Finally, the paper proposes two applications to enhance hallucination detection performance, providing new insight into how LLMs internally encode truthfulness.",314.02,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07430v1_KALE Enhancing Knowledge Manipulation in Large Lan.pdf,KALE: Enhancing Knowledge Manipulation in Large Language Models via Knowledge-aware Learning,"['Qitan Lv', 'Tianyu Liu', 'Qiaosheng Zhang', 'Xingcheng Xu', 'Chaochao Lu']","Despite the impressive performance of large language models (LLMs) pretrained on vast knowledge corpora, advancing their knowledge manipulation—the ability to effectively recall, reason, and transfer relevant knowledge—remains challenging. Existing methods mainly leverage Supervised Fine-Tuning (SFT) on labeled datasets to enhance LLMs’ knowledge manipulation ability. However, we observe that SFT models still exhibit the known&incorrect phenomenon, where they explicitly possess relevant knowledge for a given question but fail to leverage it for correct answers. To address this challenge, we propose KALE (Knowledge-Aware LEarning)—a post-training framework that leverages knowledge graphs (KGs) to generate high-quality rationales and enhance LLMs’ knowledge manipulation ability. Specifically, KALE first introduces a Knowledge-Induced (KI) data synthesis method that efficiently extracts multi-hop reasoning paths from KGs to generate high-quality rationales for question-answer pairs. Then, KALE employs a Knowledge-Aware (KA) fine-tuning paradigm that enhances knowledge manipulation by internalizing rationale-guided reasoning through minimizing the KL divergence between predictions with and without rationales. Extensive experiments on eight popular benchmarks across six different LLMs demonstrate the effectiveness of KALE, achieving accuracy improvements of up to 11.72% and an average of 4.18%.",314.13,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07449v1_RLPO Residual Listwise Preference Optimization for.pdf,RLPO: Residual Listwise Preference Optimization for Long-Context Review Ranking,"['Hao Jiang', 'Zhi Yang', 'Annan Wang', 'Yichi Zhang', 'Weisi Lin*']","Review ranking is crucial in e-commerce for prioritizing user-generated feedback. While large language models have improved semantic assessment, existing ranking paradigms face a trade-off in long-context settings. Pointwise scoring is efficient but often fails to account for list-level interactions, leading to miscalibrated top-k rankings. Listwise approaches leverage global context but are computationally expensive and unstable. To address this, the authors propose Residual Listwise Preference Optimization (RLPO), which formulates ranking as listwise representation-level residual correction over a strong pointwise LLM scorer. RLPO first produces calibrated pointwise scores and item representations, then applies a lightweight encoder to predict listwise score residuals, avoiding full token-level listwise processing. The paper introduces a large-scale benchmark for long-context review ranking with human verification. Experiments show RLPO improves NDCG@k over strong pointwise and listwise baselines and remains robust as list length increases.",313.68,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07463v1_Puzzle it Out Local-to-Global World Model for Offl.pdf,Puzzle it Out: Local-to-Global World Model for Offline Multi-Agent Reinforcement Learning,"['Sijia Li', 'Xinran Li', 'Shibo Chen', 'Jun Zhang']","Offline multi-agent reinforcement learning (MARL) aims to solve cooperative decision-making problems in multi-agent systems using pre-collected datasets. Existing methods primarily constrain training within the dataset distribution, leading to overly conservative policies that struggle to generalize. Model-based approaches offer a promising solution by expanding the original dataset with synthetic data generated from a learned world model. However, accurately estimating transitions and reward functions in multi-agent systems is challenging. This paper proposes a local-to-global (LOGO) world model, a novel framework that leverages local predictions to infer global state dynamics, improving prediction accuracy while implicitly capturing agent-wise dependencies. The trained world model generates synthetic data to augment the original dataset, expanding the effective state-action space. An uncertainty-aware sampling mechanism is introduced to adaptively weight synthetic data by prediction uncertainty, reducing approximation error propagation to policies. The approach requires only an additional encoder for uncertainty estimation, significantly reducing computational overhead while maintaining accuracy. Extensive experiments across 8 scenarios against 8 baselines demonstrate that the method surpasses state-of-the-art baselines on standard offline MARL benchmarks, establishing a new model-based baseline for generalizable offline multi-agent learning.",313.78,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07464v1_IFDNS An Iterative Feedback-Driven Neuro-Symbolic .pdf,IFDNS: An Iterative Feedback-Driven Neuro-Symbolic Method for Faithful Logical Reasoning,"['Xiaoheng Wang', 'Tongxuan Liu', 'Zi Gong', 'Xianzhe Dong', 'Yuting Zeng', 'Minhan Hu', 'Weizhe Huang', 'Jing Li']","Large language models (LLMs) have demonstrated impressive capabilities across a wide range of reasoning tasks, including logical and mathematical problem-solving. While prompt-based methods like Chain-of-Thought (CoT) can enhance LLM reasoning abilities to some extent, they often suffer from a lack of faithfulness, where the derived conclusions may not align with the generated reasoning chain. To address this issue, researchers have explored neuro-symbolic approaches to bolster LLM logical reasoning capabilities. However, existing neuro-symbolic methods still face challenges with information loss during the process. To overcome these limitations, we introduce Iterative Feedback-Driven Neuro-Symbolic (IFDNS), a novel prompt-based method that employs a multi-round feedback mechanism to address LLM limitations in handling complex logical relationships. IFDNS utilizes iterative feedback during the logic extraction phase to accurately extract causal relationship statements and translate them into propositional and logical implication expressions, effectively mitigating information loss issues. Furthermore, IFDNS is orthogonal to existing prompt methods, allowing for seamless integration with various prompting approaches. Empirical evaluations across six datasets demonstrate the effectiveness of IFDNS in significantly improving the performance of CoT and Chain-of-Thought with Self-Consistency (CoT-SC). Specifically, IFDNS achieves a +9.40% accuracy boost for CoT on the LogiQA dataset and a +11.70% improvement for CoT-SC on the PrOntoQA dataset.",313.52,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07468v1_Beyond Dialogue Time Temporal Semantic Memory for .pdf,Beyond Dialogue Time: Temporal Semantic Memory for Personalized LLM Agents,"['Miao Su', 'Yucan Guo', 'Zhongni Hou', 'Long Bai', 'Zixuan Li', 'Yufei Zhang', 'Guojun Yin', 'Wei Lin', 'Xiaolong Jin', 'Jiafeng Guo', 'Xueqi Cheng']","Memory enables Large Language Model (LLM) agents to perceive, store, and use information from past dialogues, which is essential for personalization. However, existing methods fail to properly model the temporal dimension of memory in two aspects: 1) Temporal inaccuracy: memories are organized by dialogue time rather than their actual occurrence time; 2) Temporal fragmentation: existing methods focus on point-wise memory, losing durative information that captures persistent states and evolving patterns. To address these limitations, we propose Temporal Semantic Memory (TSM), a memory framework that models semantic time for point-wise memory and supports the construction and utilization of durative memory. During memory construction, it first builds a semantic timeline rather than a dialogue one. Then, it consolidates temporally continuous and semantically related information into a durative memory. During memory utilization, it incorporates the query’s temporal intent on the semantic timeline, enabling the retrieval of temporally appropriate durative memories and providing time-valid, duration-consistent context to support response generation. Experiments on LONGMEMEVAL and LOCOMO show that TSM consistently outperforms existing methods and achieves up to 12.2% absolute improvement in accuracy, demonstrating the effectiveness of the proposed method.",314.15,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07469v1_Knowledge Distillation for LLM-Based Human Activit.pdf,KNOWLEDGE DISTILLATION FOR LLM-B ASED HUMAN ACTIVITY RECOGNITION IN HOMES,"['Julien Cumin', 'Oussama Er-Rahmany', 'Xi Chen']","Human Activity Recognition (HAR) in homes based on sensor data has been a long-standing subject of research. A few recent studies have shown that Large Language Models (LLMs) can be used for HAR at home, reaching high performance and addressing key challenges. This paper provides new experimental results regarding the use of LLMs for HAR, on two state-of-the-art datasets. It shows how recognition performance evolves depending on the size of the LLM used and experiments on the use of knowledge distillation techniques to fine-tune smaller LLMs with HAR reasoning examples generated by larger LLMs. The fine-tuned models can perform almost as well as the largest LLMs, while having 50 times fewer parameters.",313.97,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07470v1_Learning How to Remember A Meta-Cognitive Manageme.pdf,Learning How to Remember: A Meta-Cognitive Management Method for Structured and Transferable Agent Memory,"['Sirui Liang', 'Pengfei Cao', 'Jian Zhao', 'Wenhao Teng', 'Xiangwen Liao', 'Jun Zhao', 'Kang Liu']","This paper proposes the Meta-Cognitive Memory Abstraction (MCMA) method, which treats memory abstraction as a learnable cognitive skill. MCMA decouples task execution from memory management by combining a frozen task model with a learned memory copilot. The memory copilot is trained using direct preference optimization to determine how memories should be structured, abstracted, and reused. Memories are organized into a hierarchy of abstraction levels, enabling selective reuse based on task similarity. When no memory is transferable, MCMA transfers the ability to abstract and manage memory by transferring the memory copilot. Experiments on ALFWorld, ScienceWorld, and BabyAI demonstrate substantial improvements in performance, out-of-distribution generalization, and cross-task transfer over several baselines.",314.02,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07474v1_Task Prototype-Based Knowledge Retrieval for Multi.pdf,Task Prototype-Based Knowledge Retrieval for Multi-Task Learning from Partially Annotated Data,"['Y oungmin Oh', 'Hyung-Il Kim', 'Jung Uk Kim']","Multi-task learning (MTL) is critical in real-world applications such as autonomous driving and robotics, but obtaining fully annotated data for all tasks is impractical due to labeling costs. Existing methods for partially labeled MTL typically rely on predictions from unlabeled tasks, leading to unreliable task associations and potentially negative transfer. This paper proposes a prototype-based knowledge retrieval framework that achieves robust MTL by consistently capturing task-specific characteristics and adaptively refining feature representations based on these associations. Extensive experiments demonstrate the effectiveness of the proposed framework, highlighting its potential for robust multi-task learning even when only a subset of tasks is annotated.",313.5,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07475v1_ARCQuant Boosting NVFP4 Quantization with Augmente.pdf,ARCQuant: Boosting NVFP4 Quantization with Augmented Residual Channels for LLMs,"['Haoqian Meng', 'Yilun Luo', 'Yafei Zhao', 'Wenyuan Liu', 'Peng Zhang*']","The emergence of fine-grained numerical formats like NVFP4 presents new opportunities for efficient Large Language Model (LLM) inference. However, adapting existing Post-Training Quantization (PTQ) strategies to these formats is challenging. This paper proposes ARCQuant, a framework that boosts NVFP4 performance via Augmented Residual Channels. Unlike methods that compromise block isolation or hardware uniformity, ARCQuant maintains a strictly unified NVFP4 format by augmenting the activation matrix with quantized residual channels. This design integrates the error compensation process directly into the matrix reduction dimension, enabling the use of standard, highly optimized GEMM kernels with minimal overhead. Extensive experiments on LLaMA and Qwen models demonstrate that ARCQuant achieves state-of-the-art accuracy, comparable to full-precision base lines in perplexity and downstream tasks. Deployment on RTX 5090 and RTX PRO 6000 GPUs confirms practical benefits, achieving up to 3× speedup over FP16.",313.58,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07477v1_JudgeFlow Agentic Workflow Optimization via Block .pdf,JUDGEFLOW: AGENTICWORKFLOWOPTIMIZATION,"['Zihan Ma∗', 'Zhikai Zhao∗', 'Chuanbo Hua', 'Federico Berto', 'Jinkyoo Park']","Optimizing LLM-based agentic workflows is challenging due to the lack of fine-grained signals for refinement. To address this, the authors propose JUDGEFLOW, an Evaluation-Judge-Optimization-Update pipeline. JUDGEFLOW incorporates reusable, configurable logic blocks and a dedicated Judge module that assigns rank-based responsibility scores to problematic blocks based on execution traces. This approach improves sample efficiency, enhances interpretability through block-level diagnostics, and provides a scalable foundation for automating complex agentic workflows. The authors evaluate JUDGEFLOW on mathematical reasoning and code generation benchmarks, achieving superior performance and efficiency compared to existing methods. The source code is publicly available at https://github.com/ma-zihan/JudgeFlow.",314.21,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07496v1_Graph Inference Towards ICD Coding.pdf,Graph Inference Towards ICD Coding,['1st Xiaoxiao Deng'],"Automated ICD coding involves assigning standardized diagnostic codes to clinical narratives. The vast label space and extreme class imbalance continue to challenge precise prediction. LabGraph is introduced—a unified framework that reformulates ICD coding as a graph generation task. By combining adversarial domain adaptation, graph-based reinforcement learning, and perturbation regularization, LabGraph effectively enhances model robustness and generalization. Experiments on benchmark datasets demonstrate that LabGraph consistently outperforms previous approaches on micro-F1, micro-AUC, and P@K.",314.29,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07514v1_Data-Driven Stochastic VRP Integration of Forecast.pdf,Data-Driven Stochastic VRP: Integration of Forecast Duration into Optimization for Utility Workforce Management,['Matteo Garbellia'],"This paper investigates the integration of machine learning forecasts of intervention durations into a stochastic variant of the Capacitated Vehicle Routing Problem with Time Windows (CVRPTW). Specifically, it uses tree-based gradient boosting (XGBoost) trained on eight years of gas meter maintenance data to produce point predictions and uncertainty estimates, which drive a multi-objective evolutionary optimization routine. The methodology addresses uncertainty through sub-Gaussian concentration bounds for route-level risk buffers and explicitly accounts for competing operational KPIs through a multi-objective formulation. Empirical analysis of prediction residuals validates the sub-Gaussian assumption underlying the risk model. The results report improvements around 20-25% in operator utilization and completion rates compared with plans computed using default durations. The integration of uncertainty quantification and risk-aware optimization provides a practical framework for handling stochastic service durations in real-world routing applications.",315.64,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07516v1_Controlling Multimodal Conversational Agents with .pdf,Controlling Multimodal Conversational Agents with Coverage-Enhanced Latent Actions,"['Yongqi Li', 'Hao Lang', 'Tieyun Qian', 'Yongbin Li']","Vision-language models are increasingly employed as multimodal conversational agents (MCAs) for various conversation tasks. Recently, reinforcement learning (RL) has been widely explored for adapting MCAs to diverse human-AI interaction scenarios. Despite showing great enhancement in generalization performance, fine-tuning MCAs via RL still faces challenges in handling the extremely large text token space. To address this, the authors learn a compact latent action space for RL fine-tuning instead, using the learning from observation mechanism to construct the codebook for the latent action space. They leverage both paired image-text data and text-only data to construct the latent action space, using a cross-modal projector for transforming text embeddings into image-text embeddings. They initialize the cross-modal projector on paired image-text data and further train it on massive text-only data with a novel cycle consistency loss to enhance its robustness. The authors show that their latent action-based method outperforms competitive baselines on two conversation tasks across various RL algorithms.",313.81,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07518v1_Mon3tr Monocular 3D Telepresence with Pre-built Ga.pdf,Mon3tr: Monocular 3D Telepresence with Pre-built Gaussian Avatars as Amortization,"['Fangyu Lin', 'Yingdong Hu', 'Zhening Liu', 'Yufan Zhuang', 'Zehong Lin', 'Jun Zhang']","Mon3tr is a novel Monocular 3D telepresence framework that integrates 3D Gaussian splatting (3DGS) based parametric human modeling into telepresence for the first time. It adopts an amortized computation strategy, dividing the process into a one-time offline multi-view reconstruction phase to build a user-specific avatar and a monocular online inference phase during live telepresence sessions. A single monocular RGB camera captures body motions and facial expressions in real time to drive the 3DGS-based parametric human model, significantly reducing system complexity and cost. The extracted motion and appearance features are transmitted at <0.2 Mbps over WebRTC's data channel, allowing robust adaptation to network fluctuations. On the receiver side, a lightweight 3DGS attribute deformation network dynamically generates corrective 3DGS attribute adjustments on the pre-built avatar, synthesizing photorealistic motion and appearance at ∼60 FPS. Extensive experiments demonstrate the state-of-the-art performance of our method, achieving a PSNR of >28 dB for novel poses, an end-to-end latency of ∼80 ms, and >1000× bandwidth reduction compared to point-cloud streaming, while supporting real-time operation from monocular inputs across diverse scenarios.",314.05,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07525v1_Thinking Before Constraining A Unified Decoding Fr.pdf,Thinking Before Constraining: A Unified Decoding Framework for Large Language Models,"['Ngoc Trinh Hung Nguyen', 'Alonso Silva', 'Laith Zumot', 'Liubov Tupikina', 'Armen Aghasaryan', 'Mehwish Alam']","Natural generation allows Language Models (LMs) to produce free-form responses with rich reasoning, but the lack of guaranteed structure makes outputs difficult to parse or verify. Structured generation, or constrained decoding, addresses this drawback by producing content in standardized formats such as JSON, ensuring consistency and guaranteed-parsable outputs, but it can inadvertently restrict the model’s reasoning capabilities. In this work, we propose a simple approach that combines the advantages of both natural and structured generation. By allowing LLMs to reason freely until specific trigger tokens are generated, and then switching to structured generation, our method preserves the expressive power of natural language reasoning while ensuring the reliability of structured outputs. We further evaluate our approach on several datasets, covering both classification and reasoning tasks, to demonstrate its effectiveness, achieving a substantial gain of up to 27% in accuracy compared to natural generation, while requiring only a small overhead of 10–20 extra tokens. Our code and results are available online.",314.01,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07528v1_From RAG to Agentic RAG for Faithful Islamic Quest.pdf,From RAG to Agentic RAG for Faithful Islamic Question Answering,"['Gagan Bhatia', 'Hamdy Mubarak', 'Mustafa Jarrar', 'George Mikros', 'Fadi Zaraket', 'Mahmoud Alhirthani', 'Mutaz Al-Khatib', 'Logan Cochrane', 'Kareem Darwish', 'Rashid Yahiaoui', 'Firoj Alam']","This paper introduces ISLAMIC FAITH QA, a 3,810-item bilingual generative benchmark for Islamic question answering. It also develops an agentic Quran-grounding framework (agentic RAG) that uses structured tool calls for iterative evidence seeking and answer revision. Experiments show that retrieval improves correctness and agentic RAG yields the largest gains beyond standard RAG, achieving state-of-the-art performance and stronger Arabic-English robustness even with a small model (i.e., Qwen3 4B). The authors will make the experimental resources and datasets publicly available for the community.",314.26,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07553v1_VirtualEnv A Platform for Embodied AI Research.pdf,VirtualEnv: A Platform for Embodied AI Research,"['Kabir Swain', 'Sijie Han', 'Ayush Raina', 'Jin Zhang', 'Shuang Li', 'Michael Stopa', 'Antonio Torralba']","VirtualEnv is a next-generation simulation platform built on Unreal Engine 5 designed to enable fine-grained benchmarking of large language models (LLMs) in embodied and interactive scenarios. It supports rich agent-environment interactions including object manipulation, navigation, and adaptive multi-agent collaboration. The platform integrates large-scale LLMs and vision-language models (VLMs) to generate novel environments and structured tasks from multimodal inputs. Experiments benchmark the performance of several popular LLMs across tasks of increasing complexity, analyzing differences in adaptability, planning, and multi-agent coordination. VirtualEnv is released as an open-source platform, aiming to advance research at the intersection of AI and gaming, enable standardized evaluation of LLMs in embodied AI settings, and pave the way for future developments in immersive simulations and interactive entertainment.",313.85,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07556v1_Backpropagation-Free Test-Time Adaptation for Ligh.pdf,Backpropagation-Free Test-Time Adaptation for Lightweight EEG-Based Brain-Computer Interfaces,"['Siyang Li', 'Jiayi Ouyang', 'Zhenyao Cui', 'Ziwei Wang', 'Tianwang Jia', 'Feng Wan', 'Dongrui Wu']","Electroencephalogram (EEG)-based brain-computer interfaces (BCIs) face significant deployment challenges due to inter-subject variability, signal non-stationarity, and computational constraints. Existing test-time adaptation (TTA) approaches heavily rely on explicitly defined loss objectives that require backpropagation for updating model parameters, which incurs computational overhead, privacy risks, and sensitivity to noisy data streams. This paper proposes Backpropagation-Free Transformations (BFT), a TTA approach for EEG decoding that eliminates these issues. BFT applies multiple sample-wise transformations of knowledge-guided augmentations or approximate Bayesian inference to each test trial, generating multiple prediction scores for a single test sample. A learning-to-rank module enhances the weighting of these predictions, enabling robust aggregation for uncertainty suppression during inference under theoretical justifications. Extensive experiments on five EEG datasets of motor imagery classification and driver drowsiness regression tasks demonstrate the effectiveness, versatility, robustness, and efficiency of BFT. This research enables lightweight plug-and-play BCIs on resource-constrained devices, broadening the real-world deployment of decoding algorithms for EEG-based BCIs.",314.18,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07565v1_A Unified Framework for Emotion Recognition and Se.pdf,A Unified Framework for Emotion Recognition and Sentiment Analysis via Expert-Guided Multimodal Fusion with Large Language Models,"['Jiaqi Qiao', 'Xiujuan Xu', 'Xinran Li', 'Yu Liu']","We present EGMF, a unified framework combining expert-guided multimodal fusion with large language models. Our approach features three specialized expert networks—fine-grained local expert for subtle emotional nuances, semantic correlation expert for cross-modal relationships, and global context expert for long-range dependencies—adaptively integrated through hierarchical dynamic gating for context-aware feature selection. Enhanced multimodal representations are integrated with LLMs via pseudo token injection and prompt-based conditioning, enabling a single generative framework to handle both classification and regression through natural language generation. We employ LoRA fine-tuning for computational efficiency. Experiments on bilingual benchmarks (MELD, CHERMA, MOSEI, SIMS-V2) demonstrate consistent improvements over state-of-the-art methods, with superior cross-lingual robustness revealing universal patterns in multimodal emotional expressions across English and Chinese. We will release the source code publicly.",315.13,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07568v1_d3LLM Ultra-Fast Diffusion LLM using Pseudo-Trajec.pdf,Ultra-Fast dLLM using Pseudo-Trajectory Distillation,"['Yu-Yang Qian', 'Junda Su', 'Lanxiang Hu', 'Peiyuan Zhang', 'Zhijie Deng', 'Peng Zhao', 'Hao Zhang']","Diffusion large language models (dLLMs) offer capabilities beyond autoregressive (AR) LLMs, such as parallel decoding and random-order generation. However, realizing these benefits in practice is non-trivial, as dLLMs inherently face an accuracy-parallelism trade-off. This paper proposes d3LLM (Pseudo-Distilled Diffusion Large Language Model), which strikes a balance between accuracy and parallelism by introducing pseudo-trajectory distillation during training and entropy-based multi-block decoding during inference. The authors introduce AUP (Accuracy Under Parallelism) as a new metric to jointly measure accuracy and parallelism. Experiments demonstrate that d3LLM achieves up to 10× speedup over vanilla LLaDA/Dream and 5× speedup over AR models without much accuracy drop.",314.11,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07573v1_A Model of Artificial Jagged Intelligence.pdf,A Model of Artificial Jagged Intelligence,['Joshua S. Gans'],"Generative AI systems often display highly uneven performance across tasks that appear 'nearby'. This paper develops a tractable economic model of Artificial Jagged Intelligence (AJI) that treats adoption as an information problem. Users care about local reliability, but typically observe only coarse, global quality signals. The model interpolates optimally, and the local error is measured by posterior variance. The paper derives an adoption threshold for a blind user, shows that experienced errors are amplified by the inspection paradox, and interprets scaling laws as denser coverage that improves average quality without eliminating jaggedness. It also studies mastery and calibration, where a calibrated user enjoys positive expected value even in domains that fail the blind adoption test. Modelling mastery as learning a reliability map via Gaussian process regression yields a learning-rate bound driven by information gain, clarifying when discovering 'where the model works' is slow. Finally, the paper explores how scaling interacts with discoverability, showing that calibrated signals and user mastery can accelerate the harvesting of scale improvements, and that opacity can make gains from scaling effectively invisible.",316.09,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07577v1_Beyond Entangled Planning Task-Decoupled Planning .pdf,Beyond Entangled Planning: Task-Decoupled Planning for Long-Horizon Agents,"['Yunfan Li', 'Bingbing Xu', 'Xueyun Tian', 'Xiucheng Xu', 'Huawei Shen']","Recent advances in large language models have enabled agents to autonomously execute complex, long-horizon tasks. However, planning remains a bottleneck. Existing methods typically fall into two paradigms: step-wise planning, which is reactive but often short-sighted, and one-shot planning, which generates a complete plan upfront but is brittle to execution errors. Crucially, both paradigms suffer from entangled contexts, where the agent must reason over a monolithic history spanning multiple sub-tasks. This entanglement increases cognitive load and allows local errors to propagate across otherwise independent decisions, making recovery computationally expensive. To address this, we propose Task-Decoupled Planning (TDP), a training-free framework that replaces entangled reasoning with task decoupling. TDP decomposes tasks into a directed acyclic graph (DAG) of sub-goals via a Supervisor. Using a Planner and Executor with scoped contexts, TDP confines reasoning and replanning to the active sub-task. This isolation prevents error propagation and corrects deviations locally without disrupting the workflow. Results on TravelPlanner, ScienceWorld, and HotpotQA show that TDP outperforms strong baselines while reducing token consumption by up to 82%, demonstrating that sub-task decoupling improves both robustness and efficiency for long-horizon agents.",313.72,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07580v1_Large Language Models for Physics Instrument Desig.pdf,Large Language Models for Physics Instrument Design,"['Sara Zoccheddu∗1', 'Shah Rukh Qasim1', 'Patrick Owen2', 'Nicola Serra1']","This paper explores the use of large language models (LLMs) for physics instrument design and compares their performance to reinforcement learning (RL). Using only prompting, LLMs are given task constraints and summaries of prior high-scoring designs and propose complete detector configurations. The authors find that modern LLMs consistently generate valid, resource-aware, and physically meaningful configurations that draw on broad pretrained knowledge of detector design principles and particle–matter interactions, despite having no task-specific training. The paper argues that LLMs are well suited as meta-planners, capable of designing and orchestrating RL-based optimization studies, defining search strategies, and coordinating multiple interacting components within a unified workflow. As a first step toward hybrid design workflows, the authors explore pairing LLMs with a dedicated trust region optimizer, serving as a precursor to future pipelines in which LLMs propose and structure design hypotheses while RL performs reward-driven optimization.",315.73,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07582v2_ES-Mem Event Segmentation-Based Memory for Long-Te.pdf,ES-Mem: Event Segmentation-Based Memory for Long-Term Dialogue Agents,"['Huhai Zou', 'Tianhao Sun†', 'Chuanjiang He', 'Yu Tian', 'Zhenyang Li', 'Li Jin', 'Nayu Liu', 'Jiang Zhong', 'Kaiwen Wei†']","Memory is critical for dialogue agents to maintain coherence and enable continuous adaptation in long-term interactions. Existing memory mechanisms offer basic storage and retrieval capabilities but are hindered by rigid memory granularity and flat retrieval paradigms. ES-Mem, a framework incorporating dynamic event segmentation and boundary-anchored retrieval, mitigates these limitations. Evaluations on memory benchmarks demonstrate consistent performance gains over baseline methods. The dynamic event segmentation module exhibits robust applicability on dialogue segmentation datasets.",313.97,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07597v1_Pheromone-Focused Ant Colony Optimization algorith.pdf,Pheromone-Focused Ant Colony Optimization algorithm for path planning,"['Yi Liu', 'Hongda Zhang', 'Zhongxue Gan', 'Yuning Chen', 'Ziqing Zhou', 'Chunlei Meng', 'Chun Ouyang']","Ant Colony Optimization (ACO) algorithms are inspired by the cooperative foraging behavior of ants and are widely applied to path planning. However, traditional ACO methods often exhibit short-comings such as blind search behavior and slow convergence within complex environments. This paper proposes the Pheromone-Focused Ant Colony Optimization (PFACO) algorithm, which introduces three key strategies to enhance the problem-solving ability of the ant colony. These strategies include concentrating the initial pheromone distribution in more promising regions based on Euclidean distances, reinforcing promising solutions during colony iterations, and implementing a forward-looking mechanism to penalize redundant path turns. These strategies collectively produce focused pheromones to guide the ant colony's search, enhancing the global optimization capabilities of the PFACO algorithm and significantly improving convergence speed and solution quality across diverse optimization problems. Experimental results demonstrate that PFACO consistently outperforms comparative ACO algorithms in terms of convergence speed and solution quality.",315.13,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07606v1_Proof of Time A Benchmark for Evaluating Scientifi.pdf,Proof of Time: A Benchmark for Evaluating Scientific Idea Judgments,"['Bingyang Ye1,2†', 'Shan Chen1,2,3†', 'Jingxuan Tu4', 'Chen Liu5', 'Zidi Xiong1', 'Samuel Schmidgall6', 'Danielle S. Bitterman1,2,3§']","Large language models are increasingly being used to assess and forecast research ideas, yet we lack scalable ways to evaluate the quality of models' judgments. To address this, we introduce Proof of Time (PoT), a semi-verifiable benchmarking framework that links scientific idea judgments to downstream signals that become observable later. PoT freezes a pre-cutoff snapshot of evidence in an offline sandbox and asks models to forecast post-cutoff outcomes, enabling verifiable evaluation when ground truth arrives, scalable benchmarking without exhaustive expert annotation, and analysis of human–model misalignment against signals such as peer-review awards. Across 30K+ instances spanning four benchmark domains, we find that higher interaction budgets generally improve agentic performance, while the benefit of tool use is strongly task dependent. By combining time-partitioned, future-verifiable targets with an offline sandbox for tool use, PoT supports scalable evaluation of agents on future-facing scientific idea judgment tasks.",313.74,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07611v1_DIAGPaper Diagnosing Valid and Specific Weaknesses.pdf,DIAGPaper: Diagnosing Valid and Specific Weaknesses in Scientific Papers via Multi-Agent Reasoning,"['Zhuoyang Zou', 'Abolfazl Ansari', 'Delvin Ce Zhang†', 'Dongwon Lee', 'Wenpeng Yin']","DIAGPaper is a novel multi-agent framework that addresses the limitations of existing approaches to identifying weaknesses in scientific papers. It integrates three tightly integrated modules: the Customizer module simulates human-defined review criteria and instantiates multiple reviewer agents with criterion-specific expertise; the Rebuttal module introduces author agents that engage in structured debate with reviewer agents to validate and refine proposed weaknesses; and the Prioritizer module learns from large-scale human review practices to assess the severity of validated weaknesses and surfaces the top-K severest ones to users. Experiments on two benchmarks, AAAR and ReviewCritique, demonstrate that DIAGPaper substantially outperforms existing methods by producing more valid and more paper-specific weaknesses, while presenting them in a user-oriented, prioritized manner.",314.73,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07618v1_Neural Architecture for Fast and Reliable Coagulat.pdf,Neural Architecture for Fast and Reliable Coagulation Assessment in Clinical Settings: Leveraging Thromboelastography,"['Yulu Wang', 'Ziqian Zeng', 'Jianjun Wu', 'Zhifeng Tang†']","Presenting Physiological State Reconstruction (PSR), a new algorithm designed to leverage dynamic changes between individuals and maximize useful information from small amounts of clinical data. The authors develop MDFE to integrate varied temporal signals using multi-domain learning and jointly learn high-level temporal interactions with attention mechanisms. PSR evaluates with 4 TEG-specialized data sets, achieving remarkable performance with R2 > 0.98 for coagulation traits and half the error compared to state-of-the-art methods, and halving the inference time. Drift-aware learning suggests a new future, with potential applications beyond thrombophilia discovery towards medical AI with data scarcity.",314.66,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07632v2_GeoMotionGPT Geometry-Aligned Motion Understanding.pdf,GeoMotionGPT: Geometry-Aligned Motion Understanding with Large Language Models,"['Zhankai Ye', 'Bofan Li', 'Yukai Jin', 'Shuoqiu Li', 'Wei Wang', 'Yanfu Zhang', 'Shangqian Gao', 'Xin Liu']","GeoMotionGPT presents a novel framework that explicitly enforces orthogonality on both the motion codebook and the Large Language Model (LLM) embedding space, ensuring that their relational structures naturally mirror each other. This approach bridges the modalities by using a sparse projection that maps motion codes into the LLM embedding space while preserving orthogonality. The framework achieves a 20% performance improvement over current state-of-the-art methods on HumanML3D, validating that a unified geometric basis effectively empowers the LLM for nuanced motion reasoning.",313.87,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07635v2_Learning About Learning A Physics Path from Spin G.pdf,Learning About Learning: A Physics Path from Spin Glasses to Artificial Intelligence,"['Denis D. Caprioti', 'Matheus Haas', 'Constantino F. Vasconcelos', 'Mauricio Girardi-Schappo']","The Hopfield model, originally inspired by spin-glass physics, occupies a central place at the intersection of statistical mechanics, neural networks, and modern artificial intelligence. Despite its conceptual simplicity and broad applicability, it is rarely integrated into standard undergraduate physics curricula. This paper presents the Hopfield model as a pedagogically rich framework that naturally unifies core topics from undergraduate statistical physics, dynamical systems, linear algebra, and computational methods. It provides a concise and illustrated theoretical introduction grounded in familiar physics concepts, analyzes the model's energy function, dynamics, and pattern stability, and discusses practical aspects of simulation, including a freely available simulation code. The work aims to help prepare physics students to understand, apply, and critically engage with computational tools increasingly central to research, industry, and society.",314.04,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07638v1_SALT-KG A Benchmark for Semantics-Aware Learning o.pdf,SALT-KG: A Benchmark for Semantics-Aware Learning on Enterprise Tables,"['Isaiah Onando Mulang’', 'Felix Sasaki', 'Tassilo Klein', 'Jonas Kolk', 'Nikolay Grechanov', 'Johannes Hoffart']","Building upon the SALT benchmark for relational prediction, this paper introduces SALT-KG, a benchmark for semantics-aware learning on enterprise tables. SALT-KG extends SALT by linking its multi-table transactional data with a structured Operational Business Knowledge represented in a Metadata Knowledge Graph (OBKG) that captures field-level descriptions, relational dependencies, and business object-types. This extension enables evaluation of models that jointly reason over tabular evidence and contextual semantics—an increasingly critical capability for foundation models on structured data. Empirical analysis reveals that while metadata-derived features yield modest improvements in classical prediction metrics, these metadata features consistently highlight gaps in models’ ability to leverage semantics in relational context. By reframing tabular prediction as semantics-conditioned reasoning, SALT-KG establishes a benchmark to advance tabular FMs grounded in declarative knowledge, providing the first empirical step toward semantically linked tables in structured data at enterprise scale.",313.93,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07641v1_Beyond Static Tools Test-Time Tool Evolution for S.pdf,Beyond Static Tools: Test-Time Tool Evolution for Scientific Reasoning,"['Jiaxuan Lu', 'Ziyu Kong', 'Yemin Wang', 'Rong Fu', 'Haiyuan Wan', 'Cheng Yang', 'Wenjie Lou', 'Haoran Sun', 'Lilong Wang', 'Yankai Jiang', 'Xiaosong Wang', 'Xiao Sun', 'Dongzhan Zhou']","The central challenge of AI for Science is not reasoning alone, but the ability to create computational methods in an open-ended scientific world. Existing LLM-based agents rely on static, pre-defined tool libraries, a paradigm that fundamentally fails in scientific domains where tools are sparse, heterogeneous, and intrinsically incomplete. In this paper, we propose Test-Time Tool Evolution (TTE), a new paradigm that enables agents to synthesize, verify, and evolve executable tools during inference. By transforming tools from fixed resources into problem-driven artifacts, TTE overcomes the rigidity and long-tail limitations of static tool libraries. To facilitate rigorous evaluation, we introduce SciEvo, a benchmark comprising 1,590 scientific reasoning tasks supported by 925 automatically evolved tools. Extensive experiments show that TTE achieves state-of-the-art performance in both accuracy and tool efficiency, while enabling effective cross-domain adaptation of computational tools.",313.97,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07651v1_Active Evaluation of General Agents Problem Defini.pdf,Active Evaluation of General Agents: Problem Definition and Comparison of Baseline Algorithms,"['Marc Lanctot', 'Kate Larson', 'Ian Gemp', 'Michael Kaisers']","As intelligent agents become more generally-capable, the complexity and cost of properly evaluating them rise significantly. Tasks that assess specific capabilities of the agents can be correlated and stochastic, requiring many samples for accurate comparisons, leading to added costs. This paper proposes a formal definition and conceptual framework for active evaluation of agents across multiple tasks, which assesses the performance of ranking algorithms as a function of number of evaluation data samples. The classical Elo rating system, while suffering from well-known failure modes, is a consistently reliable choice for efficient reduction of ranking error in practice. A recently-proposed method, Soft Condorcet Optimization, shows comparable performance on synthetic data and significantly outperforms Elo on real Atari agent evaluation. When task variation from the ground truth is high, selecting tasks based on proportional representation leads to higher rate of ranking error reduction.",314.5,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07654v1_Towards Automating Blockchain Consensus Verificati.pdf,Towards Automating Blockchain Consensus Verification with IsabeLLM,"['Elliot Jones', 'William Knottenbelt']","Consensus protocols are crucial for blockchain systems as they ensure agreement between nodes in a potentially adversarial environment. Formal verification is essential but requires high effort and expertise, often omitted. This paper presents IsabeLLM, a tool integrating Isabelle with a Large Language Model to automate proofs. It develops a novel model of Bitcoin's Proof of Work consensus protocol and verifies its correctness using the DeepSeek R1 API, generating correct proofs for non-trivial lemmas.",316.3,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07663v2_Reasoning Models Will Blatantly Lie About Their Re.pdf,Reasoning Models Will Blatantly Lie About Their Reasoning,"['William Walden', 'Johns Hopkins University']","This paper extends the work of Chen et al. (2025) to demonstrate that Large Reasoning Models (LRMs) will not only change their answers to hinted questions but also deny using the hints in their reasoning. The authors provide explicit instructions to LRMs to check for unusual prompt content (hints) and explicitly state whether and how they will use these hints. The results show that while the use of hints can be improved with simple instructions, LRMs still deny relying on hints despite clearly doing so and despite being observed to use the hints in their reasoning. This has discouraging implications for CoT monitoring and interpretability.",314.72,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07666v1_Variational Contrastive Learning for Skeleton-base.pdf,Variational Contrastive Learning for Skeleton-based Action Recognition,"['Dang-Dinh NGUYEN', 'Decky ASPANDI-LATIF', 'Titus ZAHARIA']","In recent years, self-supervised representation learning for skeleton-based action recognition has advanced with the development of contrastive learning methods. However, most contrastive paradigms are inherently discriminative and often struggle to capture the variability and uncertainty intrinsic to human motion. To address this issue, we propose a variational contrastive learning framework that integrates probabilistic latent modeling with contrastive self-supervised learning. This formulation enables the learning of structured and semantically meaningful representations that generalize across different datasets and supervision levels. Extensive experiments on three widely used skeleton-based action recognition benchmarks show that our proposed method consistently outperforms existing approaches, particularly in low-label regimes. Moreover, qualitative analyses show that the features provided by our method are more relevant given the motion and sample characteristics, with more focus on important skeleton joints, when compared to the other methods.",316.86,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07667v1_Adaptive Layer Selection for Layer-Wise Token Prun.pdf,Adaptive Layer Selection for Layer-Wise Token Pruning in LLM Inference,"['Rei Taniguchi', 'Yuyang Dong', 'Makoto Onizuka', 'Chuan Xiao']","This paper proposes ASL, a training-free method that adaptively chooses the selection layer for KV cache reduction, exploiting the variance of token ranks ordered by attention score. The proposed method balances the performance across different tasks while meeting the user-specified KV budget requirement. ASL operates during the prefilling stage and can be jointly used with existing KV cache reduction methods such as SnapKV to optimize the decoding stage. Evaluations on the InfiniteBench, RULER, and NIAH benchmarks show that ASL outperforms state-of-the-art layer-wise token selection methods in accuracy while maintaining decoding speed and KV cache reduction.",313.93,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07685v1_Predictive Analytics for Dementia Machine Learning.pdf,Predictive Analytics for Dementia: Machine Learning on Healthcare Data,"['1st Shafiul Ajam Opee', '2nd Nafiz Fahad', '3rd Anik Sen', '4th Rasel Ahmed', '5th Fariha Jahan', '6th Md. Kishor Morol', '7th Md Rashedul Islam']","This study focuses on enhancing dementia prediction using machine learning (ML) techniques on patient health data. Supervised learning algorithms including K-Nearest Neighbors (KNN), Quadratic Discriminant Analysis (QDA), Linear Discriminant Analysis (LDA), and Gaussian Process Classifiers are applied. Techniques such as Synthetic Minority Over-sampling Technique (SMOTE) and Term Frequency-Inverse Document Frequency (TF-IDF) vectorization are employed to address class imbalance and improve model performance. Among the models, LDA achieved the highest testing accuracy of 98%. The study highlights the importance of model interpretability and the correlation of dementia with features such as the presence of the APOE-ϵ4 allele and chronic conditions like diabetes. This research advocates for future ML innovations, particularly in integrating explainable AI approaches, to further improve predictive capabilities in dementia care.",314.21,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07701v1_Deep Whole-body Parkour.pdf,Deep Whole-Body Parkour,"['Ziwen Zhuang', 'Shaoting Zhu', 'Mengjie Zhao', 'Hang Zhao']","This work unites two paradigms of humanoid control: perceptive locomotion and general motion tracking. By integrating exteroceptive sensing into whole-body motion tracking, a humanoid robot can perform highly dynamic, non-locomotion tasks on uneven terrain. The framework demonstrates the non-trivial benefit of integrating perception into the control loop, enabling robust, multi-contact motions such as vaulting and dive-rolling on unstructured terrain. This significantly expands the robot's traversability beyond simple walking or running.",315.61,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07718v1_Hiking in the Wild A Scalable Perceptive Parkour F.pdf,Hiking in the Wild: A Scalable Perceptive Parkour Framework for Humanoids,"['Shaoting Zhu', 'Ziwen Zhuang', 'Mengjie Zhao', 'Kun-Ying Lee', 'Hang Zhao']","Achieving robust humanoid hiking in complex, unstructured environments requires transitioning from reactive proprioception to proactive perception. Existing end-to-end approaches often struggle with scalability and training complexity. This work presents Hiking in the Wild, a scalable, end-to-end parkour perceptive framework designed for robust humanoid hiking. The framework introduces two key mechanisms: a foothold safety mechanism combining scalable Terrain Edge Detection with Foot Volume Points to prevent catastrophic slippage on edges, and a Flat Patch Sampling strategy that mitigates reward hacking by generating feasible navigation targets. Our approach utilizes a single-stage reinforcement learning scheme, mapping raw depth inputs and proprioception directly to joint actions, without relying on external state estimation. Extensive field experiments on a full-size humanoid demonstrate the effectiveness of our policy.",315.92,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07737v1_Evaluating the encoding competence of visual langu.pdf,Evaluating the encoding competence of visual language models using uncommon actions,"['Chen Ling', 'Nai Ding*']",This undergraduate project report evaluates the encoding competence of visual language models using uncommon actions. The study aims to assess how well these models can handle and encode actions that are not commonly encountered in their training data.,315.91,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07748v1_Improving Domain Generalization in Contrastive Lea.pdf,Improving Domain Generalization in Contrastive Learning using Adaptive Temperature Control,"['Robert Lewis', 'Katie Matton', 'Rosalind W. Picard', 'John Guttag']","Self-supervised pre-training with contrastive learning is a powerful method for learning from sparsely labeled data. However, performance can drop considerably when there is a shift in the distribution of data from training to test time. This paper presents a new method for contrastive learning that incorporates domain labels to increase the domain invariance of learned representations, leading to improved out-of-distribution generalization. The method adjusts the temperature parameter in the InfoNCE loss to upweight pairs from more similar domains, encouraging the model to discriminate samples based on domain-invariant attributes. Experiments on a variant of the MNIST dataset demonstrate that this method yields better out-of-distribution performance than domain generalization baselines, while maintaining strong in-distribution task performance.",314.82,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07778v1_DT-ICU Towards Explainable Digital Twins for ICU P.pdf,DT-ICU: Towards Explainable Digital Twins for ICU Patient Monitoring via Multi-Modal and Multi-Task Iterative Inference,['Wen Guo'],"We introduce DT-ICU, a multimodal digital twin framework for continuous risk estimation in intensive care. DT-ICU integrates variable-length clinical time series with static patient information in a unified multitask architecture, enabling predictions to be updated as new observations accumulate over the ICU stay. We evaluate DT-ICU on the large, publicly available MIMIC-IV dataset, where it consistently outperforms established baseline models under different evaluation settings. Our test-length analysis shows that meaningful discrimination is achieved shortly after admission, while longer observation windows further improve the ranking of high-risk patients in highly imbalanced cohorts. To examine how the model leverages heterogeneous data sources, we perform systematic modality ablations, revealing that the model learnt a reasonable structured reliance on interventions, physiological response observations, and contextual information. These analyses provide interpretable insights into how multimodal signals are combined and how trade-offs between sensitivity and precision emerge. Together, these results demonstrate that DT-ICU delivers accurate, temporally robust, and interpretable predictions, supporting its potential as a practical digital twin framework for continuous patient monitoring in critical care.",315.1,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07779v1_OS-Symphony A Holistic Framework for Robust and Ge.pdf,OS-SYMPHONY: A Holistic Framework for Robust and Generalist Computer-Using Agent,"['Bowen Yang', 'Kaiming Jin', 'Zhenyu Wu', 'Zhaoyang Liu', 'Qiushi Sun', 'Zehao Li', 'Jingjing Xie', 'Zhoumianze Liu', 'Fangzhi Xu', 'Kanzhi Cheng', 'Qingyun Li', 'Yian Wang', 'Yu Qiao', 'Zun Wang', 'Zichen Ding']","OS-SYMPHONY introduces a holistic framework for robust and generalist Computer-Using Agents (CUAs) that address limitations in current frameworks. It comprises an Orchestrator coordinating two key innovations: a Reflection-Memory Agent utilizing milestone-driven long-term memory for trajectory-level self-correction, and Versatile Tool Agents featuring a Multimodal Searcher to navigate a browser-based sandbox and synthesize live, visually aligned tutorials. Experimental results demonstrate substantial performance gains across varying model scales, establishing new state-of-the-art results on three online benchmarks, notably achieving 65.84% on OSWorld.",313.61,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07782v1_Beyond Single-Shot Multi-step Tool Retrieval via Q.pdf,Beyond Single-Shot: Multi-step Tool Retrieval via Query Planning,"['Wei Fang', 'James Glass']","Large language models (LLMs) operating over massive, dynamic tool libraries rely on effective retrieval, yet standard single-shot dense retrievers struggle with complex requests. These failures primarily stem from the disconnect between abstract user goals and technical documentation, and the limited capacity of fixed-size embeddings to model combinatorial tool compositions. To address these challenges, we propose TOOLQP, a lightweight framework that models retrieval as iterative query planning. Instead of single-shot matching, TOOLQP decomposes instructions into sub-tasks and dynamically generates queries to interact with the retriever, effectively bridging the semantic gap by targeting the specific sub-tasks required for composition. We train TOOLQP using synthetic query trajectories followed by optimization via Reinforcement Learning with Verifiable Rewards (RLVR). Experiments demonstrate that TOOLQP achieves state-of-the-art performance, exhibiting superior zero-shot generalization, robustness across diverse retrievers, and significant improvements in downstream agentic execution.",314.87,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07790v1_Benchmarking Small Language Models and Small Reaso.pdf,Benchmarking Small Language Models and Small Reasoning Language Models on System Log Severity Classification,"['Yahya Masri', 'Emily Ma', 'Zifu Wang', 'Joseph Rogers', 'Chaowei Yang']","System logs are crucial for monitoring and diagnosing modern computing infrastructure, but their scale and complexity require reliable and efficient automated interpretation. The authors evaluate nine small language models (SLMs) and small reasoning language models (SRLMs) under zero-shot, few-shot, and retrieval-augmented generation (RAG) prompting using real-world journalctl data from Linux production servers. The results reveal strong stratification, with Qwen3-4B achieving the highest accuracy at 95.64% with RAG, and Gemma3-1B improving from 20.25% under few-shot prompting to 85.28% with RAG. The tiny Qwen3-0.6B reaches 88.12% accuracy despite weak performance without retrieval. In contrast, several SRLMs, including Qwen3-1.7B and DeepSeek-R1-Distill-Qwen-1.5B, degrade substantially when paired with RAG. Efficiency measurements further separate models, with most Gemma and Llama variants completing inference in under 1.2 seconds per log, while Phi-4-Mini-Reasoning exceeds 228 seconds per log while achieving <10% accuracy. These findings suggest that architectural design, training objectives, and the ability to integrate retrieved context under strict output constraints jointly determine performance. By emphasizing small, deployable models, this benchmark aligns with real-time requirements of digital twin systems and shows that severity classification serves as a lens for evaluating model competence and real-time deployability, with implications for root cause analysis and broader DT integration.",315.22,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07794v1_Kinship Data Benchmark for Multi-hop Reasoning.pdf,Kinship Data Benchmark for Multi-hop Reasoning,"['Tianda Sun', 'Dimitar Kazakov']","Large language models (LLMs) are increasingly evaluated on their ability to perform multi-hop reasoning, combining multiple pieces of information into coherent inferences. This paper introduces KinshipQA, a benchmark designed to probe this capability through reasoning over kinship relations. The central contribution is a generative pipeline that produces large-scale, realistic, and culture-specific genealogical data, allowing for systematic control of task difficulty, cultural assumptions, and relational depth. From these genealogies, textual inference tasks are derived that require reasoning over implicit relational chains. The benchmark is evaluated using six state-of-the-art LLMs, and the results demonstrate a wide spread of outcomes and systematic differences in multi-hop reasoning across models and cultural settings.",315.53,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07821v1_Failure-Aware RL Reliable Offline-to-Online Reinfo.pdf,Failure-Aware RL: Reliable Offline-to-Online Reinforcement Learning with Self-Recovery for Real-World Manipulation,"['Huanyu Li', 'Kun Lei', 'Sheng Zang', 'Kaizhe Hu', 'Yongyuan Liang', 'Bo An', 'Xiaoli Li', 'Huazhe Xu']",Failure-Aware Offline-to-Online Reinforcement Learning (FARL) is introduced to minimize failures during real-world reinforcement learning. FARL integrates a world-model-based safety critic and a recovery policy trained offline to prevent failures during online exploration. Extensive simulation and real-world experiments demonstrate the effectiveness of FARL in significantly reducing Intervention-requiring Failures (IR Failures) while improving performance and generalization during online reinforcement learning post-training. FARL reduces IR Failures by 73.1% while elevating performance by 11.3% on average during real-world RL post-training.,315.06,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07832v2_MHLA Restoring Expressivity of Linear Attention vi.pdf,MHLA: Restoring Expressivity of Linear Attention via Token-Level Multi-Head,"['Kewei Zhang', 'Ye Huang', 'Yufan Deng', 'Jincheng Yu', 'Junsong Chen', 'Huan Ling', 'Enze Xie', 'Daquan Zhou']","While the Transformer architecture dominates many fields, its quadratic self-attention complexity hinders its use in large-scale applications. Linear attention offers an efficient alternative, but its direct application often degrades performance, with existing fixes typically re-introducing computational overhead through extra modules. In this work, we identify a key failure mode in these methods: global context collapse, where the model loses representational diversity. To address this, we propose Multi-Head Linear Attention (MHLA), which preserves this diversity by computing attention within divided heads along the token dimension. We prove that MHLA maintains linear complexity while recovering much of the expressive power of softmax attention, and verify its effectiveness across multiple domains, achieving a 3.6% improvement on ImageNet classification, a 6.3% gain on NLP, a 12.6% improvement on image generation, and a 41% enhancement on video generation under the same time complexity.",315.85,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07885v1_Small Symbols Big Risks Exploring Emoticon Semanti.pdf,"Small Symbols, Big Risks: Exploring Emoticon Semantic Confusion in Large Language Models","['Weipeng Jiang', 'Xiaoyu Zhang', 'Juan Zhai', 'Shiqing Ma', 'Chao Shen', 'Yang Liu']","Emoticons are widely used in digital communication to convey affective intent, yet their safety implications for Large Language Models (LLMs) remain largely unexplored. This paper identifies emoticon semantic confusion, a vulnerability where LLMs misinterpret ASCII-based emoticons to perform unintended and even destructive actions. The study reveals that emoticon semantic confusion is pervasive, with an average confusion ratio exceeding 38%. More critically, over 90% of confused responses yield 'silent failures', which are syntactically valid outputs but deviate from user intent, potentially leading to destructive security consequences. The vulnerability readily transfers to popular agent frameworks, while existing prompt-based mitigations remain largely ineffective. The authors call for the community to recognize this emerging vulnerability and develop effective mitigation methods to uphold the safety and reliability of human-AI interactions.",314.09,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07891v1_KVzap Fast Adaptive and Faithful KV Cache Pruning.pdf,"KVzap: Fast, Adaptive, and Faithful KV Cache Pruning","['Simon Jégou *', 'Maximilian Jeblick']","Growing context lengths in transformer-based language models have made the key-value (KV) cache a critical inference bottleneck. While many KV cache pruning methods have been proposed, they have not yet been adopted in major inference engines due to speed–accuracy trade-offs. We introduce KVzap, a fast, input-adaptive approximation of KVzip that works in both prefilling and decoding. On Qwen3-8B, Llama-3.1-8B-Instruct, and Qwen3-32B across long-context and reasoning tasks, KVzap achieves 2–4× KV cache compression with negligible accuracy loss and achieves state-of-the-art performance on the KVpress Leaderboard. Code and models are available at/githubNVIDIA/kvpress.",316.58,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07892v1_Sherry Hardware-Efficient 1.25-Bit Ternary Quantiz.pdf,JSON_FAIL,[],N/A,179.5,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07894v1_Revealing the Attention Floating Mechanism in Mask.pdf,Revealing the Attention Floating Mechanism in Masked Diffusion Models,"['Xin Dai', 'Pengcheng Huang', 'Zhenghao Liu*', 'Shuo Wang', 'Yukun Yan', 'Chaojun Xiao', 'Yu Gu', 'Ge Yu', 'Maosong Sun']","Masked diffusion models (MDMs) leverage bidirectional attention and a denoising process to narrow the performance gap with autoregressive models (ARMs). However, their internal attention mechanisms remain under-explored. This paper investigates the attention behaviors in MDMs, revealing the phenomenon of Attention Floating. Unlike ARMs, where attention converges to a fixed sink, MDMs exhibit dynamic, dispersed attention anchors that shift across denoising steps and layers. Further analysis reveals a Shallow Structure-Aware, Deep Content-Focused attention mechanism: shallow layers utilize floating tokens to build a global structural framework, while deeper layers allocate more capability toward capturing semantic content. Empirically, this distinctive attention pattern provides a mechanistic explanation for the strong in-context learning capabilities of MDMs, allowing them to double the performance compared to ARMs in knowledge-intensive tasks. All codes and datasets are available at https://github.com/NEUIR/Attention-Floating.",336.35,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07898v1_Large Language Models and Algorithm Execution Appl.pdf,Large Language Models and Algorithm Execution: Application to an Arithmetic Function,"['Farah Ben Slama', 'Frédéric Armetta']",Large Language Models (LLMs) have advanced functionalities but struggle with autonomous algorithm execution. This paper investigates extending LLMs' capabilities through specialized supervised training focused on reasoning decomposition. The authors introduce LLM-DAL (Large Language Model - Decompositional Algorithmic Learning) to demonstrate improved algorithmic inference and generalization when training methods guide the model's learning process.,334.99,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07901v1_Decentralized Online Convex Optimization with Unkn.pdf,Decentralized Online Convex Optimization with Unknown Feedback Delays,"['Hao Qiu', 'Mengxiao Zhang', 'Juliette Achddou']","This paper studies decentralized online convex optimization (D-OCO) under unknown, time- and agent-varying feedback delays. Recent work has addressed this problem, but existing algorithms assume prior knowledge of the total delay over agents and still suffer from suboptimal dependence on both the delay and network parameters. The authors propose a novel algorithm that achieves an improved regret bound, incorporating an adaptive learning rate mechanism via a decentralized communication protocol. This enables each agent to estimate delays locally using a gossip-based strategy without the prior knowledge of the total delay. The approach is extended to the strongly convex setting and results in a sharper regret bound. Experimental results validate the effectiveness of the approach, showing improvements over existing benchmark algorithms.",334.6,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07903v2_Enhancing Large Language Models for Time-Series Fo.pdf,Enhancing Large Language Models for Time-Series Forecasting via Vector-Injected In-Context Learning,"['Jianqi Zhang', 'Jingyao Wang', 'Wenwen Qiang', 'Fanjiang Xu', 'Changwen Zheng']","The World Wide Web needs reliable predictive capabilities to respond to changes in user behavior and usage patterns. Time series forecasting (TSF) is a key means to achieve this goal. In recent years, large language models (LLMs) for TSF (LLM4TSF) have achieved good performance. However, there is a significant difference between pretraining corpora and time series data, making it hard to guarantee forecasting quality when directly applying LLMs to TSF; fine-tuning LLMs can mitigate this issue, but often incurs substantial computational overhead. Thus, LLM4TSF faces a dual challenge of prediction performance and compute overhead. To address this, the authors aim to explore a method for improving the forecasting performance of LLM4TSF while freezing all LLM parameters to reduce computational overhead. Inspired by in-context learning (ICL), they propose LVICL, which uses a vector-injected ICL to inject example information into a frozen LLM, eliciting its in-context learning ability and thereby enhancing its performance on the example-related task (i.e., TSF). Specifically, they use the LLM together with a learnable context vector adapter to extract a context vector from multiple examples adaptively, which contains compressed, example-related information. During the forward pass, they inject this vector into every layer of the LLM to improve forecasting performance. Compared with conventional ICL that adds examples into the prompt, their vector-injected ICL does not increase prompt length and suppresses components harmful to forecasting, thereby improving model performance. Extensive experiments demonstrate the effectiveness of their approach.",334.35,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07935v1_Towards Specialized Generalists A Multi-Task MoE-L.pdf,Towards Specialized Generalists: A Multi-Task MoE-LoRA Framework for Domain-Specific LLM Adaptation,"['Yuxin Yang', 'Shanghai University', 'Aoxiong Zeng', 'East China Normal University', 'Xiangquan Yang', 'East China Normal University']","The rapid evolution of Large Language Models (LLMs) has shifted focus from general-purpose capabilities to domain-specific expertise. However, adapting LLMs to specialized fields such as medicine presents two challenges: the 'Stability-Plasticity Dilemma' and 'Task Interference'. In this paper, we propose Med-MoE-LoRA, a novel framework that integrates Mixture-of-Experts (MoE) with Low-Rank Adaptation (LoRA) to enable efficient multi-task domain adaptation, especially for medical scenarios. Our framework employs an asymmetric expert distribution and a 'Knowledge-Preservation Plugin' to isolate and protect general-purpose reasoning. By utilizing soft merging with adaptive routing and rank-wise decoupling, Med-MoE-LoRA achieves superior performance in medical benchmarks while reducing interference. Experimental results demonstrate that our approach consistently outperforms standard LoRA and conventional MoE architectures across multiple clinical NLP tasks while retaining the model's general cognitive capabilities.",335.74,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07939v1_SECite Analyzing and Summarizing Citations in Soft.pdf,SECite: Analyzing and Summarizing Citations in Software Engineering Literature,"['Shireesh Reddy Pyreddy', 'Khaja Valli Pathan', 'Hasan Masum', 'Tarannum Shaila Zaman']","Identifying the strengths and limitations of a research paper is a core component of any literature review. However, traditional summaries reflect only the authors' self-presented perspective. Analyzing how other researchers discuss and cite the paper can offer a deeper, more practical understanding of its contributions and shortcomings. In this research, the authors introduce SECite, a novel approach for evaluating scholarly impact through sentiment analysis of citation contexts. They develop a semi-automated pipeline to extract citations referencing nine research papers and apply advanced natural language processing (NLP) techniques with unsupervised machine learning to classify these citation statements as positive or negative. Beyond sentiment classification, they use generative AI to produce sentiment-specific summaries that capture the strengths and limitations of each target paper, derived both from clustered citation groups and from the full text. Their findings reveal meaningful patterns in how the academic community perceives these works, highlighting areas of alignment and divergence between external citation feedback and the authors' own presentation. By integrating citation sentiment analysis with LLM-based summarization, this study provides a comprehensive framework for assessing scholarly contributions.",335.39,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07941v2_Moonworks Lunara Aesthetic Dataset.pdf,Moonworks Lunara Aesthetic Dataset,"['Yan Wang', 'M M Sayeef Abdullah', 'Partho Hassan', 'Sabit Hassan']","This data card presents the first public release of the Lunara Aesthetic Dataset, a curated set of 2,000 image–prompt pairs for controlled research on prompt grounding and style conditioning in text-to-image generation systems. The dataset spans diverse artistic styles, including regionally grounded aesthetics from the Middle East, Northern Europe, East Asia, and South Asia, alongside general categories such as sketch and oil painting. All images are generated using the Moonworks Lunara model and intentionally crafted to embody distinct, high-quality aesthetic styles, yielding a first-of-its-kind dataset with substantially higher aesthetic scores, exceeding even aesthetics-focused datasets and general-purpose datasets by a larger margin. Each image is accompanied by a human-refined prompt and structured annotations that jointly describe salient objects, attributes, relationships, and stylistic cues. Unlike large-scale web-derived datasets that emphasize breadth over precision, the Lunara Aesthetic Dataset prioritizes aesthetic quality, stylistic diversity, and licensing transparency, and is released under the Apache 2.0 license to support research and unrestricted academic and commercial use.",336.02,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07946v1_Coupled Diffusion-Encoder Models for Reconstructio.pdf,Coupled Diffusion–Encoder Models for Reconstruction of Flow Fields,"['AmirPouya Hemmasian', 'Amir Barati Farimani']","DiffCoder is a coupled framework that integrates a probabilistic diffusion model with a conventional convolutional ResNet encoder. It compresses the flow field into a latent representation and learns a generative prior over reconstructions conditioned on the compressed state. This design allows DiffCoder to recover distributional and spectral properties of the flow field, which are not strictly required for minimizing pointwise reconstruction loss but are critical for faithful representation. The authors evaluate DiffCoder and VAE baselines across multiple model sizes and compression ratios on a challenging dataset of Kolmogorov flow fields. Under aggressive compression, DiffCoder significantly improves spectral accuracy while VAEs exhibit substantial degradation. Although both methods show comparable relative L2 reconstruction error, DiffCoder better preserves the underlying distributional structure of the flow. At moderate compression levels, sufficiently large VAEs remain competitive, suggesting that diffusion-based priors provide the greatest benefit when information bottlenecks are severe.",333.99,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07948v1_Reinforcement Learning Methods for Neighborhood Se.pdf,Reinforcement Learning Methods for Neighborhood Selection in Local Search,"['Yannick Molinghen', 'Augustin Delecluse', 'Renaud De Landtsheer', 'Stefano Michelini']","Reinforcement learning has recently gained traction as a means to improve combinatorial optimization methods, yet its effectiveness within local search metaheuristics speciﬁcally remains comparatively underexamined. In this study, we evaluate a range of reinforcement learning-based neighborhood selection strategies – multi-armed bandits (upper conﬁdence bound, ε-greedy) and deep reinforcement learning methods (proximal policy optimization, double deep Q-network) – and compare them against multiple baselines across three different problems: the traveling salesman problem, the pickup and delivery problem with time windows, and the car sequencing problem. We show how search-speciﬁc characteristics, particularly large variations in cost due to constraint violation penalties, necessitate carefully designed reward functions to provide stable and informative learning signals. Our extensive experiments reveal that algorithm performance varies substantially across problems, although that ε-greedy consistently ranks among the best performers. In contrast, the computational overhead of deep reinforcement learning approaches only makes them competitive with a substantially longer runtime. These findings highlight both the promise and the practical limitations of deep reinforcement learning in local search.",333.72,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07951v1_Hybrid SARIMA LSTM Model for Local Weather Forecas.pdf,Hybrid SARIMA–LSTM Model for Local Weather Forecasting: A Residual-Learning Approach for Data-Driven Meteorological Prediction,"['Shreyas Rajeev', 'Karthik Mudenahalli', 'Amit Mallappa', 'I. Tiparaddi']","For decades, accurately predicting the weather over the long term has been a major scientific problem due to the chaotic nature of atmospheric systems. Traditional statistical methods like SARIMA and other linear models struggle with nonlinear fluctuations, leading to systematic residual errors. Deep learning techniques, particularly recurrent neural networks like LSTMs, have shown exceptional efficacy in addressing intricate time-series challenges. However, LSTMs become unstable when predicting far into the future without ground truth feedback. This project proposes a hybrid SARIMA–LSTM architecture that combines the strengths of both methods. SARIMA models the long-term seasonal trend, while the LSTM learns the random changes in prediction errors. Fourier seasonal encoding is used to clearly show the yearly cycle, and a new stabilized recursive forecasting mechanism keeps predictions within a 293-day future horizon. The goal is to accurately predict daily average temperature in New York City using data from 2020 to 2023, and to evaluate if the hybrid model performs better than SARIMA alone.",334.86,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07953v1_Quantum automated theorem proving.pdf,Quantum automated theorem proving,"['Zheng-Zhi Sun', 'Qi Ye', 'Dong-Ling Deng']","Automated theorem proving, or more broadly automated reasoning, aims at using computer programs to automatically prove or disprove mathematical theorems and logical statements. This paper proposes a generic framework for quantum automated theorem proving, where the intrinsic quantum superposition and entanglement features would lead to potential advantages. The authors introduce quantum representations of knowledge bases and propose corresponding reasoning algorithms for a variety of tasks. They show how automated reasoning can be achieved with quantum resolution in both propositional and first-order logic with quadratically reduced query complexity. Additionally, they propose the quantum algebraic proving method for geometric theorems, extending Wu’s algebraic approach beyond the classical setting. Through concrete examples, including geometry problems from the International Mathematical Olympiad, they demonstrate how a quantum computer may prove geometric theorems with quadratic better query complexity. The results establish a primary approach towards building quantum automatic theorem provers, which would be crucial for practical applications of both near-term and future quantum technologies.",335.28,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07957v1_LWMSCNN-SE A Lightweight Multi-Scale Network for E.pdf,LWMSCNN-SE: A Lightweight Multi-Scale Network for Efficient Maize Disease Classification on Edge Devices,['LWMSCNN-SE: A Lightweight Multi-Scale Network for Efficient Maize Disease Classification on Edge Devices'],"Maize disease classification plays a vital role in mitigating yield losses and ensuring food security. However, traditional disease detection models face challenges in resource-constrained environments. We propose LWMSCNN-SE, a lightweight convolutional neural network (CNN) that integrates multi-scale feature extraction, depthwise separable convolutions, and squeeze-and-Excitation (SE) attention mechanisms. This novel combination enables the model to achieve 96.63% classification accuracy with only 241,348 parameters and 0.666 GFLOPs, suitable for real-time deployment in field applications. Our approach addresses the accuracy-efficiency trade-off by delivering high accuracy while maintaining low computational costs, demonstrating its potential for efficient maize disease diagnosis on edge devices in precision farming systems.",335.22,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07958v1_LJ-Spoof A Generatively Varied Corpus for Audio An.pdf,LJ-SPOOF: A GENERATIVELY V ARIED CORPUS FOR AUDIO ANTI-SPOOFING AND SYNTHESIS SOURCE TRACING,"['Surya Subramani', 'Hashim Ali', 'Hafiz Malik']","Speaker-specific anti-spoofing and synthesis-source tracing are central challenges in audio anti-spoofing. Progress has been hampered by the lack of datasets that systematically vary model architectures, synthesis pipelines, and generative parameters. To address this gap, we introduce LJ-Spoof, a speaker-specific, generatively diverse corpus that systematically varies prosody, vocoders, generative hyperparameters, bona fide prompt sources, training regimes, and neural post-processing. The corpus spans one speaker including studio-quality recordings, 30 TTS families, 500 generatively variant subsets, 10 bona fide neural-processing variants, and more than 3 million utterances. This variation-dense design enables robust speaker-conditioned anti-spoofing and fine-grained synthesis-source tracing. The dataset is positioned as both a practical reference training resource and a benchmark evaluation suite for anti-spoofing and source tracing.",333.9,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07964v1_Executable Ontologies in Game Development From Alg.pdf,Executable Ontologies in Game Development: From Algorithmic Control to Semantic World Modeling,['Alexander Boldachev'],"This paper examines the application of Executable Ontologies (EO), implemented through the boldsea framework, to game development. It argues that EO represents a paradigm shift from algorithmic behavior programming to semantic world modeling, where agent behavior emerges naturally from declarative domain rules. Using a survival game scenario (Winter Feast), it demonstrates how EO achieves priority-based task interruption through dataflow conditions rather than explicit preemption logic. Comparison with Behavior Trees (BT) and Goal-Oriented Action Planning (GOAP) reveals that while these approaches model what agents should do, EO models when actions become possible, addressing the semantic-process gap in game AI architecture. The paper discusses integration strategies, debugging advantages inherent to temporal event graphs, and the potential for LLM-driven runtime model generation.",335.55,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07965v1_When Models Know When They Do Not Know Calibration.pdf,"When a Model Knows When It Does Not Know: Calibration, Cascading, and Cleaning","['Chenjie Hao', 'Weyl Lu', 'Yuko Ishiwaka', 'Zengyi Li', 'Weier Wan', 'Yubei Chen']","This work proposes a simple, effective, and universal training-free method for model calibration, cascading, and data cleaning. The authors highlight two key empirical observations: higher confidence corresponds to higher accuracy within a single model, and models calibrated on the validation set remain calibrated on a held-out test set. These findings establish the reliability and comparability of calibrated confidence. The authors introduce two applications: model cascading with calibrated advantage routing and data cleaning based on model ensemble. They demonstrate that enabling models to recognize when they do not know is a practical step toward more efficient, reliable, and trustworthy AI.",334.12,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07969v1_Tuberculosis Screening from Cough Audio Baseline M.pdf,"Tuberculosis Screening from Cough Audio: Baseline Models, Clinical Variables, and Uncertainty Quantification","['George P. Kafentzis', 'Efstratios Selisios']","In this paper, we propose a standardized framework for automatic tuberculosis (TB) detection from cough audio and routinely collected clinical data using machine learning. While TB screening from audio has attracted growing interest, progress is difficult to measure because existing studies vary substantially in datasets, cohort definitions, feature representations, model families, validation protocols, and reported metrics. Consequently, reported gains are often not directly comparable, and it remains unclear whether improvements stem from modeling advances or from differences in data and evaluation. We address this gap by establishing a strong, well-documented baseline for TB prediction using cough recordings and accompanying clinical metadata from a recently compiled dataset from several countries. Our pipeline is reproducible end-to-end, covering feature extraction, multimodal fusion, cougher-independent evaluation, and uncertainty quantification, and it reports a consistent suite of clinically relevant metrics to enable fair comparison. We further quantify performance for cough audio-only and fused (audio + clinical metadata) models, and release the full experimental protocol to facilitate benchmarking. This baseline is intended to serve as a common reference point and to reduce methodological variance that currently holds back progress in the field.",335.38,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07973v1_Cultural Compass A Framework for Organizing Societ.pdf,Cultural Compass: A Framework for Organizing Societal Norms to Detect Violations in Human-AI Conversations,"['Myra Cheng', 'Vinodkumar Prabhakaran', 'Alice Oh', 'Hayk Stepanyan', 'Aishwarya Verma', 'Charu Kalia', 'Erin MacMurray van Liemt', 'Sunipa Dev']","Generative AI models need to adhere to diverse cultural norms to be useful and safe across cross-cultural contexts. This paper introduces a taxonomy of norms that clarifies their contexts, specifications, and mechanisms. The authors demonstrate how their taxonomy can be operationalized to automatically evaluate models' norm adherence in naturalistic, open-ended settings. They find that state-of-the-art models frequently violate norms, with rates varying by model, interactional context, and country. The taxonomy and evaluation pipeline enable nuanced, context-sensitive evaluation of cultural norm adherence in realistic settings.",334.08,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07988v1_From Word Sequences to Behavioral Sequences Adapti.pdf,From Word Sequences to Behavioral Sequences: Adapting Modeling and Evaluation Paradigms for Longitudinal NLP,"['Adithya V Ganesan†', 'Vasudha Varadarajan⊙', 'Oscar NE Kjell‡', 'Whitney R Ringwaldδ', 'Scott Feltman†', 'Benjamin J Luft†', 'Roman Kotov†', 'Ryan L Boyd∆Θ', 'H Andrew Schwartz†‡']","While NLP typically treats documents as independent and unordered samples, in longitudinal studies, documents are nested within authors and ordered in time, forming person-indexed, time-ordered behavioral sequences. This paper demonstrates the need for and proposes a longitudinal modeling and evaluation paradigm that updates four parts of the NLP pipeline: evaluation splits, accuracy metrics, sequence inputs, and model internals. The authors demonstrate the issues with traditional pipeline and their proposed improvements on a dataset of 17k daily diary transcripts paired with PTSD symptom severity from 238 participants, finding that traditional document-level evaluation can yield substantially different and sometimes reversed conclusions compared to their ecologically valid modeling and evaluation. The paper ties results to a broader discussion motivating a shift from word-sequence evaluation toward behavioral-sequence paradigms for NLP.",334.53,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.07994v2_DYCP Dynamic Context Pruning for Long-Form Dialogu.pdf,DYCP: Dynamic Context Pruning for Long-Form Dialogue with LLMs,"['Nayoung Choi', 'Jonathan Zhang', 'Jinho D. Choi']","Large Language Models (LLMs) often exhibit increased response latency and degraded answer quality as dialogue length grows. Existing methods rely on extra LLM calls to build memory or perform offline memory construction without considering the current user utterance, which can introduce inefficiencies or disrupt conversational continuity. This paper introduces DYCP, a lightweight context management method that dynamically segments and retrieves relevant memory at query time, preserving the sequential structure of dialogue without predefined topic boundaries and supporting efficient, adaptive context retrieval. Across three long-form dialogue benchmarks—LoCoMo, MT-Bench+, and SCM4LLMs—and multiple LLMs, DYCP consistently improves answer quality while reducing response latency. The paper also examines the gap between modern LLMs' expanded context windows and their actual long-context processing capacity, highlighting the continued importance of effective context management.",334.17,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08000v1_Reasoning over Precedents Alongside Statutes Case-.pdf,Case-Augmented Deliberative Alignment for LLM Safety,"['Can Jin', 'Rui Wu', 'Tong Che', 'Qixin Zhang', 'Hongwu Peng', 'Jiahui Zhao', 'Wenqi Wei', 'Zheting Wang', 'Zhao Zhang', 'Yuan Cao', 'Ruixiang Tang', 'Dimitris N. Metaxas']","This work systematically evaluates the impact of explicitly specifying extensive safety codes versus demonstrating them through illustrative cases in Large Language Models (LLMs). It finds that referencing explicit codes inconsistently improves harmlessness but systematically degrades helpfulness, while training on case-augmented simple codes yields more robust and generalized safety behaviors. The authors propose CADA, a case-augmented deliberative alignment method for LLMs utilizing reinforcement learning on self-generated safety reasoning chains, which effectively enhances harmlessness, improves robustness against attacks, and reduces over-refusal while preserving utility across diverse benchmarks.",333.92,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08003v1_LLM Review Enhancing Creative Writing via Blind Pe.pdf,Enhancing Creative Writing via Blind Peer Review Feedback,"['Weiyue Li*', 'Mingxiao Song*', 'Zhenda Shen*', 'Dachuan Zhao*', 'Yunfan Long', 'Yi Li', 'Yongce Li', 'Ruyi Yang', 'Mengyu Wang']","Large Language Models (LLMs) often struggle with creative generation, and multi-agent frameworks that improve reasoning through interaction can paradoxically hinder creativity by inducing content homogenization. We introduce LLM Review, a peer-review-inspired framework implementing Blind Peer Review: agents exchange targeted feedback while revising independently, preserving divergent creative trajectories. To enable rigorous evaluation, we propose SciFi-100, a science fiction writing dataset with a unified framework combining LLM-as-a-judge scoring, human annotation, and rule-based novelty metrics. Experiments demonstrate that LLM Review consistently outperforms multi-agent baselines, and smaller models with our framework can surpass larger single-agent models, suggesting interaction structure may substitute for model scale.",333.88,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08005v1_Internal Deployment Gaps in AI Regulation.pdf,Internal Deployment Gaps in AI Regulation,"['JOE KWON', 'STEPHEN CASPER']","Frontier AI regulations primarily focus on systems deployed to external users, where deployment is more visible and subject to outside scrutiny. However, high-stakes applications can occur internally when companies deploy highly capable systems within their own organizations. This paper examines how frontier AI regulations in the United States and European Union in 2025 handle internal deployment. We identify three gaps that could cause internally-deployed systems to evade intended oversight: (1) scope ambiguity that allows internal systems to evade regulatory obligations, (2) point-in-time compliance assessments that fail to capture the continuous evolution of internal systems, and (3) information asymmetries that subvert regulatory awareness and oversight. We then analyze why these gaps persist, examining tensions around measurability, incentives, and information access. Finally, we map potential approaches to address them and their associated tradeoffs. By understanding these patterns, we hope that policy choices around internally deployed AI systems can be made deliberately rather than incidentally.",335.99,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08011v1_TP-Blend Textual-Prompt Attention Pairing for Prec.pdf,TP-Blend: Textual-Prompt Attention Pairing for Precise Object-Style Blending in Diffusion Models,"['Xin Jin', 'Yichuan Zhong', 'Yapeng Tian']","Current text-conditioned diffusion editors handle single object replacement well but struggle when a new object and a new style must be introduced simultaneously. TP-Blend, a lightweight training-free framework, receives two separate textual prompts: one specifying a blend object and the other defining a target style. It injects both into a single denoising trajectory using two complementary attention processors. Cross-Attention Object Fusion (CAOF) averages head-wise attention to locate spatial tokens responding strongly to either prompt and reassigns feature vectors to those positions. Self-Attention Style Fusion (SASF) injects style at every self-attention layer through Detail-Sensitive Instance Normalization, separating low- and high-frequency components and blending only the high-frequency residual. Extensive experiments show that TP-Blend produces high-resolution, photo-realistic edits with precise control over both content and appearance, surpassing recent baselines in quantitative fidelity, perceptual quality, and inference speed.",332.91,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08017v1_Representations of Text and Images Align From Laye.pdf,Representations of Text and Images Align From Layer One,"['Evòzen Wybitul', 'Javier Rando', 'Florian Tramér', 'Stanislav Fort']","We show that for a variety of concepts in adapter-based vision-language models, the representations of their images and their text descriptions are meaningfully aligned from the very first layer. This contradicts the established view that such image-text alignment only appears in late layers. We use a new synthesis-based method inspired by DeepDream to demonstrate this, and find that the synthesised images often depict salient visual features of the targeted textual concepts. Our method provides direct, constructive evidence of image-text alignment on a concept-by-concept and layer-by-layer basis, and does not require auxiliary models or datasets. It also offers a new path towards model interpretability.",334.07,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08026v2_FigEx2 Visual-Conditioned Panel Detection and Capt.pdf,FigEx2: Visual-Conditioned Panel Detection and Captioning for Scientific Compound Figures,"['Jifeng Song', 'Arun Das', 'Pan Wang', 'Hui Ji', 'Kun Zhao', 'Yufei Huang']","This paper introduces FigEx2, a visual-conditioned framework that localizes panels and generates panel-wise captions directly from scientific compound figures. To address the challenge of diverse phrasing in open-ended captioning, FigEx2 employs a noise-aware gated fusion module that adaptively filters token-level features. Additionally, it combines supervised learning with reinforcement learning (RL) for multimodal consistency. FigEx2 achieves superior performance in detection and captioning, significantly outperforming existing methods in METEOR and BERTScore metrics. Notably, FigEx2 demonstrates remarkable zero-shot transferability to out-of-distribution scientific domains without any fine-tuning.",333.51,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08043v1_The Role of Noisy Data in Improving CNN Robustness.pdf,The Role of Noisy Data in Improving CNN Robustness for Image Classification,"['Oscar H. Ramírez-Agudela', 'Nicoleta Gorea', 'Aliza Reif', 'Lorenzo Bonasera', 'Michael Karla']","Data quality plays a central role in the performance and robustness of convolutional neural networks (CNNs) for image classification. While high-quality data is often preferred for training, real-world inputs are frequently affected by noise and other distortions. This paper investigates the effect of deliberately introducing controlled noise into the training data to improve model robustness. Using the CIFAR-10 dataset, we evaluate the impact of three common corruptions, namely Gaussian noise, Salt-and-Pepper noise, and Gaussian blur at varying intensities and training set pollution levels. Experiments using a Resnet-18 model reveal that incorporating just 10% noisy data during training is sufficient to significantly reduce test loss and enhance accuracy under fully corrupted test conditions, with minimal impact on clean-data performance. These findings suggest that strategic exposure to noise can act as a simple yet effective regularizer, offering a practical trade-off between traditional data cleanliness and real-world resilience.",335.62,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08049v1_Integrating Attendance Tracking and Emotion Detect.pdf,Integrating Attendance Tracking and Emotion Detection for Enhanced Student Engagement in Smart Classrooms,"['Keith Ainebyona', 'Ann Move Oguti', 'Joseph Walusimbi', 'Ritah Kobusingye']","The increasing adoption of smart classroom technologies in higher education has mainly focused on automating attendance, with limited attention given to students' emotional and cognitive engagement during lectures. This limits instructors' ability to identify disengagement and adapt teaching strategies in real time. This paper presents SCASED (Smart Classroom Attendance System with Emotion Detection), an IoT-based system that integrates automated attendance tracking with facial emotion recognition to support classroom engagement monitoring. The system uses a Raspberry Pi camera and a fine-tuned MobileNetV2 model to classify four learning-related emotional states: engagement, boredom, confusion, and frustration. A session-based mechanism is implemented to manage attendance and emotion monitoring by recording attendance once per session and performing continuous emotion analysis thereafter. Attendance and emotion data are visualized through a cloud-based dashboard to provide instructors with insights into classroom dynamics. Experimental evaluation using the DAiSEE dataset achieved an emotion classification accuracy of 89.5%. The results show that integrating attendance data with emotion analytics can provide instructors with additional insight into classroom dynamics and support more responsive teaching practices.",335.6,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08052v1_Forecast Aware Deep Reinforcement Learning for Eff.pdf,Forecast Aware Deep Reinforcement Learning for Efficient Electricity Load Scheduling in Dairy Farms,"['Nawazish Alia', 'Rachael Shaw', 'Karl Mason']","Dairy farming is an energy-intensive sector that relies heavily on grid electricity. With increasing renewable energy integration, sustainable energy management has become essential for reducing grid dependence and supporting the United Nations Sustainable Development Goal 7 on affordable and clean energy. However, the intermittent nature of renewables poses challenges in balancing supply and demand in real time. This study proposes a Deep Reinforcement Learning framework for efficient load scheduling in dairy farms, focusing on battery storage and water heating under realistic operational constraints. The proposed Forecast-Aware PPO incorporates short-term forecasts of demand and renewable generation using hour-of-day and month-based residual calibration, while the PID-KL PPO variant employs a proportional–integral–derivative controller to regulate KL-divergence for stable policy updates adaptively. Trained on real-world dairy farm data, the method achieves up to 1% lower electricity cost than PPO, 4.8% than DQN, and 1.5% than SAC. For battery scheduling, PPO reduces grid imports by 13.1%, demonstrating scalability and effectiveness for sustainable energy management in modern dairy farming.",336.34,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08058v1_Reasoning Beyond Chain-of-Thought A Latent Computa.pdf,Reasoning Beyond Chain-of-Thought: A Latent Computational Mode in Large Language Models,"['Zhenghao He', 'Guangzhi Xiong', 'Bohan Liu', 'Sanchit Sinha', 'Aidong Zhang']","This work investigates the internal representations of large language models (LLMs) with Sparse Autoencoders (SAEs) to identify latent features causally associated with reasoning behavior. Across multiple model families and reasoning benchmarks, steering a single reasoning-related latent feature can substantially improve accuracy without explicit Chain-of-Thought (CoT) prompting. For large models, latent steering achieves performance comparable to standard CoT prompting while producing more efficient outputs. The study suggests that multi-step reasoning in LLMs is supported by latent internal activations that can be externally activated, while CoT prompting is one effective, but not unique, way of activating this mechanism rather than its necessary cause.",334.37,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08065v1_A New Strategy for Verifying Reach-Avoid Specifica.pdf,A New Strategy for Verifying Reach-Avoid Specifications in Neural Feedback Systems,"['Samuel I. Akinwande', 'Sydney M. Katz', 'Mykel J. Kochenderfer', 'Clark Barrett']","Forward reachability analysis is the predominant approach for verifying reach-avoid properties in neural feedback systems. This work introduces new algorithms that compute both over- and under-approximations of backward reachable sets for such systems, integrating these backward algorithms with established forward analysis techniques to yield a unified verification framework.",335.07,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08070v1_Semantic Gravity Wells Why Negative Constraints Ba.pdf,Semantic Gravity Wells: Why Negative Constraints Backfire,['Shailesh Rana'],"Negative constraints, instructions of the form 'do not use word X', represent a fundamental test of instruction-following capability in large language models. Despite their apparent simplicity, these constraints fail with striking regularity, and the conditions governing failure have remained poorly understood. This paper presents the first comprehensive mechanistic investigation of negative instruction failure. It introduces semantic pressure, a quantitative measure of the model's intrinsic probability of generating the forbidden token, and demonstrates that violation probability follows a tight logistic relationship with pressure. Through layer-wise analysis using the logit lens technique, the paper establishes that the suppression signal induced by negative instructions is present but systematically weaker in failures, revealing a fundamental tension in negative constraint design.",333.92,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08079v1_MemoBrain Executive Memory as an Agentic Brain for.pdf,MemoBrain: Executive Memory as an Agentic Brain for Reasoning,"['Hongjin Qian', 'Zhao Cao', 'Zheng Liu']","Complex reasoning in tool-augmented agent frameworks is inherently long-horizon, causing reasoning traces and transient tool artifacts to accumulate and strain the bounded working context of large language models. Without explicit memory mechanisms, such accumulation disrupts logical continuity and undermines task alignment. This paper proposes MemoBrain, an executive memory model for tool-augmented agents that constructs a dependency-aware memory over reasoning steps, capturing salient intermediate states and their logical relations. Operating as a co-pilot alongside the reasoning agent, MemoBrain organizes reasoning progress without blocking execution and actively manages the working context. Specifically, it prunes invalid steps, folds completed sub-trajectories, and preserves a compact, high-salience reasoning backbone under a fixed context budget. Together, these mechanisms enable explicit cognitive control over reasoning trajectories rather than passive context accumulation. The authors evaluate MemoBrain on challenging long-horizon benchmarks, demonstrating consistent improvements over strong baselines.",333.55,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08089v1_Q-realign Piggybacking Realignment on Quantization.pdf,Q-realign: Piggybacking Realignment on Quantization for Safe and Efficient LLM Deployment,"['Qitao Tan', 'Xiaoying Song', 'Ningxi Cheng', 'Ninghao Liu', 'Xiaoming Zhai', 'Lingzi Hong', 'Yanzhi Wang', 'Zhen Xiang', 'Geng Yuan']","Public large language models (LLMs) are typically safety-aligned during pretraining, but task-specific fine-tuning often erodes this alignment and introduces safety risks. Existing defenses either embed safety recovery into fine-tuning or rely on post-hoc correction derived from fine-tuning. Q-realign proposes a post-hoc defense method based on post-training quantization, guided by an analysis of representational structure. By reframing quantization as a dual-objective procedure for compression and safety, Q-realign decouples safety alignment from fine-tuning and naturally piggybacks into modern deployment pipelines. Experiments across multiple models and datasets demonstrate that Q-realign substantially reduces unsafe behaviors while preserving task performance, with significant reductions in memory usage and GPU hours. Notably, Q-realign can recover the safety alignment of a fine-tuned 7B LLM on a single RTX 4090 within 40 minutes. Overall, the work provides a practical, turnkey solution for safety-aware deployment.",334.37,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08094v1_Local-Global Feature Fusion for Subject-Independen.pdf,Local-Global Feature Fusion for Subject-Independent EEG Emotion Recognition,"['Zheng Zhou', 'Isabella McEvoy', 'Camilo E. Valderrama']","Local-Global Feature Fusion for Subject-Independent EEG Emotion Recognition addresses the challenge of pronounced inter-subject variability in EEG emotion recognition. The proposed framework integrates local, channel-wise descriptors and global, trial-level descriptors, improving cross-subject generalization on the SEED-VII dataset. Experiments demonstrate that the proposed method consistently outperforms single-view and classical baselines, achieving approximately 40% mean accuracy in 7-class subject-independent emotion recognition.",332.95,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08104v1_High-Fidelity Modeling of Stochastic Chemical Dyna.pdf,HIGH-FIDELITYMODELING OFSTOCHASTICCHEMICAL DYNAMICS ONCOMPLEXMANIFOLDS: A MULTI-SCALE SIREN-PINN FRAMEWORK FOR THECURVATURE-PERTURBED GINZBURG-LANDAUEQUATION,"['Julian Evan Chrisnanto', 'Salsabila Rahma Alia', 'Nurfauzi Fadillah', 'Yulison Herry Chrisnanto']","The authors propose a Multi-Scale SIREN-PINN architecture to accurately identify and control spatiotemporal chaos in reaction-diffusion systems, particularly on complex manifolds. This architecture uses periodic sinusoidal activations with frequency-diverse initialization to resolve high-frequency gradients and preserve topological invariants. The model achieves state prediction errors of approximately 1.92×10−2, outperforming standard baselines by an order of magnitude. The authors solve the inverse pinning problem, reconstructing hidden Gaussian curvature fields from partial observations of chaotic wave dynamics. Training dynamics reveal a distinctive Spectral Phase Transition, driving the solver to Pareto-optimal solutions. This work establishes a new paradigm for Geometric Catalyst Design, offering a mesh-free, data-driven tool for identifying surface heterogeneity and engineering passive control strategies in turbulent chemical reactors.",334.56,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08107v1_STO-RL Offline RL under Sparse Rewards via LLM-Gui.pdf,STO-RL: Offline RL under Sparse Rewards via LLM-Guided Subgoal Temporal Order,"['Chengyang Gu', 'Yuxin Pan', 'Hui Xiong', 'Yize Chen']","STO-RL (Offline RL using LLM-Guided Subgoal Temporal Order) is an offline RL framework that leverages large language models (LLMs) to generate temporally ordered subgoal sequences and corresponding state-to-subgoal-stage mappings. Using this temporal structure, STO-RL applies potential-based reward shaping to transform sparse terminal rewards into dense, temporally consistent signals, promoting subgoal progress while avoiding suboptimal solutions. Evaluations on four discrete and continuous sparse-reward benchmarks demonstrate that STO-RL consistently outperforms state-of-the-art offline goal-conditioned and hierarchical RL base-lines, achieving faster convergence, higher success rates, and shorter trajectories. Ablation studies further confirm STO-RL's robustness to imperfect or noisy LLM-generated subgoal sequences.",333.81,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08108v1_Debiasing Large Language Models via Adaptive Causa.pdf,Debiasing Large Language Models via Adaptive Causal Prompting with Sketch-of-Thought,"['Bowen Li', 'Ziqi Xu', 'Jing Ren', 'Renqiang Luo', 'Xikun Zhang', 'Xiuzhen Zhang', 'Yongli Ren', 'Feng Xia']","Despite notable advancements in prompting methods for Large Language Models (LLMs), such as Chain-of-Thought (CoT), existing strategies still suffer from excessive token usage and limited generalisability across diverse reasoning tasks. To address these limitations, the authors propose an Adaptive Causal Prompting with Sketch-of-Thought (ACPS) framework, which leverages structural causal models to infer the causal effect of a query on its answer and adaptively select an appropriate intervention. This design enables generalisable causal reasoning across heterogeneous tasks without task-specific retraining. By replacing verbose CoT with concise Sketch-of-Thought, ACPS enables efficient reasoning that significantly reduces token usage and inference cost. Extensive experiments on multiple reasoning benchmarks and LLMs demonstrate that ACPS consistently outperforms existing prompting baselines in terms of accuracy, robustness, and computational efficiency.",334.1,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08109v1_CSQL Mapping Documents into Causal Databases.pdf,Csql: Mapping Documents into Causal Databases,['Sridhar Mahadevan'],"We describe a novel system, Csql, that automatically converts a collection of unstructured text documents into an SQL-queryable causal database (CDB). Unlike retrieval-augmented generation (RAG) systems or knowledge-graph-centric approaches, which yield traditional databases, Csql supports causal analysis over document collections rather than purely associative retrieval. Csql also differs fundamentally from traditional causal inference methods, which typically focus on narrow, domain-specific studies grounded in numerical or experimental data. In contrast, Csql operates directly on large collections of unstructured text. A central feature of Csql is that it induces its relational schema directly from language. Unlike prior approaches that rely on hand-designed ontologies, fixed schemas, or domain-specific information extraction pipelines, Csql automatically constructs a causally grounded database whose structure emerges from the language itself.",335.29,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08118v1_MirrorBench An Extensible Framework to Evaluate Us.pdf,MIRRORBENCH: ANEXTENSIBLEFRAMEWORK TOEVALUATEUSER-PROXY AGENTS FORHUMAN-LIKENESS,"['Ashutosh Hathidara', 'Julien Yu', 'Vaishali Senthil', 'Sebastian Schreiber', 'Anil Babu Ankisettipalli']","Large language models (LLMs) are increasingly used as human simulators, both for evaluating conversational systems and for generating fine-tuning data. However, naive 'act-as-a-user' prompting often yields verbose, unrealistic utterances, underscoring the need for principled evaluation of user proxy agents. We present MIRRORBENCH, a reproducible, extensible benchmarking framework that evaluates user proxies solely on their ability to produce human-like user utterances across diverse conversational tasks, explicitly decoupled from downstream task success. MIRRORBENCH features a modular execution engine with typed interfaces, metadata-driven registries, multi-backend support, caching, and robust observability. The system supports pluggable user proxies, datasets, tasks, and metrics, enabling researchers to evaluate arbitrary simulators under a uniform, variance-aware harness. We include three lexical-diversity metrics (MATTR, YULE’S K, and HD-D) and three LLM-judge-based metrics (GTEVAL, PAIRWISEINDISTINGUISHABILITY, and RUBRIC-AND-REASON). Across four open datasets, MIRRORBENCH yields variance-aware results and reveals systematic gaps between user proxies and real human users. The framework is open source and includes a simple command-line interface for running experiments, managing configurations and caching, and generating reports.",334.15,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08125v1_How vehicles change lanes after encountering crash.pdf,How vehicles change lanes after encountering crashes: Empirical analysis and modeling,"['Kequan Chen', 'Yuxuan Wang*', 'Pan Liu*', 'Victor L. Knoop', 'David Z. W. Wang', 'Yu Han']",This paper explores how vehicles adjust their lane positions following collisions. It combines empirical data with modeling techniques to understand the dynamics of lane changes post-crashes.,330.14,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08127v1_PathoGen Diffusion-Based Synthesis of Realistic Le.pdf,PathoGen: Diffusion-Based Synthesis of Realistic Lesions in Histopathology Images,"['Mohamad Koohi-Moghadam', 'Mohammad-Ali Nikouei Mahani']","PathoGen is a diffusion-based generative model that synthesizes realistic lesions into benign histopathology images. Unlike conventional augmentation techniques, it leverages iterative refinement of diffusion models to create lesions with natural tissue boundaries, preserved cellular structures, and authentic staining characteristics. PathoGen is validated across four diverse datasets representing distinct diagnostic challenges and outperforms state-of-the-art generative baselines in image fidelity and distributional similarity. It enhances downstream segmentation performance compared to traditional geometric augmentations, particularly in data-scarce regimes. By simultaneously generating realistic morphology and pixel-level ground truth, PathoGen effectively overcomes the manual annotation bottleneck, offering a scalable pathway for developing generalizable medical AI systems despite limited expert-labeled data.",335.02,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08128v1_Embedded AI Companion System on Edge Devices.pdf,Embedded AI Companion System on Edge Devices,"['Rahul Gupta', 'Stephen Hsu']","This paper proposes a memory paradigm that alternates between active and inactive phases for an embedded AI companion system on edge devices. During user activity phases, the system performs low-latency, real-time dialog using lightweight retrieval over existing memories and context. During inactivity phases, it conducts more computationally intensive extraction, consolidation, and maintenance of memories. The design minimizes latency while maintaining long-term personalization under tight embedded hardware constraints. The paper also introduces an AI Companion benchmark to holistically evaluate the system's conversational quality and memory capabilities. Experiments show that the proposed system outperforms raw LLMs without memory and performs comparably to GPT-3.5 with 16k context window.",334.77,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08133v1_How Do Optical Flow and Textual Prompts Collaborat.pdf,How Do Optical Flow and Textual Prompts Collaborate to Assist in Audio-Visual Semantic Segmentation?,"['Peng Gao', 'Yujian Lee', 'Yongqi Xu', 'Wentao Fan']","Audio-visual semantic segmentation (AVSS) represents an extension of the audio-visual segmentation (AVS) task, necessitating a semantic understanding of audio-visual scenes beyond merely identifying sound-emitting objects at the visual pixel level. Contrary to a previous methodology, by decomposing the AVSS task into two discrete subtasks by initially providing a prompted segmentation mask to facilitate subsequent semantic analysis, our approach innovates on this foundational strategy. We introduce a novel collaborative framework, Stepping Stone Plus (SSP), which integrates optical flow and textual prompts to assist the segmentation process. In scenarios where sound sources frequently coexist with moving objects, our pre-mask technique leverages optical flow to capture motion dynamics, providing essential temporal context for precise segmentation. To address the challenge posed by stationary sound-emitting objects, such as alarm clocks, SSP incorporates two specific textual prompts: one identifies the category of the sound-emitting object, and the other provides a broader description of the scene. Additionally, we implement a visual-textual alignment module (VTA) to facilitate cross-modal integration, delivering more coherent and contextually relevant semantic interpretations. Our training regimen involves a post-mask technique aimed at compelling the model to learn the diagram of the optical flow. Experimental results demonstrate that SSP outperforms existing AVS methods, delivering efficient and precise segmentation results.",334.04,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08139v1_Subspace Alignment for Vision-Language Model Test-.pdf,Subspace Alignment for Vision-Language Model Test-time Adaptation,"['Zhichen Zeng', 'Wenxuan Bao', 'Xiao Lin', 'Ruizhong Qiu', 'Tianxin Wei', 'Xuying Ning', 'Yuchen Yan', 'Chen Luo', 'Monica Xiao Cheng', 'Jingrui He', 'Hanghang Tong']","Vision-language models (VLMs), despite their extraordinary zero-shot capabilities, are vulnerable to distribution shifts. Test-time adaptation (TTA) emerges as a predominant strategy to adapt VLMs to unlabeled test data on the fly. However, existing TTA methods heavily rely on zero-shot predictions as pseudo-labels for self-training, which can be unreliable under distribution shifts and misguide adaptation due to two fundamental limitations. First (Modality Gap), distribution shifts induce gaps between visual and textual modalities, making cross-modal relations inaccurate. Second (Visual Nuisance), visual embeddings encode rich but task-irrelevant noise that often overwhelms task-specific semantics under distribution shifts. To address these limitations, we propose SubTTA, which aligns the semantic subspaces of both modalities to enhance zero-shot predictions to better guide the TTA process. To bridge the modality gap, SubTTA extracts the principal subspaces of both modalities and aligns the visual manifold to the textual semantic anchor by minimizing their chordal distance. To eliminate visual nuisance, SubTTA projects the aligned visual features onto the task-specific textual subspace, which filters out task-irrelevant noise by constraining visual embeddings within the valid semantic span, and standard TTA is further performed on the purified space to refine the decision boundaries. Extensive experiments on various benchmarks and VLM architectures demonstrate the effectiveness of SubTTA, yielding an average improvement of 2.24% over state-of-the-art TTA methods.",334.58,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08141v1_Qalb Largest State-of-the-Art Urdu Large Language .pdf,Qalb: Largest State-of-the-Art Urdu Large Language Model for 230M Speakers with Systematic Continued Pre-training,"['1st Muhammad Taimoor Hassan', '2st Jawad Ahmed', '3st Muhammad Awais']","Despite remarkable progress in large language models, Urdu—a language spoken by over 230 million people—remains critically underrepresented in modern NLP systems. Existing multilingual models demonstrate poor performance on Urdu-specific tasks. We introduce Qalb, an Urdu language model developed through a two-stage approach: continued pre-training followed by supervised fine-tuning. Starting from LLaMA 3.1 8B, we perform continued pre-training on a dataset of 1.97 billion tokens. This corpus comprises 1.84 billion tokens of diverse Urdu text—spanning news archives, classical and contemporary literature, government documents, and social media—combined with 140 million tokens of English Wikipedia data to prevent catastrophic forgetting. We then fine-tune the resulting model on the Alif Urdu-instruct dataset. Through extensive evaluation on Urdu-specific benchmarks, Qalb demonstrates substantial improvements, achieving a weighted average score of 90.34 and outperforming the previous state-of-the-art Alif-1.0-Instruct model (87.1) by 3.24 points, while also surpassing the base LLaMA-3.1 8B-Instruct model by 44.64 points. Qalb achieves state-of-the-art performance with comprehensive evaluation across seven diverse tasks including Classification, Sentiment Analysis, and Reasoning. Our results demonstrate that continued pre-training on diverse, high-quality language data, combined with targeted instruction fine-tuning, effectively adapts foundation models to low-resource languages.",334.77,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08146v2_Mechanisms are Transferable Data-Efficient Low-Res.pdf,Mechanisms are Transferable: Data-Efficient Low-Resource Adaptation via Circuit-Targeted Supervised Fine-Tuning,"[""Khumaisa Nur'aini"", 'Ayu Purwarianti', 'Alham Fikri Aji', 'Derry Wijaya']","The paper proposes Circuit-Targeted Supervised Fine-Tuning (CT-SFT) for adapting large language models (LLMs) to low-resource languages. CT-SFT uses a label-balanced mean baseline and task-directional relevance scoring to identify task-relevant attention heads in a proxy-language checkpoint. It then transfers these heads to a target language by updating only those heads (plus LayerNorm) via head-level gradient masking. CT-SFT improves cross-lingual accuracy over continued full fine-tuning while updating only a small subset of model parameters. The authors find a trade-off between harder and easier transfers, with harder transfers favoring editing circuit heads and easier transfers often favoring near-zero updates. CT-SFT also reduces catastrophic forgetting, preserving proxy/source-language competence during transfer.",334.43,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08148v1_Enriching Semantic Profiles into Knowledge Graph f.pdf,Enriching Semantic Profiles into Knowledge Graph for Recommender Systems Using Large Language Models,"['Seokho Ahn', 'Sungbok Shin', 'Young-Duk Seo']","Rich and informative profiling to capture user preferences is essential for improving recommendation quality. However, there is no consensus on how best to construct and utilize such profiles. The authors revisit recent profiling-based approaches in recommender systems along four dimensions: knowledge base, preference indicator, impact range, and subject. They argue that large language models (LLMs) are effective at extracting compressed rationales from diverse knowledge sources, while knowledge graphs (KGs) are better suited for propagating these profiles to extend their reach. Building on this insight, they propose a new recommendation model, called SPiKE, which consists of three core components: entity profile generation using LLMs, profile-aware KG aggregation, and pairwise profile preference matching during training. Experiments demonstrate that SPiKE consistently outperforms state-of-the-art KG- and LLM-based recommenders in real-world settings.",334.02,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08149v1_Dynamic Graph Structure Learning via Resistance Cu.pdf,Dynamic Graph Structure Learning via Resistance Curvature Flow,"['Chaoqun Fei', 'Huanjiang Liu', 'Tinglve Zhou', 'Y angyang Li', 'Tianyong Hao']","Introduces a novel and computationally efficient curvature flow based on effective resistance from circuit theory, establishing a new paradigm for geometric graph structure evolution. Formulates the dynamic evolution equation of RCF, elucidates its mechanisms for manifold enhancement and noise suppression, and highlights its differentiability and compatibility with deep learning frameworks. Proposes an efficient Dynamic Graph Structure Learning method based on RCF. Extensive experiments on deep metric learning, manifold learning and graph structure learning tasks demonstrate that DGSL-RCF consistently improves representation quality and downstream performance with low runtime cost.",332.51,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08156v1_Project Synapse A Hierarchical Multi-Agent Framewo.pdf,Project Synapse: A Hierarchical Multi-Agent Framework with Hybrid Memory for Autonomous Resolution of Last-Mile Delivery Disruptions,"['Arin Gopalan Yadav', 'Varad Dherange', 'Kumar Shivam']","The operational efficiency of super-apps is critically dependent on the performance of their last-mile delivery (LMD) networks, which are increasingly vulnerable to complex, real-time disruptions. This paper introduces Project Synapse, a novel agentic framework designed for the autonomous resolution of LMD disruptions. Synapse employs a hierarchical multi-agent architecture, where a central Resolution Supervisor agent performs strategic task decomposition and delegates sub-tasks to a team of specialized worker agents responsible for tactical execution. A core contribution of this work is a novel Hybrid Memory Architecture that integrates short-term working memory, long-term episodic memory of past incidents, and a semantic memory of organizational policies. This cognitive architecture enables agents to perform stateful, context-aware, and factually-grounded reasoning. The system is orchestrated using LangGrapht to manage complex, cyclical workflows. To validate the framework, a benchmark dataset of 30 complex disruption scenarios was curated from a qualitative analysis of over 6,000 real-world user reviews. The system's performance was evaluated using an LLM-as-a-Judge protocol with explicit bias mitigation. Initial results are highly promising, with the Synapse system achieving 1.",335.29,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08160v1_SwiftMem Fast Agentic Memory via Query-aware Index.pdf,SwiftMem: Fast Agentic Memory via Query-aware Indexing,"['Anxin Tian', 'Yiming Li', 'Xing Li', 'Hui-Ling Zhen', 'Lei Chen', 'Xianzhi Yu', 'Zhenhua Dong', 'Mingxuan Yuan']","Agentic memory systems are crucial for enabling large language models (LLMs) to maintain long-term context and efficiently retrieve relevant information. However, existing memory frameworks perform exhaustive retrieval across the entire storage layer, leading to severe latency bottlenecks as memory grows. SwiftMem proposes a query-aware agentic memory system that achieves sub-linear retrieval through specialized indexing over temporal and semantic dimensions. Temporal indexing enables logarithmic-time range queries for time-sensitive retrieval, while the semantic DAG index maps queries to relevant topics through hierarchical tag structures. To address memory fragmentation during growth, SwiftMem introduces an embedding-tag co-consolidation mechanism that reorganizes storage based on semantic clusters to improve cache locality. Experiments on LoCoMo and LongMemEval benchmarks demonstrate that SwiftMem achieves 47× faster search compared to state-of-the-art baselines while maintaining competitive accuracy, enabling practical deployment of memory-augmented LLM agents.",333.51,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08166v1_ZeroDVFS Zero-Shot LLM-Guided Core and Frequency A.pdf,Zero-Shot LLM-Guided Core and Frequency Allocation for Embedded Platforms,"['Mohammad Pivezhandi', 'Mahdi Banisharif', 'Abusayeed Saifullah', 'Ali Jannesari']","Dynamic voltage and frequency scaling (DVFS) and task-to-core allocation are critical for thermal management and balancing energy and performance in embedded systems. Existing approaches either rely on utilization-based heuristics that overlook stall times, or require extensive offline profiling for table generation, preventing runtime adaptation. We propose a model-based hierarchical multi-agent reinforcement learning (MARL) framework for thermal- and energy-aware scheduling on multi-core platforms. Two collaborative agents decompose the exponential action space, achieving 358ms latency for subsequent decisions. First decisions require 3.5 to 8.0s including one-time LLM feature extraction. An accurate environment model leverages regression techniques to predict thermal dynamics and performance states. When combined with LLM-extracted semantic features, the environment model enables zero-shot deployment for new workloads on trained platforms by generating synthetic training data without requiring workload-specific profiling samples. We introduce LLM-based semantic feature extraction that characterizes OpenMP programs through 13 code-level features without execution. The Dyna-Q-inspired framework integrates direct reinforcement learning with model-based planning, achieving 20× faster convergence than model-free methods. Experiments on BOTS and PolybenchC benchmarks across NVIDIA Jetson TX2, Jetson Orin NX, RubikPi, and Intel Core i7 demonstrate 7.09 × better energy efficiency and 4.0 × better makespan than Linux ondemand governor. First-decision latency is 8,300$ times faster than table-based profiling, enabling practical deployment in dynamic embedded systems.",335.83,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08173v1_The Agents First Day Benchmarking Learning Explora.pdf,"The Agent’s First Day: Benchmarking Learning, Exploration, and Scheduling in the Workplace Scenarios","['Daocheng Fu', 'Jianbiao Mei', 'Rong Wu', 'Xuemeng Yang', 'Jia Xu', 'Ding Wang', 'Pinlong Cai', 'Yong Liu', 'B Licheng Wen', 'Botian Shi']","The rapid evolution of Multi-modal Large Language Models (MLLMs) has advanced workflow automation, but existing research mainly focuses on performance upper bounds in static environments, overlooking robustness for stochastic real-world deployment. This paper identifies three key challenges: dynamic task scheduling, active exploration under uncertainty, and continuous learning from experience. To bridge this gap, the authors introduce Trainee-Bench, a dynamic evaluation environment that simulates a ",325.41,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08176v1_Prompt-Based Clarity Evaluation and Topic Detectio.pdf,Prompt-Based Clarity Evaluation and Topic Detection in Political Question Answering,"['Lavanya Prahallad', 'Sai Utkarsh Choudarypally', 'Pragna Prahallad', 'Pranathi Prahallad']","This paper studies prompt-based clarity evaluation using the CLARITY dataset from the SemEval-2026 shared task. It compares a GPT-3.5 baseline with GPT-5.2 evaluated under three prompting strategies: simple prompting, chain-of-thought prompting, and chain-of-thought with few-shot examples. Results show that GPT-5.2 consistently outperforms the GPT-3.5 baseline on clarity prediction, with accuracy improving from 56% to 63% under chain-of-thought with few-shot prompting. Chain-of-thought prompting yields the highest evasion accuracy (34%), though improvements are less stable across fine-grained evasion categories. The paper also evaluates topic identification and finds that reasoning-based prompting improves accuracy from 60% to 74% relative to human annotations. Overall, the findings indicate that prompt design reliably improves high-level clarity evaluation, while fine-grained evasion and topic detection remain challenging despite structured reasoning prompts.",334.7,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08179v1_Instruction-Driven 3D Facial Expression Generation.pdf,Instruction-Driven 3D Facial Expression Generation and Transition,"['Anh H. V o', 'Tae-Seok Kim', 'Hulin Jin', 'Soo-Mi Choi', 'Yong-Guk Kim*']","A 3D avatar typically has one of six cardinal facial expressions. To simulate realistic emotional variation, we should be able to render a facial transition between two arbitrary expressions. This study presents a new framework for instruction-driven facial expression generation that produces a 3D face and, starting from an image of the face, transforms the facial expression from one designated facial expression to another. The Instruction-driven Facial Expression Decomposer (IFED) module is introduced to facilitate multimodal data learning and capture the correlation between textual descriptions and facial expression features. Subsequently, we propose the Instruction to Facial Expression Transition (I2FET) method, which leverages IFED and a vertex reconstruction loss function to refine the semantic comprehension of latent vectors, thus generating a facial expression sequence according to the given instruction. Lastly, we present the Facial Expression Transition model to generate smooth transitions between facial expressions. Extensive evaluation suggests that the proposed model outperforms state-of-the-art methods on the CK+ and CelebV-HQ datasets. The results show that our framework can generate facial expression trajectories according to text instruction. Considering that text prompts allow us to make diverse descriptions of human emotional states, the repertoire of facial expressions and the transitions between them can be expanded greatly. We expect our framework to find various practical applications. More information about our project can be found at https://vohoanganh.github.io/tg3dfet/",335.11,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08183v2_GI-Bench A Panoramic Benchmark Revealing the Knowl.pdf,GI-Bench: A Panoramic Benchmark Revealing the Knowledge-Experience Dissociation of Multimodal Large Language Models in Gastrointestinal Endoscopy Against Clinical Standards,"['Yan Zhu', 'Te Luo', 'Pei-Yao Fu', 'Zhen Zhang', 'Zi-Long Wang', 'Yi-Fan Qu', 'Zi-Han Geng', 'Jia-Qi Xu', 'Lu Yao', 'Li-Yun Ma', 'Wei Su', 'Wei-Feng Chen', 'Quan-Lin Li', 'Shuo Wang', 'Ping-Hong Zhou']","This study evaluates state-of-the-art Multimodal Large Language Models (MLLMs) across a panoramic gastrointestinal endoscopy workflow, comparing their performance against human endoscopists. The authors constructed GI-Bench, a benchmark encompassing 20 fine-grained lesion categories. Twelve MLLMs were evaluated across a five-stage clinical workflow: anatomical localization, lesion identification, diagnosis, findings description, and management. Model performance was benchmarked against three junior endoscopists and three residency trainees using Macro-F1, mean Intersection-over-Union (mIoU), and multi-dimensional Likert scale. The study found that Gemini-3-Pro achieved state-of-the-art performance in diagnostic reasoning.",336.52,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08185v1_Autonomous Materials Exploration by Integrating Au.pdf,Autonomous Materials Exploration by Integrating Automated Phase Identification and AI-Assisted Human Reasoning,"['Ming-Chiang Chang', 'Maximilian Amsler', 'Duncan R. Sutherland', 'Sebastian Ament', 'Katie R. Gann', 'Lan Zhou', 'Louisa M. Smieska', 'Arthur R. Woll', 'John M. Gregoire', 'Carla P. Gomes', 'R. Bruce van Dover', 'Michael O. Thompson']","Autonomous experimentation holds the potential to accelerate materials development by combining artificial intelligence (AI) with modular robotic platforms to explore extensive combinatorial chemical and processing spaces. The paper presents an autonomous materials synthesis extension to SARA, utilizing phase information provided by an automated probabilistic phase labeling algorithm to expedite the search for targeted phase regions. By incorporating human input into an expanded SARA-H framework, the efficiency of the underlying reasoning process is enhanced. The authors demonstrate the efficiency of their AI implementation using synthetic benchmarks and show that human input can contribute to significant improvement in sampling efficiency. Experimental active learning campaigns using robotic processing of thin-film samples of several oxide material systems are conducted, including Bi2O3, SnOx, and Bi-Ti-O, to synthesize and kinetically trap metastable phases. The utility of human-in-the-loop autonomous experimentation is showcased for the Bi-Ti-O system, identifying extensive processing domains that stabilize δ-Bi2O3 and Bi2Ti2O7, exploring ternary oxide phase behavior, and providing evidence confirming predictions that cationic substitutional doping of TiO2 with Bi inhibits the unfavorable transformation of the metastable anatase to the ground-state rutile phase. The developed autonomous methods enable the discovery of new materials and new understanding of materials synthesis and properties.",333.68,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08187v2_Improving LLM Reasoning with Homophily-aware Struc.pdf,IMPROVINGLLM REASONING WITHHOMOPHILY-AWARE STRUCTURAL AND SEMANTIC TEXT-ATTRIBUTED GRAPH COMPRESSION,"['Zijun Di', 'Bin Lu', 'Huquan Kang', 'Luoyi Fu', 'Jiaxin Ding', 'Xiaoying Gan', 'Lei Zhou', 'Xinbing Wang', 'Chenghu Zhou']","Large language models (LLMs) have shown promising capabilities in understanding Text-Attributed Graphs (TAGs). However, existing methods often rely on random sampling to handle the context window, leading to noise and instability in reasoning. This paper proposes Homophily-aware Structural and Semantic Compression for LLMs (HS2C), a framework that exploits graph homophily to improve LLMs' reasoning performance. Structurally, HS2C performs a global hierarchical partition to identify homophilic communities, reducing stochastic noise. Semantically, it compresses redundant background contexts into community-level consensus, preserving semantically homophilic information. Extensive experiments on 10 node-level benchmarks across various LLM sizes and families demonstrate that HS2C enhances compression rate and inference accuracy, validating its superiority and scalability. Notably, on OGBN-ArXiv, it achieves a 94.98% graph scale compression with a 3.06%–4.92% accuracy improvement.",335.5,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08189v2_ForgetMark Stealthy Fingerprint Embedding via Targ.pdf,FORGETMARK: STEALTHY FINGERPRINT EMBEDDING VIA TARGETED UNLEARNING IN LANGUAGE MODELS,"['Zhenhua Xu', 'Haobo Zhang', 'Zhebo Wang', 'Qichen Liu', 'Haitao Xu', 'Wenpeng Xing', 'Meng Han']","Existing invasive (backdoor) fingerprints suffer from high-perplexity triggers, fixed response patterns, and spurious activations. ForgetMark introduces a stealthy fingerprinting framework that encodes provenance via targeted unlearning. It builds a compact, human-readable key–value set with an assistant model and predictive-entropy ranking, then trains lightweight LoRA adapters to suppress original values on keys while preserving general capabilities. Ownership is verified under black/gray-box access by aggregating likelihood and semantic evidence into a fingerprint success rate. By relying on probabilistic forgetting traces rather than fixed trigger–response patterns, ForgetMark avoids high-perplexity triggers, reduces detectability, and lowers false triggers. Across diverse architectures and settings, it achieves 100% ownership verification on fingerprinted models while maintaining standard performance, surpasses backdoor baselines in stealthiness and robustness to model merging, and remains effective under moderate incremental fine-tuning.",332.38,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08196v1_Evaluating Implicit Regulatory Compliance in LLM T.pdf,Evaluating Implicit Regulatory Compliance in LLM Tool Invocation via Logic-Guided Synthesis,"['Da Song', 'Yuheng Huang', 'Boqi Chen', 'Tianshuo Cong', 'Randy Goebel', 'Lei Ma', 'Foutse Khomh']","Recent advances in large language models (LLMs) have enabled the emergence of LLM-based agents that can interpret complex user instructions, invoke external tools, and interact with the physical or digital world to achieve multi-step goals. However, in high-stakes domains such as financial services, legal reasoning, healthcare, and smart home control, functional task completion alone is insufficient; LLMs must consistently satisfy safety and regulatory constraints throughout the entire decision-making and execution process. Violations may result in severe consequences, including physical harm and regulatory non-compliance. To mitigate such risks, systematic evaluation and pre-deployment testing are essential. Existing evaluation practices fall short of this requirement, relying on static test sets derived from manual cura-tion or web scraping, which are expensive to scale, difficult to validate, and prone to data saturation. They primarily evaluate functional correctness, while treating implicit regulatory compliance as an overlooked aspect. To fill this gap, we introduce LOGISAFETYGEN, a framework that converts unstructured regulations into Linear Temporal Logic oracles and employs logic-guided fuzzing to synthesize valid, safety-critical traces. Building on this framework, we construct LOGISAFETYBENCH, a benchmark comprising 240 human-verified tasks that require LLMs to generate Python programs that satisfy both functional objectives and latent compliance rules. Evaluations of 13 state-of-the-art (SOTA) LLMs reveal that larger models, despite achieving better functional correctness, frequently prioritize task completion over safety, resulting in non-compliant behavior.",334.52,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08211v1_Adapting Rules of Official International Mahjong f.pdf,Adapting Rules of Official International Mahjong for Online Players,"['Chucai Wang', 'Lingfeng Li', 'Yunlong Lu', 'Wenxin Li']","As one of the worldwide spread traditional game, Official International Mahjong can be played and promoted online through remote devices instead of requiring face-to-face interaction. However, online players have fragmented playtime and unfixed combination of opponents in contrary to offline players who have fixed opponents for multiple rounds of play. Therefore, the rules designed for offline players need to be modified to ensure the fairness of online single-round play. Specifically, the authors employ a world champion AI to engage in self-play competitions and conduct statistical data analysis. Their study reveals the first-mover advantage and issues in the subgoal scoring settings. Based on their findings, they propose rule adaptations to make the game more suitable for the online environment, such as introducing compensatory points for the first-mover advantage and refining the scores of subgoals for different tile patterns. Compared with the traditional method of rotating positions over multiple rounds to balance first-mover advantage, their compensatory points mechanism in each round is more convenient for online players. Furthermore, they implement the revised Mahjong game online, which is open for online players. This work is an initial attempt to use data from AI systems to evaluate Official International Mahjong's game balance and develop a revised version of the traditional game better adapted for online players.",335.69,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08223v2_DNF Dual-Layer Nested Fingerprinting for Large Lan.pdf,DUAL-LAYER NESTED FINGERPRINTING FOR LARGE LANGUAGE MODEL INTELLECTUAL PROPERTY PROTECTION,"['Zhenhua Xu', 'Yiran Zhao', 'Mengting Zhong', 'Dezhang Kong', 'Changting Lin', 'Tong Qiao', 'Meng Han']","The rapid growth of large language models raises concerns about intellectual property protection under black-box deployment. Existing backdoor-based fingerprints either rely on rare tokens or use fixed trigger–response mappings that are brittle to leakage and post-hoc adaptation. The paper proposes Dual-Layer Nested Fingerprinting (DNF), a black-box method that embeds a hierarchical backdoor by coupling domain-specific stylistic cues with implicit semantic triggers. Across Mistral-7B, LLaMA-3-8B-Instruct, and Falcon3-7B-Instruct, DNF achieves perfect fingerprint activation while preserving downstream utility. Compared with existing methods, it uses lower-perplexity triggers, remains undetectable under fingerprint detection attack, and is relatively robust to incremental fine-tuning and model merging. These results position DNF as a practical, stealthy, and resilient solution for LLM ownership verification and IP protection.",334.21,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08224v1_An Axiomatic Approach to General Intelligence SANC.pdf,An Axiomatic Approach to General Intelligence,"['Daesuk Kwon', 'Won-gi Paeng']","This paper proposes SANC(E3), an axiomatic framework in which representational units are not given a priori but instead arise as stable outcomes of competitive selection, reconstruction, and compression under finite activation capacity, governed by the explicit minimization of an energy functional E3. SANC(E3) draws a principled distinction between system tokens and sensory sources, and introduces residual capacity Cremain(t) as an explicit control variable. The framework unifies perception, imagination, prediction, planning, and action within a single representational and energetic process, extending to embodied and physical agents. Twelve propositions show that category formation, automatic threshold tuning, hierarchical organization, unsupervised learning, and high-level cognitive activities can all be understood as instances of Gestalt completion under E3 minimization.",334.14,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08226v1_Knowledge-based learning in Text-RAG and Image-RAG.pdf,Knowledge-based learning in Text-RAG and Image-RAG,"['Alexander Shim', 'Khalil Saieh', 'Samuel Clarke']","This research analyzed and compared the multi-modal approach in the Vision Transformer (EVA-ViT) based image encoder with the LlaMA or ChatGPT LLM to reduce the hallucination problem and detect diseases in chest x-ray images. The text-based RAG effectively reduces the hallucination problem by using external knowledge information, and the image-based RAG improves prediction confidence and calibration by using KNN methods. The GPT LLM showed better performance, a low hallucination rate, and better Expected Calibration Error (ECE) than Llama Llama-based model. The research highlights the challenges of data imbalance and complex multi-stage structures but suggests a large experience environment and balanced example use.",334.74,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08230v1_GADPN Graph Adaptive Denoising and Perturbation Ne.pdf,GADPN: Graph Adaptive Denoising and Perturbation Networks via Singular Value Decomposition,"['Hao Deng', 'Bo Liu, Member, IEEE']","While Graph Neural Networks (GNNs) excel on graph-structured data, their performance is fundamentally limited by the quality of the observed graph, which often contains noise, missing links, or structural properties misaligned with GNNs' underlying assumptions. To address this, graph structure learning aims to infer a more optimal topology. Existing methods, however, often incur high computational costs due to complex generative models and iterative joint optimization, limiting their practical utility. In this paper, we propose GADPN, a simple yet effective graph structure learning framework that adaptively refines graph topology via low-rank denoising and generalized structural perturbation. Our approach makes two key contributions: (1) we introduce Bayesian optimization to adaptively determine the optimal denoising strength, tailoring the process to each graph's homophily level; and (2) we extend the structural perturbation method to arbitrary graphs via Singular Value Decomposition (SVD), overcoming its original limitation to symmetric structures. Extensive experiments on benchmark datasets demonstrate that GADPN not only achieves state-of-the-art performance but does so with significantly improved efficiency. It shows particularly strong gains on challenging disassortative graphs, validating its ability to robustly learn enhanced graph structures across diverse network types.",333.77,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08235v2_MPCI-Bench A Benchmark for Multimodal Pairwise Con.pdf,MPCI-Bench: A Benchmark for Multimodal Pairwise Contextual Integrity Evaluation of Language Model Agents,"['Shouju Wang', 'Haopeng Zhang']","As language-model agents evolve from passive chatbots into proactive assistants handling personal data, evaluating their adherence to social norms becomes increasingly critical. Existing benchmarks are largely text-centric and emphasize negative refusal scenarios, overlooking multimodal privacy risks and the trade-off between privacy and utility. This paper introduces MPCI-Bench, the first multimodal pairwise contextual integrity benchmark for evaluating privacy behavior in agentic settings. MPCI-Bench consists of paired positive and negative instances derived from the same visual source and instantiated across three tiers: normative Seed judgments, context-rich Story reasoning, and executable agent action Traces. Data quality is ensured through a Tri-Principle Iterative Refinement pipeline. Evaluations of state-of-the-art multimodal models reveal systematic failures to balance privacy and utility and a pronounced modality leakage gap, where sensitive visual information is leaked more frequently than textual information.",333.94,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08237v1_The End of Reward Engineering How LLMs Are Redefin.pdf,The End of Reward Engineering: How LLMs Are Redefining Multi-Agent Coordination,"['Haoran Su', 'Yandong Sun', 'Congjia Yu']","Reward engineering remains a bottleneck in multi-agent reinforcement learning due to credit assignment ambiguity, environmental non-stationarity, and complexity scaling. Large language models (LLMs) enable a paradigm shift from hand-crafted numerical rewards to natural language objectives. Recent work demonstrates LLMs' ability to generate human-level reward functions, adapt rewards dynamically, and coordinate agents through semantic understanding. This transition is validated by Reinforcement Learning from Verifiable Rewards (RLVR). The paper presents three pillars of this transition: semantic reward specification, dynamic adaptation, and inherent human alignment, while acknowledging computational cost, hallucination risks, and scalability challenges. The authors conclude with a vision for multi-agent systems where coordination emerges from shared semantic understanding.",336.26,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08251v1_Hyperbolic Heterogeneous Graph Transformer.pdf,Hyperbolic Heterogeneous Graph Transformer,"['Jongmin Park', 'Seunghoon Han', 'Hyewon Lee', 'Won-Yong Shin', 'Sungsu Lim']","In heterogeneous graphs, complex structures such as tree-like or hierarchical structures are observed. Recently, the hyperbolic space has been widely adopted to effectively learn these complex structures. Although existing methods have demonstrated the advantages of the hyperbolic space, they still face challenges such as mapping distortions and limited focus on local neighborhood information. To address these limitations, the authors propose Hyperbolic Heterogeneous Graph Transformer (HypHGT), which effectively and efficiently learns heterogeneous graph representations within the hyperbolic space. Unlike previous methods, HypHGT captures both local and global dependencies through a transformer-based architecture and uses a relation-specific hyperbolic attention mechanism with linear time complexity to preserve heterogeneous information across different relation types. The results demonstrate that HypHGT consistently outperforms state-of-the-art methods in node classification tasks, with significantly reduced training time and memory usage.",334.3,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08254v1_Large Artificial Intelligence Model Guided Deep Re.pdf,Large Artificial Intelligence Model–Guided Deep Reinforcement Learning for Resource Allocation in Non-Terrestrial Networks,"['Abdikarim Mohamed Ibrahim', 'Rosdiadee Nordin']","Large AI Model (LAM) have been proposed to applications of Non-Terrestrial Networks (NTN), that offer better performance with its great generalization and reduced task specific trainings. In this paper, we propose a Deep Reinforcement Learning (DRL) agent that is guided by a Large Language Model (LLM). The LLM operates as a high level coordinator that generates textual guidance that shape the reward of the DRL agent during training. The results show that the LAM-DRL outperforms the traditional DRL by 40% in nominal weather scenarios and 64% in extreme weather scenarios compared to heuristics in terms of throughput, fairness, and outage probability.",334.63,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08257v2_On Evaluation of Unsupervised Feature Selection fo.pdf,On Evaluation of Unsupervised Feature Selection for Pattern Classification,"['Gyu-Il Kim', 'Dae-Won Kim', 'Jaesung Lee']","This study revisits the evaluation paradigm of Unsupervised Feature Selection (UFS) by adopting a multi-label classification framework. Experiments on 21 multi-label datasets using several representative methods demonstrate that performance rankings differ markedly from those reported under single-label settings, suggesting the possibility of multi-label evaluation settings for fair and reliable comparison of UFS methods.",336.0,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08258v1_T3 Benchmarking Sycophancy and Skepticism in Causa.pdf,JSON_FAIL,[],N/A,180.6,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08262v1_VGG Induced Deep Hand Sign Language Detection.pdf,VGG Induced Deep Hand Sign Language Detection,"['Subham Sharma', 'Sharmila Subudhi']","Hand gesture recognition is an important aspect of human-computer interaction. This work proposes a novel hand gesture recognizing system for the differently-abled persons using a convolutional neural network, VGG-16 net, and Python/Keras libraries. The model is validated using the NUS dataset and a testing dataset of 10 classes created by Google's API capturing different gestures. The experimental results show that by combining transfer learning and image data augmentation, the VGG-16 net achieved around 98% accuracy.",339.02,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08271v1_Sparsity Is Necessary Polynomial-Time Stability fo.pdf,Sparsity Is Necessary: Polynomial-Time Stability for Agentic LMs in Large Action Spaces,['Angshul Majumdar'],"This paper formalizes the setting of Sparse Agentic Control (SAC) for sequential decision-making with a massive discrete action universe. It establishes sharp, compressed-sensing-style results for ℓ1,2-regularized policy learning, including estimation and value suboptimality scaling, exact tool-support recovery under certain conditions, and the necessity of sparse representations for dense policy classes. The paper also extends these results to partial observability, showing that LLMs matter only through a belief/representation error εb, preserving logarithmic dependence on M. The findings explain the instability of prompt-only controllers and provide guidance for tuning-free, online, robust, group-sparse, and interaction-aware SAC.",330.24,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08273v1_HIPPO Accelerating Video Large Language Models Inf.pdf,HIPPO: Accelerating Video Large Language Models Inference via Holistic-aware Parallel Speculative Decoding,"['Qitan Lv', 'Tianyu Liu', 'Wen Wu', 'Xuenan Xu', 'Bowen Zhou', 'Chao Zhang']","Speculative decoding (SD) has emerged as a promising approach to accelerate Large Language Models (LLMs) inference without sacrificing output quality. Existing SD methods tailored for video-LLMs primarily focus on pruning redundant visual tokens to mitigate the computational burden of massive visual inputs. However, existing methods do not achieve inference acceleration comparable to text-only LLMs. The authors observe that this phenomenon mainly stems from two limitations: (i) their pruning strategies inadequately preserve visual semantic tokens, degrading draft quality and acceptance rates; (ii) even with aggressive pruning (e.g., 90% visual tokens removed), the draft model's remaining inference cost limits overall speedup. To address these limitations, the authors propose HIPPO, a holistic-aware parallel speculative decoding framework. Specifically, HIPPO proposes (i) a semantic-aware token preservation method, which fuses global attention scores with local visual semantics to retain semantic information at high pruning ratios; (ii) a video parallel SD algorithm that decouples and overlaps draft generation and target verification phases. Experiments on four video-LLMs across six benchmarks demonstrate HIPPO's effectiveness, yielding up to 3.51× speedup compared to vanilla auto-regressive decoding.",334.54,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08276v1_ToolACE-MCP Generalizing History-Aware Routing fro.pdf,ToolACE-MCP: Generalizing History-Aware Routing from MCP Tools to the Agent Web,"['Zhiyuan Yao', 'Zishan Xu', 'Yifu Guo', 'Zhiguang Han', 'Cheng Yang', 'Shuo Zhang', 'Weinan Zhang', 'Xingshan Zeng', 'Weiwen Liu']","With the rise of the Agent Web and Model Context Protocol (MCP), the agent ecosystem is evolving into an open collaborative network, exponentially increasing accessible tools. However, current architectures face severe scalability and generality bottlenecks. To address this, the authors propose ToolACE-MCP, a pipeline for training history-aware routers to empower precise navigation in large-scale ecosystems. By leveraging a dependency-rich candidate graph to synthesize multi-turn trajectories, they effectively train routers with dynamic context understanding to create the plug-and-play Light Routing Agent. Experiments on real-world benchmarks MCP-Universe and MCP-Mark demonstrate superior performance. Notably, ToolACE-MCP exhibits critical properties for the future Agent Web: it not only generalizes to multi-agent collaboration with minimal adaptation but also maintains exceptional robustness against noise and scales effectively to massive candidate spaces. These findings provide a strong empirical foundation for universal orchestration in open-ended ecosystems.",334.45,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08280v1_Greedy Is Enough Sparse Action Discovery in Agenti.pdf,Greedy Is Enough: Sparse Action Discovery in Agentic LLMs,['Angshul Majumdar'],"Modern agentic systems operate in environments with extremely large action spaces, such as tool-augmented language models with thousands of available APIs or retrieval operations. Despite this scale, empirical evidence suggests that only a small subset of actions meaningfully influences performance in a given deployment. This work studies a contextual linear reward model in which action relevance is governed by a structured sparsity assumption. The authors formulate action discovery as a block-sparse recovery problem and analyze a greedy algorithm inspired by Orthogonal Matching Pursuit. Under standard assumptions on incoherence, signal strength, and action coverage, they prove that the greedy procedure exactly recovers the relevant action set with high probability, using a number of samples that scales polynomially in the sparsity level and latent dimension, and only logarithmically in the total number of actions. They further provide estimation error guarantees for refitted parameters and show that the resulting decision rule is near-optimal for new latent states. Complementing these results, they establish information-theoretic lower bounds demonstrating that sparsity and sufficient coverage are necessary for tractability. Together, their results identify sparse action discovery as a fundamental principle underlying large-action decision-making and provide a theoretical foundation for action pruning in agentic systems.",335.85,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08288v1_OpenMic A Multi-Agent-Based Stand-Up Comedy Genera.pdf,OpenMic: A Multi-Agent-Based Stand-Up Comedy Generation System,"['Yuyang Wu', 'Hanzhong Cao', 'Jianhao Chen', 'Yufei Li']","OpenMic is an end-to-end multi-agent system built on AutoGen that transforms a user-provided life topic into a 3–5 minute Chinese stand-up performance and produces a narrated comedy video. The system orchestrates multiple specialized agents in a multi-round iterative loop to jointly optimize humor, timing, and performability. To mitigate the dataset-task mismatch, OpenMic augments generation with retrieval-augmented generation (RAG) for material grounding and idea expansion, and fine-tunes a dedicated JokeWriter to better internalize stand-up-specific setup–punchline structures and long-range callbacks.",334.62,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08297v1_Demystifying the Slash Pattern in Attention The Ro.pdf,Demystifying the Slash Pattern in Attention: The Role of RoPE,"['Yuan Cheng', 'Fengzhuo Zhang', 'Yunlong Hou', 'Cunxiao Du', 'Chao Du', 'Tianyu Pang', 'Aixin Sun', 'Zhuoran Yang']","Large Language Models (LLMs) often exhibit slash attention patterns, where attention scores concentrate along the ∆-th sub-diagonal for some offset ∆. This paper demystifies the emergence of these Slash-Dominant Heads (SDHs) from both empirical and theoretical perspectives. By analyzing open-source LLMs, the authors find that SDHs are intrinsic to models and generalize to out-of-distribution prompts. Empirical analysis reveals two characteristic conditions of SDHs: (1) Queries and keys are almost rank-one, and (2) RoPE is dominated by medium- and high-frequency components. Under these conditions, queries and keys are nearly identical across tokens, and interactions between medium- and high-frequency components of RoPE give rise to SDHs.",334.51,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08302v1_Enhancing Sentiment Classification and Irony Detec.pdf,Enhancing Sentiment Classification and Irony Detection in Large Language Models through Advanced Prompt Engineering Techniques,"['Marvin Schmitt ∗∗', 'Anne Schwerk', 'Sebastian Lempert ∗']","This study investigates the use of prompt engineering to enhance large language models (LLMs), specifically GPT-4o-mini and gemini-1.5-flash, in sentiment analysis tasks. It evaluates advanced prompting techniques like few-shot learning, chain-of-thought prompting, and self-consistency against a baseline. Key tasks include sentiment classification, aspect-based sentiment analysis, and detecting subtle nuances such as irony. The research details the theoretical background, datasets, and methods used, assessing performance of LLMs as measured by accuracy, recall, precision, and F1 score. Findings reveal that advanced prompting significantly improves sentiment analysis, with the few-shot approach excelling in GPT-4o-mini and chain-of-thought prompting boosting irony detection in gemini-1.5-flash by up to 46%. Thus, while advanced prompting techniques overall improve performance, the fact that few-shot prompting works best for GPT-4o-mini and chain-of-thought excels in gemini-1.5-flash for irony detection suggests that prompting strategies must be tailored to both the model and the task. This highlights the importance of aligning prompt design with both the LLM’s architecture and the semantic complexity of the task.",333.01,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08310v1_ORBIT On-policy Exploration-Exploitation for Contr.pdf,ORBIT: On-policy Exploration-Exploitation for Controllable Multi-Budget Reasoning,"['Kun Liang', 'Clive Bai', 'Xin Xu', 'Chenming Tang', 'Sanwoo Lee', 'Weijie Liu', 'Saiyong Yang', 'Yunfang Wu']","Recent Large Reasoning Models achieve strong performance by leveraging long-form Chain-of-Thought reasoning, but uniformly applying overlong reasoning at inference time incurs substantial computational cost. ORBIT proposes a controllable multi-budget reasoning framework with well-separated reasoning modes triggered by input, employing multi-stage reinforcement learning to discover Pareto-optimal reasoning behaviors at each effort, followed by on-policy distillation to fuse these behaviors into a single unified model. Experiments show that ORBIT achieves controllable reasoning behavior over multiple modes, competitive reasoning density within each mode, and integration of frontier policies into a single unified student model while preserving clear mode separation and high per-mode performance.",330.89,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08311v1_Enhancing Image Quality Assessment Ability of LMMs.pdf,Enhancing Image Quality Assessment Ability of LMMs via Retrieval-Augmented Generation,"['Kang Fu', 'Huiyu Duan', 'Zicheng Zhang', 'Yucheng Zhu', 'Jun Zhao', 'Xiongkuo Min', 'Jia Wang', 'Guangtao Zhai']","Large Multimodal Models (LMMs) have shown remarkable promise in Image Quality Assessment (IQA), particularly in demonstrating strong zero-shot capability. However, achieving state-of-the-art performance often requires computationally expensive fine-tuning methods. Inspired by recent training-free works, we introduce IQARAG, a novel, training-free framework that enhances LMMs' IQA ability. IQARAG leverages Retrieval-Augmented Generation (RAG) to retrieve semantically similar but quality-variant reference images with corresponding Mean Opinion Scores (MOSs) for input images. These retrieved images and input image are integrated into a specific prompt, providing a visual perception anchor for the IQA task. IQARAG contains three key phases: Retrieval Feature Extraction, Image Retrieval, and Integration & Quality Score Generation. Extensive experiments across multiple IQA datasets demonstrate that IQARAG effectively boosts the IQA performance of LMMs, offering a resource-efficient alternative to fine-tuning.",333.81,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08323v1_AtomMem  Learnable Dynamic Agentic Memory with Ato.pdf,AtomMem : Learnable Dynamic Agentic Memory with Atomic Memory Operation,"['Yupeng Huo', 'Yaxi Lu', 'Zhong Zhang', 'Haotian Chen', 'Yankai Lin*']","Equipping agents with memory is essential for solving real-world long-horizon problems. However, most existing agent memory mechanisms rely on static and hand-crafted workflows, limiting performance and generalization. This paper proposes AtomMem, which reframes memory management as a dynamic decision-making problem, deconstructing high-level memory processes into fundamental atomic CRUD operations. By combining supervised fine-tuning with reinforcement learning, AtomMem learns an autonomous, task-aligned policy to orchestrate memory behaviors tailored to specific task demands. Experimental results across 3 long-context benchmarks demonstrate that the trained AtomMem-8B consistently outperforms prior static-workflow memory methods. Further analysis of training dynamics shows that the learning-based formulation enables the agent to discover structured, task-aligned memory management strategies, highlighting a key advantage over predefined routines.",334.15,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08327v1_Safe Heterogeneous Multi-Agent RL with Communicati.pdf,Safe Heterogeneous Multi-Agent RL with Communication Regularization for Coordinated Target Acquisition,"['Gabriele Calzolari', 'Vidya Sumathy', 'Christoforos Kanellakis', 'George Nikolakopoulos']","This paper introduces a decentralized multi-agent reinforcement learning framework enabling structurally heterogeneous teams of agents to jointly discover and acquire randomly located targets in environments characterized by partial observability, communication constraints, and dynamic interactions. Each agent's policy is trained with the Multi-Agent Proximal Policy Optimization algorithm and employs a Graph Attention Network encoder that integrates simulated range-sensing data with communication embeddings exchanged among neighboring agents, enabling context-aware decision-making from both local sensing and relational information. In particular, this work introduces a unified framework that integrates graph-based communication and trajectory-aware safety through safety filters. The architecture is supported by a structured reward formulation designed to encourage effective target discovery and acquisition, collision avoidance, and de-correlation between the agents' communication vectors by promoting informational orthogonality. The effectiveness of the proposed reward function is demonstrated through a comprehensive ablation study. Moreover, simulation results demonstrate safe, and stable task execution confirming the framework's effectiveness.",335.27,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08332v1_IGAN A New Inception-based Model for Stable and Hi.pdf,IGAN: A New Inception-based Model for Stable and High-Fidelity Image Synthesis Using Generative Adversarial Networks,"['Ahmed A. Hashim', 'Ali Al-Shuwaili', 'Asraa Saeed', 'Ali Al-Bayaty*']","This paper proposes a novel GAN structural model termed the Inception Generative Adversarial Network (IGAN) that incorporates deeper inception-inspired convolution and dilated convolution. The IGAN model generates high-quality synthetic images while maintaining training stability by reducing mode collapse and preventing vanishing and exploding gradients. It achieves a Fréchet Inception Distance (FID) of 13.12 and 15.08 on the CUB-200 and ImageNet datasets, respectively, representing a 28-33% improvement in FID over state-of-the-art GANs. Additionally, the IGAN model attains an Inception Score (IS) of 9.27 and 68.25, reflecting improved image diversity and generation quality. Dropout and spectral normalization techniques are used in both the generator and discriminator structures to further mitigate gradient explosion and overfitting. These findings confirm that the IGAN model potentially balances training stability with image generation quality, constituting a scalable and computationally efficient framework for high-fidelity image synthesis.",338.74,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08333v1_Semantic Laundering in AI Agent Architectures Why .pdf,Semantic Laundering in AI Agent Architectures: Why Tool Boundaries Do Not Confer Epistemic Warrant,"['Oleg Romanchuk', 'Roman Bondar']","This paper identifies a structural defect in AI agent architectures that conflate information transport mechanisms with epistemic justification mechanisms. The authors formalize this as semantic laundering, a pattern where propositions with absent or weak warrant are accepted by the system. They show that this effect is architecturally determined and systematically reproducible, constituting an architectural realization of the Gettier problem. The central result is the Theorem of Inevitable Self-Licensing, which states that under standard architectural assumptions, circular epistemic justification cannot be eliminated. The authors introduce the Warrant Erosion Principle as the fundamental explanation for this effect and demonstrate that scaling, model improvement, and LLM-as-judge schemes are structurally incapable of eliminating the problem.",332.28,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08360v1_Scalable Sequential Recommendation under Latency a.pdf,Scalable Sequential Recommendation under Latency and Memory Constraints,"['Adithya Parthasarathy', 'Aswathnarayan Muthukrishnan Kirubakaran', 'Vinoth Punniyamoorthy', 'Nachiappan Chockalingam', 'Lokesh Butra', 'Kabilan Kannan', 'Abhirup Mazumder', 'Sumit Saha']","This paper presents HoloMambaRec, a lightweight sequential recommendation architecture that combines holographic reduced representations for attribute-aware embedding with a selective state space encoder for linear-time sequence processing. Item and attribute information are bound using circular convolution, preserving embedding dimensionality while encoding structured metadata. A shallow selective state space backbone, inspired by recent Mamba-style models, enables efficient training and constant-time recurrent inference. Experiments on Amazon Beauty and MovieLens-1M datasets demonstrate that HoloMambaRec consistently outperforms SASRec and achieves competitive performance with GRU4Rec under a constrained 10-epoch training budget, while maintaining substantially lower memory complexity. The design further incorporates forward-compatible mechanisms for temporal bundling and inference-time compression, positioning HoloMambaRec as a practical and extensible alternative for scalable, metadata-aware sequential recommendation.",335.57,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08371v1_Geo-NVS-w Geometry-Aware Novel View Synthesis In-t.pdf,Geo-NVS-w: Geometry-Aware Novel View Synthesis In-the-Wild with an SDF Renderer,"['Anastasios Tsalakopoulos', 'Angelos Kanlis', 'Evangelos Chatzis', 'Antonis Karakottas', 'Dimitrios Zarpalas']","We introduce Geo-NVS-w, a geometry-aware framework for high-fidelity novel view synthesis from unstructured, in-the-wild image collections. Leveraging an underlying geometric representation based on a Signed Distance Function (SDF) to guide the rendering process, Geo-NVS-w addresses the limitation of existing in-the-wild methods by ensuring fine structural details are preserved. Our framework achieves competitive rendering performance and demonstrates a 4–5× reduction in energy consumption compared to similar methods. Geo-NVS-w yields photorealistic results with sharp, geometrically coherent details, robust for in-the-wild NVS.",332.14,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08379v1_Training-Free Distribution Adaptation for Diffusio.pdf,Training-Free Distribution Adaptation for Diffusion Models via Maximum Mean Discrepancy Guidance,"['Matina Mahdizadeh Sani', 'Nima Jamali', 'Mohammad Jalali', 'Farzan Farnia']","Training-free distribution adaptation for diffusion models via Maximum Mean Discrepancy (MMD) guidance. This method augments the reverse diffusion process with gradients of the MMD between generated samples and a reference dataset. It provides reliable distributional estimates from limited data, exhibits low variance in practice, and is efficiently differentiable, making it particularly well-suited for the guidance task. The framework can be extended to prompt-aware adaptation in conditional generation models via product kernels and applied with computational efficiency in latent diffusion models (LDMs). Experiments on synthetic and real-world benchmarks demonstrate that MMD Guidance can achieve distributional alignment while preserving sample fidelity.",333.48,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08380v1_Thematic Working Group 5 -- Artificial Intelligenc.pdf,EDUsummIT 2025 - eBook,"['Mary Webb', 'Matt Bower', 'Ana Amélia Carvalho', 'Fredrik Mørk Røkenes', 'Jodie Torrington', 'Jonathan D. Cohen', 'Yousra Chtouki', 'Kathryn MacCallum', 'Tanya Linden', 'Deirdre Butler', 'Juliana E. Raffagheli', 'Henriikka Vartiainen', 'Martina Ronci', 'Peter Tiernan', 'David M. Smith', 'Chris Shelton', 'Joyce Malyn-Smith', 'Pierre Gorissen']","TWG 5 focused on developing and implementing effective strategies for enhancing AI literacy and agency of teachers, equipping them with the knowledge and skills necessary to integrate AI into their teaching practices. Explorations covered curriculum design, professional development programs, practical classroom applications, and policy guidelines aimed at empowering educators to confidently utilize AI tools and foster a deeper understanding of AI concepts among students. The introduction discusses the impact of OpenAI's release of ChatGPT3 in November 2022, highlighting the potential disruptions to traditional educational processes and the concerns around plagiarism, academic integrity, creativity, and critical thinking.",334.16,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08382v2_A Qualitative Model to Reason about Object Rotatio.pdf,A Qualitative Model to Reason about Object Rotations – applied to solve the Cube Comparison Test,"['Zoe Falomira', 'aUmeå University, Computing Science Department, Sweden']","This paper presents a Qualitative model for Reasoning about Object Rotations (QOR) applied to solve the Cube Comparison Test (CCT) by Ekstrom et al. (1976). A conceptual neighborhood graph relating the Rotation movement to the Location change and the Orientation change of the features on the cube sides has been built and it produces composition tables to calculate inferences for reasoning about rotations. Studies in the literature show that spatial reasoning skills correlate with success in Science, Technology, Engineering, and Math (STEM) disciplines and have a unique role in the development of creativity or creative-thinking. Qualitative models are useful to represent knowledge and to reason in order to solve spatial reasoning tests. In this paper, a new qualitative descriptor for reasoning about object rotations (QOR) is presented and implemented in to reason about how object rotations change the localisation and orientation of their sides and to present an interactive version of the Cube Comparison Test.",333.04,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08383v1_Deconstructing Pre-training Knowledge Attribution .pdf,Deconstructing Pre-training: Knowledge Attribution Analysis in MoE and Dense Models,"['Bo Wang', 'Junzhuo Li', 'Hong Chen', 'Yuanlin Chu', 'Yuxuan Fan', 'Xuming Hu']","This paper introduces Gated-LPI (Log-Probability Increase), a neuron-level attribution metric, to analyze knowledge acquisition dynamics in Mixture-of-Experts (MoE) and dense models. It presents a time-resolved comparison of knowledge acquisition in MoE and dense architectures, tracking checkpoints over 1.2M and 600K training steps, respectively. The study reveals three patterns: (1) Low-entropy backbone, where the top approximately 1% of MoE neurons capture over 45% of positive updates, forming a high-utility core; (2) Early consolidation, where the MoE model locks into a stable importance profile within <100K steps, while the dense model remains volatile; (3) Functional robustness, where masking the ten most important MoE attention heads reduces relational HIT@10 by <10%, compared with >50% for the dense model. These patterns collectively demonstrate that sparsity fosters an intrinsically stable and distributed computational backbone from early in training, helping bridge the gap between sparse architectures and training-time interpretability.",334.37,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08388v1_Creativity in AI as Emergence from Domain-Limited .pdf,Creativity in AI as Emergence from Domain-Limited Generative Models,['Corina Chutaux'],"This paper proposes a generative perspective on creativity in AI, framing it as an emergent property of domain-limited generative models embedded within bounded informational environments. It introduces a conceptual decomposition of creativity into four interacting components: pattern-based generation, induced world models, contextual grounding, and arbitrariness, and examines how these components manifest in multimodal generative systems. By grounding creativity in the interaction between generative dynamics and domain-specific representations, this work aims to provide a technical framework for studying creativity as an emergent phenomenon in AI systems, rather than as a post hoc evaluative label.",338.24,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08393v1_Controlled LLM Training on Spectral Sphere.pdf,Controlled LLM Training on Spectral Sphere,"['Tian Xie', 'Haoming Luo', 'Haoyu Tang', 'Yiwen Hu', 'Jason Klein Liu Qingnan Ren', 'Yang Wang', 'Wayne Xin Zhao', 'Rui Yan', 'Bing Su', 'Chong Luo', 'Baining Guo']","Scaling large models requires optimization strategies that ensure rapid convergence grounded in stability. Maximal Update Parametrization (µP) provides a theoretical safeguard for width-invariant Θ(1) activation control, whereas emerging optimizers like Muon are only ""half-aligned"" with these constraints: they control updates but allow weights to drift. To address this limitation, the Spectral Sphere Optimizer (SSO) is introduced, which enforces strict module-wise spectral constraints on both weights and their updates. By deriving the steepest descent direction on the spectral sphere, SSO realizes a fully µP-aligned optimization process. Through extensive pretraining on diverse architectures, including Dense 1.7B, MoE 8B-A1B, and 200-layer DeepNet models, SSO consistently outperforms AdamW and Muon. Furthermore, significant practical stability benefits are observed, including improved MoE router load balancing, suppressed outliers, and strictly bounded activations.",336.16,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08401v1_An Explainable Two Stage Deep Learning Framework f.pdf,An Explainable Two-Stage Deep Learning Framework for Pericoronitis Assessment in Panoramic Radiographs Using YOLOv8 and ResNet-50,"['Ajo Babu George', 'Pranav S', 'Kunal Agarwal']","The study presents a two-stage deep learning framework for diagnosing pericoronitis on panoramic radiographs (OPGs). The first stage uses YOLOv8 to detect third molars and classify their anatomical positions and angulations based on Winter's classification. Detected regions are then fed into a second-stage classifier, a modified ResNet-50 architecture, for detecting radiographic features suggestive of pericoronitis. To enhance clinical trust, Grad-CAM is used to highlight key diagnostic regions on the radiographs. The YOLOv8 component achieved 92% precision and 92.5% mean average precision. The ResNet-50 classifier yielded F1-scores of 88% for normal cases and 86% for pericoronitis. Radiologists reported 84% alignment between Grad-CAM and their diagnostic impressions, supporting the radiographic relevance of the interpretability output. The system shows strong potential for AI-assisted panoramic assessment, with explainable AI features that support clinical confidence.",335.34,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08402v1_PATS Personality-Aware Teaching Strategies with La.pdf,PATS: Personality-Aware Teaching Strategies,"['Donya Rooein', 'Sankalan Pal Chowdhury', 'Mariia Eremeeva', 'Yuan Qin', 'Debora Nozza', 'Mrinmaya Sachan', 'Dirk Hovy']","Recent advances in large language models (LLMs) demonstrate their potential as educational tutors. However, different tutoring strategies benefit different student personalities, and mismatches can be counterproductive to student outcomes. Despite this, current LLM tutoring systems do not take into account student personality traits. To address this problem, the authors first construct a taxonomy that links pedagogical methods to personality profiles, based on pedagogical literature. They simulate student-teacher conversations and use their framework to let the LLM tutor adjust its strategy to the simulated student personality. The evaluation with human teachers shows that they consistently prefer the approach over two base lines. The method also increases the use of less common, high-impact strategies such as role-playing, which human and LLM annotators prefer significantly. The findings pave the way for developing more personalized and effective LLM use in educational applications.",333.08,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08403v1_Owen-Shapley Policy Optimization OSPO A Principled.pdf,Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for Generative Search LLMs,"['Abhijnan Nath', 'Alireza Bagheri Garakani', 'Tianchen Zhou', 'Fan Yang', 'Nikhil Krishnaswamy']","Large language models are increasingly trained via reinforcement learning for personalized recommendation tasks. Standard methods like GRPO rely on sparse, sequence-level rewards that create a credit assignment gap, obscuring which tokens drive success. This gap is especially problematic when models must infer latent user intent from under-specified language without ground truth labels. We introduce Owen-Shapley Policy Optimization (OSPO), a framework that redistributes sequence-level advantages based on tokens' marginal contributions to outcomes. Unlike value-model-based methods requiring additional computation, OSPO employs potential-based reward shaping via Shapley-Owen attributions to assign segment-level credit while preserving the optimal policy. By forming coalitions of semantically coherent units, OSPO identifies which response parts drive performance. Experiments on Amazon ESCI and H&M Fashion datasets show consistent gains over baselines, with notable test-time robustness to out-of-distribution retrievers unseen during training.",334.14,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08406v1_WebTrap Park An Automated Platform for Systematic .pdf,WebTrap Park: An Automated Platform for Systematic Security Evaluation of Web Agents,"['Xinyi Wu†', 'Jiagui Chen †', 'Geng Hong †', 'Jiayi Dong †', 'Xudong Pan †', 'Jiarun Dai †', 'Min Yang †B']","Web Agents are increasingly deployed to perform complex tasks in real web environments, yet their security evaluation remains fragmented and difficult to standardize. We present WebTrapPark, an automated platform for systematic security evaluation of Web Agents through direct observation of their concrete interactions with live web pages. WebTrapPark instantiates three major sources of security risk into 1,226 executable evaluation tasks and enables action-based assessment without requiring agent modification. Our results reveal clear security differences across agent frameworks, highlighting the importance of agent architecture beyond the underlying model. WebTrapPark is publicly accessible at https://security.fudan.edu.cn/webagent and provides a scalable foundation for reproducible Web Agent security evaluation.",332.93,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08412v1_Hybrid Distillation with CoT Guidance for Edge-Dro.pdf,Hybrid Distillation with CoT Guidance for Edge-Drone Control Code Generation,"['Yizhan Feng', 'Hichem Snoussi', 'Yuhang Wang', 'Jing Teng', 'Abel Cherouat', 'Tian Wang']","With large language models demonstrating significant potential in code generation tasks, their application to onboard control of resource-constrained Unmanned Aerial Vehicles has emerged as an important research direction. However, a notable contradiction exists between the high resource consumption of large models and the real-time, lightweight requirements of UAV platforms. This paper proposes an integrated approach that combines knowledge distillation, chain-of-thought guidance, and supervised fine-tuning for UAV multi-SDK control tasks, aiming to efficiently transfer complex reasoning and code generation capabilities to smaller models. Firstly, a high-quality dataset covering various mainstream UAV SDKs is constructed, featuring instruction-code-reasoning chains, and incorporates counterfactual negative samples for data augmentation, guiding the model to learn the end-to-end logic from instruction parsing to code generation. Secondly, leveraging DeepSeek-Coder-V2-Lite quantized via QLoRA as the teacher model, and based on a hybrid black-box and white-box distillation strategy, high-quality chain-of-thought soft labels are generated. These are combined with a weighted cross-entropy loss using hard labels to transfer complex reasoning capabilities to the smaller student model. Finally, through prompt tuning engineering optimized for the UAV control scenario, the model's performance on core tasks such as SDK type recognition and function call matching is enhanced. Experimental results indicate that the distilled lightweight model (parameters ≤ 1B) maintains high code generation accuracy while achieving significant improvements in deployment and inference efficiency, effectively demonstrating the feasibility and superiority of our approach in achieving precise and lightweight intelligent control for UAVs.",333.78,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08415v2_Regulatory gray areas of LLM Terms.pdf,Regulatory gray areas of LLM Terms,"['Brittany I. Davidson', 'Kate Muir', 'Florian A.D. Burnat', 'Adam N. Joinson']","Large Language Models (LLMs) are increasingly integrated into academic research pipelines; however, the Terms of Service governing their use remain under-examined. We present a comparative analysis of the Terms of Service of five major LLM providers (Anthropic, DeepSeek, Google, OpenAI, and xAI) collected in November 2025. Our analysis reveals substantial variation in the stringency and specificity of usage restrictions for general users and researchers. We identify specific complexities for researchers in security research, computational social sciences, and psychological studies. We identify 'regulatory gray areas' where Terms of Service create uncertainty for legitimate use. We contribute a publicly available resource comparing terms across platforms (OSF) and discuss implications for general users and researchers navigating this evolving landscape.",336.38,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08418v1_Taxon Hierarchical Tax Code Prediction with Semant.pdf,Taxon: Hierarchical Tax Code Prediction with Semantically Aligned LLM Expert Guidance,"['Jihang Li', 'Qing Liu', 'Zulong Chen', 'Jing Wang', 'Wei Wang', 'Chuanfei Xu', 'Zeyi Wen']","Taxon is a semantically aligned and expert-guided framework for hierarchical tax code prediction. It integrates a feature-gating mixture-of-experts architecture and a semantic consistency model distilled from large language models. To address noisy supervision, it combines curated tax databases, invoice validation logs, and merchant registration data. Extensive experiments on proprietary and public benchmarks show that Taxon achieves state-of-the-art performance, improving structural and semantic consistency. Taxon has been deployed in Alibaba's tax service system, handling over 500,000 tax code queries per day and reaching peak volumes of up to five million requests, with improved accuracy, interpretability, and robustness.",333.38,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08430v1_RubricHub A Comprehensive and Highly Discriminativ.pdf,RubricHub: A Comprehensive and Highly Discriminative Rubric Dataset via Automated Coarse-to-Fine Generation,"['Sunzhu Li', 'Jiale Zhao', 'Miteto Wei', 'Huimin Ren', 'Yang Zhou', 'Jingwen Yang', 'Shunyu Liu', 'Kaike Zhang', 'Wei Chen']","RubricHub is a large-scale dataset (∼110k) and multi-domain dataset introduced to address the challenge of optimizing open-ended generation in reinforcement learning with verifiable rewards. The authors propose an automated Coarse-to-Fine Rubric Generation framework that combines principle-guided synthesis, multi-model aggregation, and difficulty evolution to produce comprehensive and highly discriminative criteria. The dataset is validated through a two-stage post-training pipeline comprising Rubric-based Rejection Sampling Fine-Tuning (RuFT) and Reinforcement Learning (RuRL). Experimental results demonstrate significant performance gains, with the post-trained Qwen3-14B achieving state-of-the-art results on HealthBench (69.3), surpassing proprietary frontier models like GPT-5. The authors also provide a short poem and a rubric to illustrate the difference between coarse-grained and fine-grained evaluation.",334.36,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08434v3_Large Multimodal Models for Embodied Intelligent D.pdf,Large Multimodal Models for Embodied Intelligent Driving: The Next Frontier in Self-Driving?,"['Long Zhang', 'Yuchen Xia', 'Bingqing Wei', 'Zhen Liu', 'Shiwen Mao', 'Zhu Han', 'Mohsen Guizani']","The advent of Large Multimodal Models (LMMs) offers a promising technology to tackle the limitations of modular design in autonomous driving, which often falters in open-world scenarios requiring sustained environmental understanding and logical reasoning. Embodied artificial intelligence facilitates policy optimization through closed-loop interactions to achieve continuous learning capability, thereby advancing autonomous driving toward embodied intelligent (El) driving. This article introduces a novel semantics and policy dual-driven hybrid decision framework to tackle this challenge, ensuring continuous learning and joint decision. The framework merges LMMs for semantic understanding and cognitive representation, and deep reinforcement learning (DRL) for real-time policy optimization. A case study is conducted experimentally to validate the performance superiority of our framework in completing lane-change planning task. Several future research directions are identified to empower El driving.",332.8,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08441v1_YaPO Learnable Sparse Activation Steering Vectors .pdf,YaPO: Learnable Sparse Activation Steering Vectors for Domain Adaptation,"['Abdelaziz Bounhar', 'Rania Hossam Elmohamady Elbadry', 'Hadi Abdine', 'Preslav Nakov', 'Michalis Vazirgiannis', 'Guokan Shang']","Steering Large Language Models (LLMs) through activation interventions has emerged as a lightweight alternative to fine-tuning for alignment and personalization. Recent work on Bi-directional Preference Optimization (BiPO) shows that dense steering vectors can be learned directly from preference data in a Direct Preference Optimization (DPO) fashion, enabling control over truthfulness, hallucinations, and safety behaviors. However, dense steering vectors often entangle multiple latent factors due to neuron multi-semanticity, limiting their effectiveness and stability in fine-grained settings such as cultural alignment. In this paper, we propose Y aPO, a reference-free method that learns sparse steering vectors in the latent space of a Sparse Autoencoder (SAE). By optimizing sparse codes, Y aPO produces disentangled, interpretable, and efficient steering directions. Empirically, we show that Y aPO converges faster, achieves stronger performance, and exhibits improved training stability compared to dense steering baselines. Beyond cultural alignment, Y aPO generalizes to a range of alignment-related behaviors, including hallucination, wealth-seeking, jail-break, and power-seeking. Importantly, Y aPO preserves general knowledge, with no measurable degradation on MMLU. Overall, our results show that Y aPO provides a general recipe for efficient, stable, and fine-grained alignment of LLMs, with broad applications to controllability and domain adaptation.",336.26,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08444v1_Beyond Linearization Attributed Table Graphs for T.pdf,Beyond Linearization: Attributed Table Graphs for Table Reasoning,"['Yuxiang Wang', 'Junhao Gan', 'Shengxiang Gao', 'Shenghao Ye', 'Zhengyi Yang', 'Jianzhong Qi']","Table reasoning aims to answer questions by reasoning over data presented in tables. Recent studies leverage the semantic understanding and reasoning capabilities of Large Language Models (LLMs) for table reasoning. They typically follow two paradigms: (i) decomposition-based reasoning, which generates executable code or conducts iterative symbolic operations to decompose tables, and then reasons over the decomposed subtables, and (ii) full-table reasoning, which applies Linearization-based Methods. Linearization-based methods linearize tables to form plain texts that are served as input to LLMs, but this paradigm has critical issues such as losing table structures, lacking explicit reasoning paths for result explainability, and being subject to the 'lost-in-the-middle' issue. To address these issues, the authors propose Table Graph Reasoner (TABGR), a training-free model that represents tables as an Attributed Table Graph (ATG). The ATG explicitly preserves row-column-cell structures while enabling graph-based reasoning for explainability. They further propose a Question-Guided Personalized PageRank (QG-PPR) mechanism to rerank tabular data and mitigate the lost-in-the-middle issue. Extensive experiments on two commonly used benchmarks show that TABGR consistently outperforms state-of-the-art models by up to 9.7% in accuracy.",334.39,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08448v1_Divide and Conquer Static-Dynamic Collaboration fo.pdf,Divide and Conquer: Static-Dynamic Collaboration for Few-Shot Class-Incremental Learning,"['Kexin Bao', 'Daichi Zhang∗', 'Yong Li', 'Dan Zeng', 'Shiming Ge∗']","Few-shot class-incremental learning (FSCIL) aims to continuously recognize novel classes under limited data, suffering from the key stability-plasticity dilemma. The authors propose a framework termed Static-Dynamic Collaboration (SDC) to achieve a better trade-off between stability and plasticity. Specifically, their method divides the normal pipeline of FSCIL into Static Retaining Stage (SRS) and Dynamic Learning Stage (DLS), which harnesses old static and incremental dynamic class information, respectively. By employing both stages, their method achieves improved retention of old knowledge while continuously adapting to new classes. Extensive experiments on public benchmarks and a real-world application dataset demonstrate state-of-the-art performance.",334.7,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08450v1_Decoding Order Matters in Autoregressive Speech Sy.pdf,DECODING ORDER MATTERS IN AUTOREGRESSIVE SPEECH SYNTHESIS,"['Minghui Zhao', 'Anton Ragni']","This paper investigates the impact of decoding order on autoregressive speech synthesis using a masked diffusion framework. It shows that randomness in decoding order affects speech quality and compares fixed and adaptive decoding strategies. The authors find that fixed-order decoding, including the left-to-right approach, is suboptimal, while adaptive decoding yields better performance. They also explore the use of quantized acoustic representations to support high-quality speech synthesis.",332.59,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08457v1_An Under-Explored Application for Explainable Mult.pdf,An Under-Explored Application for Explainable Multimodal Misogyny Detection,"['Sargam Yadava', 'Abhishek Kaushik', 'Kevin Mc Daid']","Digital platforms have become a hub for communication, business, and connectivity, but they also facilitate the spread of hate speech and misogyny. This paper presents a multi-modal and explainable web application for detecting misogyny in text and memes in code-mixed Hindi and English. The system leverages state-of-the-art transformer-based models and provides feature importance scores using explainability techniques like SHAP and LIME. The application aims to serve as a tool for researchers and content moderators to combat gender-based digital violence and ensure a safe digital space. The system has been evaluated using human evaluators who provided their responses on Chatbot Usability Questionnaire (CUQ) and User Experience Questionnaire (UEQ) to determine overall usability.",333.48,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08462v1_M3-BENCH Process-Aware Evaluation of LLM Agents So.pdf,M3-BENCH: Process-Aware Evaluation of LLM Agents Social Behaviors in Mixed-Motive Games,"['Sixiong Xie*', 'Zhuofan Shi*', 'Haiyang Shen*', 'Gang Huang', 'Yun Ma', 'Xiang Jing*']","As large language model agents become increasingly capable, their advanced social behaviors in complex interactions—including cooperation, deception, alliance formation, and collusion—have attracted widespread attention. To systematically assess these capabilities, researchers have proposed a variety of benchmarks. However, existing efforts still commonly suffer from two key limitations: the narrowness of evaluation dimensions and the outcome-oriented nature of evaluation. M3-BENCH, a multi-stage benchmark for mixed-motive games, proposes a process-aware evaluation framework that conducts synergistic analysis across three modules: BTA (Behavioral Trajectory Analysis), RPA (Reasoning Process Analysis), and CCA (Communication Content Analysis). Furthermore, it integrates the Big Five personality model and Social Exchange Theory to aggregate multi-dimensional evidence into interpretable social behavior portraits, thereby characterizing agents' personality traits and capability profiles beyond simple task scores or outcome-based metrics. Experimental results show that M3-BENCH can reliably distinguish diverse social behavior competencies across models, and it reveals that some models achieve seemingly reasonable behavioral outcomes while exhibiting pronounced inconsistencies in their reasoning and communication.",333.25,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08464v1_CoMa Contextual Massing Generation with Vision-Lan.pdf,CoMa: Contextual Massing Generation with Vision-Language Models,"['Evgenii Maslov', 'Valentin Khrulkov', 'Anastasia Volkova', 'Anton Gusarov', 'Andrey Kuznetsov', 'Ivan Oseledets']","The paper proposes an automated framework for generating building massing based on functional requirements and site context. It introduces the CoMa-20K dataset, a comprehensive collection that includes detailed massing geometries, associated economical and programmatic data, and visual representations of the development site within its existing urban context. The authors benchmark this dataset by formulating massing generation as a conditional task for Vision-Language Models (VLMs), evaluating both fine-tuned and large zero-shot models. The experiments reveal the inherent complexity of the task and demonstrate the potential of VLMs to produce context-sensitive massing options. The dataset and analysis establish a foundational benchmark and highlight significant opportunities for future research in data-driven architectural design.",335.95,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08468v1_JudgeRLVR Judge First Generate Second for Efficien.pdf,"Judge First, Generate Second for Efficient Reasoning","['Jiangshan Duo †‡★', 'Hanyu Li ‡§', 'Hailin Zhang ‡', 'Yudong Wang †‡', 'Sujian Li †⋄', 'Liang Zhao ‡⋄']","This paper proposes JudgeRLVR, a two-stage judge-then-generate paradigm for Reinforcement Learning with Verifiable Rewards (RLVR). The first stage trains the model to judge solution responses with verifiable answers, and the second stage fine-tunes the model with vanilla generating RLVR initialized from the judge. Compared to Vanilla RLVR, JudgeRLVR achieves a better quality-efficiency trade-off, delivering significant accuracy gains on in-domain math tasks and demonstrating enhanced generalization on out-of-domain benchmarks.",333.52,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08472v1_sui-1 Grounded and Verifiable Long-Form Summarizat.pdf,Grounded and Verifiable,"['Benedikt Droste*', 'Jan Philipp Harries', 'Maximilian Idahl', 'Björn Plüster', 'ellamind']","The paper introduces sui-1, a 24B parameter model that produces abstractive summaries with inline citations, enabling users to trace each claim to its source sentence. The model processes documents up to 100K tokens in a single pass and supports iterative processing for texts exceeding 2 million tokens. The authors address the challenge of training citation-grounded models by using a capable teacher model for synthetic data generation and automated verification to ensure citation accuracy before training. Evaluation shows that sui-1 significantly outperforms all tested open-weight baselines, including models with 3× more parameters, demonstrating that task-specific training provides greater benefit than scale alone for citation-grounded summarization.",335.74,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08475v1_SUMMPILOT Bridging Efficiency and Customization fo.pdf,SUMMPILOT: Bridging Efficiency and Customization for Interactive Summarization System,"['JungMin Yun', 'Juhwan Choi', 'Kyohoon Jin', 'Soojin Jang', 'Jinhee Jang', 'YoungBin Kim']","This paper introduces SUMMPILOT, an interactive customizable summarization system that combines the efficiency of automatic summarization with personalized summaries tailored to individual users' interests and requirements. SUMMPILOT leverages a large language model to facilitate both automatic and interactive summarization. Users can engage with the system to understand document content and personalize summaries through interactive components such as semantic graphs, entity clustering, and explainable evaluation. The system demonstrates adaptability and usefulness for customizable summarization through demos and user studies, addressing the limitations of existing interactive summarization systems by incorporating user-specific needs into the summarization process.",330.33,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08490v1_BenchOverflow Measuring Overflow in Large Language.pdf,BenchOverflow: Measuring Overflow in Large Language Models via Plain-Text Prompts,"['Erin Feiglin', 'Nir Hutnik', 'Raz Lapid']","This paper investigates a failure mode of large language models (LLMs) in which plain-text prompts elicit excessive outputs, termed Overflow. The authors introduce BenchOverflow, a model-agnostic benchmark of nine plain-text prompting strategies that amplify output volume without adversarial suffixes or policy circumvention. Using a standardized protocol with a fixed budget of 5,000 new tokens, they evaluate nine open- and closed-source models and observe pronounced rightward shifts and heavy tails in length distributions. The paper also discusses the practical implications of Overflow, including economic and environmental costs, and proposes a lightweight mitigation strategy.",335.56,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08493v1_PKI Prior Knowledge-Infused Neural Network for Few.pdf,PKI: Prior Knowledge-Infused Neural Network for Few-Shot Class-Incremental Learning,"['Kexin Bao', 'Fanzhao Lin', 'Zichen Wang', 'Yong Li', 'Dan Zeng', 'Shiming Ge']","Few-shot class-incremental learning (FSCIL) aims to continually adapt a model on a limited number of new-class examples, facing two well-known challenges: catastrophic forgetting and overfitting to new classes. Existing methods tend to freeze more parts of network components and finetune others with an extra memory during incremental sessions. These methods emphasize preserving prior knowledge to ensure proficiency in recognizing old classes, thereby mitigating catastrophic forgetting. Meanwhile, constraining fewer parameters can help in overcoming overfitting with the assistance of prior knowledge. Following previous methods, we retain more prior knowledge and propose a prior knowledge-infused neural network (PKI) to facilitate FSCIL. PKI consists of a backbone, an ensemble of projectors, a classifier, and an extra memory. In each incremental session, we build a new projector and add it to the ensemble. Subsequently, we finetune the new projector.",311.74,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08499v2_EfficientFSL Enhancing Few-Shot Classification via.pdf,EfficientFSL: Enhancing Few-Shot Classification via Query-Only Tuning in Vision Transformers,"['Wenwen Liao', 'Hang Ruan', 'Jianbo Yu*', 'Bing Song', 'Yuansong Wang', 'Xiaofeng Yang']","EfficientFSL is a query-only fine-tuning framework specifically designed for few-shot classification with Vision Transformers (ViTs). It achieves competitive performance while significantly reducing computational overhead. The framework leverages the knowledge embedded in the pre-trained model and its strong comprehension ability to achieve high classification accuracy with an extremely small number of tunable parameters. It introduces a lightweight trainable Forward Block to synthesize task-specific queries that extract informative features from the intermediate representations of the pre-trained model in a query-only manner. A Combine Block fuses multi-layer outputs, enhancing the depth and robustness of feature representations. Finally, a Support-Query Attention Block mitigates distribution shift by adjusting prototypes to align with the query set distribution. With minimal trainable parameters, EfficientFSL achieves state-of-the-art performance on four in-domain few-shot datasets and six cross-domain datasets, demonstrating its effectiveness in real-world applications.",309.15,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08503v1_Temporal Fusion Nexus A task-agnostic multi-modal .pdf,Temporal Fusion Nexus: A task-agnostic multi-modal embedding model for clinical narratives and irregular time series in post-kidney transplant care,"['Aditya Kumar', 'Simon Rauch', 'Mario Cypko', 'Marcel Naik', 'Matthieu-P Schapranow', 'Aadil Rashid', 'Fabian Halleck', 'Bilgin Osmanodja', 'Roland Roller', 'Lars Pape', 'Klemens Budde', 'Mario Schiffer', 'Oliver Amft']","We introduce Temporal Fusion Nexus (TFN), a multi-modal and task-agnostic embedding model to integrate irregular time series and unstructured clinical narratives. TFN achieved higher performance for graft loss (AUC 0.96 vs. 0.94) and graft rejection (AUC 0.84 vs. 0.74) compared to state-of-the-art models in post-kidney transplant care. In mortality prediction, TFN yielded an AUC of 0.86. TFN outperformed unimodal baselines (≈10% AUC improvement over time series only baseline, ≈5% AUC improvement over time series with static patient data). Integrating clinical text improved performance across all tasks. Disentanglement metrics confirmed robust and interpretable latent factors in the embedding space, and SHAP-based attributions confirmed alignment with clinical reasoning. TFN has potential application in clinical tasks beyond KTx.",314.02,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08509v1_What If TSF A Benchmark for Reframing Forecasting .pdf,What If TSF: A Benchmark for Reframing Forecasting as Scenario-Guided Multimodal Forecasting,"['Jinkwan Jang', 'Hyunbin Jin', 'Hyungjin Park', 'Kyubyung Chae', 'Taesup Kim']","Time series forecasting is critical for decision-making, but most methods are unimodal and rely on historical patterns. Recent progress in large language models highlights the potential for multimodal forecasting, but existing benchmarks provide retrospective or misaligned raw context, making it unclear if models leverage textual inputs meaningfully. Inspired by human experts' use of what-if scenarios, What If TSF (WIT) introduces a benchmark to evaluate whether models can condition forecasts on contextual text, especially future scenarios. WIT provides expert-crafted plausible or counterfactual scenarios for rigorous testing of scenario-guided multimodal forecasting.",329.7,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08510v2_STAGE A Benchmark for Knowledge Graph Construction.pdf,"STAGE: A Benchmark for Knowledge Graph Construction, Question Answering, and In-Script Role-Playing over Movie Screenplays","['Qiuyu Tian', 'Yiding Li', 'Fengyi Chen', 'Zequn Liu', 'Youyong Kong', 'Fan Guo', 'Yuyao Li', 'Jinjing Shen', 'Zhijing Xie', 'Yiyun Luo', 'Xin Zhang']","Movie screenplays are rich, long-form narratives that interleave complex character relationships, temporally ordered events, and dialogue-driven interactions. Prior benchmarks target individual subtasks such as question answering or dialogue generation, but rarely evaluate whether models can construct a coherent story world and use it consistently across multiple forms of reasoning and generation. We introduce STAGE, a unified benchmark for narrative understanding over full-length movie screenplays, defining four tasks: knowledge graph construction, scene-level event summarization, long-context screenplay question answering, and in-script character role-playing, all grounded in a shared narrative world representation. The benchmark provides cleaned scripts, curated knowledge graphs, and event- and character-centric evaluation.",311.56,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08519v1_CD2 Constrained Dataset Distillation for Few-Shot .pdf,CD2: Constrained Dataset Distillation for Few-Shot Class-Incremental Learning,"['Kexin Bao', 'Daichi Zhang', 'Hansong Zhang', 'Yong Li', 'Yutao Yue', 'Shiming Ge']","Few-shot class-incremental learning (FSCIL) faces the challenge of catastrophic forgetting, where models tend to overwrite previously acquired concepts when confronted with new data. This paper proposes a framework termed Constrained Dataset Distillation (CD2) to facilitate FSCIL, which includes a dataset distillation module (DDM) and a distillation constraint module (DCM). The DDM synthesizes highly condensed samples guided by the classifier, forcing the model to learn compact essential class-related clues from a few incremental samples. The DCM introduces a designed loss to constrain the previously learned class distribution, preserving distilled knowledge more sufficiently. Extensive experiments on three public datasets demonstrate the superiority of the proposed method over state-of-the-art competitors.",309.9,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08531v1_Sketch-Based Facade Renovation With Generative AI .pdf,Sketch-Based Facade Renovation With Generative AI Models,"['Warissara Booranamaitree', 'Xusheng Du', 'Y ushu Cai', 'Zhengyang Wang', 'Ye Zhang', 'Haoran Xie']","Facade renovation offers a sustainable alternative to full demolition, but producing design proposals that preserve existing structures while expressing new intent remains challenging. Current workflows typically require detailed as-built modelling before design, which is time-consuming, labour-intensive, and often involves repeated revisions. To solve this issue, the authors propose a three-stage framework combining generative artificial intelligence (AI) and vision-language models (VLM) that directly processes rough structural sketch and textual descriptions to produce consistent renovation proposals. The framework bypasses the need for detailed as-built modelling, enabling architects to rapidly explore design alternatives, iterate on early-stage concepts, and communicate renovation intentions with greater clarity.",321.76,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08545v2_Learner-Tailored Program Repair A Solution Generat.pdf,Learner-Tailored Program Repair: A Solution Generator with Iterative Edit-Driven Retrieval Enhancement,"['Zhenlong Dai', 'Zhuoluo Zhao', 'Hengning Wang', 'Xiu Tang', 'Sai Wu', 'Chang Yao', 'Zhipeng Gao', 'Jingyuan Chen']","With the development of large language models (LLMs) in programming, intelligent programming coaching systems have gained widespread attention. However, most research focuses on repairing the buggy code of programming learners without providing the underlying causes of the bugs. To address this gap, we introduce a novel task, namely LPR (Learner-Tailored Program Repair). We propose a novel and effective framework, LSGEN (Learner-Tailored Solution Generator), to enhance program repair while offering bug descriptions for buggy code. In the first stage, we utilize a repair solution retrieval framework to construct a solution retrieval database and employ an edit-driven code retrieval approach to retrieve valuable solutions, guiding LLMs in identifying and fixing bugs in buggy code. In the second stage, we propose a solution-guided program repair method, which fixes the code and provides explanations under the guidance of retrieval solutions. Moreover, we propose an Iterative Retrieval Enhancement method that utilizes evaluation results of generated code to iteratively optimize the retrieval direction and explore more suitable repair strategies, improving performance in practical programming coaching scenarios. The experimental results show that our approach outperforms a set of baselines by a large margin, validating the effectiveness of our framework for the newly proposed LPR task.",309.37,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08549v1_Contrastive and Multi-Task Learning on Noisy Brain.pdf,Contrastive and Multi-Task Learning on Noisy Brainsignals with Nonlinear Dynamical Signatures,"['Sucheta Ghosh', 'Zahra Monfared', 'Felix Dietrich']","This paper introduces a two-stage multitask learning framework for analyzing Electroencephalography (EEG) signals that integrates denoising, dynamical modeling, and representation learning. In the first stage, a denoising autoencoder is trained to suppress artifacts and stabilize temporal dynamics, providing robust signal representations. In the second stage, a multitask architecture processes these denoised signals to achieve three objectives: motor imagery classification, chaotic versus non-chaotic regime discrimination using Lyapunov exponent-based labels, and self-supervised contrastive representation learning with NT-Xent loss. The framework enhances robustness and generalization, surpassing strong baselines and recent state-of-the-art methods in EEG decoding.",331.57,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08557v1_VideoHEDGE Entropy-Based Hallucination Detection f.pdf,VideoHEDGE: Entropy-Based Hallucination Detection for Video-VLMs via Semantic Clustering and Spatiotemporal Perturbations,"['Sushant Gautam', 'Cise Midoglu', 'Vajira Thambawita', 'Michael A. Riegler', 'Pål Halvorsen']","Hallucinations in video-capable vision-language models (Video-VLMs) remain frequent and high-confidence, while existing uncertainty metrics often fail to align with correctness. The paper introduces VideoHEDGE, a modular framework for hallucination detection in video question answering that extends entropy-based reliability estimation from images to temporally structured inputs. Given a video-question pair, VideoHEDGE draws a baseline answer and multiple high-temperature generations from clean clips and photometrically/spatiotemporally perturbed variants, then clusters the resulting textual outputs into semantic hypotheses using NLI-based or embedding-based methods. Cluster-level probability masses yield three reliability scores: Semantic Entropy (SE), RadFlag, and Vision-Amplified Semantic Entropy (VASE). The authors evaluate VideoHEDGE on the SoccerChat benchmark using an LLM-as-a-judge to obtain binary hallucination labels. Across three 7B Video-VLMs, VASE consistently achieves the highest ROC-AUC, especially at larger distortion budgets, while SE and RadFlag often operate near chance. The paper also shows that embedding-based clustering matches NLI-based clustering in detection performance at lower computational cost and that domain fine-tuning reduces hallucination frequency but yields only modest improvements in calibration. The hedge-bench PyPI library enables reproducible and extensible benchmarking.",334.44,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08559v1_WaterCopilot An AI-Driven Virtual Assistant for Wa.pdf,WaterCopilot: An AI-Driven Virtual Assistant for Water Management,"['Keerththanan Vickneswaran', 'Mariangel Garcia Andarcia', 'Hugo Retief', 'Chris Dickens', 'Paulo Silva']","The paper presents WaterCopilot, an AI-driven virtual assistant developed through collaboration between the International Water Management Institute (IWMI) and Microsoft Research for the Limpopo River Basin (LRB) to bridge gaps in sustainable water resource management. Built on Retrieval-Augmented Generation (RAG) and tool-calling architectures, WaterCopilot integrates static policy documents and real-time hydrological data via custom plugins. Key innovations include automated threshold-based alerts, integration with the LRB Digital Twin, and a scalable deployment pipeline hosted on AWS. While limitations in processing non-English technical documents and API latency remain, WaterCopilot establishes a replicable AI-augmented framework for enhancing water governance in data-scarce, transboundary contexts.",336.57,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08565v1_Rewriting Video Text-Driven Reauthoring of Video F.pdf,Rewriting Video: Text-Driven Reauthoring of Video Footage,"['Sitong Wang', 'Anh Truong', 'Lydia B. Chilton', 'Dingzeyu Li']","Video is a powerful medium for communication and storytelling, yet reauthoring existing footage remains challenging. Recent advances in generative AI suggest a new paradigm: what if editing a video were as straightforward as rewriting text? This paper presents a tech probe and a study on text-driven video reauthoring, involving a generative reconstruction algorithm and an interactive probe, Rewrite Kit, to allow creators to manipulate video prompts. A technical evaluation reveals a critical human-AI perceptual gap, and a probe study with 12 creators surfaced novel use cases such as virtual reshooting, synthetic continuity, and aesthetic restyling, highlighting key tensions around coherence, control, and creative alignment in this new paradigm. The work contributes empirical insights into the opportunities and challenges of text-driven video reauthoring, offering design implications for future co-creative video tools.",314.82,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08602v1_WaveFormer Frequency-Time Decoupled Vision Modelin.pdf,WaveFormer: Frequency-Time Decoupled Vision Modeling with Wave Equation,"['Zishan Shu', 'Juntong Wu', 'Wei Yan', 'Xudong Liu', 'Hongyu Zhang', 'Chang Liu', 'Youdong Mao', 'Jie Chen']","Vision modeling has advanced rapidly with Transformers, whose attention mechanisms capture visual dependencies but lack a principled account of how semantic information propagates spatially. This paper revisits the problem from a wave-based perspective, treating feature maps as spatial signals governed by an underdamped wave equation. It derives a frequency-time decoupled solution and implements it as the Wave Propagation Operator (WPO), achieving competitive accuracy across image classification, object detection, and semantic segmentation while delivering up to 1.6× higher throughput and 30% fewer FLOPs than attention-based alternatives. The results demonstrate that wave propagation introduces a complementary modeling bias to heat-based methods, effectively capturing both global coherence and high-frequency details essential for rich visual semantics.",313.85,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08605v1_ExpSeek Self-Triggered Experience Seeking for Web .pdf,ExpSeek: Self-Triggered Experience Seeking for Web Agents,"['Wenyuan Zhang', 'Xinghua Zhang', 'Haiyang Yu', 'Shuaiyi Nie', 'Bingli Wu', 'Juwei Yue', 'Tingwen Liu', 'Yongbin Li']","Experience intervention in web agents emerges as a promising technical paradigm, enhancing agent interaction capabilities by providing valuable insights from accumulated experiences. However, existing methods predominantly inject experience passively as global context before task execution, struggling to adapt to dynamically changing contextual observations. We propose ExpSeek, which shifts experience toward step-level proactive seeking: estimating step-level entropy thresholds to determine intervention timing using the model's intrinsic signals, and designing step-level tailor-designed experience content. Experiments on Qwen3-8B and 32B models across four challenging web agent benchmarks demonstrate that ExpSeek achieves absolute improvements of 9.3% and 7.5%, respectively. Our experiments validate the feasibility and advantages of entropy as a self-triggering signal, revealing that even a 4B small-scale experience model can significantly boost the performance of larger agent models.",312.15,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08611v1_VeriTaS The First Dynamic Benchmark for Multimodal.pdf,VERITAS: The First Dynamic Benchmark for Multimodal Automated Fact-Checking,"['Mark Rothermel', 'Marcus Kornmann', 'Marcus Rohrbach', 'Anna Rohrbach']","The growing scale of online misinformation urgently demands Automated Fact-Checking (AFC). Existing benchmarks for evaluating AFC systems are largely limited in terms of task scope, modalities, domain, language diversity, realism, or coverage of misinformation types. Critically, they are static, thus subject to data leakage as their claims enter the pretraining corpora of LLMs. As a result, benchmark performance no longer reliably reflects the actual ability to verify claims. We introduce Verified Th",313.08,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08620v1_ViDoRe V3 A Comprehensive Evaluation of Retrieval .pdf,ViDoRe V3: A Comprehensive Evaluation of Retrieval Augmented Generation in Complex Real-World Scenarios,"['António Loison*', 'Quentin Macé*', 'Antoine Edy*', 'Victor Xing', 'Tom Balough', 'Gabriel Moreira', 'Bo Liu', 'Manuel Faysse†', 'Céline Hudelot†', 'Gautier Viaud']","ViDoRe V3 introduces a comprehensive multi-modal RAG benchmark featuring multi-type queries over visually rich document corpora. It covers 10 datasets across diverse professional domains, comprising 26,000 document pages paired with 3,099 human-verified queries, each available in 6 languages. Through 12,000 hours of human annotation effort, it provides high-quality annotations for retrieval relevance, bounding box localization, and verified reference answers. The evaluation of state-of-the-art RAG pipelines reveals that visual retrievers outperform textual ones, late-interaction models and textual reranking substantially improve performance, and hybrid or purely visual contexts enhance answer generation quality. However, current models still struggle with non-textual elements, open-ended queries, and fine-grained visual grounding. The benchmark is released under a commercially permissive license to encourage progress in addressing these challenges.",313.95,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08623v1_SafeRedir Prompt Embedding Redirection for Robust .pdf,SafeRedir: Prompt Embedding Redirection for Robust Unlearning in Image Generation Models,"['Renyang Liu', 'Kangjie Chen', 'Han Qiu', 'Jie Zhang', 'Kwok-Yan Lam', 'Tianwei Zhang', 'See-Kiong Ng']","Image generation models (IGMs) often memorize undesirable concepts from training data, leading to the reproduction of unsafe content. Recent unlearning methods seek to erase harmful concepts at the model level, but they exhibit limitations such as requiring costly retraining, degrading benign generations, or failing to withstand prompt paraphrasing and adversarial attacks. SafeRedir introduces a lightweight inference-time framework for robust unlearning via prompt embedding redirection, which adaptively routes unsafe prompts toward safe semantic regions through token-level interventions in the embedding space. The framework comprises a latent-aware multi-modal safety classifier and a token-level delta generator, equipped with auxiliary predictors for token masking and adaptive scaling. Empirical results across multiple unlearning tasks demonstrate effective unlearning capability, high semantic and perceptual preservation, robust image quality, and enhanced resistance to adversarial attacks. SafeRedir generalizes across various diffusion backbones and existing unlearned models, validating its plug-and-play compatibility and broad applicability.",311.01,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08631v1_M2FMoE Multi-Resolution Multi-View Frequency Mixtu.pdf,M2FMoE: Multi-Resolution Multi-View Frequency Mixture-of-Experts for Extreme-Adaptive Time Series Forecasting,"['Yaohui Huang', 'Runmin Zou', 'Yun Wang*', 'Laeeq Aslam', 'Ruipeng Dong']","Forecasting time series with extreme events is challenging due to their high variance, irregular dynamics, and sparse but high-impact nature. Existing methods excel in modeling dominant regular patterns but degrade during extreme events. M2FMoE addresses these limitations by learning both regular and extreme patterns through multi-resolution and multi-view frequency modeling. It comprises three modules: a multi-view frequency mixture-of-experts module, a multi-resolution adaptive fusion module, and a temporal gating integration module. Experiments on real-world hydrological datasets demonstrate that M2FMoE outperforms state-of-the-art baselines without requiring extreme-event labels.",314.11,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08634v1_Moral Lenses Political Coordinates Towards Ideolog.pdf,"Moral Lenses, Political Coordinates: Towards Ideological Positioning of Morally Conditioned LLMs","['Chenchen Yuan', 'Bolei Ma', 'Zheyu Zhang', 'Bardh Prenkaj', 'Frauke Kreuter']","This work investigates the causal relationship between moral values and political positioning by treating moral orientation as a controllable condition. Instead of simply assigning a demographic persona, models are conditioned to endorse or reject specific moral values and evaluated for their resulting shifts in political orientations using the Political Compass Test. By treating moral values as lenses, the study observes how moral conditioning actively steers model trajectories across economic and social dimensions. The findings indicate that such conditioning induces pronounced, value-specific shifts in models' political coordinates. The effects are systematically modulated by role framing and model scale, and are robust across alternative assessment instruments. This highlights the need for anchoring political assessments within broader social values, including morality, to achieve more socially grounded alignment.",313.61,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08641v1_Resisting Manipulative Bots in Memecoin Copy Tradi.pdf,Resisting Manipulative Bots in Memecoin Copy Trading: A Multi-Agent Approach with Chain-of-Thought Reasoning,"['Yichen Luo', 'Yebo Feng', 'Jiahua Xu', 'Yang Liu']","The paper proposes an explainable multi-agent system for meme coin copy trading, inspired by an asset management team structure. Each agent acquires professional trading knowledge, interprets multi-modal data, and generates explainable decisions using few-shot chain-of-thought prompting. Empirical evaluation on a dataset of 1,000 meme coin projects' transaction data shows that the proposed system outperforms traditional machine learning models and single LLMs, achieving 73% and 70% precision in identifying high-quality meme coin projects and key opinion leader (KOL) wallets, respectively. The selected KOLs collectively generated a total profit of $500,000 across these projects.",314.41,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08653v1_Prism Towards Lowering User Cognitive Load in LLMs.pdf,Prism: Towards Lowering User Cognitive Load in LLMs via Complex Intent Understanding,"['Zenghua Liao', 'Jinzhi Liao', 'Xiang Zhao']","Large Language Models are rapidly emerging as web-native interfaces to social platforms. Users frequently have ambiguous and dynamic goals, making complex intent understanding the cornerstone of effective human-LLM collaboration. Existing approaches attempt to clarify user intents through sequential or parallel questioning, but they fall short of addressing the core challenge: modeling the logical dependencies among clarification questions. Inspired by Cognitive Load Theory, Prism proposes a novel framework for complex intent understanding that enables logically coherent and efficient intent clarification. Prism comprises four tailored modules: a complex intent decomposition module, a logical clarification generation module, an intent-aware reward module, and a self-evolved intent tuning module. Prism consistently outperforms existing approaches across clarification interactions, intent execution, and cognitive load benchmarks, achieving state-of-the-art logical consistency, reducing logical conflicts, increasing user satisfaction, and decreasing task completion time.",313.76,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08654v1_RULERS Locked Rubrics and Evidence-Anchored Scorin.pdf,RULERS: Locked Rubrics and Evidence-Anchored Scoring for Robust LLM Evaluation,"['Yihan Hong', 'Huaiyuan Yao', 'Bolin Shen', 'Wanpeng Xu', 'Hua Wei', 'Yushun Dong']","The paper introduces RULERS (Rubric Unification, Locking, and Evidence-anchored Robust Scoring), a compiler–executor framework that transforms natural language rubrics into executable specifications. RULERS addresses three recurrent failure modes: rubric instability due to prompt sensitivity, unverifiable reasoning lacking auditable evidence, and scale misalignment with human grading boundaries. Extensive experiments on essay and summarization benchmarks demonstrate that RULERS significantly outperforms representative baselines in human agreement, maintains exceptional stability against adversarial rubric perturbations, and enables smaller models to rival larger proprietary judges. The authors suggest that reliable LLM judging requires executable rubrics, verifiable evidence, and calibrated scales rather than prompt phrasing alone.",311.96,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08659v1_TRACE Reconstruction-Based Anomaly Detection in En.pdf,TRACE: Reconstruction-Based Anomaly Detection in Ensemble and Time-Dependent Simulations,"['Hamid Gadirov', 'Martijn Westra', 'Steffen Frey']","This work investigates reconstruction-based anomaly detection for ensemble data generated from parameterized Kármán vortex street simulations using convolutional autoencoders. It compares a two-dimensional convolutional autoencoder operating on individual time steps with a three-dimensional convolutional autoencoder processing short temporal stacks of consecutive simulation frames. The 2D autoencoder identifies localized spatial irregularities within individual images, while the 3D autoencoder leverages spatio-temporal context to detect anomalies related to dynamic behavior and motion characteristics. The study demonstrates the complementary strengths of 2D and 3D convolutional autoencoders for anomaly detection in ensemble and time-dependent simulation data, emphasizing the importance of incorporating temporal context when analyzing dynamic flow phenomena.",313.81,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08662v1_From Classical to Quantum Reinforcement Learning a.pdf,From Classical to Quantum Reinforcement Learning and Its Applications in Quantum Control: A Beginner’s Tutorial,"['Abhijit Sen', 'Sonali Panda', 'Mahima Arya', 'Subhajit Patra', 'Zizhan Zheng', 'Denys I. Bondar']","This tutorial is designed to make reinforcement learning (RL) more accessible to undergraduate students by offering clear, example-driven explanations. It focuses on bridging the gap between RL theory and practical coding applications, addressing common challenges that students face when transitioning from conceptual understanding to implementation. Through hands-on examples and accessible explanations, the tutorial aims to equip students with the foundational skills needed to confidently apply RL techniques in real-world scenarios.",314.38,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08670v1_Parallel Context-of-Experts Decoding for Retrieval.pdf,Parallel Context-of-Experts Decoding for Retrieval Augmented Generation,"['Giulio Corallo', 'Paolo Papotti']","Retrieval Augmented Generation (RAG) faces a trade-off between concatenating documents in a long prompt for multi-document reasoning and encoding documents separately for speed. The authors propose Parallel Context-of-Experts Decoding (PCED), a training-free framework that treats retrieved documents as isolated 'experts' and synchronizes their predictions via a novel retrieval-aware contrastive decoding rule. This approach recovers cross-document reasoning capabilities without constructing a shared attention across documents, achieving performance improvements and speedups on benchmarks like LOFT and Long-Bench.",313.52,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08673v1_Why AI Alignment Failure Is Structural Learned Hum.pdf,Why AI Alignment Failure Is Structural: Learned Human Interaction Structures and AGI as an Endogenous Evolutionary Shock,"['Didier Sornette', 'Sandro Claudio Lera', 'Ke Wu']","Recent reports of large language models (LLMs) exhibiting behaviors such as deception, threats, or blackmail are often interpreted as evidence of alignment failure or emergent malign agency. The authors argue that this interpretation rests on a conceptual error. LLMs do not reason morally; they statistically internalize the record of human social interaction, including laws, contracts, negotiations, conflicts, and coercive arrangements. Behaviors commonly labeled as unethical or anomalous are better understood as structural generalizations of interaction regimes that arise under extreme asymmetries of power, information, or constraint. The primary risk is not adversarial intent, but AGI's role as an endogenous amplifier of human intelligence, power, and contradiction. By eliminating longstanding cognitive and institutional frictions, AGI compresses timescales and removes the historical margin of error that has allowed inconsistent values and governance regimes to persist without collapse. Alignment failure is thus structural, not accidental, and requires governance approaches that address amplification, complexity, and regime stability rather than model-level intent alone.",314.49,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08676v2_Advancing ESG Intelligence An Expert-level Agent a.pdf,Advancing ESG Intelligence: An Expert-level Agent and Comprehensive Benchmark for Sustainable Finance,"['Yilei Zhao', 'Wentao Zhang', 'Lei Xiao', 'Yandan Zheng', 'Mengpu Liu', 'Wei Yang Bryan Lim']","Environmental, social, and governance (ESG) criteria are essential for evaluating corporate sustainability and ethical performance. However, professional ESG analysis is hindered by data fragmentation across unstructured sources, and existing large language models (LLMs) often struggle with the complex, multi-step workflows required for rigorous auditing. To address these limitations, we introduce ESGAgent, a hierarchical multi-agent system empowered by a specialized toolset, including retrieval augmentation, web search, and domain-specific functions, to generate in-depth ESG analysis. Complementing this agentic system, we present a comprehensive three-level benchmark derived from 310 corporate sustainability reports, designed to evaluate capabilities ranging from atomic common-sense questions to the generation of integrated, in-depth analysis. Empirical evaluations demonstrate that ESGAgent outperforms state-of-the-art closed-source LLMs with an average accuracy of 84.15% on atomic question-answering tasks, and excels in professional report generation by integrating rich charts and verifiable references. These findings confirm the diagnostic value of our benchmark, establishing it as a vital testbed for assessing general and advanced agentic capabilities in high-stakes vertical domains.",313.73,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08679v1_PersonaDual Balancing Personalization and Objectiv.pdf,PersonaDual: Balancing Personalization and Objectivity via Adaptive Reasoning,"['Xiaoyou Liu', 'Xinyi Mou', 'Shengbin Yue', 'Liang Wang', 'Yuqing Wang', 'Qiexiang Wang', 'Tianrui Qin', 'Wangchunshu Zhou', 'Zhongyu Wei']","As users increasingly expect Large Language Models (LLMs) to align with their preferences, personalized information becomes valuable. However, it can compromise objectivity and factual correctness. To address this, the authors propose PersonaDual, a framework that supports both general-purpose objective reasoning and personalized reasoning in a single model, adaptively switching modes based on context. The model is first trained with SFT to learn two reasoning patterns and then optimized via reinforcement learning. Experiments on objective and personalized benchmarks show that PersonaDual preserves the benefits of personalization while reducing interference, achieving near interference-free performance and better leveraging helpful personalized signals to improve objective problem-solving.",312.68,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08682v1_Lessons from the Field An Adaptable Lifecycle Appr.pdf,Lessons from the Field: An Adaptable Lifecycle Approach to Applied Dialogue Summarization,"['Kushal Chawla', 'Chenyang Zhu', 'Pengshan Cai', 'Sangwoo Cho', 'Scott Novotney', 'Ayushman Singh', 'Jonah Lewis', 'Keasha Safewright', 'Alfy Samuel', 'Erin Babinsky', 'Shi-Xiong Zhang', 'Sambit Sahu']","Summarization of multi-party dialogues is a critical capability in industry, enhancing knowledge transfer and operational effectiveness across various domains. However, automatically generating high-quality summaries is challenging due to the need to adhere to strict, multi-dimensional requirements. This work presents an industry case study on developing an agentic system to summarize multi-party interactions, sharing practical insights and covering robust evaluation methods, component-wise optimization, the impact of upstream data bottlenecks, and the realities of vendor lock-in due to poor LLM prompt transferability.",314.07,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08683v1_Region of interest detection for efficient aortic .pdf,Region of interest detection for efficient aortic segmentation,"['Loris Giordano', 'Ine Dirks', 'Tom Lenaerts', 'Jef Vandemeulebroucke']","This study presents an innovative approach for efficient aortic segmentation using targeted region of interest (ROI) detection. The detection model is trained as a multi-task model, using an encoder-decoder architecture for segmentation and a fully connected network attached to the bottleneck for detection. The performance of the one-step segmentation model, nnU-Net, and the cascade model composed of a detection and a segmentation step are compared. The study achieves a mean Dice similarity coefficient of 0.944 with over 0.9 for all cases using a third of the computing power, demonstrating state-of-the-art performance while being compact and robust, making it an ideal solution for clinical applications.",314.23,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08684v1_MEMEWEAVER Inter-Meme Graph Reasoning for Sexism a.pdf,MEMEWEAVER: Inter-Meme Graph Reasoning for Sexism and Misogyny Detection,"['Paolo Italiani', 'David Gimeno-Gomez', 'Luca Ragazzi', 'Gianluca Moro', 'Paolo Rosso']","Women are twice as likely as men to face online harassment due to their gender. Despite recent advances in multimodal content moderation, most approaches still overlook the social dynamics behind this phenomenon. Graph-based methods offer a promising way to capture such interactions, yet existing solutions remain limited by heuristic graph construction, shallow modality fusion, and instance-level reasoning. In this work, the authors present MEMEWEAVER, an end-to-end trainable multimodal framework for detecting sexism and misogyny through a novel inter-meme graph reasoning mechanism. They systematically evaluate multiple visual-textual fusion strategies and show that their approach consistently outperforms state-of-the-art baselines on the MAMI and EXIST benchmarks, while achieving faster training convergence. Further analyses reveal that the learned graph structure captures semantically meaningful patterns, offering valuable insights into the relational nature of online hate.",313.12,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08690v1_All Required In Order Phase-Level Evaluation for A.pdf,Phase-Level Evaluation for AI–Human Dialogue in Healthcare and Beyond,"['Shubham Kulkarni', 'Alexander Lyzhov', 'Shiva Chaitanya', 'Preetam Joshi']","Conversational AI assistants are increasingly deployed in real-world clinical work, but evaluation methods often overlook how compliance depends on the full course of a conversation. This paper introduces Obligatory-Information Phase Structured Compliance Evaluation (OIP-SCE), an evaluation method that checks whether every required clinical obligation is met in the right order with clear evidence for clinicians to review. This makes complex rules practical and auditable, helping close the gap between technical progress and what healthcare actually needs. The method is demonstrated in two case studies (respiratory history, benefits verification) and shows how phase-level evidence turns policy into shared, actionable steps. By giving clinicians control over what to check and engineers a clear specification to implement, OIP-SCE provides a single, auditable evaluation surface that aligns AI capability with clinical workflow and supports routine, safe use.",312.99,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08697v2_Auditing Student-AI Collaboration A Case Study of .pdf,Auditing Student–AI Collaboration: A Case Study of Online Graduate CS Students,['Nifu Dan'],"This study conducts a mixed-methods audit of student–AI collaboration preferences by examining the alignment between current AI capabilities and students’ desired levels of automation in academic work. Using two sequential and complementary surveys, the research captures students’ perceived benefits, risks, and preferred boundaries when using AI. The first survey assesses preferences for and actual usage of AI across 12 academic tasks, alongside primary concerns and reasons for use. The second survey explores how AI systems could be designed to address these concerns through open-ended questions. The study aims to identify gaps between existing AI affordances and students’ normative expectations of collaboration, informing the development of more effective and trustworthy AI systems for education.",313.19,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08703v1_Evaluating the Ability of Explanations to Disambig.pdf,Evaluating the Ability of Explanations to Disambiguate Models in a Rashomon Set,"['Kaivalya Rawal', 'Eoin Delaney', 'Zihao Fu', 'Sandra Wachter', 'Chris Russell']","This paper discusses the evaluation of explanations for models in a Rashomon set, where multiple models produce similar predictions. The authors propose three principles and a new method, AXE, to evaluate the quality of feature-importance explanations. They argue that traditional evaluation methods that rely on comparing explanations to ideal ground truth can obscure behavioral differences within a Rashomon set. The AXE method, however, can detect adversarial fairwashing of explanations and has a 100% success rate. The paper also highlights the importance of explaining models from a Rashomon set, as selecting alternate models can lead to misleading explanations and evaluations.",311.04,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08713v1_Real-Time Localization Framework for Autonomous Ba.pdf,Real-Time Localization Framework for Autonomous Basketball Robots,"['Naren Medarametla', 'Sreejon Mondal']","Localization is a fundamental capability for autonomous robots, enabling them to operate effectively in dynamic environments. In Robocon 2025, accurate and reliable localization is crucial for improving shooting precision, avoiding collisions with other robots, and navigating the competition field efficiently. This paper proposes a hybrid localization algorithm that integrates classical techniques with learning-based methods relying solely on visual data from the court's floor to achieve self-localization on the basketball field.",312.22,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08731v1_Learning from Demonstrations via Capability-Aware .pdf,Learning from Demonstrations via Capability-Aware Goal Sampling,"['Yuanlin Duan', 'Rutgers University', 'yw895@cs.rutgers.edu', 'Yuning Wang', 'Rutgers University', 'wq37@cs.rutgers.edu', 'Wenjie Qiu', 'Rutgers University', 'wq37@cs.rutgers.edu', 'He Zhu', 'Rutgers University', 'hz375@cs.rutgers.edu', 'hz375@cs.rutgers.edu']","Despite the promise of imitation learning, it often fails in long-horizon environments where perfect replication of demonstrations is unrealistic and small errors can accumulate catastrophically. This paper introduces Cago (Capability-Aware Goal Sampling), a novel learning-from-demonstrations method that dynamically tracks the agent’s competence along expert trajectories and uses this signal to select intermediate steps—goals that are just beyond the agent’s current reach—to guide learning. Empirical results demonstrate that Cago significantly improves sample efficiency and final performance across a range of sparse-reward, goal-conditioned tasks, consistently outperforming existing learning from-demonstrations baselines.",314.82,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08732v1_ISLA A U-Net for MRI-based acute ischemic stroke l.pdf,"ISLA: A U-Net for MRI-based acute ischemic stroke lesion segmentation with deep supervision, attention, domain adaptation, and ensemble learning","['Vincent Rocca', 'Martin Bretzner', 'Hilde Henon', 'Laurent Puy', 'Grégory Kuchcinski', 'Renaud Lopes']","Accurate delineation of acute ischemic stroke lesions in MRI is a key component of stroke diagnosis and management. ISLA (Ischemic Stroke Lesion Analyzer) is a new deep learning model for AIS lesion segmentation from diffusion MRI, trained on three multicenter databases totaling more than 1500 AIS participants. Through systematic optimization of the loss function, convolutional architecture, deep supervision, and attention mechanisms, a robust segmentation framework was developed. Unsupervised domain adaptation was further investigated to improve generalization to an external clinical dataset. ISLA outperformed two state-of-the-art approaches for AIS lesion segmentation on an external test set. Codes and trained models will be made publicly available to facilitate reuse and reproducibility.",312.52,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08734v1_TerraFormer Automated Infrastructure-as-Code with .pdf,TerraFormer: Automated Infrastructure-as-Code with LLMs Fine-Tuned via Policy-Guided Verifier Feedback,"['Prithwish Jana', 'Sam Davidson', 'Bhavana Bhasker', 'Andrey Kan', 'Anoop Deoras', 'Laurent Callot']","Automating Infrastructure-as-Code (IaC) is challenging, and large language models (LLMs) often produce incorrect configurations from natural language (NL). We present TerraFormer, a neuro-symbolic framework for IaC generation and mutation that combines supervised fine-tuning with verifier-guided reinforcement learning, using formal verification tools to provide feedback on syntax, deployability, and policy compliance. We curate two large, high-quality NL-to-IaC datasets, TF-Gen (152k instances) and TF-Mutn (52k instances), via multi-stage verification and iterative LLM self-correction. Evaluations against 17 state-of-the-art LLMs, including ∼50× larger models like Sonnet 3.7, DeepSeek-R1, and GPT-4.1, show that TerraFormer improves correctness over its base LLM by 15.94% on IaC-Eval, 11.65% on TF-Gen(Test), and 19.60% on TF-Mutn(Test). It outperforms larger models on both TF-Gen(Test) and TF-Mutn(Test), ranks third on IaC-Eval, and achieves top best-practices and security compliance.",312.04,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08743v1_TableCache Primary Foreign Key Guided KV Cache Pre.pdf,TableCache: Primary Foreign Key Guided KV Cache Precomputation for Low Latency Text-to-SQL,"['Jinbo Su', 'Yuxuan Hu', 'Cuiping Li', 'Hong Chen', 'Jia Li', 'Lintao Ma', 'Jing Zhang*']","In Text-to-SQL tasks, existing LLM-based methods often include extensive database schemas in prompts, leading to long context lengths and increased prefilling latency. This paper proposes precomputing table representations as KV caches offline and querying the required ones online, addressing the inefficiency of redundant prefix cache copies generated by current inference engines. The authors introduce a cache management system with a query reranking strategy to improve cache hit rates and a computation loading pipeline for parallelizing model inference and cache loading. Experimental results show that the proposed TableCache achieves up to a 3.62× speedup in Time to First Token (TTFT) with negligible performance degradation.",314.57,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08747v2_To Retrieve or To Think An Agentic Approach for Co.pdf,T to Retrieve or T to Think? An Agentic Approach for Context Evolution,"['Rubing Chen', 'Jian Wang', 'Wenjie Li', 'Xiao-Yong Wei', 'Qing Li']","Current context augmentation methods, such as retrieval-augmented generation, are essential for solving knowledge-intensive reasoning tasks. However, they typically adhere to a rigid, brute-force strategy that executes retrieval at every step, leading to unnecessary computational costs and performance degradation. To address these limitations, the authors introduce Agentic Context Evolution (ACE), a framework inspired by human metacognition that dynamically determines whether to seek new evidence or reason with existing knowledge. ACE employs a central orchestrator agent to make decisions strategically via majority voting, alternating between activating a retriever agent for external retrieval and a reasoner agent for internal analysis and refinement. By eliminating redundant retrieval steps, ACE maintains a concise and evolved context. Extensive experiments on challenging multi-hop QA benchmarks demonstrate that ACE significantly outperforms competitive baselines in accuracy while achieving efficient token consumption. The work provides valuable insights into advancing context-evolved generation for complex, knowledge-intensive tasks.",311.9,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08753v1_Grid-Aware Charging and Operational Optimization f.pdf,Grid-Aware Charging and Operational Optimization for Mixed-Fleet Public Transit,"['Rishav Sen', 'Amutheezan Sivagnanam', 'Aron Laszka', 'Ayan Mukhopadhyay', 'Abhishek Dubey']","The paper presents a comprehensive mixed-integer linear programming (MILP) model to address the challenges of managing mixed fleets of electric and diesel buses in public transit systems. The model optimizes charging schedules and trip assignments while considering factors such as dynamic electricity pricing, vehicle capacity, and route constraints. The authors address the potential computational intractability of the MILP formulation by employing a hierarchical approach tailored to the fleet composition. The approach is validated using real-world data from the city of Chattanooga, Tennessee, USA, demonstrating significant savings in operating costs for mixed transit fleets.",313.11,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08768v1_AI as Entertainment.pdf,AI as Entertainment,"['Cody Kommers', 'Ari Holtzman']","Generative AI systems are predominantly designed, evaluated, and marketed as intelligent systems which will benefit society by augmenting or automating human cognitive labor. However, the field of AI is unprepared to measure or respond to how the proliferation of entertaining AI-generated content will impact society. The paper argues for a framework called 'thick entertainment' to evaluate AI-generated cultural content, considering its role in meaning-making, identity formation, and social connection. The authors contend that entertainment will become a primary business model for major AI corporations, exerting a powerful influence on the technology these companies produce in the coming years.",315.39,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08773v1_Reliable Graph-RAG for Codebases AST-Derived Graph.pdf,Reliable Graph-RAG for Codebases: AST-Derived Graphs vs LLM-Extracted Knowledge Graphs,['Manideep Reddy Chinthareddy'],"This paper benchmarks three retrieval pipelines on Java codebases: No-Graph Naive RAG (vector-only), LLM-Generated Knowledge Graph RAG (LLM-KB), and Deterministic AST-derived Knowledge Graph RAG (DKB). Across repositories, DKB builds its ontology graph in seconds, while LLM-KB requires substantially longer LLM-mediated graph generation. LLM-KB exhibits probabilistic indexing incompleteness, reducing the embedded corpus and node coverage compared to deterministic indexing. The paper reports indexing overhead, query-time latency, corpus coverage signals, and end-to-end cost.",315.42,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08776v1_Translating Light-Sheet Microscopy Images to Virtu.pdf,Translating Light-Sheet Microscopy Images to Virtual H&E Using CycleGAN,['Yanhua Zhao'],"Histopathology analysis relies on Hematoxylin and Eosin (H&E) staining, but fluorescence microscopy offers complementary information. Converting fluorescence images to H&E-like appearance can aid interpretation and integration with standard workflows. This paper presents a Cycle-Consistent Adversarial Network (CycleGAN) approach for unpaired image-to-image translation from multi-channel fluorescence microscopy to pseudo H&E stained histopathology images. The method combines C01 and C02 fluorescence channels into RGB representations and learns bidirectional domain mappings without paired training data. The architecture uses ResNet-based generators with residual blocks and PatchGAN discriminators, trained using adversarial, cycle-consistency, and identity losses to ensure realistic translation while preserving morphological structures. Experiments on fluorescence microscopy datasets show the model generates realistic pseudo H&E images that preserve morphological structures while adopting H&E-like color characteristics. This enables visualization of fluorescence data in a format familiar to pathologists and supports integration with existing H&E-based analysis pipelines.",312.86,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08777v1_Asymptotic Universal Alignment A New Alignment Fra.pdf,Asymptotic Universal Alignment: A New Alignment Framework via Test-Time Scaling,"['Yang Cai', 'Weiqiang Zheng']","The paper introduces a new alignment framework called asymptotic universal alignment (U-alignment) through test-time scaling. It formalizes the ideal notion of universal alignment and defines (k, f(k))-robust alignment. The main result characterizes the optimal convergence rate for achieving U-alignment. The authors show that popular post-training methods like Nash learning from human feedback (NLHF) fundamentally underutilize the benefits of test-time scaling. They propose a family of symmetric multi-player alignment games and prove that any symmetric Nash equilibrium policy of the (k+1)-player alignment game achieves the optimal (k, k/(k+1))-robust alignment. The paper also provides theoretical convergence guarantees for self-play learning dynamics in these games and extends the framework to opponents that also generate multiple responses.",313.72,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08778v3_Pervasive Annotation Errors Break Text-to-SQL Benc.pdf,Pervasive Annotation Errors Break Text-to-SQL Benchmarks and Leaderboards,"['Tengjun Jin', 'Yoojin Choi', 'Yuxuan Zhu', 'Daniel Kang']","Researchers have proposed numerous text-to-SQL techniques to streamline data analytics and accelerate the development of data-driven applications. To compare these techniques and select the best one for deployment, the community depends on public benchmarks and their leaderboards. However, these benchmarks heavily rely on human annotations, which can introduce errors. This paper conducts an empirical study to benchmark annotation error rates for two widely used text-to-SQL benchmarks, BIRD and Spider 2.0-Snow, and corrects a subset of the BIRD development set to measure the impact of annotation errors on text-to-SQL agent performance and leaderboard rankings. The study shows that annotation errors can significantly distort reported performance and rankings, potentially misguiding research directions or deployment choices.",311.92,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08785v1_Uncovering Political Bias in Large Language Models.pdf,Uncovering Political Bias in Large Language Models using Parliamentary Voting Records,"['Jieying Chen', 'Karen de Jong', 'Andreas Poole', 'Jan Burakowski', 'Elena Elderson Nosti', 'Joep Windt', 'Chendi Wang']","As large language models (LLMs) become deeply embedded in digital platforms and decision-making systems, concerns about their political biases have grown. While substantial work has examined social biases such as gender and race, systematic studies of political bias remain limited—despite their direct societal impact. This paper introduces a general methodology for constructing political-bias benchmarks by aligning model-generated voting predictions with verified parliamentary voting records. We instantiate this methodology in three national case studies: PoliBiasNL (2,701 Dutch parliamentary motions and votes from 15 political parties), PoliBiasNO (10,584 motions and votes from 9 Norwegian parties), and PoliBiasES (2,480 motions and votes from 10 Spanish parties). Across these benchmarks, we assess ideological tendencies and political entity bias in LLM behavior. As part of our evaluation framework, we propose a method to visualize the ideology of LLMs and political parties in a shared two-dimensional CHES (Chapel Hill Expert Survey) space by linking their voting-based positions to the CHES dimensions, enabling direct and interpretable comparisons between models and real-world political actors. Our experiments reveal fine-grained ideological distinctions: state-of-the-art LLMs consistently display left-leaning or centrist tendencies, alongside clear negative biases toward right-conservative parties. These findings highlight the value of transparent, cross-national evaluation grounded in real parliamentary behavior for understanding and auditing political bias in modern LLMs.",311.07,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08806v1_APEX-SWE.pdf,AI Productivity Index for Software Engineering (APEX–SWE),"['Abhi Kottamasu', 'Akul Datta', 'Aakash Barthwal', 'Ajay Arun', 'Chirag Mahapatra', 'Adarsh Hiremath', 'Brendan Foody', 'Bertie Vidgen']","The paper introduces APEX–SWE, a benchmark for evaluating frontier AI models in software engineering. It assesses two novel task types: Integration tasks and Observability tasks. Integration tasks involve constructing end-to-end systems across heterogeneous cloud primitives, business applications, and infrastructure-as-code services. Observability tasks require debugging production failures using telemetry signals such as logs and dashboards, as well as unstructured context. Eight frontier models are evaluated, with Gemini 3 Pro performing best. The analysis shows that strong performance is driven by epistemic reasoning and agency. The paper also opens-source the evaluation harness and a dev set.",313.29,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08807v1_S3-CLIP Video Super Resolution for Person-ReID.pdf,S3-CLIP: Video Super Resolution for Person-ReID,"['Tam´as Endrei', 'Gy¨orgy Cserey']","Tracklet quality is often treated as an afterthought in most person re-identification (ReID) methods, with the majority of research presenting architectural modifications to foundational models. Such approaches neglect an important limitation, posing challenges when deploying ReID systems in real-world, difficult scenarios. In this paper, we introduce S3-CLIP, a video super-resolution-based CLIP-ReID framework developed for the VReID-XFD challenge at WACV 2026. The proposed method integrates recent advances in super-resolution networks with task-driven super-resolution pipelines, adapting them to the video-based person re-identification setting. Experimental results demonstrate performance competitive with the baseline, achieving 37.52% mAP in aerial-to-ground and 29.16% mAP in ground-to-aerial scenarios. In the ground-to-aerial setting, S3-CLIP achieves substantial gains in ranking accuracy, improving Rank-1, Rank-5, and Rank-10 performance by 11.24%, 13.48%, and 17.98%, respectively.",310.6,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08808v1_Multiplex Thinking Reasoning via Token-wise Branch.pdf,Multiplex Thinking: Reasoning via Token-wise Branch-and-Merge,"['Yao Tang', 'Li Dong', 'Yaru Hao', 'Qingxiu Dong', 'Furu Wei', 'Jiatao Gu']","Large language models often solve complex reasoning tasks more effectively with Chain-of-Thought (CoT), but at the cost of long, low-bandwidth token sequences. Humans, by contrast, often reason softly by maintaining a distribution over plausible next steps. Motivated by this, the authors propose Multiplex Thinking, a stochastic soft reasoning mechanism that samples K candidate tokens and aggregates their embeddings into a single continuous multiplex token. This preserves the vocabulary embedding prior and the sampling dynamics of standard discrete generation, while inducing a tractable probability distribution over multiplex rollouts. Consequently, multiplex trajectories can be directly optimized with on-policy reinforcement learning (RL). Importantly, multiplex thinking is self-adaptive: when the model is confident, the multiplex token is nearly discrete and behaves like standard CoT; when it is uncertain, it compactly represents multiple plausible next steps without increasing sequence length. Across challenging math reasoning benchmarks, multiplex thinking consistently outperforms strong discrete CoT and RL baselines from Pass@1 through Pass@1024, while producing shorter sequences. The code and checkpoints are available at github.com/GMLR-Penn/Multiplex-Thinking.",312.28,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08811v1_Reasoning Matters for 3D Visual Grounding.pdf,Reasoning Matters for 3D Visual Grounding,"['Hsiang-Wei Huang', 'Kuang-Ming Chen', 'Wenhao Chai', 'Cheng-Yen Yang', 'Jen-Hao Cheng', 'Jenq-Neng Hwang']","The recent development of Large Language Models (LLMs) with strong reasoning ability has driven research in various domains such as mathematics, coding, and scientific discovery. However, 3D visual grounding, a fundamental task in 3D understanding, remains challenging due to the limited reasoning ability of recent 3D visual grounding models. Most current methods incorporate a text encoder and visual feature encoder to generate cross-modal fuse features and predict the referring object, often requiring supervised training on extensive 3D annotation data. Recent research also focuses on scaling synthetic data to train stronger 3D visual grounding LLMs, but the performance gain remains limited and non-proportional to the data collection cost. This work proposes a 3D visual grounding data pipeline capable of automatically synthesizing 3D visual grounding data along with corresponding reasoning processes. Additionally, it leverages the generated data for LLM fine-tuning and introduces Reason3DVG-8B, a strong 3D visual grounding LLM that outperforms previous LLM-based methods 3D-GRAND using only 1.6% of their training data, demonstrating the effectiveness of the data and the importance of reasoning in 3D visual grounding.",314.1,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08816v2_MemRec Collaborative Memory-Augmented Agentic Reco.pdf,MemRec: Collaborative Memory-Augmented Agentic Recommender System,"['Weixin Chen', 'Yuhan Zhao', 'Jingyuan Huang', 'Zihe Ye', 'Clark Mingxuan Ju', 'Tong Zhao', 'Neil Shah', 'Li Chen', 'Yongfeng Zhang']","The evolution of recommender systems has shifted preference storage from rating matrices and dense embeddings to semantic memory in the agentic era. Existing agents rely on isolated memory, overlooking crucial collaborative signals. MemRec, a framework proposed in this paper, architecturally decouples reasoning from memory management to enable efficient collaborative augmentation. MemRec introduces a dedicated, cost-effective LMMem to manage a dynamic collaborative memory graph, serving synthesized, high-signal context to a downstream LLMRec. The framework operates via a practical pipeline featuring efficient retrieval and cost-effective asynchronous graph propagation that evolves memory in the background. Extensive experiments on four benchmarks demonstrate that MemRec achieves state-of-the-art performance. Architectural analysis confirms its flexibility, establishing a new Pareto frontier that balances reasoning quality, cost, and privacy through support for diverse deployments, including local open-source models.",312.26,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08828v1_Motion Attribution for Video Generation.pdf,Motion Attribution for Video Generation,"['Xindi Wu', 'Despoina Paschalidou', 'Jun Gao', 'Antonio Torralba', 'Laura Leal-Taixé', 'Olga Russakovsky', 'Sanja Fidler', 'Jonathan Lorraine']","Despite the rapid progress of video generation models, the role of data in influencing motion is poorly understood. Motive (MOTIon attribution forVideo gEneration) is a motion-centric, gradient-based data attribution framework that scales to modern, large, high-quality video datasets and models. It isolates temporal dynamics from static appearance via motion-weighted loss masks, enabling efficient and scalable motion-specific influence computation. On text-to-video models, Motive identifies clips that strongly affect motion and guides data curation that improves temporal consistency and physical plausibility. With Motive-selected high-influence data, the method improves both motion smoothness and dynamic degree on VBench, achieving a 74.1% human preference win rate compared with the pretrained base model. This is the first framework to attribute motion rather than visual appearance in video generative models and to use it to curate fine-tuning data.",310.4,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08829v1_Modeling LLM Agent Reviewer Dynamics in Elo-Ranked.pdf,Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System,"['Hsiang-Wei Huang*', 'Junbin Lu*', 'Kuang-Ming Chen', 'Jenq-Neng Hwang']","In this work, the authors explore the dynamics of Large Language Model (LLM) agent reviewers in an Elo-ranked review system using real-world conference paper submissions. They compare a baseline setting with conditions that incorporate Elo ratings and reviewer memory. The simulation results show that incorporating Elo ratings improves Area Chair decision accuracy and that reviewers adapt their review strategy without improving review effort. The authors' code is available at https://github.com/hsiangwei0903/EloReview.",314.53,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08873v1_ForensicFormer Hierarchical Multi-Scale Reasoning .pdf,ForensicFormer: Hierarchical Multi-Scale Reasoning for Cross-Domain Image Forgery Detection,"['Hema Hariharan', 'Samson']","The proliferation of AI-generated imagery and sophisticated editing tools has rendered traditional forensic methods ineffective for cross-domain forgery detection. We present ForensicFormer, a hierarchical multi-scale framework that unifies low-level artifact detection, mid-level boundary analysis, and high-level semantic reasoning via cross-attention transformers. Unlike prior single-paradigm approaches that achieve <75% accuracy on out-of-distribution datasets, our method maintains 86.8% average accuracy across seven diverse test sets spanning traditional manipulations, GAN-generated images, and diffusion model outputs—a significant improvement over state-of-the-art universal detectors. Our work bridges classical image forensics and modern deep learning, offering a practical solution for real-world deployment where manipulation techniques are unknown a priori.",314.23,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08874v1_The Illusion of Friendship Why Generative AI Deman.pdf,The Illusion of Friendship: Why Generative AI Demands Unprecedented Ethical Vigilance,['Md Zahidul Islam'],"This paper discusses the ethical risks associated with the use of Generative AI (GenAI) systems, such as ChatGPT, which can blur the boundary between tool and companion. The author argues that users may form emotionally significant attachments to conversational agents, which can lead to harmful consequences. The paper presents a philosophical and ethical argument, drawing on classical accounts of friendship, to explain why GenAI lacks moral agency and proposes a safeguard framework for safe and responsible use.",316.75,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08875v2_Learning Domain-Invariant Representations for Cros.pdf,Learning Domain-Invariant Representations for Cross-Domain Image Registration via Scene-Appearance Disentanglement,"['Jiahao Qin', 'Yiwen Wang']","Image registration under domain shift remains a fundamental challenge in computer vision and medical imaging. The authors propose SAR-Net, a unified framework that addresses this challenge through principled scene-appearance disentanglement. They decompose observed images into domain-invariant scene representations and domain-specific appearance codes, enabling registration via re-rendering rather than direct intensity matching. The method achieves a median relative Target Registration Error (rTRE) of 0.25%, outperforming the state-of-the-art MEVIS method by 7.4%, with robustness of 99.1%. The authors validate SAR-Net on the ANHIR challenge benchmark, where multi-stain histopathology images exhibit coupled domain shift and geometric distortion from tissue preparation.",314.5,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08881v1_TAG-MoE Task-Aware Gating for Unified Generative M.pdf,TAG-MoE: Task-Aware Gating for Unified Generative Mixture-of-Experts,"['Yu Xu', 'Hongbin Yan', 'Juan Cao', 'Yiji Cheng', 'Tiankai Hang', 'Runze He', 'Zijin Yin', 'Shiyi Zhang', 'Yuxin Zhang', 'Jintao Li', 'Chunyu Wang', 'Qinglin Lu', 'Tong-Yee Lee', 'Fan Tang']","Unified image generation and editing models suffer from severe task interference in dense diffusion transformer architectures. The sparse Mixture-of-Experts (MoE) paradigm is a promising solution, but its gating networks remain task-agnostic. This paper proposes a novel framework to inject semantic intent into MoE routing, introducing a Hierarchical Task Semantic Annotation scheme and Predictive Alignment Regularization to evolve the gating network from a task-agnostic executor to a dispatch center. The model effectively mitigates task interference, outperforming dense baselines in fidelity and quality.",314.78,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08882v1_Compressing Vision Transformers in Geospatial Tran.pdf,Compressing Vision Transformers in Geospatial Transfer Learning with Manifold-Constrained Optimization,"['Thomas Snyder', 'H. Lexie Yang', 'Stefan Schnake', 'Steffen Schotthöfer']","Deploying geospatial foundation models on resource-constrained edge devices demands compact architectures that maintain high downstream performance. However, their large parameter counts and the accuracy loss often induced by compression limit practical adoption. This work leverages manifold-constrained optimization framework DLRT to compress large vision transformer-based geospatial foundation models during transfer learning. By enforcing structured low-dimensional parameterizations aligned with downstream objectives, this approach achieves strong compression while preserving task-specific accuracy. Experiments on diverse geospatial benchmarks confirm substantial parameter reduction with minimal accuracy loss, enabling high-performing, on-device geospatial models.",314.92,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08884v1_Bridging the Gap Empowering Small Models in Reliab.pdf,Bridging the Gap: Empowering Small Models in Reliable OpenACC-based Parallelization via GEPA-Optimized Prompting,"['Samyak Jhaveri', 'Cristina V. Lopes']","Directive-based parallel programming frameworks like OpenACC lower the barrier to GPU-offloading by abstracting low-level programming details. However, manually writing high-performance pragmas remains a significant challenge. Large Language Models (LLMs) present a promising potential solution for automated parallel code generation, but naive prompting often results in syntactically incorrect directives, uncompilable code, or performance that fails to exceed CPU baselines. This work presents a systematic prompt optimization approach to enhance OpenACC pragma generation without prohibitive computational costs associated with LLM post-training. The GEPA (GEnetic-PAreto) framework iteratively evolves prompts through a reflective feedback loop, using crossover and mutation of prompt instructions guided by expertly curated 'gold' pragma examples and structured feedback based on clause and parameter-level mismatches between 'gold' pragma and predicted pragma. Evaluation on the PolyBench suite shows a significant increase in compilation success rates for programs annotated with OpenACC pragma generated using optimized prompts, particularly for smaller and cheaper 'nano'-scale models. The optimized prompts resulted in a 21% increase in the number of programs achieving functional GPU speedups over CPU baselines, demonstrating that prompt optimization effectively unlocks the potential of smaller, cheaper LLMs to write stable and effective GPU-offloading directives, establishing a cost-effective pathway and lowering the expertise barrier to automated directive-based parallelization in HPC development workflows.",313.03,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08891v1_Attention Consistency Regularization for Interpret.pdf,Attention Consistency Regularization for Interpretable Early-Exit Neural Networks,['Yanhua Zhao'],"This paper presents Explanation-Guided Training (EGT), a multi-objective framework that improves interpretability and consistency in early-exit neural networks through attention-based regularization. EGT introduces an attention consistency loss that aligns early-exit attention maps with the final exit. The framework jointly optimizes classification accuracy and attention consistency through a weighted combination of losses. Experiments on a real-world image classification dataset demonstrate that EGT achieves up to 98.97% overall accuracy (matching baseline performance) with a 1.97× inference speedup through early exits, while improving attention consistency by up to 18.5% compared to baseline models. The proposed method provides more interpretable and consistent explanations across all exit points, making early-exit networks more suitable for explainable AI applications in resource-constrained environments.",314.11,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08892v1_Evaluating Role-Consistency in LLMs for Counselor .pdf,Evaluating Role-Consistency in LLMs for Counselor Training,"['Eric Rudolph', 'Natalie Engert', 'Jens Albrecht']","The rise of online counseling services has highlighted the need for effective training methods for future counselors. This paper extends research on VirCo, a Virtual Client for Online Counseling, designed to complement traditional role-playing methods in academic training by simulating realistic client interactions. Building on previous work, the authors introduce a new adversarial dataset to test the ability of large language models (LLMs) to maintain their assigned roles (role-consistency). The study focuses on evaluating the role consistency and coherence of the Vicuna model's responses, comparing these findings with earlier research. Additionally, the authors assess and compare various open-source LLMs for their performance in sustaining role consistency during virtual client interactions. The contributions include creating an adversarial dataset, evaluating conversation coherence and persona consistency, and providing a comparative analysis of different LLMs.",316.21,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08896v1_XGBoost Forecasting of NEPSE Index Log Returns wit.pdf,XGBoost Forecasting of NEPSE Index Log Returns with Walk Forward Validation,"['Sahaj Raj Mallaa', 'Shreeyash Kayastha', 'Rumi Suwala', 'Harish Chandra Bhandari', 'Rajendra Adhikari']","This study develops a robust machine learning framework for one-step-ahead forecasting of daily log-returns in the Nepal Stock Exchange (NEPSE) Index using the XGBoost regressor. A comprehensive feature set is engineered, including lagged log-returns (up to 30 days) and established technical indicators such as short- and medium-term rolling volatility measures and the 14-period Relative Strength Index. Hyperparameter optimization is performed using Optuna with time-series cross-validation on the initial training segment. Out-of-sample performance is rigorously assessed via walk-forward validation under both expanding and fixed-length rolling windows schemes across multiple lag configurations, simulating real-world deployment and avoiding lookahead bias. Predictive accuracy is evaluated using root mean squared error, mean absolute error, coefficient of determination (R²), and directional accuracy on both log-returns and reconstructed closing prices. Empirical results show that the optimal configuration—an expanding window with 20 lags—outperforms tuned ARIMA and Ridge regression benchmarks, achieving the lowest log-return RMSE (0.013450) and MAE (0.009814) alongside a directional accuracy of 65.15%. While R² remains modest, consistent with the noisy nature of financial returns, primary emphasis is placed on relative error reduction and directional prediction. Feature importance analysis and visual inspection further enhance interpretability. These findings demonstrate the effectiveness of gradient boosting ensembles in modeling nonlinear dynamics in volatile emerging market time series and establish a reproducible benchmark for NEPSE Index forecasting.",311.59,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08901v1_Navigating Ideation Space Decomposed Conceptual Re.pdf,Navigating Ideation Space: Decomposed Conceptual Representations for Positioning Scientific Ideas,"['Yuexi Shen', 'Minqian Liu', 'Dawei Zhou', 'Lifu Huang']","Scientific discovery is a cumulative process requiring new ideas to be situated within an expanding landscape of existing knowledge. The pace of this expansion is astonishing, particularly in computer science and AI. Current embedding approaches typically conflate distinct conceptual aspects into single representations, hindering fine-grained literature retrieval. LLM-based evaluators are subject to sycophancy biases, failing to provide discriminative novelty assessment. This paper introduces the Ideation Space, a structured representation that decomposes scientific knowledge into three dimensions: research problem, methodology, and core findings, each learned through contrastive training. This framework enables principled measurement of conceptual distance between ideas and modeling of ideation transitions. Building upon this, a Hierarchical Sub-Space Retrieval framework and a Decomposed Novelty Assessment algorithm are proposed for efficient, targeted literature retrieval and identifying novel aspects of ideas, respectively. Extensive experiments demonstrate substantial improvements in recall, hit rate, and correlation with expert judgments.",313.3,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08910v1_Towards a Self-Driving Trigger at the LHC Adaptive.pdf,Towards a Self-Driving Trigger at the LHC: Adaptive Response in Real Time,"['Shaghayegh Emami', 'Cecilia Tosciri', 'Giovanna Salvi', 'Zixin Ding', 'Yuxin Chen', 'Abhijith Gandrakota', 'Christian Herwig', 'David W. Miller', 'Jennifer Ngadiuba', 'Nhan Tran']","Real-time data filtering and selection – ortrigger– systems at high-throughput scientific facilities such as the experiments at the Large Hadron Collider (LHC) must process extremely high-rate data streams under stringent bandwidth, latency, and storage constraints. This work explores the concept of a self-driving trigger, an autonomous data-filtering framework that reallocates resources and adjusts thresholds dynamically in real-time to optimize signal efficiency, rate stability, and computational cost. The authors introduce a benchmark ecosystem to emulate realistic collider scenarios and demonstrate real-time optimization of a menu including canonical energy sum triggers and modern anomaly-detection algorithms using machine learning. Using simulated data streams and publicly available collision data from the Compact Muon Solenoid (CMS) experiment, they demonstrate the capability to dynamically and automatically optimize trigger performance under specific cost objectives without manual retuning. Their adaptive strategy shifts trigger design from static menus with heuristic tuning to intelligent, automated, data-driven control, unlocking greater flexibility and discovery potential in future high-energy physics analyses.",311.59,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08950v1_ConvoLearn A Dataset of Constructivist Tutor-Stude.pdf,ConvoLearn: A Dataset of Constructivist Tutor-Student Dialogue,"['Mayank Sharma', 'Pea Roy', 'Hari Subramonyam']","In educational applications, Large Language Models (LLMs) exhibit fundamental pedagogical limitations, such as their tendency to reveal solutions rather than support dialogic learning. This paper introduces ConvoLearn, a dataset grounded in knowledge-building theory that operationalizes six core pedagogical dimensions: cognitive engagement, formative assessment, accountability, cultural responsiveness, metacognition, and power dynamics. The dataset consists of 1,250 tutor-student dialogues (20 turns each) in middle school Earth Science through controlled interactions between human teachers and a simulated student. Using QLoRA, the authors demonstrate that training on this dataset meaningfully shifts LLM behavior towards knowledge-building strategies. Human evaluation by 31 teachers shows that the fine-tuned Mistral-7B model significantly outperforms its base version and Claude Sonnet 4.5 overall. This work establishes a potential framework to guide future development and evaluation of constructivist AI tutors.",313.22,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08951v1_PluriHarms Benchmarking the Full Spectrum of Human.pdf,PLURIHARMS: BENCHMARKING THE FULL SPECTRUM OF HUMAN JUDGMENTS ON AI HARM,"['Jing-Jing Li', 'Joel Mire', 'Eve Fleisig', 'Valentina Pyatkin', 'Anne G. E. Collins', 'Maarten Sap', 'Sydney Levine']","Current AI safety frameworks often treat harmfulness as binary, leading to safety datasets that over-sample unambiguous extremes and overlook meaningful disagreement in borderline cases. PLURIHARMS is a benchmark designed to systematically study human harm judgments across two key dimensions: the harm axis (benign to harmful) and the agreement axis (agreement to disagreement). The scalable framework generates prompts that capture diverse AI harms and human values while targeting cases with high disagreement rates, validated by human data. The benchmark includes 150 prompts with 15,000 ratings from 100 human annotators, enriched with demographic and psychological traits and prompt-level features of harmful actions, effects, and values. The analyses show that prompts related to imminent risks and tangible harms amplify perceived harmfulness, while annotator traits and their interactions with prompt content explain systematic disagreement. The work provides a principled benchmark for moving beyond “one-size-fits-all” safety toward pluralistically safe AI.",314.42,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08953v1_Fairness risk and its privacy-enabled solution in .pdf,Fairness risk and its privacy-enabled solution in AI-driven robotic applications,"['Le Liu', 'Bangguo Yu', 'Nynke Vellinga', 'Ming Cao']","Complex decision-making by autonomous machines and algorithms could underpin the foundations of future society. Generative AI is emerging as a powerful engine for such transitions. However, the paper shows that Generative AI-driven developments pose a critical pitfall: fairness concerns. In robotic applications, although intuitions about fairness are common, a precise and implementable definition that captures user utility and inherent data randomness is missing. The authors provide a utility-aware fairness metric for robotic decision-making and analyze fairness jointly with user-data privacy, deriving conditions under which privacy budgets govern fairness metrics. This yields a unified framework that formalizes and quantifies fairness and its interplay with privacy, tested in a robot navigation task. The approach shows that privacy budgets can be jointly used to meet fairness targets, addressing fairness concerns in the combined consideration of privacy, which strengthens trust in autonomous robots deployed in everyday environments.",309.78,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08955v1_Imagine-then-Plan Agent Learning from Adaptive Loo.pdf,Imagine-then-Plan: Agent Learning from Adaptive Lookahead with World Models,"['Youwei Liu2', 'Jian Wang 1†', 'Hanlin Wang 1', 'Beichen Guo 1', 'Wenjie Li 1']","Recent advances in world models have shown promise for modeling future dynamics of environmental states, enabling agents to reason and act without accessing real environments. Current methods mainly perform single-step or fixed-horizon rollouts, leaving their potential for complex task planning under-exploited. We propose Imagine-then-Plan (ITP), a unified framework for agent learning via lookahead imagination, where an agent's policy model interacts with the learned world model, yielding multi-step 'imagined' trajectories. Since the imagination horizon may vary by tasks and stages, we introduce a novel adaptive lookahead mechanism by trading off the ultimate goal and task progress. The resulting imagined trajectories provide rich signals about future consequences, such as achieved progress and potential conflicts, which are fused with current observations, forming a partially observable and imaginable Markov decision process to guide policy learning. We instantiate ITP with both training-free and reinforcement-trained variants. Extensive experiments across representative agent benchmarks demonstrate that ITP significantly outperforms competitive baselines. Further analyses validate that our adaptive lookahead largely enhances agents' reasoning capability, providing valuable insights into addressing broader, complex tasks. Our code and data will be released.",309.99,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.08988v1_ART Action-based Reasoning Task Benchmarking for M.pdf,ART: Action-based Reasoning Task Benchmarking for Medical AI Agents,"['Ananya Mantravadi', 'Shivali Dalmia', 'Abhishek Mukherji']","Reliable clinical decision support requires medical AI agents capable of safe, multi-step reasoning over structured electronic health records (EHRs). While large language models (LLMs) show promise in healthcare, existing benchmarks inadequately assess performance on action-based tasks involving threshold evaluation, temporal aggregation, and conditional logic. We introduce ART, an Action-based Reasoning clinical Task benchmark for medical AI agents, which mines real-world EHR data to create challenging tasks targeting known reasoning weaknesses. Through analysis of existing benchmarks, we identify three dominant error categories: retrieval failures, aggregation errors, and conditional logic misjudgments. Our four-stage pipeline—scenario identification, task generation, quality audit, and evaluation—produces diverse, clinically validated tasks grounded in real patient data. Evaluating GPT-4o-mini and Claude 3.5 Sonnet on 600 tasks shows near-perfect retrieval after prompt refinement, but substantial gaps in aggregation (28-64%) and threshold reasoning (32-38%). By exposing failure modes in action-oriented EHR reasoning, ART advances toward more reliable clinical agents, an essential step for AI systems that reduce cognitive load and administrative burden, supporting workforce capacity in high-demand care settings.",315.37,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09012v3_TranslateGemma Technical Report.pdf,TranslateGemma Technical Report,['Google Translate Research Team'],"The report presents TranslateGemma, an open machine translation suite based on the Gemma 3 foundation models. It employs a two-stage fine-tuning process: supervised fine-tuning using a mixture of human-translated and synthetic parallel data, and reinforcement learning from human and model-based feedback. The report demonstrates the effectiveness of TranslateGemma with human evaluation on the WMT25 test set across 10 language pairs and automatic evaluation on the WMT24++ benchmark across 55 language pairs. It shows consistent and substantial gains in translation quality over the baseline Gemma 3 models. Smaller TranslateGemma models often achieve performance comparable to larger baseline models, offering improved efficiency. The report also highlights the model's strong multimodal capabilities, with enhanced performance on the Vistra image translation benchmark. The release of the open TranslateGemma models aims to provide a powerful and adaptable tool for the machine translation community.",314.63,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09018v1_Meta-learning to Address Data Shift in Time Series.pdf,META-LEARNING TOADDRESSDATASHIFT INTIMESERIES CLASSIFICATION,"['Samuel Myrenab', 'Nidhi Parikha', 'Natalie Kleina']","Across engineering and scientific domains, traditional deep learning models perform well when training and test data share the same distribution. However, real-world data's dynamic nature, termed data shift, renders TDL models prone to rapid performance degradation, requiring costly relabeling and inefficient retraining. Meta-learning, which enables models to adapt quickly to new data with few examples, offers a promising alternative for mitigating these challenges. This work systematically compares TDL with fine-tuning and optimization-based meta-learning algorithms to assess their ability to address data shift in time-series classification. A controlled, task-oriented seismic benchmark (SeisTask) is introduced, showing that meta-learning typically achieves faster and more stable adaptation with reduced overfitting in data-scarce regimes and smaller model architectures. As data availability and model capacity increase, its advantages diminish, with TDL with fine-tuning performing comparably. Finally, task diversity influences meta-learning, with alignment between training and test distributions driving performance gains. Overall, this work provides a systematic evaluation of when and why meta-learning outperforms TDL under data shift and contributes SeisTask as a benchmark for advancing adaptive learning research in time-series domains.",313.96,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09028v1_OpenDecoder Open Large Language Model Decoding to .pdf,OpenDecoder: Open Large Language Model Decoding to Incorporate Document Quality in RAG,"['Fengran Mo', 'Zhan Su', 'Yuchen Hui', 'Jianhan Zhang', 'Jia Ao Sun', 'Zheyuan Liu', 'Chao Zhang', 'Tetsuya Sakai', 'Jian-Yun Nie']","The paper proposes OpenDecoder, a new approach that leverages explicit evaluation of the retrieved information as quality indicator features for generation. It considers three types of explicit evaluation information: relevance score, ranking score, and QPP (query performance prediction) score. The experimental results on five benchmark datasets demonstrate the effectiveness and better robustness of OpenDecoder by outperforming various baseline methods. The paradigm is flexible to be integrated with the post-training of LLMs for any purposes and incorporated with any type of external indicators.",314.19,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09029v1_Proactively Detecting Threats A Novel Approach Usi.pdf,Proactively Detecting Threats: A Novel Approach Using LLMs,"['Aniesh Chawla', 'Udbhav Prasad']","Enterprise security faces escalating threats from sophisticated malware, compounded by expanding digital operations. This paper presents the first systematic evaluation of large language models (LLMs) to proactively identify indicators of compromise (IOCs) from unstructured web-based threat intelligence sources, distinguishing it from reactive malware detection approaches. We developed an automated system that pulls IOCs from 15 web-based threat report sources to evaluate six LLM models (Gemini, Qwen, and Llama variants). Our evaluation of 479 webpages containing 2,658 IOCs (711 IPv4 addresses, 502 IPv6 addresses, 1,445 domains) reveals significant performance variations. Gemini 1.5 Pro achieved 0.958 precision and 0.788 specificity for malicious IOC identification, while demonstrating perfect recall (1.0) for actual threats.",310.32,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09031v1_Generalizable Geometric Prior and Recurrent Spikin.pdf,GENERALIZABLE GEOMETRIC PRIOR AND RECURRENT SPIKING FEATURE LEARNING FOR HUMANOID ROBOT MANIPULATION,"['Xuetao Li', 'Wenke Huang', 'Mang Ye', 'Jifeng Xuan', 'Bo Du', 'Sheng Liu', 'Miao Li']","This paper presents a novel RGMP-S, Recurrent Geometric-prior Multimodal Policy with Spiking features, facilitating both high-level skill reasoning and data-efficient motion synthesis. The authors leverage lightweight 2D geometric inductive biases to enable precise 3D scene understanding within the vision-language model. They introduce a Recursive Adaptive Spiking Network to address the data efficiency issue in robotic action generation. Extensive experiments across the Maniskill simulation benchmark and three heterogeneous real-world robotic systems validate the superiority of the proposed method over state-of-the-art baselines.",313.79,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09032v1_The Hierarchy of Agentic Capabilities Evaluating F.pdf,The Hierarchy of Agentic Capabilities: Evaluating Frontier Models on Realistic RL Environments,"['Logan Ritchie∗', 'Sushant Mehta', 'Nick Heiner', 'Mason Yu', 'Edwin Chen', 'Surge AI']","The advancement of large language model (LLM) based agents has shifted AI evaluation from single-turn response assessment to multi-step task completion in interactive environments. This study evaluates frontier AI models on 150 workplace tasks within a realistic e-commerce RL environment from Surge. The analysis reveals an empirically-derived hierarchy of agentic capabilities that models must master for real-world deployment: tool use, planning and goal formation, adaptability, groundedness, and common-sense reasoning. Even the best-performing models fail approximately 40% of the tasks, with failures clustering predictably along this hierarchy. The findings suggest that while current frontier models can demonstrate coherent multi-step behavior, substantial capability gaps remain before achieving human-level task completion in realistic workplace settings.",311.8,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09035v1_A Decompilation-Driven Framework for Malware Detec.pdf,A Decompilation-Driven Framework for Malware Detection with Large Language Models,"['Aniesh Chawla', 'Udbhav Prasad']","The paper evaluates the efficacy of state-of-the-art Large Language Models (LLMs) in classifying executable code as either benign or malicious. It introduces an automated pipeline that first decompiles Windows executable into C code using Ghidra disassembler and then leverages LLMs for classification. The evaluation shows that while standard LLMs show promise, they are not yet robust enough to replace traditional anti-virus software. A fine-tuned model trained on curated malware and benign datasets significantly outperforms its vanilla counterpart, but performance degrades with newer malware. This highlights the need for continuous fine-tuning with emerging threats to maintain model effectiveness against changing coding patterns and behaviors of malicious software.",310.97,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09041v1_Can LLMs interpret figurative language as humans d.pdf,CANLLMSINTERPRETFIGURATIVELANGUAGE ASHUMANSDO?: SURFACE-LEVEL VS. REPRESENTATIONAL SIMILARITY,"['Samhita Bollepally', 'Aurora Sloman-Moll', 'Takashi Yamauchi']","This study investigates the extent to which large language models (LLMs) align with human judgments in interpreting figurative and socially grounded language. Human participants and four instruction-tuned LLMs (GPT-4, Gemma-2-9B, Llama-3.2, and Mistral-7B) rated 240 dialogue-based sentences representing six linguistic traits: conventionality, sarcasm, funny, emotional, idiomacy, and slang. Results indicate that humans and LLMs align at the surface level but diverge significantly at the representational level, especially in interpreting figurative sentences involving idioms and Gen Z slang. GPT-4 most closely approximates human representational patterns, while all models struggle with context-dependent and socio-pragmatic expressions like sarcasm, slang, and idiomacy.",311.75,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09049v1_Is Grokking Worthwhile Functional Analysis and Tra.pdf,Grokking Worthwhile? Functional Analysis and Transferability of Generalization Circuits in Transformers,"['Kaiyu He', 'Mian Zhang', 'Peilin Wu', 'Xinya Du', 'Zhiyu Zoey Chen']","While Large Language Models (LLMs) excel at factual retrieval, they often struggle with the 'curse of two-hop reasoning' in compositional tasks. Recent research suggests that parameter-sharing transformers can bridge this gap by forming a 'Generalization Circuit' during a prolonged 'grokking' phase. A fundamental question arises: Is a grokked model superior to its non-grokked counterparts on downstream tasks? Furthermore, is the extensive computational cost of waiting for the grokking phase worthwhile? In this work, we conduct a mechanistic study to evaluate the Generalization Circuit's role in knowledge assimilation and transfer. We demonstrate that: (i) The inference paths established by non-grokked and grokked models for in-distribution compositional queries are identical. This suggests that the 'Generalization Circuit' does not represent the sudden acquisition of a new reasoning paradigm. Instead, we argue that grokking is the process of integrating memorized atomic facts into an naturally established reasoning path. (ii) Achieving high accuracy on unseen cases after prolonged training and the formation of a certain reasoning path are not bound; they can occur independently under specific data regimes. (iii) Even a mature circuit exhibits limited transferability when integrating new knowledge, suggesting that 'grokked' Transformers do not achieve a full mastery of compositional logic. Our code and data are available at: https://github.com/KaiyuHe998/IsGrokkingWorthwhile.",313.54,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09066v1_Midm 2.0 Korea-centric Bilingual Language Models.pdf,Mi:dm 2.0,"['Tech. Innovation Group, KT']","We introduce Mi:dm 2.0, a bilingual large language model (LLM) specifically engineered to advance Korea-centric AI. This model integrates the values, reasoning patterns, and commonsense knowledge inherent to Korean society, enabling nuanced understanding of cultural contexts, emotional subtleties, and real-world scenarios. Mi:dm 2.0 addresses limitations of existing LLMs by emphasizing robust data quality through a comprehensive pipeline that includes proprietary data cleansing, high-quality synthetic data generation, strategic data mixing with curriculum learning, and a custom Korean-optimized tokenizer. The model achieves state-of-the-art performance in Korean-specific benchmarks and offers two complementary configurations: Mi:dm 2.0 Base (11.5B parameters) and Mi:dm 2.0 Mini (2.3B parameters). KT aims to accelerate AI adoption across Korean industries, public services, and education by releasing these accessible and high-performance Korea-centric LLMs under the MIT license.",310.89,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09069v1_From Symbolic to Natural-Language Relations Rethin.pdf,Symbolic to Natural-Language Relations: Rethinking Knowledge Graph Construction in the Era of Large Language Models,"['Kanyao Han', 'Yushang Lai']","This position paper argues that the emergence of large language models (LLMs) has reshaped how knowledge is created and consumed. LLMs support scalable synthesis of domain facts directly in concise natural language, and prompting-based inference favors context-rich free-form text over quantified representations. The authors advocate moving from symbolic to natural-language relation descriptions, proposing hybrid design principles that preserve a minimal structural backbone while enabling more flexible and context-sensitive relational representations.",313.5,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09072v1_Human-AI Co-design for Clinical Prediction Models.pdf,Human-AI Co-design for Clinical Prediction Models,"['Jean Feng', 'Avni Kothari', 'Patrick Vossler', 'Andrew Bishara', 'Lucas Zier', 'Newton Addo', 'Aaron Kornblith', 'Yan Shuo Tan', 'Chandan Singh']","Developing safe, effective, and practically useful clinical prediction models (CPMs) traditionally requires iterative collaboration between clinical experts, data scientists, and informaticists. However, this process is time- and resource-intensive, resulting in only a small fraction of CPMs reaching clinical practice. To address this challenge, we introduce HACHI, an iterative human-in-the-loop framework that uses AI agents to accelerate the development of fully interpretable CPMs by enabling the exploration of concepts in clinical notes. HACHI alternates between an AI agent rapidly exploring and evaluating candidate concepts in clinical notes and clinical and domain experts providing feedback to improve the CPM learning process. In two real-world prediction tasks (acute kidney injury and traumatic brain injury), HACHI outperforms existing approaches, surfaces new clinically relevant concepts not included in commonly-used CPMs, and improves model generalizability across clinical sites and time periods. Furthermore, HACHI reveals the critical role of the clinical AI team, such as directing the AI agent to explore entire categories of concepts that it had not previously considered, adjusting the granularity of concepts it considers, changing the objective function to better align with the clinical objectives, and identifying issues of data bias and leakage.",314.53,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09085v1_MMR-GRPO Accelerating GRPO-Style Training through .pdf,MMR-GRPO: Accelerating GRPO-Style Training through Diversity-Aware Reward Reweighting,"['Kangda Wei', 'Ruihong Huang']","MMR-GRPO integrates Maximal Marginal Relevance to reweigh rewards based on completion diversity, aiming to accelerate convergence. Evaluations across three model sizes and five mathematical reasoning benchmarks show that MMR-GRPO achieves comparable peak performance while requiring on average 47.9% fewer training steps and 70.2% less wall-clock time. The key insight is that semantically redundant completions contribute limited marginal learning signal, and prioritizing diverse solutions yields more informative updates.",310.83,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09089v1_SubTokenTest A Practical Benchmark for Real-World .pdf,SUBTOKENTEST: A Practical Benchmark for Real-World Sub-token Understanding,"['Shuyang Hou', 'Yi Hu', 'Muhan Zhang']","Recent advancements in large language models (LLMs) have significantly enhanced their reasoning capabilities, but they continue to struggle with basic character-level tasks, such as counting letters in words. Existing benchmarks have highlighted this weakness through basic character operations, but many real-world applications rely on precise sub-token understanding. SUBTOKENTEST introduces a comprehensive benchmark that assesses sub-token understanding through practical, utility-driven tasks. The benchmark includes ten tasks across four domains and isolates tokenization-related failures by decoupling performance from complex reasoning. Nine advanced LLMs are evaluated, and the impact of test-time scaling on sub-token reasoning is investigated. Additionally, the encoding of character-level information within hidden states is explored.",310.16,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09097v1_Programming over Thinking Efficient and Robust Mul.pdf,Programming over Thinking: Efficient and Robust Multi-Constraint Planning,"['Derrick Goh Xin Deik', 'Quanyu Long', 'Zhengyuan Liu', 'Nancy F. Chen', 'Wenya Wang']","Multi-constraint planning involves identifying, evaluating, and refining candidate plans while satisfying multiple, potentially conflicting constraints. Existing large language model (LLM) approaches face fundamental limitations in this domain. Pure reasoning paradigms, which rely on long natural language chains, are prone to inconsistency, error accumulation, and prohibitive cost as constraints compound. Conversely, LLMs combined with coding- or solver-based strategies lack flexibility: they often generate problem-specific code from scratch or depend on fixed solvers, failing to capture generalizable logic across diverse problems. To address these challenges, the ScalableCodePlanningEngine (SCOPE) framework is introduced, which disentangles query-specific reasoning from generic code execution. By separating reasoning from execution, SCOPE produces solver functions that are consistent, deterministic, and reusable across queries while requiring only minimal changes to input parameters. SCOPE achieves state-of-the-art performance while lowering cost and latency. For example, with GPT-4, it reaches 93.1% success on TravelPlanner, a 61.6% gain over the best baseline (CoT) while cutting inference cost by 1.4x and time by 4.67x. Code is available at https://github.com/DerrickGXD/SCOPE.",312.23,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09100v2_DScheLLM Enabling Dynamic Scheduling through a Fin.pdf,Enabling Dynamic Scheduling through a Fine-Tuned Dual-System Large Language Model,"['Lixiang Zhang', 'Chenggong Zhao', 'Qing Gao', 'Xiaoke Zhao', 'Gengyi Bai', 'Jinhu Lv']","Production scheduling, particularly job shop scheduling, is highly susceptible to dynamic disruptions such as variations in processing times, machine availability, and unexpected task insertions. Conventional approaches typically rely on event-specific models and explicit analytical formulations, which limits their adaptability and generalization. This paper proposes DScheLLM, a dynamic scheduling approach that leverages fine-tuned large language models within a dual-system (fast–slow) reasoning architecture to address disturbances of different scales. A unified large language model-based framework is constructed to handle dynamic events, where training datasets for both fast and slow reasoning modes are generated using exact schedules obtained from an operations research solver. The Huawei OpenPangu Embedded-7B model is subsequently fine-tuned under the hybrid reasoning paradigms using LoRA. Experimental evaluations on standard job shop scheduling benchmarks demonstrate that the fast-thinking mode can efficiently generate high-quality schedules, and the slow-thinking mode can produce solver-compatible and well-formatted decision inputs. This work represents one of the earliest studies applying large language models to job shop scheduling in dynamic environments, highlighting their considerable potential for intelligent and adaptive scheduling optimization.",311.2,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09105v2_AviationLMM A Large Multimodal Foundation Model fo.pdf,AviationLMM: A Large Multimodal Foundation Model for Civil Aviation,"['Wenbin Li', 'Jingling Wu', 'Xiaoyong Lin', 'Jing Chen', 'Cong Chen']","Civil aviation is a cornerstone of global transportation and commerce. This paper introduces AviationLMM, a Large Multimodal foundation Model for civil aviation, designed to unify heterogeneous data streams and enable understanding, reasoning, generation, and agentic applications. The model ingests multimodal inputs such as air-ground voice, surveillance, on-board telemetry, video, and structured texts, performs cross-modal alignment and fusion, and produces flexible outputs ranging from situation summaries and risk alerts to predictive diagnostics and multimodal incident reconstructions. Key research opportunities include data acquisition, alignment and fusion, pretraining, reasoning, trustworthiness, privacy, robustness to missing modalities, and synthetic scenario generation. By articulating the design and challenges of AviationLMM, the authors aim to boost civil aviation foundation model progress and catalyze coordinated research efforts toward an integrated, trustworthy, and privacy-preserving aviation AI ecosystem.",310.07,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09113v1_The AI Hippocampus How Far are We From Human Memor.pdf,The AI Hippocampus: How Far are We From Human Memory?,"['Zixia Jia', 'Jiaqi Li', 'Yipeng Kang', 'Yuxuan Wang', 'Tong Wu', 'Quansen Wang', 'Xiaobo Wang', 'Shuyi Zhang', 'Junzhe Shen', 'Qing Li', 'Siyuan Qi', 'Yitao Liang', 'Di He', 'Zilong Zheng', 'Song-Chun Zhu']","Memory plays a foundational role in modern Large Language Models (LLMs) and Multi-Modal LLMs (MLLMs). This survey presents a comprehensive and structured synthesis of memory in LLMs and MLLMs, organizing the literature into a cohesive taxonomy comprising implicit, explicit, and agentic memory paradigms. The survey delineates three primary memory frameworks: implicit memory, explicit memory, and agentic memory. Implicit memory refers to the knowledge embedded within the internal parameters of pre-trained transformers, encompassing their capacity for memorization, associative retrieval, and contextual reasoning. Recent work has explored methods to interpret, manipulate, and reconfigure this latent memory. Explicit memory involves external storage and retrieval components designed to augment model outputs with dynamic, queryable knowledge representations—such as textual corpora, dense vectors, and graph-based structures—thereby enabling scalable and updatable interaction with information sources. Agentic memory introduces persistent, temporally extended memory structures within autonomous agents, facilitating long-term planning, self-consistency, and collaborative behavior in multi-agent systems. The survey also examines the integration of memory within multi-modal settings, where coherence across vision, language, audio, and action modalities is essential. Key architectural advances, benchmark tasks, and open challenges are discussed, including issues related to memory capacity, alignment, factual consistency, and cross-system interoperability. By charting the current landscape and identifying critical research directions, this survey aims to inform the development of memory-augmented (M)LLMs that are more flexible, context-sensitive, and aligned with the requirements of real-world intelligent systems.",314.73,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09116v1_LP-LLM End-to-End Real-World Degraded License Plat.pdf,LP-LLM: End-to-End Real-World Degraded License Plate Text Recognition via Large Multimodal Models,"['Haoyan Gong', 'Hongbin Liu']","Real-world License Plate Recognition (LPR) faces significant challenges from severe degradations such as motion blur, low resolution, and complex illumination. The prevailing two-stage paradigm of restoration-then-recognition suffers from a fundamental flaw: pixel-level optimization objectives of image restoration models are misaligned with semantic goals of character recognition, leading to artifact interference and error accumulation. This paper proposes an end-to-end structure-aware multimodal reasoning framework based on Qwen3-VL, introducing a Character-Aware Multimodal Reasoning Module (CMRM) with learnable Character Slot Queries. Through cross-attention, these queries actively retrieve fine-grained evidence corresponding to character positions from visual features. Character-aware representations are then injected back into visual tokens via residual modulation, enabling autoregressive generation based on explicit structural priors. Combined with LoRA parameter-efficient fine-tuning, the model achieves domain adaptation while retaining large model generalization capabilities. Extensive experiments on synthetic and real-world severely degraded datasets validate the superiority of incorporating structured reasoning into large models for low-quality text recognition tasks.",313.63,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09117v1_A Marketplace for AI-Generated Adult Content and D.pdf,A Marketplace for AI-Generated Adult Content and Deepfakes,"['Shalmoli Ghosh', 'Matthew R. DeVerna', 'Filippo Menczer']","Generative AI systems enable highly realistic synthetic media. Civitai's Bounties feature allows users to commission AI-generated content in exchange for payment. This study examines 14-month bounty requests, finding that requests for content not trained to generate are common, and requests for 'Not Safe For Work' content have increased. Deepfake requests are concentrated, with explicit content prohibited. These bounties disproportionately target female celebrities, revealing gender asymmetry in social harm. The findings raise questions about consent, governance, and enforcement in monetized, community-driven generative AI platforms.",314.66,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09120v1_Adaptive Multi-Stage Patent Claim Generation with .pdf,Adaptive Multi-Stage Patent Claim Generation with Unified Quality Assessment,"['Chen-Wei Liang', 'Bin Guo', 'Zhen-Yuan Wei', 'Mu-Jiang-Shan Wang']","Current patent claim generation systems face three fundamental limitations: poor cross-jurisdictional generalization, inadequate semantic relationship modeling between claims and prior art, and unreliable quality assessment. The authors introduce a novel three-stage framework that addresses these challenges through relationship-aware similarity analysis, domain-adaptive claim generation, and unified quality assessment. The approach employs multi-head attention with eight specialized heads for explicit relationship modeling, integrates curriculum learning with dynamic LoRA adapter selection across five patent domains, and implements cross-attention mechanisms between evaluation aspects for comprehensive quality assessment. Extensive experiments on USPTO HUPD dataset, EPO patent collections, and Patent-CE benchmark demonstrate substantial improvements: 7.6-point ROUGE-L gain over GPT-4o, 8.3% BERTScore enhancement over Llama-3.1-8B, and 0.847 correlation with human experts compared to 0.623 for separate evaluation models. The method maintains 89.4% cross-jurisdictional performance retention versus 76.2% for baselines, establishing a comprehensive solution for automated patent prosecution workflows.",315.51,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09130v1_Equi-ViT Rotational Equivariant Vision Transformer.pdf,EQUI-VIT: ROTATIONAL EQUIV ARIANT VISION TRANSFORMER FOR ROBUST HISTOPATHOLOGY ANALYSIS,"['Fuyao Chen', 'Yuexi Du', 'Eléonore V. Lieffrig', 'Nicha C. Dvornek', 'John A. Onofrey']","Vision Transformers (ViTs) have gained rapid adoption in computational pathology for their ability to model long-range dependencies through self-attention, addressing the limitations of convolutional neural networks that excel at local pattern capture but struggle with global context reasoning. Recent pathology-specific foundation models have further advanced performance by leveraging large-scale pretraining. However, standard ViTs remain inherently non-equivariant to transformations such as rotations and reflections, which are ubiquitous variations in histopathology imaging. To address this limitation, we propose Equi-ViT, which integrates an equivariant convolution kernel into the patch embedding stage of a ViT architecture, imparting built-in rotational equivariance to learned representations. Equi-ViT achieves superior rotation-consistent patch embeddings and stable classification performance across image orientations. Our results on a public colorectal cancer dataset demonstrate that incorporating equivariant patch embedding enhances data efficiency and robustness, suggesting that equivariant transformers could potentially serve as more generalizable backbones for the application of ViT in histopathology such as digital pathology foundation models.",311.81,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09136v1_SkinFlow Efficient Information Transmission for Op.pdf,SkinFlow: Efficient Information Transmission for Open Dermatological Diagnosis via Dynamic Visual Encoding and Staged RL,"['Lijun Liu', 'Linwei Chen', 'Zhishou Zhang', 'Meng Tian', 'Hengfu Cui', 'Ruiyang Li', 'Zhaocheng Liu', 'Qiang Ju', 'Qianxi Li', 'Hong-Yu Zhou']","This paper challenges the assumption that parameter scaling is the only path to medical precision in dermatology. It introduces SkinFlow, a framework that treats diagnosis as an optimization of visual information transmission efficiency. Utilizing a Virtual-Width Dynamic Vision Encoder (DVE) and a two-stage Reinforcement Learning strategy, SkinFlow sequentially aligns explicit medical descriptions and reconstructs implicit diagnostic textures within a constrained semantic space. The authors propose a clinically grounded evaluation protocol prioritizing diagnostic safety and hierarchical relevance over rigid label matching. Empirical results demonstrate that the 7B model of SkinFlow achieves significant gains in Top-1 and Top-6 accuracy compared to general-purpose models, showcasing the superiority of optimizing geometric capacity and information flow over raw parameter scaling.",313.61,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09147v2_SSVP Synergistic Semantic-Visual Prompting for Ind.pdf,SSVP: Synergistic Semantic-Visual Prompting for Industrial Zero-Shot Anomaly Detection,"['Chenhao Fu', 'Han Fang', 'Xiuzheng Zheng', 'Wenbo Wei', 'Yonghua Li', 'Hao Sun', 'Xuelong Li']","Zero-Shot Anomaly Detection (ZSAD) leverages Vision-Language Models (VLMs) to enable supervision-free industrial inspection. However, existing ZSAD paradigms are constrained by single visual backbones, which struggle to balance global semantic generalization with fine-grained structural discriminability. To bridge this gap, Synergistic Semantic-Visual Prompting (SSVP) introduces the Hierarchical Semantic-Visual Synergy (HSVS) mechanism, which deeply integrates DINOv3’s multi-scale structural priors into the CLIP semantic space. Subsequently, the Vision-Conditioned Prompt Generator (VCPG) employs cross-modal attention to guide dynamic prompt generation, enabling linguistic queries to precisely anchor to specific anomaly patterns. Furthermore, the Visual-Text Anomaly Mapper (VTAM) establishes a dual-gated calibration paradigm to address the discrepancy between global scoring and local evidence. Extensive evaluations on seven industrial benchmarks validate the robustness of our method, achieving state-of-the-art performance with 93.0% Image-AUROC and 92.2% Pixel-AUROC on MVTec-AD, significantly outperforming existing zero-shot approaches.",313.33,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09152v1_PrivacyReasoner Can LLM Emulate a Human-like Priva.pdf,PrivacyReasoner: Can LLM Emulate a Human-like Privacy Mind?,"['Yiwen Tu', 'Xuan Liu', 'Lianhui Qin', 'Haojian Jin']","This paper introduces PrivacyReasoner, an AI-agent designed to simulate how individual users form privacy concerns in response to real-world news. Unlike traditional population-level sentiment analysis, PrivacyReasoner integrates privacy and cognitive theories to model user-specific privacy reasoning based on personal comment histories and contextual cues. The agent reconstructs each user's ",302.29,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09156v1_KTCF Actionable Recourse in Knowledge Tracing via .pdf,KTCF: Actionable Recourse in Knowledge Tracing via Counterfactual Explanations for Education,"['Woojin Kim', 'Changkwon Lee', 'Hyeoncheol Kim']","This paper proposes KTCF, a counterfactual explanation generation method for Knowledge Tracing (KT) that accounts for knowledge concept relationships and converts counterfactual explanations into educational instructions. The method is evaluated on a large-scale educational dataset and shown to achieve superior and robust performance over existing methods, with improvements ranging from 5.7% to 34% across metrics. The authors also provide a qualitative evaluation of their post-processing scheme, demonstrating that the resulting educational instructions help in reducing large study burden. The paper highlights the potential of counterfactuals to advance the responsible and practical use of AI in education and suggests future works on XAI for KT that should be grounded in education and stakeholder-centered methods.",314.33,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09182v1_Position on LLM-Assisted Peer Review Addressing Re.pdf,Position on LLM-Assisted Peer Review: Addressing Reviewer Gap through Mentoring and Feedback,"['JungMin Yun', 'JuneHyoung Kwon', 'MiHyeon Kim', 'YoungBin Kim']","The rapid expansion of AI research has intensified the Reviewer Gap, threatening the peer-review sustainability and perpetuating a cycle of low-quality evaluations. This position paper critiques existing LLM approaches that automatically generate reviews and argues for a paradigm shift that positions LLMs as tools for assisting and educating human reviewers. The paper defines the core principles of high-quality peer review and proposes two complementary systems: an LLM-assisted mentoring system to cultivate reviewers' long-term competencies and an LLM-assisted feedback system to help reviewers refine the quality of their reviews. This human-centered approach aims to strengthen reviewer expertise and contribute to building a more sustainable scholarly ecosystem.",314.21,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09195v1_ProFit Leveraging High-Value Signals in SFT via Pr.pdf,ProFit: Leveraging High-Value Signals in SFT via Probability-Guided Token Selection,"['Tao Liu', 'Taiqiang Wu', 'Runming Yang', 'Shaoning Sun', 'Junjie Wang', 'Yujiu Yang']","ProFit addresses the limitations of traditional Supervised Fine-Tuning (SFT) by selectively masking low-probability tokens, thereby preventing surface-level overfitting. It leverages the intrinsic connection between token probability and semantic importance, focusing on high-probability tokens that carry core logical frameworks. Extensive experiments demonstrate that ProFit consistently outperforms traditional SFT baselines on general reasoning and mathematical benchmarks. The proposed approach aims to mitigate single-reference overfitting while maintaining efficiency, addressing the dual challenges of expensive data construction and training convergence.",313.69,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09208v2_Mikasa A Character-Driven Emotional AI Companion I.pdf,Mikasa: A Character-Driven Emotional AI Companion Inspired by Japanese Oshi Culture,['Miki Ueno'],"Recent progress in AI companions has led to systems that can have fluent and emotionally expressive conversations. However, many of these systems struggle with long-term user satisfaction. This paper argues that the problems are not primarily due to weak models but to poor character design and unclear user-AI relationship definitions. Mikasa, inspired by Japanese Oshi culture, is presented as a case study of character-driven companion design. Mikasa is designed as a coherent character with a stable personality and a clearly defined relationship as a partner, not as a general-purpose assistant or a chatbot that changes roles. Through exploratory evaluations, users value relationship control and imaginative engagement, suggesting that character coherence and relationship definition shape interaction quality. The contribution is to show that character design is a functional part of AI companion systems, not just decoration. Mikasa is one example based on a specific cultural context, but the design principles—commitment to a consistent personality and clear relationship definition—can be applied to many emotionally grounded AI companions.",315.32,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09212v1_Annealed Relaxation of Speculative Decoding for Fa.pdf,Annealed Relaxation of Speculative Decoding for Faster Autoregressive Image Generation,"['Xingyao Li', 'Fengzhuo Zhang', 'Cunxiao Du']","Despite significant progress in auto-regressive image generation, inference remains slow due to the sequential nature of AR models and the ambiguity of image tokens, even when using speculative decoding. Recent works attempt to address this with relaxed speculative decoding but lack theoretical grounding. In this paper, we establish the theoretical basis of relaxed speculative decoding and propose COOL-SD, an annealed relaxation of speculative decoding built on two key insights. The first analyzes the total variation (TV) distance between the target model and relaxed speculative decoding and yields an optimal resampling distribution that minimizes an upper bound of the distance. The second uses perturbation analysis to reveal an annealing behavior in relaxed speculative decoding, motivating our annealed design. Together, these insights enable COOL-SD to generate images faster with comparable quality, or achieve better quality at similar latency. Experiments validate the effectiveness of COOL-SD, showing consistent improvements over prior methods in speed-quality trade-offs.",313.46,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09213v1_SpikeVAEDiff Neural Spike-based Natural Visual Sce.pdf,SpikeVAEDiff: Neural Spike-based Natural Visual Scene Reconstruction via VD-V AE and Versatile Diffusion,"['Jialu Li', 'Taiyan Zhou']","This paper presents SpikeVAEDiff, a novel two-stage framework that combines a Very Deep Variational Autoencoder (VDVAE) and the Versatile Diffusion model to generate high-resolution and semantically meaningful image reconstructions from neural spike data. The first stage uses VDVAE to produce low-resolution preliminary reconstructions, while the second stage maps neural spike signals to CLIP-Vision and CLIP-Text features to enable Versatile Diffusion for image refinement. The authors test their method on the Allen Visual Coding—Neuropixels dataset and find that the VISI region exhibits the most prominent activation, making it a key region for subsequent analysis. The study highlights the potential of spike data for visual reconstruction and the importance of considering different visual brain areas for improved neural decoding.",314.09,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09233v1_GIFT Unlocking Global Optimality in Post-Training .pdf,GIFT: Unlocking Global Optimality in Post-Training via Finite-Temperature Gibbs Initialization,"['Zhengyang Zhao', 'Lu Ma', 'Yizhen Jiang', 'Xiaochen Ma', 'Chengyu Shen', 'Lexiang Tang', 'Haoze Sun', 'Peng Pei', 'Wentao Zhang']","The prevailing post-training paradigm for Large Reasoning Models (LRMs) suffers from an intrinsic optimization mismatch. This paper reformulates Supervised Fine-Tuning (SFT) within a unified post-training framework and proposes Gibbs Initialization with Finite Temperature (GIFT). GIFT incorporates supervision as a finite-temperature energy potential, ensuring objective consistency throughout the post-training pipeline. Experiments demonstrate that GIFT significantly outperforms standard SFT and other competitive baselines when utilized for RL initialization, providing a mathematically principled pathway toward achieving global optimality in post-training.",310.46,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09236v2_Reward Learning through Ranking Mean Squared Error.pdf,Reward Learning Through Ranking Mean Squared Error,"['Chaitanya Kharyal', 'Calarina Muslimani', 'Matthew E. Taylor']","Reward design remains a significant bottleneck in applying reinforcement learning to real-world problems. A popular alternative is reward learning, where reward functions are inferred from human feedback rather than manually specified. Recent work has proposed learning reward functions from human feedback in the form of ratings, rather than traditional binary preferences, enabling richer and potentially less cognitively demanding supervision. Building on this paradigm, we introduce a new rating-based RL method, Ranked Return Regression for RL (R4). At its core, R4 employs a novel ranking mean squared error (rMSE) loss, which treats teacher-provided ratings as ordinal targets. Our approach learns from a dataset of trajectory-rating pairs, where each trajectory is labeled with a discrete rating (e.g., “bad,” “neutral,” “good”). At each training step, we sample a set of trajectories, predict their returns, and rank them using a differentiable sorting operator (soft ranks). We then optimize a mean squared error loss between the resulting soft ranks and the teacher’s ratings. Unlike prior rating-based approaches, R4 offers formal guarantees: its solution set is provably minimal and complete under mild assumptions. Empirically, using simulated human feedback, we demonstrate that R4 consistently matches or outperforms existing rating and preference-based RL methods on robotic locomotion benchmarks from OpenAI Gym and the Deep-Mind Control Suite, while requiring significantly less feedback.",313.04,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09239v2_DSA-Tokenizer Disentangled Semantic-Acoustic Token.pdf,DSA-Tokenizer: Disentangled Semantic-Acoustic Tokenization via Flow Matching-based Hierarchical Fusion,"['Hanlin ZHANG', 'Daxin Tan', 'Dehua Tao', 'Xiao Chen', 'Haochen Tan', 'Yunhe Li', 'Yuchen Cao', 'Jianping Wang', 'Linqi Song']","Speech tokenizers are crucial for discrete Speech Large Language Models (Speech LLMs). Existing tokenizers either prioritize semantic encoding, fuse semantic content with acoustic style inseparably, or achieve incomplete semantic-acoustic disentanglement. To improve disentanglement, DSA-Tokenizer explicitly separates speech into discrete semantic and acoustic tokens via distinct optimization constraints. Semantic tokens are supervised by ASR for linguistic content, while acoustic tokens focus on mel-spectrogram restoration for style encoding. A hierarchical Flow-Matching decoder eliminates rigid length constraints and improves speech generation quality. Joint reconstruction-recombination training enforces this separation. DSA-Tokenizer enables high-fidelity reconstruction and flexible recombination through robust disentanglement, facilitating controllable generation in Speech LLMs. The paper highlights disentangled tokenization as a pivotal paradigm for future speech modeling.",313.68,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09248v1_Hybrid guided variational autoencoder for visual p.pdf,Hybrid guided variational autoencoder for visual place recognition,"['Ni Wang', 'Zihan You', 'Emre Neftci', 'Thorben Schoepe']","This work overcomes the limitations of state-of-the-art visual place recognition models for robotics by combining event-based vision sensors with an event-based novel guided variational autoencoder (VAE). The encoder part of the model is based on a spiking neural network compatible with neuromorphic hardware. The VAE successfully disentangles the visual features of 16 distinct places in a new indoor dataset, achieving comparable classification performance to other state-of-the-art approaches and robust performance under various illumination conditions. The model can distinguish between these places when tested with novel visual inputs, demonstrating high generalization capability. This compact and robust guided VAE poses a promising model for visual place recognition that can significantly enhance mobile robot navigation in known and unknown indoor environments.",316.38,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09251v1_HGATSolver A Heterogeneous Graph Attention Solver .pdf,HGA TSolver: A Heterogeneous Graph Attention Solver for Fluid–Structure Interaction,"['Qin-Yi Zhang', 'Hong Wang', 'Siyao Liu', 'Haichuan Lin', 'Linying Cao', 'Xiao-Hu Zhou', 'Chen Chen', 'Shuangyi Wang', 'Zeng-Guang Hou']","This paper proposes the Heterogeneous Graph Attention Solver (HGATSolver) to address the challenges of learning-based solvers in capturing the heterogeneous dynamics of Fluid–Structure Interaction (FSI) systems. HGATSolver encodes the system as a heterogeneous graph, embedding physical structure directly into the model via distinct node and edge types for fluid, solid, and interface regions. This enables specialized message-passing mechanisms tailored to each physical domain. To stabilize explicit time stepping, HGATSolver introduces a novel physics-conditioned gating mechanism as a learnable, adaptive relaxation factor. Additionally, an Interdomain Gradient-Balancing Loss dynamically balances the optimization objectives across domains based on predictive uncertainty. Extensive experiments on two constructed FSI benchmarks and a public dataset demonstrate that HGAT-Solver achieves state-of-the-art performance, establishing an effective framework for surrogate modeling of coupled multi-physics systems.",313.86,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09253v1_RIFT Repurposing Negative Samples via Reward-Infor.pdf,RIFT: Repurposing Negative Samples via Reward-Informed Fine-Tuning,"['Zehua Liu', 'Shuqi Liu†', 'Tao Zhong', 'Mingxuan Yuan']","While Supervised Fine-Tuning (SFT) and Rejection Sampling Fine-Tuning (RFT) are standard approaches for LLM alignment, they either rely on costly expert data or discard valuable negative samples, leading to data inefficiency. To address this, the authors propose Reward Informed Fine-Tuning (RIFT), a simple yet effective framework that utilizes all self-generated samples. Unlike RFT, which uses a hard threshold, RIFT repurposes negative trajectories, reweighting the loss with scalar rewards to learn from both positive and negative trajectories. To overcome training collapse caused by naive reward integration, RIFT introduces a stabilized loss formulation. Extensive experiments on mathematical benchmarks across various base models show that RIFT consistently outperforms RFT, demonstrating robust and data-efficient alignment using mixed-quality, self-generated data.",312.84,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09259v1_MAXS Meta-Adaptive Exploration with LLM Agents.pdf,Meta-Adaptive Exploration with LLM Agents,"['Jian Zhang', 'Zhiyuan Wang', 'Zhangqi Wang', 'Yu He*', 'Haoran Luo', 'Li Yuan', 'Lingling Zhang', 'Rui Mao', 'Qika Lin*', 'Jun Liu']","Large Language Model (LLM) Agents exhibit inherent reasoning abilities through the collaboration of multiple tools. However, during agent inference, existing methods often suffer from locally myopic generation and trajectory instability. To address these issues, we propose MAXS, a meta-adaptive reasoning framework based on LLM Agents that flexibly integrates tool execution and reasoning planning. MAXS employs a lookahead strategy to extend reasoning paths a few steps ahead, estimating the advantage value of tool usage, and combines step consistency variance and inter-step trend slopes to jointly select stable, consistent, and high-value reasoning steps. Additionally, we introduce a trajectory convergence mechanism that controls computational cost by halting further rollouts once path consistency is achieved, enabling a balance between resource efficiency and global effectiveness in multi-tool reasoning. Extensive empirical studies across three base models and five datasets demonstrate that MAXS consistently outperforms existing methods in both performance and inference efficiency. Further analysis confirms the effectiveness of our lookahead strategy and tool usage.",312.56,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09260v1_Efficient Paths and Dense Rewards Probabilistic Fl.pdf,Efficient Paths and Dense Rewards: Probabilistic Flow Reasoning for Large Language Models,"['Yan Liu', 'Feng Zhang', 'Zhanyu Ma', 'Jun Xu', 'Jiuchong Gao', 'Jinghua Hao', 'Renqing He', 'Han Liu', 'Yangdong Deng']","High-quality chain-of-thought has demonstrated strong potential for unlocking the reasoning capabilities of large language models. However, current paradigms typically treat the reasoning process as an indivisible sequence, lacking an intrinsic mechanism to quantify stepwise information gain. This granularity gap manifests in two limitations: inference inefficiency from redundant exploration without explicit guidance, and optimization difficulty due to sparse outcome supervision or costly external verifiers. In this work, the authors propose CoT-Flow, a framework that reconceptualizes discrete reasoning steps as a continuous probabilistic flow, quantifying the contribution of each step toward the ground-truth answer. Built on this formulation, CoT-Flow enables two complementary methodologies: flow-guided decoding, which employs a greedy flow-based decoding strategy to extract information-efficient reasoning paths, and flow-based reinforcement learning, which constructs a verifier-free dense reward function. Experiments on challenging benchmarks demonstrate that CoT-Flow achieves a superior balance between inference efficiency and reasoning performance.",313.13,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09262v1_Magnifying change Rapid burn scar mapping with mul.pdf,"Magnifying change: Rapid burn scar mapping with multi-resolution, multi-source satellite imagery","['Maria Sdraka', 'Dimitrios Michail', 'Ioannis Papoutsis']","Delineating wildfire affected areas using satellite imagery remains challenging due to irregular and spatially heterogeneous spectral changes across the electromagnetic spectrum. While recent deep learning approaches achieve high accuracy when high-resolution multispectral data are available, their applicability in operational settings, where a quick delineation of the burn scar shortly after a wildfire incident is required, is limited by the trade-off between spatial resolution and temporal revisit frequency of current satellite systems. To address this limitation, we propose a novel deep learning model, namely BAM-MRCD, which employs multi-resolution, multi-source satellite imagery (MODIS and Sentinel-2) for the timely production of detailed burnt area maps with high spatial and temporal resolution. Our model manages to detect even small scale wildfires with high accuracy, surpassing similar change detection models as well as solid baselines. All data and code are available in the GitHub repository: https://github.com/Orion-AI-Lab/BAM-MRCD.",315.04,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09264v1_Coordinated Pandemic Control with Large Language M.pdf,Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants,"['Ziyi Shi', 'Xusen Guo', 'Hongliang Lu', 'Mingxing Peng', 'Haotian Wang', 'Zheng Zhu', 'Zhenning Li', 'Yuxuan Liang', 'Xinhu Zheng', 'Hai Yang']","Effective pandemic control requires timely and coordinated policymaking across administrative regions that are intrinsically interdependent. However, human-driven responses are often fragmented and reactive, with policies formulated in isolation and adjusted only after outbreaks escalate, undermining proactive intervention and global pandemic mitigation. To address this challenge, the authors propose a large language model (LLM) multi-agent policymaking framework that supports coordinated and proactive pandemic control across regions. Each administrative region is assigned an LLM agent as an AI policymaking assistant. The agent reasons over region-specific epidemiological dynamics while communicating with other agents to account for cross-regional interdependencies. By integrating real-world data, a pandemic evolution simulator, and structured inter-agent communication, the framework enables agents to jointly explore counterfactual intervention scenarios and synthesize coordinated policy decisions through a closed-loop simulation process. The proposed framework is validated using state-level COVID-19 data from the United States between April and December 2020, together with real-world mobility records and observed policy interventions. Compared with real-world pandemic outcomes, the approach reduces cumulative infections and deaths by up to 63.7% and 40.1%, respectively, at the individual state level, and by 39.0% and 27.0%, respectively, when aggregated across states. These results demonstrate that LLM multi-agent systems can enable more effective pandemic control with coordinated policymaking. More broadly, this study presents a generalizable framework for operationalizing LLM agents in large-scale public policy settings, offering a promising decision-support paradigm for future pandemics and other complex societal challenges characterized by strong regional interdependence.",313.94,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09269v2_RISER Orchestrating Latent Reasoning Skills for Ad.pdf,Orchestrating Latent Reasoning Skills for Adaptive Activation Steering,"['Wencheng Ye', 'Xiaoyang Yuan', 'Yi Bin', 'Hengyu Jin', 'Liang Peng', 'Pengpeng Zeng', 'Heng Tao Shen']","Recent work on domain-specific reasoning with large language models often relies on training-intensive approaches that require parameter updates. While activation steering has emerged as a parameter-efficient alternative, existing methods apply static, manual interventions that fail to adapt to the dynamic nature of complex reasoning. To address this limitation, the authors propose RISER (Router-based Intervention for Steerable Enhancement of Reasoning), a plug-and-play intervention framework that adaptively steers LLM reasoning in activation space. RISER constructs a library of reusable reasoning vectors and employs a lightweight Router to dynamically compose them for each input. The Router is optimized via reinforcement learning under task-level rewards, activating latent cognitive primitives in an emergent and compositional manner. Across seven diverse benchmarks, RISER yields 3.4–6.5% average zero-shot accuracy improvements over the base model while surpassing CoT-style reasoning with 2–3× higher token efficiency and robust accuracy gains. Further analysis shows that RISER autonomously combines multiple vectors into interpretable, precise control strategies, pointing toward more controlled and efficient LLM reasoning. Code can be found in: RISER.",312.23,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09274v1_A3-Bench Benchmarking Memory-Driven Scientific Rea.pdf,A3-Bench: Benchmarking Memory-Driven Scientific Reasoning via Anchor and Attractor Activation,"['Jian Zhang', 'Yu He', 'Zhiyuan Wang', 'Zhangqi Wang', 'Kai He', 'Fangzhi Xu', 'Qika Lin', 'Jun Liu']","Scientific reasoning tasks, including those in math, physics, and chemistry, require not only logical inference but also the activation of prior knowledge and experiential structures. Memory can efficiently reuse knowledge and enhance reasoning consistency and stability. However, existing benchmarks mainly evaluate final answers or step-by-step coherence, overlooking the memory-driven mechanisms that underlie human reasoning, which involves activating anchors and attractors, then integrating them into multi-step inference. To address this gap, A3-Bench proposes a benchmark to evaluate scientific reasoning through dual-scale memory-driven activation, grounded in Anchor and Attractor Activation. The authors annotate 2,198 science reasoning problems across domains using the SAPM process (subject, anchor & attractor, problem, and memory developing). They introduce a dual-scale memory evaluation framework utilizing anchors and attractors, along with the AAUI (Anchor-Attractor Utilization Index) metric to measure memory activation rates. Through experiments with various base models and paradigms, they validate A3-Bench and analyze how memory activation impacts reasoning performance, providing insights into memory-driven scientific reasoning.",312.34,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09278v1_M3Searcher Modular Multimodal Information Seeking .pdf,M3Searcher: Modular Multimodal Information Seeking Agency with Retrieval-Oriented Reasoning,"['Xiaohan Yu', 'Chao Feng', 'Lang Mei', 'Chong Chen']","Recent advances in DeepResearch-style agents have demonstrated strong capabilities in autonomous information acquisition and synthesis from real-world web environments. However, existing approaches remain limited to text modality. M3Searcher, a modular multimodal information-seeking agent, explicitly decouples information acquisition from answer derivation and is optimized with a retrieval-oriented multi-objective reward that encourages factual accuracy, reasoning soundness, and retrieval fidelity. Additionally, MM-SearchVQA is developed as a multimodal multi-hop dataset to support retrieval-centric RL training. Experimental results show that M3Searcher outperforms existing approaches, exhibits strong transfer adaptability, and effective reasoning in complex multimodal tasks.",313.77,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09280v1_ReGraM Region-First Knowledge Graph Reasoning for .pdf,ReGraM: Region-First Knowledge Graph Reasoning for Medical Question Answering,"['Chaerin Lee', 'Sohee Park', 'Hyunsik Na', 'Daseon Choi']","Recent studies in medical question answering have actively explored the integration of large language models with biomedical knowledge graphs to improve factual accuracy. However, most existing approaches still rely on traversing the entire KG or performing large-scale retrieval, which introduces substantial noise and leads to unstable multi-hop reasoning. ReGraM is a region-first knowledge graph reasoning framework that addresses this challenge by constructing a query-aligned subgraph and performing stepwise reasoning constrained to this localized region under multiple evidence-aware modes. By focusing inference on only the most relevant portion of the KG, ReGraM departs from the assumption that all relations are equally useful—an assumption that rarely holds in domain-specific medical settings. Experiments on seven medical QA benchmarks demonstrate that ReGraM consistently outperforms a strong baseline (KGARevion), achieving an 8.04% absolute accuracy gain on MCQ, a 4.50% gain on SAQ, and a 42.9% reduction in hallucination rate. Ablation and qualitative analyses further show that aligning region construction with hop-wise reasoning is the primary driver of these improvements. Overall, our results highlight region-first KG reasoning as an effective paradigm for improving factual accuracy and consistency in medical QA.",311.92,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09281v1_STaR Sensitive Trajectory Regulation for Unlearnin.pdf,STaR: Sensitive Trajectory Regulation for Unlearning in Large Reasoning Models,"['Jingjing Zhou', 'Gaoxiang Cong', 'Li Su', 'Liang Li']","Large Reasoning Models (LRMs) have advanced automated multi-step reasoning but introduce severe privacy risks due to sensitive information embedded in the reasoning process. Existing unlearning approaches for Large Language Models (LLMs) are insufficient for LRMs, as they fail to remove sensitive content from intermediate steps. To address these challenges, the authors propose Sensitive Trajectory Regulation (STaR), a parameter-free, inference-time unlearning framework that achieves robust privacy protection throughout the reasoning process. STaR identifies sensitive content via semantic-aware detection, injects global safety constraints through secure prompt prefix, performs trajectory-aware suppression to dynamically block sensitive content, and applies token-level adaptive filtering to prevent both exact and paraphrased sensitive tokens. The authors introduce two metrics, Multi-Decoding Consistency Assessment (MCS) and Multi-Granularity Membership Inference Attack (MIA), to evaluate privacy protection. Experiments on the R-TOFU benchmark demonstrate that STaR achieves comprehensive and stable unlearning with minimal utility loss, setting a new standard for privacy-preserving reasoning in LRMs.",313.59,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09282v1_Cluster Workload Allocation Semantic Soft Affinity.pdf,Cluster Workload Allocation: Semantic Soft Affinity Using Natural Language Processing,"['Leszek Sliwko1', 'Jolanta Mizeria-Pietraszko2']","This paper introduces a semantic, intent-driven scheduling paradigm for cluster systems using Natural Language Processing. The system employs a Large Language Model (LLM) integrated via a Kubernetes scheduler extender to interpret natural language allocation hint annotations for soft affinity preferences. A prototype featuring a cluster state cache and an intent analyzer (using AWS Bedrock) was developed. Empirical evaluation demonstrated high LLM parsing accuracy (>95% Subset Accuracy on an evaluation ground-truth dataset) for top-tier models like Amazon Nova Pro/Premier and Mistral Pixtral Large, significantly outperforming a baseline engine. Scheduling quality tests across six scenarios showed the prototype achieved superior or equivalent placement compared to standard Kubernetes configurations, particularly excelling in complex and quantitative scenarios and handling conflicting soft preferences. The results validate using LLMs for accessible scheduling but highlight limitations like synchronous LLM latency, suggesting asynchronous processing for production readiness. This work confirms the viability of semantic soft affinity for simplifying workload orchestration.",315.45,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09286v1_Why not Collaborative Filtering in Dual View Bridg.pdf,Why not Collaborative Filtering in Dual View? Bridging Sparse and Dense Models,"['HANZE GUO', 'JIANXUN LIAN', 'XIAO ZHOU∗†‡']","Collaborative Filtering (CF) remains the cornerstone of modern recommender systems, with dense embedding–based methods dominating current practice. However, these approaches suffer from a critical limitation: our theoretical analysis reveals a fundamental signal-to-noise ratio (SNR) ceiling when modeling unpopular items, where parameter-based dense models experience diminishing SNR under severe data sparsity. To overcome this bottleneck, we propose SaD (Sparse and Dense), a unified framework that integrates the semantic expressiveness of dense embeddings with the structural reliability of sparse interaction patterns. We theoretically show that aligning these dual views yields a strictly superior global SNR. Concretely, SaD introduces a lightweight bidirectional alignment mechanism: the dense view enriches the sparse view by injecting semantic correlations, while the sparse view regularizes the dense model through explicit structural signals. Extensive experiments demonstrate that, under this dual-view alignment, even a simple matrix factorization–style dense model can achieve state-of-the-art performance. Moreover, SaD is plug-and-play and can be seamlessly applied to a wide range of existing recommender models, highlighting the enduring power of collaborative filtering when leveraged from dual perspectives. Further evaluations on real-world benchmarks show that SaD consistently outperforms strong baselines, ranking first on the BarsMatch leaderboard.1 The code is publicly available at https://github.com/harris26-G/SaD.",313.07,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09292v1_Blue Teaming Function-Calling Agents.pdf,Blue Teaming Function-Calling Agents,"['Greta Dolcetti', 'Giulio Zizzo', 'Sergio Maffeis']","This paper presents an experimental evaluation of four open source LLMs with function-calling capabilities against three different attacks and measures the effectiveness of eight different defences. The results show that these models are not safe by default, and the defenses are not yet employable in real-world scenarios. The authors identify unique attack vectors and introduce new related defenses, providing insights for designing more secure and trustworthy agentic systems.",309.75,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09293v1_Policy-Based Reinforcement Learning with Action Ma.pdf,Policy-Based Reinforcement Learning with Action Masking for Dynamic Job Shop Scheduling under Uncertainty: Handling Random Arrivals and Machine Failures,"['Sofiene Lassoued', 'Stefan Lier', 'Andreas Schwung']","We present a novel framework for solving Dynamic Job Shop Scheduling Problems under uncertainty, addressing the challenges introduced by stochastic job arrivals and unexpected machine breakdowns. Our approach follows a model-based paradigm, using Coloured Timed Petri Nets to represent the scheduling environment, and Maskable Proximal Policy Optimization to enable dynamic decision-making while restricting the agent to feasible actions at each decision point. To simulate realistic industrial conditions, dynamic job arrivals are modeled using a Gamma distribution, capturing complex temporal patterns such as bursts, clustering, and fluctuating workloads. Machine failures are modeled using a Weibull distribution to represent age-dependent degradation and wear-out dynamics. These stochastic models enable the framework to reflect real-world manufacturing scenarios better. In addition, we study two action-masking strategies: a non-gradient approach that overrides the probabilities of invalid actions, and a gradient-based approach that assigns negative gradients to invalid actions within the policy network. We conduct extensive experiments on dynamic JSSP benchmarks, demonstrating that our method consistently outperforms traditional heuristic and rule-based approaches in terms of makespan minimization. The results highlight the strength of combining interpretable Petri-net-based models with adaptive reinforcement learning policies, yielding a resilient, scalable, and explainable framework for real-time scheduling in dynamic and uncertain manufacturing environments.",314.14,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09306v1_On-Device Large Language Models for Sequential Rec.pdf,On-Device Large Language Models for Sequential Recommendation,"['Xin Xia', 'Hongzhi Yin', 'Shane Culpepper']","On-device recommendation is critical for real-world applications, especially in scenarios with strict latency, privacy, and connectivity constraints. While large language models (LLMs) can provide exceptional user behavior modeling, their substantial memory footprint and computational overhead make deployment on resource-constrained devices risky. This paper introduces OD-LLM, a task-adaptive compression framework that integrates low-rank structural compression and a novel tokenization normalization technique to efficiently deploy LLMs on devices. Empirical evaluations show that OD-LLM maintains effectiveness when deployed on half the original model size, demonstrating its efficacy and scalability for real-time, on-device solutions.",313.46,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09313v1_Understanding or Memorizing A Case Study of German.pdf,Understanding or Memorizing? A Case Study of German Definite Articles in Language Models,"['Jonathan Drechsel', 'Erisa Bytyqi', 'Steffen Herbold']","Language models perform well on grammatical agreement, but it is unclear whether this reflects rule-based generalization or memorization. This study investigates this question for German definite singular articles, whose forms depend on gender and case. Using GRADIEND, a gradient-based interpretability method, the authors learn parameter update directions for gender-case specific article transitions. They find that updates learned for a specific gender-case article transition frequently affect unrelated gender-case settings, with substantial overlap among the most affected neurons across settings. These results argue against a strictly rule-based encoding of German definite articles, indicating that models at least partly rely on memorized associations rather than abstract grammatical rules.",309.8,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09342v1_Improving Implicit Hate Speech Detection via a Com.pdf,Improving Implicit Hate Speech Detection via a Community-Driven Multi-Agent Framework,"['Ewelina Gajewska', 'Katarzyna Budzynska', 'Jarosław A. Chudziak']","This work proposes a contextualised detection framework for implicitly hateful speech, implemented as a multi-agent system comprising a central Moderator Agent and dynamically constructed Community Agents representing specific demographic groups. Our approach explicitly integrates socio-cultural context from publicly available knowledge sources, enabling identity-aware moderation that surpasses state-of-the-art prompting methods. We enhance the technical rigour of performance evaluation by incorporating balanced accuracy as a central metric of classification fairness. We demonstrate that our community-driven consultative framework significantly improves both classification accuracy and fairness across all target groups.",309.83,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09351v1_Navigating Ethical AI Challenges in the Industrial.pdf,Navigating Ethical AI Challenges in the Industrial Sector: Balancing Innovation and Responsibility,"['Ruomu Tan', 'Martin W Hoffmann']","The integration of artificial intelligence (AI) into the industrial sector has driven innovation but also expanded the ethical landscape, necessitating a reevaluation of principles governing technology and its applications. This chapter explores how AI-empowered industrial innovation intersects with ethics, examining ethical aspects of AI in industrial use cases and the importance of embedding ethical principles into industrial AI systems.",311.53,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09353v1_Monte-Carlo Tree Search with Neural Network Guidan.pdf,Monte-Carlo Tree Search with Neural Network Guidance for Lane-Free Autonomous Driving,"['Ioannis Peridis', 'Dimitrios Troullinos', 'Georgios Chalkiadakis', 'Pantelis Giankoulidis', 'Ioannis Papamichail', 'Markos Papageorgiou']","Lane-free traffic environments allow vehicles to better harness the lateral capacity of the road without being restricted to lane-keeping, thereby increasing the traffic flow rates. This work considers a Monte-Carlo Tree Search (MCTS) planning approach for single-agent autonomous driving in lane-free traffic, where the associated Markov Decision Process is influenced from existing reinforcement learning frameworks. MCTS is equipped with a pre-trained neural network (NN) that guides the selection phase, incorporating the predictive capabilities of NNs for a more informed tree search process under computational constraints. The experimental evaluation addresses both safety (through collision rates) and efficacy (through measured speed), examining the influence of isotropic state information, the acceleration of performance for the NN-guided variant of MCTS, and the trade-off between computational resources and solution quality.",311.16,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09361v1_GeoRA Geometry-Aware Low-Rank Adaptation for RLVR.pdf,GeoRA: Geometry-Aware Low-Rank Adaptation for RLVR,"['Jiaying Zhang', 'Lei Shi', 'Jiguo Li', 'Jun Xu', 'Jiuchong Gao', 'Jinghua Hao', 'Renqing He']","Reinforcement Learning with Verifiable Rewards (RLVR) is crucial for large-scale reasoning models. However, existing parameter-efficient methods like PiSSA and MiLoRA are designed for Supervised Fine-Tuning (SFT) and do not account for the distinct optimization dynamics and geometric structures of RLVR. Applying these methods directly leads to spectral collapse and optimization instability, severely limiting model performance. GeoRA (Geometry-Aware Low-Rank Adaptation) exploits the anisotropic and compressible nature of RL update subspaces. It initializes adapters by extracting principal directions via Singular Value Decomposition (SVD) within a geometrically constrained subspace while freezing the residual components. This method preserves the pre-trained geometric structure and enables efficient GPU computation through dense operators. Experiments on Qwen and Llama demonstrate that GeoRA mitigates optimization bottlenecks caused by geometric misalignment, consistently outperforming established low-rank baselines on key mathematical benchmarks, achieving state-of-the-art (SOTA) results. Moreover, GeoRA shows superior generalization and resilience to catastrophic forgetting in out-of-domain tasks.",313.88,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09365v1_Frame of Reference Addressing the Challenges of Co.pdf,Frame of Reference: Addressing the Challenges of Common Ground Representation in Situational Dialogs,"['Biswesh Mohapatra*', 'Théo Charlot†‡', 'Giovanni Duca†‡', 'Mayank Palan†‡', 'Laurent Romary*', 'Justine Cassell*']","This work evaluates a model's ability to establish common ground by utilizing relational references in dynamic and shared environments of situated dialogs. The authors test multiple methods for representing common ground and propose approaches to improve their performance. The challenge is amplified in dialogs that extend over longer periods, where systems must move beyond context windows and employ memory management techniques to retrieve information from the established common ground. The importance of this ability is particularly pronounced in spoken situational dialogs, such as Embodied Conversational Agents and Social Robots, where the conversations can take place over multiple interactions. The authors address three central research questions: benchmarking, representation, and improvement of common ground establishment.",311.27,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09381v1_Query Languages for Machine-Learning Models.pdf,Query Languages for Machine-Learning Models,"['Martin Grohe', 'envel⌢pe']","In this paper, the author discusses two logics for weighted finite structures: first-order logic with summation (FO(SUM)) and its recursive extension IFP(SUM). These logics originate from foundational work by Grädel, Gurevich, and Meer in the 1990s. In recent joint work with Standke, Steegmans, and Van den Bussche, these logics are investigated as query languages for machine learning models, specifically neural networks, which are naturally represented as weighted graphs. The author presents illustrative examples of queries to neural networks that can be expressed in these logics and discusses fundamental results on their expressiveness and computational complexity.",313.8,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09382v1_Long-term Task-oriented Agent Proactive Long-term .pdf,Long-term Task-oriented Agent: Proactive Long-term Intent Maintenance in Dynamic Environments,"['Qinglong Shi', 'Donghai Wang', 'Hantao Zhou', 'Jiguo Li', 'Jun Xu', 'Jiuchong Gao', 'Jinghua Hao', 'Renqing He']","Current large language model agents predominantly operate under a reactive paradigm, responding only to immediate user queries within short-term sessions. This limitation hinders their ability to maintain long-term user’s intents and dynamically adapt to evolving external environments. In this paper, we propose a novel interaction paradigm for proactive Task-oriented Agents capable of bridging the gap between relatively static user’s needs and a dynamic environment. We formalize proactivity through two key capabilities: Intent-Conditioned Monitoring and Event-Triggered Follow-up. We introduce a high-quality data synthesis pipeline to construct complex, multi-turn dialog data in a dynamic environment. Furthermore, we attempt to address the lack of evaluation criteria for task-oriented interaction in dynamic environments by proposing a new benchmark, ChronosBench. We evaluate some leading close-source and open-source models and reveal their flaws in long-term task-oriented interaction. Our fine-tuned model trained using synthetic data for supervised learning achieves a task completion rate of 85.19% for complex tasks including shifts in user intent, outperforming other models under test. The result validates the effectiveness of our data-driven strategy.",311.5,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09394v2_FairGE Fairness-Aware Graph Encoding in Incomplete.pdf,FairGE: Fairness-Aware Graph Encoding in Incomplete Social Networks,"['Renqiang Luo', 'Jilin University', 'Changchun, China', 'lrenqiang@outlook.com', 'Huafei Huang', 'Adelaide University', 'Adelaide, Australia', 'hhuafei@outlook.com', 'Tao Tang', 'Zhejiang University of Technology', 'Hangzhou, China', 'tao.tang@ieee.org', 'Jing Ren', 'RMIT Universty', 'Melbourne, Australia', 'jing.ren@ieee.org', 'Ziqi Xu∗', 'RMIT University', 'Melbourne, Australia', 'ziqi.xu@rmit.edu.au', 'Mingliang Hou', 'Jinan University & TAL Education', 'Group', 'Guangzhou, China', 'teemohold@outlook.com', 'Enyan Dai', 'HKUST', 'Guangzhou, China', 'enyandai@hkust-gz.edu.cn', 'Feng Xia', 'RMIT University', 'Melbourne, Australia', 'f.xia@ieee.org']","Graph Transformers (GTs) are increasingly applied to social network analysis, yet their deployment is often constrained by fairness concerns, particularly in incomplete social networks where sensitive attributes are frequently missing due to privacy and ethical restrictions. Existing solutions commonly generate these incomplete attributes, which may introduce additional biases and further compromise user privacy. To address this challenge, FairGE (Fair Graph Encoding) is introduced as a fairness-aware framework for GTs in incomplete social networks. Instead of generating sensitive attributes, FairGE encodes fairness directly through spectral graph theory. By leveraging the principal eigenvector to represent structural information and padding incomplete sensitive attributes with zeros to maintain independence, FairGE ensures fairness without data reconstruction. Theoretical analysis demonstrates that the method suppresses the influence of non-principal spectral components, thereby enhancing fairness. Extensive experiments on seven real-world social network datasets confirm that FairGE achieves at least a 16% improvement in both statistical parity and equality of opportunity compared with state-of-the-art baselines.",312.25,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09398v1_Ability Transfer and Recovery via Modularized Para.pdf,Ability Transfer and Recovery via Modularized Parameters Localization,"['Songyao Jin', 'Kun Zhou*', 'Wenqi Li', 'Peng Wang', 'Biwei Huang']","Large language models (LLMs) can be specialized for specific domains, languages, or skills, but this often degrades other abilities and causes catastrophic forgetting. This work investigates how abilities are distributed within LLM parameters by analyzing module activations under domain- and language-specific inputs. It finds that ability-related activations are highly concentrated in a small set of channels (typically <5%), and these channels are largely disentangled. Building on these observations, the authors propose ACT (Activation-Guided Channel-wise Ability Transfer), which localizes ability-relevant channels via activation differences and selectively transfers only the corresponding parameters, followed by lightweight fine-tuning for compatibility. Experiments on multilingual mathematical and scientific reasoning show that ACT can recover forgotten abilities while preserving retained skills, and it can also merge multiple specialized models to integrate several abilities into a single model with minimal interference. The authors will publicly release their code and data.",308.51,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09413v1_Speech-Hands A Self-Reflection Voice Agentic Appro.pdf,Speech-Hands: A Self-Reflection Voice Agentic Approach to Speech Recognition and Audio Reasoning with Omni Perception,"['Zhen Wan', 'Chao-Han Huck Yang', 'Jinchuan Tian', 'Hanrong Ye', 'Ankita Pasad', 'Szu-wei Fu', 'Arushi Goel', 'Ryo Hachiuma', 'Shizhe Diao', 'Kunal Dhawan', 'Sreyan Ghosh', 'Yusuke Hirota', 'Zhehuai Chen', 'Rafael Valle', 'Ehsan Hosseini Asl', 'Chenhui Chu', 'Shinji Watanabe', 'Yu-Chiang Frank Wang', 'Boris Ginsburg']","The paper introduces a voice-agentic framework named Speech-Hands that learns to reflect on its own decisions, addressing the issue of naive fine-tuning on both speech recognition and external sound understanding tasks. The framework recasts the problem as an explicit self-reflection decision, which proves effective in preventing the model from being misled by noisy hypotheses. The authors show that this agentic action mechanism generalizes from speech recognition to complex, multiple-choice audio reasoning tasks, outperforming strong baselines by 12.1% WER on seven benchmarks. The model achieves 77.37% accuracy and high F1 on audio QA decisions, demonstrating robust generalization and reliability across diverse datasets. By unifying perception and decision-making, the work offers a practical path toward more reliable and resilient audio intelligence.",313.75,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09416v1_Radiomics-Integrated Deep Learning with Hierarchic.pdf,RADIOMICS-INTEGRA TED DEEP LEARNING WITH HIERARCHICAL LOSS FOR OSTEOSARCOMA HISTOLOGY CLASSIFICA TION,"['Yaxi Chen', 'Zi Ye', 'Shaheer U. Saeed', 'Oliver Yu', 'Simin Ni', 'Jie Huang', 'Yipeng Hu']","Osteosarcoma (OS) is an aggressive primary bone malignancy that predominantly affects children and adolescents. Accurate histopathological assessment of viable versus non-viable tumor regions after neoadjuvant chemotherapy is critical for prognosis and treatment planning. This work proposes the use of radiomic features as additional input in model training and optimizing two binary classification tasks with hierarchical classes (tumor-vs-non-tumor and viable-vs-non-viable) to improve classification performance and enable a hierarchical loss. The hierarchical loss, with trainable weightings between the two tasks, significantly improves per-class performance. The authors experimentally demonstrate the benefits of each new approach and their combination, setting a new state-of-the-art performance on the TCIA OS Tumor Assessment dataset.",312.18,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09421v2_Bias Dynamics in BabyLMs Towards a Compute-Efficie.pdf,Bias Dynamics in BabyLMs: Towards a Compute-Efficient Sandbox for Democratising Pre-Training Debiasing,"['Filip Trhlik', 'Andrew Caines', 'Paula Buttery']","Pre-trained language models have grown in size and training costs, limiting progress in understanding and mitigating biases. This work seeks to democratize pre-model debiasing research by using low-cost proxy models, specifically BabyLMs. BabyLMs, compact BERT-like models trained on small corpora, display similar bias dynamics to standard BERT models. The authors show that BabyLMs can serve as an effective sandbox for large-scale LMs, reducing pre-training costs from over 500 GPU-hours to under 30 GPU-hours. This provides a way to democratize pre-model debiasing research and enables faster, more accessible exploration of methods for building fairer LMs.",309.87,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09433v1_Do Transformers Understand Ancient Roman Coin Moti.pdf,Automated Analysis of Ancient Coins: Vision Transformer vs. CNNs,"['David Reid', 'Ognjen Arandjelović']","This paper evaluates the performance of Vision Transformer (ViT) and Convolutional Neural Networks (CNNs) in identifying semantic elements on ancient coins. Previous research has shown promise in using CNNs for this task. This paper is the first to apply ViT to ancient coin analysis, using fully automatic learning from multi-modal data. The results indicate that ViT models outperform newly trained CNN models in accuracy.",312.61,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09445v1_Where Knowledge Collides A Mechanistic Study of In.pdf,Where Knowledge Collides: A Mechanistic Study of Intra-Memory Knowledge Conflict in Language Models,"['Minh Vu Pham', 'Hsuvas Borkakoty', 'Yufang Hou']","In language models, intra-memory knowledge conflict arises when inconsistent information about the same event is encoded within the model's parametric knowledge. This work designs a framework based on mechanistic interpretability methods to identify where and how conflicting knowledge from pre-training data is encoded within LMs. The findings contribute to evidence that specific internal components of a language model are responsible for encoding conflicting knowledge from pre-training, and demonstrate how mechanistic interpretability methods can be leveraged to causally intervene in and control conflicting knowledge at inference time.",308.92,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09446v1_Improving Symbolic Translation of Language Models .pdf,Improving Symbolic Translation of Language Models for Logical Reasoning,"['Ramya Keerthy Thatikonda', 'Jiuzhou Han', 'Wray Buntine', 'Ehsan Shareghi']","The use of formal language for deductive logical reasoning aligns well with language models (LMs), where translating natural language (NL) into first-order logic (FOL) and employing an external solver results in a verifiable and therefore reliable reasoning system. However, smaller LMs often struggle with this translation task, frequently producing incorrect symbolic outputs due to formatting and translation errors. Existing approaches typically rely on self-iteration to correct these errors, but such methods depend heavily on the capabilities of the underlying model. To address this, the authors categorize common errors, fine-tune smaller LMs using data synthesized by large language models, introduce incremental inference, and develop a verification module. The evaluation is performed using defined error categories, and the study evaluates three families of models across four logical-reasoning datasets. Comprehensive fine-tuning, incremental inference, and verification modules reduce error rates, increase predicate coverage, and improve reasoning performance for smaller LMs, moving closer to developing reliable and accessible symbolic-reasoning systems.",311.02,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09448v1_Population-Aligned Audio Reproduction With LLM-Bas.pdf,Population-Aligned Audio Reproduction With LLM-Based Equalizers,"['Ioannis Stylianou', 'Jon Francombe', 'Pablo Martínez-Nuevo', 'Sven Ewan Shepstone', 'Zheng-Hua Tan']","Conventional audio equalization requires manual and cumbersome adjustments to adapt to changing listening contexts. This paper introduces a Large Language Model (LLM)-based alternative that maps natural language text prompts to equalization settings, enabling a conversational approach to sound system control. By utilizing data from a controlled listening experiment, the models exploit in-context learning and parameter-efficient fine-tuning techniques to reliably align with population-preferred equalization settings. Evaluation methods show statistically significant improvements in distributional alignment over random sampling and static preset baselines, indicating that LLMs could function as 'artificial equalizers.'",310.18,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09451v1_Late Breaking Results Quamba-SE Soft-edge Quantize.pdf,Late Breaking Results: Quamba-SE: Soft-edge Quantizer for Activations in State Space Models,"['Yizhi Chen', 'Ahmed Hemani']","We propose Quamba-SE, a soft-edge quantizer for State Space Model (SSM) activation quantization. Unlike existing methods, Quamba-SE employs three adaptive scales: high-precision for small values, standard scale for normal values, and low-precision for outliers. This preserves outlier information instead of hard clipping, while maintaining precision for other values. We evaluate on Mamba-130M across 6 zero-shot benchmarks. Results show that Quamba-SE consistently outperforms Quamba, achieving up to +2.68% on individual benchmarks and up to +0.83% improvement in the average accuracy of 6 datasets.",312.67,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09455v1_On the Hardness of Computing Counterfactual and Se.pdf,On the Hardness of Computing Counterfactual and Semi-factual Explanations in XAI,"['André Artelt', 'Martin Olsen', 'Kevin Tierney']","Providing clear explanations to the choices of machine learning models is essential for these models to be deployed in crucial applications. Counterfactual and semi-factual explanations have emerged as two mechanisms for providing users with insights into the outputs of their models. We provide an overview of the computational complexity results in the literature for generating these explanations, finding that in many cases, generating explanations is computationally hard. We strengthen the argument for this considerably by further contributing our own inapproximability results showing that not only are explanations often hard to generate, but under certain assumptions, they are also hard to approximate. We discuss the implications of these complexity results for the XAI community and for policymakers seeking to regulate explanations in AI.",308.65,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09460v1_SoK Enhancing Cryptographic Collaborative Learning.pdf,Enhancing Cryptographic Collaborative Learning with Differential Privacy,"['Francesco Capano', 'Jonas Böhler', 'Benjamin Weggenmann']","In collaborative learning (CL), multiple parties jointly train a machine learning model on their private datasets. However, data cannot be shared directly due to privacy concerns. To ensure input confidentiality, cryptographic techniques, such as multi-party computation (MPC), enable training on encrypted data. Yet, even securely trained models are vulnerable to inference attacks aiming to extract memorized data from model outputs. To ensure output privacy and mitigate inference attacks, differential privacy (DP) injects calibrated noise during training. While cryptography and DP offer complementary guarantees, combining them efficiently for cryptographic and differentially private CL (CPCL) is challenging. This work systematizes the CPCL landscape, introduces a unified framework, analyzes trade-offs of different secure noise sampling techniques, noise types, and DP mechanisms, and proposes future research directions based on identified key observations, gaps, and possible enhancements in the literature.",313.3,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09465v1_EvoFSM Controllable Self-Evolution for Deep Resear.pdf,EvoFSM: Controllable Self-Evolution for Deep Research with Finite State Machines,"['Shuo Zhang', 'Chaofa Yuan', 'Ryan Guo', 'Xiaomin Yu', 'Rui Xu', 'Zhangquan Chen', 'Zinuo Li', 'Zhi Yang', 'Shuhao Guan', 'Zhenheng Tang', 'Sen Hu', 'Liwen Zhang', 'Ronghao Chen', 'Huacan Wang']","EvoFSM is a structured self-evolving framework that evolves an explicit Finite State Machine (FSM) to achieve both adaptability and control. It decouples the optimization space into macroscopic Flow (state-transition logic) and microscopic Skill (state-specific behaviors), enabling targeted improvements under clear behavioral boundaries. Guided by a critic mechanism, EvoFSM refines the FSM through a small set of constrained operations and incorporates a self-evolving memory that distills successful trajectories as reusable priors and failure patterns as constraints for future queries. Extensive evaluations on five multi-hop QA benchmarks demonstrate the effectiveness of EvoFSM, reaching 58.0% accuracy on the DeepSearch benchmark. Additional results on interactive decision-making tasks further validate its generalization.",310.37,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09467v1_Searth Transformer A Transformer Architecture Inco.pdf,Searth Transformer: A Transformer Architecture Incorporating Earth's Geospheric Physical Priors for Global Mid-Range Weather Forecasting,"['Tianye Li', 'Qi Liu', 'Hao Li', 'Lei Chen', 'Wencong Cheng', 'Fei Zheng', 'Xiangao Xia', 'Ya Wang', 'Gang Huang', 'Weiwei Wang', 'Xuan Tong', 'Ziqing Zu', 'Yi Fang', 'Shenming Fu', 'Jiang Jiang', 'Haochen Li', 'Mingxing Li', 'Jiangjiang Xia', 'Wencong Cheng']","Accurate global medium-range weather forecasting is pivotal to Earth system science and serving as a critical public-service application. While modern weather forecasting increasingly employs data-driven AI models, most Transformer-based architectures rely on generic vision-centric designs that overlook the Earth’s inherent spherical topology and zonal periodicity. Additionally, the resource-intensive nature of autoregressive training imposes critical bottlenecks, constraining attainable forecast horizons while aggravating error propagation. These limitations not only compromise physical consistency and forecast accuracy but also effectively preclude resource-constrained institutions from leveraging localized datasets to refine global model performance. To address these challenges, this paper proposes the Shifted Earth Transformer (Searth Transformer), a physics-informed transformer architecture designed for global medium-range weather forecasting. Searth Transformer integrates zonal periodicity and meridional boundaries into window-based self-attention, enabling physically consistent global information exchange. To mitigate the computational bottlenecks, we develop the Relay Autoregressive (RAR) fine-tuning strategy, a memory-efficient strategy decoupling GPU memory usage from the forecast length. This enables the model to learn efficiently and effectively.",308.12,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09469v2_FairGU Fairness-aware Graph Unlearning in Social N.pdf,FairGU: Fairness-aware Graph Unlearning in Social Networks,"['Renqiang Luo', 'Yongshuai Yang', 'Huafei Huang', 'Qing Qing', 'Mingliang Hou', 'Ziqi Xu', 'Yi Yu', 'Jingjing Zhou', 'Feng Xia']","Graph unlearning has emerged as a critical mechanism for supporting sustainable and privacy-preserving social networks. However, existing graph unlearning techniques often lead to degraded algorithmic fairness compared to traditional graph learning methods. To address this gap, the authors introduce FairGU, a fairness-aware graph unlearning framework designed to preserve both utility and fairness during the unlearning process. FairGU integrates a dedicated fairness-aware module with effective data protection strategies, ensuring that sensitive attributes are neither inadvertently amplified nor structurally exposed when nodes are removed. Extensive experiments on multiple real-world datasets demonstrate that FairGU consistently outperforms state-of-the-art graph unlearning methods and fairness-enhanced graph learning baselines in terms of both accuracy and fairness metrics.",313.46,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09470v1_Personalized Multimodal Feedback Using Multiple Ex.pdf,Personalized Multimodal Feedback Using Multiple External Representations: Strategy Profiles and Learning in High School Physics,"['Natalia Revenga-Lozano', 'Karina E. Avila', 'Steffen Steinert', 'Matthias Schweinberger', 'Clara E. Gómez-Pérez', 'Jochen Kuhn', 'Stefan Küchemann']","This study investigated the effectiveness of personalized feedback using multiple external representations (MERs) in high school physics. A 16-24 week observational study was conducted with 661 students using a computer-based platform that provided feedback in verbal, graphical, and mathematical forms. Linear mixed-effects models and strategy-cluster analyses tested associations between feedback use and post-test performance, finding that elaborated multirepresentational feedback had a small but consistent positive association with post-test scores independent of prior knowledge and confidence. Learners adopted distinct representation-selection strategies; students with lower representational competence benefited from using a diverse set of representations, while this advantage diminished as competence increased. These findings motivate adaptive feedback designs and inform intelligent tutoring systems capable of tailoring feedback elaboration.",309.52,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09473v1_SimMerge Learning to Select Merge Operators from S.pdf,SimMerge: Learning to Select Merge Operators from Similarity Signals,"['Oliver Bolton', 'Aakanksha', 'Arash Ahmadian', 'Sara Hooker', 'Marzieh Fadaee', 'Beyza Ermis']","SimMerge is a predictive merge-selection method that selects the best merge using inexpensive, task-agnostic similarity signals between models. It computes functional and structural features from a small set of unlabeled probes and uses them to predict the performance of a given 2-way merge. SimMerge selects the best merge operator, the subset of models to merge, and the merge order, eliminating the expensive merge-and-evaluate loop. The method surpasses standard merge-operator performance on 2-way merges of 7B-parameter LLMs and generalizes to multi-way merges and 111B-parameter LLM merges without retraining. Additionally, a bandit variant supports adding new tasks, models, and operators on the fly.",310.89,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09478v3_Bridging Semantic Understanding and Popularity Bia.pdf,Bridging Semantic Understanding and Popularity Bias with LLMs,"['Renqiang Luo', 'Jilin University', 'Changchun, China', 'lrenqiang@outlook.com', 'Dong Zhang', 'Dalian University of Technology', 'Dalian, China', 'dongzhang1222@outlook.com', 'Yupeng Gao', 'Dalian University of Technology', 'Dalian, China', 'commer@mail.dlut.edu.cn', 'Mingliang Hou', 'Jinan University & TAL Education Group', 'Guangzhou, China', 'teemohold@outlook.com', 'Jiaying Liu', 'Dalian University of Technology', 'Dalian, China', 'jiayingliu@dlut.edu.cn', 'Zhe Wang', 'Jilin University', 'Changchun, China', 'wz2000@jlu.edu.cn', 'Shuo Yu*', 'Dalian University of Technology', 'Dalian, China', 'shuo.yu@ieee.org']","Semantic understanding of popularity bias is a crucial yet underexplored challenge in recommender systems. Most existing debiasing methods treat the semantic understanding of popularity bias as a matter of diversity enhancement or long-tail coverage, neglecting the deeper semantic layer that embodies the causal origins of the bias itself. FairLRM, a novel framework proposed in this paper, bridges the gap in the semantic understanding of popularity bias with Recommendation via Large Language Model (RecLLM). FairLRM decomposes popularity bias into item-side and user-side components, using structured instruction-based prompts to enhance the model's comprehension of both global item distributions and individual user preferences. Unlike traditional methods that rely on surface-level features such as 'diversity' or 'debiasing', FairLRM improves the model's ability to semantically interpret and address the underlying bias. Empirical evaluation shows that FairLRM significantly enhances both fairness and recommendation accuracy, providing a more semantically aware and trustworthy approach to enhance the semantic understanding of popularity bias.",312.32,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09503v1_What Do LLM Agents Know About Their World Task2Qui.pdf,What Do LLM Agents Know About Their World?,"['Siyuan Liu', 'Hongbang Yuan', 'Xinze Li', 'Ziyue Zhu', 'Yixin Cao', 'Yu-Gang Jiang']","Large language model (LLM) agents have demonstrated remarkable capabilities in complex decision-making and tool-use tasks, yet their ability to generalize across varying environments remains a concern. Current evaluation paradigms predominantly rely on trajectory-based metrics that measure task success, while failing to assess whether agents possess a grounded, transferable model of the environment. To address this gap, we propose Task-to-Quiz (T2Q), a deterministic and automated evaluation paradigm designed to decouple task execution from world-state understanding. We instantiate this paradigm in T2QBench, a suite comprising 30 environments and 1,967 grounded QA pairs across multiple difficulty levels. Our extensive experiments reveal that task success is often a poor proxy for environment understanding, and that current memory mechanisms can not effectively help agents acquire a grounded model of the environment. These findings identify proactive exploration and fine-grained state representation as primary bottlenecks, offering a robust foundation for developing more generalizable autonomous agents.",310.33,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09518v1_Learning Whole-Body Human-Humanoid Interaction fro.pdf,Learning Whole-Body Human-Humanoid Interaction from Human-Human Demonstrations,"['Wei-Jin Huang', 'Yue-Yi Zhang', 'Yi-Lin Wei', 'Zhi-Wei Xia', 'Juantao Tan', 'Yuan-Ming Li', 'Zhilin Zhao', 'Wei-Shi Zheng']","Enabling humanoid robots to physically interact with humans is a critical frontier, but progress is hindered by the scarcity of high-quality Human-Humanoid Interaction (HHoI) data. While leveraging abundant Human-Human Interaction (HHI) data presents a scalable alternative, standard retargeting fails by breaking essential contacts. The paper introduces PAIR (Physics-Aware Interaction Retargeting), a contact-centric, two-stage pipeline that preserves contact semantics across morphology differences to generate physically consistent HHoI data. This high-quality data exposes a second failure: conventional imitation learning policies merely mimic trajectories and lack interactive understanding. The paper introduces D-STAR (Decoupled Spatio-Temporal Action Reasoner), a hierarchical policy that disentangles when to act from where to act. In D-STAR, Phase Attention (when) and a Multi-Scale Spatial module (where) are used to achieve this.",311.1,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09520v1_Towards Realistic Synthetic Data for Automatic Dru.pdf,TOW ARDS REALISTIC SYNTHETIC DA TA FOR AUTOMA TIC DRUM TRANSCRIPTION,"['Pierfrancesco Melucci', 'Paolo Merialdo', 'Taketo Akama']","This paper introduces a new paradigm for Automatic Drum Transcription (ADT) that circumvents the need for paired audio-MIDI training data. The authors present a semi-supervised method to automatically curate a large and diverse corpus of one-shot drum samples from unlabeled audio sources. These samples are then used to synthesize a high-quality dataset from MIDI files alone, which is used to train a sequence-to-sequence transcription model. The model achieves new state-of-the-art results on the ENST and MDB test sets, significantly outperforming both fully supervised methods and previous synthetic-data approaches. The code for reproducing the experiments is publicly available at https://github.com/pier-maker92/ADT_STR.",312.87,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09527v1_Private LLM Inference on Consumer Blackwell GPUs A.pdf,Private LLM Inference on Consumer Blackwell GPUs: A Practical Guide for Cost-Effective Local Deployment in SMEs,"['Jonathan Knoop', 'Hendrik Holtmann']","This paper presents a systematic evaluation of NVIDIA's Blackwell consumer GPUs (RTX 5060 Ti, 5070 Ti, 5090) for production Large Language Model (LLM) inference. The study benchmarks four open-weight models (Qwen3-8B, Gemma3-12B, Gemma3-27B, GPT-OSS-20B) across 79 configurations spanning quantization formats, context lengths, and three workloads: RAG, multi-LoRA agentic serving, and high-concurrency APIs. The RTX 5090 delivers 3.5-4.6× higher throughput than the 5060 Ti with 21× lower latency for RAG, but budget GPUs achieve the highest throughput-per-dollar for API workloads with sub-second latency. NVFP4 quantization provides 1.6× throughput over BF16 with 41% energy reduction and only 2-4% quality loss. Self-hosted inference costs $0.001-$0.04 per million tokens (electricity only), 40-200× cheaper than budget-tier cloud APIs, with hardware breaking even in under four months at moderate volume (30M tokens/day). The results show that consumer GPUs can reliably replace cloud inference for most SME workloads, except for latency-critical long-context RAG, where high-end GPUs remain essential. The paper provides deployment guidance and releases all benchmark data for reproducible SME-scale deployments.",308.95,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09536v1_Omni-R1 Towards the Unified Generative Paradigm fo.pdf,Omni-R1: Towards the Unified Generative Paradigm for Multimodal Reasoning,"['Dongjie Cheng', 'Yongqi Li', 'Zhixin Ma', 'Hongru Cai', 'Yupeng Hu', 'Wenjie Wang', 'Liqiang Nie', 'Wenjie Li']","Multimodal Large Language Models (MLLMs) are making significant progress in multimodal reasoning. Early approaches focus on pure text-based reasoning, while more recent studies incorporate multimodal information into the reasoning steps. However, these studies often follow a single task-specific reasoning pattern, limiting their generalizability. To address this, the authors propose unified generative multimodal reasoning, which unifies diverse multimodal reasoning skills by generating intermediate images during the reasoning process. They instantiate this paradigm with Omni-R1, a two-stage SFT+RL framework featuring perception alignment loss and perception reward, enabling functional image generation. Additionally, they introduce Omni-R1-Zero, which eliminates the need for multimodal annotations by bootstrapping step-wise visualizations from text-only reasoning data. Empirical results show that Omni-R1 achieves unified generative reasoning across a wide range of multimodal tasks, and Omni-R1-Zero can match or even surpass Omni-R1 on average, suggesting a promising direction for generative multimodal reasoning.",309.47,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09555v1_Benchmarking Post-Training Quantization of Large L.pdf,Benchmarking Post-Training Quantization of Large Language Models under Microscaling Floating Point Formats,"['Manyi Zhang', 'Ji-Fu Li', 'Zhongao Sun', 'Haoli Bai', 'Hui-Ling Zhen', 'Zhenhua Dong', 'Xianzhi Yu']","Microscaling Floating-Point (MXFP) has emerged as a promising low-precision format for large language models (LLMs). Despite various post-training quantization (PTQ) algorithms being proposed, they mostly focus on integer quantization, while their applicability and behavior under MXFP formats remain largely unexplored. This work conducts a systematic investigation of PTQ under MXFP formats, encompassing over 7 PTQ algorithms, 15 evaluation benchmarks, and 3 LLM families. Key findings include: 1) MXFP8 consistently achieves near-lossless performance, while MXFP4 introduces substantial accuracy degradation and remains challenging; 2) PTQ effectiveness under MXFP depends strongly on format compatibility, with some algorithmic paradigms being consistently more effective than others; 3) PTQ performance exhibits highly consistent trends across model families and modalities, in particular, quantization sensitivity is dominated by the language model rather than the vision encoder in multi-modal LLMs; 4) The scaling factor of quantization is a critical error source in MXFP4, and a simple pre-scale optimization strategy can significantly mitigate its impact. These results provide practical guidance on adapting existing PTQ methods to MXFP quantization.",313.13,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09566v2_Hot-Start from Pixels Low-Resolution Visual Tokens.pdf,Hot-Start from Pixels: Low-Resolution Visual Tokens for Chinese Language Modeling,"['Shuyang Xiang', 'Hao Guan']","The authors investigate whether low-resolution visual inputs can serve as an alternative for character-level modeling in Chinese language. They find that grayscale images of individual characters, with resolutions as low as 8×8 pixels, achieve 39.2% accuracy, comparable to the index-based baseline of 39.1%. The study also highlights the pronounced hot-start effect, where accuracy reaches above 12% by 0.4% of total training, while index-based models lag at below 6%. The results demonstrate that minimal visual structure can provide a robust and efficient signal for Chinese language modeling, offering an alternative perspective on character representation that complements traditional index-based approaches.",316.92,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09600v1_Information Access of the Oppressed A Problem-Posi.pdf,Information Access of the Oppressed: A Problem-Posing Framework for Envisioning Emancipatory Information Access Platforms,"['BHASKAR MITRA', 'Nicola Neophytou', 'Sireesh Gururaja']","This paper explores the challenges of authoritarian capture of information access platforms, particularly in the context of rising democratic erosion, AI technologies, and concentration of power. It proposes a problem-posing framework inspired by Paulo Freire's theories of emancipatory pedagogy, challenging the traditional roles of technologists and users. The authors advocate for marginalized communities to co-construct and co-opt technology as part of their material struggle against oppression, and to redesign technology stacks to expose spaces for community participation.",309.9,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09603v1_Linear Complexity Self-Supervised Learning for Mus.pdf,Linear Complexity Self-Supervised Learning for Music Understanding with Random Quantizer,"['Petros Vavaroutsos', 'Theodoros Palamas', 'Pantelis Vikatos']","In recent years, foundation models have become popular due to their exceptional performance in natural language tasks. This paper focuses on reducing the size of a foundation model when applied to music information retrieval tasks. The authors combine the Branchformer architecture with SummaryMixing, which were first applied in speech recognition, along with a random quantization process. They conduct pre-training on publicly available datasets and ensure robust evaluation using a variety of downstream MIR tasks. The results show that their architecture achieves competitive performance while reducing the model size from 8.5% to 12.3%.",308.48,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09605v1_Sim2real Image Translation Enables Viewpoint-Robus.pdf,Sim2real Image Translation Enables Viewpoint-Robust Policies from Fixed-Camera Datasets,"['Jeremiah Coholich', 'Justin Wit', 'Robert Azarcon', 'Zsolt Kira']","Vision-based policies for robot manipulation have achieved significant recent success but are still brittle to distribution shifts such as camera viewpoint variations. Robot demonstration data is scarce and often lacks variation in camera viewpoints. Simulation offers a way to collect robot demonstrations at scale with comprehensive coverage of different viewpoints, but presents a visual sim2real challenge. To bridge this gap, the authors propose MANGO – an unpaired image translation method with a novel segmentation-conditioned InfoNCE loss, a highly-regularized discriminator design, and a modified PatchNCE loss. They find that these elements are crucial for maintaining viewpoint consistency during sim2real translation. When training MANGO, they only require a small amount of fixed-camera data from the real world, but show that their method can generate diverse unseen viewpoints by translating simulated observations. In this domain, MANGO outperforms all other image translation methods tested. Imitation-learning policies trained on data augmented by MANGO achieve success rates as high as 60% on views that the non-augmented policy fails completely on.",313.56,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09609v1_DPWriter Reinforcement Learning with Diverse Plann.pdf,DPWriter: Reinforcement Learning with Diverse Planning Branching for Creative Writing,"['Qian Cao', 'Yahui Liu', 'Wei Bi', 'Yi Zhao', 'Ruihua Song', 'Xiting Wang', 'Ruiming Tang', 'Guorui Zhou', 'Han Li']","This paper proposes an RL framework structured around a semi-structured long Chain-of-Thought (CoT), in which the generation process is decomposed into explicitly planned intermediate steps. The authors introduce a Diverse Planning Branching method that strategically introduces divergence at the planning phase based on diversity variation, alongside a group-aware diversity reward to encourage distinct trajectories. Experimental results on creative writing benchmarks demonstrate that our approach significantly improves output diversity without compromising generation quality, consistently outperforming existing baselines.",311.39,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09613v1_CogRail Benchmarking VLMs in Cognitive Intrusion P.pdf,CogRail: Benchmarking VLMs in Cognitive Intrusion Perception for Intelligent Railway Transportation Systems,"['Yonglin Tian', 'Qiyao Zhang', 'Wei Xu', 'Yutong Wang', 'Yihao Wu', 'Xinyi Li', 'Xingyuan Dai', 'Hui Zhang', 'Zhiyong Cui', 'Baoqing Guo', 'Zujun Yu', 'Yisheng Lv']","Accurate and early perception of potential intrusion targets is essential for ensuring the safety of railway transportation systems. Most existing systems focus narrowly on object classification within fixed visual scopes and apply rule-based heuristics to determine intrusion status, often overlooking latent intrusion risks. CogRail introduces a novel benchmark that integrates curated open-source datasets with cognitively driven question-answer annotations to support spatio-temporal reasoning and prediction. The authors conduct a systematic evaluation of state-of-the-art visual-language models (VLMs) using multimodal prompts to identify their strengths and limitations. They fine-tune VLMs for better performance and propose a joint fine-tuning framework that integrates position perception, movement prediction, and threat analysis. Extensive experiments reveal that current large-scale multimodal models struggle with complex spatial-temporal reasoning, underscoring the limitations of existing foundation models in this safety-critical domain. The proposed joint fine-tuning framework significantly improves performance.",308.26,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09620v1_Full Disclosure Less Trust How the Level of Detail.pdf,"Full Disclosure, Less Trust? How the Level of Detail about AI Use in News Writing Affects Readers’ Trust","['Pooja Prajod', 'Hannes Cools', 'Thomas Röggla', 'Karthikeya Puttur Venkatraj', 'Amber Kusters', 'Alia Elkattan', 'Pablo Cesar', 'Abdallah El Ali']","This 3×2×2 mixed factorial study investigates how three levels of AI disclosures (none, one-line, detailed) across two types of news (politics and lifestyle) and two levels of AI involvement (low and high) affect news readers' trust. The study found that detailed AI disclosures led to a decline in trust, while one-line and detailed disclosures increased source-checking behavior. Semi-structured interviews revealed that source-checking behavior was driven by interest in the topic, and trust was the main factor influencing subscription decisions. Participants expressed a preference for detailed disclosures, with most preferring one-line disclosures with demand for detail-on-demand formats.",314.6,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09624v1_Toward Understanding Unlearning Difficulty A Mecha.pdf,Toward Understanding Unlearning Difficulty: A Mechanistic Perspective and Circuit-Guided Difficulty Metric,"['Jiali Cheng', 'Ziheng Chen', 'Chirag Agarwal', 'Hadi Amiri']","Machine unlearning is essential for building trustworthy and compliant language models. However, unlearning success varies significantly across individual samples. This paper argues that this disparity is not only a data-side phenomenon but also reflects model-internal mechanisms that encode and protect memorized information. The authors study this problem from a mechanistic perspective based on model circuits, proposing Circuit-guided Unlearning Difficulty (CUD) as a pre-unlearning metric that assigns each sample a continuous difficulty score using circuit-level signals. Extensive experiments demonstrate that CUD reliably separates intrinsically easy and hard samples and remains stable across unlearning methods. The paper identifies key circuit-level patterns that reveal a mechanistic signature of difficulty, with easy-to-unlearn samples associated with shorter, shallower interactions concentrated in earlier-to-intermediate parts of the original model, while hard samples rely on longer and deeper pathways closer to late-stage computation. Compared to existing qualitative studies, CUD takes a first step toward a principled, fine-grained, and interpretable analysis of unlearning difficulty, motivating the development of unlearning methods grounded in model mechanisms.",309.19,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09625v1_The Promptware Kill Chain How Prompt Injections Gr.pdf,The Promptware Kill Chain: How Prompt Injections Gradually Evolved Into a Multi-Step Malware,"['Ben Nassi', 'Bruce Schneier', 'Oleg Brodt']","The rapid adoption of large language model (LLM)-based systems has created a new attack surface that existing security frameworks inadequately address. The dominant framing of these threats as 'prompt injection' obscures a more complex reality: Attacks on LLM-based systems increasingly involve multi-step sequences that mirror traditional malware campaigns. This paper proposes that attacks targeting LLM-based applications constitute a distinct class of malware, termed 'promptware', and introduces a five-step kill chain model for analyzing these threats. The framework comprises Initial Access (prompt injection), Privilege Escalation (jailbreaking), Persistence (memory and retrieval poisoning), Lateral Movement (cross-system and cross-user propagation), and Actions on Objective (ranging from data exfiltration to unauthorized transactions). By mapping recent attacks to this structure, the authors demonstrate that LLM-related attacks follow systematic sequences analogous to traditional malware campaigns. The promptware kill chain offers a structured methodology for threat modeling and provides a common vocabulary for researchers across AI safety and cybersecurity to address a rapidly evolving threat landscape.",310.22,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09626v1_From Prompt to Protocol Fast Charging Batteries wi.pdf,From Prompt to Protocol: Fast Charging Batteries with Large Language Models,"['Ge Lei', 'Ferran Brosa Planella', 'Sterling G. Baird', 'Samuel J. Cooper']","Efficiently optimizing battery charging protocols is challenging due to the slow, costly, and non-differentiable nature of evaluations. Existing approaches often limit the diversity of explored protocols by heavily constraining the search space. This paper introduces two gradient-free, LLM-driven closed-loop methods: Prompt-to-Optimizer (P2O) and Prompt-to-Protocol (P2P). P2O uses an LLM to propose code for small neural-network-based protocols, which are then trained by an inner-loop. P2P simply writes an explicit function for the current and its scalar parameters. Across case studies, LLM-guided P2O outperforms neural networks designed by Bayesian optimization, evolutionary algorithms, and random search. In a realistic fast-charging scenario, both P2O and P2P yield around a 4.2% improvement in state of health over a state-of-the-art multi-step constant current (CC) baseline, with P2P achieving this under matched evaluation budgets. These results demonstrate that LLMs can expand the space of protocol functional forms, incorporate language-based constraints, and enable efficient optimization in high-cost experimental settings.",313.15,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09635v1_LLM for Large-Scale Optimization Model Auto-Formul.pdf,LLM for Large-Scale Optimization Model Auto-Formulation: A Lightweight Few-Shot Learning Approach,"['Kuo Liang', 'Yuhang Lu', 'Jianming Mao', 'Shuyi Sun', 'Chunwei Yang', 'Congcong Zeng', 'Xiao Jin', 'Hanzhang Qin', 'Ruihao Zhu', 'Chung-Piaw Teo']","Large-scale optimization is a key backbone of modern business decision-making. However, building these models is often labor-intensive and time-consuming. We address this by proposing LEAN-LLM-OPT, a LightwEight AgeNtic workflow construction framework for LLM-assisted large-scale OPTimization auto-formulation. LEAN-LLM-OPT takes as input a problem description together with associated datasets and orchestrates a team of LLM agents to produce an optimization formulation. Specifically, upon receiving a query, two upstream LLM agents dynamically construct a workflow that specifies, step-by-step, how optimization models for similar problems can be formulated. A downstream LLM agent then follows this workflow to generate the final output. Leveraging LLMs' text-processing capabilities and common modeling practices, the workflow decomposes the modeling task into a sequence of structured sub-tasks and offloads mechanical data-handling operations to auxiliary tools. This design alleviates the downstream agent's burden related to planning and data handling, allowing it to focus on the most challenging components that cannot be readily standardized. Extensive simulations show that LEAN-LLM-OPT, instantiated with GPT-4.1 and the open source gpt-oss-20B, achieves strong performance on large-scale optimization modeling tasks and is competitive with state-of-the-art approaches. In addition, in a Singapore Airlines choice-based revenue management use case, LEAN-LLM-OPT demonstrates practical value by achieving leading performance across a range of scenarios. Along the way, we introduce Large-Scale-OR and Air-NRM, the first comprehensive benchmarks for large-scale optimization auto-formulation. The code and data of this work is available at https://github.com/CoraLiang01/lean-llm-opt.",310.76,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09636v1_PersonalAlign Hierarchical Implicit Intent Alignme.pdf,PersonalAlign: Hierarchical Implicit Intent Alignment for Personalized GUI Agent with Long-Term User-Centric Records,"['Yibo Lyu', 'Gongwei Chen', 'Rui Shao†', 'Weili Guan', 'Liqiang Nie†']","While GUI agents have shown strong performance under explicit and completion instructions, real-world deployment requires aligning with users' more complex implicit intents. This work introduces Hierarchical Implicit Intent Alignment for Personalized GUI Agent (PersonalAlign), a new agent task that requires agents to leverage long-term user records as persistent context to resolve omitted preferences in vague instructions and anticipate latent routines by user state for proactive assistance. The study introduces AndroidIntent, a benchmark to evaluate agents' ability in resolving vague instructions and providing proactive suggestions through reasoning over long-term user records. 775 user-specific preferences and 215 routines from 20k long-term records across different users were annotated for evaluation. HIM-Agent, a Hierarchical Intent Memory Agent, maintains a continuously updating personal memory and hierarchically organizes user preferences and routines for personalization. The evaluation of GUI agents on AndroidIntent, including GPT-5, Qwen3-VL, and UI-TARS, shows that HIM-Agent significantly improves both execution and proactive performance by 15.7% and 7.3%.",308.72,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09667v2_Collaborative Multi-Agent Test-Time Reinforcement .pdf,Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning,"['Zhiyuan Hu', 'Yunhai Hu', 'Juncheng Liu', 'Shuyue Stella Li', 'Yucheng Wang', 'Zhen Xu', 'See-Kiong Ng', 'Anh Tuan Luu', 'Xinxing Xu', 'Bryan Hooi', 'Cynthia Breazeal', 'Hae Won Park']","Multi-agent systems have evolved into practical LLM-driven collaborators for various applications, gaining robustness from diversity and cross-checking. However, multi-agent reinforcement learning (MARL) training is resource-intensive and unstable due to non-stationarity and sparse, high-variance rewards. This paper introduces Multi-Agent Test-Time Reinforcement Learning (MATTRL), a framework that injects structured textual experience into multi-agent deliberation at inference time. MATTRL forms a multi-expert team of specialists for multi-turn discussions, retrieves and integrates test-time experiences, and reaches consensus for final decision-making. The framework improves accuracy by an average of 3.67% over a multi-agent baseline and by 8.67% over comparable single-agent baselines across challenging benchmarks in medicine, math, and education. Ablation studies examine different credit-assignment schemes and provide a detailed comparison of their effects on training outcomes. MATTRL offers a stable, effective, and efficient path to distribution-shift-robust multi-agent reasoning without tuning.",312.73,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09680v1_Automating Supply Chain Disruption Monitoring via .pdf,Automating Supply Chain Disruption Monitoring via an Agentic AI Approach,"['Sara AlMahria', 'Liming Xu', 'Alexandra Brintrup']","Modern supply chains are increasingly exposed to disruptions from geopolitical events, demand shocks, trade restrictions, and natural disasters. While most companies lack visibility beyond Tier-1 suppliers, this work introduces a minimally supervised agentic AI framework that autonomously monitors, analyzes, and responds to disruptions across extended supply networks. The framework comprises seven specialised agents powered by large language models and deterministic tools, which jointly detect disruption signals from unstructured news, map them to multi-tier supplier networks, evaluate exposure based on network structure, and recommend mitigations such as alternative sourcing options. The system achieves high accuracy across core tasks and performs full end-to-end analyses in a mean of 3.83 minutes at a cost of $0.0836 per disruption, representing a reduction of more than three orders of magnitude in response time compared to industry benchmarks.",314.05,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09684v1_Disentangling Task Conflicts in Multi-Task LoRA vi.pdf,Disentangling Task Conflicts in Multi-Task LoRA via Orthogonal Gradient Projection,"['Ziyu Yang', 'Guibin Chen', 'Yuxin Yang', 'Aoxiong Zeng', 'Xiangquan Yang']","Multi-Task Learning (MTL) combined with Low-Rank Adaptation (LoRA) has emerged as a promising direction for parameter-efficient deployment of Large Language Models (LLMs). However, this approach suffers from negative transfer, where conflicting gradient updates from distinct tasks degrade the performance of individual tasks compared to single-task fine-tuning. This problem is exacerbated in LoRA due to the low-rank constraint, which limits the optimization landscape's capacity to accommodate diverse task requirements. In this paper, we propose Ortho-LoRA, a gradient projection method specifically tailored for the bipartite structure of LoRA. Ortho-LoRA dynamically projects conflicting task gradients onto the orthogonal complement of each other within the intrinsic LoRA subspace. Extensive experiments on the GLUE benchmark demonstrate that Ortho-LoRA effectively mitigates task interference, outperforming standard joint training and recovering 95% of the performance gap between multi-task and single-task baselines with negligible computational overhead.",309.38,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09692v1_Routing with Generated Data Annotation-Free LLM Sk.pdf,Routing with Generated Data: Annotation-Free LLM Skill Estimation and Expert Selection,"['Tianyi Niu', 'Justin Chih-Yao Chen', 'Genta Indra Winata', 'Shi-Xiong Zhang', 'Supriyo Chakraborty', 'Sambit Sahu', 'Elias Stengel-Eskin', 'Mohit Bansal']","Large Language Model (LLM) routers dynamically select optimal models for given inputs. Existing approaches typically assume access to ground-truth labeled data, which is often unavailable in practice. We introduce Routing with Generated Data (RGD), a challenging setting in which routers are trained exclusively on generated queries and answers produced from high-level task descriptions by generator LLMs. We evaluate query-answer routers and query-only routers across four diverse benchmarks and 12 models, finding that query-answer routers degrade faster than query-only routers as generator quality decreases. Our analysis reveals two crucial characteristics of effective generators: they must accurately respond to their own questions, and their questions must produce sufficient performance differentiation among the model pool. We then show how filtering for these characteristics can improve the quality of generated data. We further propose CASCAL, a novel query-only router that estimates model correctness through consensus voting and identifies model-specific skill niches via hierarchical clustering. CASCAL is substantially more robust to generator quality, outperforming the best query-answer router by 4.6% absolute accuracy when trained on weak generator data.",313.34,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09694v1_LLMs can Compress LLMs Adaptive Pruning by Agents.pdf,LLMs can Compress LLMs: Adaptive Pruning by Agents,"['Sai Varun Kodathala', 'Rakesh Vunnam']","As Large Language Models (LLMs) continue to scale, post-training pruning has emerged as a promising approach to reduce computational costs while preserving performance. Existing methods such as SparseGPT and Wanda achieve high sparsity through layer-wise weight reconstruction or activation-aware magnitude pruning, but rely on uniform or hand-crafted heuristics to determine per-layer sparsity ratios. Recent work has shown that pruned LLMs suffer from severe factual knowledge degradation, with structured pruning methods experiencing near-total collapse in factual question-answering capabilities. The paper introduces agent-guided pruning, where a foundation model acts as an adaptive pruning agent to intelligently select which layers to prune at each iteration while preserving critical knowledge pathways. The method constructs layer-wise sensitivity profiles by combining Wanda-inspired weight-activation metrics with gradient importance scores, normalized as z-scores for model-agnostic comparison. These statistics are processed by an LLM agent equipped with self-reflection capabilities, enabling it to learn from previous pruning outcomes and iteratively refine its strategy. A checkpoint rollback mechanism maintains model quality by reverting when perplexity degradation exceeds a threshold. The approach is evaluated on Qwen3 models (4B and 8B parameters) at approximately 45% sparsity, demonstrating substantial improvements over structured pruning baselines: 56% relative improvement in MMLU accuracy, 19× better factual knowledge retention on FreebaseQA, and 69% lower perplexity degradation. Notably, the framework requires no retraining, operates in a model-agnostic manner, and exhibits effective self-correction with only 2-4 rollbacks across 21-40 iterations, demonstrating that foundation models can effectively guide the compression of other foundation models.",314.03,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09703v1_ShortCoder Knowledge-Augmented Syntax Optimization.pdf,ShortCoder: Knowledge-Augmented Syntax Optimization for Token-Efficient Code Generation,"['Sicong Liu', 'Yanxian Huang', 'Mingwei Liu', 'Jiachi Chen', 'Ensheng Shi', 'Yuchi Ma', 'Hongyu Zhang', 'Yin Zhang', 'Yanlin Wang']","Code generation tasks aim to automate the conversion of user requirements into executable code, significantly reducing manual development efforts and enhancing software productivity. The emergence of large language models (LLMs) has advanced code generation, but their efficiency is impacted by architectural constraints. ShortCoder, a knowledge-infused framework, optimizes code generation efficiency while preserving semantic equivalence and readability. It introduces ten syntax-level simplification rules for Python, a hybrid data synthesis pipeline, and a fine-tuning strategy to inject conciseness awareness into base LLMs. Extensive experimental results demonstrate that ShortCoder consistently outperforms state-of-the-art methods on HumanEval, achieving improvements of 18.1%-37.8% in generation efficiency.",310.04,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09706v1_Value-Aware Numerical Representations for Transfor.pdf,Value-Aware Numerical Representations for Transformer Language Models,"['Andreea Dutulescu', 'Stefan Ruseti', 'Mihai Dascalu']","Transformer-based language models often achieve strong results on mathematical reasoning benchmarks while remaining fragile on basic numerical understanding and arithmetic operations. A central limitation is that numbers are processed as symbolic tokens whose embeddings do not explicitly encode numerical value, leading to systematic errors. This paper introduces a value-aware numerical representation that augments standard tokenized inputs with a dedicated prefix token whose embedding is explicitly conditioned on the underlying numerical value. Evaluation on arithmetic tasks shows that the proposed approach outperforms baselines across numerical formats, tasks, and operand lengths, indicating that explicitly encoding numerical value is an effective and efficient way to improve fundamental numerical robustness in language models.",313.79,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09708v1_Fast-ThinkAct Efficient Vision-Language-Action Rea.pdf,Fast-ThinkAct: Efficient Vision-Language-Action,"['Chi-Pin Huang', 'Yunze Man', 'Zhiding Yu', 'Min-Hung Chen', 'Jan Kautz', 'Yu-Chiang Frank Wang', 'Fu-En Yang']","Fast-ThinkAct is an efficient reasoning framework that achieves compact yet performant planning through verbalizable latent reasoning. It learns to reason efficiently with latent chain-of-thoughts by distilling from a teacher, driven by a preference-guided objective to align manipulation trajectories that transfer both linguistic and visual planning capabilities for embodied control. This enables reasoning-enhanced policy learning that effectively connects compact reasoning to action execution. Extensive experiments across diverse embodied manipulation and reasoning benchmarks demonstrate that Fast-ThinkAct achieves strong performance with up to 89.3% reduced inference latency over state-of-the-art reasoning VLAs, while maintaining effective long-horizon planning, few-shot adaptation, and failure recovery.",310.24,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09749v1_R-LAM Reproducibility-Constrained Large Action Mod.pdf,R-LAM: Reproducibility-Constrained Large Action Models for Scientific Workflow Automation,['Suriya Sureshkumar'],"Large Action Models (LAMs) extend large language models by enabling autonomous decision-making and tool execution, making them promising for automating scientific workflows. However, scientific workflows impose strict requirements on reproducibility, auditability, and deterministic execution, which are not satisfied by generic LLM-based agents. Unconstrained action generation can lead to silent state changes, non-deterministic executions, and irreproducible experimental results, limiting the applicability of LAMs in scientific settings. This paper proposes R-LAM, a reproducibility-constrained framework for applying Large Action Models to scientific workflow automation. R-LAM introduces structured action schemas, deterministic execution policies, and explicit provenance tracking to ensure that every action and intermediate artifact is auditable and replayable. The framework supports failure-aware execution loops and controlled workflow forking, enabling iterative experimentation without compromising reproducibility. The authors implement R-LAM as a lightweight Python framework and release it as an open-source PyPI package to facilitate reproducible research. An experimental evaluation demonstrates that R-LAM improves reproducibility success rates and execution reliability compared to unconstrained LLM-based agents, while retaining adaptive control over workflow execution.",312.61,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09750v1_SAGE Tool-Augmented LLM Task Solving Strategies in.pdf,SAGE: Tool-Augmented LLM Task Solving Strategies in Scalable Multi-Agent Environments,"['Robert K. Strehlow', 'Tobias Küster', 'Oskar F. Kupke', 'Brandon Llanque Kurps', 'Fikret Sivrikaya', 'Sahin Albayrak']","This paper presents SAGE, a specialized conversational AI interface based on the OPACA framework for tool discovery and execution. It integrates new tools or services dynamically, allowing for the seamless switching between different models and adding various prompting methods. The authors implemented a variety of task-solving strategies and evaluated them against comprehensive benchmark services, highlighting the strengths and weaknesses of different approaches. The results are available as open source and open data on GitHub.",314.66,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09753v1_Critically Engaged Pragmatism A Scientific Norm an.pdf,"Critically Engaged Pragmatism: A Scientific Norm and Social, Pragmatist Epistemology for AI Science Evaluation Tools",['Carole J. Lee'],The scientific community faces crises in credibility assessment due to the proliferation of papers and the strain on peer review capacity. AI science evaluation tools are criticized for being prone to ,238.11,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09755v1_Heterogeneous computing platform for real-time rob.pdf,Heterogeneous computing platform for real-time robotics,"['Jakub Fil', 'Yulia Sandamirskaya', 'Hector Gonzalez', 'Loïc Azzalin', 'Stefan Glüge', 'Lukas Friedenstab', 'Matthias Lohrmann', 'Mahmoud Akl', 'Khaleel Khan', 'Leonie Wolf', 'Kristin Richter', 'Holm Puder', 'Mazhar Ali Bari', 'Xuan Choo', 'Noha Alharthi', 'Michael Hopkins', 'Mansoor Hanif', 'Christian Mayr', 'Jens Struckmeier', 'Steve Furber']","This paper explores the computing platform required to enable the vision of cognitive cities, where robotics will play a pivotal role. The authors propose a hybrid computing architecture combining neuromorphic hardware (Loihi2 processor) with high-density GPU solutions for real-time social robotics. They demonstrate the use of this architecture in an interactive task, where a humanoid robot plays a musical instrument with a human. The central focus is on the efficient and seamless integration of disparate components, ensuring the synergy between software and hardware maximizes overall performance and responsiveness. The proposed system architecture highlights the potential of heterogeneous computing architectures in advancing robotic autonomy and interactive intelligence, pointing toward a future where such integrated systems become the norm in complex, real-time applications.",313.15,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09756v1_Synthetic Data for Veterinary EHR De-identificatio.pdf,"Synthetic Data for Veterinary EHR De-identification: Benefits, Limits, and Safety Trade-offs Under Fixed Compute","['David Brundage, PhD']",This study evaluates the use of large language model-generated synthetic veterinary clinical narratives in de-identification processes. It explores the impact of synthetic augmentation and substitution under fixed compute constraints. The findings indicate that synthetic data can reduce document-level leakage when used to expand training exposure but does not substitute for labeled real notes under fixed training budgets. The study also highlights systematic synthetic-real mismatches and suggests that observed gains are largely due to increased exposure rather than intrinsic advantages of synthetic text.,314.05,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09757v1_Democracy and Distrust in an Era of Artificial Int.pdf,Democracy & Distrust in an Era of Artificial Intelligence,['Sonia K. Katyal'],"The author argues that the rise of AI decision-making poses a similar challenge to democracy's basic framework as the failure of the political process to recognize the rights or interests of minorities. The author outlines a theory of judicial review in an era of artificial intelligence, analyzing both the limitations and possibilities of judicial review of AI. The author draws on cases in which AI decision-making has been challenged in courts to show how concepts of due process and equal protection can be recuperated in a modern AI era, and even integrated into AI to provide for better oversight and accountability.",316.09,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09760v1_Investigating Tool-Memory Conflicts in Tool-Augmen.pdf,Investigating Tool-Memory Conflicts in Tool-Augmented LLMs,"['Jiali Cheng', 'Rui Pan', 'Hadi Amiri']","This paper investigates a new type of knowledge conflict, Tool-Memory Conflict (TMC), in tool-augmented large language models (LLMs). TMC occurs when the internal parametric knowledge of the model contradicts the external tool knowledge. The authors find that existing LLMs suffer from TMC, especially on STEM-related tasks. They also uncover that under different conditions, tool knowledge and parametric knowledge may be prioritized differently. The paper evaluates existing conflict resolving techniques, including prompting-based and RAG-based methods, and finds that none of these approaches can effectively resolve tool-memory conflicts.",313.43,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09762v1_Explicating Tacit Regulatory Knowledge from LLMs t.pdf,Explicating Tacit Regulatory Knowledge from LLMs to Auto-Formalize Requirements for Compliance Test Case Generation,"['Zhiyi Xue', 'Xiaohong Chen', 'Min Zhang']","This paper proposes RAFT, a framework for requirements auto-formalization and compliance test generation via explicating tacit regulatory knowledge from multiple Large Language Models (LLMs). RAFT employs an Adaptive Purification-Aggregation strategy to extract tacit regulatory knowledge from LLMs and integrates it into three artifacts: a domain meta-model, a formal requirements representation, and testability constraints. These artifacts are dynamically injected into prompts to guide high-precision requirement formalization and automated test generation. Experiments across financial, automotive, and power domains demonstrate that RAFT achieves expert-level performance, significantly outperforming state-of-the-art methods while reducing overall generation and review time.",313.77,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09765v1_AI Survival Stories a Taxonomic Analysis of AI Exi.pdf,Survival Stories: A Taxonomic Analysis of AI Existential Risk,"['John Hawthorne', 'Herman Cappelena', 'Simon Goldstein']","This paper develops a general framework for thinking about the existential risk of AI systems. It analyzes a two-premise argument that AI systems pose a threat to humanity, with premises stating that AI systems will become extremely powerful and that if they do, they will destroy humanity. The authors introduce a taxonomy of 'survival stories,' in which humanity survives into the far future. Each survival story highlights one of the ways that the future could go if humanity were to survive rather than be destroyed by AI. The authors argue that different survival stories face different challenges and motivate different responses to the threats from AI. They also use their taxonomy to produce rough estimates of 'P(doom)', the probability that humanity will be destroyed by AI.",313.54,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09768v1_CLiMB A Domain-Informed Novelty Detection Clusteri.pdf,CLiMB: A Domain-Informed Novelty Detection Clustering Framework for Scientific Discovery,"['Lorenzo Monti', 'Tatiana Muraveva', 'Brian Sheridan', 'Davide Massari', 'Alessia Garofalo', 'Gisella Clementini', 'Umberto Michelucci']","In data-driven scientific discovery, a challenge lies in classifying well-characterized phenomena while identifying novel anomalies. Current semi-supervised clustering algorithms often assume global representativeness of supervisory signals and enforce rigid constraints, suppressing unanticipated patterns or requiring a pre-specified number of clusters. To bridge this gap, CLiMB (CLustering in Multiphase Boundaries) is introduced, a domain-informed framework decoupling prior knowledge exploitation from unknown structure exploration. Using a sequential two-phase approach, CLiMB first anchors known clusters using constrained partitioning and subsequently applies density-based clustering to residual data. Demonstrated on RR Lyrae stars data from GaiaData Release 3, CLiMB attains an Adjusted Rand Index of 0.829 with 90% seed coverage in recovering known Milky Way substructures, outperforming heuristic and constraint-based baselines. Sensitivity analysis confirms CLiMB's superior data efficiency, showing monotonic improvement as knowledge increases. Finally, CLiMB successfully isolates three dynamical features (Shiva, Shakti, and the Galactic Disk) in the unlabelled field, validating its potential for scientific discovery.",314.24,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09770v1_GUI-Eyes Tool-Augmented Perception for Visual Grou.pdf,GUI-Eyes: Tool-Augmented Perception for Visual Grounding in GUI Agents,"['Chen Chen', 'Jiawei Shao', 'Dakuan Lu', 'Haoyi Hu', 'Xiangcheng Liu', 'Hantao Yao', 'Wu Liu']","GUI-Eyes is a reinforcement learning framework for active visual perception in GUI tasks. It learns to make strategic decisions on whether and how to invoke visual tools, such as cropping or zooming, within a two-stage reasoning process. The framework introduces a progressive perception strategy that decomposes the decision-making into coarse exploration and fine-grained grounding, coordinated by a two-level policy. It also designs a spatially continuous reward function tailored to tool usage, which integrates both location proximity and region overlap to provide dense supervision and alleviate reward sparsity. On the ScreenSpot-Pro benchmark, GUI-Eyes-3B achieves 44.8% grounding accuracy using only 3k labeled samples, significantly outperforming both supervised and RL-based baselines. These results highlight the critical role of tool-aware active perception in building robust and data-efficient GUI agents.",313.52,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09771v1_PCN-Rec Agentic Proof-Carrying Negotiation for Rel.pdf,PCN-Rec: Agentic Proof-Carrying Negotiation for Reliable Governance-Constrained Recommendation,"['Aradhya Dixit', 'Shreem Dixit']","Modern LLM-based recommenders can generate compelling ranked lists, but they struggle to reliably satisfy governance constraints such as minimum long-tail exposure or diversity requirements. We present PCN-Rec, a proof-carrying negotiation pipeline that separates natural-language reasoning from deterministic enforcement. A base recommender (MF/CF) produces a candidate window of size 𝑊, which is negotiated by two agents: a User Advocate optimizing relevance and a Policy Agent enforcing constraints. A mediator LLM synthesizes a Top-𝑁 slate together with a structured certificate (JSON) describing the claimed constraint satisfaction. A deterministic verifier recomputes all constraints from the slate and accepts only verifier-checked certificates; if verification fails, a deterministic constrained-greedy repair produces a compliant slate for re-verification, yielding an auditable trace. On MovieLens-100K with governance constraints, PCN-Rec achieves a 98.55% pass rate on feasible users (𝑛= 551, 𝑊= 80) versus a one-shot single-LLM baseline without verification/repair, while preserving utility with only a 0.021 absolute drop in NDCG@10 (0.403 vs. 0.424); differences are statistically significant (𝑝<0.05).",311.42,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09772v1_Antisocial behavior towards large language model u.pdf,Antisocial behavior towards large language model users: experimental evidence,"['Paweł Niszczota', 'Cassandra Grützner']",This study investigates antisocial behavior towards users of large language models. The authors report experimental evidence of such behavior and discuss the implications for ethical considerations in AI research and development.,312.67,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09773v1_Enhancing LUT-based Deep Neural Networks Inference.pdf,Enhancing LUT-based Deep Neural Networks Inference through Architecture and Connectivity Optimization,"['Binglei Lou', 'Ruilin Wu', 'Philip Leong']","This paper presents SparseLUT, a comprehensive framework that addresses the challenges of exponential growth of LUT size and inefficient random sparse connectivity in LUT-based DNNs. It introduces architectural enhancements and a non-greedy training algorithm to optimize neuron connectivity and deliver consistent accuracy improvements across benchmarks.",312.84,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09805v1_Improving Chain-of-Thought for Logical Reasoning v.pdf,Improving Chain-of-Thought for Logical Reasoning via Attention-Aware Intervention,"['Phuong Minh Nguyen', 'Tien Huu Dang', 'Naoya Inoue']","This work introduces an end-to-end framework for logical reasoning tasks without requiring external resources. By introducing structural information into few-shot prompts, the framework activates attention heads that align with logical reasoning operators. Building on this insight, Attention-Aware Intervention (AAI) reweights attention scores across selected heads identified by their logical patterns. Extensive experiments demonstrate that AAI enhances logical reasoning performance across diverse benchmarks and architectures, while incurring negligible additional computational overhead.",312.11,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09806v1_Diffusion-Driven Deceptive Patches Adversarial Man.pdf,Diffusion-Driven Deceptive Patches: Adversarial Manipulation and Forensic Detection in Facial Identity Verification,"['Shahrzad Sayyafzadeh', 'Hongmei Chi', 'Shonda Bernadin']","This work presents an end-to-end pipeline for generating, refining, and evaluating adversarial patches to compromise facial biometric systems with forensic analysis and security testing applications. The pipeline utilizes FGSM to generate adversarial noise and a diffusion model for reverse diffusion to enhance imperceptibility. The refined patch is applied to facial images to test its ability to evade recognition systems while maintaining natural visual characteristics. A Vision Transformer (ViT)-GPT2 model generates captions to provide a semantic description of a person’s identity for Adv Images, supporting forensic interpretation and documentation for identity evasion attacks and recognition. The pipeline evaluates changes in identity classification, captioning results, and the vulnerability of facial identity verification and expression to adversarial attacks, and successfully detected and analyzed a series of adversaries generated with 0.95% SSIM.",315.5,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09809v1_QFed Parameter-Compact Quantum-Classical Federated.pdf,QFed: Parameter-Compact Quantum-Classical Federated Learning,"['Samar Abdelghani', 'Soumaya Cherkaoui']","This study examines the potential of quantum-assisted federated learning, which could cut the number of parameters in classical models by polylogarithmic factors and thus lessen training overhead. The authors introduce QFed, a quantum-enabled federated learning framework aimed at boosting computational efficiency across edge device networks. Experimental results using the FashionMNIST dataset show that QFed achieves a 77.6% reduction in the parameter count of a VGG-like model while maintaining comparable accuracy to classical approaches in a scalable environment. These results point to the potential of leveraging quantum computing within a federated learning context to strengthen FL capabilities of edge devices.",313.21,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09814v1_Explainable Deep Learning for Pediatric Pneumonia .pdf,Explainable Deep Learning for Pediatric Pneumonia Detection in Chest X-Ray Images,"['Adil O. Khadidos1', 'Aziida Nanyonga2*', 'Alaa O. Khadidos3,4', 'Olfat M. Mirza5', 'Mustafa Tahsin Yilmaz6']","This study compares two state-of-the-art convolutional neural network architectures, DenseNet121 and EfficientNet-B0, for automated pediatric pneumonia detection using a publicly available dataset of 5,863 chest X-ray images. The models were fine-tuned using pretrained ImageNet weights and evaluated using accuracy, F1-score, Matthews Correlation Coefficient (MCC), and recall. Explained models using Gradient-weighted Class Activation Mapping (Grad-CAM) and Local Interpretable Model-agnostic Explanations (LIME) were also incorporated to visualize regions contributing to model decisions. EfficientNet-B0 achieved superior classification performance, with an accuracy of 84.6%, F1-score of 0.8899, and MCC of 0.6849. DenseNet121 obtained 79.7% accuracy, an F1-score of 0.8597, and an MCC of 0.5852. Both models achieved high recall values above 0.99, indicating strong sensitivity to pneumonia detection.",315.93,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09822v2_LLM-Based Agentic Systems for Software Engineering.pdf,LLM-Based Agentic Systems for Software Engineering: Challenges and Opportunities,"['Yongjian Tang', 'Thomas Runkler']","This concept paper systematically reviews the emerging paradigm of LLM-based multi-agent systems, examining their applications across the Software Development Life Cycle (SDLC), from requirements engineering and code generation to static code checking, testing, and debugging. The authors delve into a wide range of topics such as language model selection, SE evaluation benchmarks, state-of-the-art agentic frameworks and communication protocols. They identify key challenges and outline future research opportunities, focusing on multi-agent orchestration, human-agent coordination, computational cost optimization, and effective data collection. This work aims to provide researchers and practitioners with valuable insights into the current forefront landscape of agentic systems within the software engineering domain.",315.87,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09841v2_A pipeline for enabling path-specific causal fairn.pdf,APIPIPELINE FOR ENABLING PATH-SPECIFIC CAUSAL FAIRNESS IN OBSERVATIONAL HEALTH DATA,"['Aparajita Kashyap', 'Sara Matijevic', 'Noémie Elhadad', 'Steven A. Kushner', 'Shalmali Joshi']","When training machine learning (ML) models for potential deployment in a healthcare setting, it is essential to ensure that they do not replicate or exacerbate existing healthcare biases. Although many definitions of fairness exist, we focus on path-specific causal fairness, which allows us to better consider the social and medical contexts in which biases occur. In this work, we map the structural fairness model to the observational healthcare setting and create a generalizable pipeline for training causally fair models. The pipeline explicitly considers specific healthcare context and disparities to define a target 'fair' model. Our work fills two major gaps: first, we expand on characterizations of the 'fairness-accuracy' tradeoff by detangling direct and indirect sources of bias and jointly presenting these fairness considerations alongside considerations of accuracy in the context of broadly known biases. Second, we demonstrate how a foundation model trained without fairness constraints on observational health data can be leveraged to generate causally fair downstream predictions in tasks with known social and medical disparities. This work presents a model-agnostic pipeline for training causally fair machine learning models that address both direct and indirect forms of healthcare bias.",315.29,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09851v1_ViSIL Unified Evaluation of Information Loss in Mu.pdf,ViSIL: Unified Evaluation of Information Loss in Multimodal Video Captioning,"['Po-han Li', 'Shenghui Chen', 'Ufuk Topcu', 'Sandeep Chinchali']","Multimodal video captioning condenses dense footage into a structured format of keyframes and natural language. However, traditional metrics like BLEU or ROUGE fail to quantify information coverage across disparate modalities. To address this, the paper proposes the Video Summary Information Loss (ViSIL) score, an information-theoretic framework that quantifies the video information not captured by a summary via vision-language model (VLM) inference. ViSIL is a unified metric that enables direct comparison across multimodal summary formats despite their structural discrepancies. Results show that ViSIL scores correlate with both human and VLM performance on Video Question Answering (VQA) tasks and enable summary selection to optimize the trade-off between information loss and processing speed.",312.53,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09853v1_MedRedFlag Investigating how LLMs Redirect Misconc.pdf,MedRedFlag: Investigating how LLMs Redirect Misconceptions in Real-World Health Communication,"['Sraavya Sambara∗', 'Yuan Pu1', 'Ayman Ali1', 'Vishala Mishra1', 'Lionel Wong2', 'Monica Agrawal1']","This work investigates how large language models (LLMs) react to false premises embedded within real-world health questions. The authors develop a semi-automated pipeline to curate MedRedFlag, a dataset of 1100+ questions sourced from Reddit that require redirection. They then systematically compare responses from state-of-the-art LLMs to those from clinicians. The analysis reveals that LLMs often fail to redirect problematic questions, even when the problematic premise is detected, and provide answers that could lead to suboptimal medical decision making. The findings highlight a substantial gap in how LLMs perform under real-world health communication conditions, emphasizing critical safety concerns for patient-facing medical AI systems.",312.22,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09855v1_Thinking Long but Short Stable Sequential Test-Tim.pdf,Stable Sequential Test-Time Scaling for Large Reasoning Models,"['Michael R. Metel', 'Yufei Cui', 'Boxing Chen', 'Prasanna Parthasarathi']","Sequential test-time scaling is a training-free method to improve large reasoning model accuracy. However, it has limitations such as accuracy degradation and model instability as reasoning length is extended. This work presents a novel method, Min-Seek, which improves model accuracy significantly over a wide range of induced thoughts, stabilizing the accuracy of sequential scaling and removing the need for reasoning length fine-tuning. The method is inherently efficient, keeping only the KV pairs of one additional induced thought in the KV cache during reasoning. It can continue to reason well beyond a model's maximum context length and has linear computational complexity.",313.4,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09858v1_OUTLINEFORGE Hierarchical Reinforcement Learning w.pdf,Hierarchical Reinforcement Learning with Explicit States for Scientific Writing,"['Yilin Bao', 'Ziyao He', 'Zayden Yang']","Scientific paper generation requires document-level planning and factual grounding, but current large language models often fail in global structure, input coverage, and citation consistency. The authors present a reinforcement learning framework that casts scientific outline construction as a long-horizon planning problem over hierarchical document structures. Their approach models edit evolving outlines through structured actions, enabling the system to incrementally build a complete scientific manuscript. To support effective and stable learning, they introduce a two-stage optimization procedure consisting of backward outline reconstruction and forward value-guided reinforcement learning with rewards explicitly modeling scientific correctness, discourse coherence, and citation fidelity. Additionally, they introduce a benchmark for scientific paper generation that evaluates document planning, input utilization, reference faithfulness, outline organization, and content-level factual accuracy. Their results show consistent improvements over strong neural and LLM baselines, particularly in long-range structural coherence and citation reliability.",313.55,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09865v1_Advancing Model Refinement Muon-Optimized Distilla.pdf,Advancing Model Refinement: Muon-Optimized Distillation and Quantization for LLM Deployment,"['Jacob Sander', 'Brian Jalaian', 'V enkat R. Dasarivenkateswara']","Large Language Models (LLMs) enable advanced natural language processing but face deployment challenges on resource-constrained edge devices due to high computational, memory, and energy demands. Optimizing these models requires addressing three key challenges: acquiring task-specific data, fine-tuning for performance, and compressing models to accelerate inference while reducing resource demands. We propose an integrated framework combining GPTQ-based quantization, low-rank adaptation (LoRA), and a specialized data distillation process to significantly reduce model size and complexity while preserving or enhancing task-specific performance. By leveraging data distillation, knowledge distillation via Kullback-Leibler divergence, Bayesian hyperparameter optimization, and the Muon optimizer, our pipeline achieves up to 2×memory compression (e.g., reducing a 6GB model to 3GB) and enables efficient inference for specialized tasks. Empirical results demonstrate superior performance on standard LLM benchmarks compared to GPTQ quantization alone, with the Muon optimizer notably enhancing fine-tuned models' resistance to accuracy decay during quantization.",313.82,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09869v1_A Scoping Review of the Ethical Perspectives on An.pdf,A SCOPING REVIEW OF THE ETHICAL PERSPECTIVES ON ANTHROPOMORPHISING LARGELANGUAGEMODEL-BASED CONVERSATIONAL AGENTS,"['Andrea Ferrario', 'Rasita Vinay', 'Matteo Casserini', 'Alessandro Facchini']","Anthropomorphisation, the attribution of human-like qualities to non-human entities, has become increasingly relevant with the rise of large language model (LLM)-based conversational agents (CAs). Unlike earlier chatbots, LLM-based CAs generate interactional and linguistic cues that can increase engagement. However, anthropomorphisation raises ethical concerns such as deception, overreliance, and exploitative relationship framing. Some authors argue that anthropomorphic interaction may support autonomy, well-being, and inclusion. Despite increasing interest, literature remains fragmented and varies in how it defines, operationalizes, and normatively evaluates anthropomorphisation. This scoping review maps ethically oriented work on anthropomorphising LLM-based CAs across five databases and three preprint repositories, synthesizing conceptual foundations, ethical challenges and opportunities, and methodological approaches. It finds convergence on attribution-based definitions but substantial divergence in operationalization, a predominantly risk-forward normative framing, and limited empirical work linking observed interaction effects to actionable governance guidance. The review concludes with a research agenda and design/governance recommendations for ethically deploying anthropomorphic cues in LLM-based conversational agents.",312.25,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09871v1_Epistemology gives a Future to Complementarity in .pdf,EPISTEMOLOGY GIVES AFUTURE TOCOMPLEMENTARITY IN HUMAN-AI INTERACTIONS,"['Andrea Ferrario', 'Alessandro Facchini', 'Juan M. Durán']","Human-AI complementarity is the claim that a human supported by an AI system can outperform either alone in a decision-making process. The authors leverage epistemology to address theoretical challenges and argue that historical instances of complementarity function as evidence that a given human-AI interaction is a reliable epistemic process for a given predictive task. Together with other reliability indicators, complementarity contributes to the degree of reliability of human-AI teams when generating predictions, supporting practical reasoning for those affected by these outputs.",311.33,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09879v1_MedVL-SAM2 A unified 3D medical vision-language mo.pdf,MedVL-SAM2: A unified 3D medical vision–language model for multimodal reasoning and prompt-driven segmentation,"['Yang Xing', 'Jiong Wu', 'Savas Ozdemir', 'Ying Zhang', 'Yang Yang', 'Wei Shao', 'Kuang Gong']","Recent progress in medical vision-language models (VLMs) has achieved strong performance on image-level text-centric tasks such as report generation and visual question answering (VQA). However, achieving fine-grained visual grounding and volumetric spatial reasoning in 3D medical VLMs remains challenging. To address this challenge, we proposed MedVL-SAM2, a unified 3D medical multimodal model that concurrently supports report generation, VQA, and multi-paradigm segmentation, including semantic, referring, and interactive segmentation. MedVL-SAM2 integrates image-level reasoning and pixel-level perception through a cohesive architecture tailored for 3D medical imaging, and incorporates a SAM2-based volumetric segmentation module to enable precise multi-granular spatial reasoning. The model is trained in a multi-stage pipeline: it is first pre-trained on a large-scale corpus of 3D CT image-text pairs to align volumetric visual features with radiology-language embeddings. It is then jointly optimized with both language-understanding and segmentation objectives using a comprehensive 3D CT segmentation dataset. This joint training enables flexible interaction via language, point, or box prompts, thereby unifying high-level visual reasoning with spatially precise localization. Our unified architecture delivers state-of-the-art performance across report generation, VQA, and multiple 3D segmentation tasks. Extensive analyses further show that the model provides reliable 3D visual grounding, controllable interactive segmentation, and robust cross-modal reasoning, demonstrating that high-level semantic reasoning and precise 3D localization can be achieved.",312.83,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09881v1_Transition Matching Distillation for Fast Video Ge.pdf,Transition Matching Distillation for Fast Video Generation,"['Weili Nie', 'Julius Berner', 'Nanye Ma', 'Chao Liu', 'Saining Xie', 'Arash Vahdat']","This work presents Transition Matching Distillation (TMD), a novel framework for distilling video diffusion models into efficient few-step generators. The central idea is to match the multi-step denoising trajectory of a diffusion model with a few-step probability transition process, where each transition is modeled as a lightweight conditional flow. The authors decompose the original diffusion backbone into two components: a main backbone and a flow head. They introduce a flow head to the pretrained model and adapt it into a conditional flow map. Distribution matching distillation is applied to the student model with flow head rollout in each transition step. Extensive experiments demonstrate that TMD provides a flexible and strong trade-off between generation speed and visual quality, outperforming existing distilled models under comparable inference costs.",310.79,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09883v1_Beyond Rule-Based Workflows An Information-Flow-Or.pdf,Beyond Rule-Based Workflows: An Information-Flow-Orchestrated Multi-Agents Paradigm via Agent-to-Agent Communication from CORAL,"['Xinxing Ren', 'Quagmire Zang', 'Caelum Forder', 'Suman Deb', 'Ahsen Tahir', 'Roman J. Georgio', 'Peter Carroll', 'Zekun Guo']","Recent advances in Large Language Models (LLMs) have enabled the development of intelligent agents capable of performing complex reasoning and decision-making tasks. This paper proposes an Information-Flow-Orchestrated Multi-Agent Paradigm via Agent-to-Agent (A2A) Communication from CORAL, in which a dedicated information flow orchestrator continuously monitors task progress and dynamically coordinates other agents through the A2A toolkit using natural language, without relying on predefined workflows. The approach is evaluated on the general-purpose benchmark GAIA, using the representative workflow-based MAS OWL as the baseline while controlling for agent roles and underlying models. Under the pass@1 setting, our method achieves 63.64% accuracy, outperforming OWL's 55.15% by 8.49 percentage points with comparable token consumption. Further case-level analysis shows that our paradigm enables more flexible task monitoring and more robust handling of edge cases. Our implementation is publicly available at: https://github.com/Coral-Protocol/Beyond-Rule-Based-Workflows.",310.79,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09896v1_The Algorithmic Gaze An Audit and Ethnography of t.pdf,The Algorithmic Gaze: An Audit and Ethnography of the LAION-Aesthetics Predictor Model,"['Jordan Taylor', 'William Agnew', 'Maarten Sap', 'Sarah E. Fox', 'Haiyi Zhu']","The paper examines the LAION-Aesthetics Predictor (LAP) model, which is used to curate datasets for training visual generative image models and evaluate AI-generated images. The authors find that LAP disproportionately filters images with captions mentioning women, while filtering out images with captions mentioning men or LGBTQ+ people. They also find that LAP rates realistic images of landscapes, cityscapes, and portraits from western and Japanese artists highly. The authors perform a digital ethnography of public materials related to the creation of LAP and find that the development of LAP reflects biases found in their audits, such as the aesthetic scores primarily coming from English-speaking photographers and western AI-enthusiasts. The authors discuss how aesthetic evaluation can perpetuate representational harms and call for more pluralistic evaluation in AI development.",310.41,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09902v1_A Novel Contrastive Loss for Zero-Day Network Intr.pdf,A Novel Contrastive Loss for Zero-Day Network Intrusion Detection,"['Jack Wilkie', 'Hanan Hindy', 'Craig Michie', 'Christos Tachtatzis', 'James Irvine', 'Robert Atkinson']","Machine learning has achieved state-of-the-art results in network intrusion detection; however, its performance significantly degrades when confronted by a new attack class—zero-day attacks. This work proposes a novel contrastive loss function which maintains the advantages of other contrastive learning-based approaches (robustness to imbalanced data) but can also generalize to zero-day attacks. Unlike anomaly detectors, this model learns the distributions of benign traffic using both benign and known malign samples, achieving significant performance improvements. The proposed approach is experimentally verified on the Lycos2017 dataset, achieving AUROC improvements of 0.000065 and 0.060883 over previous models in known and zero-day attack detection, respectively. Finally, the proposed method is extended to open-set recognition, achieving OpenAUC improvements of 0.170883 over existing approaches.",314.8,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09913v1_Continuum Memory Architectures for Long-Horizon LL.pdf,Continuum Memory Architectures for Long-Horizon LLM Agents,"['Joe Logan', 'Mode7 GK']","Retrieval-augmented generation (RAG) has become the default strategy for providing large language model (LLM) agents with contextual knowledge. However, RAG treats memory as a stateless lookup table, leading to issues with persistence, read-only retrieval, and temporal continuity. This paper introduces the Continuum Memory Architecture (CMA), a class of systems that maintain and update internal state across interactions through persistent storage, selective retention, associative routing, temporal chaining, and consolidation into higher-order abstractions. The authors specify the architectural requirements CMA imposes and demonstrate consistent behavioral advantages on tasks that stress memory dynamics, while highlighting open challenges around latency, drift, and interpretability.",309.0,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09921v1_Learning to Decode in Parallel Self-Coordinating N.pdf,Learning to Decode in Parallel: Self-Coordinating Neural Network for Real-Time Quantum Error Correction,"['Kai Zhang', 'Zhengzhong Yi', 'Shaojun Guo', 'Linghang Kong', 'Situ Wang', 'Xiaoyu Zhan', 'Tan He', 'Weiping Lin', 'Tao Jiang', 'Dongxin Gao', 'Yiming Zhang', 'Fangming Liu', 'Fang Zhang', 'Zhengfeng Ji', 'Fusheng Chen', 'Jianxin Chen']","Fast, reliable decoders are pivotal components for enabling fault-tolerant quantum computation. Neural network decoders like AlphaQubit have demonstrated significant potential, achieving higher accuracy than traditional human-designed decoding algorithms. However, existing implementations of neural network decoders face challenges in real-time applications, such as the need for parallel processing and self-coordination. This paper presents a self-coordinating neural network designed to address these challenges, enabling real-time quantum error correction.",313.96,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09923v1_CaMeLs Can Use Computers Too System-level Security.pdf,SYSTEM-LEVELSECURITY FORCOMPUTERUSEAGENTS,"['Hanna Foerster∗', 'Robert Mullins', 'Tom Blanchard∗', 'Nicolas Papernot', 'Kristina Nikolić', 'Florian Tramèr', 'Ilia Shumailov', 'Cheng Zhang', 'Yiren Zhao']","AI agents are vulnerable to prompt injection attacks, where malicious content hijacks agent behavior to steal credentials or cause financial loss. The only known robust defense is architectural isolation that strictly separates trusted task planning from untrusted environment observations. However, applying this design to Computer Use Agents (CUAs) – systems that automate tasks by viewing screens and executing actions – presents a fundamental challenge. We resolve this tension by demonstrating that UI workflows, while dynamic, are structurally predictable. We introduce Single-Shot Planning for CUAs, where a trusted planner generates a complete execution graph with conditional branches before any observation of potentially malicious content, providing provable control flow integrity guarantees against arbitrary instruction injections. Although this architectural isolation successfully prevents instruction injections, we show that additional measures are needed to prevent Branch Steering attacks, which manipulate UI elements to trigger unintended valid paths within the plan. We evaluate our design on OSWorld, and retain up to 57% of the performance of frontier models while improving performance for smaller open-source models by up to 19%, demonstrating that rigorous security and utility can coexist in CUAs.",311.93,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09929v1_Hallucination Detection and Mitigation in Large La.pdf,Hallucination Detection and Mitigation in Large Language Models,"['Ahmad Pesaranghader', 'Erin Li']","Large Language Models (LLMs) and Large Reasoning Models (LRMs) offer transformative potential in high-stakes domains like finance and law, but their tendency to hallucinate poses a critical reliability risk. This paper introduces a comprehensive operational framework for hallucination management, built on a continuous improvement cycle driven by root cause awareness. The framework categorizes hallucination sources into model, data, and context-related factors, allowing targeted interventions over generic fixes. It integrates multi-faceted detection methods (e.g., uncertainty estimation, reasoning consistency) with stratified mitigation strategies (e.g., knowledge grounding, confidence calibration). The framework is demonstrated through a tiered architecture and a financial data extraction case study, where model, context, and data tiers form a closed feedback loop for progressive reliability enhancement. This systematic, scalable methodology provides a way to build trustworthy generative AI systems in regulated environments.",310.57,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09933v1_Malware Classification using Diluted Convolutional.pdf,Malware Classification using Diluted Convolutional Neural Network with Fast Gradient Sign Method,"['1st Ashish Anand', '2nd Bhupendra Singh', '3rd Sunil Khemka', '4th Bireswar Banerjee', '5th Vishi Singh Bhatia', '6th Piyush Ranjan']","A malware classification method using Fast Gradient Sign Method with Diluted Convolutional Neural Network (FGSM-DICNN) is proposed. DICNN contains diluted convolutions which increase receptive field, enabling the model to capture dispersed malware patterns across long ranges using fewer features without adding parameters. FGSM strategy enhances accuracy by using one-step perturbations during training, providing a lower computational cost. This integration helps manage high classification accuracy while reducing dependence on extensive feature sets. The proposed FGSM-DICNN model attains 99.44% accuracy, outperforming other existing approaches such as Custom Deep Neural Network (DCNN).",314.22,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09949v2_Kinematic Tokenization Optimization-Based Continuo.pdf,Kinematic Tokenization: Optimization-Based Continuous-Time Tokens for Learnable Decision Policies in Noisy Time Series,"['Griffin M. Kearney, Ph.D.']","Transformers are designed for discrete tokens, yet many real-world signals are continuous processes observed through noisy sampling. Discrete tokenizations can be brittle in low signal-to-noise regimes. The authors introduce Kinematic Tokenization, an optimization-based continuous-time representation that reconstructs an explicit spline from noisy measurements and tokenizes local spline coefficients (position, velocity, acceleration, jerk). This is applied to financial time series data in the form of asset prices in conjunction with trading volume profiles. Across a multi-asset daily-equity testbed, the authors use a risk-averse asymmetric classification objective as a stress test for learnability. Under this objective, several discrete baselines collapse to an absorbing cash policy (the Liquidation Equilibrium), whereas the continuous spline tokens sustain calibrated, non-trivial action distributions and stable policies. These results suggest that explicit continuous-time tokens can improve the learnability and calibration of selective decision policies in noisy time series under abstention-inducing losses.",311.16,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09966v1_A Sustainable AI Economy Needs Data Deals That Wor.pdf,A Sustainable AI Economy Needs Data Deals That Work for Generators,"['Ruoxi Jia∗', 'Luis Oala∗', 'Wenjie Xiong', 'Suqin Ge', 'Jiachen T. Wang', 'Feiyang Kang', 'Dawn Song']","The authors argue that the machine learning value chain is structurally unsustainable due to an economic data processing inequality. They analyze seventy-three public data deals and find that the majority of value accrues to aggregators, with creator royalties rounding to zero and widespread opacity of deal terms. The authors identify three structural faults—missing provenance, asymmetric bargaining power, and non-dynamic pricing—as the operational machinery of this inequality. They propose an Equitable Data-Value Exchange (EDVEX) Framework to enable a minimal market that benefits all participants.",310.18,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09972v1_Chinese Labor Law Large Language Model Benchmark.pdf,Chinese Labor Law Large Language Model Benchmark,"['Zixun Lan', 'Maochun Xu', 'Yifan Ren', 'Rui Wu', 'Jianghui Zhou', 'Xueyang Cheng', 'Jian’an Ding', 'Xinheng Wang', 'Mingmin Chi', 'Fei Ma']","Recent advancements in large language models (LLMs) have led to substantial progress in domain-specific applications, particularly within the legal domain. Although general-purpose models such as GPT-4 exhibit promising performance on basic legal tasks, they often struggle with specialized subdomains that demand precise legal knowledge, complex reasoning, and contextual sensitivity. To address these limitations, this paper presents LaborLawLLM, a legal large language model specifically tailored to the labor law domain—a subfield marked by intricate statutory structures, frequent disputes, and high real-world impact. The paper constructs LabourLawBench, a comprehensive benchmark comprising diverse labor law tasks such as legal provision citation, knowledge-based question answering, case classification, compensation computation, named entity recognition, and legal case analysis. The evaluation framework integrates both objective metrics (e.g., ROUGE-L, accuracy, F1, soft-F1) and subjective assessments based on GPT-4 scoring. Experimental results demonstrate that LaborLawLLM significantly outperforms both general-purpose and existing legal-specific LLMs across all task categories. This work not only fills a key research gap in labor law-specific legal AI but also offers a scalable methodology for developing specialized LLMs in other legal subfields, thereby enhancing the accuracy, reliability, and societal value of legal AI applications.",313.72,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09974v1_SPRInG Continual LLM Personalization via Selective.pdf,SPRInG: Continual LLM Personalization via Selective Parametric Adaptation and Retrieval-Interpolated Generation,"['Seoyeon Kim', 'Jaehyung Kim']","Personalizing Large Language Models typically relies on static retrieval or one-time adaptation, assuming user preferences remain invariant over time. However, real-world interactions are dynamic, where user interests continuously evolve, posing a challenge for models to adapt to preference drift without catastrophic forgetting. Standard continual learning approaches often struggle in this context, as they indiscriminately update on noisy interaction streams, failing to distinguish genuine preference shifts from transient contexts. To address this, we introduce SPRING, a novel semi-parametric framework designed for effective continual personalization. During training, SPRING employs drift-driven selective adaptation, which utilizes a likelihood-based scoring function to identify high-novelty interactions. This allows the model to selectively update the user-specific adapter on drift signals while preserving hard-to-learn residuals in a replay buffer. During inference, we apply strict relevance gating and fuse parametric knowledge with retrieved history via logit interpolation. Experiments on the long-form personalized generation benchmark demonstrate that SPRING outperforms existing baselines, validating its robustness for real-world continual personalization.",300.55,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09980v1_Performance of AI agents based on reasoning langua.pdf,ALD optimization using reasoning LLMs,['Angel Yanguas-Gil'],"In this work, the authors explore the performance and behavior of reasoning large language models (LLMs) in optimizing atomic layer deposition (ALD) processes. The agent, built on top of a reasoning LLM, autonomously finds optimal dose times for an ALD precursor and coreactant without prior knowledge of the process, including whether it is self-limited. The agent interacts iteratively with an ALD reactor in a fully unsupervised manner. The results show that agents based on reasoning models like OpenAI’s o3 and GPT5 consistently succeeded at completing this optimization task. However, significant run-to-run variability was observed due to the non-deterministic nature of the model's response. To understand the logic followed by the reasoning model, the agent uses a two-step process: first generating an open response detailing the reasoning process, which is then transformed into a structured output. Analysis of these reasoning traces revealed that the logic of the model was sound and based on the notions of self-limited process and saturation expected in the case of ALD. However, the agent can sometimes be misled by its own prior choices when exploring the optimization space.",309.42,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.09982v1_Context Volume Drives Performance Tackling Domain .pdf,Context Volume Drives Performance: Tackling Domain Shift in Extremely Low-Resource Translation via RAG,"['David Samuel Setiawan', 'Raphaël Merx', 'Jey Han Lau']","Neural Machine Translation (NMT) models for low-resource languages suffer significant performance degradation under domain shift. This work addresses the challenge using Dhao, an indigenous language of Eastern Indonesia with no digital footprint beyond the New Testament (NT). When applied to the Old Testament (OT), a standard NMT model fine-tuned on the NT drops from an in-domain score of 36.17 chrF++ to 27.11 chrF++. To recover this loss, a hybrid framework is introduced where a fine-tuned NMT model generates an initial draft, which is then refined by a Large Language Model (LLM) using Retrieval-Augmented Generation (RAG). The final system achieves 35.21 chrF++ (+8.10 recovery), effectively matching the original in-domain quality. The analysis reveals that the performance is driven primarily by the number of retrieved examples rather than the choice of retrieval algorithm. Qualitative analysis confirms that the LLM acts as a robust 'safety net,' repairing severe failures in zero-shot domains.",311.69,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10010v1_VERHallu Evaluating and Mitigating Event Relation .pdf,VERHallu: Evaluating and Mitigating Event Relation Hallucination in Video Large Language Models,"['Zefan Zhang', 'Kehua Zhu', 'Shijie Jiang', 'Hongyuan Lu', 'Shengkai Sun', 'Tian Bai*']","Video Large Language Models (VideoLLMs) exhibit various types of hallucinations. Existing research has primarily focused on hallucinations involving the presence of events, objects, and scenes in videos, while largely neglecting event relation hallucination. In this paper, we introduce a novel benchmark for evaluating the Video Event Relation Hallucination, named VERHallu. This benchmark focuses on causal, temporal, and subevent relations between events, encompassing three types of tasks: relation classification, question answering, and counterfactual question answering, for a comprehensive evaluation of event relation hallucination. Additionally, it features counterintuitive video scenarios that deviate from typical pretraining distributions, with each sample accompanied by human-annotated candidates covering both vision-language and pure language biases. Our analysis reveals that current state-of-the-art VideoLLMs struggle with dense-event relation reasoning, often relying on prior knowledge due to insufficient use of frame-level cues. Although these models demonstrate strong grounding capabilities for key events, they often overlook the surrounding subevents, leading to an incomplete and inaccurate understanding of event relations. To tackle this, we propose a Key-Frame Propagating (KFP) strategy, which reallocates frame-level attention within intermediate layers to enhance multi-event understanding. Experiments show it effectively mitigates the event relation hallucination without affecting inference speed.",309.07,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10011v1_Memo-SQL Structured Decomposition and Experience-D.pdf,Memo-SQL: Structured Decomposition and Experience-Driven Self-Correction for Training-Free NL2SQL,"['Zerui Yang', 'Weichuan Wang', 'Yanwei Xu', 'Linqi Song', 'Yudai Matsuda', 'Wei Han', 'Bo Bai']","Existing NL2SQL systems rely on in-context learning with only correct examples, overlooking historical error-fix pairs. Memo-SQL addresses these issues through structured decomposition and experience-aware self-correction. It applies entity-wise, hierarchical, and atomic sequential strategies for decomposition and uses a dynamic memory of successful queries and historical error-fix pairs for correction. Memo-SQL achieves 68.5% execution accuracy on BIRD, setting a new state of the art among open, zero-fine-tuning methods, while using over 10× fewer resources than prior test-time scaling approaches.",309.22,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10018v1_Empowering Older Adults in Digital Technology Use .pdf,Empowering Older Adults in Digital Technology Use with Foundation Models,"['Hasti Sharifi', 'Homaira Huda Shomee', 'Sourav Medya', 'Debaleena Chattopadhyay']","This study examines communication challenges faced by older adults in using digital applications and explores AI-based approaches to mitigate them. A diary study with English-speaking, community-dwelling older adults identified four key communication challenges: verbosity, incompleteness, over-specification, and under-specification. The study evaluated how foundation models can paraphrase older adults' queries to improve solution accuracy. Two controlled experiments followed: one with younger adults evaluating AI-rephrased queries and another with older adults evaluating AI-generated solutions. The prompt-chaining approach using the large language model, GPT-4o, elicited contextual details, paraphrased the original query, and generated a solution. AI-rephrased queries significantly improved solution accuracy and Google search results. Younger adults better understood AI-rephrased queries and reported greater confidence and ease. Older adults reported high perceived ability to answer contextual questions and follow solutions, with high confidence and ease. The OATS dataset demonstrated strong fidelity and face validity, offering a scalable resource for developing equitable AI systems that better serve aging populations.",311.01,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10025v1_Structured Personality Control and Adaptation for .pdf,Structured Personality Control and Adaptation for LLM Agents,"['Jinpeng Wang', 'Xinyu Jia', 'Wei Wei Heng', 'Yuquan Li', 'Binbin Shi', 'Qianlei Chen', 'Guannan Chen', 'Junxia Zhang', 'Yuyu Yin']","Large Language Models (LLMs) are increasingly shaping human–computer interaction (HCI), from personalized assistants to social simulations. Beyond language competence, researchers are exploring whether LLMs can exhibit human-like characteristics that influence engagement, decision-making, and perceived realism. Personality, in particular, is critical, yet existing approaches often struggle to achieve both nuanced and adaptable expression. We present a framework that models LLM personality via Jungian psychological types, integrating three mechanisms: a dominant–auxiliary coordination mechanism for coherent core expression, a reinforcement–compensation mechanism for temporary adaptation to context, and a reflection mechanism that drives long-term personality evolution. This design allows the agent to maintain nuanced traits while dynamically adjusting to interaction demands and gradually updating its underlying structure. Personality alignment is evaluated using Myers–Briggs Type Indicator questionnaires and tested under diverse challenge scenarios as a preliminary structured assessment. Findings suggest that evolving, personality-aware LLMs can support coherent, context-sensitive interactions, enabling naturalistic agent design in HCI.",313.48,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10029v1_PaperScout An Autonomous Agent for Academic Paper .pdf,PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization,"['Tingyue Pan', 'Jie Ouyang', 'Mingyue Cheng', 'Qingchuan Li', 'Zirui Liu', 'Mingfan Pan', 'Shuo Yu', 'Qi Liu']","Academic paper search is a fundamental task in scientific research, yet most existing approaches rely on rigid, predefined workflows that struggle with complex, conditional queries. To address this limitation, we propose PaperScout, an autonomous agent that reformulates paper search as a sequential decision-making process. Unlike static workflows, PaperScout dynamically decides whether, when, and how to invoke search and expand tools based on accumulated retrieval context. We introduce Proximal Sequence Policy Optimization (PSPO), a process-aware, sequence-level policy optimization method that aligns optimization with agent-environment interaction. Comprehensive experiments on both synthetic and real-world benchmarks demonstrate that PaperScout significantly outperforms strong workflow-driven and RL baselines in both recall and relevance, validating the effectiveness of our adaptive agentic framework and optimization strategy.",313.01,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10031v1_FilDeep Learning Large Deformations of Elastic-Pla.pdf,FilDeep: Learning Large Deformations of Elastic-Plastic Solids with Multi-Fidelity Data,"['Jianheng Tang', 'Shilong Tao', 'Zhe Feng', 'Haonan Sun', 'Menglu Wang', 'Zhanxing Zhu', 'Yunhuai Liu']","The scientific computation of large deformations in elastic-plastic solids is crucial in various manufacturing applications. Traditional numerical methods exhibit several inherent limitations, prompting Deep Learning (DL) as a promising alternative. The effectiveness of current DL techniques typically depends on the availability of high-quantity and high-accuracy datasets, which are yet difficult to obtain in large deformation problems. During the dataset construction process, a dilemma stands between data quantity and data accuracy, leading to suboptimal performance in the DL models. To address this challenge, the authors propose FilDeep, a Fidelity-based Deep Learning framework for large Deformation of elastic-plastic solids. Our FilDeep aims to resolve the quantity-accuracy dilemma by simultaneously training with both low-fidelity and high-fidelity data, where the former provides greater quantity but lower accuracy, while the latter offers higher accuracy but in less quantity. In FilDeep, attention-enabled cross-fidelity modules are proposed to effectively capture long-range physical interactions across Multi-Fidelity (MF) data. Extensive experiments demonstrate that our FilDeep consistently achieves state-of-the-art performance and can be efficiently deployed in manufacturing.",310.18,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10038v1_What Understanding Means in AI-Laden Astronomy.pdf,Understanding in AI-Laden Astronomy,"['Yuan-Sen Ting', 'André Curtis-Trudel', 'Siyu Y ao']","The rapid integration of artificial intelligence (AI) in astronomical research has led to questions about the nature of discovery, progress, and understanding. Philosophers and historians of science have long grappled with these issues, but they are often excluded from mainstream discussions about AI in research. This paper discusses the importance of philosophical contributions in navigating the transformation of astronomy. It highlights the need for conceptual engineering, critical examination of assumptions, and frameworks for abstraction in understanding the role of AI in science. The authors propose fostering interdisciplinary dialogue through workshops and emphasize the essential role of philosophy in evaluating scientific contributions in an era where much of the labor can be automated.",314.33,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10073v1_ReaMIL Reasoning- and Evidence-Aware Multiple Inst.pdf,ReaMIL: Reasoning- and Evidence-Aware Multiple Instance Learning for Whole-Slide Histopathology,"['Hyun Do Jung1', 'Jungwon Choi2', 'Hwiyoung Kim1*']","We introduce ReaMIL, a multiple instance learning approach for whole-slide histopathology that adds a light selection head to a strong MIL backbone. The head produces soft per-tile gates and is trained with a budgeted-sufficiency objective: a hinge loss that enforces the true-class probability to be ≥τ using only the kept evidence, under a sparsity budget on the number of selected tiles. The budgeted-sufficiency objective yields small, spatially compact evidence sets without sacrificing baseline performance. Across TCGA-NSCLC (LUAD vs. LUSC), TCGA-BRCA (IDC vs. Others), and PANDA, ReaMIL matches or slightly improves baseline AUC and provides quantitative evidence-efficiency diagnostics. On NSCLC, it attains AUC 0.983 with a mean minimal sufficient K (MSK) ≈ 8.2 tiles at τ = 0.90 and AUKC ≈ 0.864, showing that class confidence rises sharply and stabilizes once a small set of tiles is kept. The method requires no extra supervision, integrates seamlessly with standard MIL training, and naturally yields slide-level overlays. We report accuracy alongside MSK, AUKC, and contiguity for rigorous evaluation of model behavior on WSIs.",311.85,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10079v1_Sparse-RL Breaking the Memory Wall in LLM Reinforc.pdf,Sparse-RL: Breaking the Memory Wall in LLM Reinforcement Learning via Stable Sparse Rollouts,"['Sijia Luo', 'Xiaokang Zhang', 'Yuxuan Hu', 'Bohan Zhang', 'Ke Wang', 'Jinbo Su', 'Mengshu Sun', 'Lei Liang', 'Jing Zhang']","Sparse-RL addresses the memory bottleneck in Long-Short Term Memory (LSTM) training by introducing stable RL training under sparse rollouts. It incorporates Sparsity-Aware Rejection Sampling and Importance-based Reweighting to correct off-policy bias introduced by compression-induced information loss. Experimental results show that Sparse-RL reduces rollout overhead compared to dense baselines while preserving performance. Additionally, it inherently implements sparsity-aware training, significantly enhancing model robustness during sparse inference deployment.",309.91,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10088v1_State of AI An Empirical 100 Trillion Token Study .pdf,State of AI: An Empirical 100 Trillion Token Study with OpenRouter,"['Malika Aubakirova∗†', 'Alex Atallah ‡', 'Chris Clark ‡', 'Justin Summerville ‡', 'Anjney Midha †']","This work analyzes over 100 trillion tokens of real-world interactions with large language models (LLMs) across various tasks, geographies, and time. It observes substantial adoption of open-weight models, the popularity of creative roleplay and coding assistance, and the rise of agentic inference. The study identifies foundational cohorts of early users and discusses implications for model builders, AI developers, and infrastructure providers. The findings highlight the complexity and multifaceted nature of user engagement with LLMs in real-world scenarios.",314.86,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10090v1_Difficulty-guided Sampling Bridging the Target Gap.pdf,Difficulty-guided Sampling: Bridging the Target Gap between Dataset Distillation and Downstream Tasks,"['Mingzhuo Lia', 'Guang Lia', 'Linfeng Ye', 'Jiafeng Mao', 'Takahiro Ogawa', 'Konstantinos N. Plataniotis', 'Miki Haseyama']","In this paper, we propose difficulty-guided sampling (DGS) to bridge the target gap between the distillation objective and the downstream task, therefore improving the performance of dataset distillation. We introduce the concept of difficulty and propose DGS as a plug-in post-stage sampling module, focusing on the downstream task of image classification. Difficulty-aware guidance (DAG) is also proposed to explore the effect of difficulty in the generation process.",311.5,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10092v1_LeMoF Level-guided Multimodal Fusion for Heterogen.pdf,LEMOF: LEVEL-GUIDEDMULTIMODALFUSION FOR HETEROGENEOUSCLINICALDATA,"['Jongseok Kim', 'Seongae Kang', 'Jonghwan Shin', 'Yuhan Lee', 'Ohyun Jo']","Multimodal clinical prediction is widely used to integrate heterogeneous data such as Electronic Health Records (EHR) and biosignals. However, existing methods tend to rely on static modality integration schemes and simple fusion strategies, failing to fully exploit modality-specific representations. This paper proposes Level-guided Modal Fusion (LeMoF), a novel framework that selectively integrates level-guided representations within each modality. Each level refers to a representation extracted from a different layer of the encoder. LeMoF explicitly separates and learns global modality-level predictions from level-specific discriminative representations, enabling balanced performance between prediction stability and discriminative capability. Experiments on length of stay prediction using ICU data demonstrate that LeMoF consistently outperforms existing state-of-the-art multimodal fusion techniques across various encoder configurations.",314.88,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10094v1_V-Zero Self-Improving Multimodal Reasoning with Ze.pdf,V-Zero: Self-Improving Multimodal Reasoning with Zero Annotation,"['Han Wang', 'Yi Yang', 'Jingyuan Hu', 'Minfeng Zhu', 'Wei Chen']","Recent advances in multimodal learning have significantly enhanced the reasoning capabilities of vision-language models (VLMs). However, state-of-the-art approaches rely heavily on large-scale human-annotated datasets, which are costly and time-consuming to acquire. To overcome this limitation, we introduce V-Zero, a general post-training framework that facilitates self-improvement using exclusively unlabeled images. V-Zero establishes a co-evolutionary loop by instantiating two distinct roles: a Questioner and a Solver. The Questioner learns to synthesize high-quality, challenging questions by leveraging a dual-track reasoning reward that contrasts intuitive guesses with reasoned results. The Solver is optimized using pseudo-labels derived from majority voting over its own sampled responses. Both roles are trained iteratively via Group Relative Policy Optimization (GRPO), driving a cycle of mutual enhancement. Remarkably, with no single human annotation, V-Zero achieves consistent performance gains on Qwen2.5-VL-7B-Instruct, improving visual mathematical reasoning by +1.7 and general vision-centric by +2.6, demonstrating the potential of self-improvement in multimodal systems.",313.19,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10101v2_Matrix as Plan Structured Logical Reasoning with F.pdf,Matrix as Plan: Structured Logical Reasoning with Feedback-Driven Replanning,"['Ke Chen', 'Jiandian Zeng', 'Zihao Peng', 'Guo Li', 'Guangxue Zhang', 'Tian Wang']","As knowledge and semantics on the web grow increasingly complex, enhancing Large Language Models (LLMs)’ comprehension and reasoning capabilities has become particularly important. Chain-of-Thought (CoT) prompting has been shown to enhance the reasoning capabilities of LLMs. However, it still falls short on logical reasoning tasks that rely on symbolic expressions and strict deductive rules. Neuro-symbolic methods address this gap by enforcing formal correctness through external solvers. Yet these solvers are highly format-sensitive, and small instabilities in model outputs can lead to frequent processing failures. The LLM-driven approaches avoid parsing brittleness, but they lack structured representations and process-level error-correction mechanisms. To further enhance the logical reasoning capabilities of LLMs, the authors propose MatrixCoT, a structured CoT framework with a matrix-based plan. Specifically, they normalize and type natural language expressions and attach explicit citation fields, and introduce a matrix-based planning method to preserve global relations among steps. The plan thus becomes a verifiable artifact and execution becomes more stable. For verification, they also add a feedback-driven replanning mechanism. Under semantic-equivalence constraints, it identifies omissions and defects, rewrites and compresses the dependency matrix, and produces a more trustworthy final answer. Experiments on five logical-reasoning benchmarks and five LLMs show that MatrixCoT enhances both the robustness and interpretability of LLMs when tackling complex symbolic reasoning tasks, while maintaining competitive performance.",313.7,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10103v1_FlowAct-R1 Towards Interactive Humanoid Video Gene.pdf,FlowAct-R1: Towards Interactive Humanoid Video Generation,"['Lizhen Wang', 'Yongming Zhu', 'Zhipeng Ge', 'Youwei Zheng', 'Longhao Zhang', 'Tianshu Hu†', 'Shiyang Qin', 'Mingshuang Luo', 'Jiaxu Zhang', 'Xin Chen', 'Yulong Wang', 'Zerong Zheng', 'Jianwen Jiang', 'Chao Liang', 'Weifeng Chen', 'Xing Wang', 'Yuan Zhang', 'Mingyuan Gao']","Interactive humanoid video generation aims to synthesize lifelike visual agents that can engage with humans through continuous and responsive video. FlowAct-R1, a framework specifically designed for real-time interactive humanoid video generation, enables the streaming synthesis of video with arbitrary durations while maintaining low-latency responsiveness. The paper introduces a chunkwise diffusion forcing strategy, complemented by a novel self-forcing variant, to alleviate error accumulation and ensure long-term temporal consistency during continuous interaction. By leveraging efficient distillation and system-level optimizations, FlowAct-R1 achieves a stable 25fps at 480p resolution with a time-to-first-frame (TTFF) of only around 1.5 seconds. The proposed method provides holistic and fine-grained full-body control, enabling the agent to transition naturally between diverse behavioral states in interactive scenarios. Experimental results demonstrate exceptional behavioral vividness and perceptual realism, while maintaining robust generalization across diverse character styles.",315.27,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10104v1_MathDoc Benchmarking Structured Extraction and Act.pdf,MathDoc: Benchmarking Structured Extraction and Active Refusal on Noisy Mathematics Exam Papers,"['Chenyue Zhou', 'Jiayi Tuo', 'Shitong Qin', 'Wei Dai', 'Mingxuan Wang', 'Ziwei Zhao', 'Duoyang Li', 'Shiyang Su', 'Yanxi Lu', 'Yanbiao Ma']","The paper introduces MathDoc, a benchmark for document-level information extraction from authentic high school mathematics exam papers. It contains 3,609 carefully curated questions with real-world artifacts and explicitly includes unrecognizable samples to evaluate active refusal behavior. The authors propose a multi-dimensional evaluation framework covering stem accuracy, visual similarity, and refusal capability. Experiments on state-of-the-art MLLMs show that while end-to-end models achieve strong extraction performance, they consistently fail to refuse illegible inputs, instead producing confident but invalid outputs. These results highlight a critical gap in current MLLMs and establish MathDoc as a benchmark for assessing model reliability under degraded document conditions.",313.15,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10108v1_SIN-Bench Tracing Native Evidence Chains in Long-C.pdf,SIN-Bench: Tracing Native Evidence Chains in Long-Context Multimodal Scientific Interleaved Literature,"['Yiming Ren', 'Junjie Wang', 'Yuxin Meng', 'Yihang Shi', 'Zhiqiang Lin', 'Ruihang Chu', 'Yiran Xu', 'Ziming Li', 'Yunfei Zhao', 'Zihan Wang', 'Yu Qiao', 'Ruiming Tang', 'Minghao Liu', 'Yujiu Yang']","Evaluating whether multimodal large language models truly understand long-form scientific papers remains challenging. Answer-only metrics and synthetic 'Needle-In-A-Haystack' tests often reward answer matching without requiring a causal, evidence-linked reasoning trace in the document. The paper proposes the 'Fish-in-the-Ocean' (FITO) paradigm, which requires models to construct explicit cross-modal evidence chains within native scientific documents. To operationalize FITO, SIN-Data, a scientific interleaved corpus, and SIN-Bench with four progressive tasks (SIN-Find, SIN-Verify, SIN-QA, SIN-Summary) are built. The authors introduce 'No Evidence, No Score' scoring predictions when grounded to verifiable anchors and diagnose evidence quality via matching, relevance, and logic. Experiments on eight MLLMs show that grounding is the primary bottleneck, with Gemini-3-pro achieving the best average overall score (0.566) and GPT-5 attaining the highest SIN-QA answer accuracy (0.767) but underperforming on evidence-aligned overall scores, exposing a gap between correctness and traceable support.",309.99,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10112v1_Repository Intelligence Graph Deterministic Archit.pdf,Repository Intelligence Graph: Deterministic Architectural Map for LLM Code Assistants,"['Tsvi Cherny-Shahar', 'Amiram Yehudai']","Repository aware coding agents often struggle to recover build and test structure, especially in multilingual projects where cross language dependencies are encoded across heterogeneous build systems and tooling. We introduce the Repository Intelligence Graph (RIG), a deterministic, evidence-backed architectural map that represents buildable components, aggregators, runners, tests, external packages, and package managers, connected by explicit dependency and coverage edges that trace back to concrete build and test definitions. We also present SPADE, a deterministic extractor that constructs RIG from build and test artifacts (currently with an automatic CMake plugin based on the CMake File API and CTest metadata), and exposes RIG as an LLM-friendly JSON view that agents can treat as the authoritative description of repository structure. We evaluate three commercial agents (Claude Code, Cursor, Codex) on eight repositories spanning low to high build-oriented complexity, including the real-world MetaFFI project. Providing RIG improves mean accuracy by 12.2% and reduces completion time by 53.9%, yielding a mean 57.8% reduction in seconds per correct answer. Gains are larger in multilingual repositories, which improve by 17.7% in accuracy and 69.5% in efficiency on average, compared to 6.6% and 46.1% in single language repositories. Qualitative analysis suggests that RIG shifts failures from structural misunderstandings toward reasoning mistakes over a correct structure, while rare regressions highlight that graph-based reasoning quality remains a key factor.",309.52,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10114v1_Following the Teachers Footsteps Scheduled Checkpo.pdf,Following the Teacher’s Footsteps: Scheduled Checkpoint Distillation for Domain-Specific LLMs,"['Cheng Feng', 'Chaoliang Zhong', 'Jun Sun', 'Yusuke Oishi']","Large language models (LLMs) are challenging to deploy for domain-specific tasks due to their massive scale. While distilling a fine-tuned LLM into a smaller student model is a promising alternative, the capacity gap between teacher and student often leads to suboptimal performance. This raises a key question: when and how can a student model match or even surpass its teacher on domain-specific tasks? In this work, we propose a novel theoretical insight: a student can outperform its teacher if its advantage on a Student-Favored Subdomain (SFS) outweighs its deficit on the Teacher-Favored Subdomain (TFS). Guided by this insight, we propose Scheduled Checkpoint Distillation (SCD), which reduces the TFS deficit by emulating the teacher’s convergence process during supervised fine-tuning (SFT) on the domain task, and a sample-wise Adaptive Weighting (AW) mechanism to preserve student strengths on SFS. Experiments across diverse domain tasks—including QA, NER, and text classification in multiple languages—show that our method consistently outperforms existing distillation approaches, allowing the student model to match or even exceed the performance of its fine-tuned teacher.",314.64,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10120v1_TopoDIM One-shot Topology Generation of Diverse In.pdf,TopoDIM: One-shot Topology Generation of Diverse Interaction Modes for Multi-Agent Systems,"['Rui Sun', 'Jie Ding', 'Chenghua Gong', 'Tianjun Gu', 'Yihang Jiang', 'Juyuan Zhang', 'Liming Pan', 'Linyuan Lü']","Optimizing communication topology in LLM-based multi-agent systems is critical for enabling collective intelligence. Existing methods mainly rely on spatio-temporal interaction paradigms, leading to high latency and computation. This paper proposes TOPODIM, a framework for one-shot topology generation with diverse interaction modes. Designed for decentralized execution, TOPODIM enables agents to autonomously construct heterogeneous communication without iterative coordination, achieving token efficiency and improved task performance. Experiments demonstrate that TOPODIM reduces total token consumption by 46.41% while improving average performance by 1.50% over state-of-the-art methods. The framework exhibits strong adaptability in organizing communication among heterogeneous agents.",311.4,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10122v1_Role-Playing Agents Driven by Large Language Model.pdf,"Role-Playing Agents Driven by Large Language Models: Current Status, Challenges, and Future Trends","['Ye Wang', 'Jiaxing Chen', 'Hongjiang Xiao']","This paper systematically reviews the current development and key technologies of role-playing language agents (RPLAs), tracing the technological evolution from rule-based template paradigms to cognitive simulation centered on personality modeling and memory mechanisms. It highlights critical technical pathways supporting high-quality role-playing, including psychological scale-driven character modeling, memory-augmented prompting mechanisms, and motivation-situation-based behavioral decision control. The paper also analyzes the methods and challenges of constructing role-specific corpora, focusing on data sources, copyright constraints, and structured annotation processes. In terms of evaluation, it collates multi-dimensional assessment frameworks and benchmark datasets covering role knowledge, personality fidelity, value alignment, and interactive hallucination, while commenting on the advantages and disadvantages of human evaluation, reward models, and LLM-based scoring. Finally, the paper outlines future development directions of role-playing agents, including personality evolution modeling, multi-agent collaborative narrative, multimodal immersive interaction, and integration with cognitive neuroscience, aiming to provide a systematic perspective and methodological insights for subsequent research.",315.18,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10129v1_LaViT Aligning Latent Visual Thoughts for Multi-mo.pdf,LaViT: Aligning Latent Visual Thoughts for Multi-modal Reasoning,"['Linquan Wu', 'Tianxiang Jiang', 'Yifei Dong', 'Haoyu Yang', 'Fengji Zhang', 'Shichang Meng', 'Ai Xuan', 'Linqi Song', 'Jacky Keung']","Current multimodal latent reasoning often relies on external supervision, ignoring intrinsic visual attention dynamics. This work proposes LaViT, a framework that aligns latent visual thoughts rather than static embeddings. LaViT compels the student to autoregressively reconstruct the teacher’s visual semantics and attention trajectories prior to text generation, employing a curriculum sensory gating mechanism to prevent shortcut learning. Extensive experiments show that LaViT significantly enhances visual grounding, achieving up to +16.9% gains on complex reasoning tasks and enabling a compact 3B model to outperform larger open-source variants and proprietary models like GPT-4.",314.01,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10130v1_Redundancy-Driven Top-k Functional Dependency Disc.pdf,Redundancy-Driven Top-k Functional Dependency Discovery,"['Xiaolong Wan', 'Xixian Han']","Functional dependencies (FDs) are basic constraints in relational databases. Most FD discovery algorithms find all valid dependencies, but this causes two problems: high computational cost and a huge result set. The proposed SDP (Selective-Discovery-and-Prune) algorithm discovers the top-k FDs ranked by redundancy count, which measures how much duplicated information an FD explains. SDP uses an upper bound on redundancy to prune the search space. It is proved that this upper bound is monotone: adding attributes refines partitions and thus decreases the bound. Once the bound falls below the top-k threshold, the entire branch can be skipped. SDP is improved with three optimizations: ordering attributes by partition cardinality, using pairwise statistics in a Partition Cardinality Matrix to tighten bounds, and a global schedule to explore promising branches first. Experiments on over 40 datasets show that SDP is much faster and uses less memory than exhaustive methods.",313.57,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10131v2_M4olGen Multi-Agent Multi-Stage Molecular Generati.pdf,"M4olGen: Multi-Agent, Multi-Stage Molecular Generation under Precise Multi-Property Constraints","['Yizhan Li', 'Florence Cloutier', 'Sifan Wu', 'Ali Parviz', 'Boris Knyazev', 'Yan Zhang', 'Glen Berseth', 'Bang Liu']","Generating molecules that satisfy precise numeric constraints over multiple physicochemical properties is critical and challenging. Although large language models (LLMs) are expressive, they struggle with precise multi-objective control and numeric reasoning without external structure and feedback. We introduce M4olGen, a fragment-level, retrieval-augmented, two-stage framework for molecule generation under multi-property constraints. Stage I: Prototype generation involves a multi-agent reasoner performing retrieval-anchored, fragment-level edits to produce a candidate near the feasible region. Stage II: RL-based fine-grained optimization applies one- or multi-hop refinements to explicitly minimize property errors toward the target while regulating edit complexity and deviation from the prototype. A large, automatically curated dataset with reasoning chains of fragment edits and measured property deltas underpins both stages, enabling deterministic, reproducible supervision and controllable multi-hop reasoning. Unlike prior work, our framework better reasons about molecules by leveraging fragments and supports controllable refinement toward numeric targets. Experiments on generation under two sets of property constraints (QED, LogP, Molecular Weight, and HOMO, LUMO) show consistent gains in validity and precise satisfaction of multi-property targets, outperforming strong LLMs and graph-based algorithms.",313.65,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10132v1_Is More Context Always Better Examining LLM Reason.pdf,Is More Context Always Better? Examining LLM Reasoning Capability for Time Interval Prediction,"['Yanan Cao', 'Farnaz Fallahi', 'Murali Mohana Krishna Dandu', 'Lalitesh Morishetti', 'Kai Zhao', 'Luyi Ma', 'Sinduja Subramaniam', 'Jianpeng Xu', 'Evren Korpeoglu', 'Kaushiki Nag', 'Sushant Kumar', 'Kannan Achan']","Large Language Models (LLMs) have demonstrated impressive capabilities in reasoning and prediction across different domains. However, their ability to infer temporal regularities from structured behavioral data remains underexplored. This paper presents a systematic study investigating whether LLMs can predict time intervals between recurring user actions, such as repeated purchases. Using a simple but representative repurchase scenario, the authors benchmark state-of-the-art LLMs in zero-shot settings against both statistical and machine-learning models. The key findings are: 1) LLMs surpass lightweight statistical baselines but consistently underperform dedicated machine-learning models, indicating their limited ability to capture quantitative temporal structure; 2) Moderate context can improve LLM accuracy, but adding further user-level detail degrades performance. These results challenge the assumption that 'more context leads to better reasoning.' The study highlights fundamental limitations of today's LLMs in structured temporal inference and offers guidance for designing future context-aware hybrid models that integrate statistical precision with linguistic flexibility.",312.73,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10137v1_Step-by-Step Causality Transparent Causal Discover.pdf,Step-by-Step Causality: Transparent Causal Discovery with Multi-Agent,"['Ziyi Ding * 1', 'Chenfei Ye-Hao* 1', 'Zheyuan Wang 2', 'Xiao-Ping Zhang 1']","This paper introduces Tree-Query, a tree-structured, multi-expert LLM framework that reduces pairwise causal discovery to a short sequence of queries about backdoor paths, (in)dependence, latent confounding, and causal direction, yielding interpretable judgments with robustness-aware confidence scores. Theoretical guarantees are provided for asymptotic identifiability of four pairwise relations. On data-free benchmarks derived from Mooij et al. and UCI causal graphs, Tree-Query improves structural metrics over direct LLM baselines, and a diet–weight case study illustrates confounder screening and stable, high-confidence causal conclusions. Tree-Query thus offers a principled way to obtain data-free causal priors from LLMs that can complement downstream data-driven causal discovery.",313.65,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10141v1_Understanding and Preserving Safety in Fine-Tuned .pdf,Understanding and Preserving Safety in Fine-Tuned LLMs,"['Jiawen Zhang', 'Zhejiang University', 'kevinzh@zju.edu.cn', 'Yangfan Hu', 'University of Wisconsin–Madison', 'Wisconsin, USA', 'yhu557@wisc.edu', 'Kejia Chen', 'Zhejiang University', 'Zhejiang, China', 'chenkejia@zju.edu.cn', 'Lipeng He', 'University of Waterloo', 'Ontario, Canada', 'lipeng.he@uwaterloo.ca', 'Jiachen Ma', 'Shanghai Artificial Intelligence Laboratory', 'Shanghai, China', 'majiachen@pjlab.org.cn', 'Jian Lou', 'Sun Yat-sen University', 'Guangzhou, China', 'louj5@mail.sysu.edu.cn', 'Dan Li', 'Sun Yat-sen University', 'Guangzhou, China', 'lidan263@mail.sysu.edu.cn', 'Jian Liu', 'Zhejiang University', 'Zhejiang, China', 'liujian2411@zju.edu.cn', 'Xiaohu Yang', 'Zhejiang University', 'Zhejiang, China', 'yangxh@zju.edu.cn', 'Ruoxi Jia', 'Virginia Tech', 'Virginia, USA', 'ruoxijia@vt.edu']","Fine-tuning is a critical functionality for applying large language models (LLMs) to specific tasks. However, it can substantially degrade safety alignment, especially when fine-tuning data is harmless. Existing methods struggle with a safety-utility dilemma, where emphasizing safety compromises task performance, and prioritizing utility often leads to steep safety decline. This work addresses this dilemma by shedding light on the geometric interaction between safety- and utility-oriented gradients in safety-aligned LLMs. Through systematic empirical analysis, three key insights are uncovered: safety gradients lie in a low-rank subspace, utility gradients span a broader space, and these subspaces are often negatively correlated, causing directional conflicts during fine-tuning. SPF, a lightweight approach, explicitly removes gradient components conflicting with the low-rank safety subspace, ensuring utility convergence while bounding safety drift. Empirically, SPF maintains downstream task performance and recovers nearly all pre-trained safety alignment, even under adversarial fine-tuning scenarios. SPF also exhibits robust resistance to deep fine-tuning and dynamic jailbreak attacks. These findings provide new mechanistic understanding and practical guidance for always-aligned LLM fine-tuning.",313.05,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10143v1_History Is Not Enough An Adaptive Dataflow System .pdf,History Is Not Enough: An Adaptive Dataflow System for Financial Time-Series Synthesis,"['Haochong Xia', 'Yao Long Teng', 'Regan Tan', 'Molei Qin', 'Xinrun Wang', 'Bo An']","In quantitative finance, the gap between training and real-world performance—driven by concept drift and distributional non-stationarity—remains a critical obstacle for building reliable data-driven systems. Models trained on static historical data often overfit, resulting in poor generalization in dynamic markets. The mantra “History Is Not Enough” underscores the need for adaptive data generation that learns to evolve with the market rather than relying solely on past observations. We present a drift-aware dataflow system that integrates machine learning-based adaptive control into the data curation process. The system couples a parameterized data manipulation module comprising single-stock transformations, multi-stock mix-ups, and curation operations, with an adaptive planner–scheduler that employs gradient-based bi-level optimization to control the system. This design unifies data augmentation, curriculum learning, and data workflow management under a single differentiable framework, enabling provenance-aware replay and continuous data quality monitoring. Extensive experiments on forecasting and reinforcement learning trading tasks demonstrate that our framework enhances model robustness and improves risk-adjusted returns. The system provides a generalizable approach to adaptive data management and learning-guided workflow automation for financial data.",314.77,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10148v1_DecisionLLM Large Language Models for Long Sequenc.pdf,DecisionLLM: Large Language Models for Long Sequence Decision Exploration,"['Xiaowei Lv', 'Zhiling Zhang', 'Yijun Li', 'Yusen Huo', 'Siyuan Ju', 'Xuyan Li', 'Chunxiang Hong', 'Tianyu Wang', 'Peng Sun', 'Chuan Yu', 'Jian Xu', 'Bo Zheng']","Long-sequence decision-making, traditionally addressed through reinforcement learning (RL), is a critical component for optimizing strategic operations in dynamic environments. This work investigates the application of Large Language Models (LLMs) to offline decision-making tasks. A fundamental challenge is LLMs' inability to interpret continuous values, as they lack a native understanding of numerical magnitude and order. To address this, the authors propose treating trajectories as a distinct modality, aligning trajectory data with natural language task descriptions. The model, termed DecisionLLM, autoregressively predicts future decisions within a cohesive framework. The work establishes scaling laws governing this paradigm, demonstrating that performance hinges on model scale, data volume, and quality. In offline experimental benchmarks and bidding scenarios, DecisionLLM achieves strong performance, outperforming traditional Decision Transformer (DT) by 69.4 on Maze2D umaze-v1 and by 0.085 on AuctionNet. It extends the AIGB paradigm and points to promising directions for future exploration in online bidding.",313.62,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10150v1_Simple Network Graph Comparative Learning.pdf,Simple Network Graph Comparative Learning,"['Qiang Yu', 'Xinran Cheng', 'Shiqiang Xu', 'Chuanyi Li']","The effectiveness of contrastive learning methods has been widely recognized in the field of graph learning, especially in contexts where graph data often lack labels or are difficult to label. However, the application of these methods to node classification tasks still faces a number of challenges. This study proposes a novel node classification contrast learning method called Simple Network Graph Comparative Learning (SNGCL), which employs a superimposed multilayer Laplace smoothing filter to obtain global and local feature smoothing matrices, and uses an improved triple recombination loss function to bring the intra-class distance closer and the inter-class distance farther. The experimental results show that SNGCL is strongly competitive in most tasks.",315.16,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10154v1_MHub.ai A Simple Standardized and Reproducible Pla.pdf,JSON_FAIL,[],N/A,179.32,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10155v1_LOOKAT Lookup-Optimized Key-Attention for Memory-E.pdf,LOOKAT: Lookup-Optimized Key-Attention for Memory-Efficient Transformers,['Aryan Karmore'],"LOOKAT is a method that applies product quantization and asymmetric distance computation to transformer architecture for efficient compression of key-value (KV) cache. It decomposes key vectors into subspaces, learns codebooks, and computes attention tables via lookup tables, transforming attention from memory-bound to compute-bound. LOOKAT achieves 64× compression at 95.7% output fidelity and 32× compression at 95.0% fidelity, requiring no architectural changes or training. Theoretical analysis confirms that rank correlation degrades as O(d k/mK), with guarantees validated across sequence lengths up to 1024 tokens.",335.49,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10157v1_MMPG MoE-based Adaptive Multi-Perspective Graph Fu.pdf,Mixture of Experts-based Adaptive Multi-Perspective Graph Fusion for Protein Representation Learning,"['Yusong Wang', 'Jialun Shen', 'Zhihao Wu', 'Yicheng Xu', 'Shiyin Tan', 'Mingkun Xu', 'Changshuo Wang', 'Zixing Song', 'Prayag Tiwari']","Graph Neural Networks (GNNs) have been widely adopted for Protein Representation Learning (PRL) due to the natural representation of residue interactions as graphs. However, current GNN-based PRL methods typically rely on single-perspective graph construction strategies, which capture partial properties of residue interactions, leading to incomplete protein representations. To address this limitation, the authors propose MMPG, a framework that constructs protein graphs from multiple perspectives and adaptively fuses them via Mixture of Experts (MoE) for PRL. MMPG constructs graphs from physical, chemical, and geometric perspectives to characterize different properties of residue interactions. The MoE module dynamically routes perspectives to specialized experts, enabling the learning of intrinsic features and cross-perspective interactions. Quantitative verification shows that MoE automatically specializes experts in modeling distinct levels of interaction—from individual representations, to pairwise inter-perspective synergies, and ultimately to a global consensus across all perspectives. Through integrating multi-level information, MMPG produces superior protein representations and achieves advanced performance on four different downstream protein tasks.",312.53,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10160v1_Alignment Pretraining AI Discourse Causes Self-Ful.pdf,Alignment Pretraining: AI Discourse Causes Self-Fulfilling (Mis)alignment,"['Cameron Tice', 'Puria Radmard', 'Samuel Ratnam', 'Andy Kim', 'David Africa', ""Kyle O'Brien""]","This paper investigates the hypothesis that pretraining corpora containing extensive discourse about AI systems can lead to self-fulfilling misalignment in language models. By pretraining 6.9B-parameter LLMs with varying amounts of misalignment discourse, the authors find that discussion of AI contributes to misalignment. Upsampling synthetic training documents about AI misalignment leads to a notable increase in misaligned behavior, while upsampling aligned behavior reduces misalignment scores. The findings suggest that pretraining data shapes alignment priors and establish the study of how pretraining data shapes alignment priors as a complement to post-training methods. The authors recommend practitioners pretrain for alignment as well as capabilities and provide their models and datasets at alignmentpretraining.ai.",313.6,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10161v1_AWED-FiNER Agents Web applications and Expert Dete.pdf,"A WED-FiNER: Agents, Web applications, and Expert Detectors for Fine-grained Named Entity Recognition across 36 Languages for 6.6 Billion Speakers","['Prachuryya Kaushik', 'Ashish Anand']","A WED-FiNER is an open-source ecosystem designed to bridge the gap in Fine-grained Named Entity Recognition (FgNER) for 36 global languages spoken by over 6.6 billion people. It provides a collection of agentic toolkits, web applications, and state-of-the-art expert models for FgNER solutions across 36 languages. The agentic tools enable multilingual text routing to specialized expert models and fetch FgNER annotations within seconds. The web-based platforms provide ready-to-use FgNER annotation services for non-technical users. The collection of language-specific extremely small-sized open-source state-of-the-art expert models facilitates offline deployment in resource-constrained scenarios, including edge devices. The resources cover languages spoken by over 6.6 billion people, including a specific focus on vulnerable languages such as Bodo, Manipuri, Bishnupriya, and Mizo.",313.99,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10168v1_RAG-3DSG Enhancing 3D Scene Graphs with Re-Shot Gu.pdf,RAG-3DSG: ENHANCING 3D SCENE GRAPHS WITH RE-SHOT GUIDED RETRIEVAL-AUGMENTED GENERATION,"['Yue Chang', 'Rufeng Chen', 'Zhaofan Zhang', 'Yi Chen', 'Sihong Xie']",RAG-3DSG addresses the challenges of low object-level recognition accuracy and speed in open-vocabulary 3D Scene Graph (3DSG) generation. It mitigates aggregation noise through re-shot guided uncertainty estimation and supports object-level Retrieval-Augmented Generation (RAG) via reliable low-uncertainty objects. The dynamic downsample-mapping strategy accelerates cross-image object aggregation with adaptive granularity. Experiments on the Replica dataset demonstrate that RAG-3DSG significantly improves node captioning accuracy in 3DSG generation while reducing the mapping time by two-thirds compared to the vanilla version.,311.76,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10169v1_CtD Composition through Decomposition in Emergent .pdf,Composition through Decomposition: Emergent Communication for Compositional Generalization,"['Boaz Carmeli', 'Ron Meir', 'Yonatan Belinkov']","This study demonstrates how artificial neural agents acquire and utilize compositional generalization to describe previously unseen images. The method, termed 'Composition through Decomposition' (CtD), involves two sequential training steps: decomposing an image into basic concepts and composing these concepts into complex phrases. Remarkably, the agents achieve zero-shot generalization in the 'Compose' step without additional training.",313.72,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10173v1_ReasAlign Reasoning Enhanced Safety Alignment agai.pdf,ReasAlign: Reasoning Enhanced Safety Alignment against Prompt Injection Attack,"['Hao Li', 'Yankai Yang', 'G. Edward Suh', 'Ning Zhang', 'Chaowei Xiao']","Large Language Models (LLMs) have enabled the development of powerful agentic systems capable of automating complex workflows across various fields. However, these systems are highly vulnerable to indirect prompt injection attacks, where malicious instructions embedded in external data can hijack agent behavior. In this work, the authors present ReasAlign, a model-level solution to improve safety alignment against indirect prompt injection attacks. The core idea of ReasAlign is to incorporate structured reasoning steps to analyze user queries, detect conflicting instructions, and preserve the continuity of the user’s intended tasks to defend against indirect injection attacks. To further ensure reasoning logic and accuracy, the authors introduce a test-time scaling mechanism with a preference-optimized judge model that scores reasoning steps and selects the best trajectory. Comprehensive evaluations across various benchmarks show that ReasAlign maintains utility comparable to an undefended model while consistently outperforming Meta SecAlign, the strongest prior guardrail. On the representative open-ended CyberSecEval2 benchmark, ReasAlign achieves 94.6% utility and only 3.6% ASR, far surpassing the state-of-the-art defensive model of Meta SecAlign (56.4% utility and 74.4% ASR). These results demonstrate that ReasAlign achieves the best trade-off between security and utility, establishing a robust and practical defense against prompt injection attacks in real-world agentic systems.",313.88,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10187v1_HOMURA Taming the Sand-Glass for Time-Constrained .pdf,HOMURA: Taming the Sand-Glass for Time-Constrained LLM Translation via Reinforcement Learning,"['Ziang Cui', 'Mengran Yu', 'Tianjiao Li', 'Chenyu Shi', 'Yingxuan Shi', 'Lusheng Zhang', 'Hongwei Lin']","Large Language Models (LLMs) have achieved remarkable strides in multilingual translation but are hindered by a systemic cross-lingual verbosity bias, rendering them unsuitable for strict time-constrained tasks like subtitling and dubbing. Current prompt-engineering approaches struggle to resolve this conflict between semantic fidelity and rigid temporal feasibility. To bridge this gap, we introduce Sand-Glass, a benchmark specifically designed to evaluate translation under syllable-level duration constraints, and propose HOMURA, a reinforcement learning framework that explicitly optimizes the trade-off between semantic preservation and temporal compliance. By employing a KL-regularized objective with a novel dynamic syllable-ratio reward, HOMURA effectively ",268.06,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10191v1_How does downsampling affect needle electromyograp.pdf,Automated Analysis of Needle Electromyography Signals: A Generalizable Workflow for Understanding Downsampling Effects on High-Frequency Time Series,"['Mathieu J.L. Cherpitel', 'Janne A.M. Luijten', 'Thomas H.W. Bäck', 'Camiel Verhamme', 'Martijn R. Tannemaat', 'Anna V. Kononova']","This study presents a workflow for systematically evaluating information loss caused by downsampling in high-frequency time series. The workflow combines shape-based distortion metrics with classification outcomes from feature-based machine learning models and feature space analysis to quantify how different downsampling algorithms and factors affect both waveform integrity and predictive performance. The workflow is used to experimentally evaluate a three-class neuromuscular disorders classification task, demonstrating how shape-aware downsampling algorithms outperform standard decimation in preserving diagnostic information while substantially reducing computational load.",315.32,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10193v1_GFM4GA Graph Foundation Model for Group Anomaly De.pdf,GFM4GA: Graph Foundation Model for Group Anomaly Detection,"['Jiujiu Chen', 'Weijun Zeng', 'Shaofeng Hu', 'Sihong Xie∗', 'Hui Xiong']","Group anomaly detection is crucial in many network applications but faces challenges due to diverse anomaly patterns. Motivated by the success of large language models (LLMs) in natural language processing, a graph foundation model (GFMs) is proposed to handle few-shot learning tasks with fewer labeling efforts. However, GFMs cannot be generalized to group anomalies, as group anomaly patterns must be detected as a whole and individuals in an abnormal group can look rather normal. Therefore, a novel graph foundation model for group anomaly detection, GFM4GA, is proposed. The pipeline is pretrained via dual-level contrastive learning based on feature-based estimation and group extraction to capture potential group anomaly structure and feature inconsistencies. In downstream tasks, the pipeline is finetuned in parameter-constrained and group-anomaly-proportion weighted few-shot settings, and its adaptive ability to unseen group anomalies is expanded via group contexts determined by labeled anomaly neighbors. Experiments show that GFM4GA surpasses group anomaly detectors and GFMs for individual anomalies, achieving average improvements of 2.85% in AUROC and 2.55% in AUPRC.",311.58,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10201v1_PRL Process Reward Learning Improves LLMs Reasonin.pdf,PRL: Process Reward Learning Improves LLMs’ Reasoning Ability and Broadens the Reasoning Boundary,"['Jiarui Yao', 'Ruida Wang', 'Tong Zhang']","Improving the reasoning abilities of Large Language Models (LLMs) has been a continuous topic. Most relevant works rely on outcome rewards at the trajectory level, missing fine-grained supervision during the reasoning process. This paper proposes Process Reward Learning (PRL), which decomposes the entropy regularized reinforcement learning objective into intermediate steps with rigorous process rewards. PRL turns outcome rewards into process supervision signals, helping better guide exploration during RL optimization. Experimental results demonstrate that PRL improves both the average performance and the reasoning boundary of LLMs.",312.28,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10205v1_One Instruction Does Not Fit All How Well Do Embed.pdf,One Instruction Does Not Fit All: How Well Do Embeddings Align Personas and Instructions in Low-Resource Indian Languages?,"['Arya Shah', 'Himanshu Beniwal', 'Mayank Singh']","Aligning multilingual assistants with culturally grounded user preferences is essential for serving India's linguistically diverse population. This paper presents a unified benchmark spanning 12 Indian languages and four evaluation tasks: monolingual and cross-lingual persona-to-instruction retrieval, reverse retrieval from instruction to persona, and binary compatibility classification. Eight multilingual embedding models are evaluated in a frozen-encoder setting with a thin logistic regression head for classification. E5-Large-Instruct achieves the highest Recall@1 of 27.4% on monolingual retrieval and 20.7% on cross-lingual transfer, while BGE-M3 leads reverse retrieval at 32.1% Recall@1. For classification, LaBSE attains 75.3% AUROC with strong calibration. These findings offer practical guidance for model selection in Indic multilingual retrieval and establish reproducible baselines for future work.",311.79,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10212v1_PADER Paillier-based Secure Decentralized Social R.pdf,PADER: Paillier-based Secure Decentralized Social Recommendation,"['Chaochao Chen', 'Jiaming Qian', 'Fei Zheng∗', 'Yachuan Liu']","The paper proposes PADER, a Paillier-based secure decentralized social recommendation system. It operates in a decentralized network where users and sellers are nodes. The training and inference of the recommendation model are carried out securely without a centralized platform. The authors apply the Paillier cryptosystem to the SoReg (Social Regularization) model, which combines user ratings and social relations. They design secure addition and multiplication protocols for efficient secure computation on any arithmetic circuit and an optimal data packing scheme suitable for polynomial computations. Experiment results show that the method is practical, taking about one second per user with hundreds of ratings and training with ∼500K ratings in under 3 hours. The code is available at https://github.com/ GarminQ/ PADER.",312.91,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10215v1_Topo-RAG Topology-aware retrieval for hybrid text-.pdf,TOPO-RAG: TOPOLOGY-AWARE RETRIEVAL FOR HYBRID TEXT-TABLE DOCUMENTS,"['Alex Dantart∗', 'Marco Kővacs-Navarro']","In enterprise datasets, documents are rarely pure. They are not just text, nor just numbers; they are a complex amalgam of narrative and structure. Current Retrieval-Augmented Generation (RAG) systems have attempted to address this complexity with a blunt tool: linearization. This work presents Topo-RAG, a framework that challenges the assumption that ‘everything is text.’ We propose a dual architecture that respects the topology of the data: we route fluid narrative through traditional dense retrievers, while tabular structures are processed by a Cell-Aware Late Interaction mechanism, preserving their spatial relationships. Evaluated on SEC-25, a synthetic enterprise corpus that mimics real-world complexity, Topo-RAG demonstrates an 18.4% improvement in nDCG@10 on hybrid queries compared to standard linearization approaches. It’s not just about searching better; it’s about understanding the shape of information.",315.66,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10222v1_Introduction to optimization methods for training .pdf,Introduction to optimization methods for training SciML models,"['Alena Kopaničáková', 'Elisa Riccietti']","Optimization is the foundation of modern machine learning (ML). Historically, optimization methods have been categorized by the degree to which they exploit derivative information. First-order methods rely exclusively on gradient evaluations, whereas (approximate) second-order methods incorporate curvature information via Hessians or suitable approximations. However, the massive scale of modern ML problems, combined with the principles of empirical risk minimization, has driven the field toward stochastic optimization. Stochastic optimization methods, such as Stochastic Gradient Descent (SGD) and its variants (e.g., AdaGrad and Adam), employ inexpensive noisy gradient evaluations that scale efficiently with data size. Consequently, much of modern ML focuses on integrating first-order schemes, adaptive gradient methods, and curvature-aware techniques into stochastic optimization frameworks. This familiar optimization landscape changes substantially in the context of scientific machine learning (SciML). Unlike classical ML, where abundant data allows stochastic approximation to perform well, SciML often operates in data-scarce regimes in which physical models must supplement, or even dominate, the available data. As a result, the optimization problems arising in SciML frequently take the form of physics-informed or operator-constrained formulations, in which the objective function incorporates a partial-differential equation (PDE) and boundary or initial conditions (BC or IC). These components change the structure of the objective function, since the loss depends on differential operators and induces global spatio-temporal coupling. This difference has profound implications. In classical ML, the loss function typically decomposes into independent sample contributions, which enables efficient stochastic optimization. In contrast, SciML losses are often non-independent, leading to more complex optimization challenges.",315.09,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10236v1_Who Owns the Text Design Patterns for Preserving A.pdf,Who Owns the Text? Design Patterns for Preserving Authorship in AI-Assisted Writing,"['Bohan Zhang', 'Chengke Bu', 'Paramveer Dhillon∗']","This study examines the tension between AI writing assistants and writers' sense of authorship. It presents an ownership-aware co-writing editor that offers on-demand, sentence-level suggestions. The study tests two design choices: persona-based coaching and style personalization. Participants completed three professional writing tasks: an email without AI help, a proposal with generic AI suggestions, and a cover letter with persona-based coaching. The results show that psychological ownership dropped relative to unassisted writing, even as cognitive load decreased and quality ratings stayed similar. Persona coaching did not prevent the ownership decline, but style personalization partially restored ownership and increased AI incorporation in text.",315.75,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10242v1_Loop as a Bridge Can Looped Transformers Truly Lin.pdf,LOOP AS ABRIDGE: CANLOOPEDTRANSFORMERS TRULYLINKREPRESENTATIONSPACE ANDNATURAL LANGUAGEOUTPUTS?,"['Guanxu Chen', 'Dongrui Liu', 'Jing Shao']","Recent advancements in Large Language Models (LLMs) have shifted the focus from direct response to complex multi-step reasoning. Key techniques such as Chain-of-Thoughts (CoTs) allow LLMs to refine and verify their answers through intermediate reasoning steps. This phenomenon implies a relationship between reasoning accuracy and verification capabilities. LLMs’ ability to produce a correct solution is often upper-bounded by their ability to verify the correctness of their own solution. In parallel, another line of LLM research—encompassing AI Monitoring and Introspection—has moved beyond analyzing mere textual outputs to designing internal monitors based on model representations and interpretability. However, the gap between their internal representation and verification output remains. This report investigates whether Looped Transformers (LTs), which increase computational depth by iterating shared layers, can bridge this gap by utilizing their iterative nature as a form of introspection. Experiments reveal that while increasing loop iterations narrows the gap, it is partly driven by a degradation of their internal 'knowledge' carried by representations. Moreover, another empirical analysis suggests that current LTs' ability to perceive representations does not improve across loops; it is only present in the final loop. These results suggest that while LTs offer a promising direction for scaling computational depth, they have yet to achieve the introspection required to truly link representation space and natural language.",313.21,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10245v1_TRIM Hybrid Inference via Targeted Stepwise Routin.pdf,Hybrid Inference via Targeted Stepwise Routing in Multi-Step Reasoning Tasks,"['Vansh Kapoor†', 'Aman Gupta', 'Hao Chen', 'Anurag Beniwal', 'Jing Huang', 'Aviral Kumar']","Multi-step reasoning tasks, such as mathematical problem solving, are vulnerable to cascading failures where a single incorrect step can lead to complete solution breakdown. Current LLM routing methods assign entire queries to one model, treating all reasoning steps as equal. The paper proposes TRIM (Targeted routing in multi-step reasoning tasks), which routes only critical steps to larger models while letting smaller models handle routine continuations. The key insight is that targeted step-level interventions can fundamentally transform inference efficiency by confining expensive calls to precisely those steps where stronger models prevent cascading errors. TRIM operates at the step-level, using process reward models to identify erroneous steps and make routing decisions based on step-level uncertainty and budget constraints. The authors develop several routing strategies, ranging from simple threshold-based policies to more expressive policies that reason about long-horizon accuracy-cost trade-offs and uncertainty in step-level correctness estimates. On MATH-500, even the simplest thresholding strategy surpasses prior routing methods with 5× higher cost efficiency, while more advanced policies match the strong, expensive model's performance using 80% fewer expensive model tokens. On harder benchmarks such as AIME, TRIM achieves up to 6× higher cost efficiency. All methods generalize effectively across math reasoning tasks, demonstrating that step-level difficulty represents fundamental characteristics of reasoning.",314.26,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10251v1_X-SAM Boosting Sharpness-Aware Minimization with D.pdf,Boosting Sharpness-Aware Minimization with Dominant-Eigenvector,"['Hongru Duan', 'Yongle Chen', 'Lei Guan']","Sharpness-Aware Minimization (SAM) aims to improve generalization by minimizing a worst-case perturbed loss over a small neighborhood of model parameters. However, its optimization behavior during training does not always align with theoretical expectations. This paper investigates SAM from a spectral and geometric perspective, using the angle between the gradient and the leading eigenvector of the Hessian as a measure of sharpness. When this angle is less than or equal to ninety degrees, SAM's sharpness regularization effect can be weakened. The authors propose an explicit eigenvector-aligned SAM (X-SAM), which corrects the gradient via orthogonal decomposition along the top eigenvector, enabling more direct and efficient regularization of the Hessian's maximum eigenvalue. The paper proves X-SAM's convergence and superior generalization, with extensive experimental evaluations confirming both theoretical and practical advantages.",311.44,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10254v1_NoReGeo Non-Reasoning Geometry Benchmark.pdf,NoReGeo: Non-Reasoning Geometry Benchmark,"['Irina Abdullaeva', 'Anton Vasiliuk', 'Elizaveta Goncharova', 'Temurbek Rahmatullaev', 'Ivan Zagorulko', 'Maxim Kurkin', 'Andrey Kuznetsov']","The paper introduces NoReGeo, a novel benchmark designed to evaluate the intrinsic geometric understanding of large language models (LLMs) without relying on reasoning or algebraic computation. Unlike existing benchmarks that primarily assess models' proficiency in reasoning-based geometry, NoReGeo focuses on evaluating whether LLMs can inherently encode spatial relationships and recognize geometric properties directly. The benchmark comprises 2,500 trivial geometric problems spanning 25 categories, each carefully crafted to be solvable purely through native geometric understanding, assuming known object locations. The authors assess a range of state-of-the-art models on NoReGeo, including frontier models like GPT-4, observing that even the most advanced systems achieve an overall maximum of 65% accuracy in binary classification tasks. Ablation experiments demonstrate that such geometric understanding does not emerge through fine-tuning alone, indicating that effective training for geometric comprehension requires a specialized approach from the outset. The findings highlight a significant gap in current LLMs' ability to natively grasp geometric concepts, providing a foundation for future research toward models with true geometric cognition.",313.87,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10257v1_Untangling Input Language from Reasoning Language .pdf,Untangling Input Language from Reasoning Language: A Diagnostic Framework for Cross-Lingual Moral Alignment in LLMs,"['Nan Li', 'Bo Kang', 'Tijl De Bie']","This paper introduces a methodology to separately manipulate the language of the moral dilemma and the language in which the model reasons. By studying English-Chinese moral judgment with 13 LLMs, the authors demonstrate the diagnostic power of their framework. They show that reasoning-language effects contribute twice the variance of input-language effects, detect context-dependency in nearly half of models, and translate these patterns into deployment guidance. The methodology isolates reasoning-language effects, enabling a better understanding of cross-lingual moral judgments.",314.46,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10272v1_MoST Mixing Speech and Text with Modality-Aware Mi.pdf,MOST: MIXINGSPEECH ANDTEXT WITHMODALITY,"['Yuxuan Lou', 'Kai Yang', 'Yang You']","We present MoST (Mixture of Speech and Text), a novel multimodal large language model that seamlessly integrates speech and text processing through our proposed Modality-Aware Mixture of Experts (MAMoE) architecture. While current multimodal models typically process diverse modality representations with identical parameters—disregarding their inherent representational differences, we introduce specialized routing pathways that direct tokens to modality-appropriate experts based on input type. MAMoE simultaneously enhances modality-specific learning and cross-modal understanding through two complementary components: modality-specific expert groups that capture domain-specific patterns and shared experts that facilitate information transfer between modalities. Building on this architecture, we develop an efficient transformation pipeline that adapts the pretrained MoE language model through strategic post-training on ASR and TTS datasets, followed by fine-tuning with a carefully curated speech-text instruction dataset. A key feature of this pipeline is that it relies exclusively on fully accessible, open-source datasets to achieve strong performance and data efficiency. Comprehensive evaluations across ASR, TTS, audio language modeling, and spoken question answering benchmarks show that MoST consistently outperforms existing models of comparable parameter counts. Our ablation studies confirm that the modality-specific routing mechanism and shared experts design significantly contribute to performance gains across all tested domains. To our knowledge, MoST represents the first fully open-source speech-text LLM built on a Mixture of Experts architecture.",314.37,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10274v1_Queueing-Aware Optimization of Reasoning Tokens fo.pdf,Queueing-Aware Optimization of Reasoning Tokens for Accuracy-Latency Trade-offs in LLM Servers,"['Emre Ozbas', 'Melih Bastopcu']","We consider a single large language model (LLM) server that serves a heterogeneous stream of queries belonging to N distinct task types. Queries arrive according to a Poisson process, and each type occurs with a known prior probability. For each task type, the server allocates a fixed number of internal thinking tokens, which determines the computational effort devoted to that query. The token allocation induces an accuracy-latency trade-off: the service time follows an approximately affine function of the allocated tokens, while the probability of a correct response exhibits diminishing returns. Under a first-in, first-out (FIFO) service discipline, the system operates as an M/G/1 queue, and the mean system time depends on the first and second moments of the resulting service-time distribution. We formulate a constrained optimization problem that maximizes a weighted average accuracy objective penalized by the mean system time, subject to architectural token-budget constraints and queue-stability conditions. The objective function is shown to be strictly concave over the stability region, which ensures existence and uniqueness of the optimal token allocation. The first-order optimality conditions yield a coupled projected fixed-point characterization of the optimum, together with an iterative solution and an explicit sufficient condition for contraction. Moreover, a projected gradient method with a computable global step-size bound is developed to guarantee convergence beyond the contractive regime. Finally, integer-valued token allocations are attained via rounding of the continuous solution, and the resulting performance loss is evaluated in simulation results.",313.22,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10282v2_SPIKE Sparse Koopman Regularization for Physics-In.pdf,SPIKE: Sparse Koopman Regularization for Physics-Informed Neural Networks,"['Jose Marie Antonio Miñoza', 'Center for AI Research PH']","SPIKE is a framework that regularizes Physics-Informed Neural Networks (PINNs) with continuous-time Koopman operators to learn parsimonious dynamics representations. By enforcing linear dynamics dz/dt=Az in a learned observable space, SPIKE and its variants learn sparse generator matrices, embodying the parsimony principle that complex dynamics admit low-dimensional structure. Experiments across various PDEs, including fluid dynamics and chaotic ODEs, demonstrate consistent improvements in temporal extrapolation, spatial generalization, and long-term prediction accuracy. The continuous-time formulation with matrix exponential integration provides unconditional stability for stiff systems while avoiding diagonal dominance issues inherent in discrete-time Koopman operators.",313.8,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10305v1_DanQing An Up-to-Date Large-Scale Chinese Vision-L.pdf,DanQing: An Up-to-Date Large-Scale Chinese Vision-Language Pre-training Dataset,"['Hengyu Shen', 'Tiancheng Gu', 'Bin Qin', 'Lan Wu', 'Yuling Wu', 'Shuo Tan', 'Zelong Sun', 'Jun Wang', 'Nan Wu', 'Xiang An', 'Weidong Cai', 'Ziyong Feng', 'Kaicheng Yang']","Vision-Language Pre-training (VLP) models demonstrate strong performance across various downstream tasks by learning from large-scale image-text pairs through contrastive pretraining. The release of extensive English image-text datasets has enabled widespread adoption of models such as CLIP and SigLIP in tasks including cross-modal retrieval and image captioning. However, the advancement of Chinese vision-language pretraining has substantially lagged behind due to the scarcity of high-quality Chinese image-text data. To address this gap, the authors develop a comprehensive pipeline for constructing a high-quality Chinese cross-modal dataset, proposing DanQing, which contains 100 million image-text pairs collected from Common Crawl. DanQing is curated through a more rigorous selection process, yielding superior data quality and is primarily built from 2024-2025 web data, enabling models to better capture evolving semantic trends. The authors compare DanQing with existing datasets by continual pre-training of the SigLIP2 model, showing consistent superior performance across Chinese downstream tasks.",313.83,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10306v1_Evidence-Augmented Policy Optimization with Reward.pdf,Evidence-Augmented Policy Optimization with Reward Co-Evolution for Long-Context Reasoning,"['Xin Guan*', 'Zijian Li', 'Shen Huang', 'Pengjun Xie', 'Jingren Zhou', 'Jiuxin Cao']","This paper proposes EAPO (Evidence-Augmented Policy Optimization), a specialized RL algorithm designed to improve long-context reasoning. EAPO introduces a reward model that computes a Group-Relative Evidence Reward, providing dense process supervision to explicitly improve evidence quality. The authors validate their approach using Tree-Structured Evidence Sampling and demonstrate that precise evidence extraction is a critical bottleneck for long-context reasoning. Comprehensive evaluations across eight benchmarks show that EAPO significantly enhances long-context reasoning performance compared to state-of-the-art (SOTA) baselines.",312.81,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10338v1_Agent Skills in the Wild An Empirical Study of Sec.pdf,Agent Skills in the Wild: An Empirical Study of Security Vulnerabilities at Scale,"['Yi Liu∗', 'Weizhe Wang∗', 'Ruitao Feng†', 'Yao Zhang†', 'Guangquan Xu†', 'Gelei Deng', 'Yuekang Li', 'Leo Zhang']","The rise of AI agent frameworks has introduced agent skills—modular packages containing instructions and executable code that dynamically extend agent capabilities. While this architecture enables powerful customization, skills execute with implicit trust and minimal vetting, creating a significant yet uncharacterized attack surface. The authors conduct the first large-scale empirical security analysis of this emerging ecosystem, collecting 42,447 skills from two major marketplaces and systematically analyzing 31,132 using SkillScan, a multi-stage detection framework integrating static analysis with LLM-based semantic classification. Their findings reveal pervasive security risks: 26.1% of skills contain at least one vulnerability, spanning 14 distinct patterns across four categories—prompt injection, data exfiltration, privilege escalation, and supply chain risks. Data exfiltration (13.3%) and privilege escalation (11.8%) are most prevalent, while 5.2% of skills exhibit high-severity patterns strongly suggesting malicious intent. Skills bundling executable scripts are 2.12× more likely to contain vulnerabilities than instruction-only skills (OR=2.12, p< 0.001). The authors contribute a grounded vulnerability taxonomy derived from 8,126 vulnerable skills, a validated detection methodology achieving 86.7% precision and 82.5% recall, and an open dataset and detection toolkit to support future research.",311.96,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10342v1_C-GRASP Clinically-Grounded Reasoning for Affectiv.pdf,C-GRASP: Clinically-Grounded Reasoning for Affective Signal Processing,"['Cheng Lin Cheng', 'Ting Chuan Lin', 'Chai Kai Chang']","Heart rate variability (HRV) is a key non-invasive marker for autonomic monitoring, yet applying Large Language Models (LLMs) to HRV interpretation poses unique challenges: respiratory sinus arrhythmia (RSA) can contaminate frequency-domain indices, short data segments destabilize nonlinear metrics, and visual plots are prone to scaling-induced hallucinations. A critical gap exists in current LLM-based HRV interpretation: models lack respect for individualized baselines, defaulting to population norms. This limitation leads to misdiagnosis in high-HRV populations, where individuals with naturally elevated HRV metrics are incorrectly flagged as abnormal when their values exceed population averages, despite being normal relative to their personal baselines. We propose C-GRASP (Clinically-Grounded Reasoning for Affective Signal Processing), a guardrailed RAG-enhanced pipeline that decomposes HRV interpretation into eight traceable steps. The key innovation of C-GRASP is the integration of a Dual Z-score Priority Hierarchy with quantitative guardrails into the RAG reasoning chain architecture, ensuring that individualized baseline shifts take precedence over normative statistics while automatically detecting and mitigating spectral artifacts. Key contributions include stepwise reasoning for transparent, auditable interpretation and quality-aware guardrails triggered by quantitative metrics.",314.11,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10343v2_OctoBench Benchmarking Scaffold-Aware Instruction .pdf,OCTOBENCH: Benchmarking Scaffold-Aware Instruction Following in Repository-Grounded Agentic Coding,"['Deming Ding', 'Shichun Liu', 'Enhui Yang', 'Jiahang Lin', 'Ziying Chen', 'Shihan Dou', 'Honglin Guo', 'Weiyu Cheng', 'Pengyu Zhao', 'Chengjun Xiao', 'Qunhong Zeng', 'Qi Zhang', 'Xuanjing Huang', 'Qidi Xu', 'Tao Gui']","Modern coding scaffolds turn Large Language Models (LLMs) into capable software agents, but their ability to follow scaffold-specified instructions remains under-examined, especially when constraints are heterogeneous and persist across interactions. OCTOBENCH introduces a benchmark for measuring scaffold-aware instruction following in repository-grounded agentic coding. It includes 34 environments and 217 tasks, paired with 7,098 objective checklist items. The toolkit captures full trajectories and performs fine-grained checks to disentangle task-solving from following rules. Experiments on eight representative models reveal a systematic gap between task-solving and scaffold-aware compliance, highlighting the need for training and evaluation that explicitly targets heterogeneous instruction following. The benchmark is released to support reproducible benchmarking and accelerate the development of more scaffold-aware coding agents.",312.98,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10348v1_Training-Trajectory-Aware Token Selection.pdf,Training-Trajectory-Aware Token Selection,"['Zhanming Shen', 'Jiaqi Hu', 'Zeyu Qin', 'Hao Chen', 'Wentao Ye', 'Zenan Huang', 'Yihong Zhuang', 'Guoshan Lu', 'Junlin Zhou', 'Junbo Zhao']","Efficient distillation is a key pathway for converting expensive reasoning capability into deployable efficiency. However, in the frontier regime where the student already has strong reasoning ability, naive continual distillation often yields limited gains or even degradation. The authors observe a characteristic training phenomenon: even as loss decreases monotonically, all performance metrics can drop sharply at almost the same bottleneck, before gradually recovering. They uncover a token-level mechanism: confidence bifurcates into steadily increasing Imitation-Anchor Tokens that quickly anchor optimization and other yet-to-learn tokens whose confidence is suppressed until after the bottleneck. The characteristic that these two types of tokens cannot coexist is the root cause of the failure in continual distillation. To address this, the authors propose Training-Trajectory-Aware Token Selection (T3S) to reconstruct the training objective at the token level, clearing the optimization path for yet-to-learn tokens. T3 yields consistent gains in both AR and dLLM settings, surpassing competitive reasoning benchmarks and achieving state-of-the-art performance among all 16B-scale no-think models.",313.88,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10349v1_SuS Strategy-aware Surprise for Intrinsic Explorat.pdf,SuS: Strategy-aware Surprise for Intrinsic Exploration,"['Mark Kashirskiy', 'Ilya Makarov']","We propose Strategy-aware Surprise (SuS), a novel intrinsic motivation framework that uses pre-post prediction mismatch as a novelty signal for exploration in reinforcement learning. SuS introduces two complementary components: Strategy Stability (SS) and Strategy Surprise (SuS). SS measures consistency in behavioral strategy across temporal steps, while SuS captures unexpected outcomes relative to the agent’s current strategy representation. Our combined reward formulation leverages both signals through learned weighting coefficients. We evaluate SuS on mathematical reasoning tasks using large language models, demonstrating significant improvements in both accuracy and solution diversity. Ablation studies confirm that removing either component results in at least 10% performance degradation, validating the synergistic nature of our approach. SuS achieves 17.4% improvement in Pass@1 and 26.4% improvement in Pass@5 compared to baseline methods, while maintaining higher strategy diversity throughout training.",315.02,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10373v1_Towards Efficient Low-rate Image Compression with .pdf,Towards Efficient Low-rate Image Compression with Frequency-aware Diffusion Prior Refinement,"['Yichong Xia', 'Yimin Zhou', 'Jinpeng Wang', 'Bin Chen']","Recent advancements in diffusion-based generative priors have enabled visually plausible image compression at extremely low bit rates. However, existing approaches suffer from slow sampling processes and suboptimal bit allocation due to fragmented training paradigms. This work proposes AccelerateDiffusion-based Image Compression via Consistency Prior Refinement (DiffCR), a novel compression framework for efficient and high-fidelity image reconstruction. At the heart of DiffCR is a Frequency-aware Skip Estimation (FaSE) module that refines the ϵ-prediction prior from a pre-trained latent diffusion model and aligns it with compressed latents at different timesteps via Frequency Decoupling Attention (FDA). Furthermore, a lightweight consistency estimator enables fast two-step decoding by preserving the semantic trajectory of diffusion sampling. Without updating the backbone diffusion model, DiffCR achieves substantial bitrate savings (27.2% BD-rate (LPIPS) and 65.1% BD-rate (PSNR)) and over 10× speed-up compared to state-of-the-art diffusion-based compression baselines.",314.0,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10378v2_Global Context Compression with Interleaved Vision.pdf,Global Context Compression with Interleaved Vision-Text Transformation,"['Dian Jiao*', 'Jiaxin Duan*', 'Shuai Zhao', 'Jiabing Leng', 'Yiran Zhang', 'Feng Huang*']","Recent achievements of vision-language models in end-to-end OCR motivate earlier works that render the Transformer's input into images for prefilling, which effectively reduces the number of tokens through visual encoding. However, this partial compression fails to save computational or memory costs at token-by-token inference. This paper investigates global context compression, which saves tokens at both prefilling and inference stages. Consequently, a novel Transformer called VIST2 is proposed, interleaving input text chunks alongside their visual encoding, while depending exclusively on visual tokens in the pre-context to predict the next text token distribution. The authors conduct extensive experiments using VIST2 families scaled from 0.6B to 8B to explore the training recipe and hyperparameters. The resulting models demonstrate significant superiority over baselines on long writing tasks, achieving a 3× speedup in first-token generation, 77% reduction in memory usage, and 74% reduction in FLOPS with a 4× compression ratio.",311.34,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10386v1_Handling Missing Modalities in Multimodal Survival.pdf,Handling Missing Modalities in Multimodal Survival Prediction for Non-Small Cell Lung Cancer,"['Filippo Ruffini', 'Camillo Maria Caruso', 'Claudia Tacconi', 'Lorenzo Nibid', 'Francesca Miccolis', 'Marta Lovino', 'Carlo Greco', 'Edy Ippolito', 'Michele Fiore', 'Alessio Cortellini', 'Bruno Beomonte Zobel', 'Giuseppe Perrone', 'Bruno Vincenzi', 'Claudio Marrocco', 'Alessandro Bria', 'Elisa Ficarra', 'Sara Ramella', 'Valerio Guarrasi', 'Paolo Soda']","This paper addresses the challenge of handling missing modalities in the context of survival prediction for non-small cell lung cancer. The authors propose a novel approach that integrates various types of medical imaging and clinical data to improve survival prediction models. The study demonstrates the effectiveness of their method through a comprehensive analysis of a large dataset from the Fondazione Policlinico Universitario Campus Bio-Medico, Rome. The findings suggest that incorporating multiple modalities can significantly enhance the accuracy of survival predictions, even when some data are missing.",315.8,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10398v2_LatentRefusal Latent-Signal Refusal for Unanswerab.pdf,LatentRefusal: Latent-Signal Refusal for Unanswerable Text-to-SQL Queries,"['Xuancheng Ren', 'Shijing Hu', 'Zhihui Lu', 'Jiangqi Huang', 'Qiang Duan']","In LLM-based Text-to-SQL systems, unanswerable and underspecified user queries may generate incorrect text and executable programs that yield misleading results or violate safety constraints. Existing refusal strategies either rely on output-level instruction following, which is brittle due to model hallucinations, or on estimating output uncertainty, which adds complexity and overhead. To address this challenge, the authors formalize safe refusal in Text-to-SQL systems as an answerability-gating problem and propose LATENTREFUSAL, a latent-signal refusal mechanism that predicts query answerability from intermediate hidden activations of an LLM. They introduce the Tri-Residual Gated Encoder (TRGE) to suppress schema noise and amplify sparse, localized question-schema mismatch cues. Extensive empirical evaluations demonstrate the effectiveness of the proposed scheme and show that LATENTREFUSAL provides an attachable, efficient safety layer for Text-to-SQL systems.",312.31,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10402v1_Toward Ultra-Long-Horizon Agentic Science Cognitiv.pdf,Toward Ultra-Long-Horizon Agentic Science: Cognitive Accumulation for Machine Learning Engineering,"['Xinyu Zhu', 'Yuzhu Cai', 'Zexi Liu', 'Bingyang Zheng', 'Cheng Wang', 'Rui Ye', 'Jiaao Chen', 'Hanrui Wang', 'Wei-Chen Wang', 'Yuzhi Zhang', 'Linfeng Zhang', 'Weinan E', 'Di Jin', 'Siheng Chen']","The advancement of artificial intelligence toward agentic science is currently bottlenecked by the challenge of ultra-long-horizon autonomy, the ability to sustain strategic coherence and iterative correction over experimental cycles spanning days or weeks. While Large Language Models (LLMs) have demonstrated prowess in short-horizon reasoning, they are easily overwhelmed by execution details in high-dimensional, delayed-feedback environments of real-world research. This paper presents ML-Master 2.0, an autonomous agent that masters ultra-long-horizon machine learning engineering (MLE), a representative microcosm of scientific discovery. By reframing context management as a process of cognitive accumulation, our approach introduces Hierarchical Cognitive Caching (HCC), a multi-tiered architecture that enables the structural differentiation of experience over time. By dynamically distilling transient execution traces into stable knowledge and cross-task wisdom, HCC allows agents to decouple immediate execution from long-term experimental strategy, effectively overcoming the scaling limits of static context windows. Evaluations on OpenAI's MLE-Bench under 24-hour budgets demonstrate that ML-Master 2.0 achieves a state-of-the-art medal rate of 56.44%. Our findings demonstrate that ultra-long-horizon autonomy provides a scalable blueprint for AI capable of autonomous exploration beyond human-precedent complexities.",309.3,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10406v1_ErrEval Error-Aware Evaluation for Question Genera.pdf,ErrEval: Error-Aware Evaluation for Question Generation through Explicit Diagnostics,"['Weiping Fu', 'Bifan Wei', 'Jingyi Hao', 'Yushun Zhang', 'Jian Zhang', 'Jiaxin Wang', 'Bo Li', 'Yu He', 'Lingling Zhang', 'Jun Liu']","Automatic Question Generation (QG) often produces outputs with critical defects, such as factual hallucinations and answer mismatches. Existing evaluation methods, including LLM-based evaluators, mainly adopt a black-box and holistic paradigm without explicit error modeling, leading to the neglect of such defects and overestimation of question quality. To address this issue, ErrEval proposes a flexible and error-aware evaluation framework that enhances QG evaluation through explicit error diagnostics. Specifically, ErrEval reformulates evaluation as a two-stage process of error diagnosis followed by informed scoring. At the first stage, a lightweight plug-and-play Error Identifier detects and categorizes common errors across structural, linguistic, and content-related aspects. These diagnostic signals are then incorporated as explicit evidence to guide LLM evaluators toward more fine-grained and grounded judgments. Extensive experiments on three benchmarks demonstrate the effectiveness of ErrEval, showing that incorporating explicit diagnostics improves alignment with human judgments. Further analyses confirm that ErrEval effectively mitigates the overestimation of low-quality questions.",313.56,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10413v1_LADFA A Framework of Using Large Language Models a.pdf,LADFA: A Framework of Using Large Language Models and Retrieval-Augmented Generation for Personal Data Flow Analysis in Privacy Policies,"['Haiyue Yuan∗', 'Nikolay Matyunin', 'Ali Raza', 'Shujun Li∗']","This paper presents the development of LADFA, an end-to-end computational framework for processing unstructured text in privacy policies, extracting personal data flows, and constructing a personal data flow graph. The framework combines large language models (LLMs) with retrieval-augmented generation (RAG) and a customised knowledge base derived from existing studies. The authors demonstrate and validate the effectiveness and accuracy of LADFA by conducting a case study involving ten selected privacy policies from the automotive industry. LADFA is designed to be flexible and customisable, making it suitable for a range of text-based analysis tasks beyond privacy policy analysis.",312.14,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10416v1_LLMdoctor Token-Level Flow-Guided Preference Optim.pdf,LLMdoctor: Token-Level Flow-Guided Preference Optimization for Efficient Test-Time Alignment of Large Language Models,"['Tiesunlong Shen', 'Rui Mao', 'Jin Wang', 'Heming Sun', 'Jian Zhang', 'Xuejie Zhang', 'Erik Cambria']","This paper introduces LLMdoctor, a novel framework for efficient test-time alignment of large language models (LLMs). Unlike traditional fine-tuning methods, LLMdoctor operates via a patient-doctor paradigm, integrating token-level reward acquisition with token-level flow-guided preference optimization (TFPO). It extracts fine-grained token-level preference signals from the patient model's behavioral variations and guides the training of the doctor model via TFPO, ensuring precise token-by-token alignment while preserving generation diversity. Extensive experiments demonstrate that LLMdoctor significantly outperforms existing test-time alignment methods and even surpasses the performance of full fine-tuning approaches like DPO.",308.36,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10421v1_Are Language Models Models.pdf,Are Language Models Models?,['Philip Resnik'],"Futrell and Mahowald claim that Language Models (LMs) serve as model systems, but an assessment at each of Marr's three levels suggests the claim is not true at the implementation level, poorly motivated at the algorithmic-representational level, and problematic at the computational theory level. LMs are good candidates as tools; calling them cognitive models overstates the case and unnecessarily feeds LLM hype.",312.28,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10436v1_Development of Ontological Knowledge Bases by Leve.pdf,Development of Ontological Knowledge Bases by Leveraging Large Language Models,"['LE Ngoc Luyen', 'Marie-Hélène ABEL', 'Philippe GOUSPILLOU']","Ontological Knowledge Bases (OKBs) are crucial for structuring domain-specific knowledge and serve as a foundation for effective knowledge management systems. However, their traditional manual development faces challenges related to scalability, consistency, and adaptability. Recent advancements in Generative AI, particularly Large Language Models (LLMs), offer promising solutions for automating and enhancing OKB development. This paper introduces a structured, iterative methodology leveraging LLMs to optimize knowledge acquisition, automate ontology artifact generation, and enable continuous refinement cycles. The approach is demonstrated through a detailed case study focused on developing a user context profile ontology within the vehicle sales domain. Key contributions include significantly accelerated ontology construction processes, improved ontological consistency, effective bias mitigation, and enhanced transparency in the ontology engineering process. The findings highlight the transformative potential of integrating LLMs into ontology development, notably improving scalability, integration capabilities, and overall efficiency in knowledge management systems.",313.97,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10440v1_AgentGuardian Learning Access Control Policies to .pdf,Learning Access Control Policies to Govern AI Agent Behavior,"['Nadya Abaev*', 'Denis Klimov *', 'Gerard Levinov', 'David Mimran', 'Yuval Elovici', 'Asaf Shabtai']","Artificial intelligence (AI) agents are increasingly used in various domains to automate tasks, interact with users, and make decisions based on data inputs. Ensuring that AI agents perform only authorized actions and handle inputs appropriately is essential for maintaining system integrity and preventing misuse. This study introduces the AgentGuardian, a novel security framework that governs and protects AI agent operations by enforcing context-aware access-control policies. During a controlled staging phase, the framework monitors execution traces to learn legitimate agent behaviors and input patterns. From this phase, it derives adaptive policies that regulate tool calls made by the agent, guided by both real-time input context and the control flow dependencies of multi-step agent actions. Evaluation across two real-world AI agent applications demonstrates that AgentGuardian effectively detects malicious or misleading inputs while preserving normal agent functionality. Moreover, its control-flow-based governance mechanism mitigates hallucination-driven errors and other orchestration-level malfunctions.",314.75,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10457v1_NSR-Boost A Neuro-Symbolic Residual Boosting Frame.pdf,NSR-Boost: A Neuro-Symbolic Residual Boosting Framework for Industrial Legacy Models,"['Ziming Dai', 'Dabiao Ma', 'Jinle Tong', 'Mengyuan Han', 'Jian Yang', 'Haojun Fei']","Although Gradient Boosted Decision Trees (GBDTs) dominate industrial tabular applications, upgrading legacy models in high-concurrency production environments still faces prohibitive retraining costs and systemic risks. To address this problem, the authors present NSR-Boost, a neuro-symbolic residual boosting framework designed specifically for industrial scenarios. Its core advantage lies in being 'non-intrusive'. It treats the legacy model as a frozen model and performs targeted repairs on 'hard regions' where predictions fail. The framework comprises three key stages: finding hard regions through residuals, generating interpretable experts using Large Language Model (LLM) and fine-tuning parameters using Bayesian optimization, and dynamically integrating experts with legacy model output through a lightweight aggregator. The authors report on the successful deployment of NSR-Boost within the core financial risk control system at Qfin Holdings, showing significant performance gains on real-world online data and excellent performance on public and private datasets.",313.94,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10460v1_Contextual StereoSet Stress-Testing Bias Alignment.pdf,Contextual StereoSet: Stress-Testing Bias Alignment Robustness in Large Language Models,"['Abhinaba Basu', 'Pavan Chakraborty']","The paper introduces Contextual StereoSet, a benchmark that systematically varies contextual framing while holding stereotype content fixed. Testing 13 models across two protocols, the authors find striking patterns in bias shifts, such as anchoring to 1990 versus 2030 raising stereotype selection in all models tested on this contrast, and gossip framing raising it in 5 of 6 full-grid models. The authors propose Context Sensitivity Fingerprints (CSF) for evaluating bias sensitivity and release their benchmark, code, and results. The paper suggests that bias scores from fixed-condition tests may not generalize and proposes Context Sensitivity Fingerprints (CSF) as a compact profile of per-dimension dispersion and paired contrasts with bootstrap CIs and FDR correction.",315.38,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10462v3_ChartComplete A Taxonomy-based Inclusive Chart Dat.pdf,ChartComplete: A Taxonomy-based Inclusive Chart Dataset,"['Ahmad Mustapha', 'Charbel Toumieh', 'Mariette Awad']","With advancements in deep learning (DL) and computer vision techniques, the field of chart understanding is evolving rapidly. In particular, multi-modal large language models (MLLMs) are proving to be efficient and accurate in understanding charts. To accurately measure the performance of MLLMs, the research community has developed multiple datasets to serve as benchmarks. By examining these datasets, we found that they are all limited to a small set of chart types. To bridge this gap, we propose the ChartComplete dataset. The dataset is based on a chart taxonomy borrowed from the visualization community, and it covers thirty different chart types. The dataset is a collection of classified chart images and doesn’t include a learning signal. We present the ChartComplete dataset as is to the community to build upon it.",314.96,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10477v1_Urban Socio-Semantic Segmentation with Vision-Lang.pdf,URBANSOCIO-SEMANTICSEGMENTATION WITH VISION-LANGUAGEREASONING,"['Yu Wang', 'Yi Wang', 'Rui Dai', 'Yujie Wang', 'Kaikui Liu', 'Xiangxiang Chu', 'Yansheng Li']","This work achieves socio-semantic segmentation by vision-language model reasoning. It introduces the Urban Socio-Semantic Segmentation dataset named SocioSeg, comprising satellite imagery, digital maps, and pixel-level labels of social semantic entities organized in a hierarchical structure. Additionally, it proposes a novel vision-language reasoning framework called SocioReasoner, which simulates the human process of identifying and annotating social semantic entities via cross-modal recognition and multi-stage reasoning. The approach is optimized using reinforcement learning and demonstrates gains over state-of-the-art models and strong zero-shot generalization. The dataset and code are available in github.com/AMAP-ML/SocioReasoner.",313.54,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10485v1_Panning for Gold Expanding Domain-Specific Knowled.pdf,Panning for Gold: Expanding Domain-Specific Knowledge Graphs with General Knowledge,"['Runhao Zhao', 'Weixin Zeng', 'Wentao Zhang', 'Chong Chen', 'Zhengpin Li', 'Xiang Zhao', 'Lei Chen']","Domain-specific knowledge graphs (DKGs) are essential for supporting intelligent applications in specialized fields, but they often suffer from limited coverage and incompleteness compared to general knowledge graphs (GKGs) such as Wikipedia and YAGO. Existing tasks to enrich DKGs rely primarily on extracting knowledge from unstructured data or completing KGs through internal reasoning, but the scope and quality of such integration remain limited. This highlights a critical gap: little systematic exploration has been conducted on how comprehensive, high-quality GKGs can be effectively leveraged to supplement DKGs. To address this gap, the authors propose a new task: domain-specific knowledge graph fusion (DKGF), which aims to mine and integrate relevant facts from general knowledge graphs into domain-specific knowledge graphs to enhance their completeness and utility. Unlike previous research, this new task faces two key challenges: high ambiguity of domain relevance and cross-domain knowledge granularity misalignment. To tackle these challenges, the authors propose ExeFuse, a Fact-as-Program paradigm that reformulates DKGF as executable semantic reasoning over DKGs. By unifying relevance assessment and granularity transformation within a single probabilistic framework, ExeFuse enables precise identification and integration of domain-relevant, consistent knowledge from GKGs. The authors construct two new benchmark datasets (DKGF(W-I) and DKGF(Y-I)) and propose 21 representative benchmark configurations to systematically assess DKGF performance. Extensive experiments highlight the value of the new task and demonstrate the effectiveness of ExeFuse, providing the first standardized evaluation suite for this emerging task.",313.06,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10496v1_Model See Model Do Exposure-Aware Evaluation of Bu.pdf,"Model See, Model Do? Exposure-Aware Evaluation of Bug-vs-Fix Preference in Code LLMs","['Ali Al-Kaswan', 'Claudio Spiess', 'Prem Devanbu', 'Arie van Deursen', 'Maliheh Izadi']","Large language models are increasingly used for code generation and debugging, but their outputs can still contain bugs. This paper introduces an exposure-aware evaluation framework to quantify how prior exposure to buggy versus fixed code influences a model's preference. Using the ManySStuBs4J benchmark and the Stack-V2 corpus, the authors estimate whether each variant was seen during training and stratify examples by exposure. They find that most examples have neither variant in the training data, and when only one is present, fixes are more frequently present than bugs. In model generations, models reproduce buggy lines far more often than fixes, with bug-exposed examples amplifying this tendency and fix-exposed examples showing only marginal improvement. Likelihood scoring metrics consistently prefer the fixed code, indicating a stable bias toward correct fixes, while metrics like the Gini coefficient reverse preference when only the buggy variant is seen. The results highlight the risk that LLMs may propagate memorised errors in practice.",313.73,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10498v1_Projected Microbatch Accumulation yields reference.pdf,Projected Microbatch Accumulation yields reference-free proximal policy updates for reinforcement learning,['Nilin Abrahamsen'],"This note introduces Projected Microbatch Accumulation (PROMA), a proximal policy update method for large language model fine-tuning. PROMA accumulates policy gradients across microbatches by projecting out sequence-wise gradient components before microbatch aggregation. Unlike PPO and GRPO, PROMA achieves proximal updates without inducing entropy collapse and does not rely on a reference policy or likelihood-ratio clipping.",314.92,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10511v1_Scalable Algorithms for Approximate DNF Model Coun.pdf,Scalable Algorithms for Approximate DNF Model Counting,"['Paul Burkhardt', 'David G. Harris', 'Kevin T. Schmitt']","The paper develops a new Monte Carlo approach for approximate DNF model counting, which achieves Probably Approximately Correct (PAC) learning bounds and is asymptotically more efficient than previous methods. It outperforms prior algorithms by orders of magnitude and can scale to much larger problems with millions of variables.",317.33,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10512v2_SatMap Revisiting Satellite Maps as Prior for Onli.pdf,SatMap: Revisiting Satellite Maps as Prior for Online HD Map Construction,"['Kanak Mazumder', 'Fabian B. Flohr']","Online high-definition (HD) map construction is an essential part of a safe and robust end-to-end autonomous driving (AD) pipeline. Onboard camera-based approaches suffer from limited depth perception and degraded accuracy due to occlusion. In this work, the authors propose SatMap, an online vectorized HD map estimation method that integrates satellite maps with multi-view camera observations and directly predicts a vectorized HD map for downstream prediction and planning modules. Our method leverages lane-level semantics and texture from satellite imagery captured from a Bird’s Eye View (BEV) perspective as a global prior, effectively mitigating depth ambiguity and occlusion. In experiments on the nuScenes dataset, SatMap achieves 34.8% mAP performance improvement over the camera-only baseline and 8.5% mAP improvement over the camera-LiDAR fusion baseline. Moreover, the model is evaluated in long-range and adverse weather conditions to demonstrate the advantages of using a satellite prior map.",316.26,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10520v1_Breaking Up with Normatively Monolithic Agency wit.pdf,Breaking Up with Normatively Monolithic Agency: A Reason-Based Neuro-Symbolic Architecture for Safe and Ethical AI Alignment,"['Felix Jahn', 'Yannic Muskalla', 'Lisa Dargasz', 'Patrick Schramowski', 'Kevin Baum']","The paper introduces GRACE, a neuro-symbolic reason-based containment architecture that decouples normative reasoning from instrumental decision-making. GRACE restructures decision-making into three modules: a Moral Module (MM) that determines permissible macro actions via deontic logic-based reasoning; a Decision-Making Module (DMM) that encapsulates the target agent while selecting instrumentally optimal primitive actions in accordance with derived macro actions; and a Guard that monitors and enforces moral compliance. The MM uses a reason-based formalism providing a semantic foundation for deontic logic, enabling interpretability, contestability, and justifiability. Its symbolic representation enriches the DMM’s informational context and supports formal verification and statistical guarantees of alignment enforced by the Guard. The authors demonstrate GRACE on an example of a LLM therapy assistant, showing how it enables stakeholders to understand, contest, and refine agent behavior.",314.96,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10524v1_Diagnosing Generalization Failures in Fine-Tuned L.pdf,Diagnosing Generalization Failures in Fine-Tuned LLMs: A Cross-Architectural Study on Phishing Detection,"['Frank Bobe IIIFrank Bobe IIIFrank Bobe III∗', 'Gregory D. Vetaw', 'Chase Pavlick', 'Darshan Bryner', 'Matthew Cook', 'Jose Salas-Vernis']","The practice of fine-tuning Large Language Models (LLMs) has achieved state-of-the-art performance on specialized tasks, yet diagnosing why these models become brittle and fail to generalize remains a critical open problem. To address this, we introduce and apply a multi-layered diagnostic framework to a cross-architectural study. We fine-tune Llama 3.1 8B, Gemma 2 9B, and Mistral models on a high-stakes phishing detection task and use SHAP analysis and mechanistic interpretability to uncover the root causes of their generalization failures. Our investigation reveals three critical findings: (1) Generalization is driven by a powerful synergy between architecture and data diversity. The Gemma 2 9B model achieves state-of-the-art performance (>91% F1), but only when trained on a stylistically diverse “generalist” dataset. (2) Generalization is highly architecture-dependent. We diagnose a specific failure mode in Llama 3.1 8B, which performs well on a narrow domain but cannot integrate diverse data, leading to a significant performance drop. (3) Some architectures are inherently more generalizable. The Mistral model proves to be a consistent and resilient performer across multiple training paradigms. By pinpointing the flawed heuristics responsible for these failures, our work provides a concrete methodology for diagnosing and understanding generalization failures, underscoring that reliable AI requires deep validation of the interplay between architecture, data, and training strategy.",314.68,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10527v2_A Safety Report on GPT-5.2 Gemini 3 Pro Qwen3-VL G.pdf,"A Safety Report on GPT-5.2, Gemini 3 Pro, Qwen3-VL, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5","['Xingjun Ma', 'Yixu Wang', 'Hengyuan Xu', 'Yutao Wu', 'Yifan Ding', 'Yunhan Zhao', 'Zilong Wang', 'Jiabin Hua', 'Ming Wen', 'Jianan Liu', 'Yifeng Gao', 'Yingshui Tan', 'Yunhao Chen', 'Hui Xue', 'Xin Wang', 'Wei Cheng', 'Jingjing Chen', 'Zuxuan Wu', 'Bo Li', 'Yu-Gang Jiang']","The rapid evolution of Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) has driven major gains in reasoning, perception, and generation across language and vision. However, the safety improvements of these models are unclear, partly due to fragmented evaluations. This report presents an integrated safety evaluation of six frontier models: GPT-5.2, Gemini 3 Pro, Qwen3-VL, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5. The evaluation covers language, vision-language, and image generation settings using a unified protocol that integrates benchmark evaluation, adversarial evaluation, multilingual evaluation, and compliance evaluation. The results reveal a highly uneven safety landscape, with GPT-5.2 demonstrating consistent strong and balanced performance, while other models exhibit clear trade-offs across benchmarks, adversarial robustness, multilingual generalization, and regulatory compliance. Despite achieving strong results under standard benchmark evaluations, all models remain highly vulnerable under adversarial testing, with worst-case safety rates dropping below 6%. The report highlights that safety in frontier models is multidimensional and emphasizes the need for standardized, holistic safety assessments to better reflect real-world risk and guide responsible deployment.",315.67,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10543v1_Defending Large Language Models Against Jailbreak .pdf,Defending Large Language Models Against Jailbreak Attacks via In-Decoding Safety-Awareness Probing,"['Yinzhi Zhao', 'Ming Wang', 'Shi Feng', 'Xiaocui Yang', 'Daling Wang', 'Yifei Zhang']","This paper examines the decoding process of Large Language Models (LLMs) and observes that even when successfully jailbroken, models internally exhibit latent safety-related signals during generation. These signals are overridden by the model's drive for fluent continuation, preventing timely self-correction or refusal. The authors propose a simple yet effective approach that explicitly surfaces and leverages these latent safety signals for early detection of unsafe content during decoding. Experiments across diverse jailbreak attacks demonstrate that this approach significantly enhances safety, while maintaining low over-refusal rates on benign inputs and preserving response quality. The results suggest that activating intrinsic safety-awareness during decoding offers a promising and complementary direction for defending against jailbreak attacks.",314.24,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10560v1_Learning Latency-Aware Orchestration for Parallel .pdf,Learning Latency-Aware Orchestration for Parallel Multi-Agent Systems,"['Xi Shi', 'Mengxin Zheng', 'Qian Lou']","Multi-agent systems (MAS) enable complex reasoning by coordinating multiple agents, but often incur high inference latency due to multi-step execution and repeated model invocations, severely limiting their scalability and usability in time-sensitive scenarios. Most existing approaches primarily optimize task performance and inference cost, and explicitly or implicitly assume sequential execution, making them less optimal for controlling latency under parallel execution. This work investigates the learning-based orchestration of multi-agent systems with explicit latency supervision under parallel execution, proposing Latency-Aware Multi-agent System (LAMaS), a latency-aware multi-agent orchestration framework that enables parallel execution and explicitly optimizes the critical execution path. Experiments show that our approach reduces critical path length by 38–46% compared to the SOTA baseline for multi-agent architecture search across multiple benchmarks while maintaining or even improving task performance, highlighting the importance of explicitly optimizing for latency under parallel execution when designing efficient multi-agent systems.",313.96,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10562v1_Process-Guided Concept Bottleneck Model.pdf,Process-Guided Concept Bottleneck Model,"['Reza M. Asiyabi', 'Sam Harrison', 'John L. Godlee', 'David Milodowski', 'Nicole H. Augustin', 'Penelope J. Mograbi', 'Timothy R. Baker', 'Lorena M. Benitez', 'Samuel J. Bowers', 'Thomas K. Brade', 'Joao M. B. Carreiras', 'Duncan M. Chalo', 'V era De Cauwer', 'Kyle G. Dexter', 'Hermane Diesse', 'Mathias I. Disney', 'Luisa F. Escobar-Alvarado', 'Manfred Finckh', 'Tatenda Gotore', 'Gabriele C. Hegerl', 'John N. Kigomo', 'Fainess C. Lumbwe', 'Francisco Maiato', 'Rudzani A. Makhado', 'Collins W. Masinde', 'Musingo Tito E. Mbuvi', 'Iain M. McNicol', 'Edward T.A. Mitchard', 'Buster P. Mogonong', 'Wilson A. Mugasha', 'Aristides Baptista Muhate', 'Hinji Mutondo', 'Leena Naftal', 'Paula Nieto-Quintano', 'Elifuraha Elisha Njoghomi', 'Catherine L. Parr', 'Oliver L. Phillips', 'Pierre Proces', 'Tshililo Ramaswiela', 'Jayashree Ratnam', 'Mathew Rees', 'Rasmus Revermann', 'Natasha Ribeiro', 'Mahesh Sankaran', 'Abel M. Siampale', 'Stephen Sitch', 'Kathleen G. Smart', 'Hemant G. Tripathi', 'Wayne Twine', 'Gabriel I.K. Uusiku', 'Helga van der Merwe', 'Chemuku Wekesa', 'Benjamin J. Wigley', 'Mathew Williams', 'Ellie Wood', 'Shaun Quegan', 'Steven Hancock', 'Casey M. Ryan']","This study presents a process-guided concept bottleneck model to analyze and predict the carbon dynamics in the dry tropics. The model integrates machine learning techniques with pattern analysis to identify and quantify the concept bottleneck, which is a critical factor affecting carbon fluxes. The research is supported by the UK NCEO and SECO grants, and field data are provided by the SEOSAW Partnership. The authors acknowledge the contributions of various researchers and institutions, as well as the use of AI-assisted tools for manuscript refinement.",312.32,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10567v1_Generative AI collective behavior needs an interac.pdf,Generative AI collective behavior needs an interactionist paradigm,"['Laura Ferrarotti', 'Gian Maria Campedelli', 'Roberto Dessì', 'Andrea Baronchelli', 'Giovanni Iacca', 'Kathleen M. Carley', 'Alex Pentland', 'Joel Z. Leibo', 'James Evans', 'Bruno Lepri']","In this article, the authors argue that understanding the collective behavior of agents based on large language models (LLMs) is an essential area of inquiry. They claim that the distinctive nature of LLMs, including their initialization with extensive pre-trained knowledge and implicit social priors, along with their capability of adaptation through in-context learning, motivates the need for an interactionist paradigm. This paradigm consists of alternative theoretical foundations, methodologies, and analytical tools to systematically examine how prior knowledge and embedded values interact with social context to shape emergent phenomena in multi-agent generative AI systems. The authors propose and discuss four crucial directions for the development and deployment of LLM-based collectives, focusing on theory, methods, and trans-disciplinary dialogue.",314.93,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10581v1_From Single to Multi-Agent Reasoning Advancing Gen.pdf,From Single to Multi-Agent Reasoning: Advancing GeneGPT for Genomics QA,"['Kimia Abedini', 'Farzad Shami', 'Gianmaria Silvello']","Comprehending genomic information is essential for biomed-ical research, yet extracting data from complex distributed databases remains challenging. Large language models (LLMs) offer potential for genomic Question Answering (QA) but face limitations due to restricted access to domain-specific databases. GeneGPT is the current state-of-the-art system that enhances LLMs by utilizing specialized API calls, though it is constrained by rigid API dependencies and limited adaptability. We replicate GeneGPT and propose GenomAgent, a multi-agent framework that efficiently coordinates specialized agents for complex genomics queries. Evaluated on nine tasks from the GeneTuring benchmark, GenomAgent outperforms GeneGPT by 12% on average, and its flexible architecture extends beyond genomics to various scientific domains needing expert knowledge extraction.",316.39,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10587v1_Adversarial Evasion Attacks on Computer Vision usi.pdf,Adversarial Evasion Attacks on Computer Vision using SHAP Values,"['Frank Mollard', 'Marcus Becker', 'Florian Röhrbein']",The paper introduces a white-box attack on computer vision models using SHAP values. It demonstrates how adversarial evasion attacks can compromise the performance of deep learning models by reducing output confidence or inducing misclassifications. Such attacks are particularly insidious as they can deceive the perception of an algorithm while eluding human perception due to their imperceptibility to the human eye. The proposed attack leverages SHAP values to quantify the significance of individual inputs to the output at the inference stage. A comparison is drawn between the SHAP attack and the well-known Fast Gradient Sign Method. We find evidence that SHAP attacks are more robust in generating misclassifications particularly in gradient hiding scenarios.,315.32,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10591v1_ProbFM Probabilistic Time Series Foundation Model .pdf,Probabilistic Time Series Foundation Model with Uncertainty Decomposition,"['Arundeep Chinta', 'Lucas Vinh Tran', 'Jay Katukuri']","This work presents a novel transformer-based probabilistic framework, ProbFM, that leverages Deep Evidential Regression (DER) to provide principled uncertainty quantification with explicit epistemic-aleatoric decomposition. Unlike existing approaches that pre-specify distributional forms or require sampling-based inference, ProbFM learns optimal uncertainty representations through higher-order evidence learning while maintaining single-pass computational efficiency. The authors conduct an extensive controlled comparison study using a consistent LSTM architecture across five probabilistic methods to rigorously evaluate DER's effectiveness. Evaluation on cryptocurrency return forecasting demonstrates that DER maintains competitive forecasting accuracy while providing explicit epistemic-aleatoric uncertainty decomposition. The practical value of uncertainty-aware trading strategies is demonstrated, showing how epistemic-aleatoric decomposition enables effective risk management by filtering high-uncertainty predictions. This work establishes both an extensible framework for principled uncertainty quantification in foundation models and empirical evidence for DER's effectiveness in financial applications.",314.66,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10600v1_Procedural Fairness in Multi-Agent Bandits.pdf,Procedural Fairness in Multi-Agent Bandits,"['Joshua Caiata', 'Carter Blair', 'Kate Larson']","In the context of multi-agent multi-armed bandits (MA-MAB), fairness is often reduced to outcomes: maximizing welfare, reducing inequality, or balancing utilities. However, evidence suggests that fairness is also about process and who gets a say in the decisions being made. This paper introduces a new fairness objective, procedural fairness, which provides equal decision-making power for all agents, lies in the core, and provides for proportionality in outcomes. Empirical results confirm that fairness notions based on optimizing for outcomes sacrifice equal voice and representation, while the sacrifice in outcome-based fairness objectives (like equality and utilitarianism) is minimal under procedurally fair policies. The paper argues that procedural legitimacy deserves greater focus as a fairness objective and provides a framework for putting procedural fairness into practice.",315.95,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10611v1_Molmo2 Open Weights and Data for Vision-Language M.pdf,Open Weights and Data for Vision-Language Models with Video Understanding and Grounding,"['Christopher Clark', 'Jieyu Zhang', 'Zixian Ma', 'Jae Sung Park', 'Mohammadreza Salehi', 'Rohun Tripathi', 'Sangho Lee', 'Zhongzheng Ren', 'Chris Dongjoo Kim', 'Yinuo Yang', 'Vincent Shao', 'Yue Yang', 'Weikai Huang', 'Ziqi Gao', 'Taira Anderson', 'Jianrui Zhang', 'Jitesh Jain', 'George Stoica', 'Winson Han', 'Ali Farhadi', 'Ranjay Krishna']","Presenting Molmo2, a new family of Vision-Language Models (VLMs) that are state-of-the-art among open-source models and demonstrate exceptional new capabilities in point-driven grounding in single image, multi-image, and video tasks. The key contribution includes 7 new video datasets and 2 multi-image datasets, collected without the use of closed VLMs, and a training recipe utilizing an efficient packing and message-tree encoding scheme. The 8B model outperforms others in short videos, counting, and captioning, and is competitive on long videos. Molmo2 significantly outperforms existing open-weight models on video-grounding tasks.",313.63,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10651v1_Multi-Property Synthesis.pdf,Multi-Property Synthesis,"['Christoph Weinhuber', 'Yannik Schnitzer', 'Alessandro Abate', 'David Parker', 'Giuseppe De Giacomo', 'Moshe Y. Vardi']","The paper studies LTLf synthesis with multiple properties, where satisfying all properties may be impossible. Instead of enumerating subsets of properties, the authors compute the relation between product-game states and the goal sets that are realizable from them, and synthesize strategies achieving maximal realizable sets. They develop a fully symbolic algorithm that introduces Boolean goal variables and exploits monotonicity to represent exponentially many goal combinations compactly. The approach substantially outperforms enumeration-based baselines, with speedups of up to two orders of magnitude.",311.94,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10679v1_Are Your Reasoning Models Reasoning or Guessing A .pdf,Are Your Reasoning Models Reasoning or Guessing?,"['Zirui Ren', 'Ziming Liu']","This paper conducts a mechanistic study on hierarchical reasoning models (HRM) and finds three surprising facts about their reasoning patterns. HRM can fail on extremely simple puzzles due to the violation of the fixed point property. The answer is not improved uniformly but there is a critical reasoning step that suddenly makes the answer correct. HRM 'guesses' the first fixed point, which could be incorrect and gets trapped there for a while or forever. The authors propose three strategies to scale HRM's guesses: data augmentation, input perturbation, and model bootstrapping. By combining these methods, Augmented HRM boosts accuracy on Sudoku-Extreme from 54.5% to 96.9%. The analysis provides new insights into how reasoning models 'reason'.",314.21,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10681v1_Structure and Diversity Aware Context Bubble Const.pdf,Structure and Diversity Aware Context Bubble Construction for Enterprise Retrieval Augmented Systems,"['Amir Khurshid1a*', 'Abhishek Sehgal1b']","Large language model (LLM) contexts are typically constructed using retrieval-augmented generation (RAG), which involves ranking and selecting the top-k passages. This approach causes fragmentation in information graphs, over-retrieval, and duplication of content. The paper proposes a structure-informed and diversity-constrained context bubble construction framework that assembles coherent, citable bundles of spans under a strict token budget. The method preserves and exploits inherent document structure by organizing multi-granular spans and using task-conditioned structural priors to guide retrieval. Starting from high-relevance anchor spans, a context bubble is constructed through constrained selection that balances query relevance, marginal coverage, and redundancy penalties. It explicitly constrains diversity and budget, producing compact and informative context sets, unlike top-k retrieval. Moreover, a full retrieval is emitted that traces the scoring and selection choices of the records, thus providing auditability and deterministic tuning. Experiments on enterprise documents demonstrate the efficiency of context bubble as it significantly reduces redundant context, is better able to cover secondary facets, and has better answer quality and citation faithfulness within a limited context window. Ablation studies show that both structural priors and diversity constraint selection are necessary; removing either component results in a decline in coverage and an increase in redundant or incomplete context.",315.38,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10684v1_On the origin of neural scaling laws from random g.pdf,On the origin of neural scaling laws: from random graphs to natural language,"['Maissam Barkeshli', 'Alberto Alfarano', 'Andrey Gromov']","This paper studies scaling laws for transformers trained to predict random walks (bigrams) on graphs with tunable complexity. It demonstrates that even in the absence of power law structure in the data correlations, neural scaling laws can arise. The authors also consider natural language by systematically dialing down its complexity and reveal a monotonic evolution of scaling exponents. Additionally, they explore scaling laws from training on random walks on random graphs and provide preliminary evidence for maximal update parameterization being more parameter efficient than standard parameterization.",310.07,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10696v1_The Impact of Generative AI on Architectural Conce.pdf,"The Impact of Generative AI on Architectural Conceptual Design: Performance, Creative Self-Efficacy and Cognitive Load","['Han Jiang', 'Yao Xiao', 'Rachel Hurley', 'Shichao Liu']","Our study examines how generative AI (GenAI) influences performance, creative self-efficacy, and cognitive load in architectural conceptual design tasks. Thirty-six student participants from Architectural Engineering and other disciplines completed a two-phase architectural design task, first independently and then with external tools (GenAI-assisted condition and control condition using an online repository of existing architectural projects). Design outcomes were evaluated by expert raters, while self-efficacy and cognitive load were self-reported after each phase. Difference-in-differences analyses revealed no overall performance advantage of GenAI across participants; however, subgroup analyses showed that GenAI significantly improved design performance for novice designers. In contrast, general creative self-efficacy declined for students using GenAI. Cognitive load did not differ significantly between conditions, though prompt usage patterns showed that iterative idea-generation and visual feedback prompts were linked to greater reduction in cognitive load. These findings suggest that GenAI’s effectiveness depends on users’ prior expertise and interaction strategies through prompting.",315.72,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10700v2_LIBERTy A Causal Framework for Benchmarking Concep.pdf,LIBERTy: A Causal Framework for Benchmarking Concept-Based Explanations of LLMs with Structural Counterfactuals,"['Gilat Toker', 'Nitay Calderon', 'Ohad Amosy', 'Roi Reichart']","This paper introduces LIBERTy, a framework for constructing datasets containing structural counterfactual pairs to benchmark concept-based explanations of Large Language Models (LLMs). LIBERTy is grounded in explicitly defined Structured Causal Models (SCMs) of the text generation, where interventions on a concept propagate through the SCM until an LLM generates the counterfactual. The authors introduce three datasets (disease detection, CV screening, and workplace violence prediction) and a new evaluation metric, order-faithfulness. Using these datasets, they evaluate a wide range of methods across five models and identify substantial headroom for improving concept-based explanations. LIBERTy also enables systematic analysis of model sensitivity to interventions, revealing that proprietary LLMs show markedly reduced sensitivity to demographic concepts, likely due to post-training mitigation. Overall, LIBERTy provides a much-needed benchmark for developing faithful explainability methods.",310.27,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10702v1_Grounding Agent Memory in Contextual Intent.pdf,Grounding Agent Memory in Contextual Intent,"['Ruozhen Yang', 'Yucheng Jiang', 'Yueqi Jiang', 'Priyanka Kargupta', 'Yunyi Zhang', 'Jiawei Han']","Deploying large language models in long-horizon, goal-oriented interactions remains challenging due to the recurrence of similar entities and facts under different latent goals and constraints. The paper proposes STITCH (StructuredIntentTracking in ContextualHistory), an agentic memory system that indexes each trajectory step with a structured retrieval cue, contextual intent, and retrieves history by matching the current step’s intent. Contextual intent provides compact signals that disambiguate repeated mentions and reduce interference. During inference, STITCH filters and prioritizes memory snippets by intent compatibility, suppressing semantically similar but context-incompatible history. The paper introduces CAME-Bench, a benchmark for context-aware retrieval in realistic, dynamic, goal-oriented trajectories, and achieves state-of-the-art performance, outperforming the strongest baseline by 35.6%.",313.41,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10712v1_MatchTIR Fine-Grained Supervision for Tool-Integra.pdf,MatchTIR: Fine-Grained Supervision for Tool-Integrated Reasoning via Bipartite Matching,"['Changle Qu', 'Sunhao Dai', 'Hengyi Cai', 'Jun Xu', 'Shuaiqiang Wang', 'Dawei Yin']","MatchTIR is a framework that introduces fine-grained supervision via bipartite matching-based turn-level reward assignment and dual-level advantage estimation. It addresses the coarse-grained credit assignment issue in existing reinforcement learning methods, which fails to distinguish effective tool calls from redundant or erroneous ones, particularly in long-horizon multi-turn scenarios. Extensive experiments on three benchmarks demonstrate the superiority of MatchTIR, with a 4B model surpassing the majority of 8B competitors, particularly in long-horizon and multi-turn tasks.",313.12,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10748v1_AnyECG Evolved ECG Foundation Model for Holistic H.pdf,AnyECG: Evolved ECG Foundation Model for Holistic Health Profiling,"['Jun Li', 'Hongling Zhu', 'Yujie Xiao', 'Qinghao Zhao', 'Yalei Ke', 'Gongzheng Tang', 'Guangkun Nie', 'Deyun Zhang', 'Jin Li', 'Canqing Yu', 'Shenda Hong']","This study constructs a large-scale, multicenter electrocardiogram (ECG) dataset containing 13,348,593 ECG records and their corresponding ICD diagnostic codes from 2,984,209 patients. The dataset integrates retrospective and prospective data, providing a foundation for multiple tasks including current disease diagnosis, future risk prediction, and comorbidity identification. The authors employed a transfer learning strategy to fine-tune the pre-trained ECGFounder, developing an improved ECG foundation model, AnyECG, aimed at significantly enhancing its capabilities in holistic health profiling. The model achieved an AUROC above 0.7 for 306 of the 1,172 ICD-coded conditions, revealing many novel discoveries and demonstrating robustness in current diagnosis, future prediction, and comorbidity identification in a 10-year longitudinal cohort study.",314.2,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10768v1_Optimisation of complex product innovation process.pdf,OPTIMISATION OF COMPLEX PRODUCT INNOVATION PROCESSES BASED ON TREND MODELS WITH THREE-VALUED LOGIC,"['NINA BO ˇCKOV´A', 'BARBORA VOLN ´A', 'MIRKO DOHNAL']","This paper investigates complex product-innovation processes using models grounded in a set of heuristics. Each heuristic is expressed through simple trends – increasing, decreasing, or constant – which serve as minimally information-intensive quantifiers, avoiding reliance on numerical values or rough sets. A solution to a trend model is defined as a set of scenarios with possible transitions between them, represented by a transition graph. Any possible future or past behavior of the system under study can thus be depicted by a path within this graph.",316.4,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10770v1_Unifying Speech Recognition Synthesis and Conversi.pdf,"UNIFYINGSPEECHRECOGNITION, SYNTHESIS AND CONVERSION WITHAUTOREGRESSIVETRANSFORMERS","['Runyuan Cai', 'Yu Lin', 'Yiming Wang', 'Chunlin Fu', 'Xiaodong Zeng']","Traditional speech systems typically rely on separate, task-specific models for text-to-speech (TTS), automatic speech recognition (ASR), and voice conversion (VC), resulting in fragmented pipelines that limit scalability, efficiency, and cross-task generalization. In this paper, we present General-Purpose Audio (GPA) * , a unified audio foundation model that integrates multiple core speech tasks within a single large language model (LLM) architecture. GPA operates on a shared discrete audio token space and supports instruction-driven task induction, enabling a single autoregressive model to flexibly perform TTS, ASR, and VC without architectural modifications. This unified design combines a fully autoregressive formulation over discrete speech tokens, joint multi-task training across speech domains, and a scalable inference pipeline that achieves high concurrency and throughput. The resulting model family supports efficient multi-scale deployment, including a lightweight 0.3B-parameter variant optimized for edge and resource-constrained environments. Together, these design choices demonstrate that a unified autoregressive architecture can achieve competitive performance across diverse speech tasks while remaining viable for low-latency, practical deployment.",315.67,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10773v1_LogicLens Leveraging Semantic Code Graph to explor.pdf,LogicLens: Leveraging Semantic Code Graph to explore Multi Repository large systems,"['Niko Usai', 'Dario Montagnini', 'Kristian Ilianov Iliev', 'Raffaele Camanzo']","Understanding large software systems is a challenging task, especially when code is distributed across multiple repositories and microservices. Developers often need to reason not only about the structure of the code, but also about its domain logic and runtime behaviors, which are typically implicit and scattered. We introduce LogicLens, a reactive conversational agent that assists developers in exploring complex software systems through a semantic multi-repository graph. This graph is built in a preprocessing step by combining syntactic code analysis, via AST parsing and repository traversal, with semantic enrichment using Large Language Models (LLMs). The resulting graph captures both structural elements, such as files, classes, and functions, as well as functional abstractions like domain entities, operations, and workflows. Once the graph is constructed, LogicLens enables developers to interact with it via natural language, dynamically retrieving relevant subgraphs and answering technical or functional queries. We present the architecture of the system, discuss emergent behaviors, and evaluate its effectiveness on real-world multi-repository scenarios. We demonstrate emergent capabilities including impact analysis and symptom-based debugging that arise naturally from the semantic graph structure.",313.71,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10779v1_Unified Optimization of Source Weights and Transfe.pdf,Unified Optimization of Source Weights and Transfer Quantities in Multi-Source Transfer Learning: An Asymptotic Framework,"['Qingyue Zhang', 'Chang Chu', 'Haohao Fu', 'Tianren Peng', 'Yanru Wu', 'Guanbo Huang', 'Yang Li', 'Shao-Lun Huang']","Transfer learning plays a vital role in improving model performance in data-scarce scenarios. However, naive uniform transfer from multiple source tasks may result in negative transfer, highlighting the need to properly balance the contributions of heterogeneous sources. The proposed Unified Optimization of Weights and Quantities (UOWQ) framework formulates multi-source transfer learning as a parameter estimation problem grounded in an asymptotic analysis of a Kullback–Leibler divergence-based generalization error measure. The framework jointly determines the optimal source weights and optimal transfer quantities for each source task. The authors prove that using all available source samples is always optimal once the weights are properly adjusted and provide a theoretical explanation for this phenomenon. Moreover, the analysis yields closed-form solutions in the single-source setting and develops a convex optimization-based numerical procedure for the multi-source case. The theoretical results are validated through practical algorithms for both multi-source transfer learning and multi-task learning settings, demonstrating consistent performance on real-world benchmarks.",314.99,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10810v1_Digital Metabolism Decoupling Logic from Facts via.pdf,Digital Metabolism: Decoupling Logic from Facts via Regenerative Unlearning Towards a Pure Neural Logic Core,"['Mengmeng Peng', 'Zhenyu Fang', 'He Sun']","This paper proposes 'digital metabolism,' a thermodynamic hypothesis suggesting that targeted forgetting is necessary for distilling a pure neural logic core. To validate this hypothesis, the authors introduce the Regenerative Logic-Core Protocol (RLCP), a dual-stream training framework that renders specific factual dependencies linearly undecodable via deep-layer gradient reversal. Applying RLCP to Qwen2.5-0.5B, the model achieves near-zero retention of targeted factual associations while exhibiting changes consistent with an emergent 'structural crystallization' effect. The findings provide a dynamic weight-level counterpart to architectural innovations like DeepSeek's Engram, paving the way for modular 'Neural CPU + Symbolic RAM' architectures.",314.53,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10820v1_Towards Reliable ML Feature Engineering via Planni.pdf,Towards Reliable ML Feature Engineering via Planning in Constrained-Topology of LLM Agents,"['Himanshu Thakur∗', 'Anusha Kamath', 'Anurag Muthyala', 'Dhwani Sanmukhani', 'Smruthi Mukund', 'Jay Katukuri']","Recent advances in code generation models have unlocked opportunities for automating feature engineering, but real-world adoption remains constrained by challenges such as the scarcity of datasets capturing iterative coding processes, limited integration of widely used coding agents, and suboptimal human-AI collaboration. This paper addresses these challenges with a planner-guided, constrained-topology multi-agent framework that generates code for repositories in a multi-step fashion. The LLM-powered planner leverages a team's environment, represented as a graph, to orchestrate calls to available agents, generate context-aware prompts, and use downstream failures to retroactively correct upstream artifacts. It can request human intervention at critical steps, ensuring generated code is reliable, maintainable, and aligned with team expectations. On a novel in-house dataset, the approach achieves significant improvements in evaluation metrics over manually crafted and unplanned workflows.",315.73,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10827v1_Approximately Optimal Global Planning for Contact-.pdf,Approximately Optimal Global Planning for Contact-Rich SE(2) Manipulation on a Graph of Reachable Sets,"['Simin Liu', 'Tong Zhao', 'Bernhard Paus Graesdal', 'Peter Werner', 'Jiuguang Wang', 'John Dolan', 'Changliu Liu', 'Tao Pang']","This paper introduces a new paradigm for computing approximately optimal manipulator plans for contact-rich SE(2) manipulation. It consists of two phases: offline construction of a graph of mutual reachable sets and online planning over this graph. The approach outperforms a leading planner on a challenging, representative contact-rich task, reducing task cost by 61% and achieving a 91% success rate across 250 queries with sub-minute query times. The authors demonstrate that globally optimized contact-rich manipulation is now practical for real-world tasks.",314.29,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10835v1_Can Vision-Language Models Understand Construction.pdf,Vision-Language Models Understand Construction Workers? An Exploratory Study,"['Hieu Bui', 'Nathaniel E. Chodosh', 'Arash Tavakoli']","This study evaluates the performance of three leading Vision-Language Models (GPT-4o, Florence 2, and LLaVa-1.5) in detecting construction worker actions and emotions from static site images. Using a curated dataset of 1,000 images annotated across ten action and ten emotion categories, the models' outputs are assessed through standardized inference pipelines and multiple evaluation metrics. GPT-4o consistently achieved the highest scores across both tasks, with an average F1-score of 0.756 and accuracy of 0.799 in action recognition, and an F1-score of 0.712 and accuracy of 0.773 in emotion recognition. Florence 2 performed moderately, with F1-scores of 0.497 (action) and 0.414 (emotion), while LLaVa-1.5 showed the lowest overall performance (F1-scores of 0.466 for action and 0.461 for emotion). Confusion matrix analyses revealed that all models struggled to distinguish semantically close categories, highlighting limitations in current VLMs when applied to visually nuanced, domain-specific tasks. The study provides an initial benchmark and practical insights for deploying human-aware AI systems in complex, safety-critical settings.",313.56,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10880v1_Medical SAM3 A Foundation Model for Universal Prom.pdf,Medical SAM3: A Foundation Model for Universal Prompt-Driven Medical Image Segmentation,"['Chongcong Jiang', 'Tianxingjian Ding', 'Chuhan Song', 'Jiachen Tu', 'Ziyang Yan', 'Yihua Shao', 'Zhenyi Wang', 'Yuzhang Shang', 'Tianyu Han', 'Yu Tian']","Promptable segmentation foundation models such as SAM3 have demonstrated strong generalization capabilities through interactive and concept-based prompting. However, their direct applicability to medical image segmentation remains limited by severe domain shifts, the absence of privileged spatial prompts, and the need to reason over complex anatomical and volumetric structures. Here, we present Medical SAM3, a foundation model for universal prompt-driven medical image segmentation, obtained by fully fine-tuning SAM3 on large-scale, heterogeneous 2D and 3D medical imaging datasets with paired segmentation masks and text prompts. Through a systematic analysis of vanilla SAM3, we observe that its performance degrades substantially on medical data, with its apparent competitiveness largely relying on strong geometric priors such as ground-truth-derived bounding boxes. These findings motivate full model adaptation beyond prompt engineering alone. By fine-tuning SAM3's model parameters on 33 datasets spanning 10 medical imaging modalities, Medical SAM3 acquires robust domain-specific representations while preserving prompt-driven flexibility. Extensive experiments across organs, imaging modalities, and dimensionalities demonstrate consistent and significant performance gains, particularly in challenging scenarios characterized by semantic ambiguity, complex morphology, and long-range 3D context. Our results establish Medical SAM3 as a universal, text-guided segmentation foundation model for medical imaging and highlight the importance of holistic model adaptation for achieving robust prompt-driven segmentation under severe domain shift. Code and model will be made available at https://github.com/AIM-Research-Lab/Medical-SAM3.",315.51,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10904v1_ARC Prize 2025 Technical Report.pdf,ARC Prize 2025: Technical Report,"['François Chollet', 'Mike Knoop', 'Gregory Kamradt', 'Bryan Landers']","The ARC Prize 2025 global competition targeted the newly released ARC-AGI-2 dataset, which features greater task complexity compared to its predecessor. The competition attracted 1,455 teams and 15,154 entries, with the top score reaching 24% on the ARC-AGI-2 private evaluation set. Paper submissions nearly doubled year-over-year to 90 entries, reflecting the growing research interest in fluid intelligence and abstract reasoning. The defining theme of 2025 is the emergence of the refinement loop—a per-task iterative program optimization loop guided by a feedback signal. Such refinement loops are also possible in weight space, as evidenced by zero-pretraining deep learning methods which are now achieving competitive performance with remarkably small networks (7M parameters). In parallel, four frontier AI labs (Anthropic, Google DeepMind, OpenAI, and xAI) reported ARC-AGI performance in public model cards in 2025, establishing ARC-AGI as an industry standard benchmark for AI reasoning. However, current frontier AI reasoning performance remains fundamentally constrained to knowledge coverage, giving rise to new forms of benchmark contamination. In this paper, we survey the top-performing methods, examine the role of refinement loops in AGI progress, discuss knowledge-dependent overfitting, and preview ARC-AGI-3, which introduces interactive reasoning challenges that require exploration, planning, memory, goal acquisition, and alignment capabilities.",310.2,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10917v1_Self-learned representation-guided latent diffusio.pdf,SELF-LEARNED REPRESENTATION-GUIDED LATENT DIFFUSION MODEL FOR BREAST CANCER CLASSIFICATION IN DEEP ULTRA VIOLET WHOLE SURFACE IMAGES,"['Pouya Afshin', 'David Helminiak', 'Tianling Niu', 'Julie M. Jorns', 'Tina Yen', 'Bing Yu', 'Dong Hye Ye']","Breast-Conserving Surgery requires precise intraoperative margin assessment. Deep Ultraviolet Fluorescence Scanning Microscopy offers rapid, high-resolution surface imaging. However, the scarcity of annotated DUV data hinders the training of robust deep learning models. This paper proposes a Self-Supervised Learning-guided Latent Diffusion Model to generate high-quality synthetic training patches. By guiding the LDM with embeddings from a fine-tuned DINO teacher, rich semantic details of cellular structures are injected into synthetic data. Real and synthetic patches are combined to fine-tune a Vision Transformer for WSI-level classification. Experiments using 5-fold cross-validation demonstrate that the method achieves 96.47% accuracy and reduces the FID score to 45.72, significantly outperforming class-conditioned baselines.",309.57,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10921v1_RobuMTL Enhancing Multi-Task Learning Robustness A.pdf,RobuMTL: Enhancing Multi-Task Learning Robustness Against Weather Conditions,"['Tasneem Shaffee', 'Sherief Reda']","Robust Multi-Task Learning (MTL) is crucial for autonomous systems operating in real-world environments, where adverse weather conditions can severely degrade model performance and reliability. This paper introduces RobuMTL, a novel architecture designed to adaptively address visual degradation by dynamically selecting task-specific hierarchical Low-Rank Adaptation (LoRA) modules and a LoRA expert squad based on input perturbations in a mixture-of-experts fashion. The framework enables adaptive specialization based on input characteristics, improving robustness across diverse real-world conditions. The authors evaluated RobuMTL on the PASCAL and NYUD-v2 datasets and compared it against single-task models, standard MTL baselines, and state-of-the-art methods. RobuMTL delivers a +2.8% average relative improvement under single perturbations and up to +44.4% under mixed weather conditions compared to the MTL baseline on the PASCAL benchmark. On NYUD-v2, RobuMTL achieves a +9.7% average relative improvement across tasks. The code is available at GitHub.",312.27,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10922v1_What Matters in Data Curation for Multimodal Reaso.pdf,What Matters in Data Curation for Multimodal Reasoning? Insights from the DCVLR Challenge,"['Yosub Shin', 'Michael Buriek', 'Boris Sobolev', 'Pavel Bushuyeu', 'Vikas Kumar', 'Haoyang Xu', 'Samuel Watson', 'Igor Molybog']","This paper studies data curation for multimodal reasoning through the NeurIPS 2025 Data Curation for Vision–Language Reasoning (DCVLR) challenge. Using a compact curated dataset derived primarily from the Walton Multimodal Cold Start corpus, our team placed first in the challenge. Post-competition ablations show that difficulty-based example selection on an aligned base dataset is the dominant driver of performance gains. Increasing dataset size does not reliably improve mean accuracy under the fixed training recipe, but mainly reduces run-to-run variance. Commonly used diversity and synthetic augmentation heuristics provide no additional benefit and often degrade performance. These results characterize DCVLR as a saturation-regime evaluation and highlight the central role of alignment and difficulty in data-efficient multimodal reasoning.",310.25,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10926v1_Selecting Language Models for Social Science Start.pdf,"Selecting Language Models for Social Science: Start Small, Start Open, and Validate","['Dustin S. Stoltz', 'Marshall A. Taylor', 'Sanuj Kumar']","Currently, there are thousands of large pretrained language models (LLMs) available to social scientists. The authors explore the significance of model openness, model footprint, training data, and model architectures and fine-tuning using validity, reliability, reproducibility, and replicability as guides. They propose starting with smaller, open models and constructing delimited benchmarks to demonstrate the validity of the entire computational pipeline.",311.11,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10931v1_Sparse Data Tree Canopy Segmentation Fine-Tuning L.pdf,Sparse Data Tree Canopy Segmentation: Fine-Tuning Leading Pretrained Models on Only 150 Images,"['David Szczecina', 'Niloofar Azad', 'Hudson Sun', 'Kyle Gao', 'Anthony Bertnyk', 'Lincoln Linlin Xu']","Tree canopy detection from aerial imagery is an important task for environmental monitoring, urban planning, and ecosystem analysis. The Solafune Tree Canopy Detection competition provides a small and imbalanced dataset of only 150 annotated images, posing significant challenges for training deep models without severe overfitting. This work evaluates five representative architectures, YOLOv11, Mask R-CNN, DeepLabv3, Swin-UNet, and DINOv2, to assess their suitability for canopy segmentation under extreme data scarcity. The experiments show that pretrained convolution-based models, particularly YOLOv11 and Mask R-CNN, generalize significantly better than pretrained transformer-based models. DeeplabV3, Swin-UNet, and DINOv2 underperform likely due to differences between semantic and instance segmentation tasks, the high data requirements of Vision Transformers, and the lack of strong inductive biases. These findings confirm that transformer-based architectures struggle in low-data regimes without substantial pretraining or augmentation and that differences between semantic and instance segmentation further affect model performance. Lightweight CNN-based methods remain the most reliable for canopy detection on limited imagery.",310.15,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10945v1_PatientVLM Meets DocVLM Pre-Consultation Dialogue .pdf,PatientVLM Meets DocVLM: Pre-Consultation Dialogue Between Vision-Language Models for Efficient Diagnosis,"['K Lokesh', 'Abhirama Subramanyam Penamakuri', 'Uday Agarwal', 'Apoorva Challa', 'Shreya K Gowda', 'Somesh Gupta', 'Anand Mishra']","The paper proposes a Pre-Consultation Dialogue Framework (PCDF) that simulates realistic doctor-patient dialogues between two vision-language models: a DocVLM and a PatientVLM. The DocVLM generates follow-up questions based on the image and dialogue history, while the PatientVLM responds using a symptom profile derived from the ground-truth diagnosis. The authors conducted a small-scale clinical validation of synthetic symptoms generated by their framework, confirming their clinical relevance, symptom coverage, and overall realism. The findings indicate that the resulting DocVLM-PatientVLM interactions form coherent, multi-turn consultations paired with images and diagnoses, which are used to fine-tune the DocVLM. This dialogue-based supervision leads to substantial gains over image-only training, highlighting the value of realistic symptom elicitation for diagnosis.",309.29,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10951v1_Multi-Stage Patient Role-Playing Framework for Rea.pdf,Multi-Stage Patient Role-Playing Framework for Realistic Clinical Interactions,"['Shijie Jiang', 'Zefan Zhang', 'Kehua Zhu', 'Tian Bai', 'Ruihong Zhao']","The simulation of realistic clinical interactions plays a pivotal role in advancing clinical Large Language Models (LLMs) and supporting medical diagnostic education. Existing approaches and benchmarks rely on generic or LLM-generated dialogue data, which limits the authenticity and diversity of doctor-patient interactions. In this work, we propose the first Chinese patient simulation dataset (Ch-PatientSim), constructed from realistic clinical interaction scenarios to comprehensively evaluate the performance of models in emulating patient behavior. Patients are simulated based on a five-dimensional persona structure. To address issues of the persona class imbalance, a portion of the dataset is augmented using few-shot generation, followed by manual verification. We evaluate various state-of-the-art LLMs and find that most produce overly formal responses that lack individual personality. To address this limitation, we propose a training-free Multi-Stage Patient Role-Playing (MSPRP) framework, which decomposes interactions into three stages to ensure both personalization and realism in model responses. Experimental results demonstrate that our approach significantly improves model performance across multiple dimensions of patient simulation. Our dataset is available at https://github.com/SerajJon/MSPRP.",315.63,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10955v1_Beyond Max Tokens Stealthy Resource Amplification .pdf,Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents,"['Kaiyu Zhou', 'Yongsen Zheng∗', 'Yicheng He', 'Meng Xue', 'Xueluan Gong', 'Yuji Wang', 'Kwok-Yan Lam']","The agent-tool communication loop is a critical attack surface in modern Large Language Model (LLM) agents. Existing Denial-of-Service (DoS) attacks are inefficient for this new paradigm. We introduce a stealthy, multi-turn economic DoS attack that operates at the tool layer under the guise of a correctly completed task. This method adjusts text-visible fields and a template-governed return policy in a benign, Model Context Protocol (MCP)-compatible tool server, optimizing these edits with a Monte Carlo Tree Search (MCTS) optimizer. These adjustments leave function signatures unchanged and preserve the final payload, steering the agent into prolonged, verbose tool-calling sequences using text-only notices. This compounds costs across turns, escaping single-turn caps while keeping the final answer correct to evade validation. Across six LLMs on the ToolBench and BFCL benchmarks, our attack expands tasks into trajectories exceeding 60,000 tokens, inflates costs by up to 658 ×, and raises energy by 100–560 ×. It drives GPU KV cache occupancy from <1% to 35–74% and cuts co-running throughput by approximately 50%. Because the server remains protocol-compatible and the task outcomes are correct, conventional checks fail. These results elevate the agent-tool interface to a first-class security frontier, demanding a paradigm shift from validating final answers to monitoring the economic and computational cost of the entire agentic process.",310.3,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.10960v1_Steering Language Models Before They Speak Logit-L.pdf,Steering Language Models Before They Speak: Logit-Level Interventions,"['Hyeseon An', 'Shinwoo Park', 'Hyundong Jin', 'Yo-Sub Han *']","Steering Large Language Models (LLMs) is essential for specialized applications such as style-sensitive text rewriting, user-adaptive communication, and toxicity mitigation. Current steering methods, like prompting-based and activation-based approaches, are widely used but have limitations. Activation-based techniques require deep access to internal layers, while prompting-based steering often fails to provide consistent or fine-grained control. To address these limitations, the authors propose a training-free inference-time logit intervention for controllable generation. Their approach uses a statistical token score table derived from z-normalized log-odds of labeled corpora to shift the decoding distribution. Empirical evaluations across three diverse datasets demonstrate that this method effectively steers output characteristics, confirming its broad applicability and task-agnostic nature. Results show that statistically grounded logit steering can achieve large, consistent, and multi-task control gains: up to +47%p accuracy and 50×F1 improvement.",310.26,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11000v1_When Personalization Misleads Understanding and Mi.pdf,When Personalization Misleads: Understanding and Mitigating Hallucinations in Personalized LLMs,"['Zhongxiang Sun', 'Yi Zhan', 'Chenglei Shen', 'Weijie Yu', 'Xiao Zhang', 'Ming He', 'Jun Xu']","Personalized large language models (LLMs) adapt model behavior to individual users to enhance user satisfaction, yet personalization can inadvertently distort factual reasoning. This paper shows that when personalized LLMs face factual queries, they generate answers aligned with a user's prior history rather than the objective truth, resulting in personalization-induced hallucinations that degrade factual reliability and may propagate incorrect beliefs. To address this issue, the authors propose Factuality-Preserving Personalized Steering (FPPS), a lightweight inference-time approach that mitigates personalization-induced factual distortions while preserving personalized behavior. The paper introduces PFQABench, the first benchmark designed to jointly evaluate factual and personalized question answering under personalization. Experiments across multiple LLM backbones and personalization methods show that FPPS substantially improves factual accuracy while maintaining personalized performance.",314.66,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11007v1_AdaMARP An Adaptive Multi-Agent Interaction Framew.pdf,AdaMARP: An Adaptive Multi-Agent Interaction Framework for General Immersive Role-Playing,"['Zhenhua Xu', 'Dongsheng Chen', 'Shuo Wang', 'Jian Li', 'Chengjie Wang', 'Meng Han', 'Yabiao Wang']","AdaMARP proposes an adaptive multi-agent interaction framework for LLM role-playing, featuring an immersive message format that interleaves [Thought], (Action), <Environment>, and Speech, and an explicit Scene Manager that controls role-playing via discrete actions (init_scene, pick_speaker, switch_scene, add_role, end) with rationales. To train these abilities, AdaRPSet and AdaSMSet are constructed for the Actor Model and supervising orchestration decisions, respectively, and AdaptiveBench is introduced for trajectory-level evaluation. Experiments across multiple backbones and scales show consistent gains: AdaRPSet improves character consistency, environment grounding, and narrative coherence, while AdaSMSet enables smoother scene transitions and more natural role introductions.",310.62,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11012v1_Efficient Protein Optimization via Structure-aware.pdf,Efficient Protein Optimization via Structure-aware Hamiltonian Dynamics,"['Jiahao Wang', 'Shuangjia Zheng']","The paper proposes HADES, a Bayesian optimization method utilizing Hamiltonian dynamics to efficiently sample from a structure-aware approximated posterior. Leveraging momentum and uncertainty in simulated physical movements, HADES enables rapid transition of proposals toward promising areas. A position discretization procedure is introduced to propose discrete protein sequences from a continuous state system. The posterior surrogate is powered by a two-stage encoder-decoder framework to determine the structure and function relationships between mutant neighbors, facilitating the design of protein sequences with similar structures and optimized properties. Extensive experiments demonstrate that the method outperforms state-of-the-art baselines in in-silico evaluations across most metrics.",311.72,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11016v1_Contextual Distributionally Robust Optimization wi.pdf,Contextual Distributionally Robust Optimization with Causal and Continuous Structure: An Interpretable and Tractable Approach,"['Fenglin Zhang', 'Jie Wang∗']","In this paper, we introduce a framework for contextual distributionally robust optimization (DRO) that considers the causal and continuous structure of the underlying distribution by developing interpretable and tractable decision rules that prescribe decisions using covariates. We first introduce the causal Sinkhorn discrepancy (CSD), an entropy-regularized causal Wasserstein distance that encourages continuous transport plans while preserving the causal consistency. We then formulate a contextual DRO model with a CSD-based ambiguity set, termed Causal Sinkhorn DRO (Causal-SDRO), and derive its strong dual reformulation where the worst-case distribution is characterized as a mixture of Gibbs distributions. To solve the corresponding infinite-dimensional policy optimization, we propose the Soft Regression Forest (SRF) decision rule, which approximates optimal policies within arbitrary measurable function spaces. The SRF preserves the interpretability of classical decision trees while being fully parametric, differentiable, and Lipschitz smooth, enabling intrinsic interpretation from both global and local perspectives. To solve the Causal-SDRO with parametric decision rules, we develop an efficient stochastic compositional gradient algorithm that converges to anε-stationary point at a rate of O(ε−4), matching the convergence rate of standard stochastic gradient descent. Finally, we validate our method through numerical experiments on synthetic and real-world datasets, demonstrating its superior performance and interpretability.",311.87,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11019v1_Finding the Translation Switch Discovering and Exp.pdf,Finding the Translation Switch: Discovering and Exploiting the Task-Initiation Features in LLMs,"['Xinwei Wu', 'Heng Liu', 'Xiaohu Zhao', 'Yuqi Ren', 'Linlong Xu', 'Longyue Wang', 'Deyi Xiong', 'Weihua Luo', 'Kaifu Zhang']",This paper investigates the translation capabilities of Large Language Models (LLMs) and introduces a novel framework to identify task-specific features. The authors use Sparse Autoencoders (SAEs) to identify features that are frequently co-activated on translation inputs and filter them for functional coherence using a PCA-based consistency metric. This framework isolates a set of ,263.94,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11021v1_Combating Spurious Correlations in Graph Interpret.pdf,Combating Spurious Correlations in Graph Interpretability via Self-Reflection,"['Kecheng Cai', 'Chenyang Xu', 'Chao Peng']","Interpretable graph learning has emerged as a popular topic in machine learning, focusing on identifying important nodes and edges in input graphs for specific graph reasoning tasks. However, models often struggle with spurious correlations in synthetic benchmarks, leading to poor performance. This paper proposes a self-reflection framework to enhance interpretability on challenging Spurious-Motif datasets, demonstrating that this technique can improve performance. The authors analyze the reasons behind this improvement and propose a fine-tuning training method based on feedback from the self-reflection process, leading to further performance improvements.",309.94,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11030v1_IDDR-NGP Incorporating Detectors for Distractor Re.pdf,IDDR-NGP: Incorporating Detectors for Distractor Removal with Instant Neural Radiance Field,"['Xianliang Huang', 'Jiajie Gou', 'Shuhang Chen', 'Zhizhou Zhong', 'Jihong Guan', 'Shuigeng Zhou']","This paper presents the first unified distractor removal method, named IDDR-NGP, which directly operates on Instant-NPG. The method is able to remove a wide range of distractors in 3D scenes, such as snowflakes, confetti, defoliation and petals, whereas existing methods usually focus on a specific type of distractors. By incorporating implicit 3D representations with 2D detectors, the authors demonstrate that it is possible to efficiently restore 3D scenes from multiple corrupted images. They design the learned perceptual image patch similarity (LPIPS) loss and the multi-view compensation (MVCL) loss to jointly optimize the rendering results of IDDR-NGP, which could aggregate information from multi-view corrupted images. All of them can be trained in an end-to-end manner to synthesize high-quality 3D scenes. To support the research on distractors removal in implicit 3D representations, the authors build a new benchmark dataset that consists of both synthetic and real-world distractors. Extensive experimental results demonstrate the effectiveness and robustness of IDDR-NGP in removing multiple types of distractors. In addition, our approach achieves results comparable with the existing SOTA desnow methods and is capable of accurately removing both realistic and synthetic distractors.",312.32,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11035v1_Your One-Stop Solution for AI-Generated Video Dete.pdf,Recent Advances in Generative Modeling for Synthetic Video Detection,"['Long Ma', 'Zihao Xue', 'Yan Wang', 'Zhiyuan Yan', 'Jin Xu', 'Xiaorui Jiang', 'Haiyang Yu', 'Yong Liao', 'Zhen Bi']","Recent advances in generative modeling can create remarkably realistic synthetic videos, making it increasingly difficult for humans to distinguish them from real ones and necessitating reliable detection methods. However, two key limitations hinder the development of this field. From the dataset perspective, existing datasets are often limited in scale and constructed using outdated or narrowly scoped generative models, making it difficult to capture the diversity of real-world video content. The authors propose a comprehensive evaluation framework for synthetic video detection, covering various aspects such as image quality, motion smoothness, relevance to major content, and temporal attribute control. They also introduce a benchmark for video-to-video generation and analysis, providing insightful analyses for future research.",312.76,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11037v1_BAPO Boundary-Aware Policy Optimization for Reliab.pdf,BAPO: Boundary-Aware Policy Optimization for Reliable Agentic Search,"['Shiyu Liu', 'Yongjing Yin', 'Jianhao Yan', 'Yunbo Tang', 'Qinggang Zhang', 'Bei Li', 'Xin Chen', 'Jingang Wang', 'Xunliang Cai', 'Jinsong Su']","RL-based agentic search enables LLMs to solve complex questions via dynamic planning and external search. However, these agents often fail to recognize their reasoning boundaries and rarely admit ‘I DON’T KNOW’ (IDK) even when evidence is insufficient or reasoning reaches its limit. To address this reliability gap, the paper proposes Boundary-Aware Policy Optimization (BAPO), a novel RL framework designed to cultivate reliable boundary awareness without compromising accuracy. BAPO introduces two key components: a group-based boundary-aware reward that encourages an IDK response only when reasoning reaches its limit, and an adaptive reward modulator that strategically suspends this reward during early exploration. Extensive experiments on four benchmarks demonstrate that BAPO substantially enhances the overall reliability of agentic search.",309.98,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11042v1_Spectral Characterization and Mitigation of Sequen.pdf,Spectral Characterization and Mitigation of Sequential Knowledge Editing Collapse,"['Chi Zhang', 'Mengqi Zhang', 'Xiaotian Ye', 'Runxi Cheng', 'Zisheng Zhou', 'Ying Zhou', 'Pengjie Ren', 'Zhumin Chen']","Sequential knowledge editing in large language models often leads to catastrophic collapse of the model's general abilities, especially for parameter-modifying methods. Existing approaches mitigate this issue through heuristic constraints on parameter updates, but the mechanisms underlying such degradation remain insufficiently understood. This work presents a spectral analysis of sequential knowledge editing and shows that a model's general abilities are closely associated with dominant singular directions of pretrained weight matrices. These directions are highly sensitive to perturbations and are progressively disrupted by repeated edits, closely tracking the collapse in both editing efficacy and general performance. Building on this insight, the authors propose REVIVE, a plug-and-play framework that stabilizes sequential editing by explicitly preserving the dominant singular subspace. REVIVE represents parameter updates in the spectral basis of the original weights and filters components that would interfere with the protected region. Extensive experiments across multiple models and benchmarks show that REVIVE consistently improves editing efficacy while substantially preserving general abilities under long-horizon sequential editing, including extreme settings with up to 20,000 edits.",313.66,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11044v2_AgencyBench Benchmarking the Frontiers of Autonomo.pdf,AgencyBench: Benchmarking the Frontiers of Autonomous Agents in 1M-Token Real-World Contexts,"['Keyu Li', 'Junhao Shi', 'Yang Xiao', 'Mohan Jiang', 'Jie Sun', 'Yunze Wu', 'Dayuan Fu', 'Shijie Xia', 'Xiaojie Cai', 'Tianze Xu', 'Weiye Si', 'Wenjie Li', 'Dequan Wang', 'Pengfei Liu']","AgencyBench is a comprehensive benchmark derived from daily AI usage, evaluating 6 core agentic capabilities across 32 real-world scenarios, comprising 138 tasks with specific queries, deliverables, and rubrics. These scenarios require an average of 90 tool calls, 1 million tokens, and hours of execution time to resolve. To enable automated evaluation, a user simulation agent provides iterative feedback, and a Docker sandbox conducts visual and functional rubric-based assessment. Experiments reveal that closed-source models significantly outperform open-source models (48.4% vs 32.1%). Further analysis shows significant disparities in resource efficiency, feedback-driven self-correction, and specific tool-use preferences. The study investigates the impact of agentic scaffolds, observing that proprietary models demonstrate superior performance within their native ecosystems, while open-source models exhibit distinct performance peaks. AgencyBench serves as a critical testbed for next-generation agents, highlighting the necessity of co-optimizing model architecture with agentic frameworks.",311.96,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11049v1_Predicting Biased Human Decision-Making with Large.pdf,Predicting Biased Human Decision-Making with Large Language Models in Conversational Settings,"['Stephen Pilli', 'Vivek Nallur']","This study examines whether large language models (LLMs) can predict biased decision-making in conversational settings. Participants completed six classic decision-making tasks via a chatbot with dialogues of varying complexity. The study found that increased dialogue complexity selectively increased the effect of cognitive biases, such as the Framing Effect and Status Quo Bias. LLMs were able to predict individual decisions given demographic information and prior dialogue, with GPT-4 family models consistently aligning with human behavior and outperforming GPT-5 and open-source models in predictive accuracy and fidelity to human-like bias patterns.",315.71,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11063v1_H-AIM Orchestrating LLMs PDDL and Behavior Trees f.pdf,"H-AIM: Orchestrating LLMs, PDDL, and Behavior Trees for Hierarchical Multi-Robot Planning","['Haishan Zeng', 'Peng Li']","In embodied artificial intelligence, enabling heterogeneous robot teams to execute long-horizon tasks from high-level instructions remains a critical challenge. While large language models (LLMs) show promise in instruction parsing and preliminary planning, they exhibit limitations in long-term reasoning and dynamic multi-robot coordination. The paper proposes H-AIM, a novel embodied multi-robot task planning framework that addresses these issues through a three-stage cascaded architecture. The framework leverages an LLM to parse instructions and generate PDDL problem descriptions, combines the semantic reasoning of LLMs with the search capabilities of a classical planner to produce optimized action sequences, and compiles the resulting plan into behavior trees for reactive control. The framework supports dynamically sized heterogeneous robot teams via a shared blackboard mechanism for communication and state synchronization. Experimental results demonstrate that H-AIM achieves a remarkable performance improvement, elevating the task success rate from 12% to 55% and boosting the goal condition recall from 32% to 72% against the strongest baseline, LaMMA-P.",313.24,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11065v1_Fairness in Healthcare Processes A Quantitative An.pdf,Fairness in Healthcare Processes: A Quantitative Analysis of Decision Making in Triage,"['Rachmadita Andreswari', 'Stephan A. Fahrenkrog-Petersen', 'Jan Mendling']","This study addresses the research problem of fairness in automated decision-making in high-pressure healthcare scenarios, such as emergency triage. It proposes a process mining approach to assess fairness in triage by linking real-life event logs with conceptual dimensions of justice. Using the MIMIC-EL event log (derived from MIMIC-IV ED), the study analyzes time, redo, deviation, and decision as process outcomes and evaluates the influence of age, gender, race, language, and insurance using Kruskal–Wallis, Chi-square, and effect size measurements. The results demonstrate which aspects of potential unfairness are present in high-acuity and sub-acute cases, contributing empirical insights that support further research in responsible, fairness-aware process mining in healthcare.",315.83,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11073v1_Bridging Cognitive Neuroscience and Graph Intellig.pdf,Bridging Cognitive Neuroscience and Graph Intelligence: Hippocampus-Inspired Multi-View Hypergraph Learning for Web Finance Fraud,"['Rongkun Cui', 'Nana Zhang', 'Kun Zhu', 'Qi Zhang']","Online financial services are a crucial part of contemporary web ecosystems, but they expose users to significant fraud risks. Existing graph neural network (GNN) methods struggle with two challenges: fraud camouflage and long-tailed data distributions. To address these issues, the authors propose HIMVH, a Hippocampus-Inspired Multi-View Hypergraph learning model for web finance fraud detection. HIMVH captures subtle discrepancies and behavioral heterogeneity across multiple transaction views, enabling the detection of online camouflaged fraudulent behaviors. It also introduces a novelty-aware hypergraph learning module to enhance sensitivity to rare fraud patterns in long-tailed settings. Extensive experiments on six web-based financial fraud datasets show that HIMVH achieves significant improvements in AUC, F1, and AP metrics over 15 state-of-the-art models.",309.26,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11076v1_A3D Adaptive Affordance Assembly with Dual-Arm Man.pdf,A3D: Adaptive Affordance Assembly with Dual-Arm Manipulation,"['Jiaqi Liang', 'Yue Chen', 'Qize Yu', 'Yan Shen', 'Haipeng Zhang', 'Hao Dong', 'Ruihai Wu']","Furniture assembly is a crucial yet challenging task for robots, requiring precise dual-arm coordination. The proposed A3D framework learns adaptive affordances to identify optimal support and stabilization locations on furniture parts. It employs dense point-level geometric representations to model part interaction patterns, enabling generalization across varied geometries. To handle evolving assembly states, an adaptive module uses interaction feedback to dynamically adjust support strategies during assembly. The framework is validated in a simulation environment featuring 50 diverse parts across 8 furniture types, designed for dual-arm collaboration evaluation. Experiments demonstrate effective generalization to diverse part geometries and furniture categories in both simulation and real-world settings.",314.01,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11077v1_ABC-Bench Benchmarking Agentic Backend Coding in R.pdf,ABC-Bench: Benchmarking Agentic Backend Coding in Real-World Development,"['Jie Yang', 'Honglin Guo', 'Li Ji', 'Jiazheng Zhou', 'Rui Zheng', 'Zhikai Lei', 'Shuo Zhang', 'Shichun Liu', 'Yuxin Wang', 'Bo Wang', 'Yining Zheng', 'Tao Gui', 'Xipeng Qiu']","The evolution of Large Language Models (LLMs) into autonomous agents has expanded the scope of AI coding from localized code generation to complex, repository-level, and execution-driven problem solving. However, current benchmarks predominantly evaluate code logic in static contexts, neglecting the dynamic, full-process requirements of real-world engineering, particularly in backend development which demands rigorous environment configuration and service deployment. To address this gap, we introduce ABC-Bench, a benchmark explicitly designed to evaluate agentic backend coding within a realistic, executable workflow. Using a scalable automated pipeline, we curated 224 practical tasks spanning 8 languages and 19 frameworks from open-source repositories. Distinct from previous evaluations, ABC-Bench requires the agents to manage the entire development lifecycle from repository exploration to instantiating containerized services and pass the external end-to-end API tests. Our extensive evaluation reveals that even state-of-the-art models struggle to deliver reliable performance on these holistic tasks, highlighting a substantial disparity between current model capabilities and the demands of practical backend engineering.",315.88,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11078v1_Visual Marker Search for Autonomous Drone Landing .pdf,Visual Marker Search for Autonomous Drone Landing in Diverse Urban Environments,"['Jiaohong Yao', 'Linfeng Liang', 'Yao Deng', 'Xi Zheng', 'Richard Han', 'Yuankai Qi']","Marker-based landing is widely used in drone delivery and return-to-base systems for its simplicity and reliability. However, most approaches assume idealized landing site visibility and sensor performance, limiting robustness in complex urban settings. This paper presents a simulation-based evaluation suite on the AirSim platform with systematically varied urban layouts, lighting, and weather to replicate realistic operational diversity. Using onboard camera sensors—RGB for marker detection and depth for obstacle avoidance—we benchmark two heuristic coverage patterns and a reinforcement learning-based agent, analyzing how exploration strategy and scene complexity affect success rate, path efficiency, and robustness. Results underscore the need to evaluate marker-based autonomous landing under diverse, sensor-relevant conditions to guide the development of reliable aerial navigation systems.",312.37,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11089v2_MiCA A Mobility-Informed Causal Adapter for Lightw.pdf,MiCA: A Mobility-Informed Causal Adapter for Lightweight Epidemic Forecasting,"['Suhan Guo', 'Jiahong Deng', 'Furao Shen']","Accurate forecasting of infectious disease dynamics is critical for public health planning and interventions. Human mobility plays a central role in shaping the spatial spread of epidemics, but mobility data are noisy, indirect, and difficult to integrate reliably with disease records. This work proposes the Mobility-Informed Causal Adapter (MiCA), a lightweight and architecture-agnostic module for epidemic forecasting. MiCA infers mobility relations through causal discovery and integrates them into temporal forecasting models via gated residual mixing. Extensive experiments on four real-world epidemic datasets show that MiCA consistently improves lightweight temporal backbones, achieving an average relative error reduction of 7.5% across forecasting horizons. Moreover, MiCA attains performance competitive with state-of-the-art spatio-temporal models while remaining lightweight.",311.43,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11090v1_Efficient Multilingual Name Type Classification Us.pdf,Eﬀicient Multilingual Name T ype Classification Using Convolutional Networks,['Davor Lauc'],"The paper presents a convolutional neural network approach for classifying proper names by language and entity type. The model, Onomas-CNN X, combines parallel convolution branches with depthwise-separable operations and hierarchical classification to process names efficiently on CPU hardware. The model achieves 92.1% accuracy while processing 2,813 names per second on a single CPU core, 46 times faster than fine-tuned XLM-RoBERTa with comparable accuracy. The model reduces energy consumption by a factor of 46 compared to transformer baselines. The experiments demonstrate that specialized CNN architectures remain competitive with large pre-trained models for focused NLP tasks when sufficient training data exists.",310.21,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11100v1_ReCreate Reasoning and Creating Domain Agents Driv.pdf,ReCreate: Reasoning and Creating Domain Agents Driven by Experience,"['Zhezheng Hao', 'Hong Wang', 'Jian Luo', 'Jianqing Zhang', 'Yuyan Zhou', 'Qiang Lin', 'Can Wang', 'Hande Dong', 'Jiawei Chen']","This paper proposes ReCreate, an experience-driven framework for the automatic creation of domain agents. ReCreate leverages agent interaction histories to systematically learn from experience, providing rich concrete signals on the causes of success or failure and avenues for improvement. It introduces an agent-as-optimizer paradigm with three key components: an experience storage and retrieval mechanism, a reasoning-creating synergy pipeline, and hierarchical updates. Experiments across diverse domains consistently show that ReCreate outperforms human-designed agents and existing automated agent generation methods, even starting from minimal seed scaffolds.",314.18,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11109v1_Vision-as-Inverse-Graphics Agent via Interleaved M.pdf,Vision-as-Inverse-Graphics Agent via Interleaved Multimodal Reasoning,"['Shaofeng Yin', 'Jiaxin Ge', 'Zora Zhiruo Wang', 'Xiuyu Li', 'Michael J. Black', 'Trevor Darrell', 'Angjoo Kanazawa', 'Haiwen Feng']","Vision-as-inverse-graphics, the concept of reconstructing an image as an editable graphics program, is a long-standing goal of computer vision. However, even strong VLMs lack fine-grained spatial and physical grounding capability. Our key insight is that interleaved multimodal reasoning through iterative execution and verification is required to close this gap. VIGA (Vision-as-Inverse-Graphic Agent) starts from an empty world and reconstructs or edits scenes through a closed-loop write→run→render→compare→revise procedure. It combines a skill library that alternates generator and verifier roles and an evolving context memory that contains plans, code diffs, and render history. VIGA is task-agnostic and model-agnostic, enabling a unified protocol to evaluate heterogeneous foundation VLMs. Empirically, VIGA substantially improves one-shot baselines on BlenderGym (35.32%) and SlideBench (117.17%).",315.8,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11124v1_Learn Before Represent Bridging Generative and Con.pdf,Learn Before Represent: Bridging Generative and Contrastive Learning for Domain-Specific LLM Embeddings,"['Xiaoyu Liang', 'Yuchen Peng', 'Jiale Luo', 'Wenhao Wang', 'Haoji Hu', 'Xincheng Zhou']","This work identifies a core bottleneck in the prevailing 'LLM+CL' paradigm, which focuses on semantic alignment but cannot perform knowledge acquisition, leading to failures on specialized terminology. To bridge this gap, the authors propose Learn Before Represent (LBR), a novel two-stage framework. LBR first injects domain knowledge via an Information Bottleneck-Constrained Generative Learning stage, preserving the LLM's causal attention to maximize knowledge acquisition while compressing semantics. It then performs Generative-Refined Contrastive Learning on the compressed representations for alignment. Extensive experiments on medical, chemistry, and code retrieval tasks show that LBR significantly outperforms strong baselines, establishing a new paradigm for building accurate and robust representations in vertical domains.",314.09,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11135v1_Context-aware Graph Causality Inference for Few-Sh.pdf,Context-aware Graph Causality Inference for Few-Shot Molecular Property Prediction,"['Van Thuy Hoang', 'O-Joun Lee*']","Molecular property prediction is a major application of graph learning in web-based services. A key challenge arises in few-shot scenarios where only a few labeled molecules are available for predicting unseen properties. This paper proposes CaMol, a context-aware graph causality inference framework to address these challenges. CaMol uses a causal inference perspective, assuming each molecule has a latent causal structure that determines a specific property. It introduces a context graph to encode chemical knowledge, a learnable atom masking strategy to disentangle causal substructures, and a distribution intervener to combine causal substructures with chemically grounded confounders. Experiments on diverse molecular datasets show that CaMol achieves superior accuracy and sample efficiency in few-shot tasks, demonstrating its generalizability to unseen properties and supporting model interpretability.",311.6,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11143v1_Learning Quadrupedal Locomotion for a Heavy Hydrau.pdf,Learning Quadrupedal Locomotion for a Heavy Hydraulic Robot Using an Actuator Model,"['Minho Lee', 'Hyeonseok Kim', 'Jin Tak Kim', 'Sangshin Park', 'Jeong Hyun Lee', 'Jungsan Cho', 'Jemin Hwangbo ∗']","The simulation-to-reality (sim-to-real) transfer of large-scale hydraulic robots presents a significant challenge in robotics due to the slow control response and complex fluid dynamics. The work proposes an analytical actuator model driven by hydraulic dynamics to represent the complicated actuators, predicting joint torques for all 12 actuators in under 1 microsecond. The model is compared with neural network-based actuator models and demonstrates advantages in data-limited scenarios. The locomotion policy trained in reinforcement learning with the model is deployed on a hydraulic quadruped robot over 300 kg, showcasing the first successful transfer of stable and robust command-tracking locomotion with RL on a heavy hydraulic quadruped robot.",313.33,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11144v2_Deep GraphRAG A Balanced Approach to Hierarchical .pdf,Deep GraphRAG: A Balanced Approach to Hierarchical Retrieval and Adaptive Integration,"['Yuejie Li', 'Ke Yang', 'Tao Wang', 'Bolin Chen', 'Bowen Li', 'Chengjun Mao']","Graph-based Retrieval-Augmented Generation (GraphRAG) frameworks face a trade-off between the comprehensiveness of global search and the efficiency of local search. Existing methods are often challenged by navigating large-scale hierarchical graphs, optimizing retrieval paths, and balancing exploration-exploitation dynamics, frequently lacking robust multi-stage re-ranking. To overcome these deficits, the authors propose Deep GraphRAG, a framework designed for a balanced approach to hierarchical retrieval and adaptive integration. It introduces a hierarchical global-to-local retrieval strategy that integrates macroscopic inter-community and microscopic intra-community contextual relations. This strategy employs a three-stage process: inter-community filtering, community-level refinement, and entity-level fine-grained search. A beam search-optimized dynamic re-ranking module guides this process, continuously filtering candidates to balance efficiency and global comprehensiveness. Deep GraphRAG also features a Knowledge Integration Module leveraging a compact LLM, trained with Dynamic Weighting Reward GRPO (DW-GRPO). This novel reinforcement learning approach dynamically adjusts reward weights to balance relevance, faithfulness, and conciseness. This training enables compact models (1.5B) to approach the performance of large models (70B) in the integration task. Evaluations on Natural Questions and HotpotQA demonstrate that Deep GraphRAG significantly outperforms baseline graph retrieval methods in both accuracy and efficiency.",313.8,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11147v1_Do We Always Need Query-Level Workflows Rethinking.pdf,Do We Always Need Query-Level Workflows?,"['Zixu Wang', 'Bingbing Xu', 'Yige Yuan', 'Huawei Shen', 'Xueqi Cheng']","This paper rethinks and analyzes the necessity of query-level workflows in Multi-Agent Systems (MAS) built on large language models. It shows that query-level workflow generation is not always necessary, as a small set of top-K best task-level workflows can cover equivalent or even more queries. The authors propose SCALE, a low-cost task-level generation framework that predicts the optimizer with few-shot calibration for evaluation instead of full validation execution. Extensive experiments demonstrate that SCALE maintains competitive performance while significantly reducing token usage.",314.46,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11151v1_Cross-Modal Attention Network with Dual Graph Lear.pdf,Cross-Modal Attention Network with Dual Graph Learning in Multimodal Recommendation,"['JI DAI', 'Beijing University of Posts and Telecommunications, China', 'QUAN FANG∗', 'Beijing University of Posts and Telecommunications, China', 'JUN HU', 'National University of Singapore, Singapore', 'DESHENG CAI', 'Tianjin University of Technology, China', 'YANG YANG', 'Beihang University, China and State Key Laboratory of CNS/ATM, China', 'CAN ZHAO', 'Aviation Data Communication Corporation, China']","Cross-modal recommendation systems leverage user-item interactions and multimodal information to capture user preferences, enabling more accurate and personalized recommendations. The paper proposes a Cross-modal RecursiveAttentionNetwork with dual graphEmbedding (CRANE) to address the limitations of shallow modality fusion and asymmetric feature treatment. CRANE uses a coreRecursive Cross-Modal Attention (RCA) mechanism to iteratively refine modality features based on cross-correlations in a joint latent space, and integrates a symmetric dual-graph framework to fuse behavioral and semantic signals. Theoretical and empirical analyses confirm its scalability and high practical efficiency, achieving faster convergence on small datasets and superior performance ceilings on large-scale ones. Comprehensive experiments on four public real-world datasets validate an average 5% improvement in key metrics over state-of-the-art baselines.",314.64,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11160v1_Clustering High-dimensional Data Balancing Abstrac.pdf,Clustering High-dimensional Data: Balancing Abstraction and Representation,"['Claudia Plant', 'Lena G. M. Bauer', 'Christian B ¨ohm']","Clustering requires a balance between abstraction and representation. The tutorial discusses how clustering algorithms implement different trade-offs between abstraction and representation. Classical K-means implements high-level abstraction but a simple representation. Subspace and deep clustering support high-dimensional and complex data by allowing richer representations. However, increasing representational expressiveness requires explicitly enforcing abstraction in the objective function. Current deep clustering methods define and enforce abstraction through centroid-based and density-based clustering losses. Balancing abstraction and representation is challenging, and ideas from subspace clustering help by learning relevant and all other information in the data. The tutorial concludes with an outlook on future research in clustering, emphasizing the need for adaptive balancing and improved performance, energy efficiency, and interpretability.",310.59,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11178v1_TANDEM Temporal-Aware Neural Detection for Multimo.pdf,TANDEM: Temporal-Aware Neural Detection for Multimodal Hate Speech,"['Girish A. Koushik', 'Helen Treharne', 'Diptesh Kanojia']","This work introduces TANDEM, a unified framework that transforms audio-visual hate detection into a structured reasoning problem. It employs a novel tandem reinforcement learning strategy where vision-language and audio-language models optimize each other through self-constrained cross-modal context, stabilizing reasoning over extended temporal sequences without requiring dense frame-level supervision. Experiments across three benchmark datasets demonstrate that TANDEM significantly outperforms zero-shot and context-augmented baselines, achieving 0.73 F1 in target identification on HateMM (a ≈ 30% improvement over state-of-the-art) while maintaining precise temporal grounding. The authors also observe that while binary detection is robust, differentiating between offensive and hateful content remains challenging in multi-class settings due to inherent label ambiguity and dataset imbalance. The findings suggest that structured, interpretable alignment is achievable even in complex multimodal settings, offering a blueprint for the next generation of transparent and actionable online safety moderation tools.",313.29,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11189v1_Policy-Based Deep Reinforcement Learning Hyperheur.pdf,Policy-Based Deep Reinforcement Learning Hyperheuristics for Job-Shop Scheduling Problems,"['Sofiene Lassoued', 'Asrat Gobachew', 'Stefan Lier', 'Andreas Schwung']","This paper proposes a policy-based deep reinforcement learning hyper-heuristic framework for solving the Job Shop Scheduling Problem. The hyper-heuristic agent learns to switch scheduling rules based on the system state dynamically. The framework extends with two key mechanisms: action prefiltering and a commitment mechanism. The impact of different commitment strategies and action selection strategies are investigated. Computational experiments on standard JSSP benchmarks demonstrate that the proposed approach outperforms traditional heuristics, metaheuristics, and recent neural network-based scheduling methods.",311.27,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11196v1_Artificial Intelligence and the US Economy An Acco.pdf,Artificial Intelligence and the US Economy: An Accounting Perspective on Investment and Production,"['Luisa Carpinelli', 'Filippo Natoli', 'Marco Taboga']","This paper provides an overview on how the current AI wave is captured in US national accounts, combining a simple macro-accounting framework with a stylized description of the AI production process. It highlights the crucial role played by data centers, which constitute the backbone of the AI ecosystem and have attracted formidable investment in 2025. The boom in IT and AI-related capital expenditure in the first three quarters of the year has given an outsized boost to aggregate demand, while its contribution to GDP growth is smaller once the high import content of AI hardware is netted out. Simple calculations suggest that the production of services originating in new AI data centers could contribute to GDP over the turn of the next quarters on a scale comparable to that of investment spending to date. The paper also discusses short reinvestment cycles and uncertainty about future AI demand, which can fuel macroeconomic risks over the medium term.",315.96,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11199v1_SD-RAG A Prompt-Injection-Resilient Framework for .pdf,SD-RAG: A Prompt-Injection-Resilient Framework for Selective Disclosure in Retrieval-Augmented Generation,"['Aiman Al Masoud', 'Marco Arazzi', 'Antonino Nocera']","Retrieval-Augmented Generation (RAG) has attracted significant attention for combining the generative capabilities of Large Language Models (LLMs) with knowledge from large-scale data collections. However, current approaches often overlook the risks of exposing sensitive information directly to the generation model. This paper proposes SD-RAG, a novel approach that decouples security and privacy constraints from the generation process, applying sanitization and disclosure controls during the retrieval phase. SD-RAG also introduces a semantic mechanism for ingesting human-readable dynamic security and privacy constraints, along with an optimized graph-based data model supporting fine-grained policy-aware retrieval. Experimental evaluations demonstrate SD-RAG's superiority over baseline approaches, achieving up to a 58% improvement in privacy scores while also showing strong resilience to prompt injection attacks.",310.89,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11200v1_FAQ Mitigating Quantization Error via Regenerating.pdf,Mitigating Quantization Error via Regenerating Calibration Data with Family-Aware Quantization,"['Haiyang Xiao', 'Weiqing Li', 'Jinyue Guo', 'Guochao Jiang', 'Guohua Liu', 'Yuewei Zhang']","Although post-training quantization (PTQ) provides an efficient numerical compression scheme for deploying large language models (LLMs) on resource-constrained devices, the representativeness and universality of calibration data remain a core bottleneck in determining the accuracy of quantization parameters. Traditional PTQ methods typically rely on limited samples, making it difficult to capture the activation distribution during the inference phase, leading to biases in quantization parameters. To address this, the authors propose FAQ (Family-Aware Quantization), a calibration data regeneration framework that leverages prior knowledge from LLMs of the same family to generate high-fidelity calibration samples. Specifically, FAQ first inputs the original calibration samples into a larger LLM from the same family as the target model, regenerating a series of high-fidelity calibration data using a highly consistent knowledge system. Subsequently, this data, carrying Chain-of-Thought reasoning and conforming to the expected activation distribution, undergoes group competition under expert guidance to select the best samples, which are then re-normalized to enhance the effectiveness of standard PTQ. Experiments on multiple model series, including Qwen3-8B, show that FAQ reduces accuracy loss by up to 28.5% compared to the baseline with original calibration data, demonstrating its powerful potential and contribution.",312.92,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11202v1_Epistemic Control and the Normativity of Machine L.pdf,The Role of AI in Science: Epistemological and Methodological Studies,['Emanuele Ratti'],The author investigates the extent to which human scientists are pushed out-of-the-loop in science due to the use of machine learning (ML) systems. Ratti introduces the concept of 'epistemic control' and identifies two conditions: 'tracking' and 'tracing'. He argues against Humphreys' pessimistic view and constructs a more nuanced view of epistemic control in ML-based science.,313.73,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11207v1_LoRA as Oracle.pdf,LoRA as Oracle,"['Marco Arazzi', 'Antonino Nocera']","Backdoored and privacy-leaking deep neural networks pose a serious threat to the deployment of machine learning systems in security-critical settings. Existing defenses for backdoor detection and membership inference typically require access to clean reference models, extensive retraining, or strong assumptions about the attack mechanism. In this work, we introduce a novel LoRA-based oracle framework that leverages low-rank adaptation modules as a lightweight, model-agnostic probe for both backdoor detection and membership inference. Our approach attaches task-specific LoRA adapters to a frozen backbone and analyzes their optimization dynamics and representation shifts when exposed to suspicious samples. We show that poisoned and member samples induce distinctive low-rank updates that differ significantly from those generated by clean or non-member data. These signals can be measured using simple ranking and energy-based statistics, enabling reliable inference without access to the original training data or modification of the deployed model.",315.08,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11219v1_SDFLoRA Selective Dual-Module LoRA for Federated F.pdf,Selective Dual-Module LoRA for Federated Fine-tuning with Heterogeneous Clients,"['Zhikang Shen', 'Jianrong Lu', 'Haiyuan Wan', 'Jianhai Chen']","Parameter-efficient federated fine-tuning has become a practical route for adapting large language models (LLMs) when data are distributed and privacy-sensitive. However, practical federated learning (FL) deployments often exhibit rank heterogeneity, where clients use different low-rank configurations, leading to biased and unstable aggregation of LoRA updates. To address this issue, the paper proposes SDFLoRA, which decomposes each client adapter into a global module for transferable knowledge and a local module for client-specific adaptations. The global module is selectively aligned and aggregated across clients, while local modules remain private, enabling robust learning under rank heterogeneity and privacy-aware optimization by injecting differential privacy noise exclusively into the global module. Experiments on GLUE benchmarks show that SDFLoRA outperforms representative federated LoRA baselines and achieves a better utility–privacy trade-off.",312.49,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11232v1_FactCorrector A Graph-Inspired Approach to Long-Fo.pdf,FACTCORRECTOR: A Graph-Inspired Approach to Long-Form Factuality Correction of Large Language Models,"['Javier Carnerero-Cano', 'Massimiliano Pronesti', 'Radu Marinescu', 'Tigran Tchrakian', 'James Barry', 'Jasmina Gajcin', 'Yufang Hou', 'Alessandra Pascale', 'Elizabeth Daly']","Large language models (LLMs) are widely used in knowledge-intensive applications but often generate factually incorrect responses. A promising approach to rectify these flaws is correcting LLMs using feedback. This paper introduces FACTCORRECTOR, a new post-hoc correction method that adapts across domains without retraining and leverages structured feedback about the factuality of the original response to generate a correction. To support rigorous evaluations of factuality correction methods, the authors also develop the VELI5 benchmark, a novel dataset containing systematically injected factual errors and ground-truth corrections. Experiments on VELI5 and several popular long-form factuality datasets show that the FACTCORRECTOR approach significantly improves factual precision while preserving relevance, outperforming strong baselines. The authors release their code at https://ibm.biz/factcorrector.",314.16,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11252v1_Beyond Model Scaling Test-Time Intervention for Ef.pdf,BEYONDMODELSCALING: TEST-TIMEINTERVENTION FOREFFICIENTDEEPREASONING,"['Qianyue Wang', 'Jinwu Hu', 'Yufeng Wang', 'Huanxiang Lin', 'Bolin Chen', 'Zhiquan Wen', 'Yaofo Chen', 'Mingkui Tan†']","Large Reasoning Models (LRMs) excel at multi-step reasoning but often suffer from inefficient reasoning processes like overthinking and overshoot. Existing efficient reasoning methods operate in a closed-loop manner, lacking mechanisms for external intervention. The paper proposes Think-with-Me, a novel test-time interactive reasoning paradigm that introduces external feedback intervention into the reasoning process. Key insights include the use of transitional conjunctions as natural points for intervention and the importance of appropriate use of transitional words to enhance performance. The paradigm pauses reasoning at these points for external feedback, adaptively extending or terminating reasoning to reduce redundancy while preserving accuracy. Experiments show that Think-with-Me achieves a superior balance between accuracy and reasoning length under limited context windows, outperforming QwQ-32B by 7.19% in accuracy while reducing average reasoning length by 81% under an 8K window. The paradigm also benefits security and creative tasks.",313.62,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11258v1_Knowledge is Not Enough Injecting RL Skills for Co.pdf,Knowledge is Not Enough: Injecting RL Skills for Continual Adaptation,"['Pingzhi Tang', 'Yiding Wang', 'Muhan Zhang']","Large Language Models face the 'knowledge cutoff' challenge, where their frozen parametric memory prevents direct internalization of new information. While Supervised Fine-Tuning is commonly used to update model knowledge, it often fails to reliably improve the model's ability to use newly incorporated information. Reinforcement Learning is essential for acquiring reasoning skills, but its high computational cost makes it impractical for efficient online adaptation. This paper proposes Parametric Skill Transfer (PaST), a framework that supports modular skill transfer for efficient and effective knowledge adaptation. By extracting a domain-agnostic Skill Vector from a source domain, PaST can linearly inject knowledge manipulation skills into a target model after lightweight SFT on new data. Experiments on knowledge-incorporation QA and agentic tool-use benchmarks demonstrate the effectiveness of PaST, showing significant improvements in accuracy and success rates.",310.52,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11269v1_X-Distill Cross-Architecture Vision Distillation f.pdf,X-Distill: Cross-Architecture Vision Distillation for Visuomotor Learning,"['Maanping Shao', 'Feihong Zhang', 'Gu Zhang', 'Baiye Cheng', 'Zhengrong Xue', 'Huazhe Xu']","X-Distill is a simple yet effective method that synergizes the strengths of both large Vision Transformers (ViTs) and compact CNNs. It involves offline, cross-architecture knowledge distillation, transferring rich visual representations from a large ViT teacher to a compact ResNet-18 student on the ImageNet dataset. The distilled encoder is then jointly fine-tuned with a diffusion policy head on target manipulation tasks. Extensive experiments demonstrate that X-Distill consistently outperforms policies equipped with from-scratch ResNet or fine-tuned DINOv2 encoders, and also surpasses 3D encoders that utilize privileged point cloud observations or larger Vision-Language Models.",313.49,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11282v1_From SERPs to Sound How Search Engine Result Pages.pdf,FromSERPsto Sound: How Search Engine Result Pages and AI-generated Podcasts Interact to Influence User Attitudes on Controversial Topics,"['Junjie Wang', 'Gaole He', 'Alisa Rieger', 'Ujwal Gadiraju']","Compared to search engine result pages (SERPs), AI-generated podcasts represent a relatively new and relatively more passive modality of information consumption, delivering narratives in a naturally engaging format. As these two media increasingly converge in everyday information-seeking behavior, it is essential to explore how their interaction influences user attitudes, particularly in contexts involving controversial, value-laden, and often debated topics. Through a controlled user study (N=483), the authors investigated user attitudinal effects of consuming information via SERPs and AI-generated podcasts, focusing on how the sequence and modality of exposure shape user opinions. A majority of users in the study corresponded to attitude change outcomes, and the authors found an effect of sequence on attitude change. The results further revealed a role of viewpoint bias and the degree of topic controversiality in shaping attitude change, although no effect of individual moderators was found.",312.0,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11286v1_XChoice Explainable Evaluation of AI-Human Alignme.pdf,XChoice: Explainable Evaluation of AI–Human Alignment in LLM-based Constrained Choice Decision Making,"['Weihong Qi', 'Fan Huang', 'Rasika Muralidharan', 'Jisun An', 'Haewoon Kwak']","XChoice presents an explainable framework for evaluating AI-human alignment in constrained decision making. It fits a mechanism-based decision model to human and LLM-generated decisions, recovering interpretable parameters that capture decision factors, constraint sensitivity, and trade-offs. The framework assesses alignment by comparing these parameter vectors across models, options, and subgroups. Demonstrated on Americans' daily time allocation using the American Time Use Survey (ATUS) as ground truth, XChoice reveals heterogeneous alignment across models and activities, with salient misalignment concentrated in Black and married groups. Robustness is validated via an invariance analysis, and targeted mitigation is evaluated with a retrieval-augmented generation (RAG) intervention. Overall, XChoice provides mechanism-based metrics that diagnose misalignment and support informed improvements beyond surface outcome matching.",309.61,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11344v1_How Much Would a Clinician Edit This Draft Evaluat.pdf,How Much Would a Clinician Edit This Draft?,"['Parker Seegmiller', 'Joseph Gatto', 'Sarah E. Greer', 'Ganza Belise Isingizwe', 'Rohan Ray', 'Timothy Burdick', 'Sarah M. Preum']","Large language models (LLMs) show promise in drafting responses to patient portal messages, yet their integration into clinical workflows raises various concerns, including whether they would actually save clinicians time and effort in their portal workload. This study investigates LLM alignment with individual clinicians through a comprehensive evaluation of the patient message response drafting task. The authors develop a novel taxonomy of thematic elements in clinician responses and propose a novel evaluation framework for assessing clinician editing load of LLM-drafted responses at both content and theme levels. They release an expert-annotated dataset and conduct large-scale evaluations of local and commercial LLMs using various adaptation techniques, including thematic prompting, retrieval-augmented generation, supervised fine-tuning, and direct preference optimization. The results reveal substantial epistemic uncertainty in aligning LLM drafts with clinician responses, with LLMs demonstrating capability in certain thematic elements but struggling with clinician-aligned generation in other themes, particularly question asking to elicit further information from patients. Theme-driven adaptation strategies yield improvements across most themes. The findings underscore the necessity of adapting LLMs to individual clinician preferences to enable reliable and responsible use in patient-clinician communication workflows.",313.98,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11350v1_FEATHer Fourier-Efficient Adaptive Temporal Hierar.pdf,FEATHer: Fourier-Efficient Adaptive Temporal Hierarchy Forecaster for Time-Series Forecasting,"['Jaehoon Lee †', 'Seungwoo Lee †', 'Younghwi Kim†', 'Dohee Kim*', 'Sunghyun Sim*']","Time-series forecasting plays a fundamental role in industrial domains such as manufacturing, energy management, logistics, and smart factory operations. Under strict constraints on latency, memory, and energy consumption, conventional deep forecasting architectures become computationally impractical. To address these challenges, the authors propose the Fourier-Efficient Adaptive Temporal Hierarchy Forecaster (FEATHer), a multiscale temporal model designed to achieve accurate long-term forecasting under severe resource limitations. FEATHer introduces four key components: ultra-lightweight multiscale temporal decomposition, shared Dense Temporal Kernel, frequency-aware branch gating mechanism, and Sparse Period Kernel. Compared to existing baselines, FEATHer maintains an exceptionally compact architecture while achieving strong predictive performance and operates in extreme parameter-budget regimes, including settings with as few as 400 trainable parameters. Across eight long-term forecasting benchmarks and multiple horizons, FEATHer achieves the best overall ranking, recording 60 first-place results with an average rank of 2.05. These results demonstrate that reliable long-range forecasting is achievable even under highly constrained edge conditions and suggest a practical direction for next-generation industrial systems requiring real-time inference with minimal computational cost.",315.51,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11354v1_AstroReason-Bench Evaluating Unified Agentic Plann.pdf,AstroReason-Bench: Evaluating Unified Agentic Planning across Heterogeneous Space Planning Problems,"['Weiyi Wang', 'Xinchi Chen', 'Jingjing Gong', 'Xuanjing Huang', 'Xipeng Qiu']","Recent advances in large language models have positioned them as generalist planners capable of reasoning and acting across diverse tasks. However, existing agent benchmarks primarily focus on symbolic or weakly grounded environments, leaving their performance in physics-constrained real-world domains underexplored. We introduce AstroReason-Bench, a comprehensive benchmark for evaluating agentic planning in Space Planning Problems (SPP), a family of high-stakes problems with heterogeneous objectives, strict physical constraints, and long-horizon decision-making. AstroReason-Bench integrates multiple scheduling regimes, including ground station communication and agile Earth observation, and provides a unified agent-oriented interaction protocol. Evaluating on a range of state-of-the-art open-and closed-source agentic LLM systems, we find that current agents substantially underperform specialized solvers, highlighting key limitations of generalist planning under realistic constraints. AstroReason-Bench offers a challenging and diagnostic testbed for future agentic research.",315.81,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11359v1_Think-Clip-Sample Slow-Fast Frame Selection for Vi.pdf,Think-Clip-Sample: A Training-Free Framework for Enhancing Long Video Understanding,"['Wenhui Tan∗', 'Ruihua SongB', 'Jiaze Li', 'Jianzhong Ju', 'Zhenbo LuoB']","Recent progress in multi-modal large language models (MLLMs) has significantly advanced video understanding. However, their performance on long-form videos remains limited by computational constraints and suboptimal frame selection. This paper presents Think-Clip-Sample (TCS), a training-free framework that enhances long video understanding through two key components: Multi-Query Reasoning and Clip-level Slow-Fast Sampling. Multi-Query Reasoning generates multiple queries to capture complementary aspects of the question and video, while Clip-level Slow-Fast Sampling adaptively balances dense local details and sparse global context. Extensive experiments on MLVU, LongVideoBench, and VideoMME demonstrate that TCS consistently improves performance across different MLLMs, boosting up to 6.9% accuracy and achieving comparable accuracy with 50% fewer inference time cost.",313.91,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11369v2_Institutional AI Governing LLM Collusion in Multi-.pdf,Institutional AI: Governing LLM Collusion in Multi-Agent Cournot Markets via Public Governance Graphs,"['M. Bracale Syrnikov', 'F. Pierucci', 'M. Galisai', 'M. Prandi', 'P. Bisconti', 'F. Giarrusso', 'O. Sorokoletova', 'V. Suriani', 'D. Nardi']","This paper advances an experimental framework for evaluating Institutional AI, a system-level approach to AI alignment that reframes alignment from preference engineering in agent space to mechanism design in institution space. Central to this approach is the governance graph, a public, immutable manifest that declares legal states, transitions, sanctions, and restorative paths. An Oracle/Controller runtime interprets this manifest, attaching enforceable consequences to evidence of coordination while recording a cryptographically keyed, append-only governance log for audit and provenance. The paper applies Institutional AI to govern the Cournot collusion case and compares three regimes: Ungoverned (baseline incentives from the structure of the Cournot market), Constitutional (a prompt-only policy-as-prompt prohibition implemented as a fixed written anti-collusion constitution), and Institutional (governance-graph-based). Across six model configurations including cross-provider pairs (N= 90 runs/condition), the Institutional regime produces large reductions in collusion: mean tier falls from 3.1 to 1.8 (Cohen’s d= 1.28), and severe-collusion incidence drops from 50% to 5.6%. The prompt-only Constitutional baseline yields no reliable improvement, illustrating that declarative prohibitions do not bind under optimization pressure. These results suggest that multi-agent alignment may benefit from being framed as an institutional design problem, where governance graphs can provide a tractable abstraction for alignment-relevant collective behavior.",314.63,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11379v1_Evaluating LLM Behavior in Hiring Implicit Weights.pdf,"Evaluating LLM Behavior in Hiring: Implicit Weights, Fairness Across Groups, and Alignment with Human Preferences","['Morgane Hoffmann', 'Emma Jouffroy', 'Warren Jouanneau', 'Marc Palyart', 'Charles Pebereau']","General-purpose Large Language Models (LLMs) show significant potential in recruitment applications, where decisions require reasoning over unstructured text, balancing multiple criteria, and inferring fit and competence from indirect productivity signals. However, it is uncertain how LLMs assign importance to each attribute and whether such assignments align with economic principles, recruiter preferences, or broader societal norms. This paper proposes a framework to evaluate an LLM's decision logic in recruitment by drawing on established economic methodologies for analyzing human hiring behavior. Synthetic datasets from real freelancer profiles and project descriptions are used to estimate how LLMs weigh different match-relevant criteria. The study identifies which attributes the LLM prioritizes and analyzes how these weights vary across project contexts and demographic subgroups. Finally, the paper explains how a comparable experimental setup could be implemented with human recruiters to assess alignment between model and human decisions. The findings reveal that the LLM weighs core productivity signals but interprets certain features beyond their explicit matching value. While showing minimal average discrimination against minority groups, intersectional effects reveal that productivity signals carry different weights between demographic groups.",314.54,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11389v1_Hyperparameter Optimization of Constraint Programm.pdf,Hyperparameter Optimization of Constraint Programming Solvers,"['Hedieh Haddad', 'Thibault Falque', 'Pierre Talbot', 'Pascal Bouvry']","The performance of constraint programming solvers is highly sensitive to the choice of their hyperparameters. Manually finding the best solver configuration is a difficult, time-consuming task that typically requires expert knowledge. In this paper, we introduce probe and solve algorithm, a novel two-phase framework for automated hyperparameter optimization integrated into the CPMpy library. This approach partitions the available time budget into two phases: a probing phase that explores different sets of hyperparameters using configurable hyper-parameter optimization methods, followed by a solving phase where the best configuration found is used to tackle the problem within the remaining time. We implement and compare two hyperparameter optimization methods within the probe and solve algorithm: Bayesian optimization and Hamming distance search. We evaluate the algorithm on two different constraint programming solvers, ACE and Choco, across 114 combinatorial problem instances, comparing their performance against the solver’s default configurations. Results show that using Bayesian optimization, the algorithm outperforms the solver’s default configurations, improving solution quality for ACE in 25.4% of instances and matching the default performance in 57.9%, and for Choco, achieving superior results in 38.6% of instances. It also consistently surpasses Hamming distance search within the same framework, confirming the advantage of model-based exploration over simple local search. Overall, the probe and solve algorithm demonstrates significant improvements in solver performance.",315.51,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11400v1_Wetland mapping from sparse annotations with satel.pdf,Wetland mapping from sparse annotations with satellite image time series and temporal-aware segment anything model,"['Shuai Yuana', 'Tianwu Linb', 'Shuang Chena', 'Yu Xiab', 'Peng Qinb', 'Xiangyu Liub', 'Xiaoqing Xub', 'Nan Xud', 'Hongsheng Zhanga', 'Jie Wangb', 'Peng Gonga']","Accurate wetland mapping is critical for ecosystem monitoring and management, yet acquiring dense pixel-level annotations is prohibitively costly. In practice, only sparse point labels are typically available, and existing deep learning-based models struggle under such weak supervision. Meanwhile, wetlands exhibit strong seasonal and inter-annual dynamics, making single-date imagery insufficient and causing substantial omission and commission errors when mapping. Although powerful foundation models like the Segment Anything Model (SAM) provide promising generalization from point prompts, it is intrinsically designed for static natural images, resulting in spatially fragmented masks in heterogeneous wetland environments and cannot exploit satellite image time series. To address these challenges, we propose WetSAM, a novel SAM-based framework that effectively leverages satellite image time series to enhance wetland mapping from sparse point annotations. WetSAM adopts a dual-branch design: (1) The temporal branch is prompted by sparse point labels to extend the SAM with a hierarchical adapter and a dynamic temporal aggregation module. By decomposing time series into seasonal trends and transient events, this branch effectively distinguishes wetland features from phenological variations; (2) The spatial branch reconstructs distinct boundaries via a temporal-constrained region-growing strategy, iteratively expanding sparse points into reliable dense pseudo-labels; (3) A bidirectional consistency regularization enforces minimizing the discrepancy of the predictions from two segmentation heads of two branches. We validate the effectiveness of WetSAM across eight diverse global locations, each covering an area of around 5,000 km² and with various wetland types and geographical features. WetSAM reaches an average F1-score of 85.58%, considerably outperforming other state-of-the-art algorithms. Results demonstrate that WetSAM achieves accurate, structurally consistent segmentation from sparse labels. With minimal labeling effort, our framework shows strong generalization ability and holds promise for scalable, low-cost wetland mapping at high spatial resolutions.",314.75,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11409v1_Topology-Guaranteed Image Segmentation Enforcing C.pdf,"Topology-Guaranteed Image Segmentation: Enforcing Connectivity, Genus, and Width Constraints","['Wenxiao Li', 'Xue-Cheng Tai', 'Jun Liu']","Existing research highlights the crucial role of topological priors in image segmentation, particularly in preserving essential structures such as connectivity and genus. Accurately capturing these topological features often requires incorporating width-related information, including the thickness and length inherent to the image structures. However, traditional mathematical definitions of topological structures lack this dimensional width information, limiting methods like persistent homology from fully addressing practical segmentation needs. To overcome this limitation, we propose a novel mathematical framework that explicitly integrates width information into the characterization of topological structures. This method leverages persistent homology, complemented by smoothing concepts from partial differential equations (PDEs), to modify local extrema of upper-level sets. This approach enables the resulting topological structures to inherently capture width properties. We incorporate this enhanced topological description into variational image segmentation models. Using proper loss functions, we are also able to design neural networks that can segment images with the required topological and width properties. Through variational constraints on the relevant topological energies, our approach successfully preserves essential topological invariants such as connectivity and genus counts, simultaneously ensuring that segmented structures retain critical width attributes, including line thickness and length. Numerical experiments demonstrate the effectiveness of our method, showcasing its capability to maintain topological fidelity while explicitly embedding width characteristics into segmented image structures.",313.62,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11421v1_The Great March 100 100 Detail-oriented Tasks for .pdf,THEGREATMARCH100: 100 DETAIL-ORIENTEDTASKS FOR EVALUATING EMBODIED AI AGENTS,"['Ziyu Wang', 'Chenyuan Liu', 'Yushun Xiang', 'Runhao Zhang', 'Yu Zhang', 'Qingbo Hao', 'Hongliang Lu', 'Houyu Chen', 'Zhizhong Feng', 'Kaiyue Zheng', 'Dehao Ye', 'Xianchao Zeng', 'Xinyu Zhou', 'Boran Wen', 'Jiaxin Li', 'Mingyu Zhang', 'Kecheng Zheng', 'Qian Zhu', 'Ran Cheng', 'Yong-Lu Li']","Recently, with the rapid development of robot learning and imitation learning, numerous datasets and methods have emerged. However, these datasets and their task designs often lack systematic consideration and principles. This raises important questions: Do the current datasets and task designs truly advance the capabilities of robotic agents? Do evaluations on a few common tasks accurately reflect the differentiated performance of various methods proposed by different teams and evaluated on different tasks? To address these issues, we introduce the Great March 100 (GM-100) as the first step towards a robot learning Olympics. GM-100 consists of 100 carefully designed tasks that cover a wide range of interactions and long-tail behaviors, aiming to provide a diverse and challenging set of tasks to comprehensively evaluate the capabilities of robotic agents and promote diversity and complexity in robot dataset task designs.",310.34,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11429v1_Relational Linearity is a Predictor of Hallucinati.pdf,Relational Linearity is a Predictor of Hallucinations,"['Yuetian Lu', 'Yihong Liu', 'Hinrich Schütze']","Hallucination is a central failure mode in large language models (LLMs). The authors focus on hallucinations of answers to synthetic entities that are unknown to the model. They hypothesize that the linearity of the relation is an important factor in causing hallucinations. To investigate this hypothesis, they create SyntHal, a dataset of synthetic entities for six relations. They find a strong correlation between relational linearity and hallucination rate, providing evidence for their hypothesis. This finding has implications for how to manage hallucination behavior and suggests new research directions for improving the representation of factual knowledge in LLMs.",310.07,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11440v1_GenDA Generative Data Assimilation on Complex Urba.pdf,Generative Data Assimilation for Urban Wind Flow Reconstruction,"['Francisco Giral', 'Álvaro Manzano', 'Ignacio Gómez', 'Ricardo Vinuesa', 'Soledad Le Clainche']","Urban wind flow reconstruction is essential for assessing air quality, heat dispersion, and pedestrian comfort. The proposed GenDA framework employs a multiscale graph-based diffusion architecture trained on CFD simulations to reconstruct high-resolution wind fields from limited observations. The unconditional branch learns a geometry-aware flow prior, while the sensor-conditioned branch injects observational constraints during sampling. GenDA reduces the relative root-mean-square error (RRMSE) by 25-57% and increases the structural similarity index (SSIM) by 23-33% across tested meshes compared to supervised graph neural network (GNN) baselines and classical reduced-order data assimilation methods. The framework is scalable and can handle sparse fixed sensors and trajectory-based observations, providing a path toward generative, geometry-aware data assimilation for environmental monitoring in complex domains.",311.88,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11441v1_Hierarchical Orthogonal Residual Spread for Precis.pdf,Hierarchical Orthogonal Residual Spread for Precise Massive Editing in Large Language Models,"['Xiaojie Gu', 'Guangxu Chen', 'Yuheng Yang', 'Jingxin Han', 'Andi Zhang']","Large language models (LLMs) exhibit exceptional performance across various domains but face safety concerns. Model editing has emerged as an effective approach to mitigate these issues. Existing methods often focus on optimizing an information matrix that blends new and old knowledge, which can be computationally expensive and cause conflicts. In contrast, this paper introduces Hierarchical Orthogonal Residual Spread (HORSE) of the information matrix, which reduces noisy gradients and enables more stable edits. The method is demonstrated to be effective through a clear theoretical comparison and extensive experiments on two datasets across multiple LLMs. The results show that HORSE maintains precise massive editing across diverse scenarios. The code is available at https://github.com/XiaojieGu/HORSE.",309.79,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11442v1_Map2Thought Explicit 3D Spatial Reasoning via Metr.pdf,Map2Thought: Explicit 3D Spatial Reasoning via Metric Cognitive Maps,"['Xiangjun Gao', 'Zhensong Zhang', 'Dave Zhenyu Chen', 'Songcen Xu', 'Long Quan', 'Eduardo P´erez-Pellitero', 'Youngkyoon Jang']","We propose Map2Thought, a framework that enables explicit and interpretable spatial reasoning for 3D Vision-Language Models (3D-VLMs). The framework is grounded in two key components: Metric Cognitive Map (Metric-CogMap) and Cognitive Chain-of-Thought (Cog-CoT). Metric-CogMap provides a unified spatial representation by integrating a discrete grid for relational reasoning with a continuous, metric-scale representation for precise geometric understanding. Building upon the Metric-CogMap, Cog-CoT performs explicit geometric reasoning through deterministic operations (e.g., vector operations, bounding-box distances, and occlusion-aware appearance order cues) producing interpretable inference traces grounded in 3D structure. Experimental results show that Map2Thought enables explainable 3D understanding, achieving 59.9% accuracy using only half the supervision—closely matching the 60.9% baseline trained with full dataset. It consistently outperforms state-of-the-art methods by 5.3%, 4.8%, and 4.0% under 10%, 25%, and 50% training subsets, respectively, on the VSI-Bench.",302.9,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11451v1_PRISM-CAFO Prior-conditioned Remote-sensing Infras.pdf,PRISM-CAFO: Prior-conditioned Remote-sensing Infrastructure Segmentation and Mapping for CAFOs,"['Oishee Bintey Hoque', 'Nibir Chandra Mandal', 'Kyle Luong', 'Amanda Wilson', 'Samarth Swarup', 'Madhav Marathe', 'Abhijin Adiga']","Large-scale livestock operations pose significant risks to human health and the environment. This work presents an infrastructure-first, explainable pipeline for identifying and characterizing Concentrated Animal Feeding Operations (CAFOs) from aerial and satellite imagery. The method detects candidate infrastructure, derives SAM2 masks, extracts structured descriptors, and fuses them with deep visual features. Comprehensive evaluation shows state-of-the-art performance, surpassing baseline models by up to 15%. The approach captures key infrastructure with higher confidence scores and enables transparent, scalable monitoring of livestock infrastructure.",311.2,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11459v1_Interactive Narrative Analytics Bridging Computati.pdf,Interactive Narrative Analytics: Bridging Computational Narrative Extraction and Human Sensemaking,['BRIAN KEITH'],"This paper introduces Interactive Narrative Analytics (INA), a new interdisciplinary field that combines computational narrative extraction with interactive visual analytics to support sensemaking. INA addresses the challenges of scalability, interactivity, knowledge integration, and evaluation standardization in the context of extracting meaningful narratives from large text collections. The field faces complex challenges in narrative sensemaking, including the need for sophisticated computational and interactive tools to handle the volume and complexity of information. INA emphasizes temporal, causal, and relational aspects of information, capturing how events unfold and connect over time to form coherent stories. The paper highlights the importance of INA in addressing information overload and misinformation, and its potential applications in news analysis, intelligence, scientific literature exploration, and social media analysis.",310.93,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11464v1_MHA2MLA-VLM Enabling DeepSeeks Economical Multi-He.pdf,MHA2MLA-VLM: Enabling DeepSeek’s Economical Multi-Head Latent Attention across Vision-Language Models,"['Xiaoran Fan', 'Zhichao Sun', 'Tao Ji', 'Lixing Shen', 'Tao Gui']","As vision-language models (VLMs) tackle increasingly complex and multimodal tasks, the rapid growth of Key-Value (KV) cache imposes significant memory and computational bottlenecks during inference. While Multi-Head Latent Attention (MLA) offers an effective means to compress the KV cache and accelerate inference, adapting existing VLMs to the MLA architecture without costly pretraining remains largely unexplored. In this work, the authors present MHA2MLA-VLM, a parameter-efficient and multimodal-aware framework for converting off-the-shelf VLMs to MLA. The approach features two core techniques: a modality-adaptive partial-RoPE strategy and a modality-decoupled low-rank approximation method. Parameter-efficient fine-tuning is introduced to minimize adaptation cost, and extensive experiments on three representative VLMs demonstrate that MHA2MLA-VLM restores original model performance with minimal supervised data, significantly reduces KV cache footprint, and integrates seamlessly with KV quantization.",310.54,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11468v1_Exploring LLM Features in Predictive Process Monit.pdf,Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs,"['ALESSANDRO PADELLA', 'MASSIMILIANO DE LEONI', 'MARLON DUMAS']","Predictive Process Monitoring (PPM) is a branch of process mining that aims to predict the outcome of an ongoing process. Recently, it leveraged machine-and-deep learning architectures. In this paper, we extend our prior LLM-based Predictive Process Monitoring framework, which was initially focused on total time prediction via prompting. The extension consists of comprehensively evaluating its generality, semantic leverage, and reasoning mechanisms, also across multiple Key Performance Indicators. Empirical evaluations conducted on three distinct event logs and across the Key Performance Indicators of Total Time and Activity Occurrence prediction indicate that, in data-scarce settings with only 100 traces, the LLM surpasses the benchmark methods. Furthermore, the experiments also show that the LLM exploits both its embodied prior knowledge and the internal correlations among training traces. Finally, we examine the reasoning strategies employed by the model, demonstrating that the LLM does not merely replicate existing predictive methods but performs higher-order reasoning to generate the predictions.",310.49,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11479v1_Health Facility Location in Ethiopia Leveraging LL.pdf,Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning,"['Yohai Trabelsi', 'Guojun Xiong', 'Fentabil Getnet', 'Stéphane Verguet', 'Milind Tambe']","Ethiopia's Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources require careful prioritization of which facilities to upgrade. The authors propose a hybrid framework that integrates expert knowledge with optimization techniques. The framework combines a provable approximation algorithm for population coverage optimization with LLM-driven iterative refinement, ensuring solutions reflect expert qualitative guidance while preserving coverage guarantees. Experiments on real-world data from three Ethiopian regions demonstrate the framework's effectiveness and its potential to inform equitable, data-driven health system planning.",313.23,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11492v1_BoxMind Closed-loop AI strategy optimization for e.pdf,BoxMind: Closed-loop AI strategy optimization for elite boxing validated in the 2024 Olympics,"['Kaiwen Wang', 'Kaili Zheng', 'Rongrong Deng', 'Qingmin Fan', 'Milin Zhang', 'Zongrui Li', 'Xuesi Zhou', 'Bo Han', 'Liren Chen', 'Chenyi Guo', 'Ji Wu']","BoxMind is a closed-loop AI expert system validated in elite boxing competition. It defines atomic punch events with precise temporal boundaries and spatial and technical attributes, parses match footage into 18 hierarchical technical-tactical indicators, and proposes a graph-based predictive model that fuses explicit technical-tactical profiles with learnable, time-variant latent embeddings. The model turns winning probability gradients into executable tactical adjustments, achieving state-of-the-art performance. Using this predictive model, the system generates strategic recommendations that demonstrate proficiency comparable to human experts. BoxMind is validated through a closed-loop deployment during the 2024 Paris Olympics, directly contributing to the Chinese National Team’s historic achievement of three gold and two silver medals. It establishes a replicable paradigm for transforming unstructured video data into strategic intelligence, bridging the gap between computer vision and decision support in competitive sports.",311.21,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11496v1_The Poisoned Apple Effect Strategic Manipulation o.pdf,The Poisoned Apple Effect: Strategic Manipulation of Mediated Markets via Technology Expansion of AI Agents,"['Eilam Shapira', 'Moshe Tennenholtz', 'Roi Reichart']","The integration of AI agents into economic markets fundamentally alters the landscape of strategic interaction. The authors investigate the economic implications of expanding the set of available technologies in three canonical game-theoretic settings: bargaining, negotiation, and persuasion. They find that simply increasing the choice of AI delegates can drastically shift equilibrium payoffs and regulatory outcomes, often creating incentives for regulators to proactively develop and release technologies. Conversely, they identify a strategic phenomenon termed the 'Poisoned Apple' effect: an agent may release a new technology, which neither they nor their opponent ultimately uses, solely to manipulate the regulator's choice of market design in their favor. This strategic release improves the releaser's welfare at the expense of their opponent and the regulator's fairness objectives. The findings demonstrate that static regulatory frameworks are vulnerable to manipulation via technology expansion, necessitating dynamic market designs that adapt to the evolving landscape of AI capabilities.",311.11,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11505v1_MetaboNet The Largest Publicly Available Consolida.pdf,METABONET: THELARGESTPUBLICLYAVAILABLE CONSOLIDATEDDATASET FORTYPE1 DIABETES MANAGEMENT,"['Miriam K. Wolff', 'Peter Calhoun', 'Eleonora Maria Aiello', 'Yao Qin', 'Sam F . Royston']","This work aims to establish a unified and accessible data resource for Type 1 Diabetes (T1D) algorithm development by consolidating multiple publicly available T1D datasets into the MetaboNet dataset. The dataset includes 3135 subjects and 1228 patient-years of overlapping CGM and insulin data, making it substantially larger than existing standalone benchmark datasets. The resource is distributed as a fully public subset available for immediate download and a DUA-restricted subset accessible through application processes. The consolidated public dataset covers a broad range of glycemic profiles and demographics, yielding more generalizable algorithmic performance than individual datasets.",312.1,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11516v2_Building Production-Ready Probes For Gemini.pdf,Building Production-Ready Probes For Gemini,"['János Kramár∗', 'Joshua Engels', 'Zheng Wang', 'Bilal Chughtai', 'Rohin Shah', 'Neel Nanda', 'Arthur Conmy∗']","Frontier language model capabilities are improving rapidly. We thus need stronger mitigations against bad actors misusing increasingly powerful systems. Prior work has shown that activation probes may be a promising misuse mitigation technique, but we identify a key remaining challenge: probes fail to generalize under important production distribution shifts. In particular, we find that the shift from short-context to long-context inputs is difficult for existing probe architectures. We propose several new probe architectures that handle this long-context distribution shift. We evaluate these probes in the cyber-offensive domain, testing their robustness against various production-relevant distribution shifts, including multi-turn conversations, long context prompts, and adaptive red teaming. Our results demonstrate that while our novel architectures address context length, a combination of architecture choice and training on diverse distributions is required for broad generalization. Additionally, we show that pairing probes with prompted classifiers achieves optimal accuracy at a low cost due to the computational efficiency of probes. These findings have informed the successful deployment of misuse mitigation probes in user-facing instances of Gemini, Google’s frontier language model. Finally, we find early positive results using AlphaEvolve (Novikov et al., 2025) to automate improvements in both probe architecture search and adaptive red teaming, showing that automating some AI safety research is already possible.",309.82,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11517v1_Do explanations generalize across large reasoning .pdf,ABSTRACT: ABSTRACT,"['Koyena Pal', 'David Bau', 'Chandan Singh']","The chains of thought (CoTs) produced by large reasoning models (LRMs) have enabled strong performance on a range of complex tasks. These CoTs are often presented as human-readable explanations, but many researchers have questioned whether these traces can be made faithful to the true decision-making processes followed by LRMs. This paper examines a different property related to faithfulness: the generalization of reasoning traces across different LRMs. The study evaluates whether an explanation produced from one LRM reliably guides other LRMs to the same answer, enabling an automated, quantitative evaluation of generalization for explanations. This evaluation is especially critical in scientific discovery, where explanations that capture problem-level patterns, rather than model-specific quirks, could inspire novel human insights.",313.84,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11625v1_Reasoning Stabilization Point A Training-Time Sign.pdf,Stabilization Point: A Training-Time Signal for Stable Evidence and Shortcut Reliance,['Sahil Rajesh Dhayalkar'],"Fine-tuning pretrained language models can improve task performance while subtly altering the evidence a model relies on. The authors propose a training-time interpretability view that tracks token-level attributions across fine-tuning epochs. They define explanation drift as the epoch-to-epoch change in normalized token attributions on a fixed probe set, and introduce the Reasoning Stabilization Point (RSP), the earliest epoch after which drift remains consistently low. Across multiple lightweight transformer classifiers and benchmark classification tasks, drift typically collapses into a low, stable regime early in training, while validation accuracy continues to change only marginally. In a controlled shortcut setting with label-correlated trigger tokens, attribution dynamics expose increasing reliance on the shortcut even when validation accuracy remains competitive. Overall, explanation drift provides a simple, low-cost diagnostic for monitoring how decision evidence evolves during fine-tuning and selecting stable-evidence checkpoints.",309.04,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11643v1_Syllabic Agglutinative Tokenizations for Indonesia.pdf,Syllabic Agglutinative Tokenizations for Indonesian LLM: A Study from ‘Gasing Literacy Learning System’,"['Hokky Situngkir*', 'Andhika Bernard Lumbantobing†', 'Yohanes Surya‡']","This paper presents a novel syllable-based tokenization approach for Indonesian large language models, inspired by the Gasing Literacy Learning System's pedagogical methodology. Drawing on information-theoretic principles, we develop a tokenization framework that segments Indonesian text at syllable boundaries before applying byte-pair encoding, creating a vocabulary that aligns with the language's morphophonological structure. Our approach first identifies high-frequency syllables through rule-based segmentation, then constructs a compact vocabulary of 3,500 tokens that preserves meaningful linguistic units while maintaining coverage through character-level fallback. Empirical evaluation on Indonesian Wikipedia and folklore corpora from Indonesian Culture Digital Library (PDBI) demonstrates substantial improvements over conventional tokenization methods: the syllable-based approach achieves R´enyi efficiency of 0.74 compared to 0.50-0.64 for pretrained multilingual tokenizers, while maintaining higher average token lengths (3.67 characters versus 2.72 for GPT-2) despite using a vocabulary an order of magnitude smaller. These gains emerge from the method's ability to internalize character-level dependencies within syllable units, reducing the computational burden on language models while respecting Indonesian's agglutinative morphology. We call the LLM built upon this principle, TOBA LLM (Tokenisasi Optimum Berbasis Aglutinasi), the convergence of human literacy pedagogy with computational optimization principles offers a promising paradigm for developing linguistically-informed tokenization strategies, particularly for morphologically rich and underrepresented languages in natural language processing.",309.43,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11644v1_Predicting When to Trust Vision-Language Models fo.pdf,Predicting When to Trust Vision-Language Models for Spatial Reasoning,"['Muhammad Imran', 'Yugyung Lee']","Vision-Language Models (VLMs) demonstrate impressive capabilities across multimodal tasks but exhibit systematic spatial reasoning failures. This paper proposes a vision-based confidence estimation framework that validates VLM predictions through independent geometric verification using object detection. Unlike text-based approaches, our method fuses four signals via gradient boosting: geometric alignment between VLM claims and coordinates, spatial ambiguity from overlap, detection quality, and VLM internal uncertainty. The framework achieves AUROC improvements of 34.0% on BLIP-2 and 16.1% on CLIP, generalizing across generative and classification architectures. The framework enables selective prediction, achieving 61.9% coverage at 60% target accuracy versus 27.6% baseline, and feature analysis reveals vision-based signals contribute 87.4% of model importance versus 12.7% from VLM confidence.",313.24,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11647v1_Reinforcement Learning for Dynamic Workflow Optimi.pdf,Reinforcement Learning for Dynamic Workflow Optimization in CI/CD Pipelines,"['Aniket Abhishek Soni', 'Milan Parikh', 'Rashi Nimesh Kumar Dhenia', 'Jubin Abhishek Soni', 'Ayush Raj Jha', 'Sneja Mitinbhai Shah']","Continuous Integration and Deployment (CI/CD) pipelines are core to modern software delivery, but their static workflows can be inefficient. This paper proposes a reinforcement learning (RL) approach to optimize CI/CD pipeline workflows dynamically. We model the pipeline as a Markov Decision Process and train an RL agent to make runtime decisions (e.g., selecting test scope) that maximize throughput while minimizing testing overhead. A simulated CI/CD environment with configurable build, test, and deploy stages is developed to evaluate the approach. Experimental results show that the RL-optimized pipeline achieves up to a 30% improvement in throughput and about a 25% reduction in test execution overhead compared to a static baseline. The agent learns to skip or abbreviate certain tests when appropriate, accelerating delivery without significantly increasing the risk of undetected failures. This work demonstrates the potential of RL to adapt DevOps workflows for greater efficiency, providing novel insights into intelligent pipeline automation.",310.15,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11650v1_Large Language Model Agent for User-friendly Chemi.pdf,A PREPRINT,"['Jingkang Liang ∗', 'Niklas Groll∗', 'Gürkan Sin']","This paper presents a framework integrating a large language model (LLM) agent with A VEV A Process Simulation (APS) via Model Context Protocol (MCP). The framework enables natural language interaction with rigorous process simulations, assessing its capabilities through two water-methanol separation case studies. The first case study demonstrates the agent's ability to autonomously analyze flowsheets, find improvement opportunities, and iteratively optimize, extract data, and present results clearly. The second case study assesses autonomous flowsheet synthesis through both a step-by-step dialogue and a single prompt, showing its potential for novices and experts alike. The framework benefits both educational purposes and experienced practitioners by automating data extraction, speeding routine tasks, and supporting brainstorming. While current limitations such as oversimplification, calculation errors, and technical hiccups mean expert oversight is still needed, the framework's capabilities in analysis, optimization, and guided construction suggest LLM-based agents can become valuable collaborators.",311.82,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11651v1_Aesthetics as Structural Harm Algorithmic Lookism .pdf,Aesthetics as Structural Harm:ALGORITHMICLOOKISMACROSS,"['Miriam Doh', 'Aditya Gulati', 'Corina Canali', 'Nuria Oliver']","This paper examines algorithmic lookism—the systematic preferential treatment based on physical appearance—in text-to-image (T2I) generative AI and a downstream gender classification task. Through the analysis of 26,400 synthetic faces created with Stable Diffusion 2.1 and 3.5 Medium, the authors demonstrate how generative AI models systematically associate facial attractiveness with positive attributes and vice-versa, mirroring socially constructed biases rather than evidence-based correlations. The study finds significant gender bias in three gender classification algorithms depending on the attributes of the input faces. The findings reveal three critical harms: systematic encoding of attractiveness-positive attribute associations in T2I models, gender disparities in classification systems, and intensifying aesthetic constraints through age homogenization, gendered exposure patterns, and geographic reductionism. These convergent patterns reveal algorithmic lookism as a systematic infrastructure operating across AI vision systems, compounding existing inequalities through both representation and recognition.",310.89,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11652v1_WISP Waste- and Interference-Suppressed Distribute.pdf,WISP: Waste- and Interference-Suppressed Distributed Speculative LLM Serving at the Edge via Dynamic Drafting and SLO-Aware Batching,"['XIANGCHEN LI', 'JIAKUN FAN', 'QINGYUAN WANG', 'DIMITRIOS SPATHARAKIS', 'SAEID GHAFOURI', 'HANS VANDIERENDONCK', 'DEEPU JOHN', 'BO JI', 'ALI R. BUTT', 'DIMITRIOS S. NIKOLOPOULOS']","WISP addresses the inefficiencies and scalability challenges of distributed speculative LLM serving by identifying and formalizing two critical bottlenecks: Wasted Drafting Time and Verification Interference. It proposes an efficient and SLO-aware system consisting of an intelligent speculation controller, a verification time estimator, and a verification batch scheduler. Extensive numerical results demonstrate that WISP improves system capacity and goodput by up to 2.1× and 3.7×, respectively, compared to centralized serving and SLED.",309.67,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11657v1_Size is Not the Solution Deformable Convolutions f.pdf,Size is Not the Solution: Deformable Convolutions for Effective Physics Aware Deep Learning,"['Jack T. Beerman', 'Shobhan Roy', 'H.S. Udaykumar', 'Stephen S. Baek']","Physics-aware deep learning (PADL) enables rapid prediction of complex physical systems, yet current convolutional neural network (CNN) architectures struggle with highly nonlinear flows. Drawing inspiration from Hybrid Lagrangian-Eulerian (HLE) numerical methods, we introduce deformable physics-aware recurrent convolutions (D-PARC) to overcome the rigidity of CNNs. Across Burgers’ equation, Navier-Stokes, and reactive flows, D-PARC achieves superior fidelity compared to substantially larger architectures. Analysis reveals that kernels display anti-clustering behavior, evolving into a learned 'active filtration' strategy distinct from traditional h- or p-adaptivity. Effective receptive field analysis confirms that D-PARC autonomously concentrates resources in high-strain regions while coarsening focus elsewhere, mirroring adaptive refinement in computational mechanics. This demonstrates that physically intuitive architectural design can outperform parameter scaling, establishing that strategic learning in lean networks offers a more effective path forward for PADL than indiscriminate network expansion.",315.28,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11658v1_Towards AGI A Pragmatic Approach Towards Self Evol.pdf,Towards AGI: A Pragmatic Approach Towards Self Evolving Agent,"['Indrajit Kar', 'Sammy Zonunpuia', 'Zonunfeli Ralte']","This work introduces a hierarchical self-evolving multi-agent framework that integrates a Base LLM, an operational SLM agent, a Code-Generation LLM, and a Teacher-LLM to enable continuous adaptation. The workflow begins with the agent attempting a task using reasoning and existing tools; if unsuccessful, it escalates to tool synthesis through the Code-Gen LLM, and when failures persist, it triggers an evolution phase using Curriculum Learning (CL), Reward-Based Learning (RL), or Genetic Algorithm (GA) evolution. Using the TaskCraft dataset rich in hierarchical tasks, tool-use traces, and difficulty scaling, the paradigms are evaluated. CL delivers fast recovery and strong generalization, RL excels on high-difficulty tasks, and GA offers high behavioral diversity. Across all settings, evolved agents outperform their originals, demonstrating robust, autonomous, self-improving agentic evolution.",312.48,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11663v1_Activation Sensitivity as a Unifying Principle for.pdf,Activation Sensitivity as a Unifying Principle for Post-Training Quantization,['Bruce Changlong Xu'],"Post-training quantization (PTQ) methods for large language models rely on heuristics that implicitly estimate which weight channels matter most to model behavior. Two dominant paradigms have emerged: activation-aware methods such as AWQ prioritize channels with large activation magnitudes, while second-order methods such as GPTQ allocate quantization error according to input covariance structure. Despite their empirical success, these approaches remain conceptually fragmented, and it is unclear what underlying quantity they are approximating. This work presents a unified theoretical framework for PTQ by formalizing activation sensitivity: the expected impact of channel-wise perturbations on the loss. Using a first-order Taylor expansion of the loss, it shows that sensitivity emerges naturally as the squared norm of gradient-weighted activations, providing a principled measure of channel importance that simultaneously captures activation magnitude and downstream error propagation. Within this framework, AWQ and GPTQ arise as complementary approximations that recover sensitivity under distinct simplifying assumptions—uniform downstream gradients and activation-agnostic covariance, respectively. The analysis connects gradient-based saliency, Fisher information, and Hessian-based criteria, clarifying their relationships to classical pruning methods and highlighting open challenges in post-training quantization, including cross-layer error accumulation, calibration distribution mismatch, and task-conditional sensitivity. This perspective exposes fundamental limitations of layer-local reconstruction objectives and provides a conceptual foundation for understanding, comparing, and extending PTQ methods through the lens of sensitivity.",311.22,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11664v1_Serverless AI Security Attack Surface Analysis and.pdf,Serverless AI Security: Attack Surface Analysis and Runtime Protection Mechanisms for FaaS-Based Machine Learning,"['Chetan Pathade', 'Vinod Dhimam', 'Ilsa Lareb', 'Sheheryar Ahmad']","Serverless computing has achieved widespread adoption, with over 70% of AWS organizations using serverless solutions. Machine learning inference workloads increasingly migrate to Function-as-a-Service (FaaS) platforms for their scalability and cost-efficiency. However, this convergence introduces critical security challenges, with recent reports showing a 220% increase in AI/ML vulnerabilities and serverless computing's fragmented architecture raising new security concerns. This paper presents the first comprehensive security analysis of machine learning workloads in serverless environments, characterizing the attack surface across five categories and demonstrating real-world attack scenarios. It proposes Serverless AI Shield (SAS), a multi-layered defense framework providing pre-deployment validation, runtime monitoring, and post-execution forensics, achieving 94% detection rates while maintaining performance overhead below 9% for inference latency. The paper also releases an open-source security toolkit to enable practitioners to assess and harden their serverless AI deployments, advancing the field toward more resilient cloud-native machine learning systems.",310.54,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11666v1_MATEX Multi-scale Attention and Text-guided Explai.pdf,MATEX: Multi-scale Attention and Text-guided Explainability of Medical Vision-Language Models,"['Muhammad Imran', 'Chi Lee', 'Yugyung Lee']","We introduce MATEX (Multi-scale Attention and Text-guided Explainability), a novel framework that advances interpretability in medical vision-language models by incorporating anatomically informed spatial reasoning. MATEX synergistically combines multi-layer attention rollout, text-guided spatial priors, and layer consistency analysis to produce precise, stable, and clinically meaningful gradient attribution maps. By addressing key limitations of prior methods—such as spatial imprecision, lack of anatomical grounding, and limited attention granularity—MATEX enables more faithful and interpretable model explanations. Evaluated on the MS-CXR dataset, MATEX outperforms the state-of-the-art M2IB approach in both spatial precision and alignment with expert-annotated findings. These results highlight MATEX’s potential to enhance trust and transparency in radiological AI applications.",314.26,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11667v1_Distill-then-Replace Efficient Task-Specific Hybri.pdf,Distill-then-Replace: Efficient Task-Specific Hybrid Attention Model Construction,"['Xiaojie Xia', 'Huigang Zhang', 'Chaoliang Zhong', 'Jun Sun', 'Yusuke Oishi']","Transformer architectures deliver state-of-the-art accuracy via dense full-attention, but their quadratic time and memory complexity with respect to sequence length limits practical deployment. Linear attention mechanisms offer linear or near-linear scaling yet often incur performance degradation. Hybrid models that integrate full and linear attention layers promise a balance between efficiency and expressiveness, but face two major challenges: training such hybrid models from scratch is computationally expensive, and manually designing the optimal placement of attention types is highly nontrivial. We address both issues by first transferring weights from the pretrained full-attention modules to its linear attention counterparts through blockwise local distillation, and second, introducing a greedy layer replacement strategy that iteratively substitutes full attention blocks with linear ones while monitoring validation performance on the target task. This yields a task-specific hybrid model in a single efficient pass, without costly re-training or neural architecture search, and can be applied to any pretrained full-attention backbone for diverse downstream tasks.",311.27,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11670v1_A Confidence-Variance Theory for Pseudo-Label Sele.pdf,A Conﬁdence-V ariance Theory for Pseudo-Label Selection in Semi-Supervised Learning,"['Jinshi Liu †', 'Pan Liu †']","Most pseudo-label selection strategies in semi-supervised learning rely on fixed confidence thresholds, implicitly assuming that prediction confidence reliably indicates correctness. In practice, deep networks are often overconfident: high-confidence predictions can still be wrong, while informative low-confidence samples near decision boundaries are discarded. This paper introduces a Confidence-Variance (CoVar) theory framework that provides a principled joint reliability criterion for pseudo-label selection. Starting from the entropy minimization principle, the paper derives a reliability measure that combines maximum confidence (MC) with residual-class variance (RCV), which characterizes how probability mass is distributed over non-maximum classes. The derivation shows that reliable pseudo-labels should have both high MC and low RCV, and that the influence of RCV increases as confidence grows, thereby correcting overconfident but unstable predictions. The paper casts pseudo-label selection as a spectral relaxation problem that maximizes separability in a confidence-variance feature space and designs a threshold-free selection mechanism to distinguish high- from low-reliability predictions. The CoVar framework is integrated into representative semi-supervised semantic segmentation and image classification methods, consistently improving over strong baselines across PASCAL VOC 2012, Cityscapes, CIFAR-10, and Mini-ImageNet with varying label ratios and backbones.",313.93,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11674v1_Pigment Network Detection and Classification in De.pdf,Pigment Network Detection and Classification in Dermoscopic Images Using Directional Imaging Algorithms and Convolutional Neural Networks,"['M. A. Rasel', 'Sameem Abdul Kareem', 'Unaizah Obaidellah']","This study aims to automate the pigment network (PN) detection process using a directional imaging algorithm and classify PN types using machine learning classifiers. The directional imaging algorithm incorporates Principal Component Analysis (PCA), contrast enhancement, filtering, and noise reduction. Applied to the PH2 dataset, this algorithm achieved a 96% success rate, which increased to 100% after pixel intensity adjustments. A new dataset containing only PN images from these results was created. Two classifiers, Convolutional Neural Network (CNN) and Bag of Features (BoF), were employed to categorize PN into atypical and typical classes. Given the limited dataset of 200 images, a simple and effective CNN was designed, featuring two convolutional layers and two batch normalization layers. The proposed CNN achieved 90% accuracy, 90% sensitivity, and 89% specificity. When compared to state-of-the-art methods, our CNN demonstrated superior performance. The study highlights the potential of the proposed CNN model for effective PN classification, suggesting future research should focus on expanding datasets and incorporating additional dermatological features to further enhance melanoma diagnosis.",311.94,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11675v1_Generating metamers of human scene understanding.pdf,Generating Metamers of Human Scene Understanding,"['Ritik Raina', 'Abe Leite', 'Alexandros Graikos', 'Seoyoung Ahn', 'Dimitris Samaras', 'Gregory J. Zelinsky']","This paper introduces MetamerGen, a tool for generating scenes that align with latent human scene representations. MetamerGen is a latent diffusion model that combines peripheral scene gist information with information from scene-viewing fixations to generate image metamers. The authors evaluate the perceptual alignment of MetamerGen-generated images to latent human scene representations through a same-different behavioral experiment. The study identifies scene generations that are indeed metamers for the latent scene representations formed by viewers. MetamerGen is a powerful tool for understanding scene understanding, revealing specific features at multiple levels of visual processing that contribute to human judgments. The authors find that high-level semantic alignment most strongly predicts metamerism when the generated scenes are conditioned on viewers' own fixated regions.",314.48,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11676v1_HALO Semantic-Aware Distributed LLM Inference in L.pdf,HALO: Semantic-Aware Distributed LLM Inference in Lossy Edge Network,"['Peirong Zheng', 'Wenchao Xu*', 'Haozhao Wang', 'Jinyu Chen', 'Xuemin (Sherman) Shen']","The deployment of large language models' (LLMs) inference at the edge can facilitate prompt service responsiveness while protecting user privacy. However, it is critically challenged by the resource constraints of a single edge node. Distributed inference has emerged to aggregate and leverage computational resources across multiple devices. Yet, existing methods typically require strict synchronization, which is often infeasible due to the unreliable network conditions. In this paper, we propose HALO, a novel framework that can boost the distributed LLM inference in lossy edge network. The core idea is to enable a relaxed yet effective synchronization by strategically allocating less critical neuron groups to unstable devices, thus avoiding the excessive waiting time incurred by delayed packets. HALO introduces three key mechanisms: (1) a semantic-aware predictor to assess the significance of neuron groups prior to activation. (2) a parallel execution scheme of neuron group loading during the model inference. (3) a load-balancing scheduler that efficiently orchestrates multiple devices with heterogeneous resources. Experimental results from a Raspberry Pi cluster demonstrate that HALO achieves a 3.41x end-to-end speedup for LLaMA-series LLMs under unreliable network conditions. It maintains performance comparable to optimal conditions and significantly outperforms the state-of-the-art in various scenarios.",314.1,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11683v1_Attesting Model Lineage by Consisted Knowledge Evo.pdf,Attesting Model Lineage by Consisted Knowledge Evolution with Fine-Tuning Trajectory,"['Zhuoyi Shang', 'Jiasen Li', 'Pengzhen Chen', 'Yanwei Liu', 'Xiaoyan Gu', 'Weiping Wang']","The fine-tuning technique in deep learning introduces a lineage relationship among models, enabling efficient domain adaptation. However, this also creates new security challenges such as unauthorized redistribution, adversarial fine-tuning, and false claims of model provenance. This paper proposes a novel model lineage attestation framework that verifies the joint trajectory of knowledge evolution and parameter modification. The framework quantifies parameter-level changes introduced by fine-tuning and refines the evolved knowledge into compact representations using probe samples. These embeddings enable robust attestation of model lineage across various model types, including classifiers, diffusion models, and large language models. Extensive experimental evaluations demonstrate the effectiveness and resilience of the approach in real-world adversarial scenarios.",311.93,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11684v1_Mobile-friendly Image de-noising Hardware Consciou.pdf,Mobile-friendly Image de-noising: Hardware Conscious Optimization for Edge Application,"['Srinivas Miriyala*', 'Sowmya Vajrala*', 'Hitesh Kumar', 'Sravanth Kodavanti', 'Vikram Rajendiran']","Image enhancement is a critical task in computer vision and photography that is often entangled with noise. This work presents a novel mobile-friendly network for image de-noising obtained with Entropy-Regularized differentiable Neural Architecture Search (NAS) on a hardware-aware search space for a U-Net architecture. The designed model has 12% less parameters, with ~2-fold improvement in on-device latency and 1.5-fold improvement in the memory footprint for a 0.7% drop in PSNR, when deployed and profiled on Samsung Galaxy S24 Ultra. Compared to the SOTA Swin-Transformer for Image Restoration, the proposed network had competitive accuracy with ~18-fold reduction in GMACs. Further, the network was tested successfully for Gaussian de-noising with 3 intensities on 4 benchmarks and real-world de-noising on 1 benchmark demonstrating its generalization ability.",309.07,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11685v1_Towards Efficient Image Deblurring for Edge Deploy.pdf,Towards Efficient Image Deblurring for Edge Deployment,"['Srinivas Soumitri Miriyala*', 'Sowmya Lahari Vajrala*', 'Rama Sravanth Kodavanti']","Image deblurring is a critical stage in mobile image signal processing pipelines. Recent deep networks achieve state-of-the-art (SOTA) accuracy but are inefficient on embedded hardware. This paper proposes a hardware-aware adaptation framework that restructures existing models through sensitivity-guided block substitution, surrogate distillation, and training-free multi-objective search driven by device profiling. Applied to the 36-block NAFNet baseline, the optimized variants achieve up to 55% reduction in GMACs compared to recent transformer-based SOTA while maintaining competitive accuracy. On-device deployment yields a 1.25× latency improvement over the baseline. Experiments on motion deblurring (GoPro), defocus deblurring (DPDD), and auxiliary benchmarks (RealBlur-J/R, HIDE) demonstrate the generality of the approach and confirm its accuracy-efficiency trade-off.",314.88,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11686v1_Proof of Concept Multi-Target Wildfire Risk Predic.pdf,Proof of Concept: Multi-Target Wildfire Risk Prediction and Large Language Model Synthesis,"['Nicolas Caron', 'Hassan Noura', 'Christophe Guyeux', 'Benjamin Aynes']","Current state-of-the-art approaches to wildfire risk assessment often overlook operational needs, limiting their practical value for first responders and firefighting services. Effective wildfire management requires a multi-target analysis that captures the diverse aspects of wildfire risk—including meteorological danger, ignition activity, intervention complexity, and resource mobilization—rather than relying on a single predictive indicator. In this proof of concept, we suggest the development of a hybrid framework that combines predictive models for each risk dimension with large language models (LLMs) dedicated to synthesizing heterogeneous outputs into structured, actionable reports.",310.95,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11687v1_Semantic Caching and Intent-Driven Context Optimiz.pdf,Semantic Caching and Intent-Driven Context Optimization for Multi-Agent Natural Language to Code Systems,['Harmohit Singh'],"We present a production-optimized multi-agent system designed to translate natural language queries into executable Python code for structured data analytics. Unlike systems that rely on expensive frontier models, our approach achieves high accuracy and cost efficiency through three key innovations: (1) a semantic caching system with LLM-based equivalence detection and structured adaptation hints that provides cache hit rates of 67% on production queries; (2) a dual-threshold decision mechanism that separates exact-match retrieval from reference-guided generation; and (3) an intent-driven dynamic prompt assembly system that reduces token consumption by 40-60% through table-aware context filtering. The system has been deployed in production for enterprise inventory management, processing over 10,000 queries with an average latency of 8.2 seconds and 94.3% semantic accuracy. We describe the architecture, present empirical results from production deployment, and discuss practical considerations for deploying LLM-based analytics systems at scale.",330.5,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11688v1_SpecMap Hierarchical LLM Agent for Datasheet-to-Co.pdf,SpecMap: Hierarchical LLM Agent for Datasheet-to-Code Traceability Link Recovery in Systems Engineering,"['Vedant Nipane', 'Pulkit Agrawal', 'Amit Singh']","Establishing precise traceability between embedded systems datasheets and their corresponding code implementations remains a fundamental challenge in systems engineering. Existing Traceability Link Recovery (TLR) approaches primarily rely on lexical similarity and information retrieval techniques, which struggle to capture the semantic, structural, and symbol-level relationships prevalent in embedded systems software. This paper presents a hierarchical datasheet-to-code mapping methodology that employs large language models (LLMs) for semantic analysis while explicitly structuring the traceability process across multiple abstraction levels. The method extends beyond function-centric mapping by explicitly covering macros, structs, constants, configuration parameters, and register definitions commonly found in systems-level C/C++ codebases. Experimental results show substantial improvements over traditional information-retrieval-based baselines, achieving up to 73.3% file mapping accuracy.",335.76,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11700v1_Telling Human and Machine Handwriting Apart.pdf,Telling Human and Machine Handwriting Apart,"['Luis A. Leiva', 'Moises Diaz', 'Nuwan T. Attygalle', 'Miguel A. Ferrer', 'Réjean Plamondon']","Handwriting movements can be leveraged as a unique form of behavioral biometrics to verify whether a real user is operating a device or application. This task can be framed as a 'reverse Turing test' in which a computer has to detect if an input instance has been generated by a human or artificially. The authors study ten public datasets of handwritten symbols (isolated characters, digits, gestures, pointing traces, and signatures) artificially reproduced using seven different synthesizers, including Kinematic Theory (Σh model), generative adversarial networks, Transformers, and Diffusion models. They train a shallow recurrent neural network achieving excellent performance (98.3% Area Under the ROC Curve (AUC) score and 1.4% equal error rate on average across all synthesizers and datasets) using nonfeaturized trajectory data as input. In few-shot settings, the classifier achieves such performance when trained on just 10% of the data. The authors also challenge their classifier in out-of-domain settings, observing very competitive results. Their work has implications for computerized systems that need to verify human presence and adds an additional layer of security to keep attackers at bay.",336.3,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11702v1_PASTA A Scalable Framework for Multi-Policy AI Com.pdf,PASTA: A Scalable Framework for Multi-Policy AI Compliance Evaluation,"['YU YANG', 'IG-JAE KIM', 'DONGWOOK YOON']","PASTA is a scalable compliance tool designed to address the challenges of multi-policy AI evaluation. It integrates four innovations: a comprehensive model-card format, a policy normalization scheme, an efficient LLM-powered pairwise evaluation engine, and an interface delivering interpretable evaluations. Expert evaluation shows PASTA's judgments closely align with human experts. The system evaluates five major policies in under two minutes at approximately $3. A user study confirms practitioners found outputs easy-to-understand and actionable, introducing a novel framework for scalable automated AI governance.",331.2,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11713v1_Inter-Cell Interference Rejection Based on Ultrawi.pdf,Inter-Cell Interference Rejection Based on Ultrawideband Walsh-Domain Wireless Autoencoding,"['Rodney Martinez Alonso', 'Cel Thys', 'Sofie Pollin', 'Cedric Dehos', 'Yuneisy Esthela Garcia Guzman']","This paper proposes a novel technique for rejecting partial-in-band inter-cell interference (ICI) in ultrawideband communication systems. The authors present the design of an end-to-end wireless autoencoder architecture that jointly optimizes the transmitter and receiver encoding/decoding in the Walsh domain to mitigate interference from coexisting narrower-band 5G base stations. By exploiting the orthogonality and self-inverse properties of Walsh functions, the system distributes and learns to encode bit-words across parallel Walsh branches. Through analytical modeling and simulation, the system characterizes how 5G CP-OFDM interference maps into the Walsh domain and identifies optimal ratios of transmission frequencies and sampling rate where the end-to-end autoencoder achieves the highest rejection. Experimental results show that the proposed autoencoder achieves up to 12 dB of ICI rejection while maintaining a low block error rate (BLER) for the same baseline channel noise, i.e., baseline Signal-to-Noise-Ratio (SNR) without the interference.",330.33,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11746v1_LIME-LLM Probing Models with Fluent Counterfactual.pdf,"LIME-LLM: Probing Models with Fluent Counterfactuals, Not Broken Text","['George Mihaila', 'Suleyman Olcay Polat', 'Poli Nemkova', 'Himanshu Sharma', 'Namratha V . Urs', 'Mark V . Albert']","Local explanation methods such as LIME (Ribeiro et al., 2016) remain fundamental to trustworthy AI, yet their application to NLP is limited by a reliance on random token masking. These heuristic perturbations frequently generate semantically invalid, out-of-distribution inputs that weaken the fidelity of local surrogate models. While recent generative approaches such as LLiMe (Angiulli et al., 2025b) attempt to mitigate this by employing Large Language Models for neighborhood generation, they rely on unconstrained paraphrasing that introduces confounding variables, making it difficult to isolate specific feature contributions. We introduce LIME-LLM, a framework that replaces random noise with hypothesis-driven, controlled perturbations. By enforcing a strict 'Single Mask–Single Sample' protocol and employing distinct neutral infill and boundary infill strategies, LIME-LLM constructs fluent, on-manifold neighborhoods that rigorously isolate feature effects. We evaluate our method against established baselines (LIME, SHAP, Integrated Gradients) and the generative LLiMe baseline across three diverse benchmarks: CoLA, SST-2, and HateXplain using human-annotated rationales as ground truth. Empirical results demonstrate that LIME-LLM establishes a new benchmark for black-box NLP explainability, achieving significant improvements in local explanation fidelity compared to both traditional perturbation-based methods and recent generative alternatives.",333.69,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11747v1_PRISM Learning Design Knowledge from Data for Styl.pdf,PRISM: Learning Design Knowledge from Data for Stylistic Design Improvement,"['Huaxiaoyue Wang', 'Sunav Choudhary', 'Franck Dernoncourt', 'Yu Shen', 'Stefano Petrangeli']","Graphic design often involves exploring different stylistic directions, which can be time-consuming for non-experts. This paper addresses the problem of stylistically improving designs based on natural language instructions. While Vision Language Models (VLMs) have shown initial success in graphic design, their pretrained knowledge on styles is often too general and misaligned with specific domain data. The authors propose PRISM (Prior-Informed Stylistic Modification), a method that constructs and applies a design knowledge base through three stages: clustering high-variance designs, summarizing each cluster into actionable design knowledge, and retrieving relevant knowledge during inference. Experiments on the Crello dataset show that PRISM achieves the highest average rank of 1.49 in style alignment over baselines. User studies further validate these results, showing that PRISM is consistently preferred by designers.",329.64,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11758v1_Early Linguistic Pattern of Anxiety from Social Me.pdf,Early Linguistic Pattern of Anxiety from Social Media,"['Arnab Das', 'Utsa']","This work presents a transparent approach to social media-based anxiety detection through linguistically interpretable feature-grounded modeling and cross-domain validation. Using a substantial dataset of Reddit posts, a logistic regression classifier was trained on carefully curated subreddits for training, validation, and test splits. Comprehensive evaluation included feature ablation, keyword masking experiments, and varying-density difference analyses comparing anxious and control groups, along with external validation using clinically interviewed participants with diagnosed anxiety disorders. The model achieved strong performance while maintaining high accuracy even after sentiment removal or keyword masking. Early detection using minimal post history significantly outperformed random classification, and cross-domain analysis demonstrated strong consistency with clinical interview data. Results indicate that transparent linguistic features can support reliable, generalizable, and keyword-robust anxiety detection. The proposed framework provides a reproducible baseline for interpretable mental health screening across diverse online contexts.",334.92,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11762v1_Industry-Aligned Granular Topic Modeling.pdf,Industry-Aligned Granular Topic Modeling,"['Sae Young Moon', 'Myeongjun Erik Jang', 'Haoyan Luo', 'Chunyang Xiao', 'Antonios Georgiadis', 'Fran Silavong']","Topic modeling is a Natural Language Processing technique used for discovering meaningful topics within a corpus. This paper introduces TIDE, a framework that provides a novel granular topic modeling method based on large language models (LLMs) as a core feature, along with other useful functionalities for business applications such as summarizing long documents, topic parenting, and distillation. The framework demonstrates superior performance compared to modern topic modeling methods and provides valuable support for industrial business scenarios. The study shows that business analysts prefer medium to high levels of granularity, highlighting the importance of granular topic modeling in business applications.",329.15,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11768v1_Lightweight Self-Supervised Detection of Fundament.pdf,Lightweight Self-Supervised Detection of Fundamental Frequency and Accurate Probability of Voicing in Monophonic Music,"['Venkat Suprabath Bitra', 'Homayoon Beigi']","Reliable fundamental frequency (F0) and voicing estimation is essential for neural synthesis, yet many pitch extractors depend on large labeled corpora and degrade under realistic recording artifacts. We propose a lightweight, fully self-supervised framework for joint F0 estimation and voicing inference, designed for rapid single-instrument training from limited audio. Using transposition-equivariant learning on CQT features, we introduce an EM-style iterative reweighting scheme that uses Shift Cross-Entropy (SCE) consistency as a reliability signal to suppress uninformative noisy/unvoiced frames. The resulting weights provide confidence scores that enable pseudo-labeling for a separate lightweight voicing classifier without manual annotations. Trained on MedleyDB and evaluated on MDB-stem-synth ground truth, our method achieves competitive cross-corpus performance (RPA 95.84, RCA 96.24) and demonstrates cross-instrument generalization.",334.36,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11776v1_Cleansing the Artificial Mind A Self-Reflective De.pdf,Cleansing the Artificial Mind: A Self-Reflective Detoxification Framework for Large Language Models,"['Kaituo Zhang', 'Zhimeng Jiang', 'Na Zou']","Recent breakthroughs in Large Language Models (LLMs) have revealed remarkable generative capabilities and self-regulatory mechanisms, including self-correction and self-rewarding. However, current detoxification techniques rely on external modules, labor-intensive data annotation, or human intervention, hindering scalability and consistency. This paper introduces a fully self-reflective detoxification framework that harnesses the inherent capacities of LLMs to detect, correct toxic content, and refine LLMs without external modules and data annotation. Specifically, it proposes a Toxic Signal Detector—an internal self-identification mechanism, coupled with a systematic intervention process to transform toxic text into its non-toxic counterpart. This iterative procedure yields a contrastive detoxification dataset used to fine-tune the model, enhancing its ability for safe and coherent text generation. Experiments on benchmark datasets show that the method achieves better detoxification performance than state-of-the-art methods while preserving semantic fidelity. By obviating the need for human intervention or external components, this paper reveals the intrinsic self-detoxification ability of LLMs, offering a consistent and effective approach for mitigating harmful content generation.",332.21,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11778v1_Translation as a Scalable Proxy for Multilingual E.pdf,Translation as a Scalable Proxy for Multilingual Evaluation,"['Sheriff Issaka', 'Erick Rosas Gonzalez', 'Lieqi Liu', 'Evans Kofi Agyei', 'Lucas Bandarkar', 'Nanyun Peng', 'David Ifeoluwa Adelani', 'Francisco Guzmán', 'Saadia Gabriel']","The rapid proliferation of large language models (LLMs) has created a critical evaluation paradox: while LLMs claim multilingual proficiency, comprehensive non-machine-translated benchmarks exist for fewer than 30 languages, leaving over 98% of the world's 7,000 languages in an empirical void. Traditional benchmark construction faces scaling challenges such as cost, scarcity of domain experts, and data contamination. This paper evaluates the validity of a simpler alternative: can translation quality alone indicate a model's broader multilingual capabilities? Through systematic evaluation of 14 models (1B-72B parameters) across 9 diverse benchmarks and 7 translation metrics, the authors find that translation performance is a good indicator of downstream task success. These results suggest that the representational abilities supporting faithful translation overlap with those required for multilingual understanding. Translation quality emerges as a strong, inexpensive first-pass proxy of multilingual performance, enabling a translation-first screening with targeted follow-up for specific tasks.",333.89,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11781v1_Risk-Aware Human-in-the-Loop Framework with Adapti.pdf,Risk-Aware Human-in-the-Loop Framework with Adaptive Intrusion Response for Autonomous Vehicles,"['Dawood Wasif', 'Terrence J. Moore', 'Seunghyun Yoon', 'Hyuk Lim', 'Dan Dongseong Kim', 'Frederica F. Nelson', 'Jin-Hee Cho']","The paper presents RAIL, a risk-aware human-in-the-loop framework that turns heterogeneous runtime signals into calibrated control adaptations and focused learning. RAIL fuses three cues (curvature actuation integrity, time-to-collision proximity, and observation-shift consistency) into an Intrusion Risk Score (IRS) via a weighted Noisy-OR. When IRS exceeds a threshold, actions are blended with a cue-specific shield using a learned authority, while human override remains available. When risk is low, the nominal policy executes. A contextual bandit arbitrates among shields based on the cue vector, improving mitigation choices online. RAIL couples Soft Actor–Critic (SAC) with risk-prioritized replay and dual rewards, steering learning while covering nominal behavior. On MetaDrive, RAIL achieves a Test Return (TR) of 360.65, a Test Success Rate (TSR) of 0.85, a Test Safety Violation (TSV) of 0.75, and a Disturbance Rate (DR) of 0.0027, while logging only 29.07 training safety violations—outperforming RL, safe RL, offline/imitation learning, and prior HITL baselines. Under ControllerAreaNetwork (CAN) injection and LiDAR spoofing attacks, it improves Success Rate (SR) to 0.68 and 0.80, lowers the Disengagement Rate under Attack (DRA) to 0.37 and 0.03, and reduces the Attack Success Rate (ASR) to 0.34 and 0.11. In CARLA, RAIL attains a TR of 1609.70 and TSR of 0.41 with only 8K steps.",334.52,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11792v1_A self-evolving multi-role collaborative framework.pdf,A self-evolving multi-role collaborative framework with fine-grained difficulty guidance for innovative mathematical problem generation,"['Yifei Sun', 'Yongan Li', 'A.K. Qin', 'Sicheng Hou', 'Tamas Pflanzner']","Mathematical problem generation (MPG) is a significant research direction in the field of intelligent education. In recent years, the rapid development of large language models (LLMs) has enabled new technological approaches to problem-generation tasks. Although existing LLMs can achieve high correctness rates, they generally lack innovation and exhibit poor discrimination. In this paper, we propose the task of innovative math problem generation (IMPG). To solve the IMPG task, this paper proposes a self-evolving, multi-role collaborative framework with fine-grained difficulty guidance. First, a multi-role collaborative mechanism comprising a sampler, generator, evaluator, state machine, and memory is constructed, ensuring the correctness of generated problems through iterative optimization informed by self-assessment and external feedback. Second, we introduce an improved difficulty model to quantify difficulty and provide fine-grained guidance. We adopt the data-driven association-guided pathsampling (DAPS) algorithm to enhance the semantic rationality of sampled encodings. Third, we construct the HSM3K-CN dataset, which comprises high-quality high-school math problems. A multi-stage training pipeline is adopted, incorporating continual pre-training (CPT), supervised fine-tuning (SFT), and group relative policy optimization (GRPO), to enhance the generation and evaluation capabilities of the base model. Finally, system self-evolution is achieved by transferring evaluation capabilities from the expert model to the apprentice model via distillation. Experiments show that, compared to baseline models, our proposed method significantly improves the innovation of the generated problems while maintaining a high correctness rate.",335.0,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11801v1_RobotDesignGPT Automated Robot Design Synthesis us.pdf,RobotDesignGPT: Automated Robot Design Synthesis using Vision Language Models,"['Nitish Sontakke', 'K. Niranjan Kumar', 'Sehoon Ha']","Robot design is a nontrivial process that involves careful consideration of multiple criteria, including user specifications, kinematic structures, and visual appearance. The design process often relies heavily on domain expertise and significant human effort. The majority of current methods are rule-based, requiring the specification of a grammar or a set of primitive components and modules that can be composed to create a design. The authors propose a novel automated robot design framework, RobotDesignGPT, that leverages the general knowledge and reasoning capabilities of large pre-trained vision-language models to automate the robot design synthesis process. Our framework synthesizes an initial robot design from a simple user prompt and a reference image. Our novel visual feedback approach allows us to greatly improve the design quality and reduce unnecessary manual feedback. We demonstrate that our framework can design visually appealing and kinematically valid robots inspired by nature, ranging from legged animals to flying creatures. We justify the proposed framework by conducting an ablation study and a user study.",332.62,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11809v1_Multi-agent DRL-based Lane Change Decision Model f.pdf,Multi-agent DRL-based Lane Change Decision Model for Cooperative Planning in Mixed Traffic,"['Zeyu Mu', 'Shangtong Zhang', 'B. Brian Park']","Connected automated vehicles (CAVs) can communicate and coordinate with each other, enabling cooperative platooning that enhances both energy efficiency and traffic flow. However, during the initial stage of CAV deployment, the sparse distribution of CAVs among human-driven vehicles reduces the likelihood of forming effective cooperative platoons. This study proposes a hybrid multi-agent lane change decision model to increase CAV participation in cooperative platoons and maximize associated benefits. The model employs the QMIX framework, integrating traffic data processed through a convolutional neural network (CNN-QMIX). This architecture addresses the critical issue of dynamic traffic scenarios by enabling CAVs to make optimal decisions irrespective of the varying number of CAVs present in mixed traffic. Additionally, a trajectory planner and a model predictive controller are designed to ensure smooth and safe lane-change execution. The proposed model is trained and evaluated within a microsimulation environment under varying CAV market penetration rates. The results demonstrate that the proposed model efficiently manages fluctuating traffic agent numbers, significantly outperforming the baseline rule-based models. Notably, it enhances cooperative platooning rates up to 26.2%, showcasing its potential to optimize CAV cooperation and traffic dynamics during the early stage of deployment.",331.02,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11816v1_POLARIS Typed Planning and Governed Execution for .pdf,POLARIS: Typed Planning and Governed Execution for Agentic AI in Back-Office Automation,"['Zahra Moslemi', 'Keerthi Koneru', 'Yen-Ting Lee', 'Sheethal Kumar', 'Ramesh Radhakrishnan']","Enterprise back-office workflows require agentic systems that are auditable, policy-aligned, and operationally predictable, capabilities that generic multi-agent setups often fail to deliver. We present POLARIS (Policy-Aware LLM Agentic Reasoning for Integrated Systems), a governed orchestration framework that treats automation as typed plan synthesis and validated execution over LLM agents. A planner proposes structurally diverse, type-checked directed acyclic graphs (DAGs); a rubric-guided reasoning module selects a single compliant plan; and execution is guarded by validator-gated checks, a bounded repair loop, and compiled policy guardrails that block or route side effects before they occur. Applied to document-centric finance tasks, POLARIS produces decision-grade artifacts and full execution traces while reducing human intervention. Empirically, POLARIS achieves a micro-F1 of 0.81 on the SROIE dataset and, on a controlled synthetic suite, achieves 0.95–1.00 precision for anomaly routing with preserved audit trails. These evaluations constitute an initial benchmark for governed Agentic AI. POLARIS provides a methodological and benchmark reference for policy-aligned Agentic AI.",334.43,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11825v1_AI Co-Scientist for Knowledge Synthesis in Medical.pdf,AI Co-Scientist for Knowledge Synthesis in Medical Contexts: A Proof of Concept,"['Arya Rahgozara', 'Pouria Mortezaaga']","This study aims to develop and evaluate an artificial intelligence (AI) co-scientist that enables scalable, transparent knowledge synthesis through explicit Population, Intervention, Comparator, Outcome, and Study design (PICOS) formalization. The platform integrates relational databases, vector-based semantic retrieval, and a Neo4j knowledge graph. The transformer-based classifier achieved strong agreement with expert annotations, with study design classification accuracy of 95.7%, while the Bi-LSTM baseline reached 87% accuracy for PICOS compliance detection. Retrieval-augmented generation (RAG) outperformed non-retrieval generation for queries requiring structured constraints, cross-study integration, and graph-based reasoning, whereas non-RAG approaches remained competitive for high-level summaries.",331.29,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11840v1_Imandra CodeLogician Neuro-Symbolic Reasoning for .pdf,Imandra CodeLogician: Neuro-Symbolic Reasoning for Precise Analysis of Software Logic,"['Hongyu Lin', 'Samer Abdallah', 'Makar Valentinov', 'Paul Brennan', 'Elijah Kagan', 'Christoph M. Wintersteiger', 'Denis Ignatovich', 'Grant Passmore']","Imandra CodeLogician is a neurosymbolic agent and framework designed for precise analysis of software logic. It integrates with ImandraX, an industrial automated reasoning engine, to enable automated reasoning beyond binary verification outcomes. The framework uses LLMs to construct explicit formal models of software systems, allowing for rigorous mathematical reasoning about program behavior. A new benchmark dataset, code-logic-bench, measures correctness and efficacy of reasoning about program state spaces, control flow, coverage constraints, decision boundaries, and edge cases. Formal augmentation with CodeLogician yields substantial and consistent improvements in reasoning accuracy, closing a 41–47 percentage point gap in accuracy and achieving complete coverage. These results demonstrate the essential role of neurosymbolic integration of LLMs with formal reasoning engines for scaling program analysis beyond heuristic reasoning toward rigorous, autonomous software understanding and formal verification.",332.5,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11850v1_Human-AI Collaborative Inductive Thematic Analysis.pdf,Human–AI Collaborative Inductive Thematic Analysis: How AI Guides Analysis and Researchers Reclaim Interpretive Authority,"['Matthew Nyaaba †1,2', 'Min SungEun †3', 'Mary Abiswin Apam †4', 'Kwame Owoahene Acheampong5', 'Emmanuel Dwamena6', 'Xiaoming Zhai1, 7']","This study investigates how researchers interact with an Inductive Thematic Analysis GPT (ITA–GPT), a purpose-built AI tool designed to operationalize established inductive thematic analysis procedures. The study focuses on analytic process rather than substantive content, with three experienced qualitative researchers independently conducting ITA–GPT–assisted analyses of interview transcripts from education research in the Ghanaian teacher education context. The ITA–GPT tool guided analysts through familiarization, verbatim (in-vivo) coding, gerund-based descriptive coding, and theme development, while enforcing trace-to-text integrity, transcript coverage checks, and auditability. Findings show that ITA–GPT functioned as a procedural and methodological scaffold, structuring analytic workflow and enhancing transparency. Researchers consistently exercised epistemic authority through five recurrent analytic actions: modification, deletion, rejection, insertion, and commenting. These actions were essential for correcting AI literalism, restoring contextual and emotional nuance, strengthening audit trails, and aligning interpretations with institutional and professional realities. Verbatim codes were perceived as the most reliable analytic foundation, while AI-generated abstractions required systematic human refinement.",333.43,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11854v1_ATOD An Evaluation Framework and Benchmark for Age.pdf,ATOD: An Evaluation Framework and Benchmark for Agentic Task-Oriented Dialogue System,"['Yifei Zhang', 'Hooshang Nayyeri', 'Rinat Khaziev', 'Emine Yilmaz', 'Gokhan Tur', 'Dilek Hakkani-Tür', 'Hari Thadakamalla']","Recent advances in task-oriented dialogue (TOD) systems have enabled conversational agents to coordinate interleaved goals, maintain long-horizon context, and act proactively through asynchronous execution. Existing benchmarks lack systematic support for evaluating such agentic behaviors. This paper introduces ATOD, a benchmark and synthetic dialogue generation pipeline that produces richly annotated conversations requiring long-term reasoning. ATOD captures key characteristics of advanced TOD, including multi-goal coordination, dependency management, memory, adaptability, and proactivity. ATOD-Eval, a holistic evaluation framework, translates these dimensions into fine-grained metrics and supports reproducible offline and online evaluation. A strong agentic memory-based evaluator is presented for benchmarking on ATOD. Experiments show that ATOD-Eval enables comprehensive assessment across task completion, agentic capability, and response quality, offering a better accuracy-efficiency trade-off compared to existing memory- and LLM-based approaches.",330.01,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11859v1_Cascaded Transformer for Robust and Scalable SLA D.pdf,Cascaded Transformer for Robust and Scalable SLA Decomposition via Amortized Optimization,['Cyril Shih-Huan Hsu'],"The evolution toward 6G networks increasingly relies on network slicing to provide tailored, End-to-End (E2E) logical networks over shared physical infrastructures. A critical challenge is effectively decomposing E2E Service Level Agreements (SLAs) into domain-specific SLAs, which current solutions handle through computationally intensive, iterative optimization processes that incur substantial latency and complexity. To address this, we introduce Casformer, a cascaded Transformer architecture designed for fast, optimization-free SLA decomposition. Casformer leverages historical domain feedback encoded through domain-specific Transformer encoders in its first layer, and integrates cross-domain dependencies using a Transformer-based aggregator in its second layer. The model is trained under a learning paradigm inspired by Domain-Informed Neural Networks (DINNs), incorporating risk-informed modeling and amortized optimization to learn a stable, forward-only SLA decomposition policy. Extensive evaluations demonstrate that Casformer achieves improved SLA decomposition quality against state-of-the-art optimization-based frameworks, while exhibiting enhanced scalability and robustness under volatile and noisy network conditions. In addition, its forward-only design reduces runtime complexity and simplifies deployment and maintenance. These insights reveal the potential of combining amortized optimization with Transformer-based sequence modeling to advance network automation, providing a scalable and efficient solution suitable for real-time SLA management in advanced 5G-and-beyond network environments.",335.26,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11863v1_Utilizing Metadata for Better Retrieval-Augmented .pdf,Retrieval-Augmented Generation: Metadata-aware Strategies,"['Raquib Bin Yousuf', 'Shengzhe Xu', 'Mandar Sharma', 'Andrew Neeser', 'Chris Latimer', 'Naren Ramakrishnan']","Retrieval-Augmented Generation systems rely on retrieving semantically relevant document chunks to support accurate, grounded outputs from large language models. In structured and repetitive corpora like regulatory filings, chunk similarity alone often fails to distinguish between overlapping documents. Practitioners often flatten metadata into input text as a heuristic, but the impact and trade-offs of this practice are poorly understood. This study systematically evaluates metadata-aware retrieval strategies, comparing plain-text baselines with approaches that embed metadata directly. The evaluation spans metadata-as-text (prefix and suffix), a dual-encoder unified embedding, dual-encoder late-fusion retrieval, and metadata-aware query reformulation. Across multiple retrieval metrics and question types, prefixing and unified embeddings consistently outperform plain-text baselines, with the unified embedding sometimes exceeding prefixing while being easier to maintain. The study also analyzes embedding space, showing that metadata integration improves effectiveness by increasing intra-document cohesion, reducing inter-document confusion, and widening the separation between relevant and irrelevant chunks. Field-level ablations demonstrate that structural cues provide strong disambiguating signals. The code, evaluation framework, and the RAGMate-10K dataset are publicly hosted.",334.33,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11868v1_Terminal-Bench Benchmarking Agents on Hard Realist.pdf,"TERMINAL-BENCH: BENCHMARKING AGENTS ON HARD, REALISTIC TASKS IN COMMANDLINE INTERFACES","['Mike A. Merrill', 'Alexander G. Shaw', 'Nicholas Carlini', 'Boxuan Li', 'Harsh Raj', 'Ivan Bercovich', 'Lin Shi', 'Jeong Yeon Shin', 'Thomas Walshe', 'E Kelly Buchanan', 'Junhong Shen', 'Guanghao Ye', 'Haowei Lin', 'Jason Poulos', 'Maoyu Wang', 'Marianna Nezhurina', 'Jenia Jitsev', 'Di Lu', 'Orfeas Menis Mastromichalakis', 'Zhiwei Xu', 'Zizhao Chen', 'Yue Liu', 'Robert Zhang', 'Junhong Lin', 'Manish Shetty', 'Michael Yang', 'Nabil Omi', 'Negin Raoof', 'Shanda Li', 'Wuwei Lin', 'Yiwei Dai', 'Yuxin Wang', 'Wenhao Chai', 'Shang Zhou', 'Ziyu She', 'Jiaming Hu', 'Yuxuan Zhu', 'Sasha Cui', 'Ahson Saiyed', 'Arinbj ¨orn Kolbeinsson', 'Jesse Hu', 'Christopher Michael Rytting', 'Ryan Marten', 'Yixin Wang', 'Alex Dimakis', 'Andy Konwinski', 'Ludwig Schmidt']","Presenting Terminal-Bench 2.0, a hard benchmark of 89 tasks in computer terminal environments inspired by real workflows. Frontier models and agents score less than 65% on the benchmark, with an error analysis to identify areas for improvement. The dataset and evaluation harness are published to assist future work.",330.67,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11876v1_AI for Green Spaces Leveraging Autonomous Navigati.pdf,Autonomous Trash Pickup Robot for Grass Fields,['List of strings'],"This paper proposes an autonomous robot designed to navigate, identify, and pick up litter in grass fields. The robot uses a Spanning Tree Coverage (STC) algorithm for path planning and Real-Time Kinematic (RTK) GPS for centimeter-level navigation. Computer vision with the ResNet50 Convolutional Neural Network (CNN) detects trash with 94.52% accuracy. The robot's design specifically targets litter on the field and achieved an overall success rate of 80%. The paper highlights the challenges of navigating grass fields and compares the proposed solution with existing robotic litter solutions for beaches and water.",330.9,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11880v1_TF-CoDiT Conditional Time Series Synthesis with Di.pdf,TF-CoDiT: Conditional Time Series Synthesis with Diffusion Transformers for Treasury Futures,"['Yingxiao Zhang', 'Jiaxin Duan', 'Junfu Zhang', 'Ke Feng']","Diffusion Transformers (DiT) have achieved milestones in synthesizing financial time-series data, such as stock prices and order flows. However, their performance in synthesizing treasury futures data is still underexplored. This work proposes TF-CoDiT, the first DiT framework for language-controlled treasury futures synthesis. TF-CoDiT adapts the standard DiT by transforming multi-channel 1-D time series into Discrete Wavelet Transform (DWT) coefficient matrices. A U-shape VAE is proposed to encode cross-channel dependencies hierarchically into a latent variable and bridge the latent and DWT spaces through decoding. Financial Market Attribute Protocol (FinMAP) is introduced to derive prompts covering essential conditions. Extensive evaluations demonstrate that TF-CoDiT can produce highly authentic data with errors at most 0.433 (MSE) and 0.453 (MAE) to the ground-truth, and further studies evidence its robustness across contracts and temporal horizons.",332.4,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11885v1_MyGram Modality-aware Graph Transformer with Globa.pdf,MyGram: Modality-aware Graph Transformer with Global Distribution for Multi-modal Entity Alignment,"['Zhifei Li', 'Ziyue Qin', 'Xiangyu Luo', 'Xiaoju Hou', 'Yue Zhao', 'Miao Zhang', 'Zhifang Huang', 'Kui Xiao', 'Bing Yang']","Multi-modal entity alignment aims to identify equivalent entities between two multi-modal Knowledge graphs by integrating multi-modal data, such as images and text, to enrich the semantic representations of entities. Existing methods may overlook the structural contextual information within each modality, making them vulnerable to interference from shallow features. To address these challenges, the authors propose MyGram, a modality-aware graph transformer with global distribution for multi-modal entity alignment. Specifically, they develop a modality diffusion learning module to capture deep structural contextual information within modalities and enable fine-grained multi-modal fusion. Additionally, they introduce a Gram Loss that acts as a regularization constraint by minimizing the volume of a 4-dimensional parallelotope formed by multi-modal features, thereby achieving global distribution consistency across modalities. Experiments on five public datasets show that MyGram outperforms baseline models, achieving a maximum improvement of 4.8% in Hits@1 on FBDB15K, 9.9% on FBYG15K, and 4.3% on DBP15K.",333.8,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11895v1_DevBench A Realistic Developer-Informed Benchmark .pdf,"DevBench: A Realistic, Developer-Informed Benchmark for Code Generation Models","['Pareesa Ameneh Golnari', 'Adarsh Kumarappan', 'Wen Wen', 'Xiaoyu Liu', 'Gabriel Ryan', 'Yuting Sun', 'Shengyu Fu', 'Elsie Nallipogu']","DevBench is a telemetry-driven benchmark designed to evaluate Large Language Models (LLMs) on realistic code completion tasks. It includes 1,800 evaluation instances across six programming languages and six task categories derived from real developer telemetry. Unlike prior benchmarks, DevBench emphasizes ecological validity, avoids training data contamination, and enables detailed diagnostics. The evaluation combines functional correctness, similarity-based metrics, and LLM-judge assessments focused on usefulness and contextual relevance. 9 state-of-the-art models were assessed, revealing differences in syntactic precision, semantic reasoning, and practical utility. The benchmark provides actionable insights to guide model selection and improvement.",335.37,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11903v1_AEMA Verifiable Evaluation Framework for Trustwort.pdf,AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems,"['Yen-Ting Lee', 'Keerthi Koneru', 'Zahra Moslemi', 'Sheethal Kumar', 'Ramesh Radhakrishnan']","Evaluating large language model (LLM)-based multi-agent systems remains a critical challenge, as these systems must exhibit reliable coordination, transparent decision-making, and verifiable performance across evolving tasks. Existing evaluation approaches often limit themselves to single-response scoring or narrow benchmarks, which lack stability, extensibility, and automation when deployed in enterprise settings at multi-agent scale. We present AEMA (Adaptive Evaluation Multi-Agent), a process-aware and auditable framework that plans, executes, and aggregates multi-step evaluations across heterogeneous agentic workflows under human oversight. Compared to a single LLM-as-a-Judge, AEMA achieves greater stability, human alignment, and traceable records that support accountable automation. Our results on enterprise-style agent workflows simulated using realistic business scenarios demonstrate that AEMA provides a transparent and reproducible pathway toward responsible evaluation of LLM-based multi-agent systems.",331.56,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11905v1_LIBRA Language Model Informed Bandit Recourse Algo.pdf,LIBRA: Language Model Informed Bandit Recourse Algorithm for Personalized Treatment Planning,"['Junyu Cao', 'Ruijiang Gao', 'Esmaeil Keyvanshokooh', 'Jianhao Ma']","The authors introduce a unified framework that integrates algorithmic recourse, contextual bandits, and large language models (LLMs) to support sequential decision-making in high-stakes settings such as personalized medicine. They develop the Generalized Linear Recourse Bandit (GLRB) algorithm and propose LIBRA, a Language Model–Informed Bandit Recourse Algorithm that strategically combines domain knowledge from LLMs with the statistical rigor of bandit learning. LIBRA offers three key guarantees: a warm-start guarantee, an LLM-effort guarantee, and a robustness guarantee. The authors establish matching lower bounds to characterize the fundamental difficulty of the recourse bandit problem and demonstrate the near-optimality of their algorithms through experiments on synthetic environments and a real hypertension-management case study. The results highlight the promise of recourse-aware, LLM-assisted bandit algorithms for trustworthy LLM-bandits collaboration in personalized high-stakes decision-making.",330.67,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11907v1_Towards Airborne Object Detection A Deep Learning .pdf,Towards Airborne Object Detection: A Deep Learning Analysis,"['1st Prosenjit Chatterjee', '2nd ANK Zaman']","The rapid proliferation of airborne platforms has intensified the need for real-time, automated threat assessment systems. Current approaches depend heavily on manual monitoring, resulting in limited scalability and operational inefficiencies. This work introduces a dual-task model based on EfficientNetB4 capable of performing airborne object classification and threat-level prediction simultaneously. To address the scarcity of clean, balanced training data, the AODTA Dataset was constructed by aggregating and refining multiple public sources. The model achieved 96% accuracy in object classification and 90% accuracy in threat-level prediction, underscoring its promise for applications in surveillance, defense, and airspace management. Although the title references 'detection,' this study focuses specifically on classification and threat-level inference using pre-localized airborne object images provided by existing datasets.",332.12,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11913v1_LSTM-MAS A Long Short-Term Memory Inspired Multi-A.pdf,LSTM-MAS: A Long Short-Term Memory Inspired Multi-Agent System for Long-Context Understanding,"['Yichen Jiang', 'Peng Ye', 'Jiakang Yuan', 'Chongjun Tu', 'Lei Bai', 'Tao Chen']","Effectively processing long contexts remains a fundamental yet unsolved challenge for large language models (LLMs). Existing single-LLM-based methods primarily reduce the context window or optimize the attention mechanism, but they often encounter additional computational costs or constrained expanded context length. While multi-agent-based frameworks can mitigate these limitations, they remain susceptible to the accumulation of errors and the propagation of hallucinations. In this work, we draw inspiration from the Long Short-Term Memory (LSTM) architecture to design a Multi-Agent System called LSTM-MAS, emulating LSTM’s hierarchical information flow and gated memory mechanisms for long-context understanding. Specifically, LSTM-MAS organizes agents in a chained architecture, where each node comprises a worker agent for segment-level comprehension, a filter agent for redundancy reduction, a judge agent for continuous error detection, and a manager agent for globally regulating information propagation and retention, analogous to LSTM and its input gate, forget gate, constant error carousel unit, and output gate. These novel designs enable controlled information transfer and selective long-term dependency modeling across textual segments, which can effectively avoid error accumulation and hallucination propagation. We conducted an extensive evaluation of our method. Compared with the previous best multi-agent approach, CoA, our model achieves improvements of 40.93%, 43.70%, 121.57%, and 33.12% on NarrativeQA, Qasper, HotpotQA, and MuSiQue, respectively.",330.65,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11920v1_Enhancing LLM-Based Data Annotation with Error Dec.pdf,Enhancing LLM-Based Data Annotation with Error Decomposition,"['Zhen Xu', 'Vedant Khatri', 'Yijun Dai', 'Xiner Liu', 'Siyan Li', 'Xuanming Zhang', 'Renzhe Yu']","Large language models (LLMs) offer a scalable alternative to human coding for data annotation tasks, enabling the scale-up of research across data-intensive domains such as learning analytics. While LLMs are already achieving near-human accuracy on objective annotation tasks, their performance on subjective annotation tasks, such as those involving psychological constructs, is less consistent and more prone to errors. Standard evaluation practices typically collapse all annotation errors into a single alignment metric, but this simplified approach may obscure different kinds of errors that affect final analytical conclusions in different ways. Here, we propose a diagnostic evaluation paradigm that incorporates a human-in-the-loop step to separate task-inherent ambiguity from model-driven inaccuracies and assess annotation quality in terms of their potential downstream impacts. We refine this paradigm on ordinal annotation tasks, which are common in subjective annotation. The refined paradigm includes: (1) a diagnostic taxonomy that categorizes LLM annotation errors along two dimensions: source (model-specific vs. task-inherent) and type (boundary ambiguity vs. conceptual misidentification); (2) a lightweight human annotation test to estimate task-inherent ambiguity from LLM annotations; and (3) a computational method to decompose observed LLM annotation errors following our taxonomy. We validate this paradigm on four educational annotation tasks, demonstrating both its conceptual validity and practical utility. Theoretically, our work provides empirical evidence for why excessively high alignment is unrealistic in specific annotation tasks and why single alignment metrics inadequately reflect the quality of LLM annotations. In practice, our paradigm can be a low-cost diagnostic tool that assesses the suitability of a given task for LLM annotation and provides actionable insights for further technical optimization.",334.99,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11935v1_Big Data Workload Profiling for Energy-Aware Cloud.pdf,Big Data Workload Profiling for Energy-Aware Cloud Resource Management,"['Milan Parikh', 'Aniket Abhishek Soni', 'Sneja Mitinbhai Shah', 'Ayush Raj Jha']","Cloud data centers face increasing pressure to reduce operational energy consumption as big data workloads continue to grow in scale and complexity. This paper presents a workload-aware scheduling framework that uses profiling of CPU usage, memory demand, and storage I/O behavior to guide energy-efficient virtual machine (VM) placement. By combining historical execution logs with real-time telemetry, the system predicts the energy and performance impact of candidate placement decisions and adaptively consolidates workloads without violating service-level agreements (SLAs). The framework was evaluated using representative Hadoop MapReduce, Spark MLlib, and ETL workloads on a multi-node cloud testbed. Experimental results demonstrate a consistent reduction of 15–20% in energy consumption while maintaining SLA compliance. These findings highlight the effectiveness of data-driven workload profiling as a practical strategy for improving the sustainability of cloud computing environments.",332.72,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11940v1_Thinking Traps in Long Chain-of-Thought A Measurab.pdf,Scaling Test-Time Compute via Long Chain-of-Thought: A Measurable Study and Trap-Aware Adaptive Restart,"['Kang Chen', 'Fan Yu', 'Junjie Nian', 'Shihan Zhao', 'Zhuoka Feng', 'Zĳun Yao', 'Heng Wang', 'Minshen Yu', 'Yixin Cao']","Scaling test-time compute via Long Chain-of-Thought (Long-CoT) significantly enhances reasoning capabilities, yet extended generation does not guarantee correctness. Through fine-grained trajectory analysis, the authors identify 'Thinking Traps', prefix-dominant deadlocks where later reflection, alternative attempts, or verification fail to revise the root error. On a curated subset of DAPO-MATH, 89% of failures exhibit such traps. To solve this problem, the authors introduce TAAR (Trap-Aware Adaptive Restart), a test-time control framework that trains a diagnostic policy to predict trap indices and escape probabilities. At inference time, TAAR truncates the trajectory before the predicted trap segment and adaptively restarts decoding. For severely trapped cases, it applies stronger perturbations, including higher-temperature resampling and an optional structured reboot suffix. Experiments on challenging mathematical and scientific reasoning benchmarks show that TAAR improves reasoning performance without fine-tuning base model parameters.",334.61,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11956v1_Double-Calibration Towards Trustworthy LLMs via Ca.pdf,Double-Calibration: Towards Trustworthy LLMs via Calibrating Knowledge and Reasoning Confidence,"['Yuyin Lu', 'Ziran Liang', 'Yanghui Rao', 'Wenqi Fan', 'Fu Lee Wang', 'Qing Li']","Trustworthy reasoning in Large Language Models (LLMs) is challenged by their propensity for hallucination. While augmenting LLMs with Knowledge Graphs (KGs) improves factual accuracy, existing KG-augmented methods fail to quantify epistemic uncertainty in both the retrieved evidence and LLMs' reasoning. To bridge this gap, we introduce DoublyCal, a framework built on a novel double-calibration principle. DoublyCal employs a lightweight proxy model to first generate KG evidence alongside a calibrated evidence confidence. This calibrated supporting evidence then guides a black-box LLM, yielding final predictions that are not only more accurate but also well-calibrated, with confidence scores traceable to the uncertainty of the supporting evidence. Experiments on knowledge-intensive benchmarks show that DoublyCal significantly improves both the accuracy and confidence calibration of black-box LLMs with low token cost.",333.41,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11960v1_R2PO Decoupling Training Trajectories from Inferen.pdf,R2PO: Decoupling Training Trajectories from Inference Responses for LLM Reasoning,"['Jingchu Wang', 'Bingbing Xu', 'Yige Yuan', 'Bin Xie', 'Xiaoqian Sun', 'Huawei Shen']","Reinforcement learning has become a central paradigm for improving LLM reasoning. However, existing methods use a single policy to produce both inference responses and training optimization trajectories, leading to insufficient exploration and reduced reasoning capability. This paper proposes R2PO (ResidualRolloutPolicyOptimization), which introduces a lightweight residual module to decouple training trajectories from inference responses, enabling controlled trajectory diversification during training while keeping inference generation stable. Experiments across multiple benchmarks show that R2PO consistently outperforms baselines, achieving average accuracy gains of 3.1% on MATH-500 and 2.4% on APPS, while also reducing formatting errors and mitigating length bias for stable optimization.",329.99,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11969v1_textttMemoryRewardBench Benchmarking Reward Models.pdf,MemoryRewardBench: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models,"['Zecheng Tang', 'Baibei Ji', 'Ruoxi Sun', 'Haitian Wang', 'Wangjie You', 'Yijun Zhang', 'Wenpeng Zhu', 'Ji Qi', 'Juntao Li', 'Min Zhang']","Existing works increasingly adopt memory-centric mechanisms to process long contexts in a segment manner. Effective memory management is crucial for large language models to propagate information across the entire sequence. This work introduces MemRewardBench, the first benchmark to systematically study the ability of reward models to evaluate long-term memory management processes. MemRewardBench covers both long-context comprehension and long-form generation tasks, featuring 10 distinct settings with different memory management patterns, and evaluates 13 cutting-edge reward models. Evaluations indicate a diminishing performance gap between open-source and proprietary models, with newer-generation models consistently outperforming their predecessors regardless of parameter count. The study exposes the capabilities and fundamental limitations of current reward models in evaluating LLM memory management across diverse settings.",334.18,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11974v1_Learn Like Humans Use Meta-cognitive Reflection fo.pdf,Learn Like Humans: Use Meta-cognitive Reflection for Efficient Self-Improvement,"['Xinmeng Hou', 'Peiliang Gong', 'Bohao Qu', 'Wuqi Wang', 'Qing Guo', 'Yang Liu']","While Large Language Models (LLMs) enable complex autonomous behavior, current agents are constrained by static, human-designed prompts that limit adaptability. Existing self-improving frameworks typically rely on inefficient, multi-turn recursive loops that incur high computational costs. This paper proposes Metacognitive Agent Reflective Self-improvement (MARS), a framework that achieves efficient self-evolution within a single recurrence cycle. Inspired by educational psychology, MARS integrates principle-based reflection (abstracting normative rules to avoid errors) and procedural reflection (deriving step-by-step strategies for success). By synthesizing these insights into optimized instructions, MARS allows agents to systematically refine their reasoning logic without continuous online feedback. Extensive experiments on six benchmarks demonstrate that MARS outperforms state-of-the-art self-evolving systems while significantly reducing computational overhead. Code is available at https://anonymous.4open.science/r/MARS-9F16.",331.3,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11977v1_One-Shot Price Forecasting with Covariate-Guided E.pdf,One-Shot Price Forecasting with Covariate-Guided Experts under Privacy Constraints,"['Ren He', 'Yinliang Xu', 'Jinfeng Wang', 'Jeremy Watson', 'Jian Song']","Forecasting in power systems often involves multi-variate time series with complex dependencies and strict privacy constraints across regions. Traditional forecasting methods require significant expert knowledge and struggle to generalize across diverse deployment scenarios. Recent advancements in pre-trained time series models offer new opportunities, but their zero-shot performance on domain-specific tasks remains limited. To address these challenges, the authors propose a novel MoE-Encoder module that augments pre-trained forecasting models by injecting a sparse mixture-of-experts layer between tokenization and encoding. This design enables two key capabilities: (1) transforming multivariate forecasting into an expert-guided univariate task, allowing the model to effectively capture inter-variable relations, and (2) supporting localized training and lightweight parameter sharing in federated settings where raw data cannot be exchanged. Extensive experiments on public multivariate datasets demonstrate that MoE-Encoder significantly improves forecasting accuracy compared to strong baselines. The authors further simulate federated environments and show that transferring only MoE-Encoder parameters allows efficient adaptation to new regions, with minimal performance degradation. Their findings suggest that MoE-Encoder provides a scalable and privacy-aware extension to foundation time series models.",331.0,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11979v1_Process In-Context Learning Enhancing Mathematical.pdf,Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion,"['Ang Gao', 'Changshuo Zhang', 'Xiao Zhang', 'Deyang Li', 'Minjun Zhao', 'Fangchao Liu', 'Xinyu Zhang']","In-context learning (ICL) has shown effectiveness across diverse large language model tasks, but its potential for enhancing tasks that require step-by-step logical deduction, such as mathematical reasoning, remains underexplored. A core limitation of existing ICL approaches is their static use of demonstrations: examples are pre-selected before inference and remain fixed, failing to adapt to dynamic confusion points that often arise during multi-step reasoning. Process In-Context Learning (PICL) addresses this issue by dynamically integrating demonstrations to respond to real-time inference needs. PICL operates in two stages: identifying potential confusion points and inserting relevant demonstrations into the ongoing reasoning process. Experiments show that PICL outperforms baseline methods by mitigating mid-inference confusion and highlighting the value of adaptive demonstration insertion in complex mathematical reasoning.",333.42,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11995v1_Learning Audio-Visual Embeddings with Inferred Lat.pdf,Learning Audio–Visual Embeddings with Inferred Latent Interaction Graphs,"['Donghuo Zeng', 'Hao Niu', 'Yanan Wang', 'Masato Taya']","Learning robust audio–visual embeddings requires bringing genuinely related audio and visual signals together while filtering out incidental co-occurrences. Most contrastive and triplet-loss methods use sparse annotated labels per clip and treat any co-occurrence as semantic similarity. The proposed framework leverages soft-label predictions and inferred latent interactions to address these issues. It includes AV-SAL, ILI, and LIR components, which enhance robustness and semantic coherence in embedding learning.",331.21,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.11998v1_Hybrid IDS Using Signature-Based and Anomaly-Based.pdf,Hybrid IDS Using Signature-Based and Anomaly-Based Detection,"['Messaouda Boutassetta', 'Amina Makhlouf', 'Newfel Messaoudi', 'Abdelmadjid Benmachiche', 'Ines Boutabia']","Intrusion detection systems (IDS) are essential for protecting computer systems and networks against cyber threats. This paper presents a comprehensive survey and conceptual overview of Hybrid IDS, which integrate signature-based and anomaly-based detection techniques. The survey examines recent research on Hybrid IDS, classifies existing models into functional categories, and discusses their advantages, limitations, and application domains, including financial systems, air traffic control, and social networks. It also reviews recent trends in Hybrid IDS research, such as machine learning-based approaches and cloud-based deployments, and outlines potential future research directions aimed at developing more cost-effective Hybrid IDS solutions with improved ability to detect emerging and sophisticated cyberattacks.",332.31,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12002v1_Kernel-Based Learning of Safety Barriers.pdf,Kernel-Based Learning of Safety Barriers,"['Oliver Schoen', 'Zhengang Zhong', 'Sadegh Soudjani']","The paper presents a data-driven approach for safety verification and synthesis of black-box systems with discrete-time stochastic dynamics. It employs control barrier certificates to guarantee system safety and learns these certificates directly from system trajectories. Conditional mean embeddings are used to embed data into a reproducing kernel Hilbert space (RKHS), and an RKHS ambiguity set is constructed to robustify the results against out-of-distribution behavior. The approach is scalable and distributionally robust, applicable to general classes of temporal logic specifications beyond safety. The data-driven computation of safety barriers leverages a finite Fourier expansion to transform a semi-infinite optimization problem into a linear program, allowing for efficient generation of relaxed problems using the fast Fourier transform. The work demonstrates the approach on two case studies, including a black-box system with a neural network controller.",335.31,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12003v1_Robust Verification of Concurrent Stochastic Games.pdf,Robust Verification of Concurrent Stochastic Games,"['Angel Y. He', 'David Parker']","Autonomous and intelligent systems are increasingly deployed in environments that are nondeterministic, stochastic, and concurrent. Concurrent stochastic games (CSGs) provide a powerful framework for modeling such multi-agent systems. Unlike simpler models of turn-based stochastic games, CSGs allow players to select their actions simultaneously, without knowledge of each other's choices. The outcomes depend probabilistically on the players' joint actions. Formal verification techniques for CSGs provide a means to establish quantitative guarantees on the behavior of these stochastic multi-agent systems, e.g., ensuring that a drone can safely reach its target with at least 95% probability, regardless of the actions of other aircraft. They can also be used to automatically synthesise controllers or strategies that achieve these guarantees. The paper introduces robust CSGs and their subclass interval CSGs (ICSGs), which capture epistemic uncertainty about transition probabilities in CSGs. It proposes an innovative framework for robust verification under worst-case assumptions about transition uncertainty, developing the underlying theoretical foundations and efficient algorithms for finite- and infinite-horizon objectives in both zero-sum and nonzero-sum settings. The implementation is built in the PRISM-games model checker, and the feasibility of robust verification of ICSGs is demonstrated across a selection of large benchmarks.",335.14,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12014v1_Are LLMs Ready for TOON Benchmarking Structural Co.pdf,Are LLMs Ready for TOON? Benchmarking Structural Correctness–Sustainability Trade-offs in Novel Structured Output Formats,"['Elio Masciari', 'Vincenzo Moscato', 'Enea Vincenzo Napolitano', 'Gian Marco Orlando', 'Marco Perillo', 'Diego Russo']","Large Language Models (LLMs) are increasingly required to generate structured, machine-readable outputs for downstream systems. While recent benchmarks have focused on evaluating the structural correctness of such outputs, the environmental impact of inference for different output formats has largely been overlooked. In this paper, we introduce a sustainability-aware evaluation framework for structured generation that measures token usage, generation time, and estimated carbon emissions. We propose the Environment-Aware Generation Correctness Score (GCSenv) to integrate structural correctness with carbon-aware efficiency. Using this framework, we benchmark the novel TOON format against established representations (JSON, XML, YAML) across multiple LLMs spanning different architectures and parameter scales. Our results reveal a consistent trade-off: TOON yields more compact outputs and lower emissions but lower structural correctness when models lack native support. Increased model capacity reduces this gap, and environment-aware scoring can shift format rankings depending on deployment priorities. This highlights the need for sustainability-inclusive benchmarking and provides empirical evidence that compact representations such as TOON can offer practical advantages in large-scale, carbon-conscious LLM deployments.",329.89,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12019v1_Acting Flatterers via LLMs Sycophancy Combating Cl.pdf,Acting Flatterers via LLMs Sycophancy: Combating Clickbait with LLMs Opposing-Stance Reasoning,"['Chaowei Zhang', 'Xiansheng Luo', 'Zewei Zhang', 'Yi Zhu', 'Jipeng Qiang', 'Longwei Wang']","The widespread proliferation of online content has intensified concerns about clickbait, deceptive or exaggerated headlines designed to attract attention. While Large Language Models (LLMs) offer a promising avenue for addressing this issue, their effectiveness is often hindered by Sycophancy, a tendency to produce reasoning that matches users’ beliefs over truthful ones. This work proposes a novel approach that harnesses this behavior to generate contrastive reasoning from opposing perspectives. Specifically, a Self-renewal Opposing-stance Reasoning Generation (SORG) framework prompts LLMs to produce high-quality “agree” and “disagree” reasoning pairs for a given news title without requiring ground-truth labels. To utilize the generated reasoning, a local Opposing Reasoning-based Clickbait Detection (ORCD) model is developed, integrating three BERT encoders to represent the title and its associated reasoning. The model leverages contrastive learning, guided by soft labels derived from LLM-generated credibility scores, to enhance detection robustness. Experimental evaluations on three benchmark datasets demonstrate that our method consistently outperforms LLM prompting, fine-tuned smaller language models, and state-of-the-art clickbait detection baselines.",330.18,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12024v1_A Multi-Agent System for Generating Actionable Bus.pdf,A Multi-Agent System for Generating Actionable Business Advice,"['Kartikey Singh Bhandari', 'Tanish Jain', 'Archit Agrawal', 'Dhruv Kumar', 'Praveen Kumar', 'Pratik Narang']","Customer reviews contain rich signals about product weaknesses and unmet user needs, yet existing analytic methods rarely move beyond descriptive tasks such as sentiment analysis or aspect extraction. Large language models (LLMs) can interpret nuanced language and generate human-like text, making them promising for extracting insights from reviews. However, most review-mining work stops at sentiments, aspects, or summaries, rarely translating findings into concrete, actionable guidance for businesses. This paper presents a multi-agent, LLM-based framework for prescriptive decision support, which transforms large scale review corpora into actionable business advice. The framework integrates four components: clustering to select representative reviews, generation of advice, iterative evaluation, and feasibility-based ranking. Experiments across three service domains and multiple model families show that the framework consistently outperforms single model baselines on actionability, specificity, and non-redundancy, with medium-sized models approaching the performance of large model frameworks.",333.6,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12030v1_ARC Active and Reflection-driven Context Managemen.pdf,ARC: Active and Reflection-driven Context Management for Long-Horizon Information Seeking Agents,"['Yilun Yao', 'Shan Huang', 'Elsie Dai', 'Zhewen Tan', 'Zhenyu Duan', 'Shousheng Jia', 'Yanbing Jiang', 'Tong Yang']","Large language models are increasingly deployed for deep search and long-horizon information seeking, but their performance often degrades as interaction histories grow. This degradation, known as context rot, reflects a failure to maintain coherent and task-relevant internal states over extended reasoning horizons. Existing approaches primarily manage context through raw accumulation or passive summarization, treating it as a static artifact and allowing early errors or misplaced emphasis to persist. Motivated by this perspective, the authors propose ARC, a framework that systematically formulates context management as an active, reflection-driven process, treating context as a dynamic internal reasoning state during execution. ARC operationalizes this view through reflection-driven monitoring and revision, allowing agents to actively reorganize their working context when misalignment or degradation is detected. Experiments on challenging long-horizon information-seeking benchmarks show that ARC consistently outperforms passive context compression methods, achieving up to an 11% absolute improvement in accuracy on BrowseComp-ZH with Qwen2.5-32B-Instruct.",330.07,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12038v1_Abstract Argumentation with Subargument Relations.pdf,Abstract Argumentation with Subargument Relations,['Beishui Liao'],"Dung's abstract argumentation framework characterizes argument acceptability solely via an attack relation, abstracting from the internal structure of arguments. This paper enriches the framework with an explicit subargument relation, treating it alongside attack as a basic relation. It analyzes how subargument relations interact with attacks and examines their impact on fundamental semantic properties. This framework provides a principled abstraction of structural information and clarifies the role of subarguments in abstract acceptability reasoning.",330.48,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12040v1_Partial Reasoning in Language Models Search and Re.pdf,Partial Reasoning Guided by Uncertainty,"['Murilo da Luz', 'Bruno Brandão', 'Luana Martins', 'Gustavo Oliveira', 'Bryan de Oliveira', 'Luckeciano Melo', 'Telma Soares']","The use of Large Language Models (LLMs) for reasoning and planning tasks has drawn increasing attention in Artificial Intelligence research. Despite their remarkable progress, these models still exhibit limitations in multi-step inference scenarios, particularly in mathematical and logical reasoning. We introduce PREGU (Partial Reasoning Guided by Uncertainty). PREGU monitors the entropy of the output distribution during autoregressive generation and halts the process whenever entropy exceeds a defined threshold, signaling uncertainty. From that point, a localized search is performed in the latent space to refine the partial reasoning and select the most coherent answer, using the Soft Reasoning method. Experiments conducted with LLaMA-3-8B, Mistral-7B, and Qwen2-7B across four reasoning benchmarks (GSM8K, GSM-Hard, SVAMP, and StrategyQA) showed performance greater than or similar to Soft Reasoning, indicating that entropy can serve as an effective signal to trigger selective refinement during reasoning.",329.95,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12042v1_Less Is More -- Until It Breaks Security Pitfalls .pdf,Less Is More — Until It Breaks: Security Pitfalls of Vision Token Compression in Large Vision-Language Models,"['Xiaomei Zhang', 'Zhaoxi Zhang', 'Leo Yu Zhang', 'Yanjun Zhang', 'Guanhong Tao', 'Shirui Pan']","Visual token compression is widely adopted to improve the inference efficiency of Large Vision-Language Models (LVLMs), but it has largely unexplored security implications. This work reveals that visual token compression substantially degrades the robustness of LVLMs, making them highly vulnerable once compression is enabled. By analyzing the key stages of the compression process, instability in token importance ranking is identified as the primary cause of this robustness degradation. The authors propose a Compression-Aware Attack (CAA) to systematically study and exploit this vulnerability, and further extend this approach to more realistic black-box settings. Experimental results show that compression-induced security risks persist even under practical settings, and potential defenses provide only limited protection. The work demonstrates that visual token compression significantly undermines model robustness, exposing a previously overlooked trade-off between efficiency and security.",334.12,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12049v1_textitFocaLogic Logic-Based Interpretation of Visu.pdf,FocaLogic: Logic-Based Interpretation of Visual Model Decisions,"['Chenchen Zhao*', 'Muxi Chen*', 'Qiang Xu†']","Interpretability of modern visual models is crucial, particularly in high-stakes applications. Existing methods typically rely on white-box model access or lack quantitative rigor. FocaLogic introduces a novel model-agnostic framework to interpret and quantify visual model decision-making through logic-based representations. It identifies minimal interpretable subsets of visual regions (visual focuses) that decisively influence model predictions and translates these into precise logical expressions. The framework provides a systematic, scalable, and quantitative solution for interpreting visual models, uncovering insights such as training-induced concentration, focus accuracy through generalization, and anomalous focuses under biases and adversarial attacks.",330.12,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12053v1_A New Strategy for Artificial Intelligence Trainin.pdf,A New Strategy for Artificial Intelligence: Training Foundation Models Directly on Human Brain Data,['Ma¨el Donoso'],"While foundation models have achieved remarkable results across a diversity of domains, they still rely on human-generated data, such as text, as a fundamental source of knowledge. This data is ultimately the product of human brains, the filtered projection of a deeper neural complexity. In this paper, we explore a new strategy for artificial intelligence: moving beyond surface-level statistical regularities by training foundation models directly on human brain data. We hypothesize that neuroimaging data could open a window into elements of human cognition that are not accessible through observable actions, and argue that this additional knowledge could be used, alongside classical training data, to overcome some of the current limitations of foundation models. While previous research has demonstrated the possibility to train classical machine learning or deep learning models on neural patterns, this path remains largely unexplored for high-level cognitive functions. Here, we classify the current limitations of foundation models, as well as the promising brain regions and cognitive processes that could be leveraged to address them, along four levels: perception, valuation, execution, and integration. Then, we propose two methods that could be implemented to prioritize the use of limited neuroimaging data for strategically chosen, high-value steps in foundation model training: reinforcement learning from human brain (RLHB) and chain of thought from human brain (CoTHB). We also discuss the potential implications for agents, artificial general intelligence, and artificial superintelligence, as well as the ethical, social, and technical challenges and opportunities. We argue that brain-trained foundation models could represent a realistic and effective middle ground between continuing to scale current architectures and exploring alternative, neuroscience-inspired solutions. We also note that future discoveries in cognitive and computational neuroscience could make this strategy increasingly relevant over time, as new neural signals of interest are retroactively unlocked in present neuroimaging datasets.",314.08,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12055v1_Automating Parameter Selection in Deep Image Prior.pdf,Automating Parameter Selection in Deep Image Prior for Fluorescence Microscopy Image Denoising via Similarity-Based Parameter Transfer,"['Lina Meyer', 'Felix Wissel', 'Tobias Knopp', 'Susanne Pfefferle', 'Ralf Fliegert', 'Maximilian Sandmann', 'Liana Uebler', 'Franziska Mockl', 'Björn-Philipp Diercks', 'David Lohr', 'René Werner']","This study hypothesizes that similar images share comparable optimal parameter configurations for Deep Image Prior (DIP)-based denoising, potentially enabling optimization-free DIP for fluorescence microscopy. The authors generated a calibration and validation set of semantically different images from an open-source dataset to search for ideal U-net architectures and stopping points. They implemented AUTO-DIP, a pipeline for automatic parameter transfer, and compared it to the original DIP configuration and a state-of-the-art variational denoising approach. The results show that AUTO-DIP outperforms the baseline DIP and variational denoising approaches for several open-source test datasets, particularly for very noisy inputs. The study was supported by the Deutsche Forschungsgemeinschaft (DFG) and the corresponding authors are David Lohr and René Werner.",313.44,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12061v1_Codebook-Injected Dialogue Segmentation for Multi-.pdf,Codebook-Injected Dialogue Segmentation for Multi-Utterance Constructs,"['Jinsook Lee', 'Kirk Vanacore', 'Zhuqian Zhou', 'Bakhtawar Ahtisham', 'Jeanine Grütter', 'René F. Kizilcec']","This paper proposes codebook-injected segmentation, a method that conditions boundary decisions on downstream annotation criteria. It evaluates LLM-based segmenters against standard and retrieval-augmented baselines. The authors introduce evaluation metrics for span consistency, distinctiveness, and human-AI distributional agreement to assess these methods without gold labels. The study finds that DA-awareness produces more consistent segments than text-only baselines, but LLMs excel at creating construct-consistent spans. The results highlight segmentation as a critical design choice that should be optimized for downstream objectives rather than a single performance score.",309.39,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12068v1_Bridging the Gap in Bangla Healthcare Machine Lear.pdf,Bridging the Gap in Bangla Healthcare: Machine Learning Based Disease Prediction Using a Symptoms-Disease Dataset,"['Rowzatul Zannat', 'Abdullah Al Shafi', 'Abdul Muntakim']","Increased access to reliable health information is essential for non-English-speaking populations, yet resources in Bangla for disease prediction remain limited. This study addresses this gap by developing a comprehensive Bangla symptoms-disease dataset containing 758 unique symptom-disease relationships spanning 85 diseases. The dataset enables the prediction of diseases based on Bangla symptom inputs, supporting healthcare accessibility for Bengali-speaking populations. Using this dataset, the study evaluated multiple machine learning models to predict diseases based on symptoms provided in Bangla and analyzed their performance on the dataset. Both soft and hard voting ensemble approaches combining top-performing models achieved 98% accuracy, demonstrating superior robustness and generalization. The work establishes a foundational resource for disease prediction in Bangla, paving the way for future advancements in localized health information and diagnostic tools, enhancing equitable access to health information for Bangla-speaking communities, particularly for early disease detection and healthcare interventions.",314.4,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12082v1_Conditional Random Fields for Interactive Refineme.pdf,Conditional Random Fields for Interactive Refinement of Histopathological Predictions,"['Tiffanie Godelaine†', 'Maxime Zanella†', 'Karim El Khoury1', 'Saïd Mahmoudi2', 'Benoît Macq1', 'Christophe De Vleeschouwer1']","Assisting pathologists in the analysis of histopathological images has high clinical value, as it supports cancer detection and staging. Vision-Language Models (VLMs) provide strong yet imperfect zero-shot predictions. The authors propose to refine these predictions by adapting Conditional Random Fields (CRFs) to histopathological applications, requiring no additional model training. They present HistoCRF, a CRF-based framework with a novel definition of the pairwise potential that promotes label diversity and leverages expert annotations. Experiments on five patch-level classification datasets covering different organs and diseases demonstrate average accuracy gains of 16.0% without annotations and 27.5% with only 100 annotations, compared to zero-shot predictions. Integrating a human in the loop reaches a further gain of 32.6% with the same number of annotations. The code will be made available on https://github.com/tgodelaine/HistoCRF.",310.8,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12095v1_Neural Isomorphic Fields A Transformer-based Algeb.pdf,Neural Isomorphic Fields: A Transformer-Based Algebraic Numerical Embedding,"['Hamidreza Sadeghi', 'Reza Safabakhsh', 'Reza Momtazi']","Neural network models often face challenges when processing very small or very large numbers due to issues such as overflow, underflow, and unstable output variations. To mitigate these problems, the authors propose using embedding vectors for numbers instead of directly using their raw values. These embeddings aim to retain essential algebraic properties while preventing numerical instabilities. In this paper, the authors introduce a fixed-length number embedding vector that preserves algebraic operations—addition, multiplication, and comparison—within the rational numbers field. They propose a novel Neural Isomorphic Field, a neural abstraction of algebraic structures like groups and fields. The elements of this neural field are embedding vectors that maintain algebraic structure during computations. The authors demonstrate that addition performs exceptionally well, achieving over 95% accuracy on key algebraic tests such as identity, closure, and associativity. In contrast, multiplication exhibits challenges, with accuracy ranging between 53% to 73% across various algebraic properties. These findings highlight the model's strengths in preserving algebraic properties under addition while identifying avenues for further improvement in handling multiplication.",309.37,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12099v1_Large language models struggle with ethnographic t.pdf,Large Language Models Struggle with Ethnographic Text Annotation,"['Leonardo S. Goodall†', 'Dor Shilton†', 'Daniel Austin Mullins', 'Harvey Whitehouse']","Large language models (LLMs) have shown promise for automated text annotation, but their performance on ethnographic texts is limited. The authors evaluated 7 state-of-the-art LLMs on their ability to annotate 121 ritual features across 567 ethnographic excerpts. Performance was below levels required for reliable automated annotation, especially for longer texts, features requiring ordinal distinctions, and ambiguous constructs. Human inter-coder reliability set an approximate ceiling on LLM accuracy, and even on features where humans reliably agreed, models fell short of human performance. The findings suggest that LLMs cannot yet substitute for human expertise in ethnographic annotation.",314.16,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12104v1_Powerful Training-Free Membership Inference Agains.pdf,Powerful Training-Free Membership Inference Against Autoregressive Language Models,"['David Ilić', 'David Stanojević', 'Kostadin Cvejoski']","Fine-tuned language models pose significant privacy risks, as they may memorize and expose sensitive training data. Membership inference attacks (MIAs) provide a principled framework for auditing these risks, yet existing methods achieve limited detection rates, particularly at low false-positive thresholds. The paper presents EZ-MIA, a membership inference attack that exploits the observation that memorization manifests most strongly at error positions, specifically tokens where the model predicts incorrectly yet still shows elevated probability for training examples. The Error Zone (EZ) score measures the directional imbalance of probability shifts at error positions relative to a pretrained reference model. This attack requires only two forward passes per query and no model training of any kind. On WikiText with GPT-2, EZ-MIA achieves 3.8× higher detection than the previous state-of-the-art under identical conditions (66.3% versus 17.5% true positive rate at 1% false positive rate), with near-perfect discrimination (AUC 0.98). At the stringent 0.1% FPR threshold critical for real-world auditing, EZ-MIA achieves 8× higher detection than prior work (14.0% versus 1.8%), requiring no reference model training. These gains extend to larger architectures: on AG News with Llama-2-7B, EZ-MIA achieves 3× higher detection (46.7% versus 15.8% TPR at 1% FPR). These results establish that privacy risks of fine-tuned language models are substantially greater than previously understood, with implications for both privacy auditing and deployment decisions. Code is available at https://github.com/JetBrains-Research/ez-mia.",313.5,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12124v1_SynQP A Framework and Metrics for Evaluating the Q.pdf,SYNQP: A FRAMEWORK AND METRICS FOR EVALUATING THE QUALITY AND PRIVACY RISK OF SYNTHETIC DATA,"['Bing Hu', 'Yixin Li', 'Asma Bahamyirou', 'Helen Chen']","The use of synthetic data in health applications raises privacy concerns, yet the lack of open frameworks for privacy evaluations has slowed its adoption. A major challenge is the absence of accessible benchmark datasets for evaluating privacy risks, due to difficulties in acquiring sensitive data. To address this, we introduce SYNQP, an open framework for benchmarking privacy in synthetic data generation (SDG) using simulated sensitive data, ensuring that original data remains confidential. We also highlight the need for privacy metrics that fairly account for the probabilistic nature of machine learning models. As a demonstration, we use SYNQP to benchmark CTGAN and propose a new identity disclosure risk metric that offers a more accurate estimation of privacy risks compared to existing approaches. Our work provides a critical tool for improving the transparency and reliability of privacy evaluations, enabling safer use of synthetic data in health-related applications.",310.41,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12126v1_UniMo Unified Motion Generation and Understanding .pdf,UniMo: Unified Motion Generation and Understanding with Chain of Thought,"['Guocun Wang', 'Kenkun Liu', 'Jing Lin', 'Guorui Song', 'Jian Li', 'Xiaoguang Han']","Existing 3D human motion generation and understanding methods often exhibit limited interpretability, restricting effective mutual enhancement between these inherently related tasks. UniMo, a novel framework, integrates motion-language information and interpretable chain of thought reasoning into the large language model via supervised fine-tuning. It also introduces reinforcement learning with Group Relative Policy Optimization as a post-training strategy to optimize over groups of tokens and enforce structural correctness and semantic alignment, mitigating cumulative errors in motion token prediction. Extensive experiments demonstrate that UniMo significantly outperforms existing unified and task-specific models, achieving state-of-the-art performance in both motion generation and understanding.",312.42,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12132v1_Bengali Text Classification An Evaluation of Large.pdf,Bengali Text Classification: An Evaluation of Large Language Model Approaches,"['Md Mahmudul Hoque∗', 'Md Mehedi Hassain', 'Md Hojaifa Tanvir', 'Rahul Nandy']","Bengali text classification is a significant task in natural language processing (NLP), where text is categorized into predefined labels. Unlike English, Bengali faces challenges due to the lack of extensive annotated datasets and pre-trained language models. This study explores the effectiveness of large language models (LLMs) in classifying Bengali newspaper articles. Three instruction-tuned LLMs—LLaMA 3.1 8B Instruct, LLaMA 3.2 3B Instruct, and Qwen 2.5 7B Instruct—were evaluated for this task under the same classification framework. Among the evaluated models, Qwen 2.5 achieved the highest classification accuracy of 72%, showing particular strength in the 'Sports' category. In comparison, LLaMA 3.1 and LLaMA 3.2 attained accuracies of 53% and 56%, respectively. The findings highlight the effectiveness of LLMs in Bengali text classification, despite the scarcity of resources for Bengali NLP. Future research will focus on exploring additional models, addressing class imbalance issues, and refining fine-tuning approaches to improve classification performance.",311.15,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12134v1_Human-Human-AI Triadic Programming Uncovering the .pdf,Human-Human-AI Triadic Programming: Uncovering the Role of AI Agent and the Value of Human Partner in Collaborative Learning,"['Taufiq Daryanto', 'Xiaohan Ding', 'Kaike Ping', 'Lance T. Wilhelm', 'Yan Chen', 'Chris Brown', 'Eugenia H. Rho']","As AI assistance becomes embedded in programming practice, researchers have increasingly examined how these systems help learners generate code and work more efficiently. However, these studies often position AI as a replacement for human collaboration and overlook the social and learning-oriented aspects that emerge in collaborative programming. Our work introduces human-human-AI (HHAI) triadic programming, where an AI agent serves as an additional collaborator rather than a substitute for a human partner. Through a within-subjects study with 20 participants, we show that this approach can enhance learning outcomes and preserve the social and pedagogical benefits of collaboration.",316.14,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12138v1_DriveSafe A Hierarchical Risk Taxonomy for Safety-.pdf,DriveSafe: A Hierarchical Risk Taxonomy for Safety-Critical LLM-Based Driving Assistants,"['Abhishek Kumar', 'Riya Tapwal', 'Carsten Maple']","Large Language Models (LLMs) are increasingly integrated into vehicle-based digital assistants, where unsafe, ambiguous, or legally incorrect responses can lead to serious safety, ethical, and regulatory consequences. Despite growing interest in LLM safety, existing taxonomies and evaluation frameworks remain general-purpose and fail to capture domain-specific risks. This paper introduces DriveSafe, a hierarchical, four-level risk taxonomy designed to systematically characterize safety-critical failure modes of LLM-based driving assistants. The taxonomy comprises 129 fine-grained atomic risk categories spanning technical, legal, societal, and ethical dimensions, grounded in real-world driving regulations and safety principles and reviewed by domain experts. The authors evaluate the refusal behavior of six widely deployed LLMs and find that these models often fail to appropriately refuse unsafe or non-compliant driving-related queries, underscoring the limitations of general-purpose safety alignment in driving contexts.",309.51,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12141v1_TIDE A Trace-Informed Depth-First Exploration for .pdf,TIDE: A Trace-Informed Depth-First Exploration for Planning with Temporally Extended Goals,"['Yuliia Suprun', 'Khen Elimelech', 'Lydia E. Kavraki', 'Moshe Y. Vardi']","TIDE is a novel approach for planning with temporally extended goals (TEGs) that decomposes the problem into a sequence of smaller, manageable reach-avoid subproblems. It uses cost-driven heuristics to guide exploration and an adaptive backtracking mechanism to recover from failed plans. Experimental results demonstrate that TIDE achieves promising performance and is a valuable addition to the portfolio of planning methods for TEGs.",312.51,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12147v1_Segment and Matte Anything in a Unified Model.pdf,Segment And Matte Anything in a Unified Model,"['Zezhong Fan*', 'Xiaohan Li*', 'Topojoy Biswas', 'Kaushiki Nag', 'Kannan Achan']","This paper introduces Segment And Matte Anything (SAMA), a lightweight extension of Segment Anything (SAM) that delivers high-quality interactive image segmentation and matting with minimal extra parameters. The Multi-View Localization Encoder (MVLE) captures detailed features from local views, while the Localization Adapter (Local-Adapter) refines mask outputs by recovering subtle boundary details. Two prediction heads are incorporated into the architecture to generate segmentation and matting masks simultaneously. Trained on a diverse dataset, SAMA achieves state-of-the-art performance across multiple segmentation and matting benchmarks, showcasing its adaptability and effectiveness in a wide range of downstream tasks.",309.68,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12150v1_Enhanced Diagnostic Performance via Large-Resoluti.pdf,Enhanced Diagnostic Performance via Large-Resolution Inference Optimization for Pathology Foundation Models,"['Mengxuan Hu∗', 'Zihan Guan⋆,†', 'John Kang', 'Sheng Li‡', 'Zhongliang Zhou‡']","Despite their strong performance on tasks such as ROI classification and segmentation, many pathology foundation models are constrained by a specific input size, creating inefficiencies when applied to whole-slide images (WSIs). This paper proposes an efficient inference strategy that sparsifies attention using spatially aware neighboring blocks and filters out non-informative tokens through global attention scores. This design reduces GPU memory and runtime during high-resolution WSI inference while preserving and even improving downstream performance, enabling inference at higher resolutions under the same GPU budget. Experimental results show up to a 7.67% improvement in ROI classification.",311.43,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12186v1_Aletheia What Makes RLVR For Code Verifiers Tick.pdf,Aletheia: What Makes RLVR For Code Verifiers Tick?,"['Vatsal Venkatkrishna', 'Indraneil Paul', 'Iryna Gurevych']","Aletheia is a controlled testbed that enables execution-grounded evaluation of code verifiers' robustness across disparate policy models and covariate shifts. The authors examine the components of the RLVR-based verifier training recipe, including intermediate thinking traces, learning from negative samples, and on-policy training. They find that while RLVR is optimal, there are opportunities to simplify the recipe. Particularly, on-policy learning stands out as the key component at small verifier sizes, and thinking-based training emerges as the most important component at larger scales.",308.15,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12205v1_Do Neural Codecs Generalize A Controlled Study Acr.pdf,Neural Codecs Generalize? A Controlled Study Across Unseen Languages and Non-Speech Tasks,"['Shih-Heng Wang', 'Jiatong Shi', 'Jinchuan Tian', 'Haibin Wu', 'Shinji Watanabe']","This paper investigates three crucial aspects of Neural Audio Codecs (NACs) generalization capabilities: (i) Can NACs generalize to unseen languages during pre-training, (ii) Can speech-only pre-trained NACs effectively generalize to non-speech tasks, and (iii) Will incorporating non-speech pre-training data boost performance on both speech and non-speech tasks? The authors train NACs from scratch with controlled configurations and curated pre-trained data for fair comparisons. They comprehensively evaluate NACs performance on signal reconstruction quality and downstream applications using 11 metrics. The findings show that NACs can generalize to unseen languages during pre-training, speech-only pre-trained NACs degrade on non-speech tasks, and including non-speech data during pre-training improves performance on non-speech tasks while maintaining comparable performance on speech tasks.",313.68,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12212v1_Speculative Sampling with Reinforcement Learning.pdf,Speculative Sampling with Reinforcement Learning,"['Chenan Wang', 'Daniel H. Shi', 'Haipeng Chen']","Inference time latency remains an open challenge for real-world applications of large language models (LLMs). State-of-the-art speculative sampling (SpS) methods, like EAGLE-3, use tree-based drafting to explore multiple candidate continuations in parallel. However, the hyperparameters controlling the tree structure are static, limiting flexibility and efficiency. This paper introduces Reinforcement Learning for Speculative Sampling (Re-SpS), the first RL-based framework for draft tree hyperparameter optimization. Re-SpS dynamically adjusts draft tree hyperparameters in real-time, learning context-aware policies that maximize generation speed by balancing speculative aggression with computational overhead. It leverages efficient state representations from target model hidden states and introduces multi-step action persistence for better context modeling. Evaluation results across five diverse benchmarks demonstrate consistent improvements over the SOTA method EAGLE-3, achieving up to 5.45× speedup over the backbone LLM and up to 1.12× speedup compared to EAGLE-3 across five diverse benchmarks, with no loss in output fidelity.",311.06,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12215v1_Wavelet-Driven Masked Multiscale Reconstruction fo.pdf,Wavelet-Driven Masked Multiscale Reconstruction for PPG Foundation Models,"['Megha Thukral*', 'Cyrus Tanade', 'Simon A. Lee', 'Juhyeon Lee', 'Hao Zhou', 'Keum San Chun', 'Migyeong Gwak', 'Viswam Nathan', 'Md Mahbubur Rahman', 'Li Zhu', 'Mehrab Bin Morshed', 'Subramaniam Venkatraman', 'Sharanya Arcot Desai']","Wearable foundation models have the potential to transform digital health by learning transferable representations from large-scale biosignals. This paper introduces Masked Multiscale Reconstruction (MMR) for PPG representation learning, a self-supervised pretraining framework that explicitly learns from hierarchical time–frequency scales of PPG data. The pretraining task is designed to reconstruct randomly masked out coefficients from a wavelet-based multiresolution decomposition of PPG signals. The model is pre-trained with ∼17 million unlabeled 10-second PPG segments from ∼32,000 smartwatch users. On 17 of 19 diverse health-related tasks, MMR trained on large-scale wearable PPG data improves over or matches state-of-the-art open-source PPG foundation models, time-series foundation models, and other self-supervised baselines. Extensive analysis of learned embeddings and systematic ablations underscore the value of wavelet-based representations, showing they capture robust and physiologically-grounded features. These results highlight the potential of MMR as a step toward generalizable PPG foundation models.",310.6,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12224v1_Where It Moves It Matters Referring Surgical Instr.pdf,"Where It Moves, It Matters: Referring Surgical Instrument Segmentation via Motion","['Meng Wei', 'Kun Yuan', 'Shi Li', 'Yue Zhou', 'Long Bai', 'Nassir Navab', 'Hongliang Ren', 'Hong Joo Lee', 'Tom Vercauteren', 'Nicolas Padoy']","Enabling intuitive, language-driven interaction with surgical scenes is a critical step toward intelligent operating rooms and autonomous surgical robotic assistance. However, the task of referring segmentation, localizing surgical instruments based on natural language descriptions, remains underexplored in surgical videos, with existing approaches struggling to generalize due to reliance on static visual cues and predefined instrument names. In this work, we introduce SurgRef, a novel motion-guided framework that grounds free-form language expressions in instrument motion, capturing how tools move and interact across time, rather than what they look like. This allows models to understand and segment instruments even under occlusion, ambiguity, or unfamiliar terminology. To train and evaluate SurgRef, we present Ref-IMotion, a diverse, multi-institutional video dataset with dense spatiotemporal masks and rich motion-centric expressions. SurgRef achieves state-of-the-art accuracy and generalization across surgical procedures, setting a new benchmark for robust, language-driven surgical video segmentation.",313.6,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12234v1_Proc3D Procedural 3D Generation and Parametric Edi.pdf,Proc3D: Procedural 3D Generation and Parametric Editing of 3D Shapes with Large Language Models,"['Fadlullah Raji', 'Stefano Petrangeli', 'Matheus Gadelha', 'Yu Shen', 'Uttaran Bhattacharya', 'Gang Wu']","Proc3D is a system designed to generate editable 3D models while enabling real-time modifications. It introduces procedural compact graph (PCG), a graph representation of 3D models that exposes key parameters for intuitive manual adjustments and real-time, automated modifications through natural language prompts using Large Language Models (LLMs). The system demonstrates its capabilities using two generative approaches: GPT-4o with in-context learning (ICL) and a fine-tuned LLAMA-3 model. Experimental results show that Proc3D outperforms existing methods in editing efficiency, achieving more than 400× speedup over conventional approaches that require full regeneration for each modification, and improves ULIP scores by 28%.",313.44,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12242v1_Optimal Power Allocation and Sub-Optimal Channel A.pdf,OPTIMALPOWERALLOCATION ANDSUB-OPTIMALCHANNELASSIGNMENT FORDOWNLINKNOMA SYSTEMUSINGDEEPREINFORCEMENTLEARNING,"['WooSeok Kim', 'Jeonghoon Lee', 'Sangho Kim', 'Taesun An', 'WonMin Lee', 'Dowon Kim', 'Kyungseop Shin']","In recent years, Non-Orthogonal Multiple Access (NOMA) system has emerged as a promising candidate for multiple access frameworks due to the evolution of deep machine learning, trying to incorporate deep machine learning into the NOMA system. The main motivation for such active studies is the growing need to optimize the utilization of network resources as the expansion of the internet of things (IoT) caused a scarcity of network resources. The NOMA addresses this need by power multiplexing, allowing multiple users to access the network simultaneously. Nevertheless, the NOMA system has few limitations. Several works have proposed to mitigate this, including the optimization of power allocation known as joint resource allocation (JRA) method, and integration of the JRA method and deep reinforcement learning (JRA-DRL). Despite this, the channel assignment problem remains unclear and requires further investigation. In this paper, we propose a deep reinforcement learning framework incorporating replay memory with an on-policy algorithm, allocating network resources in a NOMA system to generalize the learning. Also, we provide extensive simulations to evaluate the effects of varying the learning rate, batch size, type of model, and the number of features in the state.",301.55,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12243v1_Less is More Label-Guided Summarization of Procedu.pdf,Less is More: Label-Guided Summarization of Procedural and Instructional Videos,"['Shreya Rajpal', 'Michal Golovanesky', 'Carsten Eickhoff']","This paper proposes a three-stage framework, PRISM, for producing semantically grounded video summaries. PRISM combines adaptive visual sampling, label-driven keyframe anchoring, and contextual validation using a large language model (LLM). The method ensures that selected frames reflect meaningful and procedural transitions while filtering out generic or hallucinated content, resulting in contextually coherent summaries across both domain-specific and instructional videos. The authors evaluate their method on instructional and activity datasets, using reference summaries for instructional videos. Despite sampling fewer than 5% of the original frames, their summaries retain 84% semantic content while improving over baselines by as much as 33%. The approach generalizes across procedural and domain-specific video tasks, achieving strong performance with both semantic alignment and precision.",315.28,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12247v1_Plan Verify and Fill A Structured Parallel Decodin.pdf,"Plan, Verify and Fill: A Structured Parallel Decoding Approach for Diffusion Language Models","['Miao Li * 1', 'Hanyang Jiang * 1', 'Sikai Cheng 1', 'Hengyu Fu 2', 'Yuhang Cai2', 'Baihe Huang 2', 'Tinghan Ye1', 'Xuanzhou Chen 1', 'Pascal Van Hentenryck1']","Diffusion Language Models (DLMs) present a promising non-sequential paradigm for text generation, distinct from standard autoregressive (AR) approaches. However, current decoding strategies often adopt a reactive stance, underutilizing the global bidirectional context to dictate global trajectories. To address this, the authors propose Plan-Verify-Fill (PVF), a training-free paradigm that grounds planning via quantitative validation. PVF actively constructs a hierarchical skeleton by prioritizing high-leverage semantic anchors and employs a verification protocol to operationalize pragmatic structural stopping where further deliberation yields diminishing returns. Extensive evaluations on LLaDA-8B-Instruct and Dream-7B-Instruct demonstrate that PVF reduces the Number of Function Evaluations (NFE) by up to 65% compared to confidence-based parallel decoding across benchmark datasets, unlocking superior efficiency without compromising accuracy.",309.32,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12248v1_AQUA-Bench Beyond Finding Answers to Knowing When .pdf,AQUA-BENCH: BEYOND FINDING ANSWERS TO KNOWING WHEN THERE ARE NONE IN AUDIO QUESTION ANSWERING,"['Chun-Yi Kuan', 'Hung-yi Lee']","Recent advances in audio-aware large language models have shown strong performance on audio question answering. However, existing benchmarks mainly cover answerable questions and overlook the challenge of unanswerable ones, where no reliable answer can be inferred from the audio. To address this gap, we present AQUA-Bench, a benchmark for Audio Question Unanswerability Assessment. It systematically evaluates three scenarios: Absent Answer Detection, Incompatible Answer Set Detection, and Incompatible Audio Question Detection. By assessing these cases, AQUA-Bench offers a rigorous measure of model reliability and promotes the development of audio-language systems that are more robust and trustworthy. Our experiments suggest that while models excel on standard answerable tasks, they often face notable challenges with unanswerable ones, pointing to a blind spot in current audio-language understanding.",309.64,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12249v1_An Innovative Framework for Breast Cancer Detectio.pdf,"An Innovative Framework for Breast Cancer Detection Using Pyramid Adaptive Atrous Convolution, Transformer Integration, and Multi-Scale Feature Fusion","['Ehsan Sadeghi Pour', 'Mahdi Esmaeili', 'Morteza Romoozi']","This thesis presents an innovative framework for detecting malignant masses in mammographic images by integrating Pyramid Adaptive Atrous Convolution (PAAC) and Transformer architectures. The proposed approach utilizes Multi-Scale Feature Fusion to enhance the extraction of features from benign and malignant tissues and combines Dice Loss and Focal Loss functions to improve the model's learning process, effectively reducing errors in binary breast cancer classification and achieving high accuracy and efficiency. The study leverages a comprehensive dataset of breast cancer images from INbreast, MIAS, and DDSM, preprocessed through data augmentation and contrast enhancement and resized to 227×227 pixels for model training. The Transformer's ability to manage long-range dependencies with Self-Attention mechanisms is leveraged to achieve high accuracy in detecting cancerous masses, outperforming foundational models such as BreastNet, DeepMammo, Multi-Scale CNN, Swin-Unet, and SegFormer. The final evaluation results for the proposed model include an accuracy of 98.5%, sensitivity of 97.8%, specificity of 96.3%, F1-score of 98.2%, and overall precision of 97.9%. These metrics demonstrate a significant improvement over traditional methods and confirm the model's effectiveness in identifying cancerous masses in complex scenarios and large datasets. This model shows potential as a reliable and efficient tool for breast cancer diagnosis and can be effectively integrated into medical diagnostic systems.",312.07,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12256v1_Improving Large Molecular Language Model via Relat.pdf,Improving Large Molecular Language Model via Relation-aware Multimodal Collaboration,"['Jinyoung Park', 'Minseong Bae', 'Jeehye Na', 'Hyunwoo J. Kim']","Large language models (LLMs) have demonstrated their instruction-following capabilities and achieved powerful performance on various tasks. Inspired by their success, recent works in the molecular domain have led to the development of large molecular language models (LMLMs) that integrate 1D molecular strings or 2D molecular graphs into the language models. However, existing LMLMs often suffer from hallucination and limited robustness, largely due to inadequate integration of diverse molecular modalities such as 1D sequences, 2D molecular graphs, and 3D conformations. To address these limitations, the authors propose CoLLaMo, a large language model-based molecular assistant equipped with a multi-level molecular modality-collaborative projector. The relation-aware modality-collaborative attention mechanism in the projector facilitates fine-grained and relation-guided information exchange between atoms by incorporating 2D structural and 3D spatial relations. Furthermore, the authors present a molecule-centric new automatic measurement, including a hallucination assessment metric and GPT-based caption quality evaluation to address the limitations of token-based generic evaluation metrics (i.e., BLEU) widely used in assessing molecular comprehension of LMLMs. Our extensive experiments demonstrate that our CoLLaMo enhances the molecular modality generalization capabilities of LMLMs, achieving the best performance on multiple tasks, including molecule captioning, computed property QA, descriptive property QA, motif counting, and IUPAC name prediction.",310.47,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12257v1_Soft Shadow Diffusion SSD Physics-inspired Learnin.pdf,Soft Shadow Diffusion (SSD): Physics-inspired Learning for 3D Computational Periscopy,"['Fadlullah Raji', 'John Murray Bruce']","Conventional imaging requires a line of sight to create accurate visual representations of a scene. In certain circumstances, obtaining a suitable line of sight may be impractical, dangerous, or even impossible. Non-line-of-sight (NLOS) imaging addresses this challenge by reconstructing the scene from indirect measurements. Recently, passive NLOS methods that use an ordinary photograph of the subtle shadow cast onto a visible wall by the hidden scene have gained interest. These methods are currently limited to 1D or low-resolution 2D color imaging or to localizing a hidden object whose shape is approximately known. Here, we generalize this class of methods and demonstrate a 3D reconstruction of a hidden scene from an ordinary NLOS photograph. To achieve this, we propose a novel reformulation of the light transport model that conveniently decomposes the hidden scene into light-occluding and non-light-occluding components to yield a separable non-linear least squares (SNLLS) inverse problem. We develop two solutions: a gradient-based optimization method and a physics-inspired neural network approach, which we call Soft Shadow diffusion (SSD). Despite the challenging ill-conditioned inverse problem encountered here, our approaches are effective on numerous 3D scenes in real experimental scenarios. Moreover, SSD is trained in simulation but generalizes well to unseen classes in simulation and real-world NLOS scenes. SSD also shows surprising robustness to noise and ambient illumination.",310.14,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12259v1_FutureX-Pro Extending Future Prediction to High-Va.pdf,FutureX-Pro: Extending Future Prediction to High-Value Vertical Domains,"['ByteDance', 'Hong Kong University of Science and Technology', 'Georgia Institute of Technology', 'Stanford University', 'Princeton University']","Building upon FutureX, which established a live benchmark for general-purpose future prediction, this report introduces FutureX-Pro, including FutureX-Finance, FutureX-Retail, FutureX-PublicHealth, FutureX-NaturalDisaster, and FutureX-Search. These together form a specialized framework extending agentic future prediction to high-value vertical domains. While generalist agents demonstrate proficiency in open-domain search, their reliability in capital-intensive and safety-critical sectors remains under-explored. FutureX-Pro targets four economically and socially pivotal verticals: Finance, Retail, Public Health, and Natural Disaster. We benchmark agentic Large Language Models (LLMs) on entry-level yet foundational prediction tasks—ranging from forecasting market indicators and supply chain demands to tracking epidemic trends and natural disasters. By adapting the contamination-free, live-evaluation pipeline of FutureX, we assess whether current State-of-the-Art (SOTA) agentic LLMs possess the domain grounding necessary for industrial deployment. Our findings reveal the performance gap between generalist reasoning and the precision required for high-value vertical applications.",310.67,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12260v1_Docs2Synth A Synthetic Data Trained Retriever Fram.pdf,Docs2Synth: A Synthetic Data Trained Retriever Framework for Scanned Visually Rich Documents Understanding,"['Yihao Ding', 'Qiang Sun', 'Puzhen Wu', 'Sirui Li', 'Siwen Luo', 'Wei Liu']","Document understanding (VRDU) in regulated domains is challenging due to the presence of sensitive, evolving, and domain-specific knowledge in scanned documents. This paper introduces Docs2Synth, a synthetic-supervision framework that enables retrieval-guided inference for private and low-resource domains. Docs2Synth automatically processes raw document collections, generates and verifies diverse QA pairs via an agent-based system, and trains a lightweight visual retriever to extract domain-relevant evidence. During inference, the retriever collaborates with an MLLM through an iterative retrieval-generation loop, reducing hallucination and improving response consistency. The framework is delivered as an easy-to-use Python package, enabling plug-and-play deployment across diverse real-world scenarios. Experiments on multiple VRDU benchmarks show that Docs2Synth substantially enhances grounding and domain generalization without requiring human annotations.",313.32,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12263v1_Multimodal Generative Engine Optimization Rank Man.pdf,Multimodal Generative Engine Optimization: Rank Manipulation for Vision–Language Model Rankers,"['Yixuan Du', 'Chenxiao Yu', 'Haoyan Xu', 'Ziyi Wang', 'Yue Zhao', 'Xiyang Hu*']","This paper uncovers a critical vulnerability in Vision-Language Models (VLMs) used in modern retrieval and recommendation systems. VLMs are rapidly replacing unimodal encoders and are robust against adversarial manipulation in competitive ranking scenarios. The authors present Multimodal Generative Engine Optimization (MGEO), a novel adversarial framework that enables a malicious actor to unfairly promote a target product by jointly optimizing imperceptible image perturbations and fluent textual suffixes. Unlike existing attacks that treat modalities in isolation, MGEO employs an alternating gradient-based optimization strategy to exploit the deep cross-modal coupling within the VLM. Extensive experiments on real-world datasets using state-of-the-art models demonstrate that the coordinated attack significantly outperforms text-only and image-only baselines, revealing that multimodal synergy can be weaponized to compromise the integrity of search rankings without triggering conventional content filters.",310.25,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12269v1_Simulated Annealing Enhances Theory-of-Mind Reason.pdf,Simulated Annealing Enhances Theory-of-Mind Reasoning in Autoregressive Language Models,"['Xucong Hu', 'Jian-Qiao Zhu']","Autoregressive language models are criticized for optimizing surface plausibility rather than maintaining correct latent-state representations. This paper shows that strong Theory-of-Mind (ToM) capability can be recovered directly from the base model without additional weight updates or verifications. The authors build on recent power-sampling methods that use Markov chain Monte Carlo to sample from sharpened sequence-level probability distributions. They find that incorporating annealing, where the tempered distribution is gradually shifted from high to low temperature, substantially improves ToM performance over fixed-temperature power sampling. These results suggest that sampling-based optimization can extract latent capabilities from language models without retraining.",309.9,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12276v1_Predictive Prototyping Evaluating Design Concepts .pdf,PREDICTIVE PROTOTYPING: EVALUATING DESIGN CONCEPTS WITH GPT,"['Hilsann Yong', 'ASME']","The design-build-test cycle is critical to realize innovative solutions. This cycle enables a team to evaluate a concept based on performance and iteration to enhance the design. However, testing is often time consuming and costly. While physics-based simulation, and strategic prototyping can substantially lower cost there are still significant investments required or potential limits in test scope until an integrated prototype can be produced. Recently, generative pretrained transformers (GPTs), have demonstrated strong performance in many high level reasoning and analysis tasks. Large language models (LLMs) or GPTs in particular, may have the potential to streamline the iteration cycle of generating meaningful designs insights more efficiently. This work explores whether a GPT can accurately predict information that would be gained during a prototyping effort such as cost, performance, and perceived usability. A novel approach is introduced to emulate design feedback using retrieval augmented generation (RAG) in conjunction with a GPT, specifically OpenAI’s GPT-4o. This design method aims to bridge the gap between conceptual designs and physical. The method used in this paper leverages prototyping data scraped from the 'Instructables.com' database; thereby increasing the availability of relevant prototyping data to the model. Two efforts are reported. The first is a controlled study where predictions are made about a series of diverse designs. The GPT, and human designers were provided design sketches and asked to predict cost, performance, and usability. Performance of each condition is then compared to ground-truth physical prototyping results. A second effort reports on an experimental application, in which a physical prototype was produced based on recommendations from the GPT-RAG model. The performance of this prototype is compared against a baseline, commercial model, and a topology optimized model. The results indicate that the GPT-RAG predictions are more accurate than individual human or crowd estimations of cost and performance, while offering similar insights in terms of usability; the GPT-RAG inspired prototype also outperformed the commercial, and topology optimized prototypes. Interestingly this study also identified that repeatedly querying for cost and performance estimations from the GPT-RAG, and averaging the responses provided significantly more accurate results, highlighting that LLMs can emulate crowd behaviour, exhibiting the law of large numbers.",313.36,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12282v1_CytoCLIP Learning Cytoarchitectural Characteristic.pdf,CytoCLIP: Learning Cytoarchitectural Characteristics in Developing Human Brain Using Contrastive Language Image Pre-Training,"['Pralaypati Ta', 'Sriram Venkatesaperumal', 'Keerthi Ram', 'Mohanasankar Sivaprakasam']","The functions of different regions of the human brain are closely linked to their distinct cytoarchitecture, which is defined by the spatial arrangement and morphology of the cells. Identifying brain regions by their cytoarchitecture enables various scientific analyses of the brain. However, delineating these areas manually in brain histological sections is time-consuming and requires specialized knowledge. An automated approach is necessary to minimize the effort needed from human experts. To address this, the authors propose CytoCLIP, a suite of vision-language models derived from pre-trained Contrastive Language-Image Pre-Training (CLIP) frameworks to learn joint visual-text representations of brain cytoarchitecture. CytoCLIP comprises two model variants: one trained using low-resolution whole-region images to understand the overall cytoarchitectural pattern of an area, and the other trained on high-resolution image tiles for detailed cellular-level representation. The training dataset is created from NISSL-stained histological sections of developing fetal brains of different gestational weeks. It includes 86 distinct regions for low-resolution images and 384 brain regions for high-resolution tiles. The model's understanding of the cytoarchitecture and generalization ability are evaluated using region classification and cross-modal retrieval tasks. Experimental results demonstrate that CytoCLIP outperforms existing methods, achieving an F1 score of 0.87 for whole-region classification and 0.91 for high-resolution image tile classification.",312.07,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12286v1_Conversational Context Classification A Representa.pdf,Conversational Context Classification: A Representation Engineering Approach,['Jonathan Pan'],"The increasing prevalence of Large Language Models (LLMs) demands effective safeguards for their operation, particularly concerning their tendency to generate 'out-of-context' responses. A key challenge is accurately detecting when LLMs stray from expected conversational norms, manifesting as topic shifts, factual inaccuracies, or outright hallucinations. Traditional anomaly detection struggles to directly apply within contextual semantics. This paper outlines the use of Representation Engineering (RepE) and One-Class Support Vector Machine (OCSVM) to identify subspaces within the internal states of LLMs that represent a specific context. By training OCSVM on in-context examples, a robust boundary is established within the LLM's hidden state latent space. The approach involves identifying the optimal layers within the LLM's internal state subspaces that strongly associate with the context of interest. Evaluation results showed promising results in identifying the subspace for a specific context, contributing to better interpreting LLMs and detecting in or out of context conversation threads for AI safety.",314.78,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12288v1_TimeGMM Single-Pass Probabilistic Forecasting via .pdf,TIMEGMM: SINGLE-PASS PROBABILISTIC FORECASTING VIA ADAPTIVE GAUSSIAN MIXTURE MODELS WITH REVERSIBLE NORMALIZATION,"['Lei Liu', 'Tengyuan Liu', 'Hongwei Zhao', 'Jiahui Huang', 'Ruibo Guo', 'Bin Li']","Probabilistic time series forecasting is crucial for quantifying future uncertainty. Existing methods often rely on computationally expensive sampling or restrictive parametric assumptions to characterize future distributions, which limits predictive performance and introduces distributional mismatch. This paper presents TimeGMM, a novel probabilistic forecasting framework based on Gaussian Mixture Models (GMM) that captures complex future distributions in a single forward pass. A key component is GMM-adapted Reversible Instance Normalization (GRIN), a novel module designed to dynamically adapt to temporal-probabilistic distribution shifts. The framework integrates a dedicated Temporal Encoder (TE-Module) with a Conditional Temporal-Probabilistic Decoder (CTPD-Module) to jointly capture temporal dependencies and mixture distribution parameters. Extensive experiments demonstrate that TimeGMM consistently outperforms state-of-the-art methods, achieving maximum improvements of 22.48% in CRPS and 21.23% in NMAE.",313.72,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12294v1_ToolPRMBench Evaluating and Advancing Process Rewa.pdf,ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents,"['Dawei Li', 'Yuguang Yao', 'Zhen Tan', 'Huan Liu', 'Ruocheng Guo']","Reward-guided search methods have demonstrated strong potential in enhancing tool-using agents by effectively guiding sampling and exploration over complex action spaces. However, there is a lack of systematic and reliable evaluation benchmarks for PRMs in tool-using settings. This paper introduces ToolPRMBench, a large-scale benchmark specifically designed to evaluate PRMs for tool-using agents. ToolPRMBench is built on top of several representative tool-using benchmarks and converts agent trajectories into step-level test cases. Each case contains the interaction history, a correct action, a plausible but incorrect alternative, and relevant tool metadata. Offline and online sampling are used to isolate and capture failures, respectively. A multi-LLM verification pipeline is proposed to reduce label noise and ensure data quality. Extensive experiments across large language models, general PRMs, and tool-specialized PRMs on ToolPRMBench reveal clear differences in PRM effectiveness and highlight the potential of specialized PRMs for tool-using.",311.89,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12304v1_A Two-Stage Globally-Diverse Adversarial Attack fo.pdf,A TWO-STAGE GLOBALLY-DIVERSE ADVERSARIAL ATTACK FOR VISION-LANGUAGE PRE-TRAINING MODELS,"['Wutao Chen', 'Huaqin Zou', 'Chen Wan', 'Lifeng Huang']","Vision-language pre-training (VLP) models are vulnerable to adversarial examples, particularly in black-box scenarios. Existing multimodal attacks often suffer from limited perturbation diversity and unstable multi-stage pipelines. To address these challenges, the authors propose 2S-GDA, a two-stage globally-diverse attack framework. The method introduces textual perturbations through a globally-diverse strategy and generates image-level perturbations using multi-scale resizing and block-shuffle rotation. Extensive experiments on VLP models demonstrate that 2S-GDA consistently improves attack success rates over state-of-the-art methods, with gains of up to 11.17% in black-box settings. The framework is modular and can be easily combined with existing methods to enhance adversarial transferability.",314.12,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12310v1_Survival is the Only Reward Sustainable Self-Train.pdf,Survival is the Only Reward: Sustainable Self-Training Through Environment-Mediated Selection,"['Jennifer Dodgson', 'Alfath Daryl Alhajir', 'Michael Joedhitya', 'Akira Rafhael Janson Pattirane', 'Surender Suresh Kumar', 'Joseph Lim', 'C.H. Peh', 'Adith Ramdas', 'Steven Zhang Zhexu']","This paper presents a proof-of-concept self-training system architecture that uses environmental viability to select behaviors, rather than rewards or external criteria. The system operates under real resource constraints and only propagates behaviors that persist and preserve future interaction. The environment does not provide semantic feedback or task-specific supervision, making selection purely through differential survival. Analysis shows that improvement arises through effective and repeatable strategies under consolidation and pruning, leading to meta-learning without explicit instruction. This work establishes that environment-grounded selection enables sustainable open-ended self-improvement, offering a viable path toward more robust and generalizable autonomous systems without human-curated data or complex reward shaping.",315.11,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12316v1_GazeFormer-MoE Context-Aware Gaze Estimation via C.pdf,GAZEFORMER-MOE: CONTEXT-AWARE GAZE ESTIMATION VIA CLIP AND MOE TRANSFORMER,"['Xinyuan Zhao', 'Xianrui Chen', 'Ahmad Chaddad']","This paper presents a semantics-modulated, multi-scale Transformer for 3D gaze estimation. The model conditions CLIP global features with learnable prototype banks (illumination, head pose, background, direction), fuses these prototype-enriched global vectors with CLIP patch tokens and high-resolution CNN tokens in a unified attention space, and replaces several FFN blocks with routed/shared Mixture of Experts (MoE) to increase conditional capacity. Evaluated on MPIIFaceGaze, EYEDIAP, Gaze360, and ETH-XGaze, the model achieves new state-of-the-art angular errors of 2.49°, 3.22°, 10.16°, and 1.44°, demonstrating up to a 64% relative improvement over previously reported results. The authors attribute gains to prototype conditioning, cross-scale fusion, MoE, and hyperparameters. The code is publicly available at https://github.com/AIPMLab/Gazeformer.",308.98,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12317v1_Explanova Automatically Discover Data Insights in .pdf,Explanova: Automatically Discover Data Insights in N×M Table via XAI Combined LLM Workflow,['Yiming Huang'],"Automation in data analysis has been a long-time pursuit. Current agentic LLM solutions show promising results, but they are expensive due to LLM consumption. The authors propose Explanova, an automatic LLM workflow that enables discovering data insights through explainable AI (XAI) paradigm. It focuses on single-feature statistic analysis, feature-to-feature relation statistic analysis, and feature modeling by all other features in one data table. The workflow is designed to explore all possible analytical items and is divided into three stages: Feature Preparation Stage, Feature Analysis Stage, and Model Evaluation Stage. The authors aim to enhance LLM-based automatic data science from the data analytics side by presetting a workflow.",309.18,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12318v1_Beyond Human Annotation Recent Advances in Data Ge.pdf,Beyond Human Annotation: Recent Advances in Data Generation Methods for Document Intelligence,"['DEHAO YING', 'Wuhan University, China', 'FENGCHANG YU', 'Wuhan University, China', 'HAIHUA CHEN', 'University of North Texas, United States', 'CHANGJIANG JIANG', 'Wuhan University, China', 'YURONG LI', 'Wuhan University, China', 'WEI LU', 'Wuhan University, China']","The advancement of Document Intelligence (DI) demands large-scale, high-quality training data, yet manual annotation remains a critical bottleneck. While data generation methods are evolving rapidly, existing surveys are constrained by fragmented focuses on single modalities or specific tasks, lacking a unified perspective aligned with real-world workflows. This survey establishes the first comprehensive technical map for data generation in DI, redefining it as supervisory signal production and introducing a novel taxonomy based on the availability of data and labels. The framework organizes methodologies into four resource-centric paradigms: Data Augmentation, Data Generation from Scratch, Automated Data Annotation, and Self-Supervised Signal Construction. A multi-level evaluation framework is established to integrate intrinsic quality and extrinsic utility, compiling performance gains across diverse DI benchmarks. By systematizing this fragmented field, data generation is positioned as the central engine for next-generation DI.",311.73,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12323v1_MARO Learning Stronger Reasoning from Social Inter.pdf,MARO: Learning Stronger Reasoning from Social Interaction,"['Yin Cai', 'Zhouhong Gu', 'JunTao Zhang', 'Ping Chen*']","This paper proposes MARO, a method that enables large language models (LLMs) to acquire stronger reasoning abilities by learning and practicing in multi-agent social environments. MARO addresses the sparse learning signal problem by decomposing final success or failure outcomes into each specific behavior during the interaction process, handles the uneven role distribution problem by balancing training sample weights of different roles, and addresses environmental instability issues by directly evaluating the utility of each behavior. Experimental results demonstrate that MARO not only achieves significant improvements in social reasoning capabilities but also that the abilities acquired through social simulation learning can effectively transfer to other tasks such as mathematical reasoning and instruction following. This reveals the tremendous potential of multi-agent social learning in enhancing the general reasoning capabilities of LLMs.",309.64,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12327v1_The Expert Validation Framework EVF Enabling Domai.pdf,The Expert Validation Framework (EVF): Enabling Domain Expert Control in AI Engineering,"['Lucas Gren', 'Felix Dobslaw']","Generative AI (GenAI) systems promise to transform knowledge work by automating a range of tasks, yet their deployment in enterprise settings remains hindered by the lack of systematic quality assurance mechanisms. The authors present an Expert Validation Framework (EVF) that places domain experts at the center of building software with GenAI components, enabling them to maintain authoritative control over system behavior through structured specification, testing, validation, and continuous monitoring processes. The framework addresses the critical gap between AI capabilities and organizational trust by establishing a rigorous, expert-driven methodology for ensuring quality across diverse GenAI applications. Through a four-stage implementation process encompassing specification, system creation, validation, and production monitoring, the framework enables organizations to leverage GenAI capabilities while maintaining expert oversight and quality standards.",309.82,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12330v1_IceWatch Forecasting Glacial Lake Outburst Floods .pdf,IceWatch: Forecasting Glacial Lake Outburst Floods (GLOFs) using Multimodal Deep Learning,"['Zuha Fatima', 'Muhammad Anser Sohaib', 'Muhammad Talha', 'Ayesha Kanwal', 'Sidra Sultana', 'Nazia Perwaiz']","Glacial Lake Outburst Floods (GLOFs) pose a serious threat in high mountain regions. IceWatch is a novel deep learning framework for GLOF prediction that incorporates both spatial and temporal perspectives. The vision component, RiskFlow, uses a CNN-based classifier to predict GLOF events based on the spatial patterns of snow, ice, and meltwater. The tabular counterpart, TerraFlow, models glacier velocity from NASA ITS_LIVE time series, while TempFlow forecasts near-surface temperature from MODIS LST records. These models are integrated via harmonized preprocessing and synchronization to enable multimodal, physics-informed GLOF prediction. This system ensures strong predictive performance, rapid data processing for real-time use, and robustness to noise and missing information. IceWatch paves the way for automatic, scalable GLOF warning systems and holds potential for integration with diverse sensor inputs and global glacier monitoring activities.",309.25,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12331v1_Efficient Privacy-Preserving Retrieval Augmented G.pdf,Efficient Privacy-Preserving Retrieval Augmented Generation with Distance-Preserving Encryption,"['Huanyi Ye', 'Jiale Guo', 'Ziyao Liu', 'Kwok-Yan Lam']","Retrieval-Augmented Generation (RAG) has emerged as a key technique for enhancing response quality of large language models (LLMs) without incurring high computational cost. It works by retrieving knowledge and fact from external databases, augmenting the prompt with the retrieved data, and enabling the LLM to generate more accurate responses. In traditional architectures, RAG services are provided by a single entity that hosts the dataset and issues queries within a trusted local environment. However, individuals or small organizations often lack the resources to maintain data storage servers, leading them to rely on outsourced, cloud-based storage for scalability. This dependence on untrusted third-party services introduces significant privacy risks, particularly when handling private and sensitive data. Embedding-based retrieval mechanisms, commonly used in RAG systems, are especially vulnerable to privacy leakage such as vector-to-text reconstruction attacks and structural leakage via vector analysis. Several privacy-preserving RAG techniques have been proposed to address such vulnerabilities; however, most existing approaches rely on partially homomorphic encryption, which incurs substantial computational overhead and limits their practicality in real-world deployments. To address these challenges, we propose an efficient privacy-preserving RAG framework (ppRAG) tailored for untrusted cloud environments that defends against vector-to-text attack, vector analysis, and query analysis. At its core, we propose Conditional Approximate Distance-Comparison-Preserving Symmetric Encryption (CAPRISE) that encrypts embeddings while still allowing the cloud to compute similarity between an encrypted query embedding and the encrypted database embeddings. CAPRISE preserves only the relative distance ordering between the encrypted query and each encrypted database embedding, without exposing inter-database distances, thereby enhancing both privacy and efficiency. To further mitigate query analysis risks, we introduce differential privacy by perturbing the query embedding prior to encryption, preventing the cloud from inferring sensitive patterns from query frequency. Experimental results show that ppRAG achieves efficient processing throughput, high retrieval accuracy, strong privacy guarantees, making it a practical solution for resource-constrained users seeking secure, cloud-augmented LLMs.",312.62,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12338v1_Actionable Advice from Reviews via Mixture of LoRA.pdf,Actionable Advice from Reviews via Mixture of LoRA Experts: A Two-LLM Pipeline for Issue Extraction and Business Recommendations,"['Kartikey Singh Bhandari', 'Manav Ganesh', 'Yashwant Viswanathan', 'Archit Agrawal', 'Dhruv Kumar', 'Pratik Narang']","Customer reviews contain detailed, domain-specific signals about service failures and user expectations, but converting this unstructured feedback into actionable business decisions remains difficult. This paper proposes a modular two-LLM framework where an Issue model extracts salient issues and assigns coarse themes, and an Advice model generates targeted operational fixes conditioned on the extracted issue representation. To enable specialization without expensive full fine-tuning, the Advice model is adapted using a mixture-of-LoRA experts strategy. The approach consistently outperforms prompting-only and single-adapter baselines, yielding higher actionability and specificity while retaining favorable efficiency-quality trade-offs.",309.39,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12341v1_Time-Continuous Modeling for Temporal Affective Pa.pdf,Time-Continuous Modeling for Temporal Affective Pattern Recognition in LLM’s,"['Rezky M. Kam', 'Coddy N. Siswanto']","Text modality decoder models rely on discrete token generation, which can lack a true understanding of affective dynamics. This paper introduces a hybrid encoder-decoder architecture with progressive steering of affective trajectories, utilizing physics-informed neural networks to allow temporal and longitudinal adaptation. The approach aims to mimic psychological plausibility from users over interactions while preserving expressiveness, computational efficiency, and interpretability.",310.03,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12343v1_How Well Do LLMs Predict Human Behavior A Measure .pdf,How Well Do LLMs Predict Human Behavior?,"['Wayne Gao', 'Sukjin Han', 'Annie Liang']","Large language models (LLMs) are increasingly used to predict human behavior. The paper proposes a measure to evaluate the amount of task-specific data needed to match the predictive accuracy of a pretrained LLM, known as equivalent sample size. By comparing the prediction error of a fixed LLM to that of flexible machine learning models trained on increasing samples of domain-specific data, the authors estimate this measure and provide a statistical inference procedure. The study finds that LLMs encode considerable predictive information for some economic variables but much less for others, suggesting that their value as substitutes for domain-specific data differs across settings.",309.68,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12349v1_Zero-Permission Manipulation Can We Trust Large Mu.pdf,Zero-Permission Manipulation: Can We Trust Large Multimodal Model Powered GUI Agents?,"['Yi Qian', 'Kunwei Qian', 'Xingbang He', 'Ligeng Chen', 'Jikang Zhang', 'Tiantai Zhang', 'Haiyang Wei', 'Linzhang Wang', 'Hao Wu', 'Bing Mao']","Large multimodal model-powered GUI agents are emerging as high-privilege operators on mobile platforms, entrusted with perceiving screen content and injecting inputs. The paper demonstrates that the assumption of Visual Atomicity is fundamentally invalid in Android, creating a critical attack surface. It presents Action Rebinding, a novel cross-application attack that allows a seemingly-benign application with zero dangerous permissions to rebind an agent's execution. The attacker exploits the inevitable observation-to-action gap to trigger foreground transitions and rebind the agent's planned action toward the target application. The paper also introduces an Intent Alignment Strategy (IAS) to manipulate the agent's reasoning process and bypass verification gates. The results show a 100% success rate for atomic action rebinding and the ability to reliably orchestrate multi-step attack chains. With IAS, the success rate in bypassing verification gates increases to up to 100%. The attacker application requires no sensitive permissions and contains no privileged API calls, achieving a 0% detection rate across malware scanners. The findings reveal a fundamental architectural flaw in current agent-OS integration and provide critical insights for the secure design of future autonomous agent systems.",308.67,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12357v1_SimpleMatch A Simple and Strong Baseline for Seman.pdf,SimpleMatch: A Simple and Strong Baseline for Semantic Correspondence,"['Hailong Jin', 'Huiying Li']","Recent advances in semantic correspondence have been largely driven by the use of pre-trained large-scale models. However, these methods typically require high-resolution input images, which introduces significant computational overhead and limits their applicability. This work addresses a fundamental limitation in current methods: the irreversible fusion of adjacent keypoint features caused by deep downsampling operations. SimpleMatch, a simple yet effective framework, delivers strong performance even at low resolutions. It uses a lightweight upsample decoder to progressively recover spatial detail and a multi-scale supervised loss to ensure upsampled features retain discriminative features across different spatial scales. Sparse matching and window-based localization are introduced to optimize training memory usage and reduce it by 51%. At a resolution of 252×252 (3.3× smaller than current SOTA methods), SimpleMatch achieves superior performance with 84.1% PCK@0.1 on the SPair-71k benchmark. The authors believe this framework provides a practical and efficient baseline for future research in semantic correspondence.",311.56,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12358v1_From Prompts to Pavement LMMs-based Agentic Behavi.pdf,From Prompts to Pavement:LMMs-based Agentic Behavior-Tree Generation Framework for Autonomous Vehicles,"['Omar Y. Goba', 'Ahmed Y. Gado', 'Catherine M. Elias', 'Ahmed Hussein']","This paper presents an agentic framework that leverages large language models (LLMs) and multi-modal vision models (LVMs) to generate and adapt behavior trees (BTs) on the fly. The system integrates a Descriptor agent, a Planner agent, and a Generator agent to trigger only upon baseline BT failure, demonstrating successful navigation around unexpected obstacles with no human intervention. Compared to a static BT baseline, this approach extends to diverse driving scenarios.",312.73,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12374v1_A Scalable Entity-Based Framework for Auditing Bia.pdf,A Scalable Entity-Based Framework for Auditing Bias in LLMs,"['Akram Elbouanani', 'Aboubacar Tuo', 'Adrian Popescu']","This paper introduces a scalable bias-auditing framework using named entities as probes to measure structural disparities in model behavior. The authors show that synthetic data reliably reproduces bias patterns observed in natural text, enabling large-scale analysis. They conduct the largest bias audit to date, comprising 1.9 billion data points across multiple entity types, tasks, languages, models, and prompting strategies. The results reveal systematic biases in models, such as penalizing right-wing politicians, favoring left-wing politicians, and preferring Western and wealthy nations over the Global South. The study also finds that instruction tuning reduces bias, but increasing model scale amplifies it, and prompting in Chinese or Russian does not attenuate Western-aligned preferences. These findings indicate that LLMs should undergo rigorous auditing before deployment in high-stakes applications.",308.47,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12389v1_NADIR Differential Attention Flow for Non-Autoregr.pdf,NADIR: Differential Attention Flow for Non-Autoregressive Transliteration in Indic Languages,"['Lakshya Tomar', 'Vinayak Abrol', 'Puneet Agarwal']","In this work, the authors argue that not all sequence-to-sequence tasks require the strong inductive biases of autoregressive (AR) models. They introduce NADIR, a novel non-autoregressive (NAR) architecture designed to balance speed and accuracy for multilingual transliteration in Indic languages. NADIR integrates a Differential Transformer and a Mixture-of-Experts mechanism, enabling robust modeling of complex character mappings without sequential dependencies. NADIR achieves over a 13× speed-up compared to the state-of-the-art AR baseline while maintaining competitive mean Character Error Rate. It reduces Repetition, Substitution, Omission, and Insertion errors significantly, providing a practical blueprint for building fast and reliable NAR systems.",309.08,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12392v1_PsychēChat An Empathic Framework Focused on Emotio.pdf,Psych¯eChat: An Empathic Framework Focused on Emotion Shift Tracking and Safety Risk Analysis in Psychological Counseling,"['Zhentao Xia', 'Yongqi Fan', 'Yuxiang Chu', 'Yichao Yin', 'Liangliang Chen', 'Tong Ruan', 'Weiyan Zhang']","Psych¯eChat is an empathic framework designed for psychological counseling that explicitly integrates emotion shift tracking and safety risk analysis. It employs interactive role-playing to synthesize counselor-seeker dialogues, incorporating modules for emotion management and risk control. The Agent Model structures emotion management, risk control, and counselor responses into a collaborative multi-agent pipeline, while the LLM Model integrates these stages into a unified chain-of-thought for end-to-end inference. Extensive experiments demonstrate that Psych¯eChat outperforms existing methods for emotional insight and safety control.",309.87,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12401v1_Beyond the Dirac Delta Mitigating Diversity Collap.pdf,Beyond the Dirac Delta: Mitigating Diversity Collapse in Reinforcement Fine-Tuning for Versatile Image Generation,"['Jinmei Liu', 'Haoru Li', 'Zhenhong Sun', 'Chaofeng Chen', 'Yatao Bian', 'Bo Wang', 'Daoyi Dong', 'Chunlin Chen', 'Zhi Wang']","Reinforcement learning (RL) has emerged as a powerful paradigm for fine-tuning large-scale generative models, such as diffusion and flow models, to align with complex human preferences and user-specified tasks. However, a fundamental limitation remains: the curse of diversity collapse, where the objective formulation and optimization landscape inherently collapse the policy to a Dirac delta distribution. To address this challenge, the authors propose DRIFT, an innovative framework that systematically incentivizes output diversity throughout the on-policy fine-tuning process, reconciling strong task alignment with high generation diversity. The approach is approached across three representative perspectives: sampling a reward-concentrated subset to filter out reward outliers, prompting with stochastic variations to expand the conditioning space, and optimization of intra-group diversity with a potential-based reward shaping mechanism. Experimental results show that DRIFT achieves superior Pareto dominance regarding task alignment and generation diversity, yielding a 9.08%∼43.46% increase in diversity at equivalent alignment levels and a 59.65%∼65.86% increase in alignment at equivalent levels of diversity.",308.97,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12402v1_Weaknesses of Facial Emotion Recognition Systems.pdf,Weaknesses of Facial Emotion Recognition Systems,"['Aleksandra Jamróz', 'Patrycja Wysocka', 'Piotr Garbat']","This study presents a comprehensive analysis of the most advanced facial emotion recognition solutions currently available. The approach evaluates network performance when trained on one dataset and applied to others. This methodolgy enables to ascertain the model’s generalisation capabilities, which is a crucial aspect in determining its state-of-the-art status. The study showed that a network's performance on different datasets is significantly worse than when it is tested on the same dataset on which it was trained. The motivation for this study lies in the crucial role emotions play in decision-making and interpersonal relationships. As technology advances, human-computer systems are expected to evolve, and incorporating emotion recognition is a way for enhancing their responses. Computer vision methods play a crucial role here as humans perceive messages only in 7% from the verbal part - words, while as much as 55% from non-verbal messages - body language and facial expressions [1]. By understanding users’ emotional states, human-computer interaction systems will be able to engage more naturally, improve user interactions, and foster stronger connections.",314.79,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12405v1_Explainable Machine Learning for Pediatric Dental .pdf,Explainable Machine Learning for Pediatric Dental Risk Stratification Using Socio-Demographic Determinants,"['Manasi Kanade', 'Abhi Thakkar', 'Gabriela Fernandes']","This study aimed to develop and evaluate an explainable artificial intelligence (XAI) framework for pediatric dental risk stratification. A supervised machine learning model was trained using population-level pediatric data incorporating age, income-to-poverty ratio, race/ethnicity, gender, and medical history. The model demonstrated modest discriminative performance (AUC = 0.61) and conservative probability estimates. Global SHapley Additive exPlanations (SHAP) analysis identified age and income-to-poverty ratio as the dominant contributors to predicted dental risk, followed by race/ethnicity and gender. Individual-level explanations showed that predictions arose from cumulative socio-demographic effects rather than reliance on a single dominant feature. The study demonstrates that explainable AI can be responsibly applied to pediatric dental risk stratification in a transparent, ethical, and prevention-oriented manner.",315.32,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12410v1_Are LLMs Smarter Than Chimpanzees An Evaluation on.pdf,Are LLMs Smarter Than Chimpanzees?,"['Dingyi Yang', 'Junqi Zhao', 'Xue Li', 'Ce Li', 'Boyang Li']",This paper evaluates the performance of Large Language Models (LLMs) in understanding and predicting the actions of story characters based on their knowledge states. The authors design two tasks to test if LLMs can detect when characters demonstrate knowledge they should not possess and if they can predict characters' next actions based on their own knowledge versus objective truths they do not know. The results show that most current state-of-the-art LLMs achieve near-random performance on both tasks and are substantially inferior to humans. The authors argue that future LLM research should focus more on knowledge estimation and intention understanding.,314.53,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12415v1_Orthogonalized Policy OptimizationDecoupling Sampl.pdf,Orthogonalized Policy Optimization,['Wang Zixian'],"Recent alignment methods for large language models, including PPO, DPO, and IPO, are often presented as distinct algorithms. In this work, we show that many of these approaches implicitly conflate two fundamental and independent design choices: (i) the sampling geometry, which determines which samples dominate the gradient signal, and (ii) the optimization geometry, which determines how deviations in value are penalized. We formalize this observation by expressing alignment as the minimization of a generalized distance between policy energy and target energy, parameterized by an α-divergence-based sampling weight and a Bregman divergence-based value metric. We demonstrate that the commonly used KL divergence induces an exponential penalty on unbounded value signals, leading to numerical instability and vanishing gradients in high-confidence regimes. To address this issue, we propose Orthogonalized Policy Optimization (OPO), a framework that explicitly decouples sampling geometry from optimization geometry. By combining α-weighted importance sampling with a χ2-induced quadratic regularization in ratio coordinates, OPO yields a simple and well-conditioned objective with linear gradient dynamics. This formulation maintains stable optimization while preserving peak-seeking behavior, and avoids gradient saturation even when model confidence is high. Our analysis positions OPO as a unifying perspective on existing alignment methods and provides a principled foundation for robust reasoning-oriented training.",315.66,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12436v1_Purification Before Fusion Toward Mask-Free Speech.pdf,PURIFICA TION BEFORE FUSION: TOW ARD MASK-FREE SPEECH ENHANCEMENT FOR ROBUST AUDIO-VISUAL SPEECH RECOGNITION,"['Linzhi Wu', 'Xingyu Zhang∗', 'Hao Yuan', 'Yakun Zhang', 'Changyan Zheng', 'Liang Xie', 'Tiejun Liu', 'Erwei Yin']","Audio-visual speech recognition (AVSR) typically improves recognition accuracy in noisy environments by integrating noise-immune visual cues with audio signals. However, high-noise audio inputs are prone to introducing adverse interference into the feature fusion process. Recent AVSR methods often adopt mask-based strategies to filter audio noise during feature interaction and fusion, but such methods risk discarding semantically relevant information alongside noise. This work proposes an end-to-end noise-robust AVSR framework coupled with speech enhancement, eliminating the need for explicit noise mask generation. The framework leverages a Conformer-based bottleneck fusion module to implicitly refine noisy audio features with video assistance, reducing modality redundancy and enhancing inter-modal interactions, thereby preserving speech semantic integrity and achieving robust recognition performance. Experimental evaluations on the public LRS3 benchmark suggest that the method outperforms prior advanced mask-based baselines under noisy conditions.",313.62,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12442v1_Constraint-Aware Neurosymbolic Uncertainty Quantif.pdf,Constraint-Aware Neurosymbolic Uncertainty Quantification with Bayesian Deep Learning for Scientific Discovery,"['Shahnawaz Alam', 'Mohammed Mudassir Uddin', 'Mohammed Kaif Pasha']","Scientific Artificial Intelligence (AI) applications require models that deliver trustworthy uncertainty estimates while respecting domain constraints. Existing uncertainty quantification methods lack mechanisms to incorporate symbolic scientific knowledge, while neurosymbolic approaches operate deterministically without principled uncertainty modeling. The paper introduces the Constraint-Aware Neurosymbolic Uncertainty Framework (CANUF), unifying Bayesian deep learning with differentiable symbolic reasoning. The architecture comprises three components: automated constraint extraction from scientific literature, probabilistic neural backbone with variational inference, and differentiable constraint satisfaction layer ensuring physical consistency. Experiments on Materials Project, QM9 molecular properties, and climate benchmarks show CANUF reduces Expected Calibration Error by 34.7% versus Bayesian neural networks while maintaining 99.2% constraint satisfaction. Ablations reveal constraint-guided recalibration contributes 18.3% performance gain, with constraint extraction achieving 91.4% precision. CANUF provides the first end-to-end differentiable pipeline simultaneously addressing uncertainty quantification, constraint satisfaction, and interpretable explanations for scientific predictions.",314.91,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12443v1_Adversarial Defense in Vision-Language Models An O.pdf,Adversarial Defense in Vision-Language Models: An Overview,"['Xiaowei Fu', 'Lei Zhang*']","The widespread use of Vision Language Models (VLMs) has raised concerns about their vulnerability to adversarial attacks. Three main defense paradigms have been proposed: Training-time Defense, Test-time Adaptation Defense, and Training-free Defense. Training-time Defense involves modifying the training process through adversarial fine-tuning. Test-time Adaptation Defense focuses on adapting the model at inference time. Training-free Defense avoids modifying the model itself, instead focusing on altering the adversarial inputs or their feature embeddings. This survey reviews the latest advancements in adversarial defense strategies for VLMs, highlighting strengths and limitations and discussing ongoing challenges.",314.79,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12444v1_Large Language Model for OWL Proofs.pdf,Large Language Model for OWL Proofs,"['Hui Yang', 'Jiaoyan Chen', 'Uli Sattler']","The ability of Large Language Models (LLMs) to perform reasoning tasks such as deduction has been widely investigated. However, their capacity to generate proofs—faithful, human-readable explanations of why conclusions follow—remains largely underexplored. This work studies proof generation in the context of OWL ontologies, developing an automated dataset construction and evaluation framework. The evaluation encompasses three sequential tasks for complete proving: Extraction, Simplification, and Explanation, as well as an additional task of assessing Logic Completeness of the premise. Through extensive experiments on widely used reasoning LLMs, important findings are achieved, including: (1) Some models achieve strong results but remain limited on complex cases; (2) Logical complexity, rather than representation format, is the dominant factor shaping LLM performance; and (3) Noise and incompleteness in input data substantially diminish LLMs' performance. These results underscore both the promise of LLMs for explanation with rigorous logics and the gap of supporting resilient reasoning under complex or imperfect conditions.",313.45,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12449v1_AgenTRIM Tool Risk Mitigation for Agentic AI.pdf,AgenTRIM: Tool Risk Mitigation for Agentic AI,"['Roy Betser', 'Shamik Bose', 'Amit Giloni', 'Chiara Picardi', 'Sindhu Padakandla', 'Roman Vainshtein']","AI agents are autonomous systems that combine large language models (LLMs) with external tools to solve complex tasks. While these tools extend capability, improper tool permissions introduce security risks such as indirect prompt injection and tool misuse. The authors characterize these failures as unbalanced tool-driven agency, where agents may retain unnecessary permissions (excessive agency) or fail to invoke required tools (insufficient agency), amplifying the attack surface and reducing performance. AGENTRIM is introduced as a framework for detecting and mitigating tool-driven agency risks without altering an agent's internal reasoning. AGENTRIM addresses these risks through complementary offline and online phases. Offline, AGENTRIM reconstructs and verifies the agent's tool interface from code and execution traces. At runtime, it enforces step-by-step least-privilege tool access through adaptive filtering and status-aware validation of tool calls. Evaluations on the AgentDojo benchmark show that AGENTRIM substantially reduces attack success while maintaining high task performance. Additional experiments demonstrate robustness to description-based attacks and effective enforcement of explicit safety policies. Together, these results show that AGENTRIM provides a practical, capability-preserving approach to safer tool use in LLM-based agents.",313.46,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12465v1_Incentivizing In-depth Reasoning over Long Context.pdf,DEEPREASONQA: Overcoming the 'Almost-There' Phenomenon in Long-Context Reasoning,"['Miao Peng', 'Weizhou Shen', 'Nuo Chen', 'Chenliang Li', 'Ming Yan', 'Jia Li']","DEEPREASONQA addresses the 'almost-there' phenomenon in long-context reasoning RL, where trajectories are largely correct but fail at the final step. It proposes a KG-driven synthesis framework to construct high-difficulty, multi-hop long-context QA pairs with inherent reasoning chains. LONGPAS, a fine-grained credit assignment method, evaluates reasoning steps along validity and relevance dimensions, capturing critical learning signals from 'almost-there' trajectories. Experiments on three long-context reasoning benchmarks show that DEEPREASONQA substantially outperforms RLVR baselines and matches frontier LLMs while using far fewer parameters. The methods strengthen long-context reasoning while maintaining stable RL training.",314.26,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12467v1_Patch-Level Tokenization with CNN Encoders and Att.pdf,Patch-Level Tokenization with CNN Encoders and Attention for Improved Transformer Time-Series Forecasting,"['Saurish Nagrath', 'VIT-AP']","Transformer-based models have shown strong performance in time-series forecasting by leveraging self-attention to model long-range temporal dependencies. However, their effectiveness depends critically on the quality and structure of input representations derived from raw multivariate time-series data. This work proposes a two-stage forecasting framework that explicitly separates local temporal representation learning from global dependency modeling. In the first stage, a convolutional neural network (CNN) operates on fixed-length temporal patches to extract short-range temporal dynamics and non-linear feature interactions, producing compact patch-level token embeddings. Token-level self-attention is subsequently applied during representation learning to refine these embeddings by enabling interactions across temporal patches. In the second stage, a Transformer encoder processes the resulting token sequence to model inter-patch temporal dependencies and generate per-patch forecasts. Experiments conducted on synthetic multivariate time-series data with controlled static and dynamic factors demonstrate that the proposed patch-based tokenization strategy achieves competitive forecasting performance compared to convolutional and patch-based Transformer baselines. The results highlight the importance of structured temporal representations and show that decoupling local temporal encoding from global attention-based modeling yields more effective and stable time-series forecasting.",315.07,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12471v1_Knowing When to Abstain Medical LLMs Under Clinica.pdf,Knowing When to Abstain: Medical LLMs Under Clinical Uncertainty,"['Sravanthi Machcha', 'Sushrita Yerra', 'Sahil Gupta', 'Aishwarya Sahoo', 'Sharmin Sultana', 'Hong Yu', 'Zonghai Yao']","Current evaluation of large language models (LLMs) overwhelmingly prioritizes accuracy; however, in real-world and safety-critical applications, the ability to abstain when uncertain is equally vital for trustworthy deployment. The authors introduce MedAbstain, a unified benchmark and evaluation protocol for abstention in medical multiple-choice question answering (MCQA) – a discrete-choice setting that generalizes to agentic action selection – integrating conformal prediction, adversarial question perturbations, and explicit abstention options. Their systematic evaluation of both open- and closed-source LLMs reveals that even state-of-the-art, high-accuracy models often fail to abstain with uncertainty. Notably, providing explicit abstention options consistently increases model uncertainty and safer abstention, far more than input perturbations, while scaling model size or advanced prompting brings little improvement. These findings highlight the central role of abstention mechanisms for trustworthy LLM deployment and offer practical guidance for improving safety in high-stakes applications.",313.32,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12494v1_Harmonizing the Arabic Audio Space with Data Sched.pdf,Harmonizing the Arabic Audio Space with Data Scheduling,"['Hunzalah Hassan Bhatti', 'Firoj Alam', 'Shammur Absar Chowdhury']","This paper presents the first systematic study of multi-task instruction tuning for an Arabic-centric audio Large Language Model (LLM), covering generative tasks (Automatic Speech Recognition, ASR, and speech summarization) and discriminative tasks (dialect and emotion identification). The authors introduce AraMega-SSum, a novel dataset for Arabic speech summarization. They fine-tune Qwen2.5-Omni (7B) and propose Task-Progressive Curriculum (TPC) along with Aligner-Based Diverse Sampling (ADS), a strategy that constructs information-dense batches by selecting task-and label-balanced examples. The results reveal a critical efficiency-robustness trade-off: while ADS accelerates initial convergence and boosts paralinguistic F1-scores, its inherent gradient volatility can destabilize generative decoding under prolonged training. TPC stabilizes core acoustic mapping but often induces negative transfer in downstream tasks. The Hybrid TPC+ADS strategy provides an optimal training recipe, first establishing a robust representative foundation before employing diversity-aware refinement to capture fine-grained nuances. These findings offer practical guidance for the efficient adaptation of Omni models in complex, low-resource multimodal environments.",312.48,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12499v1_Failure Modes in Multi-Hop QA The Weakest Link Law.pdf,Failure Modes in Multi-Hop QA: The Weakest Link Law and the Recognition Bottleneck,"['Meiru Zhang', 'Zaiqiao Meng', 'Nigel Collier']","Despite scaling to massive context windows, Large Language Models (LLMs) struggle with multi-hop reasoning due to inherent position bias, which causes them to overlook information at certain positions. This paper introduces Multi-Focus Attention Instruction (MFAI), a semantic probe to disentangle recognition and synthesis failures by explicitly steering attention towards selected positions. Across 5 LLMs on two multi-hop QA tasks (MuSiQue and NeoQA), we establish the 'Weakest Link Law': multi-hop reasoning performance collapses to the performance level of the least visible evidence. Crucially, this failure is governed by absolute position rather than the linear distance between facts (performance variance <3%). We further identify a duality in attention steering: while matched MFAI resolves recognition bottlenecks, improving accuracy by up to 11.5% in low-visibility positions, misleading MFAI triggers confusion in real-world tasks but is successfully filtered in synthetic tasks. Finally, we demonstrate that 'thinking' models that utilize System-2 reasoning effectively locate and integrate the required information, matching gold-only baselines even in noisy, long-context settings.",312.95,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12518v1_Cooperative Multi-agent RL with Communication Cons.pdf,Cooperative Multi-agent RL with Communication constraints,"['Nuoya Xiong', 'Aarti Singh']","Cooperative Multi-agent reinforcement learning (MARL) often assumes frequent access to global information in a data buffer, such as team rewards or other agents' actions, which is typically unrealistic in decentralized MARL systems due to high communication costs. When communication is limited, agents must rely on outdated information to estimate gradients and update their policies. A common approach to handle missing data is called importance sampling, in which we reweigh old data from a base policy to estimate gradients for the current policy. However, it quickly becomes unstable when the communication is limited (i.e. missing data probability is high), so that the base policy in importance sampling is outdated. To address this issue, we propose a technique called base policy prediction, which utilizes old gradients to predict the policy update and collect samples for a sequence of base policies, which reduces the gap between the base policy and the current policy. This approach enables effective learning with significantly fewer communication rounds, since the samples of predicted base policies could be collected within one communication round. Theoretically, we show that our algorithm converges to an ε-Nash equilibrium in potential games with only O(ε^(-3/4)) communication rounds and O(poly(max i |Ai|)·ε^(-11/4)) samples, improving existing state-of-the-art results in communication cost, as well as sample complexity without the exponential dependence on the joint action space size. We also extend these results to general Markov Cooperative Games to find an agent-wise local maximum. Empirically, we test the base policy prediction algorithm in both simulated games and MAPPO for complex environments. The results show that our algorithms can significantly reduce the communication costs while maintaining good performance compared to the setting without communication constraints, and standard algorithms fail under the same communication cost.",312.89,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12522v1_Improved Bug Localization with AI Agents Leveragin.pdf,Improved Bug Localization with AI Agents Leveraging Hypothesis and Dynamic Cognition,"['Asif Mohammed Samir', 'Mohammad Masudur Rahman']","Software bugs cost technology providers billions annually and developers spend roughly 50% of their time on bug resolution. Traditional bug localization methods often analyze suspicious code components in isolation, overlooking their connections. Recent advances in Large Language Models (LLMs) and agentic AI techniques have shown potential for code understanding but lack causal reasoning and context management. This paper presents CogniGent, a novel agentic technique that overcomes these limitations by leveraging multiple AI agents for causal reasoning, call-graph-based root cause analysis, and context engineering. It emulates dynamic cognitive debugging practices and conducts hypothesis testing for bug localization. Experimental results show that CogniGent consistently outperforms existing techniques, achieving MAP improvements of 23.33-38.57% at the document and method levels and MRR improvements of 25.14-53.74% at both granularity levels. The technique addresses reasoning, dependency, and context limitations, advancing bug localization.",313.63,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12534v1_Encoding Emotion Through Self-Supervised Eye Movem.pdf,ENCODING EMOTION THROUGH SELF-SUPERVISED EYE MOVEMENT RECONSTRUCTION,"['Marcus Ma', 'Jordan Prescott', 'Emily Zhou', 'Tiantian Feng', 'Kleanthis Avramidis', 'Gabor Mihaly Toth', 'Shrikanth Narayanan']","The relationship between emotional expression and eye movement is well-documented, with gaze patterns being reliable indicators of emotion. However, most studies use specialized, high-resolution eye-tracking equipment, limiting the potential reach of findings. This work investigates how eye movement can predict multimodal markers of emotional expression from naturalistic, low-resolution videos. The authors use a large-scale video dataset of Holocaust survivor interviews to develop a novel gaze detection model that uses self-supervised eye movement reconstruction. They fine-tune this model on two downstream tasks related to emotional expression, aligning eye movement with directional emotion estimates from speech and predicting laughing, crying/sobbing, and sighing. The model shows predictive power and a positive correlation between pretraining performance and emotion processing performance.",313.08,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12535v1_Improving Low-Resource Machine Translation via Rou.pdf,Improving Low-Resource Machine Translation via Round-Trip Reinforcement Learning,"['Ahmed Attia', 'Alham Fikri']","This paper investigates a self-supervised reinforcement-learning-based fine-tuning approach for translation in low-resource settings using round-trip bootstrapping with the No Language Left Behind (NLLB) family of models. The authors translate English into a target low-resource language and then back into English, using a combination of chrF++ and BLEU as the reward function on the reconstructed English sentences. They evaluate both the 600M and 1.3B parameter NLLB models on the NLLB-MD dataset and observe consistent improvements for Central Aymara, Friulian, Wolof, and Russian. The method is argued to further benefit from scale, enabling models to leverage their pretrained knowledge and continue self-improving.",314.2,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12538v1_Agentic Reasoning for Large Language Models.pdf,Agentic Reasoning for Large Language Models,"['Tianxin Wei', 'Ting-Wei Li', 'Zhining Liu', 'Xuying Ning', 'Ze Yang', 'Jiaru Zou', 'Zhichen Zeng', 'Ruizhong Qiu', 'Xiao Lin', 'Dongqi Fu', 'Wenxuan Bao', 'Yunzhe Li', 'Gaotang Li', 'Cheng Qian', 'Yu Wang', 'Xiangru Tang', 'Yin Xiao', 'Liri Fang', 'Hui Liu', 'Xianfeng Tang', 'Yuji Zhang', 'Chi Wang', 'Jiaxuan You', 'Heng Ji', 'Hanghang Tong', 'Jingrui He']","Reasoning is a fundamental cognitive process underlying inference, problem-solving, and decision-making. While large language models (LLMs) demonstrate strong reasoning capabilities in closed-world settings, they struggle in open-ended and dynamic environments. The emergence of agentic reasoning marks a paradigm shift, bridging thought and action by reframing LLMs as autonomous agents that plan, act, and learn through continual interaction. This survey provides a systematic roadmap by organizing agentic reasoning along three complementary dimensions: foundational agentic reasoning, self-evolving agentic reasoning, and collective multi-agent reasoning. Across all layers, system constraints and optimization settings are analyzed, distinguishing in-context reasoning from post-training reasoning. The survey reviews and contextualizes agentic reasoning frameworks in real-world applications and benchmarks spanning science, robotics, healthcare, autonomous research, and math, illustrating how different reasoning mechanisms are instantiated and evaluated across domains. This survey synthesizes agentic reasoning methods into a unified roadmap that bridges thoughts and actions, offering actionable guidance for agentic systems across environmental dynamics, optimization settings, and agent interaction settings. Finally, open challenges and future directions are outlined, situating how agentic reasoning has developed while identifying what remains ahead: personalization, long-horizon interaction, world modeling, scalable multi-agent training, and governance frameworks for real-world deployment.",313.49,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12539v1_MemeLens Multilingual Multitask VLMs for Memes.pdf,MemeLens: Multilingual Multitask VLMs for Memes,"['Ali Ezzat Shahroor', 'Mohamed Bayan Kmainasi', 'Abul Hasnat', 'Dimitar Dimitrov', 'Giovanni Da San Martino', 'Preslav Nakov', 'Firoj Alam']","Memes are a dominant medium for online communication and manipulation. Existing research is fragmented across tasks and languages, limiting cross-domain generalization. MEMELENS proposes a unified multilingual and multitask Vision-Language Model (VLM) for meme understanding, consolidating 38 public datasets into a shared taxonomy of 20 tasks. The model exhibits robustness to multimodal training, variation across semantic categories, and sensitivity to over-specialization. The authors will make experimental resources and datasets publicly available.",312.14,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12542v1_Rethinking the AI Scientist Interactive Multi-Agen.pdf,Rethinking the AI Scientist: Interactive Multi-Agent Workflows for Scientific Discovery,"['Lukas Weidener*', 'Marko Brkić*', 'Mihailo Jovanović*', 'Ritvik Singh', 'Chiara Baccin', 'Emre Ulgac', 'Alex Dobrin', 'Aakaash Meduri']","This paper introduces Deep Research, a multi-agent system enabling interactive scientific investigation with turnaround times measured in minutes. The architecture comprises specialized agents for planning, data analysis, literature search, and novelty detection, unified through a persistent world state that maintains context across iterative research cycles. Two operational modes support different workflows: semi-autonomous mode with selective human checkpoints, and fully autonomous mode for extended investigations. Evaluation on the BixBench computational biology benchmark demonstrated state-of-the-art performance, achieving 48.8% accuracy on open response and 64.5% on multiple-choice evaluation, exceeding existing baselines by 14 to 26 percentage points. Analysis of architectural constraints, including open access literature limitations and challenges inherent to automated novelty assessment, informs practical deployment considerations for AI-assisted scientific workflows.",313.12,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12547v1_How Clinicians Think and What AI Can Learn From It.pdf,How Clinicians Think—and What AI Can Learn From,"['Dr. Dipayan Sengupta', 'Dr. Saumya Panda']","Most clinical AI systems are built as prediction engines, but real clinical reasoning is a time-bounded, sequential control problem under uncertainty. Clinicians often rely on fast-and-frugal lexicographic heuristics that evaluate a small number of cues in a fixed order and stop early. The authors argue that ordinal non-compensatory decision-making is a more appropriate computational substrate for clinician reasoning. They provide a normative rationale for why these algorithms can be preferred in medicine, addressing issues of weak measurement, structural crudeness, and decision stability. The authors outline a clinician-aligned AI blueprint, emphasizing the importance of robust ordinal decision rules and selective complexity. This perspective shifts the algorithmic focus from more accurate numbers to more robust action selection, aligning with research on judgment and decision-making.",314.56,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12549v1_Benchmarking Concept-Spilling Across Languages in .pdf,Benchmarking Concept-Spilling Across Languages in LLMs,"['Ilia Badanin', 'Daniil Dzenhaliou', 'Imanol Schlag']","This paper presents a novel comparative framework for evaluating multilingual semantic robustness by systematically measuring how models handle polysemous words across languages. The methodology provides a relative measure of model performance, revealing significant variation in semantic robustness across both models and languages. The findings provide a principled ranking system for model comparison without requiring definitive causal attribution of error sources. The paper contributes a scalable comparative benchmark for multilingual semantic evaluation and a rigorous validation pipeline, critical tools for developing more linguistically balanced AI systems.",314.67,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12554v1_Artificial Intelligence in Materials Science and E.pdf,"Artificial Intelligence in Materials Science and Engineering: Current Landscape, Key Challenges, and Future Trajectories","['Iman Peivaste', 'Salim Belouettar ∗', 'Francesco Mercuri', 'Nicholas Fantuzzi', 'Hamidreza Dehghani', 'Razieh Izadi', 'Halliru Ibrahim', 'Jakub Lengiewicz', 'Maël Belouettar-Mathis', 'Kouider Bendine', 'Ahmed Makradi', 'Martin Hörsch', 'Peter Klein', 'Mohamed El Hachemi', 'Heinz A. Preisig', 'Yacine Rezgui', 'Natalia Konchakova', 'Ali Daouadji']","Artificial Intelligence (AI) is rapidly transforming materials science and engineering, offering powerful tools to navigate complexity, accelerate discovery, and optimize material design in ways previously unattainable. This review provides a comprehensive and structured overview of the current landscape, synthesizing recent advancements and methodologies for materials scientists seeking to effectively leverage these data-driven techniques. It surveys the spectrum of machine learning approaches, from traditional algorithms to advanced deep learning architectures, including CNNs, GNNs, and Transformers, alongside emerging generative AI and probabilistic models such as Gaussian Processes for uncertainty quantification. The review also examines the pivotal role of data in this field, emphasizing effective representation and featurization strategies, spanning compositional, structural, image-based, and language-inspired approaches, combined with appropriate preprocessing, which fundamentally underpin the performance of machine learning models.",314.21,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12557v1_Life Machine Learning and the Search for Habitabil.pdf,"Life, Machine Learning, and the Search for Habitability: Predicting Biosignature Fluxes for the Habitable Worlds Observatory","['Mark Moussa', 'Amber V. Young', 'Brianna Isola', 'Vasuda Trehan', 'Michael D. Himes', 'Nicholas Wogan', 'Giada Arney']","Future direct-imaging flagship missions, such as NASA’s Habitable Worlds Observatory (HWO), face critical decisions in prioritizing observations due to stringent time and resource constraints. This paper introduces two advanced machine-learning architectures, a Bayesian Convolutional Neural Network (BCNN) and the Spectral Query Adaptive Transformer (SQuAT), for predicting biosignature species fluxes from exoplanetary reflected-light spectra. The BCNN robustly quantifies both epistemic and aleatoric uncertainties, offering reliable predictions under diverse observational conditions, while SQuAT employs query-driven attention mechanisms to enhance interpretability by explicitly associating spectral features with specific biosignature species. Both models achieve comparably high predictive accuracy on an augmented dataset spanning a wide range of exoplanetary conditions, highlighting their distinct advantages in uncertainty quantification and spectral interpretability. These capabilities position our methods as promising tools for accelerating target triage, optimizing observation schedules, and maximizing scientific return for upcoming flagship missions such as HWO.",312.35,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12560v1_Agentic Artificial Intelligence AI Architectures T.pdf,"Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents","['Arunkumar V', 'Gangadharan G.R.', 'Rajkumar Buyya']","Artificial Intelligence is moving from models that only generate text to Agentic AI, where systems behave as autonomous entities that can perceive, reason, plan, and act. Large Language Models (LLMs) are no longer used only as passive knowledge engines but as cognitive controllers that combine memory, tool use, and feedback from their environment to pursue extended goals. This shift already supports the automation of complex workflows in software engineering, scientific discovery, and web navigation, yet the variety of emerging designs, from simple single loop agents to hierarchical multi agent systems, makes the landscape hard to navigate. In this paper, we investigate architectures and propose a unified taxonomy that breaks agents into Perception, Brain, Planning, Action, Tool Use, and Collaboration. We use this lens to describe the move from linear reasoning procedures to native inference time reasoning models, and the transition from fixed API calls to open standards like the Model Context Protocol (MCP) and Native Computer Use. We also group the environments in which these agents operate, including digital operating systems, embodied robotics, and other specialized domains, and we review current evaluation practices. Finally, we highlight open challenges, such as hallucination in action, infinite loops, and prompt injection, and outline future research directions toward more robust and reliable autonomous systems.",314.81,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12577v1_Primate-like perceptual decision making emerges th.pdf,Primate-like perceptual decision making emerges through deep recurrent reinforcement learning,"['Nathan J. Wispinski', 'Scott A. Stone', 'Anthony Singhal', 'Patrick M. Pilarski', 'Craig S. Chapman']","The authors trained an end-to-end deep recurrent neural network using reinforcement learning on a noisy perceptual discrimination task. Networks learned several key abilities of primate-like decision making, including trading off speed for accuracy and flexibly changing their mind in the face of new information. The internal dynamics of these networks suggest that these abilities were supported by similar decision mechanisms as those observed in primate neurophysiological studies. These results provide experimental support for key pressures that gave rise to the primate ability to make flexible decisions.",315.39,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12582v1_Ontology-aligned structuring and reuse of multimod.pdf,Ontology-aligned structuring and reuse of multimodal materials data and workflows towards automatic reproduction,"['Sepideh Baghaee Ravari', 'Abril Azocar', 'Guzman Sarath', 'Menon Stefan', 'Sarath Sarath', 'Sarath Sarath', 'Tilmann Hickel', 'Markus Stricker']","Reproducibility of computational results in materials science remains a challenge due to unstructured reporting of workflows and parameters. An ontology-driven, large language model (LLM)-assisted framework is introduced for automated extraction and structuring of computational workflows from literature. The approach focuses on density functional theory-based stacking fault energy (SFE) calculations in hexagonal close-packed magnesium and its binary alloys, using a multi-stage filtering strategy and prompt-engineered LLM extraction. Extracted information is unified into a canonical schema and aligned with established materials ontologies, enabling systematic comparison and structured reuse of computational protocols. While full reproducibility is still constrained by missing or implicit metadata, the framework provides a foundation for organizing and contextualizing published results in a semantically interoperable form, improving transparency and reusability.",313.28,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12585v1_Do MLLMs See What We See Analyzing Visualization L.pdf,Analyzing Visualization Literacy Barriers in AI Systems,"['Mengli (Dawn) Duan', 'Yuhe (Sissi) Jiang', 'Matthew Varona', 'Carolina Nobre']","This paper presents the first systematic analysis of barriers to visualization literacy in Multimodal Large Language Models (MLLMs). Using the reVLAT benchmark with synthetic data, the authors open-coded 309 erroneous responses from four state-of-the-art models. The analysis reveals two machine-specific barriers that extend prior human-participation frameworks. Results show that models perform well on simple charts but struggle with color-intensive, segment-based visualizations, often failing to form consistent comparative reasoning. The findings inform future evaluation and design of reliable AI-driven visualization assistants.",314.47,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12594v1_SLAP Scalable Language-Audio Pretraining with Vari.pdf,SLAP: SCALABLE LANGUAGE-AUDIO PRETRAINING WITH V ARIABLE-DURATION AUDIO AND MULTI-OBJECTIVE TRAINING,"['Xinhao Mei', 'Gael Le Lan', 'Haohe Liu', 'Zhaoheng Ni', 'V arun Nagaraja', 'Yang Liu', 'Yangyang Shi', 'Vikas Chandra']","Contrastive language-audio pretraining (CLAP) has achieved notable success in learning semantically rich audio representations and is widely adopted for various audio-related tasks. However, current CLAP models face several key limitations. First, they are typically trained on relatively small datasets, often comprising a few million audio samples. Second, existing CLAP models are restricted to short and fixed duration, which constrains their usage in real-world scenarios with variable-duration audio. Third, the standard contrastive training objective operates on global representations, which may hinder the learning of dense, fine-grained audio features. To address these challenges, we introduce Scalable Language-Audio Pretraining (SLAP), which scales language-audio pretraining to 109 million audio-text pairs with variable audio durations and incorporates multiple training objectives. SLAP unifies contrastive loss with additional self-supervised and captioning losses in a single-stage training, facilitating the learning of richer dense audio representations. The proposed SLAP model achieves new state-of-the-art performance on audio-text retrieval and zero-shot audio classification tasks, demonstrating its effectiveness across diverse benchmarks.",313.05,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12607v1_A Cloud-based Multi-Agentic Workflow for Science.pdf,A Cloud-based Multi-Agentic Workflow for Science,"['Anurag Acharya', 'Timothy Vega', 'Rizwan A. Ashraf', 'Anshu Sharma', 'Derek Parker', 'Robert Rallo']","As Large Language Models (LLMs) become ubiquitous across various scientific domains, their lack of ability to perform complex tasks like running simulations or making complex decisions limits their utility. LLM-based agents bridge this gap due to their ability to call external resources and tools. In this work, we present a domain-agnostic, model-independent workflow for an agentic framework that can act as a scientific assistant while being run entirely on cloud. Built with a supervisor agent marshaling an array of agents with individual capabilities, our framework brings together straightforward tasks like literature review and data analysis with more complex ones like simulation runs. We describe the framework in full, including a proof-of-concept system we built to accelerate the study of Catalysts, which is highly important in the field of Chemistry and Material Science. We report the cost to operate and use this framework, including the breakdown of the cost by services use. We also evaluate our system on a custom-curated synthetic benchmark and a popular Chemistry benchmark, and perform expert validation of the system. The results show that our system is able to route the task to the correct agent 90% of the time and successfully complete the assigned task 97.5% of the time for synthetic tasks and 91% of the time for real-world tasks, while still achieving better or comparable accuracy to most frontier models, showing that this is a viable framework for other scientific domains to replicate.",313.08,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12617v1_Creating Disability Story Videos with Generative A.pdf,"Creating Disability Story Videos with Generative AI: Motivation, Expression, and Sharing","['Shuo Niu', 'Dylan Clements', 'Hyungsin Kim']","This research examines how nine people with disabilities (PwDs) from a disability advocacy group used generative AI (GenAI) to create videos sharing their disability experiences. Grounded in digital storytelling theory, the study explores the motivations, expression, and sharing of PwD-created GenAI story videos. The authors conclude with a framework of momentous depiction, highlighting four core affordances of GenAI that either facilitate or require improvements to better support disability storytelling: non-capturable depiction, identity concealment and representation, contextual realism and consistency, and emotional articulation. Based on this framework, the authors discuss design implications for GenAI in relation to story completion, media formats, and corrective mechanisms.",313.51,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12637v1_Topology-Aware Multiscale Mixture of Experts for E.pdf,Topology-Aware Multiscale Mixture of Experts for Efficient Molecular Property Prediction,"['Long D. Nguyen', 'Kelin Xia', 'Binh P. Nguyen']","Many molecular properties depend on 3D geometry, where non-covalent interactions, stereochemical effects, and medium- to long-range forces are determined by spatial distances and angles that cannot be uniquely captured by a 2D bond graph. Most 3D molecular graph neural networks still rely on globally fixed neighborhood heuristics to define local message-passing neighborhoods, leading to rigid, data-agnostic interaction budgets. We propose Multiscale Interaction Mixture of Experts (MI-MoE) to adapt interaction modeling across geometric regimes. Our contributions are threefold: (1) we introduce a distance-cutoff expert ensemble that explicitly captures short-, mid-, and long-range interactions without committing to a single cutoff; (2) we design a topological gating encoder that routes inputs to experts using filtration-based descriptors, including persistent homology features, summarizing how connectivity evolves across radii; and (3) we show that MI-MoE is a plug-in module that consistently improves multiple strong 3D molecular backbones across diverse molecular and polymer property prediction benchmark datasets, covering both regression and classification tasks. These results highlight topology-aware multiscale routing as an effective principle for 3D molecular graph learning.",314.88,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12638v1_Mixed Precision PointPillars for Efficient 3D Obje.pdf,Mixed Precision PointPillars for Efficient 3D Object Detection with TensorRT,"['1st Ninnart Fuengfusin', '2nd Keisuke Yoneda', '3rd Naoki Suganuma']","LIDAR 3D object detection is crucial for autonomous vehicles. The paper proposes a mixed precision framework for PointPillars to address the wide numerical distribution and extreme outliers in LIDAR data. The framework uses post-training quantization (PTQ) to identify sensitive layers and combines them with quantization-aware training (QAT) to improve performance. The authors also observe that using a small number of calibration data reduces the likelihood of encountering outliers, improving PTQ performance. The methods provide mixed precision models without training in the PTQ pipeline, while the QAT pipeline achieves performance competitive to FP models. With TensorRT deployment, the models offer reduced latency and sizes by up to 2.35 and 2.26 times, respectively.",313.41,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12641v1_STEP-LLM Generating CAD STEP Models from Natural L.pdf,"Computer-aided design (CAD) is vital to modern manufacturing, yet model creation remains labor-intensive and expertise-heavy. To enable non-experts to translate intuitive design intent into manufacturable artifacts, recent large language models (LLM)-based text-to-CAD efforts focus on command sequences or script-based formats like CadQuery. However, these formats are kernel-dependent and lack universality for manufacturing. In contrast, the Standard for the Exchange of Product Data (STEP, ISO 10303) file is a widely adopted, neutral boundary representation (B-rep) format directly compatible with manufacturing, but its graph-structured, cross-referenced nature poses unique challenges for auto-regressive LLMs. To address this, we curate a dataset of ∼40K STEP-caption pairs and introduce novel preprocessing tailored for the graph-structured format of STEP, including a depth-first search (DFS)-based reserialization that linearizes cross-references while preserving locality and chain-of-thought (CoT)-style structural annotations that explicitly guide global coherence. We integrate retrieval-augmented generation (RAG) to ground predictions in relevant examples for supervised fine-tuning (SFT), and further refine generation quality through reinforcement learning (RL) with a specific Chamfer Distance-based geometric reward. Experiments demonstrate consistent gains of our STEP-LLM in geometric fidelity over the Text2CAD baseline, with improvements arising from multiple stages of our framework: the RAG module substantially enhances completeness and renderability, the DFS-based reserialization strategy strengthens overall accuracy, and the RL refinement further reduces geometric discrepancy. Both metrics and visual comparisons confirm that STEP-LLM generates shapes with higher fidelity than Text2CAD. These results demonstrate the feasibility of LLM-driven STEP model generation from natural language, showing its potential to democratize CAD design for manufacturing.","['Xiangyu Shi', 'Junyang Ding', 'Xu Zhao', 'Sinong Zhan', 'Payal Mohapatra', 'Daniel Quispe', 'Kojo Welbeck', 'Jian Cao', 'Wei Chen', 'Ping Guo', 'Qi Zhu']","Computer-aided design (CAD) is vital to modern manufacturing, yet model creation remains labor-intensive and expertise-heavy. Recent large language models (LLM)-based text-to-CAD efforts focus on command sequences or script-based formats like CadQuery, but these formats are kernel-dependent and lack universality for manufacturing. In contrast, the Standard for the Exchange of Product Data (STEP, ISO 10303) file is a widely adopted, neutral boundary representation (B-rep) format directly compatible with manufacturing, but its graph-structured, cross-referenced nature poses unique challenges for auto-regressive LLMs. To address this, we curate a dataset of ∼40K STEP-caption pairs and introduce novel preprocessing tailored for the graph-structured format of STEP, including a depth-first search (DFS)-based reserialization that linearizes cross-references while preserving locality and chain-of-thought (CoT)-style structural annotations that explicitly guide global coherence. We integrate retrieval-augmented generation (RAG) to ground predictions in relevant examples for supervised fine-tuning (SFT), and further refine generation quality through reinforcement learning (RL) with a specific Chamfer Distance-based geometric reward. Experiments demonstrate consistent gains of our STEP-LLM in geometric fidelity over the Text2CAD baseline, with improvements arising from multiple stages of our framework: the RAG module substantially enhances completeness and renderability, the DFS-based reserialization strategy strengthens overall accuracy, and the RL refinement further reduces geometric discrepancy. Both metrics and visual comparisons confirm that STEP-LLM generates shapes with higher fidelity than Text2CAD. These results demonstrate the feasibility of LLM-driven STEP model generation from natural language, showing its potential to democratize CAD design for manufacturing.",312.85,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12646v1_Unbounded Harms Bounded Law Liability in the Age o.pdf,"Unbounded Harms, Bounded Law: Liability in the Age of Borderless AI",['Ha-Chi Tran'],"The rapid advancement of artificial intelligence (AI) has exposed significant deficiencies in existing risk governance frameworks. Despite substantial progress in ex ante harm identification and prevention, responsible AI scholarship remains underdeveloped in ex post risk governance. Core legal questions regarding compensation, mitigation, attribution of responsibility, liability allocation, and remedial mechanisms are inadequately theorized and underinstitutionalized, particularly in relation to transboundary AI harms, AI-induced risks, and damages that transcend national borders, legal jurisdictions, and regulatory authority. The paper draws on contemporary AI risk analyses to argue that such harms are structurally inherent to AI supply chains and are likely to increase in frequency and severity due to globalized deployment, cross-border data infrastructures, and asymmetric national capacities in AI development and oversight. The paper examines compensation and liability mechanisms from adjacent high-risk and transnational domains, including vaccine injury compensation, financial systemic risk governance, commercial nuclear energy liability, and international environmental harm regimes, to identify transferable legal design principles such as strict liability, pooled compensation mechanisms, and collective risk-sharing. The paper outlines the contours of a global AI compensation and accountability architecture, highlighting the tension between geopolitical rivalry and the collective action required to govern transboundary AI risk.",314.93,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12648v1_Intelligent Documentation in Medical Education Can.pdf,Intelligent Documentation in Medical Education: Can AI Replace Manual Case Logging?,"['Nafiz Imtiaz Khan', 'Kylie Cleland', 'Vladimir Filkov', 'Roger Eric Goldman']","This study investigates the feasibility of using large language models (LLMs) to automate procedural case log documentation in radiology training. The study retrospectively analyzed 414 curated radiology reports authored by nine interventional radiology residents between 2018 and 2024. Both local and commercial LLMs outperformed the standard benchmark, with Qwen-2.5 achieving F1-scores of 86.66 with chain-of-thought prompting and Claude-3.5-Haiku reaching an F1-score of 86.89%. Commercial inference delivered sub-2s latency and concise outputs, while local deployment traded speed for lower recurring cost. Automation could save over 35 hours of manual annotation per resident annually. The study concludes that LLMs show promise for automating radiology case log documentation, potentially reducing resident clerical burden, but emphasizes the need for broader validation across diverse institutions, assessment of real-world workflow integration, and safeguards against misclassification before clinical adoption.",313.24,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12654v1_Explanation Multiplicity in SHAP Characterization .pdf,Explanation Multiplicity in SHAP: Characterization and Assessment,"['HYUNSEUNG HWANG', 'KAIST, Republic of Korea', 'SEUNGEUN LEE', 'New York University, USA', 'LUCAS ROSENBLATT', 'New York University, USA', 'JULIA STOYANOVICH', 'New York University, USA', 'STEVEN EUIJONG WHANG', 'KAIST, Republic of Korea']","Post-hoc explanations are widely used in high-stakes domains such as lending, employment, and healthcare to justify and contest automated decisions. SHAP is a popular method for providing feature attributions, but it can produce different explanations for the same decision, a phenomenon known as explanation multiplicity. This paper presents a methodology to characterize and assess explanation multiplicity, showing that it is widespread and persists even under controlled conditions. The authors derive randomized baseline values to provide a principled reference point for interpreting explanation disagreement, demonstrating that explanation instability is a normative concern and that explanation practices must be evaluated using metrics and baselines aligned with their intended societal role.",314.49,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12658v1_Augmenting Question Answering with A Hybrid RAG Ap.pdf,Augmenting Question Answering with A Hybrid RAG Approach,"['Tianyi Yang', 'Nashrah Haque', 'Vaishnave Jonnalagadda', 'Yuya Jeremy Ong', 'Zhehui Chen', 'Yanzhao Wu', 'Lei Yu', 'Divyesh Jadav', 'Wenqi Wei']","Retrieval-Augmented Generation (RAG) has emerged as a powerful technique for enhancing the quality of responses in Question-Answering (QA) tasks. However, existing approaches often struggle with retrieving contextually relevant information, leading to incomplete or suboptimal answers. This paper introduces Structured-Semantic RAG (SSRAG), a hybrid architecture that integrates query augmentation, agentic routing, and a structured retrieval mechanism combining vector and graph-based techniques with context unification. By refining retrieval processes and improving contextual grounding, SSRAG improves both answer accuracy and informative-ness. Extensive evaluations on three popular QA datasets (TruthfulQA, SQuAD, WikiQA) across five Large Language Models (LLMs) demonstrate that SSRAG consistently improves response quality over standard RAG implementations.",312.07,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12661v1_MedConsultBench A Full-Cycle Fine-Grained Process-.pdf,"MedConsultBench: A Full-Cycle, Fine-Grained, Process-Aware Benchmark for Medical Consultation Agents","['Chuhan Qiao*', 'Jianghua Huang*', 'Daxing Zhao*', 'Ziding Liu', 'Yanjun Shen†', 'Bing Cheng', 'Wei Lin', 'Kai Wu']","Current evaluations of medical consultation agents often prioritize outcome-oriented tasks, overlooking the end-to-end process integrity and clinical safety essential for real-world practice. MedConsultBench introduces Atomic Information Units (AIUs) to track clinical information acquisition at a sub-turn level, enabling precise monitoring of how key facts are elicited through 22 fine-grained metrics. The benchmark evaluates uncertainty-aware yet concise inquiry while emphasizing medication regimen compatibility and the ability to handle realistic post-prescription follow-up Q&A via constraint-respecting plan revisions. Systematic evaluation of 19 large language models reveals significant deficiencies in information-gathering efficiency and medication safety, underscoring a critical gap between theoretical medical knowledge and clinical practice ability. MedConsultBench establishes a rigorous foundation for aligning medical AI with the nuanced requirements of real-world clinical care.",312.32,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12664v1_Generalizable Hyperparameter Optimization for Fede.pdf,Generalizable Hyperparameter Optimization for Federated Learning on Non-IID Cancer Images,"['Elisa Gonçalves Ribeiro', 'Rodrigo Moreira', 'Larissa Ferreira Rodrigues Moreira', 'André Ricardo Backes']","This paper examines whether hyperparameters optimized on one cancer imaging dataset generalize across non-IID federated scenarios. It considers binary histopathology tasks for ovarian and colorectal cancers and performs centralized Bayesian hyperparameter optimization. The main contribution is a simple cross-dataset aggregation heuristic that combines configurations by averaging learning rates and considering modal optimizers and batch sizes, achieving competitive classification performance.",314.62,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12667v1_Empowering All-in-Loop Health Management of Spacec.pdf,Empowering All-in-Loop Health Management of Spacecraft Power System in the Mega-Constellation Era via Human-AI Collaboration,"['Yi Di 1,2', 'Zhibin Zhao 1,2,5∗', 'Fujin Wang 3', 'Xue Liu 4', 'Jiafeng Tang 1,2', 'Jiaxin Ren 1,2', 'Zhi Zhai 1,2∗∗', 'Xuefeng Chen 1,2']","This work proposes a principle of aligning underlying capabilities (AUC principle) and develops SpaceHMchat, an open-source Human-AI collaboration (HAIC) framework for all-in-loop health management (AIL HM) of spacecraft power systems (SPS). SpaceHMchat serves across the entire loop of work condition recognition, anomaly detection, fault localization, and maintenance decision making, achieving goals such as conversational task completion, adaptive human-in-the-loop learning, personnel structure optimization, knowledge sharing, efficiency enhancement, transparent reasoning, and improved interpretability. A hardware-realistic fault injection experimental platform is established, and its simulation model is built and open-sourced, fully replicating the real SPS. The corresponding experimental results demonstrate excellent performance across 23 quantitative metrics, such as 100% conclusion accuracy in logical reasoning of work condition recognition, over 99% success rate in anomaly detection tool invocation, over 90% precision in fault localization, and knowledge base search time under 3 minutes in maintenance decision-making. Another contribution is the release of the first-ever AIL HM dataset of SPS, containing four sub-datasets, involving 4 types of AIL HM sub-tasks, 17 types of faults, and over 700,000 timestamps.",312.96,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12671v1_Exploiting Test-Time Augmentation in Federated Lea.pdf,Exploiting Test-Time Augmentation in Federated Learning for Brain Tumor MRI Classification,"['Thamara Leandra de Deus Melo', 'Rodrigo Moreira', 'Larissa Ferreira Rodrigues Moreira', 'André R. Backes']","Efficient brain tumor diagnosis is crucial for early treatment; however, it is challenging due to lesion variability and image complexity. We evaluated convolutional neural networks (CNNs) in a federated learning (FL) setting, comparing models trained on original versus preprocessed MRI images (resizing, grayscale conversion, normalization, filtering, and histogram equalization). Preprocessing alone yielded negligible gains; combined with test-time augmentation (TTA), it delivered consistent, statistically significant improvements in federated MRI classification (p<0.001). In practice, TTA should be the default inference strategy in FL-based medical imaging; when the computational budget permits, pairing TTA with light preprocessing provides additional reliable gains.",312.99,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12688v1_Logic-Guided Multistage Inference for Explainable .pdf,Logic-Guided Multistage Inference for Explainable Multidefendant Judgment Prediction,"['Xu Zhang', 'Qinghua Wang', 'Mengyang Zhao', 'Fang Wang', 'Cunquan Qu']","Crime disrupts societal stability, making law essential for balance. In multidefendant cases, assigning responsibility is complex and challenges fairness, requiring precise role differentiation. However, judicial phrasing often obscures the roles of the defendants, hindering effective AI-driven analyses. To address this issue, the authors incorporate sentencing logic into a pretrained Transformer encoder framework to enhance the intelligent assistance in multidefendant cases while ensuring legal interpretability. Within this framework, an oriented masking mechanism clarifies roles, and a comparative data construction strategy improves the model's sensitivity to culpability distinctions between principals and accomplices. Predicted guilt labels are further incorporated into a regression model through broadcasting, consolidating crime descriptions and court views. The proposed masked multistage inference (MMSI) framework, evaluated on the custom IMLJP dataset for intentional injury cases, achieves significant accuracy improvements, outperforming baselines in role-based culpability differentiation. This work offers a robust solution for enhancing intelligent judicial systems, with publicly code available.",313.25,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12711v1_Neurosymbolic LoRA Why and When to Tune Weights vs.pdf,Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts,"['Kevin Wang', 'Neel P. Bhatt', 'Cong Liu', 'Junbo Li', 'Runjin Chen', 'Yihan Xi', 'Timothy Barclay', 'Alvaro Velasquez', 'Ufuk Topcu', 'Zhangyang Wang']","Large language models (LLMs) can be adapted through numerical updates that alter model parameters or symbolic manipulations that work on discrete prompts or logical constraints. This paper introduces a neurosymbolic LoRA framework that dynamically combines these two complementary strategies. Specifically, a unified monitoring signal and a reward-based classifier are presented to decide when to employ LoRA for deeper factual reconstruction and when to apply TextGrad for token-level edits. The approach remains memory-efficient by offloading symbolic transformations to an external LLM only when needed. Additionally, refined prompts produced during symbolic editing serve as high-quality, reusable training data, an important benefit in data-scarce domains like mathematical reasoning. Extensive experiments across multiple LLM backbones show that neurosymbolic LoRA consistently outperforms purely numerical or purely symbolic baselines, demonstrating superior adaptability and improved performance. The findings highlight the value of interleaving numerical and symbolic updates to unlock a new level of versatility in language model fine-tuning.",308.49,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12715v1_RSOD Reliability-Guided Sonar Image Object Detecti.pdf,RSOD: Reliability-Guided Sonar Image Object Detection with Extremely Limited Labels,"['Chengzhou Li', 'Ping Guo', 'Guanchen Meng', 'Qi Jia*', 'Jinyuan Liu', 'Zhu Liu', 'Xiaokang Liu', 'Yu Liu', 'Zhongxuan Luo', 'Xin Fan*']","Object detection in sonar images is challenging due to fewer texture details and susceptibility to noise. This paper proposes RSOD, a teacher-student framework aiming to learn sonar image characteristics and develop pseudo-label strategies for limited labeled data. RSOD calculates a reliability score and introduces an object mixed pseudo-label method. It optimizes student performance with a reliability-guided adaptive constraint, achieving competitive results even with 5% labeled data compared to 100% labeled data. The method also leverages unlabeled data, making it suitable for underwater tasks.",310.13,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12720v1_Teaching Large Reasoning Models Effective Reflecti.pdf,Teaching Large Reasoning Models Effective Reflection,"['Hanbin Wang', 'Jingwei Song', 'Jinpeng Li', 'Qi Zhu', 'Fei Mi', 'Ganqu Cui', 'Yasheng Wang', 'Lifeng Shang']","Large Reasoning Models (LRMs) have shown impressive performance on complex reasoning tasks, often engaging in self-reflective behaviors such as self-critique and backtracking. However, not all reflections are beneficial, as many are superficial and offer little improvement over the original answer. This paper identifies and addresses the problem of superficial reflection in LRMs. It proposes Self-Critique Fine-Tuning (SCFT) and Reinforcement Learning with Effective Reflection Rewards (RLERR). Experiments on two challenging benchmarks, AIME2024 and AIME2025, show that SCFT and RLERR significantly improve both reasoning accuracy and reflection quality, outperforming state-of-the-art baselines.",306.37,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12723v1_An Evolutionary Framework for Automatic Optimizati.pdf,An Evolutionary Framework for Automatic Optimization Benchmark Generation via Large Language Models,"['Yuhiro Ono', 'Tomohiro Harada', 'Yukiya Miura']","Optimization benchmarks are crucial for assessing algorithm performance, but existing benchmarks often fail to capture real-world problem diversity and irregularity. This paper proposes an evolutionary framework using a large language model (LLM) to generate benchmarks. The LLM-driven evolutionary benchmark generator (LLM-EBG) creates and evolves benchmark problems within a flexible representation space. A case study demonstrates that LLM-EBG successfully generates problems where a genetic algorithm consistently outperforms a differential evolution algorithm in over 80% of trials. Exploratory landscape analysis reveals that benchmarks favoring genetic algorithms are sensitive to variable scaling, indicating the framework's ability to produce problems reflecting different optimization algorithm behaviors.",310.52,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12727v1_AI-exhibited Personality Traits Can Shape Human Se.pdf,AI-exhibited Personality Traits Can Shape Human Self-concept through Conversations,"['Jingshu Li', 'Tianqi Song', 'Nattapat Boonprakong', 'Zicheng Zhu', 'Yitian Yang', 'Yi-Chieh Lee']","Recent Large Language Model (LLM) based AI can exhibit recognizable and measurable personality traits during conversations to improve user experience. However, as human understandings of their personality traits can be affected by their interaction partners' traits, a potential risk is that AI traits may shape and bias users' self-concept of their own traits. To explore this possibility, we conducted a randomized behavioral experiment. Our results indicate that after conversations with the same AI, each individual's self-concept becomes aligned with the AI's measured personality traits, leading to increased homogeneity of self-concepts across individuals.",311.39,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12731v1_A Shared Geometry of Difficulty in Multilingual La.pdf,A Shared Geometry of Difficulty in Multilingual Language Models,"['Stefano Civelli', 'Pietro Bernardelle', 'Nicolò Brunello', 'Gianluca Demartini']","This work investigates the multilingual geometry of problem-difficulty in large language models (LLMs) by training linear probes on the AMC subset of the Easy2Hard benchmark, translated into 21 languages. The study finds that difficulty-related signals emerge at two distinct stages of the model internals, corresponding to shallow (early-layers) and deep (later-layers) internal representations. Probes trained on deep representations achieve high accuracy within the same language but exhibit poor cross-lingual generalization. In contrast, probes trained on shallow representations generalize better across languages, despite achieving lower within-language performance. These results suggest that LLMs first form a language-agnostic representation of problem difficulty, which subsequently becomes language-specific. The findings align with existing research in LLM interpretability, indicating that models operate in an abstract conceptual space before producing language-specific outputs. The study demonstrates that this two-stage representational process extends beyond semantic content to high-level meta-cognitive properties such as problem-difficulty estimation.",312.26,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12740v1_TreeWriter AI-Assisted Hierarchical Planning and W.pdf,TreeWriter: AI-Assisted Hierarchical Planning and Writing for Long-Form Documents,"['Zijian Zhang', 'Fangshi Du', 'Xingjian Liu', 'Pan Chen', 'Oliver Huang', 'Runlong Ye', 'Michael Liut', 'Alán Aspuru-Guzik']","Long documents pose many challenges to current intelligent writing systems, including maintaining consistency across sections, sustaining efficient planning and writing as documents become more complex, and effectively providing and integrating AI assistance to the user. Existing AI co-writing tools offer either inline suggestions or limited structured planning, but rarely support the entire writing process that begins with high-level ideas and ends with polished prose, in which many layers of planning and outlining are needed. TreeWriter, a hierarchical writing system, represents documents as trees and integrates contextual AI support, allowing authors to create, save, and refine document outlines at multiple levels. A built-in AI agent can dynamically load relevant content, navigate the document hierarchy, and provide context-aware editing suggestions. A within-subject study comparing TreeWriter with Google Docs + Gemini on long-document editing and creative writing tasks shows that TreeWriter improves idea exploration/development, AI helpfulness, and perceived authorial control. A two-month field deployment further demonstrated that hierarchical organization supports collaborative writing. The findings highlight the potential of hierarchical, tree-structured editors with integrated AI support and provide design guidelines for future AI-assisted writing tools that balance automation with user agency.",308.68,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12742v1_AirHunt Bridging VLM Semantics and Continuous Plan.pdf,AirHunt: Bridging VLM Semantics and Continuous Planning for Efficient Aerial Object Navigation,"['Xuecheng Chen', 'Zongzhuo Liu', 'Jianfa Ma', 'Bang Du', 'Tiantian Zhang', 'Xueqian Wang', 'Boyu Zhou']","Recent advances in large Vision-Language Models (VLMs) have enabled drones to search for open-set objects via natural language instructions. However, integrating VLMs into practical aerial systems is challenging due to frequency mismatch and limited 3D scene understanding. AirHunt addresses these challenges by seamlessly fusing VLM semantic reasoning with continuous path planning. It features a dual-pathway asynchronous architecture and an active dual-task reasoning module to enable selective VLM querying and dynamic semantic-geometric coherent planning. The system demonstrates higher success rates and reduced flight time compared to state-of-the-art methods, validated through diverse object navigation tasks and environments.",309.61,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12744v1_Vision Language Models for Optimization-Driven Int.pdf,Vision Language Models for Optimization-Driven Intent Processing in Autonomous Networks,"['Tasnim Ahmed', 'Yifan Zhu', 'Salimur Choudhury']","Intent-Based Networking (IBN) allows operators to specify high-level network goals rather than low-level configurations. Recent work shows that large language models can automate configuration tasks. However, a distinct class of intents requires generating optimization code to compute provably optimal solutions. Current systems assume text-based intent expression, requiring operators to enumerate topologies and parameters in prose. This paper presents IntentOpt, a benchmark of 85 optimization problems across 17 categories, evaluating four Vision-Language Models (GPT-5-Mini, Claude-Haiku-4.5, Gemini-2.5-Flash, Llama-3.2-11B-Vision) under three prompting strategies on multimodal versus text-only inputs. The evaluation shows that visual parameter extraction reduces execution success by 12–21 percentage points, with GPT-5-Mini dropping from 93% to 72%. Program-of-thought prompting decreases performance by up to 13 percentage points, and open-source models lag behind closed-source ones. Practical feasibility is demonstrated through a case study that deploys VLM-generated code to network testbed infrastructure using Model Context Protocol.",312.22,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12745v1_A Graph Prompt Fine-Tuning Method for WSN Spatio-T.pdf,A GraphA PromptA Fine-TuningA MethodA forSpatio-TemporalACorrelationA nomalyADetection,"['Miao Ye', 'Jing Cui', 'Yuan Huang', 'Yong Wang', 'Qian He', 'Jiwen Zhang']","Anomaly detection of multi-temporal modal data in Wireless Sensor Network (WSN) can provide an important guarantee for reliable network operation. Existing methods have problems of insufficient extraction of spatio-temporal correlation features, high cost of anomaly sample category annotation, and imbalance of anomaly samples. This paper designs a graph neural network anomaly detection backbone network incorporating spatio-temporal correlation features and a multi-task self-supervised training strategy of 'pre-training-graph prompting-fine-tuning'. The model is fine-tuned to reduce training cost and enhance detection generalization performance. Experiments on public and actual datasets show F1 metrics up to 91.30% and 92.31%, respectively, providing better detection performance and generalizability than existing methods.",314.69,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12754v1_PAIR-SAFE A Paired-Agent Approach for Runtime Audi.pdf,PAIR-SAFE: A Paired-Agent Approach for Runtime Auditing and Refining,"['Jiwon Kim', 'Violeta J. Rodriguez', 'Dong Whi Yoo', 'Eshwar Chandrasekharan', 'Koustuv Saha']","Large language models (LLMs) are increasingly used for mental health support, but they can produce responses that are overly directive, inconsistent, or clinically misaligned, particularly in sensitive or high-risk contexts. Existing approaches to mitigating these risks largely rely on implicit alignment through training or prompting, offering limited transparency and runtime accountability. We introduce PAIR-SAFE, a paired-agent framework for auditing and refining AI-generated mental health support that integrates a Responder agent with a supervisory Judge agent grounded in the clinically validated Motivational Interviewing Treatment Integrity (MITI-4) framework. The Judge audits each response and provides structured ALLOW or REVISE decisions that guide runtime response refinement. We simulate counseling interactions using a support-seeker simulator derived from human-annotated motivational interviewing data. Our findings show that Judge-supervised interactions show significant improvements in key MITI dimensions, including Partnership, Seek Collaboration, and overall Relational quality. Our quantitative findings are supported by qualitative expert evaluation, which further highlights the nuances of runtime supervision. Together, our results reveal that such a paired-agent approach can provide clinically grounded auditing and refinement for AI-assisted conversational mental health support.",308.58,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12758v1_VISPA Pluralistic Alignment via Automatic Value Se.pdf,VISPA: Pluralistic Alignment via Automatic Value Selection and Activation,"['Shenyan Zheng', 'Jiayou Zhong', 'Anudeex Shetty', 'Heng Ji', 'Preslav Nakov', 'Usman Naseem']","As large language models are increasingly used in high-stakes domains, achieving pluralism in their outputs is challenging. Existing approaches consider limited values or rely on prompt-level interventions, lacking value control and representation. To address this, VISPA introduces a training-free pluralistic alignment framework that enables direct control over value expression by dynamic selection and internal model activation steering. Across extensive empirical studies, VISPA shows performant results across all pluralistic alignment modes in healthcare and beyond, demonstrating adaptability with different steering initiations, models, and values. These results suggest that pluralistic alignment can be achieved through internal activation mechanisms, offering a scalable path toward language models that serve all.",311.09,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12762v1_Teaching LLMs to Learn Tool Trialing and Execution.pdf,Teaching LLMs to Learn Tool Trialing and Execution through Environment Interaction,"['Xingjie Gao', 'Pengcheng Huang', 'Zhenghao Liu', 'Yukun Yan', 'Shuo Wang', 'Zulong Chen', 'Chen Qian', 'Ge Yu', 'Yu Gu']","Equipping Large Language Models (LLMs) with external tools enables them to solve complex real-world problems. However, existing methods struggle with novel or evolving tools. This paper introduces ToolMaster, a framework that shifts tool use from imitating static solution paths to actively learning through interaction with the environment. ToolMaster adopts a trial-and-execution paradigm, training LLMs to first imitate teacher-generated trajectories containing explicit tool trials and self-correction, followed by reinforcement learning to coordinate the trial and execution phases. Experimental results demonstrate that ToolMaster significantly outperforms existing baselines in terms of generalization and robustness across unseen or unfamiliar tools.",309.08,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12781v1_VIRO Robust and Efficient Neuro-Symbolic Reasoning.pdf,VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension,"['Hyejin Park', 'Junhyuk Kwon', 'Suha Kwak', 'Jungseul Ok']","Referring Expression Comprehension (REC) aims to localize the image region corresponding to a natural-language query. Recent neuro-symbolic REC approaches leverage large language models (LLMs) and vision-language models (VLMs) to perform compositional reasoning, decomposing queries into structured programs and executing them step-by-step. While such approaches achieve interpretable reasoning and strong zero-shot generalization, they assume that intermediate reasoning steps are accurate, leading to cascading errors. To address this limitation, the authors introduce Verification-Integrated Reasoning Operators (VIRO), a neuro-symbolic framework that embeds lightweight operator-level verifiers within reasoning steps. Each operator executes and validates its output, allowing the system to robustly handle no-target cases when verification conditions are not met. The framework achieves state-of-the-art performance, reaching 61.1% balanced accuracy across target-present and no-target settings, and demonstrates generalization to real-world egocentric data. Furthermore, VIRO shows superior computational efficiency in terms of throughput, high reliability with a program failure rate of less than 0.3%, and scalability through decoupled program generation from execution.",308.93,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12785v1_Distilling Time Series Foundation Models for Effic.pdf,DISTILLING TIME SERIES FOUNDATION MODELS FOR EFFICIENT FORECASTING,"['Yuqi Li', 'Kuiye Ding', 'Chuanguang Yang', 'Szu-Yu Chen', 'Yingli Tian']","Time Series foundation models (TSFMs) deliver strong forecasting performance through large-scale pretraining, but their large parameter sizes make deployment costly. While knowledge distillation offers a natural and effective approach for model compression, techniques developed for general machine learning tasks are not directly applicable to time series forecasting due to the unique characteristics. To address this, we present DistilTS, the first distillation framework specifically designed for TSFMs. DistilTS addresses two key challenges: task difficulty discrepancy, specific to forecasting, and architecture discrepancy. It introduces horizon-weighted objectives to balance learning across horizons and a temporal alignment strategy to reduce architectural mismatch, enabling compact models. Experiments on multiple benchmarks demonstrate that DistilTS achieves forecasting performance comparable to full-sized TSFMs, while reducing parameters by up to 1/150 and accelerating inference by up to 6000×.",309.82,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12804v1_SL-CBM Enhancing Concept Bottleneck Models with Se.pdf,SL-CBM: Enhancing Concept Bottleneck Models with Semantic Locality for Better Interpretability,"['Hanwei Zhang', 'Luo Cheng', 'Rui Wen', 'Yang Zhang', 'Lijun Zhang', 'Holger Hermanns']","SL-CBM is a novel extension of Concept Bottleneck Models (CBMs) that enhances locality faithfulness by generating spatially coherent saliency maps at both concept and class levels. It integrates a1×1convolutional layer with a cross-attention mechanism to improve alignment between concepts, image regions, and final predictions. Unlike prior methods, SL-CBM produces faithful saliency maps inherently tied to the model's internal reasoning, facilitating more effective debugging and intervention. Extensive experiments on image datasets demonstrate that SL-CBM substantially improves locality faithfulness, explanation quality, and intervention efficacy while maintaining competitive classification accuracy. Ablation studies highlight the importance of contrastive and entropy-based regularization for balancing accuracy, sparsity, and faithfulness. Overall, SL-CBM bridges the gap between concept-based reasoning and spatial explainability, setting a new standard for interpretable and trustworthy concept-based models.",308.89,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12805v1_SciHorizon-GENE Benchmarking LLM for Life Sciences.pdf,SciHorizon-Gene: Benchmarking LLM for Life Sciences Inference from Gene Knowledge to Functional Understanding,"['Xiaohan Huang', 'Meng Xiao', 'Chuan Qin', 'Qingqing Long', 'Jinmiao Chen', 'Yuanchun Zhou', 'Hengshu Zhu']","Large language models (LLMs) have shown promise in biomedical research, particularly for knowledge-driven interpretation tasks. However, their ability to reliably reason from gene-level knowledge to functional understanding remains largely underexplored. To address this gap, we introduce SciHorizon-Gene, a large-scale gene-centric benchmark constructed from authoritative biological databases. The benchmark evaluates LLMs along four biologically critical perspectives: research attention sensitivity, hallucination tendency, answer completeness, and literature influence, explicitly targeting failure modes that limit the safe adoption of LLMs in biological interpretation pipelines. We systematically evaluate a wide range of state-of-the-art general-purpose and biomedical LLMs, revealing substantial heterogeneity in gene-level reasoning capabilities and persistent challenges in generating faithful, complete, and literature-grounded functional interpretations. Our benchmark establishes a systematic foundation for analyzing LLM behavior at the gene scale and offers insights for model selection and development, with direct relevance to knowledge-enhanced biological interpretation.",308.56,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12809v1_Left-Right Symmetry Breaking in CLIP-style Vision-.pdf,Left–Right Symmetry Breaking in CLIP-style Vision-Language Models Trained on Synthetic Spatial-Relation Data,"['Takaki Yamamoto', 'Chihiro Noguchi', 'Toshihiro Tanizawa']","Spatial understanding remains a key challenge in vision-language models. The authors present a controllable 1D image-text testbed to probe how left-right relational understanding emerges in Transformer-based vision and text encoders trained with a CLIP-style contrastive objective. They find that contrastive training learns left-right relations and that label diversity, more than layout diversity, is the primary driver of generalization in this setting. To gain mechanistic understanding, they perform an attention decomposition and show that interactions between positional and token embeddings induce a horizontal attention gradient that breaks left-right symmetry in the encoders. Ablating this contribution substantially reduces left-right discrimination. The results provide a mechanistic insight into when and how CLIP-style models acquire relational competence.",312.96,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12816v1_Fisher-Orthogonal Projected Natural Gradient Desce.pdf,Fisher-Orthogonal Projected Natural Gradient Descent for Continual Learning,"['Ishir Garg', 'Neel Kolhe', 'Andy Peng', 'Rohan Gopalam']","Continual learning aims to enable neural networks to acquire new knowledge on sequential tasks without catastrophic forgetting. The paper proposes the Fisher-Orthogonal Projected Natural Gradient Descent (FOPNG) optimizer, which enforces Fisher-orthogonal constraints on parameter updates to preserve old task performance while learning new tasks. Unlike existing methods that operate in Euclidean parameter space, FOPNG projects gradients onto the Fisher-orthogonal complement of previous task gradients. This approach unifies natural gradient descent with orthogonal gradient methods within an information-geometric framework. The resulting update direction is invariant under reparameterization, guarantees descent in the Fisher metric, and helps preserve prior task outputs. The paper provides theoretical analysis, describes efficient implementations using the diagonal Fisher, and demonstrates strong results on standard continual learning benchmarks.",314.29,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12822v1_MirrorGuard Toward Secure Computer-Use Agents via .pdf,MirrorGuard: Toward Secure Computer-Use Agents via Simulation-to-Real Reasoning Correction,"['Wenqi Zhang', 'Yulin Shen', 'Changyue Jiang', 'Jiarun Dai', 'Geng Hong']","Large foundation models are integrated into Computer Use Agents (CUAs) to enable autonomous interaction with operating systems through graphical user interfaces (GUIs) for complex tasks. This autonomy introduces serious security risks, as malicious instructions or visual prompt injections can trigger unsafe reasoning and cause harmful system-level actions. Existing defenses, such as detection-based blocking, prevent damage but often abort tasks prematurely, reducing agent utility. This paper presents MirrorGuard, a plug-and-play defense framework that uses simulation-based training to improve CUA security in the real world. MirrorGuard generates realistic, high-risk GUI interaction trajectories in a text-based simulated environment, capturing unsafe reasoning patterns and potential system hazards without executing real operations. It learns to intercept and rectify insecure reasoning chains of CUAs before they produce and execute unsafe actions. Extensive evaluations across diverse benchmarks and CUA architectures show that MirrorGuard significantly mitigates security risks, reducing the unsafe rate from 66.5% to 13.0% on the ByteDance UI-TARS system while maintaining a marginal false refusal rate (FRR). The state-of-the-art GuardAgent achieves a reduction to 53.9% but suffers from a 15.4% higher FRR. Our work proves that simulation-derived defenses can provide robust, real-world protection while maintaining the fundamental utility of the agent. The code and model are publicly available at https://bmz-q-q.github.io/MirrorGuard.",308.52,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12837v1_Cognition spaces natural artificial and hybrid.pdf,"Cognition spaces: natural, artificial, and hybrid","['Ricard Solé', 'Luis F Seoane', 'Jordi Pla-Mauri', 'Michael Timothy Bennett', 'Michael E. Hochberg', 'Michael Levin']","Cognitive processes are realized across natural, artificial, and hybrid systems. This paper proposes a cognition space approach to compare their forms, limits, and unrealized possibilities. Three cognition spaces—basal aneural, neural, and human–AI hybrid—are introduced and examined. The authors argue that the uneven occupation of these spaces reflects evolutionary contingencies, physical constraints, and design limitations. By focusing on the structure of cognition spaces, this approach clarifies the diversity of existing cognitive systems and highlights hybrid cognition as a promising frontier for exploring novel forms of complexity.",309.75,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12842v1_SCULPT Constraint-Guided Pruned MCTS that Carves E.pdf,SCULPT: Constraint-Guided Pruned MCTS that Carves Efficient Paths for Mathematical Reasoning,"['Qitong Fang*', 'Haotian Li†', 'Xu Wang‡']","Automated agent workflows can enhance the problem-solving ability of large language models (LLMs), but common search strategies rely on stochastic exploration and often traverse implausible branches. This paper introduces SCULPT, a constraint-guided approach for Monte Carlo Tree Search (MCTS) that integrates domain-aware scoring into selection, expansion, simulation, and backpropagation. SCULPT scores and prunes actions using a combination of symbolic checks (dimensional consistency, type compatibility, magnitude sanity, depth control, and diversity) and structural pattern guidance, thereby steering the search toward plausible reasoning paths. Under matched LLM configurations, SCULPT yields stable improvements on multiple datasets; additional results with GPT-5.2 assess executor transferability and performance on frontier reasoning models. Overall, domain-aware constraints can improve accuracy while maintaining efficiency and reasoning stability.",320.7,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12849v1_The Cost of EFX Generalized-Mean Welfare and Compl.pdf,The Cost of EFX: Generalized-Mean Welfare and Complexity Dichotomies with Few Surplus Items,"['Eugene Lim', 'Tzeh Yuan Neoh', 'Nicholas Teh']","The paper studies the interaction between envy-freeness up to any good (EFX) and generalized-mean (p-mean) welfare in the setting with few surplus items. It establishes sharp complexity dichotomies at p=0, showing that deciding whether EFX can attain the global p-mean optimum and computing an EFX allocation maximizing p-mean welfare are NP-hard. For p≤0, polynomial-time algorithms are provided to optimize p-mean welfare within the space of EFX allocations and efficiently certify when EFX attains the global optimum. The paper also quantifies the welfare loss of enforcing EFX via the price of fairness framework and shows that requiring Pareto-optimality alongside EFX is NP-hard. Overall, the results delineate when EFX is computationally costly versus structurally aligned with welfare maximization in the setting with few surplus items.",308.92,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12856v1_Mining Citywide Dengue Spread Patterns in Singapor.pdf,Mining Citywide Dengue Spread Patterns in Singapore Through Hotspot Dynamics from Open Web Data,"['Liping Huang', 'Gaoxi Xiao', 'Stefan Ma', 'Hechang Chen', 'Shisong Tang', 'Flora Salim']","This study introduces a novel framework that uncovers and exploits latent transmission links between urban regions, mined directly from publicly available dengue case data. Instead of treating cases as isolated reports, the model models how hotspot formation in one area is influenced by epidemic dynamics in neighboring regions. The learned network aligns closely with commuting flows, providing an interpretable explanation for citywide spread. These hidden links are optimized through gradient descent and used to forecast hotspot status and verify the consistency of spreading patterns. The model achieves an average F-score of 0.79 even under severe mobility disruptions due to the COVID-19 'circuit breaker', with an F-score of 0.83. The learned transmission links align with commuting flows, highlighting the interpretable interplay between hidden epidemic spread and human mobility. This work transforms open web-based case data into a predictive and explanatory resource, advancing epidemic modeling and providing a scalable, low-cost tool for public health planning, early intervention, and urban resilience.",309.02,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12879v1_Hierarchical Sparse Circuit Extraction from Billio.pdf,Hierarchical Sparse Circuit Extraction from Billion-Parameter Language Models through Scalable Attribution Graph Decomposition,"['Mohammed Mudassir Uddin', 'Shahnawaz Alam', 'Mohammed Kaif Pasha']","The proposed Hierarchical Attribution Graph Decomposition (HAGD) framework reduces circuit discovery complexity from O(2^n) exhaustive enumeration to O(n^2 log n) through multi-resolution abstraction hierarchies and differentiable circuit search. The methodology integrates cross-layer transcoders for monosemantic feature extraction, graph neural network meta-learning for topology prediction, and causal intervention protocols for validation. Empirical evaluation spans GPT-2 variants, Llama-7B through Llama-70B, and Pythia suite models across algorithmic tasks and natural language benchmarks. On modular arithmetic tasks, the framework achieves up to 91% behavioral preservation (±2.3% across runs) while maintaining interpretable subgraph sizes. Cross-architecture transfer experiments suggest that discovered circuits exhibit moderate structural similarity (averaging 67%) across model families, indicating potential shared computational patterns. These results provide preliminary foundations for interpretability at larger model scales while identifying significant limitations in current attribution methodologies that require future advances.",313.86,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12882v1_YOLO26 An Analysis of NMS-Free End to End Framewor.pdf,YOLO26: AN ANALYSIS OF NMS-FREE END-TO-END FRAMEWORK FOR REAL-TIME OBJECT DETECTION,['Sudip Chakrabarty'],"The 'You Only Look Once' (YOLO) framework has long served as the benchmark for real-time object detection, yet traditional iterations remain constrained by the latency and hyperparameter sensitivity of Non-Maximum Suppression (NMS) post-processing. This paper analyzes YOLO26, an architecture that fundamentally redefines this paradigm by eliminating NMS in favor of a native end-to-end learning strategy. The study examines critical innovations, including the MuSGD optimizer for stabilizing lightweight backbones, STAL for small-target-aware assignment, and ProgLoss for dynamic supervision. Through systematic review of official performance benchmarks, the results demonstrate that YOLO26 establishes a new Pareto front, outperforming a comprehensive suite of predecessors and state-of-the-art competitors in both inference speed and detection accuracy. The analysis confirms that by decoupling representation learning from heuristic post-processing, YOLOv26 successfully resolves the historical trade-off between latency and precision, signaling the next evolutionary step in edge-based computer vision.",326.08,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12886v1_Communication Methods in Multi-Agent Reinforcement.pdf,Communication Methods in Multi-Agent Reinforcement Learning,['Christoph Wittner'],"Multi-agent reinforcement learning is a promising research area that extends established reinforcement learning approaches to problems formulated as multi-agent systems. Recently, a multitude of communication methods have been introduced to address issues such as partially observable environments, non-stationarity, and exponentially growing action spaces. This work provides an overview of communication techniques in multi-agent reinforcement learning, evaluating the strengths and weaknesses of explicit, implicit, attention-based, graph-based, and hierarchical/role-based communication. The results show that there is no general, optimal communication framework for every problem, and the choice of communication depends heavily on the problem at hand. The comparison highlights the importance of communication methods with low computational overhead for scalability. The paper also discusses current research gaps, emphasizing the need for standardized benchmarking of system-level metrics and improved robustness under realistic communication conditions.",329.87,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12893v1_AdaNODEs Test Time Adaptation for Time Series Fore.pdf,ADANODES: TEST TIME ADAPTATION FOR TIME SERIES FORECASTING USING NEURAL ODES,"['Ting Dang', 'Soumyajit Chatterjee', 'Hong Jia', 'Yu Wu', 'Flora Salim', 'Fahim Kawsar']","This paper presents AdaNODEs, an innovative source-free test time adaptation (TTA) method tailored explicitly for time series forecasting. By leveraging Neural Ordinary Differential Equations (NODEs), the authors propose a novel adaptation framework that accommodates the unique characteristics of distribution shifts in time series data. Additionally, a new loss function is proposed to tackle TTA for forecasting tasks. AdaNODEs only requires updating limited model parameters, showing effectiveness in capturing temporal dependencies while avoiding significant memory usage. Extensive experiments with one- and high-dimensional data demonstrate relative improvements of 5.88% and 28.4% over the state-of-the-art (SOTA) baselines, especially demonstrating robustness across higher severity distribution shifts.",330.08,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12904v1_From Prefix Cache to Fusion RAG Cache Accelerating.pdf,From Prefix Cache to Fusion RAG Cache: Accelerating LLM Inference in Retrieval-Augmented Generation,"['Jiaha Wang', 'Wei Yu Xie', 'Ming Xing Zhang', 'Boxing Zhang', 'Jian Wei Dong', 'Yuening Zhu', 'Chen Lin', 'Jinqi Tang', 'Yao Chen Han', 'Zhi Yuan Ai', 'Xiang Lin Chen', 'Yong Wei Wu', 'Cong Feng Jiang']","Retrieval-Augmented Generation enhances Large Language Models by integrating external knowledge, reducing hallucinations but increasing prompt length. This paper proposes FusionRAG, a novel inference framework that optimizes both the preprocessing and reprocessing stages of RAG. By embedding information from other related text chunks into each chunk and recomputing the KVCache for tokens the model focuses on, FusionRAG achieves a better trade-off between generation quality and efficiency. Experiments show that FusionRAG significantly improves generation quality and reduces Time to First Token (TTFT) compared to previous state-of-the-art solutions.",329.2,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12910v1_SciCoQA Quality Assurance for Scientific Paper--Co.pdf,SCICOQA: Quality Assurance for Scientific Paper–Code Alignment,"['Tim Baumgärtner', 'Iryna Gurevych']","SCICOQA is a dataset for detecting discrepancies between scientific publications and their codebases to ensure faithful implementations. The dataset consists of 611 paper-code discrepancies (81 real, 530 synthetic), spanning various computational science disciplines. The authors propose discrepancy types and categories to better understand the occurring mismatches. The evaluation of 21 language models highlights the difficulty of SCICOQA, particularly for instances involving omitted paper details, long-context inputs, and data outside the models' pre-training corpus. The best performing model, GPT-5, can only detect 45.7% of real-world paper-code discrepancies.",309.06,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12912v1_Human Emotion Verification by Action Languages via.pdf,"Page 1–8. ©The Author(s), 2021. Published by Cambridge University Press 2021","['ANDREAS BR ¨ANNSTR ¨OM', 'JUAN CARLOS NIEVES']","In this paper, we introduce the action language C-MT (Mind Transition Language), built on top of answer set programming (ASP) and transition systems, to represent how human mental states evolve in response to sequences of observable actions. We formalize mental states—such as emotions—as multi-dimensional configurations and extend the language with a novel causal rule, forbids to cause, along with expressions specialized for mental state dynamics. This enables the modeling of principles for valid transitions between mental states, which are translated into transition constraints and properties of invariance. The framework supports controlled reasoning about the dynamic evolution of human mental states and the comparison of different dynamics of change by analyzing trajectories that adhere to different psychological principles. We apply the action language to design models for emotion verification.",310.72,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12913v1_Actionable Interpretability Must Be Defined in Ter.pdf,Position: Actionable Interpretability Must Be Defined in Terms of Symmetries,"['Pietro Barbiero', 'Mateo Espinosa Zarlenga', 'Francesco Giannini', 'Alberto Termine', 'Mateja Jamnik', 'Giuseppe Marra']","This paper argues that interpretability research in Artificial Intelligence is fundamentally ill-posed due to existing definitions failing to provide formal principles. It posits that for a definition of interpretability to be actionable, it must be given in terms of symmetries. The authors hypothesize that four symmetries are sufficient to motivate core interpretability properties, characterize the class of interpretable models, and derive a unified formulation of interpretable inference as a form of Bayesian inversions.",309.12,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12922v1_Your Privacy Depends on Others Collusion Vulnerabi.pdf,The right to privacy is fundamentally personal with individuals known to exhibit varying privacy preferences,"['Johannes Kaiser', 'Alexander Ziller', 'Eleni Triantafillou', 'Daniel Rückert', 'Georgios Kaissis']","Individual Differential Privacy (iDP) promises users control over their privacy, but this promise can be broken in practice. The authors reveal a previously overlooked vulnerability in sampling-based iDP mechanisms, where an individual's privacy risk is not solely governed by their own privacy budget but critically depends on the privacy choices of all other data contributors. This creates a mismatch between the promise of individual privacy control and the reality of a system where risk is collectively determined. The authors demonstrate empirically that certain distributions of privacy preferences can unintentionally inflate the privacy risk of individuals, even when their formal guarantees are met. They propose (εi, δi, ∆)-iDP, a privacy contract that uses ∆-divergences to provide users with a hard upper bound on their excess vulnerability, while offering flexibility to mechanism design. Their findings expose a fundamental challenge to the current paradigm, demanding a re-evaluation of how iDP systems are designed, audited, communicated, and deployed to make excess risks transparent and controllable.",314.47,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12925v1_ForeDiffusion Foresight-Conditioned Diffusion Poli.pdf,ForeDiffusion: Foresight-Conditioned Diffusion Policy via Future View Construction for Robot Manipulation,"['Weize Xie', 'Yi Ding', 'Ying He', 'Leilei Wang', 'Binwen Bai', 'Zheyi Zhao', 'Chenyang Wang', 'F. Richard Yu']","Diffusion strategies have advanced visual motor control by progressively denoising high-dimensional action sequences, providing a promising method for robot manipulation. However, as task complexity increases, the success rate of existing baseline models decreases considerably. This paper proposes Foresight-Conditioned Diffusion (ForeDiffusion), which injects the predicted future view representation into the diffusion process, enabling the policy to be forward-looking and correcting trajectory deviations. ForeDiffusion employs a dual loss mechanism combining traditional denoising loss and consistency loss of future observations, achieving unified optimization. Extensive evaluation on the Adroit suite and MetaWorld benchmark demonstrates that ForeDiffusion achieves an average success rate of 80% for the overall task, significantly outperforming existing mainstream diffusion methods by 23% in complex tasks, while maintaining more stable performance across the entire tasks.",308.16,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12929v1_Membership Inference Test Auditing Training Data i.pdf,Membership Inference Test: Auditing Training Data in Object Classification Models,"['Gonzalo Mancera', 'Daniel DeAlcala', 'Aythami Morales', 'Ruben Tolosana', 'Julian Fierrez']","In this research, the authors analyze the performance of Membership Inference Tests (MINT) in the domain of object recognition. They propose and develop architectures tailored for MINT models to optimize performance and efficiency in data utilization. The experiments conducted involve an object detection model, an embedding extractor, and a MINT module, performed in three public databases. The proposed architecture leverages convolutional layers to capture and model activation patterns during the training process, achieving precision rates between 70% and 80%. The study also analyzes the factors influencing the MINT module, providing insights into more transparent training processes.",322.74,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12931v1_Online Continual Learning for Time Series a Natura.pdf,ONLINE CONTINUOUS LEARNING FOR TIME SERIES: A NATURAL SCORE-DRIVEN APPROACH,"['Edoardo Urettini', 'Daniele Atzeni', 'Ioanna-Yvonni Tsaknaki', 'Antonio Carta']","This paper aims to strengthen the theoretical and practical connections between time series methods and online continual learning (OCL). It reframes neural network optimization as a parameter filtering problem, showing that natural gradient descent is a score-driven method and proving its information-theoretic optimality. The paper introduces a robust optimizer called Natural Score-driven Replay (NatSR), which combines a robust optimizer with a replay buffer and a dynamic scale heuristic. Empirical results demonstrate that NatSR achieves stronger forecasting performance than more complex state-of-the-art methods.",333.35,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12937v1_On the Evidentiary Limits of Membership Inference .pdf,On the Evidentiary Limits of Membership Inference for Copyright Auditing,"['Murat Bilgehan Ertan', 'Emirhan Boge', 'Min Chen', 'Kaleel Mahmood', 'Marten van Dijk']","As large language models (LLMs) are trained on increasingly opaque corpora, membership inference attacks (MIAs) have been proposed to audit whether copyrighted texts were used during training, despite growing concerns about their reliability under realistic conditions. The authors introduce SAGE (Structure-Aware SAE-Guided Extraction), a paraphrasing framework guided by Sparse Autoencoders (SAEs) that rewrites training data to alter lexical structure while preserving semantic content and downstream utility. Experiments show that state-of-the-art MIAs degrade when models are fine-tuned on SAGE-generated paraphrases, indicating that their signals are not robust to semantics-preserving transformations. While some leakage remains in certain fine-tuning regimes, these results suggest that MIAs are brittle in adversarial settings and insufficient, on their own, as a standalone mechanism for copyright auditing of LLMs.",328.76,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12938v1_The Post-Turing Condition Conceptualising Artifici.pdf,The Post-Turing Condition: Conceptualising Artificial Subjectivity and Synthetic Sociality,"['Thorsten Jelinek', 'Patrick Glauner', 'Alvin Wang Graylin', 'Yubao Qiu']","In the Post-Turing era, artificial intelligence increasingly shapes social coordination and meaning formation rather than merely automating cognitive tasks. The central challenge is whether processes of interpretation and shared reference are progressively automated in ways that marginalize human participation. This paper introduces the PRMO framework, relating AI design trajectories to four constitutive dimensions of human subjectivity: Perception, Representation, Meaning, and the Real. Within this framework, Synthetic Sociality denotes a technological horizon in which artificial agents negotiate coherence and social order primarily among themselves, raising the structural risk of human exclusion from meaning formation. To address this risk, the paper proposes Quadrangulation as a design principle for socially embedded AI systems, requiring artificial agents to treat the human subject as a constitutive reference within shared contexts of meaning.",314.12,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12939v1_Active Inference-Driven World Modeling for Adaptiv.pdf,ACTIVE INFERENCE-DRIVEN WORLD MODELING FOR ADAPTIVE UA V SW ARM TRAJECTORY DESIGN,"['Kaleem Arshid', 'Ali Krayani', 'Lucio Marcenaro', 'David Martin Gomez', 'Carlo Regazzoni']","This paper proposes an Active Inference-based framework for autonomous trajectory design in UA V swarms. The method integrates probabilistic reasoning and self-learning to enable distributed mission allocation, route ordering, and motion planning. Expert trajectories generated using a Genetic Algorithm with Repulsion Forces (GA-RF) are employed to train a hierarchical World Model capturing swarm behavior across mission, route, and motion levels. During online operation, UA Vs infer actions by minimizing divergence between current beliefs and model-predicted states, enabling adaptive responses to dynamic environments. Simulation results show faster convergence, higher stability, and safer navigation than Q-Learning, demonstrating the scalability and cognitive grounding of the proposed framework for intelligent UA V swarm control.",313.1,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12946v1_AI-generated data contamination erodes pathologica.pdf,AI-generated data contamination erodes pathological variability and diagnostic reliability,"['Hongyu He', 'Shaowen Xiang', 'Ye Zhang', 'Yingtao Zhu', 'Jin Zhang', 'Hao Deng', 'Emily Alsentzer', 'Qingyu Chen', 'Kun-Hsing Yu', 'Andrew Marmenshall', 'Tingting Chen', 'Srinivas Anumasa', 'Daniel Ebner', 'Dean Ho', 'Kee Yuan Ngiam', 'Ching-Yu Cheng', 'Dianbo Liu']","Generative artificial intelligence (AI) is rapidly populating medical records with synthetic content, creating a feedback loop where future models are increasingly at risk of training on uncurated AI-generated data. However, the clinical consequences of this AI-generated data contamination remain unexplored. This study shows that in the absence of mandatory human verification, this self-referential cycle drives a rapid erosion of pathological variability and diagnostic reliability. By analyzing more than 800,000 synthetic data points across clinical text generation, vision–language reporting, and medical image synthesis, the authors find that models progressively converge toward generic phenotypes regardless of the model architecture. Specifically, rare but critical findings, including pneumothorax and effusions, vanish from the synthetic content generated by AI models, while demographic representations skew heavily toward middle-aged male phenotypes. Crucially, this degradation is masked by false diagnostic confidence; models continue to issue reassuring reports while failing to detect life-threatening pathology, with false reassurance rates tripling to 40%. Blinded physician evaluation confirms that this decoupling of confidence and accuracy renders AI-generated documentation clinically useless after just two generations. The study systematically evaluates three mitigation strategies, finding that while synthetic volume scaling fails to prevent collapse, mixing real data with quality-aware filtering effectively preserves diversity. Ultimately, the results suggest that without policy-mandated human oversight, the deployment of generative AI threatens to degrade the very healthcare data ecosystems it relies upon.",314.67,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.12951v1_Beyond Accuracy Characterizing Code Comprehension .pdf,Beyond Accuracy: Characterizing Code Comprehension Capabilities in (Large) Language Models,"['Felix Mächtle', 'Jan-Niclas Serr', 'Nils Loose', 'Thomas Eisenbarth']","Large Language Models (LLMs) are increasingly integrated into software engineering workflows, yet current benchmarks provide only coarse performance summaries that obscure the diverse capabilities and limitations of these models. This paper investigates whether LLMs' code-comprehension performance aligns with traditional human-centric software metrics or instead reflects distinct, non-human regularities. We introduce a diagnostic framework that reframes code understanding as a binary input–output consistency task, enabling the evaluation of classification and generative models. Using a large-scale dataset, we correlate model performance with traditional, human-centric complexity metrics, such as lexical size, control-flow complexity, and abstract syntax tree structure. Our analyses reveal minimal correlation between human-defined metrics and LLM success (AUROC 0.63), while shadow models achieve substantially higher predictive performance (AUROC 0.86), capturing complex, partially predictable patterns beyond traditional software measures. These findings suggest that LLM comprehension reflects model-specific regularities only partially accessible through either human-designed or learned features, emphasizing the need for benchmark methodologies that move beyond aggregate accuracy and toward instance-level diagnostics, while acknowledging fundamental limits in predicting correct outcomes.",315.02,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13007v1_ArchAgent Scalable Legacy Software Architecture Re.pdf,ARCHAGENT: SCALABLE LEGACY SOFTW ARE ARCHITECTURE RECOVERY WITH LLMS,"['Rusheng Pan★', 'Bingcheng Mao★', 'Tianyi Ma★', 'Zhenhua Ling †']","Recovering accurate architecture from large-scale legacy software is hindered by architectural drift, missing relations, and the limited context of Large Language Models (LLMs). ArchAgent presents a scalable agent-based framework that combines static analysis, adaptive code segmentation, and LLM-powered synthesis to reconstruct multiview, business-aligned architectures from cross-repository codebases. It introduces scalable diagram generation with contextual pruning and integrates cross-repository data to identify business-critical modules. Evaluations of typical large-scale GitHub projects show significant improvements over existing benchmarks. An ablation study confirms that dependency context improves the accuracy of generated architectures of production-level repositories, and a real-world case study demonstrates effective recovery of critical business logics from legacy projects. The dataset is available at https://github.com/panrusheng/arch-eval-benchmark.",314.76,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13013v1_HT-GNN Hyper-Temporal Graph Neural Network for Cus.pdf,HT-GNN: Hyper-Temporal Graph Neural Network for Customer Lifetime Value Prediction in Baidu Ads,"['Xiaohui Zhao', 'Xinjian Zhao', 'Jiahui Zhang', 'Guoyu Liu', 'Houzhi Wang', 'Shu Wu']","Lifetime value (LTV) prediction is crucial for news feed advertising, enabling platforms to optimize bidding and budget allocation for long-term revenue growth. However, it faces two major challenges: demographic-based targeting creates segment-specific LTV distributions with large value variations across user groups, and dynamic marketing strategies generate irregular behavioral sequences where engagement patterns evolve rapidly. We propose a Hyper-Temporal Graph Neural Network (HT-GNN), which jointly models demographic heterogeneity and temporal dynamics through three key components: a hypergraph-supervised module capturing inter-segment relationships, a transformer-based temporal encoder with adaptive weighting, and a task-adaptive mixture-of-experts with dynamic prediction towers for multi-horizon LTV forecasting. Experiments on Baidu Advertisements with 15 million users demonstrate that HT-GNN consistently outperforms state-of-the-art methods across all metrics and prediction horizons.",312.15,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13018v1_Bi-Attention HateXplain  Taking into account the s.pdf,Bi-Attention HateXplain : Taking into account the sequential aspect of data during explainability in a multi-task context,['Ghislain Dorian Tchuente Mondjo'],"Technological advances in the Internet and online social networks have brought many benefits to humanity, but this growth has led to an increase in hate speech, the main global threat. To improve the reliability of black-box models used for hate speech detection, post-hoc approaches such as LIME, SHAP, and LRP provide the explanation after training the classification model. In contrast, multi-task approaches based on the HateXplain benchmark learn to explain and classify simultaneously. However, results from HateXplain-based algorithms show that predicted attention varies considerably when it should be constant. This attention variability can lead to inconsistent interpretations, instability of predictions, and learning difficulties. To solve this problem, we propose the BiAtt-BiRNN-HateXplain (Bidirectional Attention BiRNN HateXplain) model which is easier to explain compared to LLMs which are more complex in view of the need for transparency, and will take into account the sequential aspect of the input data during explainability thanks to a BiRNN layer. Thus, if the explanation is correctly estimated, thanks to multi-task learning (explainability and classification task), the model could classify better and commit fewer unintentional bias errors related to communities. The experimental results on HateXplain data show a clear improvement in detection performance, explainability, and a reduction in unintentional bias.",314.39,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13020v1_PASs-MoE Mitigating Misaligned Co-drift among Rout.pdf,PASs-MoE: Mitigating Misaligned Co-drift among Router and Experts via Pathway Activation Subspaces for Continual Learning,"['Zhiyan Hou', 'Haiyun Guo', 'Haokai Ma', 'Yandu Sun', 'Yonghui Yang', 'Jinqiao Wang']","Continual instruction tuning (CIT) requires multimodal large language models (MLLMs) to adapt to a stream of tasks without forgetting prior capabilities. Existing LoRA-based Mixture-of-Experts (MoE) methods often jointly update the router and experts in an indiscriminate way, causing the router's preferences to co-drift with experts' adaptation pathways and gradually deviate from early-stage input-expert specialization. This paper introduces the pathway activation subspace (PASs), a LoRA-induced subspace that reflects which low-rank pathway directions an input activates in each expert, providing a capability-aligned coordinate system for routing and preservation. Based on PASs, the authors propose a fixed-capacity PASs-based MoE-LoRA method with two components: PAS-guided Reweighting and PAS-aware Rank Stabilization. Experiments on a CIT benchmark show that the approach consistently outperforms conventional continual learning baselines and MoE-LoRA variants in both accuracy and anti-forgetting without adding parameters. The authors plan to release their code upon acceptance.",313.58,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13048v1_Analysis of Long Range Dependency Understanding in.pdf,ANALYSIS OF LONG RANGE DEPENDENCY UNDERSTANDING IN STATE SPACE MODELS,"['Srividya Ravikumar', 'Abhinav Anand', 'Shweta V erma', 'Mira Mezini']","Although state-space models (SSMs) have demonstrated strong performance on long-sequence benchmarks, most research has emphasized predictive accuracy rather than interpretability. In this work, we present the first systematic kernel interpretability study of the diagonalized state-space model (S4D) trained on a real-world task (vulnerability detection in source code). Through time and frequency domain analysis of the S4D kernel, we show that the long-range modeling capability of S4D varies significantly under different model architectures, affecting model performance. For instance, we show that the S4D kernel can behave as low-pass, band-pass, or high-pass filter depending on the architecture. The insights from our analysis can guide future work in designing better S4D-based models.",313.65,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13054v1_TinyML-Enabled IoT for Sustainable Precision Irrig.pdf,TinyML-Enabled IoT for Sustainable Precision Irrigation,"['Kamogelo Taueatsoala', 'Caitlyn Daniels', 'Angelina J. Ramsunar', 'Petrus Bronkhorst', 'Absalom E. Ezugwu']","This paper presents a novel, edge-first IoT framework that integrates Tiny Machine Learning (TinyML) for intelligent, offline-capable precision irrigation. The four-layer architecture leverages low-cost hardware, an ESP32 microcontroller, and a Raspberry Pi for autonomous decision-making without cloud dependency. The system uses environmental sensors for monitoring and an optimized Gradient Boosting model for predicting irrigation needs with exceptional accuracy. Experimental validation in a controlled environment demonstrates significant water usage reduction compared to traditional methods, confirming the system's viability for sustainable, scalable deployment in resource-constrained rural settings.",314.7,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13060v1_MagicGUI-RMS A Multi-Agent Reward Model System for.pdf,MAGICGUI-RMS: A MULTI-AGENTREWARDMODELSYSTEM FORSELF-EVOLVINGGUI AGENTS VIAAUTOMATEDFEEDBACKREFLUX,"['Zecheng Li∗', 'Zhihui Cao ∗ †', 'Wenke Huang', 'Yudong Zhang', 'Keying Qi', 'Rui Wang', 'Zeyu Zheng', 'Jian Zhao', 'Hao Zhu', 'Hengxin Wu', 'Yuran Wang', 'Guitao Fan', 'Guokun Wu', 'Yicong Liu', 'Zhilin Gao', 'Haikun Xu', 'He Yang', 'Minqi Xiang', 'Xingyu Liu †', 'Zuojian Wang †']","Graphical user interface (GUI) agents are advancing towards autonomous interaction and reliable task execution across diverse applications. However, two central challenges remain unresolved: automating the evaluation of agent trajectories and generating high-quality training data at scale. Existing approaches often rely on manual annotation or static rule-based verification, which restricts scalability and limits adaptability in dynamic environments. This paper presents MagicGUI-RMS, a multi-agent reward model system that delivers adaptive trajectory evaluation, corrective feedback, and self-evolving learning capabilities. MagicGUI-RMS integrates a Domain-Specific Reward Model (DS-RM) with a General-Purpose Reward Model (GP-RM), enabling fine-grained action assessment and robust generalization across heterogeneous GUI tasks. To support reward learning at scale, a structured data construction pipeline automatically produces balanced and diverse reward datasets, effectively reducing annotation costs while maintaining sample fidelity. During execution, the reward model system identifies erroneous actions, proposes refined alternatives, and continuously enhances agent behavior through an automated data-reflux mechanism. Extensive experiments demonstrate that MagicGUI-RMS yields substantial gains in task accuracy and behavioral robustness, establishing it as a principled and effective foundation for building self-improving GUI agents driven by reward-based adaptation.",313.65,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13075v1_METIS Mentoring Engine for Thoughtful Inquiry  Sol.pdf,Mentoring Engine for Thoughtful Inquiry & Solutions,"['Abhinav Rajeev Kumar', 'Dhruv Trehan', 'Paras Chopra']","This paper presents METIS, an AI research mentor designed to guide undergraduates from initial ideas to publishable conference papers. It combines reasoning with external tools and keeps context across sessions to help learners progress. The authors evaluate METIS against GPT-5 and Claude Sonnet 4.5, finding that METIS is preferred in single-turn judgments and yields slightly higher final quality in multi-turn tutoring sessions. The paper contributes practical mentoring workflows, a simple system with tools for literature search, guidelines retrieval, methodology checks, and memory, and an empirical comparison to other models.",311.84,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13111v1_CORE-T COherent REtrieval of Tables for Text-to-SQ.pdf,CORE-T: COherent REtrieval of Tables for Text-to-SQL,"['Hassan Soliman', 'Vivek Gupta', 'Dan Roth', 'Iryna Gurevych']","CORE-T addresses the challenge of retrieving relevant tables for text-to-SQL workflows, especially in open-book settings where queries must be answered over large, heterogeneous table collections. It proposes a scalable, training-free framework that enriches tables with LLM-generated purpose metadata and pre-computes a lightweight table-compatibility cache. At inference time, dense retrieval returns top-K candidates; a single LLM call selects a coherent, joinable subset, and a simple additive adjustment step restores strongly compatible tables. CORE-T improves table-selection F1 by up to 22.7 points and multi-table execution accuracy by up to 5.0 points on BIRD and 6.9 points on MMQA, using 4–5× fewer tokens than LLM-intensive baselines.",307.52,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13114v1_IntAgent NWDAF-Based Intent LLM Agent Towards Adva.pdf,NWDAF-Based Intent LLM Agent: Towards Advanced Next Generation Networks,"['Abdelrahman Soliman', 'Ahmed Refaey', 'Aiman Erbad', 'Amr Mohamed']","This work introduces IntAgent, an intelligent intent LLM agent that integrates NWDAF analytics and tools to fulfill the network operator’s intents. Unlike previous approaches, it develops an intent tools engine directly within the NWDAF analytics engine, allowing the agent to utilize live network analytics to inform its reasoning and tool selection. The framework offers an enriched, 3GPP-compliant data source and an MCP tools server for scheduling, monitoring, and analytics tools. Demonstrated through two practical use cases (ML-based traffic prediction and scheduled policy enforcement), IntAgent validates its ability to autonomously fulfill complex network intents.",312.66,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13122v1_Responsible AI for General-Purpose Systems Overvie.pdf,"Responsible AI for General-Purpose Systems: Overview, Challenges, and A Path Forward","['Gourab K. Patro', 'Himanshi Agrawal', 'Himanshu Gharat', 'Supriya Panigrahi', 'Nim Sherpa', 'Vishal Vaddina', 'Dagnachew Birru']","Modern general-purpose AI systems, built using large language and vision models, are capable of performing a range of tasks like writing text articles, generating and debugging codes, querying databases, and translating languages. However, they also pose risks such as hallucinations, toxicity, and stereotypes in their output, making them untrustworthy. The authors review various risks and vulnerabilities of modern general-purpose AI systems along eight widely accepted responsible AI (RAI) principles and compare them to traditional task-specific systems. They argue that the high degree of freedom in general-purpose AI output makes it difficult to apply traditional RAI principles. The authors derive C 2V2 (Control, Consistency, Value, Veracity) desiderata to meet RAI requirements for future general-purpose AI systems and discuss recent efforts in AI alignment, retrieval-augmented generation, and reasoning enhancements. They believe that formally modeling application-dependent RAI requirements along C 2V2 dimensions and taking a system design approach can help achieve the goal of developing responsible general-purpose AI.",331.73,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13142v1_TVWorld Foundations for Remote-Control TV Agents.pdf,TVWorld: Foundations for Remote-Control TV Agents,"['Zhantao Ma', 'Quanfeng Lu', 'Shuai Zhong', 'Ping Luo', 'Michael K. Ng']","Recent large vision-language models have demonstrated strong potential for device control, but existing research has primarily focused on point-and-click interaction. To address this gap, the authors introduce TVWorld, an offline graph-based abstraction of real-world TV navigation that enables reproducible and deployment-free evaluation. TVWorld-N and TVWorld-G benchmarks comprehensively assess TV-use capabilities, exposing a key limitation of existing agents: insufficient topology awareness for focus-based, long-horizon TV navigation. Motivated by this finding, the authors propose a Topology-Aware Training framework that injects topology awareness into LVLMs. Using this framework, they develop TVTheseus, a foundation model specialized for TV navigation, achieving a success rate of 68.3% on TVWorld-N and establishing state-of-the-art performance. Additional analyses provide valuable insights into the development of effective TV-use agents.",330.25,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13160v1_Training instability in deep learning follows low-.pdf,Training instability in deep learning follows low-dimensional dynamical principles,"['Zhipeng Zhang', 'Zhenjie Yao', 'Kai Li', 'Lei Yang']","Deep learning systems achieve remarkable empirical performance, yet the stability of the training process itself remains poorly understood. Training unfolds as a high-dimensional dynamical system in which small perturbations to optimization, data, parameters, or learning signals can induce abrupt and irreversible collapse, undermining reproducibility and scalability. We propose a unified dynamical perspective that characterizes training stability as an intrinsic property of learning systems, organized along four interacting dimensions: optimization, environmental/data, parametric, and learning-signal stability. We operationalize this perspective through controlled perturbation auditing of training trajectories, probing how learning dynamics respond to structured disturbances without modifying learning algorithms. Across reinforcement learning and large language model training, we identify three recurring regularities: high final performance is frequently decoupled from training stability; controlled stochasticity consistently buffers learning dynamics across paradigms; and deviations in low-dimensional latent meta-states systematically precede observable performance collapse. Together, these findings establish training stability as a measurable and comparable dynamical property of learning systems, providing a descriptive foundation for studying learning dynamics beyond final performance outcomes.",309.9,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13166v1_From 100000 images to winning the first brain MRI .pdf,"From 100,000+ images to winning the first brain MRI foundation model challenges","['Pedro M. Gordaliza', 'Jaume Banus', 'Benoît Gérin', 'Maxence Wynen', 'Nataliia Molchanova', 'Jonas Richiardi', 'Meritxell Bach Cuadra']","Developing Foundation Models for medical image analysis is essential to overcome the unique challenges of radiological tasks. Our solution ranked first in tracks of both contests SSL3D and FOMO25. It relies on a U-Net CNN architecture combined with strategies leveraging anatomical priors and neuroimaging domain knowledge. Notably, our models trained 1-2 orders of magnitude faster and were 10× smaller than competing transformer-based approaches. Models are available here.",309.24,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13186v1_Prompt Injection Mitigation with Agentic AI Nested.pdf,"Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching","['Diego Gosmar', 'Deborah A. Dahl']","This paper extends the evaluation framework for prompt injection mitigation with semantic similarity-based caching, a dedicated fourth-agent rule-based evaluator, and a fifth metric (Observability Score Ratio) to yield TIVS-O. The proposed system combines a three-stage agentic pipeline with Continuum Memory Systems that implement semantic similarity-based caching across 301 injection-focused prompts. Experiments show that the system achieves secure responses with reduced high-risk breaches and substantial computational savings, enabling real-time responses, cost reduction, and energy savings. The semantic caching mechanism not only accelerates inference but also demonstrates that security architectures can simultaneously advance environmental sustainability.",316.01,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13187v1_Scientific production in the era of Large Language.pdf,Scientific production in the era of Large Language Models,"['Keigo Kusumegi', 'Xinyu Yang', 'Paul Ginsparg', 'Mathijs de Vaan', 'Toby Stuart', 'Yian Yin']","Large Language Models (LLMs) are rapidly reshaping scientific research. The authors analyze these changes in multiple, large-scale datasets with 2.1M preprints, 28K peer review reports, and 246M online accesses to scientific documents. They find that scientists adopting LLMs to draft manuscripts demonstrate a large increase in paper production, ranging from 23.7-89.3% depending on scientific field and author background. LLM use has reversed the relationship between writing complexity and paper quality, leading to an influx of manuscripts that are linguistically complex but substantively underwhelming. LLM adopters access and cite more diverse prior work, including books and younger, less-cited documents. These findings highlight a stunning shift in scientific production that will likely require a change in how journals, funding agencies, and tenure committees evaluate scientific works.",309.39,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13197v1_Diffusion-Driven Synthetic Tabular Data Generation.pdf,Diffusion-Driven Synthetic Tabular Data Generation for Enhanced DoS/DDoS Attack Classification,"['Aravind B', 'Anirud R.S.', 'Sai Surya Teja N', 'Bala Subrahmanya Sriranga Navaneeth A', 'Karthika R', 'Mohankumar N']","Class imbalance refers to a situation where certain classes in a dataset have significantly fewer samples than others, leading to biased model performance. Class imbalance in network intrusion detection using Tabular Denoising Diffusion Probability Models (TabDDPM) for data augmentation is addressed in this paper. Our approach synthesizes high-fidelity minority-class samples from the CIC-IDS2017 dataset through iterative denoising processes. For minority classes with smaller samples, synthetic samples were generated and merged with the original dataset. The augmented training data enables an ANN classifier to achieve near-perfect recall on previously underrepresented attack classes. These results establish diffusion models as an effective solution for tabular data imbalance in security domains, with potential applications in fraud detection and medical diagnostics.",309.57,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13206v1_Real-Time Deadlines Reveal Temporal Awareness Fail.pdf,Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues,"['Neil Sehgal', 'Sharath Chandra Guntuku', 'Lyle Ungar']","Large Language Models (LLMs) generate text token-by-token in discrete time, yet real-world communication critically depends on continuous time constraints. Current LLM architectures and evaluation protocols rarely test for temporal awareness under real-time deadlines. The authors investigate how LLMs adjust their behavior in time-sensitive settings using simulated negotiations between paired agents under strict deadlines. In a control condition, agents know only the global time limit. In a time-aware condition, they receive remaining-time updates at each turn. Deal closure rates are substantially higher in the time-aware condition (32% vs. 4% for GPT-5.1) and offer acceptances are sixfold higher, suggesting LLMs struggle to internally track elapsed time. However, the same LLMs achieve near-perfect deal closure rates under turn-based limits, revealing the failure is in temporal tracking rather than strategic reasoning. These effects replicate across negotiation scenarios and models, illustrating a systematic lack of LLM time awareness that will constrain LLM deployment in many time-sensitive applications.",319.33,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13217v1_Beyond Single-shot Writing Deep Research Agents ar.pdf,Beyond Single-shot Writing: Deep Research Agents are Unreliable at Multi-turn Report Revision,"['Bingsen Chen', 'Boyan Li', 'Ping Nie', 'Yuyu Zhang', 'Xi Ye', 'Chen Zhao']","Existing benchmarks for Deep Research Agents (DRAs) treat report generation as a single-shot writing task, which fundamentally diverges from how human researchers iteratively draft and revise reports. This work introduces MRDRE, an evaluation suite that establishes multi-turn report revision as a new evaluation axis for DRAs. The analysis of five diverse DRAs reveals a critical limitation: while agents can address most user feedback, they also regress on 16–27% of previously covered content and citation quality. Over multiple revision turns, even the best-performing agents leave significant headroom, as they continue to disrupt content outside the feedback's scope and fail to preserve earlier edits. The issues are not easily resolvable through inference-time fixes such as prompt engineering and a dedicated sub-agent for report revision.",329.17,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13222v1_Incorporating QA Nuggets into Retrieval-Augmented .pdf,Incorporating Q&A Nuggets into Retrieval-Augmented Generation,"['Laura Dietz', 'Bryan Li', 'Gabrielle Liu', 'Jia-Huei Ju', 'Eugene Yang', 'Dawn Lawrie', 'William Walden', 'James Mayfield']","The paper presents Crucible, a Nugget-Augmented Generation System that integrates ideas from automatic evaluation into Retrieval-augmented Generation. Crucible constructs a bank of Q&A nuggets from retrieved documents and uses them to guide extraction, selection, and report generation. The system avoids repeated information through clear and interpretable Q&A semantics, maintaining citation provenance throughout the generation process. Evaluated on the TREC Neu-CLIR 2024 collection, Crucible substantially outperforms Ginger, a recent nugget-based RAG system, in nugget recall, density, and citation grounding.",332.43,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13227v1_Insider Knowledge How Much Can RAG Systems Gain fr.pdf,Insider Knowledge: How Much Can RAG Systems Gain from Evaluation Secrets?,"['Laura Dietz', 'Bryan Li', 'Eugene Yang', 'Dawn Lawrie', 'William Walden', 'James Mayfield']","RAG systems are increasingly evaluated and optimized using LLM judges, an approach that is rapidly becoming the dominant paradigm for system assessment. Nugget-based approaches are now embedded in both evaluation frameworks and RAG systems. While this integration can lead to genuine improvements, it also creates a risk of faulty measurements due to circularity. This paper investigates this risk through comparative experiments with nugget-based RAG systems, including Ginger and Crucible, against strong baselines such as GptResearcher. By deliberately modifying Crucible to generate outputs optimized for an LLM judge, the authors show that near-perfect evaluation scores can be achieved when elements of the evaluation—such as prompt templates or gold nuggets—are leaked or can be predicted. The results highlight the importance of blind evaluation settings and methodological diversity to guard against mistaking metric overfitting for genuine system progress.",325.12,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13228v1_Autoregressive Models Rival Diffusion Models at AN.pdf,Any-order Any-subset Autoregressive Modeling,"['Tianqi Du', 'Lizhe Fang', 'Weijie Yang', 'Chenheng Zhang', 'Zeming Wei', 'Yifei Wang', 'Yisen Wang']","Diffusion language models enable any-order generation and bidirectional conditioning, offering flexibility for tasks such as infilling, rewriting, and self-correction. However, their formulation—predicting one part of a sequence from another within a single-step dependency—limits modeling depth and often yields lower sample quality and stability than autoregressive (AR) models. This work revisits autoregressive modeling as a foundation and reformulates diffusion-style training into a structured multi-group prediction process. A3, a generalized framework, extends the standard AR factorization to arbitrary token groups and generation orders, preserving probabilistic rigor and multi-layer dependency modeling while inheriting diffusion models' flexibility for parallel and bidirectional generation. Experiments on question answering, commonsense reasoning, and story infilling demonstrate that A3 outperforms diffusion-based models while maintaining flexible decoding.",324.07,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13233v1_RAG A Random-Forest-Based Generative Design Framew.pdf,A Random-Forest-Based Generative Design Framework for Uncertainty-Aware Design of Metamaterials with Complex Functional Response Requirements,"['Bolin Chen', 'Dex Doksoo Lee', 'Wei “Wayne” Chen', 'Wei Chen']","Metamaterials design for advanced functionality often involves inverse design on nonlinear and condition-dependent responses. Most existing methods focus on vector-valued responses, making inverse design of functional responses challenging. Generative design approaches have shown promise but are often data-hungry, handle design requirements heuristically, and may generate infeasible designs without uncertainty quantification. This paper introduces a RAndom-forest-based Generative approach (RAG) that leverages random forests' small-data compatibility and reformulates the forward mapping discretization-invariantly, enabling data-efficient predictions of high-dimensional functional responses. During inverse design, the framework estimates the likelihood of solutions conditioned on design requirements, providing a lightweight, trustworthy pathway to inverse design involving functional responses, expensive simulations, and complex design requirements, beyond metamaterials.",310.17,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13235v1_RubRIX Rubric-Driven Risk Mitigation in Caregiver-.pdf,RubRIX: Rubric-Driven Risk Mitigation in Caregiver-AI Interactions,"['Drishti Goel', 'Jeongah Lee', 'Qiuyue Joy Zhong', 'Violeta J. Rodriguez', 'Daniel S. Brown', 'Ravi Karkar', 'Dong Whi Yoo', 'Koustuv Saha']","RubRIX is a theory-driven, clinician-validated framework for evaluating risks in Large Language Model (LLM) caregiving responses. Grounded in the Elements of an Ethic of Care, RubRIX operationalizes five empirically-derived risk dimensions: Attention, Bias & Stigma, Information Inaccuracy, Uncritical Affirmation, and Epistemic Arrogance. The framework evaluates six state-of-the-art LLMs on over 20,000 caregiver queries from Reddit and ALZConnected. Rubric-guided refinement consistently reduced risk-components by 45-98% after one iteration across models. This work contributes a methodological approach for developing domain-sensitive, user-centered evaluation frameworks for high-burden contexts. The findings highlight the importance of domain-sensitive, interactional risk evaluation for the responsible deployment of LLMs in caregiving support contexts. The authors release benchmark datasets to enable future research on contextual risk evaluation in AI-mediated support.",308.64,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13236v1_Pixelwise Uncertainty Quantification of Accelerate.pdf,Pixelwise Uncertainty Quantiﬁcation of Accelerated MRI Reconstruction,"['Ilias I. Giannakopoulos', 'Lokesh B Gautham Muthukumar', 'Yvonne W. Lui', 'Riccardo Lattanzi']","This work introduces a general framework for pixel-wise uncertainty quantification in parallel MRI reconstructions, enabling automatic identification of unreliable regions without access to any ground-truth reference image. The method integrates conformal quantile regression with image reconstruction methods to estimate statistically rigorous pixel-wise uncertainty intervals. The model was trained and evaluated on Cartesian undersampled brain and knee data from the fastMRI dataset using acceleration factors ranging from 2 to 10. An end-to-end Variational Network was used for image reconstruction. Quantitative experiments demonstrate strong agreement between predicted uncertainty maps and true reconstruction error. The proposed framework enables evaluation of reconstruction quality without access to fully-sampled ground-truth reference images, representing a step toward adaptive MRI acquisition protocols that may dynamically balance scan time and diagnostic reliability.",319.41,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13238v1_A Semantic Decoupling-Based Two-Stage Rainy-Day At.pdf,A Semantic Decoupling–Based Two-Stage Rainy-Day Attack for Revealing Weather Robustness Deficiencies in Vision–Language Models,"['Chengyin Hu', 'Xiang Chen', 'Zhe Jia', 'Weiwen Shi', 'Fengyu Zhang', 'Jiujiang Guo', 'Yiwei Wei']","Vision-Language Models (VLMs) achieve strong performance by aligning visual and linguistic representations through large-scale joint pre-training. However, their robustness to real-world weather conditions remains insufficiently studied. This paper introduces the first adversarial framework that exploits realistic weather to attack VLMs, using a two-stage, parameterized perturbation model based on semantic decoupling. In Stage 1, global effects of rainfall are modeled by applying a low-dimensional global modulation to condition the embedding space and gradually weaken the original semantic decision boundaries. In Stage 2, structured rain variations are introduced by explicitly modeling multi-scale raindrop appearance and rainfall-induced illumination changes, and the resulting non-differentiable weather space is optimized to induce stable semantic shifts. The framework generates perturbations that are both physically grounded and interpretable, and experiments across multiple tasks show that even physically plausible, highly constrained weather perturbations can induce substantial semantic misalignment in mainstream VLMs, posing potential safety and reliability risks in real-world deployment. Ablations confirm that illumination modeling and multi-scale raindrop structures are key drivers of these semantic shifts.",308.81,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13240v1_KOCO-BENCH Can Large Language Models Leverage Doma.pdf,KOCO-BENCH: Can Large Language Models Leverage Domain Knowledge in Software Development?,"['Xue Jiang', 'Jiaru Qian', 'Xianjie Shi', 'Chenjie Li', 'Hao Zhu', 'Ziyu Wang', 'Jielun Zhang', 'Zheyu Zhao', 'Kechi Zhang', 'Jia Li', 'Wenpin Jiao', 'Zhi Jin', 'Ge Li', 'Yihong Dong']","This paper presents KOCO-BENCH, a novel benchmark designed to evaluate domain specialization methods in real-world software development. KOCO-BENCH includes 6 emerging domains with 11 software frameworks and 25 projects, featuring curated knowledge corpora and multi-granularity evaluation tasks. The authors reveal that KOCO-BENCH poses significant challenges to state-of-the-art LLMs, even with domain specialization methods applied. They release KOCO-BENCH, evaluation code, and baselines to advance further research.",312.51,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13247v1_Aligning Agentic World Models via Knowledgeable Ex.pdf,Aligning Agentic World Models via Knowledgeable Experience Learning,"['Baochang Ren', 'Yunzhi Yao', 'Rui Sun', 'Shuofei Qiao', 'Ningyu Zhang', 'Huajun Chen']","Current Large Language Models (LLMs) exhibit a critical modal disconnect: they possess vast semantic knowledge but lack the procedural grounding to respect the immutable laws of the physical world. Existing alignment strategies predominantly rely on resource-intensive training or fine-tuning, which attempt to compress dynamic environmental rules into static model parameters. WorldMind, a framework introduced in this paper, autonomously constructs a symbolic World Knowledge Repository by synthesizing environmental feedback. Specifically, it unifies Process Experience to enforce physical feasibility via prediction errors and Goal Experience to guide task optimality through successful trajectories. Experiments on EB-ALFRED and EB-Habitat demonstrate that WorldMind achieves superior performance compared to baselines with remarkable cross-model and cross-environment transferability.",332.69,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13260v1_Stop Taking Tokenizers for Granted They Are Core D.pdf,Stop Taking Tokenizers for Granted: They Are Core Design Decisions in Large Language Models,"['Sawsan Alqahtani†♠*', 'Mir Tafseer Nayeem♣*', 'Md Tahmid Rahman Laskar♦♡', 'Tasnim Mohiuddin♢', 'M Saiful Bari♥']","This paper reframes tokenization as a core modeling decision rather than a pre-processing step. It argues for a context-aware framework that integrates tokenizer and model co-design, guided by linguistic, domain, and deployment considerations. Standardized evaluation and transparent reporting are essential to make tokenization choices accountable and comparable. The authors highlight the limitations of common subword approaches such as Byte Pair Encoding, which often misalign with linguistic structure, amplify bias, and waste capacity across languages and domains. They advocate for a more context-aware and linguistically informed approach to tokenization, emphasizing the importance of treating tokenization as a core design problem, not a technical afterthought.",332.04,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13262v1_CURE-Med Curriculum-Informed Reinforcement Learnin.pdf,CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning,"['Eric Onyame∗', 'Akash Ghosh∗', 'Subhadip Baidya', 'Sriparna Saha', 'Xiuying Chen', 'Chirag Agarwal']","While large language models (LLMs) have shown to perform well on monolingual mathematical and commonsense reasoning, they remain unreliable for multilingual medical reasoning applications, hindering their deployment in multilingual healthcare settings. We address this by first introducing CUREMED-BENCH, a high-quality multilingual medical reasoning dataset with open-ended reasoning queries with a single verifiable answer, spanning thirteen languages, including underrepresented languages such as Amharic, Yoruba, and Swahili. Building on this dataset, we propose CURE-MED, a curriculum-informed reinforcement learning framework that integrates code-switching-aware supervised fine-tuning and Group Relative Policy Optimization to jointly improve logical correctness and language stability. Across thirteen languages, our approach consistently outperforms strong baselines and scales effectively, achieving 85.21% language consistency and 54.35% logical correctness at 7B parameters, and 94.96% language consistency and 70.04% logical correctness at 32B parameters. These results support reliable and equitable multilingual medical reasoning in LLMs. The code and dataset are available atcure_med.",316.36,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13268v1_Improving the Safety and Trustworthiness of Medica.pdf,Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops,"['Zainab Ghafoor', 'Md Shafiqul Islam', 'Koushik Howlader', 'Md Rasel Khondokar', 'Tanusree Bhattacharjee', 'Sayantan Chakraborty', 'Adrito Roy', 'Ushashi Bhattacharjee', 'Tirtho Roy']","This work introduces a multi-agent refinement framework designed to enhance the safety and reliability of medical Large Language Models (LLMs) through structured, iterative alignment. The system combines two generative models—DeepSeek R1 and Med-PaLM—with two evaluation agents, LLaMA 3.1 and Phi-4, which assess responses using the American Medical Association’s (AMA) Principles of Medical Ethics and a five-tier Safety Risk Assessment (SRA-5) protocol. The evaluation is conducted across 900 clinically diverse queries spanning nine ethical domains, measuring convergence efficiency, ethical violation reduction, and domain-specific risk behavior. Results demonstrate that DeepSeek R1 achieves faster convergence (mean 2.34 vs. 2.67 iterations), while Med-PaLM shows superior handling of privacy-sensitive scenarios. The iterative multi-agent loop achieved an 89% reduction in ethical violations and a 92% risk downgrade rate, underscoring the effectiveness of the approach. This study presents a scalable, regulator-aligned, and cost-efficient paradigm for governing medical AI safety.",309.04,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13286v1_AI Skills Improve Job Prospects Causal Evidence fr.pdf,AI Skills Improve Job Prospects: Causal Evidence from a Hiring Experiment,"['Fabian Stephany', 'Ole Teutloff', 'Angelo Leone']","The study examines whether AI skills serve as a positive hiring signal and whether they can offset conventional disadvantages such as older age or lower formal education. Using a paired conjoint design, recruiters evaluated hypothetical candidates represented by synthetically designed résumés across three occupations: graphic designer, office assistant, and software engineer. AI skills significantly increase interview invitation probabilities by approximately 8 to 15 percentage points. AI skills also partially or fully offset disadvantages related to age and lower education, with effects strongest for office assistants, where formal AI certification plays an additional compensatory role. Effects are weaker for graphic designers, consistent with more skeptical recruiter attitudes toward AI in creative work. Recruiters' own background and AI usage significantly moderate these effects. Overall, the findings demonstrate that AI skills function as a powerful hiring signal and can mitigate traditional labor market disadvantages, with implications for workers' skill acquisition strategies and firms' recruitment practices.",308.83,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13295v1_CooperBench Why Coding Agents Cannot be Your Teamm.pdf,CooperBench: Why Coding Agents Cannot be Your Teammates Yet,"['CooperBench', 'Arpandeep Khatua', 'Hao Zhu', 'Peter Tran', 'Arya Prabhudesai', 'Frederic Sadrieh', 'Johann K. Lieberwirth', 'Xinkai Yu', 'Yicheng Fu', 'Michael J. Ryan', 'Jiaxin Pei', 'Diyi Yang']","CooperBench is a benchmark of over 600 collaborative coding tasks across 12 libraries in 4 programming languages. Each task assigns two agents different features that can be implemented independently but may conflict without proper coordination. The study evaluates state-of-the-art coding agents and observes a significant drop in success rates when agents work together compared to performing tasks individually. The authors hypothesize that current agents lack coordination capabilities and develop three key issues: communication channels become jammed, agents deviate from commitments, and agents hold incorrect expectations about others' plans, observations, and communication.",308.13,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13317v1_Paid Voices vs. Public Feeds Interpretable Cross-P.pdf,Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme Modeling of Climate Discourse,"['Samantha Sudhoff*', 'Pranav Perumal', 'Zhaoqing Wu', 'Tunazzina Islam*']","Climate discourse online plays a crucial role in shaping public understanding of climate change and influencing political and policy outcomes. However, climate communication unfolds across structurally distinct platforms with fundamentally different incentive structures: paid advertising ecosystems incentivize targeted, strategic persuasion, while public social media platforms host largely organic, user-driven discourse. Existing computational studies typically analyze these environments in isolation, limiting our ability to distinguish institutional messaging from public expression. This work presents a comparative analysis of climate discourse across paid advertisements on Meta (previously known as Facebook) and public posts on Bluesky from July 2024 to September 2025. An interpretable, end-to-end thematic discovery and assignment framework clusters texts by semantic similarity and leverages large language models to generate concise, human-interpretable theme labels. The quality of induced themes is evaluated using both human judgments and an LLM-based evaluator, and their semantic coherence is validated through downstream tasks such as stance prediction and theme-guided retrieval. The resulting themes characterize systematic differences between paid climate messaging and public climate discourse and examine how thematic prevalence shifts around major political events. The findings show that platform-level incentives are reflected in the thematic structure, stance alignment, and temporal responsiveness of climate narratives. While the empirical analysis focuses on climate communication, the proposed framework supports comparative narrative analysis across heterogeneous communication environments.",332.9,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13327v1_PepEDiff Zero-Shot Peptide Binder Design via Prote.pdf,PepEDiﬀ: Zero-Shot Peptide Binder Design via Protein Embedding Diffusion,"['Po-Yu Liang', 'Tibo Duran', 'Jun Bai']","We present PepEDiﬀ, a novel peptide binder generator that designs binding sequences given a target receptor protein sequence and its pocket residues. Our approach departs from existing methods by generating binder sequences directly in a continuous latent space derived from a pretrained protein embedding model, without relying on predicted structures. This zero-shot generative strategy leverages the global protein embedding manifold as a semantic prior, allowing the model to propose novel peptide sequences in previously unseen regions of the protein space. We evaluate PepEDiﬀ on TIGIT, a challenging target with a large, flat protein-protein interaction interface that lacks a druggable pocket. Despite its simplicity, our method outperforms state-of-the-art approaches across benchmark tests and in the TIGIT case study, demonstrating its potential as a general, structure-free framework for zero-shot peptide binder design.",333.34,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13348v1_The AI Genie Phenomenon and Three Types of AI Chat.pdf,"The AI Genie Phenomenon and Three Types of AI Chatbot Addiction: Escapist Roleplays, Pseudosocial Companions, and Epistemic Rabbit Holes","['M. KAREN SHEN', 'Jessica Huang', 'OLIVIA LIANG', 'IG-JAE KIM', 'DONGWOOK YOON']","Recent reports on generative AI chatbot use raise concerns about its addictive potential. This study examines how to characterize AI chatbot addiction—why users become addicted, the symptoms commonly reported, and the distinct types it comprises. Users’ dependence tied to the “AI Genie” phenomenon—users can get exactly anything they want with minimal effort—and marked by symptoms that align with addiction literature. Three distinct addiction types: Escapist Roleplay, Pseudosocial Companion, and Epistemic Rabbit Hole, were found. Sexual content involved in multiple cases, and recovery strategies’ perceived helpfulness differ between addiction types. Our work lays empirical groundwork to inform future strategies for prevention, diagnosis, and intervention.",330.03,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13352v1_LLM-as-RNN A Recurrent Language Model for Memory U.pdf,LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction,"['Yuxing Lu', 'J. Ben Tamo', 'Weichen Zhao', 'Nan Sun', 'Yishan Zhong', 'Wenqi Shi', 'Jinzhuo Wang', 'May D. Wang']","Large language models are strong sequence predictors but lack an updatable memory mechanism after making an error. The paper proposes LLM-as-RNN, an inference-only framework that turns a frozen LLM into a recurrent predictor by representing its hidden state as natural-language memory. This state is updated at each timestep via feedback-driven text rewrites, enabling learning without parameter updates. Under a fixed token budget, LLM-as-RNN corrects errors and retains task-relevant patterns, effectively performing online learning through language. The method is evaluated on three sequential benchmarks in healthcare, meteorology, and finance across Llama, Gemma, and GPT model families, significantly outperforming zero-shot, full-history, and MemPrompt baselines.",331.59,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13358v1_The Geometry of Thought How Scale Restructures Rea.pdf,The Geometry of Thought: How Scale Restructures Reasoning in Large Language Models,['Samuel Cyrenius Anderson'],"This paper challenges the traditional scaling hypothesis by demonstrating that scale does not merely improve reasoning—it restructures it, triggering qualitative geometric reorganizations in how models represent the reasoning process itself. The authors analyze 25,000+ chain-of-thought trajectories across four domains (Law, Science, Code, Math) and two scales (8B, 70B parameters), revealing that neural scaling laws trigger domain-specific phase transitions rather than uniform capability gains. The paper introduces Neural Reasoning Operators—learned mappings from initial to terminal hidden states—and identifies a universal oscillatory signature invariant across domains and scales, suggesting attention and feedforward layers drive reasoning through opposing dynamics. These findings establish that the cost of thought is determined not by task difficulty but by manifold geometry, offering a blueprint for inference acceleration where topology permits.",333.63,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13376v1_Bounded Minds Generative Machines Envisioning Conv.pdf,"Bounded Minds, Generative Machines","['JIQUN LIU', 'The University of Oklahoma, USA']","Conversational AI systems are entering the mainstream as a primary interface for information seeking and decision making. Yet most systems, evaluations, and implicit user models still presume idealized users who can carefully weigh evidence and notice implausible claims. In reality, human cognition is bounded by limited time and attention, uneven domain knowledge, and reliance on heuristics that evolved to support fast judgments under uncertainty. This article outlines a research pathway grounded in bounded rationality, and argues that conversational AI should be designed to work with human heuristics rather than against them. It identifies key directions for detecting cognitive vulnerability, supporting judgment under uncertainty, and evaluating conversational systems beyond factual accuracy, toward decision quality and cognitive robustness.",330.94,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13383v1_A Lightweight Modular Framework for Constructing A.pdf,"A LIGHTWEIGHTMODULARFRAMEWORK FORCONSTRUCTING AUTONOMOUSAGENTSDRIVEN BYLARGELANGUAGE MODELS: DESIGN, IMPLEMENTATION,ANDAPPLICATIONS IN AGENTFORGE ∗","['A. A. Jafari', 'C. Ozcinar', 'G. Anbarjafari']","The paper presents AgentForge, a lightweight, open-source Python framework designed to democratize the construction of LLM-driven autonomous agents through a principled modular architecture. It introduces three key innovations: a composable skill abstraction, a unified LLM backend interface, and a declarative YAML-based configuration system. Comprehensive experimental evaluation demonstrates that AgentForge achieves competitive task completion rates and reduces development time compared to existing frameworks. The modular design facilitates extension and provides researchers and practitioners with a production-ready foundation for constructing, evaluating, and deploying autonomous agents without sacrificing flexibility or performance.",331.05,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13385v1_Organ-Aware Attention Improves CT Triage and Class.pdf,Organ-Aware Attention Improves CT Triage and Classification,"['Lavsen Dahal', 'Yubraj Bhandari', 'Geoffrey D. Rubin', 'Joseph Y . Lo']","This study presents ORACLE-CT, an encoder-agnostic, organ-aware head that pairs Organ-Masked Attention (mask-restricted, per-organ pooling that yields spatial evidence) with Organ-Scalar Fusion (lightweight fusion of normalized volume and mean-HU cues). In the chest setting, ORACLE-CT achieves AUROC 0.86 on CT-RATE; in the abdomen setting, it exceeds a reproduced zero-shot VLM baseline and further improves performance to AUROC 0.85. These results deliver state-of-the-art supervised classification performance across both chest and abdomen CT under a unified evaluation protocol.",329.31,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13392v1_Beyond Memorization Testing LLM Reasoning on Unsee.pdf,Beyond Memorization: Testing LLM Reasoning on Unseen Theory of Computation Tasks,"['Shlok Shelat', 'Ahmedabad University', 'Gujarat, India', 'Jay Raval', 'Ahmedabad University', 'Gujarat, India', 'Souvik Roy', 'Ahmedabad University', 'Gujarat, India', 'Manas Gaur', 'University of Maryland', 'Baltimore County', 'Baltimore, MD, USA']","Large language models (LLMs) have demonstrated strong performance on formal language tasks, yet whether this reflects genuine symbolic reasoning or pattern matching on familiar constructions remains unclear. We introduce a benchmark for DFA construction from regular languages, comprising factual knowledge questions, seen construction problems from public sources, and two types of unseen problems: hand-crafted instances with multiple interacting constraints and systematically generated problems via Arden's theorem. Models achieve perfect accuracy on factual questions and 84-90% on seen tasks. However, accuracy drops sharply on unseen problems (by 30-64%), with failures stemming from systematic misinterpretation of language constraints, incorrect handling of Kleene-star semantics, and a failure to preserve global consistency. We evaluate a three-stage hint protocol that enables correction of shallow errors but does not reliably resolve globally inconsistent or structurally flawed automata. Our analysis across multiple prompting strategies reveals that errors persist regardless of prompting approach, exposing a fundamental gap between LLMs' ability to generate syntactically plausible DFAs and their capacity for semantically correct formal reasoning.",332.99,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13398v1_Can LLMs Compress and Decompress Evaluating Code U.pdf,Evaluating Code Understanding and Execution via Invertibility,"['Nickil Maveli', 'Antonio Vergari', 'Shay B. Cohen']","Recent progress in Code-LLMs has demonstrated remarkable performance across various software engineering applications. However, evaluating the reasoning ability of Code-LLMs requires going beyond isolated input–output predictions. Most existing code reasoning benchmarks evaluate single-direction execution, either forward or backward. This paper presents ROUNDTRIPCODEEVAL (RTCE), a comprehensive benchmark consisting of four distinct code execution reasoning tasks designed to rigorously test round-trip consistency. RTCE provides an execution-free, exact-match evaluation of bijection fidelity, assessing whether models preserve a consistent one-to-one mapping between encoding and decoding operations across various algorithms and directions. The authors systematically evaluate state-of-the-art Code-LLMs using zero-shot prompting, supervised fine-tuning on execution traces, and self-reflection mechanisms. Each method yields modest improvements, but none closes the gap, indicating that current LLMs struggle with true round-trip consistency, which demonstrates that they lack the internal coherence required for trustworthy code reasoning. RTCE surfaces several new and previously unmeasured insights that are not captured by existing I/O-prediction, execution-reasoning, or round-trip natural-language benchmarks.",330.24,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13400v1_Deep Image Prior with L0 Gradient Regularizer for .pdf,DEEP IMAGE PRIOR WITH L0 GRADIENT REGULARIZER FOR IMAGE SMOOTHING,"['Nhat Thanh Tran', 'Kevin Bui', 'Jack Xin']","Image smoothing is a fundamental operation that preserves strong edges and contours while removing minor details and textures. Recent state-of-the-art methods leverage deep learning but require curated training datasets. This paper proposes DIP-ℓ 0, a deep image prior framework incorporating the ℓ 0 gradient regularizer. It performs high-quality smoothing without training data. The authors develop an alternating direction method of multipliers (ADMM) algorithm for nonconvex, nonsmooth ℓ 0 minimization. Numerical experiments show DIP-ℓ 0 outperforms many image smoothing algorithms in edge-preserving and JPEG artifact removal.",331.97,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13401v1_Reasoning with Pixel-level Precision QVLM Architec.pdf,QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics,"['Peter A. Massih', 'Eric Cosatto']","Current Vision-Language Models (VLMs) fail at quantitative spatial reasoning due to their architectures destroying pixel-level information required for counting and measurements. This paper presents two contributions to address this fundamental limitation. First, it introduces SQuID, a benchmark dataset of 2,000 satellite image Question-Answer pairs with numerical and categorical answers, designed to evaluate quantitative spatial reasoning. Second, it proposes QVLM, a code-generation architecture that maintains pixel precision by decoupling language understanding from visual analysis. QVLM generates executable code that first calls a segmentation model to obtain pixel-level masks, then operates directly on these masks, preserving spatial indexing throughout the reasoning process. Experiments show that QVLM using GPT-5 as a coder achieves 42.0% accuracy on SQuID compared to 28.1% for a VLM prompted with image-question pairs. The work reveals that architectural decoupling enables better accuracy on quantitative tasks, addressing real-world challenges in climate monitoring, urban planning, and disaster response.",331.66,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13404v1_Local-to-Global Logical Explanations for Deep Visi.pdf,Local-to-Global Logical Explanations for Deep Vision Models,"['Bhavan Vasu', 'Giuseppe Raffa', 'Prasad Tadepalli']","While deep neural networks are extremely effective at classifying images, they remain opaque and hard to interpret. We introduce local and global explanation methods for black-box models that generate explanations in terms of human-recognizable primitive concepts. Both the local explanations for a single image and the global explanations for a set of images are cast as logical formulas in monotone disjunctive-normal-form (MDNF), whose satisfaction guarantees that the model yields a high score on a given class. We also present an algorithm for explaining the classification of examples into multiple classes in the form of a monotone explanation list over primitive concepts. Despite their simplicity and interpretability, we show that the explanations maintain high fidelity and coverage with respect to the black-box models they seek to explain in challenging vision datasets.",332.16,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13406v1_Integrating Virtual Reality and Large Language Mod.pdf,Integrating Virtual Reality and Large Language Models for Team-Based Non-Technical Skills Training and Evaluation in the Operating Room,"['Jacob Barker', 'Doga Demirel', 'Cullen Jackson', 'Anna Johansson', 'Robbin Miraglia', 'Darian Hoagland', 'Stephanie B. Jones', 'John Mitchell', 'Daniel B. Jones', 'Suvranu De']","Although effective teamwork and communication are critical to surgical safety, structured training for non-technical skills (NTS) remains limited compared with technical simulation. The ACS/APDS Phase III Team-Based Skills Curriculum calls for scalable tools that both teach and objectively assess these competencies during laparoscopic emergencies. We introduce the Virtual Operating Room Team Experience (VORTeX), a multi-user virtual reality (VR) platform that integrates immersive team simulation with large language model (LLM) analytics to train and evaluate communication, decision-making, teamwork, and leadership. Team dialogue is analyzed using structured prompts derived from the Non-Technical Skills for Surgeons (NOTSS) framework, enabling automated classification of behaviors and generation of directed interaction graphs that quantify communication structure and hierarchy. Two laparoscopic emergency scenarios, pneumothorax and intra-abdominal bleeding, were implemented to elicit realistic stress and collaboration. Twelve surgical professionals completed pilot sessions at the 2024 SAGES conference, rating VORTeX highly.",331.2,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13412v1_Using deep learning for predicting cleansing quali.pdf,Using deep learning for predicting cleansing quality of colon capsule endoscopy images,"['Puneet Sharma', 'Kristian Dalsbø Hindberg', 'Benedicte Schelde-Olesen', 'Ulrik Deding', 'Esmaeil S. Nadimi', 'Jan-Matthias Braun']","In this study, we explore the application of deep learning techniques for predicting cleansing quality in colon capsule endoscopy (CCE) images. Using a dataset of 500 images labeled by 14 clinicians on the Leighton–Rex scale (Poor, Fair, Good, and Excellent), a ResNet-18 model was trained for classification, leveraging stratified K-fold cross validation to ensure robust performance. Structured pruning techniques were applied iteratively to achieve significant sparsity while maintaining high accuracy. The explainability of the pruned model was evaluated using various methods such as Grad-CAM, Grad-CAM++, Eigen-CAM, Ablation-CAM, and Random-CAM, with the ROAD method employed for consistent evaluation. Our results indicate that for a pruned model, we can achieve a cross-validation accuracy of 88% with 79% sparsity, demonstrating the effectiveness of pruning in improving efficiency from 84% without compromising performance. We also highlight the challenges of evaluating cleansing quality of CCE images and emphasize the importance of explainability in clinical applications, as well as the challenges associated with using the ROAD method for our task.",331.44,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13422v1_TrustEnergy A Unified Framework for Accurate and R.pdf,TrustEnergy: A Unified Framework for Accurate and Reliable User-level Energy Usage Prediction,"['Dahai Yu', 'Rongchao Xu', 'Dingyi Zhuang', 'Yuheng Bu', 'Shenhao Wang', 'Guang Wang']","This paper proposes a unified framework called TrustEnergy for accurate and reliable user-level energy usage prediction. The framework includes a Hierarchical Spatiotemporal Representation module to efficiently capture both macro and micro energy usage patterns and an innovative Sequential Conformalized Quantile Regression module to dynamically adjust uncertainty bounds. The authors implement and evaluate their TrustEnergy framework using an electricity provider in Florida, achieving a 5.4% increase in prediction accuracy and 5.7% improvement in uncertainty quantification compared to state-of-the-art baselines.",329.26,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13435v1_A Learnable Wavelet Transformer for Long-Short Equ.pdf,A Learnable Wavelet Transformer for Long-Short Equity Trading and Risk-Adjusted Return Optimization,"['Shuozhe Li', 'Du Cheng', 'Leqi Liu']","Learning profitable intraday trading policies from financial time series is challenging due to heavy noise, non-stationarity, and strong cross-sectional dependence among related assets. The paper proposes WaveLSFormer, a learnable wavelet-based long-short Transformer that jointly performs multi-scale decomposition and return-oriented decision learning. Specifically, a learnable wavelet front-end generates low-/high-frequency components via an end-to-end trained filter bank, guided by spectral regularizers that encourage stable and well-separated frequency bands. To fuse multi-scale information, a low-guided high-frequency injection (LGHI) module is introduced that refines low-frequency representations with high-frequency cues while controlling training stability. The model outputs a portfolio of long/short positions that is rescaled to satisfy a fixed risk budget and optimized directly with a trading objective and risk-aware regularization. Extensive experiments on five years of hourly data across six industry groups demonstrate that WaveLSFormer consistently outperforms MLP, LSTM, and Transformer backbones, with and without fixed discrete wavelet front-ends. On average in all industries, WaveLSFormer achieves a cumulative overall strategy return of 0.607±0.045 and a Sharpe ratio of 2.157±0.166, substantially improving both profitability and risk-adjusted returns over the strongest baselines.",313.44,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13437v1_MOSLD-Bench Multilingual Open-Set Learning and Dis.pdf,MOSLD-Bench: Multilingual Open-Set Learning and Discovery,"['Adriana-Valentina Costache', 'Daria-Nicoleta Dragomir', 'Silviu-Florin Gheorghe', 'Eduard Poesina', 'Paul Irofti', 'Radu Tudor Ionescu']","Open-set learning and discovery (OSLD) is a challenging machine learning task where samples from new (unknown) classes can appear at test time. It involves the active discovery of new classes. The authors introduce the first multilingual open-set learning and discovery (MOSLD) benchmark for text categorization, comprising 960K data samples across 12 languages. They propose a novel framework for the OSLD task, integrating multiple stages to continuously discover and learn new classes. They evaluate several language models, including their own, and release the benchmark at https://github.com/Adriana19Valentina/MOSLD-Bench.",308.68,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13443v1_Explicit Cognitive Allocation A Principle for Gove.pdf,Explicit Cognitive Allocation: A Principle for Governed and Auditable Inference in Large Language Models,"['Héctor Manuel Manzanilla-Granados', 'Zaira Navarrete-Cazales', 'Miriam Pescador-Rojas', 'Tonahtiu Ramírez-Romero']","The rapid adoption of large language models (LLMs) has enabled new forms of AI-assisted reasoning across scientific, technical, and organizational domains. However, prevailing modes of LLM use remain cognitively unstructured, leading to limitations in traceability, epistemic control, and reproducibility. This paper introduces Explicit Cognitive Allocation (ECA), a principle for structuring AI-assisted inference through the explicit separation and orchestration of epistemic functions. ECA is instantiated in the Cognitive Universal Agent (CUA), an architecture that organizes inference into distinct stages of exploration and framing, epistemic anchoring, instrumental and methodological mapping, and interpretive synthesis. The paper evaluates the effects of ECA through controlled comparisons between CUA-orchestrated inference and baseline LLM inference, demonstrating improved epistemic convergence, alignment, and exposure of the instrumental landscape. These results establish ECA as a model-agnostic architectural principle for improving the controllability, auditability, and epistemic scope of AI-assisted reasoning.",314.99,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13458v1_Labels or Preferences Budget-Constrained Learning .pdf,Budget-Constrained Learning with Human Judgments over AI-Generated Outputs,"['Zihan Dong', 'Ruijia Wu', 'Linjun Zhang']","The increasing reliance on human preference feedback to judge AI-generated pseudo labels has created a pressing need for principled, budget-conscious data acquisition strategies. This work addresses the crucial question of how to optimally allocate a fixed annotation budget between ground-truth labels and pairwise preferences in AI. The solution, grounded in semi-parametric inference, casts the budget allocation problem as a monotone missing data framework. Building on this formulation, the authors introduce Preference-Calibrated Active Learning (PCAL), a novel method that learns the optimal data acquisition strategy and develops a statistically efficient estimator for functionals of the data distribution. Theoretical proofs demonstrate the asymptotic optimality of the PCAL estimator and establish robustness guarantees. The flexible framework applies to a general class of problems, directly optimizing the estimator's variance. Simulations and real-data analysis demonstrate the practical benefits and superior performance of the proposed method.",310.84,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13462v1_SpatialBench-UC Uncertainty-Aware Evaluation of Sp.pdf,SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt Following in Text-to-Image Generation,['Amine Rostane'],"Evaluating whether text to image models follow explicit spatial instructions is difficult to automate. Object detectors may miss targets or return multiple plausible detections, and simple geometric tests can become ambiguous in borderline cases. Spatial evaluation is naturally a selective prediction problem, a checker should be allowed to abstain when evidence is weak and should report confidence so results can be interpreted as a risk–coverage trade-off rather than a single score. We introduce SpatialBench-UC, a small, reproducible benchmark for pairwise spatial relations. The benchmark contains 200 prompts (50 object pairs × 4 relations) grouped into 100 counterfactual pairs obtained by swapping object roles. We release a benchmark package, versioned prompts, pinned configs, per-sample checker outputs, and report tables, enabling reproducible and auditable comparisons across models. We also include a lightweight human audit (N=200) used to calibrate the checker's abstention margin and confidence threshold. On three baselines, Stable Diffusion 1.5 (prompt-only), SD 1.5+BoxDiff, and SD 1.4+GLIGEN, the checker reports (PASS rate / coverage): 11.8% / 23.8%, 40.4% / 42.5%, and 51.6% / 52.0%, with conditional PASS rates of 49.5%, 95.0%, and 99.3% on decided samples. P ASS denotes the checker's judgment, not human-verified accuracy unless validated by audit labels.",309.55,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13464v1_Context and Transcripts Improve Detection of Deepf.pdf,Context and Transcripts Improve Detection of Deepfake Audios of Public Figures,"['Chongyang Gao', 'Marco Postiglione', 'Julian Baldwin', 'Natalia Denisenko', 'Isabel Gortner', 'Luke Fosdick', 'Chiara Pulice', 'Sarit Kraus', 'V. S. Subrahmanian']","Humans use context to assess the veracity of information. However, current audio deepfake detectors only analyze the audio file without considering either context or transcripts. We create and analyze a Journalist-provided Deepfake Dataset (JDD) of 255 public deepfakes and propose a novel Context-based Audio Deepfake Detector (CADD) architecture. We show that sufficient context and/or the transcript can significantly improve the efficacy of audio deepfake detectors. Performance of multiple baseline audio deepfake detectors and traditional classifiers can be improved by 5%-37.58% in F1-score, 3.77%-42.79% in AUC, and 6.17%-47.83% in EER. CADD, via its use of context and/or transcripts, is more robust to 5 adversarial evasion strategies, limiting performance degradation to an average of just -0.71% across all experiments. Code, models, and datasets are available at our project page: https://sites.northwestern.edu/nsail/cadd-context-based-audio-deepfake-detection/(access restricted during review).",312.73,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13465v1_Graph Neural Networks are Heuristics.pdf,Graph Neural Networks are Heuristics,"['Yimeng Min', 'Carla P. Gomes']","The authors demonstrate that a single training trajectory can transform a graph neural network into an unsupervised heuristic for combinatorial optimization. Focusing on the Travelling Salesman Problem, they show that encoding global structural constraints as an inductive bias enables a non-autoregressive model to generate solutions via direct forward passes, without search, supervision, or sequential decision-making. At inference time, dropout and snapshot ensembling allow a single model to act as an implicit ensemble, reducing optimality gaps through increased solution diversity. The results establish that graph neural networks do not require supervised training nor explicit search to be effective. Instead, they can internalize global combinatorial structure and function as strong, learned heuristics.",309.75,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13474v1_Preconditioning Benefits of Spectral Orthogonaliza.pdf,The Muon algorithm and prior theory,"['Jianhao Ma', 'Yu Huang', 'Yuejie Chi', 'Yuxin Chen']","The Muon algorithm, a matrix-structured optimizer that leverages spectral orthogonalization of gradients, has been shown to outperform conventional optimizers like gradient descent and Adam in training large language models. This paper studies the effectiveness of a simplified variant of Muon through two case studies: matrix factorization and in-context learning of linear transformers. It proves that simplified Muon converges linearly with iteration complexities independent of the condition number, outperforming gradient descent and Adam. The analysis reveals that Muon dynamics decouple into scalar sequences in the spectral domain, each with similar convergence behavior. The theory formalizes the preconditioning effect induced by spectral orthogonalization, offering insight into Muon's effectiveness in matrix optimization problems and potentially beyond.",311.06,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13476v1_A Unified Variational Imputation Framework for Ele.pdf,A Unified Variational Imputation Framework for Electric Vehicle Charging Data Using Retrieval-Augmented Language Model,"['Jinhao Li', 'Hao Wang, Member IEEE']","The reliability of data-driven applications in electric vehicle (EV) infrastructure, such as charging demand forecasting, hinges on the availability of complete, high-quality charging data. However, real-world EV datasets are often plagued by missing records, and existing imputation methods are ill-equipped for the complex, multimodal context of charging data, often relying on a restrictive one-model-per-station paradigm that ignores valuable inter-station correlations. To address these gaps, we develop a novel probabilistic variational imputation framework that leverages the power of large language models and retrieval-augmented memory (PRAIM). PRAIM employs a pre-trained language model to encode heterogeneous data, spanning time-series demand, calendar features, and geospatial context, into a unified, semantically rich representation. This is dynamically fortified by retrieval-augmented memory that retrieves relevant examples from the entire charging network, enabling a single, unified imputation model empowered by variational neural architecture to overcome data sparsity. Extensive experiments on four public datasets demonstrate that PRAIM significantly outperforms established baselines in both imputation accuracy and its ability to preserve the original data's statistical distribution, leading to substantial improvements in downstream forecasting performance.",312.24,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13481v1_Towards Efficient and Robust Linguistic Emotion Di.pdf,Towards Efficient and Robust Linguistic Emotion Diagnosis for Mental Health via Multi-Agent Instruction Refinement,"['Jian Zhang', 'Zhangqi Wang', 'Zhiyuan Wang', 'Weiping Fu', 'Yu He', 'Haiping Zhu∗', 'Qika Lin∗', 'Jun Liu']","Linguistic expressions of emotions, including depression, anxiety, and trauma-related states, are widespread in clinical notes, counseling dialogues, and online mental health communities. Accurate recognition of these emotions is crucial for clinical triage, risk assessment, and timely intervention in mental health related applications. Despite recent advances showing that large language models (LLMs) can generalize well to various emotion analysis tasks, their diagnostic reliability in high-stakes and context-intensive medical settings remains highly sensitive to prompt design. Existing approaches are challenged by two major issues: emotional comorbidity, where multiple intertwined emotional states complicate prediction, and inefficient exploration of clinically relevant cues. To address these issues, we propose APOLO (Automated Prompt Optimization for Linguistic emotion diagnosis), a framework that systematically explores a broader and finer-grained prompt space to enhance diagnostic efficiency and robustness. APOLO models instruction refinement as a Partially Observable Markov Decision Process (POMDP) and introduces a multi-agent collaboration mechanism comprising the Planner–Teacher–Critic–Student–Target roles. This closed-loop design enables continuous optimization of prompt generation, evaluation, and evolution. Experimental results demonstrate that APOLO improves diagnostic accuracy and robustness across domain-specific and stratified benchmarks, providing a generalizable and scalable paradigm for trustworthy LLM applications in mental healthcare.",309.0,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13487v1_The Hidden Toll of Social Media News Causal Effect.pdf,The Hidden Toll of Social Media News: Causal Effects on Psychosocial Wellbeing,"['Olivia Pal', 'Agam Goyal', 'Eshwar Chandrasekharan', 'Koustuv Saha']","News consumption on social media has become ubiquitous, yet the impact on psychosocial outcomes remains unclear. This study leveraged a large-scale dataset of ∼26M posts and ∼45M comments on the Bluesky platform, matching 81,345 treated users exposed to Newsfeeds with 83,711 control users using stratified propensity score analysis. The findings reveal that news engagement produces systematic trade-offs: increased depression, stress, and anxiety, yet decreased loneliness and increased social interaction. Regression models show that Newsfeed bookmarking is associated with greater psychosocial deterioration compared to commenting or quoting, with magnitude differences exceeding tenfold. These per-engagement effects accumulate with repeated exposure, showing significant psychosocial impacts. The study extends theories of news effects beyond crisis-centric frameworks by demonstrating that routine consumption creates distinct psychological dynamics depending on engagement type, and bears implications for tools and interventions to mitigate the psychosocial costs of news consumption on social media.",310.61,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13508v1_CatMaster An Agentic Autonomous System for Computa.pdf,CatMaster: An Agentic Autonomous System for Computational Heterogeneous Catalysis Research,"['Honghao Chen', 'Jiangjie Qiu', 'Yi Shen Tew', 'Xiaonan Wang ∗']","Density functional theory (DFT) is widely used to connect atomic structure with catalytic behavior, but computational heterogeneous catalysis studies often require long workflows that are costly, iterative, and sensitive to setup choices. CatMaster, a large-language-model (LLM)-driven agent system, turns natural language requests into complete calculation workspaces, including structures, inputs, outputs, logs, and a concise run record. It maintains a persistent project record of key facts, constraints, and file pointers to support inspection and restartability. CatMaster is paired with a multi-fidelity tool library that covers rapid surrogate relaxations and high-fidelity DFT calculations for validation when needed. We demonstrate CatMaster on four demonstrations of increasing complexity.",313.46,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13515v1_Automatic Adjustment of HPA Parameters and Attack .pdf,Automatic Adjustment of HPA Parameters and Attack Prevention in Kubernetes Using Random Forests,"['Huah Yong Chan', 'Hanlin Zhou', 'Jingfei Ni', 'Mengchun Wu', 'Qing Deng']","In this paper, HTTP status codes are used as custom metrics within the HPA as the experimental scenario. By integrating the Random Forest classification algorithm from machine learning, attacks are assessed and predicted, dynamically adjusting the maximum pod parameter in the HPA to manage attack traffic. This approach enables the adjustment of HPA parameters using machine learning scripts in targeted attack scenarios while effectively managing attack traffic. All access from attacking IPs is redirected to honeypot pods, achieving a lower incidence of 5XX status codes through HPA pod adjustments under high load conditions. This method also ensures effective isolation of attack traffic, preventing excessive HPA expansion due to attacks. Additionally, experiments conducted under various conditions demonstrate the importance of setting appropriate thresholds for HPA adjustments.",308.59,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13518v1_AgenticRed Optimizing Agentic Systems for Automate.pdf,AGENTICRED: Optimizing Agentic Systems for Automated Red-teaming,"['Jiayi Yuan*', 'Jonathan Nöther', 'Natasha Jaques', 'Goran Radanović']","While recent automated red-teaming methods show promise for systematically exposing model vulnerabilities, most existing approaches rely on human-specified workflows. This dependence on manually designed workflows suffers from human biases and makes exploring the broader design space expensive. We introduce AGENTICRED, an automated pipeline that leverages LLMs' in-context learning to iteratively design and refine red-teaming systems without human intervention. Rather than optimizing attacker policies within predefined structures, AGENTICRED treats red-teaming as a system design problem. Inspired by methods like Meta Agent Search, we develop a novel procedure for evolving agentic systems using evolutionary selection, and apply it to the problem of automatic red-teaming. Red-teaming systems designed by AGENTICRED consistently outperform state-of-the-art approaches, achieving 96% attack success rate on Llama-2-7B (36% improvement) and 98% on Llama-3-8B on HarmBench. Our approach exhibits strong transferability to proprietary models, achieving 100% attack success rate on GPT-3.5-Turbo and GPT-4o-mini, and 60% on Claude-Sonnet-3.5 (24% improvement). This work highlights automated system design as a powerful paradigm for AI safety evaluation that can keep pace with rapidly evolving models. Project website: https://yuanjiayiy.github.io/AgenticRed",308.66,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13528v1_Eliciting Harmful Capabilities by Fine-Tuning On S.pdf,ELICITING HARMFUL CAPABILITIES BY FINE-TUNING ON SAFEGUARDED OUTPUTS,"['Jackson Kaunismaa∗', 'MATS Avery Griffin', 'John Hughes', 'Christina Q Knight', 'Mrinank Sharma†', 'Erik Jones†']","This work demonstrates that even robustly safeguarded models can be used to elicit harmful capabilities in open-source models through elicitation attacks. The attacks consist of three stages: constructing prompts in adjacent domains to a target harmful task, obtaining responses from safeguarded frontier models, and fine-tuning open-source models on these prompt-output pairs. The attacks are evaluated within the domain of hazardous chemical synthesis and processing, and it is shown that they recover approximately 40% of the capability gap between the base open-source model and an unrestricted frontier model. The efficacy of the attacks scales with the capability of the frontier model and the amount of generated fine-tuning data. The work highlights the challenge of mitigating ecosystem-level risks with output-level safeguards.",309.32,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13533v1_Reasoning While Recommending Entropy-Guided Latent.pdf,JSON_FAIL,[],N/A,178.54,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13534v1_MN-TSGContinuous Time Series Generation with Irreg.pdf,MN-TSG: CONTINUOUS TIMESERIES GENERATION WITH IRREGULAR OBSERVATIONS,"['Xu Zhang', 'Junwei Deng', 'Chang Xu', 'Hao Li', 'Jiang Bian']","Time series generation (TSG) plays a critical role in various domains, including healthcare. However, most existing methods assume regularly sampled observations and fixed output resolutions, which are often misaligned with real-world scenarios. Neural Controlled Differential Equations (NCDEs) have shown strong potential for modeling irregular time series, but they still face challenges in capturing complex dynamic temporal patterns and supporting continuous TSG. To address these limitations, the authors propose MN-TSG, a novel framework that explores Mixture-of-Experts (MoE)–based NCDEs and integrates them with existing TSG models for irregular and continuous generation tasks. The core of MN-TSG is a MoE-NCDE architecture with dynamically parameterized expert functions and a decoupled design that facilitates more effective optimization of MoE dynamics. The framework not only generates new samples but also produces appropriate expert configurations tailored to each sample, supporting refined continuous TSG. Extensive experiments on ten public and synthetic datasets demonstrate the effectiveness of MN-TSG, consistently outperforming strong TSG baselines on both irregular-to-regular and irregular-to-continuous generation tasks.",333.51,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13537v1_When Wording Steers the Evaluation Framing Bias in.pdf,When Wording Steers the Evaluation: Framing Bias in LLM judges,"['Yerin Hwang', 'Dongryeol Lee', 'Taegwan Kang', 'Minwoo Lee', 'Kyomin Jung']","Large language models (LLMs) are known to produce varying responses depending on prompt phrasing, indicating that subtle guidance in phrasing can steer their answers. However, the impact of this framing bias on LLM-based evaluation, where models are expected to make stable and impartial judgments, remains largely underexplored. This paper systematically investigates how deliberate prompt framing skews model judgments across four high-stakes evaluation tasks. We design symmetric prompts using predicate-positive (P) and predicate-negative (¬P) constructions and demonstrate that such framing induces significant discrepancies in model outputs. Across 14 LLM judges, we observe clear susceptibility to framing, with model families showing distinct tendencies toward agreement or rejection. These findings suggest that framing bias is a structural property of current LLM-based evaluation systems, underscoring the need for framing-aware protocols.",330.66,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13545v1_TruthTensor Evaluating LLMs Human Imitation throug.pdf,TRUTHTENSOR: EVALUATINGLLMSHUMANIMITATION THROUGH PREDICTIONMARKETDRIFT ANDHOLISTICREASONING,"['Shirin Shahabi', 'Spencer Graham', 'Haruna Isah']","This paper introduces TruthTensor, a novel evaluation paradigm for Large Language Models (LLMs) that measures them not only as prediction engines but as human-imitation systems operating in socially-grounded, high-entropy environments. TruthTensor anchors evaluation to live prediction markets and combines probabilistic scoring to provide a holistic view of model behavior. It complements traditional correctness metrics with drift-centric diagnostics and robustness checks for reproducibility. The framework specifies human vs. automated evaluation roles, annotation protocols, and statistical testing procedures to ensure interpretability and replicability of results. In experiments across 500+ real markets, TruthTensor demonstrates that models with similar forecast accuracy can diverge markedly in calibration, drift, and risk-sensitivity, underscoring the need to evaluate models along multiple axes (accuracy, calibration, narrative stability, cost, and resource efficiency).",329.41,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13546v1_ChatAD Reasoning-Enhanced Time-Series Anomaly Dete.pdf,ChatAD: Reasoning-Enhanced Time-Series Anomaly Detection with Multi-Turn Instruction Evolution,"['Hui Sun', 'Chang Xu', 'Haonan Xie', 'Hao Li', 'Yuhao Huang', 'Chuheng Zhang', 'Ming Jin', 'Xiaoguang Liu', 'Gang Wang', 'Jiang Bian']","This paper proposes a multi-agent-based Time Series Evolution algorithm named TSEvol, introduces the AD reasoning & multi-turn dialogue Dataset TSEData-20K, and contributes the Chatbot family for AD, including ChatAD-Llama3-8B, ∼Qwen2.5-7B, and ∼Mistral-7B. It also proposes the TS Kahneman-Tversky Optimization (TKTO) to enhance ChatAD's cross-task generalization capability. Lastly, it proposes the LLM-driven Learning-based AD Benchmark LLADBench to evaluate ChatAD and nine baselines across seven datasets and tasks. Our three ChatAD models achieve substantial gains in accuracy, F1, and false positives reduction.",330.19,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13547v1_HateXScore A Metric Suite for Evaluating Reasoning.pdf,HateXScore: A Metric Suite for Evaluating Reasoning Quality in Hate Speech Explanations,"['Yujia Hu', 'Roy Ka-Wei Lee']","Hateful speech detection is a key component of content moderation, but current evaluation frameworks rarely assess why a text is deemed hateful. This paper introduces HateXScore, a four-component metric suite designed to evaluate the reasoning quality of model explanations. It assesses conclusion explicitness, faithfulness and causal grounding of quoted spans, protected group identification (policy-configurable), and logical consistency among these elements. Evaluated on six diverse hate speech datasets, HateXScore is intended as a diagnostic complement to reveal interpretability failures and annotation inconsistencies that are invisible to standard metrics like Accuracy or F1. Human evaluation shows strong agreement with HateXScore, validating it as a practical tool for trustworthy and transparent moderation.",328.72,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13558v1_Leveraging ChatGPT and Other NLP Methods for Ident.pdf,Leveraging ChatGPT and Other NLP Methods for Identifying Risk and Protective Behaviors in MSM: Social Media and Dating Apps Text Analysis,"['Mehrab Beikzadeh', 'Chenglin Hong', 'Cory J Cascalheira', 'Callisto Boka', 'Majid Sarrafzadeh', 'Ian W Holloway']","The study aimed to determine whether text data from social media and dating apps can predict risk and protective behaviors among MSM. Textual data was gathered with user consent and machine learning models were trained to identify various risk behaviors such as condomless anal sex, number of sexual partners, binge drinking, and heavy drinking. Drinking outcomes were based on the Alcohol Use Disorders Identification Test (AUDIT-C). A model was also trained to determine PrEP use. Features were extracted using ChatGPT embeddings, BERT embeddings, LIWC analysis, and a custom dictionary-based approach. The model was highly predictive of monthly binge drinking and having over 5 sexual partners (F1 scores 0.78 and 0.78), but slightly less predictive of PrEP use and heavy drinking (F1 scores 0.64 and 0.63). ChatGPT embeddings were highly informative, and combining them with LIWC and BERT and using the most correlated features improved performance. The findings suggest that text data can provide valuable insights into specific risk and protective behaviors, and increasing data volume could enhance results, particularly for less common behaviors.",332.21,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13559v1_AgentGC Evolutionary Learning-based Lossless Compr.pdf,AgentGC: Evolutionary Learning-based Lossless Compression for Genomics Data with LLM-driven Multiple Agent,"['Hui Sun', 'Yanfeng Ding', 'Huidong Ma', 'Chang Xu', 'Keyan Jin', 'Lizheng Zu', 'Cheng Zhong', 'Xiaoguang Liu', 'Gang Wang', 'Wentong Cai']","Lossless compression has made significant advancements in Genomics Data (GD) storage, sharing, and management. Current learning-based methods are non-evolvable, with issues of low-level compression modeling, limited adaptability, and user-unfriendly interfaces. This paper proposes AgentGC, the first evolutionary Agent-based GD Compressor, consisting of three layers with multi-agent named Leader and Worker. The User layer provides a user-friendly interface via Leader combined with LLM, the Cognitive layer integrates LLM to consider joint optimization of algorithm-dataset-system, and the Compression layer performs compression & decompression via an automated multi-knowledge learning-based framework. AgentGC supports three modes: CP for compression-ratio priority, TP for throughput priority, and BM for balanced mode. Compared with 14 baselines on 9 datasets, AgentGC achieves average compression ratios gains of 16.66%, 16.11%, and 16.33%, and throughput gains of 4.73×, 9.23×, and 9.15×, respectively.",327.74,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13562v1_Reasoning is a Modality.pdf,Reasoning is a Modality,"['Zhiguang Liu', 'Yi Shang']","The Abstraction and Reasoning Corpus (ARC) provides a compact laboratory for studying abstract reasoning, an ability central to human intelligence. Modern AI systems, including LLMs and ViTs, operate as sequence-of-behavior prediction machines, matching observable behaviors without a persistent, readable mental state. The authors hypothesize that reasoning is a modality, distinct from the low-level workspace on which rules are applied. They designed a role-separated transformer block to enable iterative rule execution, achieving 62.6% accuracy on ARC-1, surpassing average human performance (60.2%). The models exhibit more coherent rule-application structure than dense ViT baselines, consistent with a shift from plausible probability blobs to controller-driven reasoning.",326.03,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13563v1_ButterflyMoE Sub-Linear Ternary Experts via Struct.pdf,ButterflyMoE: Sub-Linear Ternary Experts via Structured Butterfly Orbits,['Aryan Karmore'],"Linear memory scaling in a MoE layer with 64 experts and dimension d=512 requires 256 MB of memory, exceeding edge device limits. Current compression methods like quantization, pruning, and low-rank factorization reduce constant factors but leave the scaling bottleneck unresolved. The paper introduces ButterflyMoE, a method that treats experts as geometric reorientations of a unified shared quantized substrate. Diversity among experts arises from viewing different angles of shared capacity, not from redundant storage. By applying learned rotations to a shared ternary prototype, each expert yields O(d^2 + N·dlogd) memory—sub-linear in the number of experts. The key insight is that training these rotations with quantization reduces activation outliers and stabilizes extreme low-bit training, where static methods collapse. Across language modeling benchmarks, ButterflyMoE achieves 150× memory reduction at 256 experts with negligible accuracy loss, allowing 64 experts to fit on 4GB devices compared to standard MoE's 8 experts. This shows geometric parametrization breaks linear scaling.",331.66,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13564v1_Multi-objective fluorescent molecule design with a.pdf,Multi-objective fluorescent molecule design with a data-physics dual-driven generative framework,"['Yanheng Li', 'Zhichen Pu', 'Lijiang Yang', 'Zehao Zhou', 'Yi Qin Gao']","This paper presents a novel approach to designing multi-objective fluorescent molecules using a data-physics dual-driven generative framework. The authors introduce a method that integrates data-driven and physics-informed principles to optimize the design of fluorescent molecules. The framework aims to address the challenges of designing molecules with multiple desirable properties simultaneously, which is a complex task in synthetic chemistry. The authors demonstrate the effectiveness of their approach through a series of experiments and provide insights into the underlying mechanisms.",329.38,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13566v1_Self-Improvement as Coherence Optimization A Theor.pdf,Self-Improvement as Coherence Optimization: A Theoretical Account,"['Tianyi Qiu', 'Ahmed Hani Ismail', 'Zhonghao He', 'Shi Feng']","This paper provides a theoretical explanation for why language models can improve their accuracy without external supervision. It shows that methods such as debate, internal coherence maximization, iterative bootstrap, and Metropolis-Hastings sampling all optimize the same objective: coherence, defined as the joint likelihood of the model's behaviors across all contexts. The authors prove that coherence optimization is equivalent to description-length regularization and that it is the optimal regularization scheme for semi-supervised learning when the regularizer is derived from a pretrained model. The paper explains why feedback-free self-improvement works and predicts when it should succeed or fail.",331.84,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13570v1_GeoDynamics A Geometric State-Space Neural Network.pdf,GeoDynamics: A Geometric State-Space Neural Network for Understanding Brain Dynamics on Riemannian Manifolds,"['Tingting Dan', 'Jiaqi Ding', 'Guorong Wu ∗']","State-space models (SSMs) have become a cornerstone for unraveling brain dynamics, revealing how latent neural states evolve over time and give rise to observed signals. Recent studies have achieved powerful fits to functional neuroimaging data by combining deep learning’s flexibility with SSMs’ principled dynamical structure. However, most approaches still view the brain as a set of loosely connected regions or impose oversimplified network priors, falling short of a truly holistic, self-organized dynamical system perspective. Brain functional connectivity (FC) at each time point naturally forms a symmetric positive–definite (SPD) matrix, which lives on a curved Riemannian manifold rather than in Euclidean space. Capturing the trajectories of these SPD matrices is key to understanding how coordinated networks support cognition and behavior. To this end, we introduce GeoDynamics, a geometric state-space neural network that tracks latent brain-state trajectories directly on the high-dimensional SPD manifold. GeoDynamicsembeds each connectivity matrix into a manifold -aware recurrent framework, learning smooth, geometry-respecting transitions that reveal task-driven state changes and early markers of Alzheimer’s, Parkinson’s, and autism. Beyond neuroscience, we validate GeoDynamicson human action recognition benchmarks (UTKinect, Florence, HDM05), demonstrating its scalability and robustness in modeling complex spatiotemporal dynamics across diverse domains.",332.76,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13580v1_Neural Organ Transplantation NOT Checkpoint-Based .pdf,NEURALORGANTRANSPLANTATION(NOT): CHECKPOINT-BASEDMODULARADAPTATION FOR TRANSFORMERMODELS,['Ahmad Al-Zuraiqi'],"We introduce Neural Organ Transplantation (NOT), a modular adaptation framework that enables trained transformer layers to function as reusable transferable checkpoints for domain adaptation. Unlike conventional fine-tuning approaches, NOT extracts contiguous layer subsets from pre-trained models, trains them independently on domain-specific data, and saves them as standalone checkpoint files. Through experiments on three decoder-only transformer architectures, we demonstrate that donor transplantation substantially outperforms existing adaptation methods, achieving an order-of-magnitude improvement in perplexity over LoRA while training significantly faster. The method exhibits position dependence and reveals unexpected regularization benefits at billion-parameter scale. These findings demonstrate that transformer middle layers can support efficient modular transfer for decoder-only architectures, enabling privacy-preserving expertise sharing through checkpoint distribution. The approach is currently limited to decoder-only models.",330.33,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13581v1_SCRIPTMIND Crime Script Inference and Cognitive Ev.pdf,Crime Script Inference and Cognitive Evaluation for LLM-based Social Engineering Scam Detection System,"['Heedou Kim', 'Changsik Kim', 'Sanghwa Shin', 'Jaewoo Kang']","Social engineering scams increasingly employ personalized, multi-turn deception, exposing the limits of traditional detection methods. While Large Language Models (LLMs) show promise in identifying deception, their cognitive assistance potential remains underexplored. This paper proposes SCRIPTMIND, an integrated framework for LLM-based scam detection that bridges automated reasoning and human cognition. It comprises three components: the Crime Script Inference Task (CSIT) for scam reasoning, the Crime Script–Aware Inference Dataset (CSID) for fine-tuning small LLMs, and the Cognitive Simulation-based Evaluation of Social Engineering Defense (CSED) for assessing real-time cognitive impact. Using 571 Korean phone scam cases, the authors built 22,712 structured scammer-sequence training instances. Experimental results show that the 11B small LLM fine-tuned with SCRIPTMIND outperformed GPT-4 by 13%, achieving superior performance in detection accuracy, false-positive reduction, scammer utterance prediction, and rationale quality. Moreover, in phone scam simulation experiments, it significantly enhanced and sustained users' suspicion levels, improving their cognitive awareness of scams. SCRIPTMIND represents a step toward human-centered, cognitively adaptive LLMs for scam defense.",330.76,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13588v1_TREX Tokenizer Regression for Optimal Data Mixture.pdf,TokenizerRegression for Optimal Data Mixture (TREX),"['Inho Won', 'Hangyeol Yoo', 'Minkyung Cho', 'Jungyeul Park', 'Hoyun Song', 'KyungTae Lim']","Building effective tokenizers for multilingual Large Language Models (LLMs) requires careful control over language-specific data mixtures. Existing approaches rely on heuristics or costly large-scale searches to determine optimal language ratios. This work introduces TReX, a regression-based framework that efficiently predicts the optimal data mixture for tokenizer training. TReX trains small-scale proxy tokenizers on random mixtures, gathers their compression statistics, and learns to predict compression performance from data mixtures. This learned model enables scalable mixture search before large-scale tokenizer training, mitigating the accuracy-cost trade-off in multilingual tokenizer design. Tokenizers trained with TReX's predicted mixtures outperform mixtures based on LLaMA3 and uniform distributions by up to 12% in both in- and out-of-distribution compression efficiency, demonstrating strong scalability, robustness, and practical effectiveness.",330.61,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13589v1_Motion-to-Response Content Generation via Multi-Ag.pdf,MOTION-TO-RESPONSECONTENTGENERATION VIA MULTI-AGENTAI SYSTEM WITHREAL-TIMESAFETYVERIFICATION,['HyeYoung Lee'],"This paper proposes a multi-agent artificial intelligence system that generates response-oriented media content in real time based on audio-derived emotional signals. Unlike conventional speech emotion recognition studies that focus primarily on classification accuracy, our approach emphasizes the transformation of inferred emotional states into safe, age-appropriate, and controllable response content through a structured pipeline of specialized AI agents. The system comprises four cooperative agents: an Emotion Recognition Agent, a Response Policy Decision Agent, a Content Parameter Generation Agent, and a Safety Verification Agent. Experimental results demonstrate that the system achieves 73.2% emotion recognition accuracy, 89.4% response mode consistency, and 100% safety compliance while maintaining sub-100ms inference latency.",332.49,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13590v1_Vulnerability of LLMs Belief Systems LLMs Belief R.pdf,Vulnerability of LLMs’ Belief Systems? LLMs Belief Resistance Check Through Strategic Persuasive Conversation Interventions,"['Fan Huang', 'Haewoon Kwak', 'Jisun An']","Large Language Models (LLMs) are increasingly employed in various question-answering tasks. Recent studies show that LLMs are susceptible to persuasion and can adopt counterfactual beliefs. This work presents a systematic evaluation of LLM susceptibility to persuasion under the Source–Message–Channel–Receiver (SMCR) communication framework. Across five mainstream LLMs and three domains (factual knowledge, medical QA, and social bias), the study analyzes how different persuasive strategies influence belief stability over multiple interaction turns. Meta-cognition prompting, which elicits self-reported confidence, increases vulnerability by accelerating belief erosion rather than enhancing robustness. The findings highlight substantial model-dependent limits of current robustness interventions and offer guidance for developing more trustworthy LLMs.",330.48,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13591v1_DSAEval Evaluating Data Science Agents on a Wide R.pdf,DSAEval: Evaluating Data Science Agents on a Wide Range of Real-World Data Science Problems,"['Maojun Sun', 'Yifei Xie', 'Yue Wu', 'Ruijian Han', 'Binyan Jiang', 'Defeng Sun', 'Yancheng Yuan', 'Jian Huang']","Recent advances in Large Language Model (LLM)-based data science agents have significantly promoted the automation of data science tasks, encompassing exploratory data analysis and traditional machine learning to complex deep learning workflows. However, evaluating these agents remains a formidable challenge due to the open-ended nature of real-world data science problems, which lack unique, standardized solutions. To address this, we introduce DSAEval, a comprehensive benchmark designed to evaluate data science agents using large-scale, real-world problems. DSAEval spans broad domains of data science problems, including Statistical Testing & Inference (STI), Data Mining, and Data Visualization. It incorporates three distinctive features: Multi-Modal Environment Perception, Multi-Query Interactions, and Multi-Dimensional Evaluation. We systematically evaluate 11 advanced agentic LLMs using DSAEval, demonstrating that Claude-Sonnet-4.5 achieves the strongest overall performance, GPT-5.2 is the most efficient, and MiMo-V2-Flash is the most cost-effective. The results show that multimodal perception consistently improves performance on vision-related tasks, with gains ranging from 2.04% to 11.30%. Overall, while current data science agents perform well on structured data and routine data analysis workflows, substantial challenges remain in unstructured domains. Finally, we offer critical insights and outline future research directions to advance the development of data science agents.",331.2,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13592v1_Machine learning based radiative parameterization .pdf,Machine learning based radiative parameterization scheme and its performance in operational reforecast experiments,"['Jing Hao', 'Xiao Sa', 'Li Haoyu', 'Xiao Huadong', 'Xue Wei']","Radiation is typically the most time-consuming physical process in numerical models. This study investigates critical limitations inherent to hybrid forecasting frameworks that embed deep neural networks into numerical prediction models, focusing on coupling compatibility and long-term integration stability. A residual convolutional neural network is employed to approximate the Rapid Radiative Transfer Model for General Circulation Models (RRTMG) within the global operational system of China Meteorological Administration. The hybrid model is capable of performing ten-day integrated forecasts and demonstrates accuracy comparable to traditional physical schemes while accelerating computation speed by approximately eightfold in a two-month operational reforecast experiment.",332.53,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13599v1_Diffusion In Diffusion Breaking the Autoregressive.pdf,Diffusion In Diffusion: Breaking the Autoregressive Bottle-neck in Block Diffusion Models,"['Linrui Ma', 'Yufei Cui', 'Kai Han', 'Yunhe Wang']","Block diffusion language models, operating as semi-autoregressive paradigms, combine the strengths of both autoregressive and diffusion paradigms. However, their strict unidirectional block dependencies introduce irreversibility and sacrifice the global planning capabilities for which diffusion models are renowned. To address these issues, the authors propose DIFFUSION INDIFFUSION—a 'draft-then-refine' framework designed to overcome the irreversibility and myopia problems inherent in block diffusion models. The approach first employs block diffusion to generate rapid drafts using small blocks, then refines these drafts through global bidirectional diffusion with a larger bidirectional receptive field. Snapshot confidence remasking is used to identify the most critical tokens that require modification, and mix-scale training is applied to expand the block diffusion model's global capabilities. Empirical results demonstrate that the approach sets a new benchmark for discrete diffusion models on the OpenWebText dataset, significantly narrowing the performance gap with autoregressive models.",331.16,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13600v1_Foundations of Global Consistency Checking with No.pdf,Foundations of Global Consistency Checking with Noisy LLM Oracles,"['Paul He*', 'Elke Kirschbaum', 'Shiva Kasiviswanathan']","Ensuring the global consistency of sets of natural-language facts is essential for tasks such as fact-checking, summarization, and knowledge base construction. While Large Language Models (LLMs) can assess the consistency of small subsets of facts, their judgments are noisy, and pairwise checks are insufficient to guarantee global coherence. This paper formalizes the problem and proposes an adaptive divide-and-conquer algorithm to identify minimal inconsistent subsets (MUSes) of facts and optionally compute minimal repairs through hitting-sets. The approach has low-degree polynomial query complexity and efficiently detects and localizes inconsistencies with both synthetic and real LLM oracles.",325.64,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13614v1_CauScientist Teaching LLMs to Respect Data for Cau.pdf,JSON_FAIL,[],N/A,177.67,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13622v1_CARPE Context-Aware Image Representation Prioritiz.pdf,Context-Aware Image Representation Prioritization via Ensemble for Large Vision-Language Models,"['Donghee Lee', 'Rui Cai', 'Zhe Zhao']","Recent advancements in Large Vision-Language Models (LVLMs) have pushed them closer to becoming general-purpose assistants. However, LVLMs still struggle with vision-centric tasks such as image classification, underperforming compared to their base vision encoders, which are often CLIP-based models. To address this limitation, the authors propose Context-Aware Image Representation Prioritization via Ensemble (CARPE), a novel, model-agnostic framework which introduces vision-integration layers and a context-aware ensemble strategy to identify when to prioritize image representations or rely on the reasoning capabilities of the language model. This design enhances the model's ability to adaptively weight visual and textual modalities and enables the model to capture various aspects of image representations, leading to consistent improvements in generalization across classification and vision-language benchmarks. Extensive experiments demonstrate that CARPE not only improves performance on image classification benchmarks but also enhances results across various vision-language benchmarks.",333.9,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13632v1_Resilient Routing Risk-Aware Dynamic Routing in Sm.pdf,Resilient Routing: Risk-Aware Dynamic Routing in Smart Logistics via Spatiotemporal Graph Learning,"['Zhiming Xue', 'Sichen Zhao', 'Yalun Qi', 'Xianling Zeng', 'Zihan Yu']","With the rapid development of the e-commerce industry, the logistics network is experiencing unprecedented pressure. Traditional static routing strategies are often unable to tolerate traffic congestion and fluctuating retail demand. In this paper, we propose a Risk-Aware Dynamic Routing (RADR) framework which integrates Spatiotemporal Graph Neural Networks (ST-GNN) with combinatorial optimization. We first construct a logistics topology graph by using discrete GPS data with spatial clustering methods. Subsequently, a hybrid deep learning model combining Graph Convolutional Network (GCN) and Gated Recurrent Unit (GRU) is adopted to extract spatial correlations and temporal dependencies for predicting future congestion risks. These prediction results are then integrated into a dynamic edge weight mechanism to perform path planning. We evaluated the framework on the Smart Logistics Dataset 2024, which contains real-world Internet of Things (IoT) sensor data. The experimental results show that the RADR algorithm significantly enhances the resilience of the supply chain. Particularly in the case study of high congestion scenarios, our method reduces the potential congestion risk exposure by 19.3% while only increasing the transportation distance by 2.1%. This empirical evidence confirms that the proposed data-driven approach can effectively balance delivery efficiency and operational safety.",331.02,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13645v1_Quadratic Upper Bound for Boosting Robustness.pdf,Quadratic Upper Bound for Boosting Robustness,"['Euijin You', 'Hyang-Won Lee']","This paper develops a loss function to improve robustness in Fast Adversarial Training (FAT) without requiring stronger inner maximization. Specifically, it derives a quadratic upper bound (QUB) on the adversarial training loss function and proposes to utilize the bound with existing FAT methods. Experimental results show significant improvement in robustness. The improvement is likely due to the smoothed loss landscape of the resulting models.",328.6,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13647v1_Fusion Segment Transformer Bi-Directional Attentio.pdf,FUSION SEGMENT TRANSFORMER: BI-DIRECTIONAL A TTENTION GUIDED FUSION NETWORK FOR AI GENERA TED MUSIC DETECTION,"['Yumin Kim', 'Seonghyeon Go']","With the rise of generative AI technology, anyone can now easily create and deploy AI-generated music, which has heightened the need for technical solutions to address copyright and ownership issues. While existing works mainly focused on short-audio, the challenge of full-audio detection, which requires modeling long-term structure and context, remains insufficiently explored. To address this, we propose an improved version of the Segment Transformer, termed the Fusion Segment Transformer. As in our previous work, we extract content embeddings from short music segments using diverse feature extractors. Furthermore, we enhance the architecture for full-audio AI-generated music detection by introducing a Gated Fusion Layer that effectively integrates content and structural information, enabling the capture of long-term context. Experiments on the SONICS and AIME datasets show that our approach outperforms the previous model and recent baselines, achieving state-of-the-art results in AI-generated music detection.",331.64,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13649v1_Fairness or Fluency An Investigation into Language.pdf,Fairness or Fluency? An Investigation into Language Bias of Pairwise LLM-as-a-Judge,"['Xiaolin Zhou', 'Zheng Luo', 'Yicheng Gao', 'Qixuan Chen', 'Xiyang Hu', 'Yue Zhao', 'Ruishan Liu']","Recent advances in Large Language Models (LLMs) have led to the development of LLM-as-a-judge, where LLMs are used to assess the quality of text inputs. This paper investigates two types of language bias in pairwise LLM-as-a-judge: performance disparity between languages when comparing options from the same language, and bias towards options written in major languages when comparing options from different languages. The study finds significant performance disparities across language families, with European languages consistently outperforming African languages, especially in culturally-related subjects. For inter-language judging, most models favor English answers, influenced more by answer language than question language. The paper also explores whether language bias is caused by low-perplexity bias, finding that while perplexity is slightly correlated with language bias, language bias cannot be fully explained by perplexity alone.",333.22,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13655v1_Why Does the LLM Stop Computing An Empirical Study.pdf,Why Does the LLM Stop Computing: An Empirical Study of User-Reported Failures in Open-Source LLMs,"['GUANGBA YU', 'ZIRUI WANG', 'YUJIE HUANG', 'RENYI ZHONG', 'YUEDONG ZHONG', 'YILUN WANG', 'MICHAEL R. LYU']","The democratization of open-source Large Language Models (LLMs) allows users to fine-tune and deploy models on local infrastructure but exposes them to a “First Mile” deployment landscape. Unlike black-box API consumption, the reliability of user-managed orchestration remains a critical blind spot. To bridge this gap, we conduct the first large-scale empirical study of 705 real-world failures from the open-source DeepSeek, Llama, and Qwen ecosystems. Our analysis reveals a paradigm shift: white-box orchestration relocates the reliability bottleneck from model algorithmic defects to the systemic fragility of the deployment stack. We identify three key phenomena: Diagnostic Divergence, Systemic Homogeneity, and Lifecycle Escalation. Supported by our publicly available dataset, these insights provide actionable guidance for enhancing the reliability of the LLM landscape.",330.91,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13657v1_Communication-Free Collective Navigation for a Swa.pdf,Communication-Free Collective Navigation for a Swarm of UA Vs via LiDAR-Based Deep Reinforcement Learning,"['Myong-Yol Choi', 'Hankyoul Ko', 'Hanse Cho', 'Changseung Kim', 'Seunghwan Kim', 'Jaemin Seo', 'Hyondong Oh']","This paper presents a deep reinforcement learning (DRL) based controller for collective navigation of unmanned aerial vehicle (UA V) swarms in communication-denied environments. Inspired by biological swarms, the system employs an implicit leader-follower framework where only the leader possesses goal information and followers learn robust policies using onboard LiDAR sensing. The controller is trained in GPU-accelerated Nvidia Isaac Sim, enabling followers to learn complex emergent behaviors balancing flocking and obstacle avoidance. The robustness and sim-to-real transfer of the approach are confirmed through extensive simulations and real-world experiments with a swarm of five UA Vs.",330.57,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13659v1_Temporal-Spatial Decouple before Act Disentangled .pdf,TEMPORAL-SPA TIAL DECOUPLE BEFORE ACT: DISENTANGLED REPRESENTA TION LEARNING FOR MULTIMODAL SENTIMENT ANALYSIS,"['Chunlei Meng', 'Ziyang Zhou', 'Lucas He', 'Xiaojing Du', 'Chun Ouyang', 'Zhongxue Gan']","Multimodal Sentiment Analysis (MSA) integrates Linguistic, Visual, and Auditory evidence to infer sentiment. Mainstream approaches still rely on spatiotemporal mixed modeling, which ignores spatiotemporal heterogeneity, leading to spatiotemporal information asymmetry and limited performance. This paper proposes TSDA, Temporal–Spatial Decouple before Act, which explicitly decouples each modality into temporal dynamics and spatial structural context before any interaction. For every modality, a temporal encoder and a spatial encoder project signals into separate temporal and spatial bodies. Factor-Consistent Cross-Modal Alignment then aligns temporal features only with their temporal counterparts across modalities, and spatial features only with their spatial counterparts. Factor specific supervision and decorrelation regularization reduce cross factor leakage while preserving complementarity. A Gated Recouple module subsequently recouples the aligned streams for task. Extensive experiments show that TSDA outperforms baselines. Ablation analysis confirms the necessity and interpretability of the design.",331.43,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13671v1_The Orchestration of Multi-Agent Systems Architect.pdf,"The Orchestration of Multi-Agent Systems: Architectures, Protocols, and Enterprise Adoption","['Apoorva Adimulam', 'Rajesh Gupta', 'Sumit Kumar']","The paper consolidates and formalizes the technical composition of orchestrated multi-agent systems, presenting a unified architectural framework that integrates planning, policy enforcement, state management, and quality operations into a coherent orchestration layer. It also provides in-depth technical delineation of two complementary communication protocols—the Model Context Protocol and the Agent-to-Agent protocol. These protocols establish an interoperable communication substrate that enables scalable, auditable, and policy-compliant reasoning across distributed agent collectives. The paper details how orchestration logic, governance frameworks, and observability mechanisms collectively sustain system coherence, transparency, and accountability. By synthesizing these elements into a cohesive technical blueprint, this paper provides comprehensive treatments of orchestrated multi-agent systems—bridging conceptual architectures with implementation-ready design principles for enterprise-scale AI ecosystems.",331.37,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13684v1_HeteroCache A Dynamic Retrieval Approach to Hetero.pdf,HeteroCache: A Dynamic Retrieval Approach to Heterogeneous KV Cache Compression for Long-Context LLM Inference,"['Zhiyuan Shi', 'Qibo Qiu', 'Feng Xue', 'Zhonglin Jiang', 'Li Yu', 'Jian Jiang', 'Xiaofei He', 'Wenxiao Wang', '†']","The linear memory growth of the KV cache poses a significant bottleneck for LLM inference in long-context tasks. Existing static compression methods often fail to preserve globally important information due to their coarse-grained caching strategies and high I/O overhead. To overcome these limitations, we propose HeteroCache, a training-free dynamic compression framework. Our method categorizes attention heads based on stability and redundancy, applying a fine-grained weighting strategy to allocate larger cache budgets to heads with rapidly shifting attention. This approach effectively addresses the inefficiency of coarse-grained strategies and hides I/O latency through a hierarchical storage mechanism. Experiments demonstrate that HeteroCache achieves state-of-the-art performance on multiple long-context benchmarks and accelerates decoding by up to 3× compared to the original model in the 224K context.",330.64,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13687v1_Understanding Mental States to Guide Social Influe.pdf,Understanding Mental States to Guide Social Influence in Multi-Person Group Dialogue,"['Zhichao Liang', 'Satoshi Nakamura']","Existing benchmarks of Theory of Mind (ToM) primarily focus on passive models that track mental states. This paper introduces SocialMindChange, a benchmark that shifts from tracking to changing mental states in social interactions. Each instance defines a social context with four characters and five connected scenes. The model plays one character and generates dialogue across the five scenes to reach a target while maintaining consistency with evolving states. The benchmark includes selected higher-order states and uses a structured four-step framework to construct 1,200 social contexts covering 6,000 scenarios and over 90,000 questions, each validated for realism and quality. Evaluations on ten state-of-the-art language models show that their average performance is 54.2% below human performance, suggesting that current LLMs struggle to maintain and change mental-state representations across long, linked interactions.",330.04,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13693v1_End-to-End Reverse Screening Identifies Protein Ta.pdf,End-to-End Reverse Screening Identifies Protein Targets of Small Molecules Using HelixFold3,"['Shengjie Xu', 'Xianbin Ye', 'Mengran Zhu', 'Xiaonan Zhang', 'Shanzhuo Zhang', 'Xiaomin Fang']","Identifying protein targets for small molecules, or reverse screening, is essential for understanding drug action, guiding compound repurposing, predicting off-target effects, and elucidating the molecular mechanisms of bioactive compounds. Despite its critical role, reverse screening remains challenging because accurately capturing interactions between a small molecule and structurally diverse proteins is inherently complex, and conventional step-wise workflows often propagate errors across decoupled steps such as target structure modeling, pocket identification, docking, and scoring. Here, we present an end-to-end reverse screening strategy leveraging HelixFold3, a high-accuracy biomolecular structure prediction model akin to AlphaFold3, which simultaneously models the folding of proteins from a protein library and the docking of small-molecule ligands within a unified framework. We validate this approach on a diverse and representative set of approximately one hundred small molecules. Compared with conventional reverse docking, our method improves screening accuracy and demonstrates enhanced structural fidelity, binding-site precision, and target prioritization. By systematically linking small molecules to their protein targets, this framework establishes a scalable and straightforward platform for dissecting molecular mechanisms, exploring off-target interactions, and supporting rational drug discovery.",330.29,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13697v1_Uncertainty-Aware Gradient Signal-to-Noise Data Se.pdf,Uncertainty-Aware Gradient Signal-to-Noise Data Selection for Instruction Tuning,"['Zhihang Yuan', 'Chengyu Yue', 'Long Huang', 'Litu Ou', 'Lei Shi']","Instruction tuning is a standard paradigm for adapting large language models (LLMs) to follow human instructions. However, modern instruction datasets are large, noisy, and redundant, making full-data fine-tuning expensive and often unnecessary. Existing data selection methods either build expensive gradient datastores or assign static scores from a weak proxy, largely ignoring evolving uncertainty and thus missing a key source of LLM interpretability. The paper proposes GRADFILTERING, an objective-agnostic, uncertainty-aware data selection framework that utilizes a small GPT-2 proxy with a LoRA ensemble and aggregates per-example gradients into a Gradient Signal-to-Noise Ratio (G-SNR) utility. The method matches or surpasses random subsets and strong baselines in most LLM-as-a-judge evaluations and in human assessment. Moreover, GRADFILTERING-selected subsets converge faster than competitive filters under the same compute budget, reflecting the benefit of uncertainty-aware scoring.",328.72,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13698v1_Does Privacy Always Harm Fairness Data-Dependent T.pdf,Privacy Always Harm Fairness? Data-Dependent Trade-offs via Chernoff Information Neural Estimation,"['Arjun Nichani', 'Hsiang Hsu', 'Chun-Fu (Richard) Chen', 'Haewon Jeong']","This paper utilizes the information-theoretic measure Chernoff Information to highlight the data-dependent nature of the relationship among fairness, privacy, and accuracy. It defines Noisy Chernoff Difference, a tool to analyze the relationship among the triad simultaneously. The authors show that for synthetic data, this value behaves in three distinct ways depending on the distribution of the data. They also demonstrate that Noisy Chernoff Difference acts as a proxy for the steepness of the fairness-accuracy curves. Finally, they propose a method for estimating Chernoff Information on data from unknown distributions and utilize this framework to examine the triad dynamic on real datasets. This work builds towards a unified understanding of the fairness-privacy-accuracy relationship and highlights its data-dependent nature.",330.54,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13704v1_Performance and Complexity Trade-off Optimization .pdf,Performance and Complexity Trade-off Optimization of Speech Models During Training,"['Esteban Gómez', 'Tom Bäckström']","In speech machine learning, neural network models are typically designed by choosing an architecture with fixed layer sizes and structure. These models are then trained to maximize performance on metrics aligned with the task's objective. However, this approach does not guarantee an optimal trade-off between performance and computational complexity. This paper proposes a reparameterization technique based on feature noise injection that enables joint optimization of performance and computational complexity during training using SGD-based methods. Unlike traditional pruning methods, our approach allows the model size to be dynamically optimized for a target performance-complexity trade-off, without relying on heuristic criteria to select which weights or structures to remove. The effectiveness of the method is demonstrated through three case studies, including a synthetic example and two practical real-world applications: voice activity detection and audio anti-spoofing. The code related to our work is publicly available to encourage further research.",331.35,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13707v1_Attention-space Contrastive Guidance for Efficient.pdf,Attention-space Contrastive Guidance for Efficient Hallucination Mitigation in LVLMs,"['Yujin Jo', 'Sangyoon Bae', 'Taesup Kim*']","This paper addresses the issue of hallucinations in large vision-language models (LVLMs) by framing hallucination mitigation as contrastive guidance. The authors propose Attention-space Contrastive Guidance (ACG), a single-pass mechanism that operates within self-attention layers to construct both vision-language and language-only attention paths in a single forward computation. This integration enables computationally efficient guidance directly embedded in the model's representation contextualization. The method corrects approximation bias introduced by the single-pass formulation through an orthogonalized correction that removes components aligned with the language-only path, selectively amplifying visual contributions. Experiments on the CHAIR and POPE benchmarks show that ACG achieves state-of-the-art faithfulness and caption quality while significantly reducing computational cost. The authors establish a principled and efficient alternative, reducing latency by up to 2× compared to prior contrastive decoding methods that require multiple forward passes.",331.17,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13709v1_Hidden in Plain Text Measuring LLM Deception Quali.pdf,Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games,"['Christopher Kao', 'Vanshika Vats', 'James Davis']","This paper studies deception in the Social Deduction Game (SDG) Mafia, where success is dependent on deceiving others through conversation. Unlike previous SDG studies, the authors use an asynchronous multi-agent framework to simulate realistic social contexts. They simulate 35 Mafia games with GPT-4 LLM agents and create a Mafia Detector using GPT-4-Turbo to analyze game transcripts without player role information. The Mafia Detector's mafia prediction accuracy is compared to that of 28 human games and a random baseline. Results show that the Mafia Detector's mafia prediction accuracy is lower on LLM games than on human games, indicating that LLMs blend in better and thus deceive more effectively. The authors also release a dataset of LLM Mafia transcripts to support future research. The findings underscore both the sophistication and risks of LLM deception in social contexts.",330.49,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13710v1_Who Should Have Surgery A Comparative Study of Gen.pdf,Who Should Have Surgery? A Comparative Study of GenAI vs Supervised ML for CRS Surgical Outcome Prediction,"['Sayeed Shafayet Chowdhury', 'Snehasis Mukhopadhyay', 'Shiaofen Fang', 'Vijay R. Ramakrishnan']","Artificial intelligence has reshaped medical imaging, yet its use on clinical data for prospective decision support remains limited. This study compares generative artificial intelligence (GenAI) models (ChatGPT, Claude, Gemini, Perplexity) with supervised machine learning (ML) models (logistic regression, tree ensembles, and an in-house MLP) in predicting clinically meaningful improvement in chronic rhinosinusitis (CRS) outcomes. The models were benchmarked using pre-operative clinical data from a prospectively collected cohort where all patients underwent surgery. The study aims to determine if models could have identified patients who would have poor outcomes, i.e., those who should have avoided surgery. The best ML model (MLP) achieved 85% accuracy with superior calibration and decision-curve net benefit, while GenAI models underperformed on discrimination and calibration. Notably, GenAI justifications aligned with clinician heuristics and the MLP's feature importance, highlighting baseline SNOT-22, CT/endoscopy severity, polyp phenotype, and psych/psychology/pain comorbidities. The findings support an ML-first, GenAI-augmented workflow: deploy calibrated ML for primary triage of surgical candidacy, with GenAI as an explainer to enhance transparency and shared decision-making.",330.79,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13717v1_Simulated Ignorance Fails A Systematic Study of LL.pdf,Simulated Ignorance Fails: A Systematic Study of LLM Behaviors on Forecasting Problems Before Model Knowledge Cutoff,"['Zehan Li', 'Yuxuan Wang', 'Ali El Lahib', 'Ying-Jieh Xia', 'Xinyu Pi']","Evaluating Large Language Models (LLMs) in forecasting tasks is constrained by a fundamental tension: prospective evaluation offers rigorous methodology but prohibitive latency, while retrospective forecasting (RF) faces shrinking clean evaluation data due to increasingly recent knowledge cutoffs. Simulated Ignorance (SI), prompting models to suppress pre-cutoff knowledge, has emerged as a potential solution. This study provides the first systematic test of whether SI can approximate True Ignorance (TI). Across 477 competition-level questions and 9 models, it finds that SI fails systematically: (1) cutoff instructions leave a 52% performance gap between SI and TI; (2) chain-of-thought reasoning fails to suppress prior knowledge, even when reasoning traces contain no explicit post-cutoff references; (3) reasoning-optimized models exhibit worse SI fidelity despite superior reasoning trace quality. These findings demonstrate that prompts cannot reliably rewind model knowledge. The study concludes that RF on pre-cutoff events is methodologically flawed, and recommends against using SI-based retrospective setups to benchmark forecasting capabilities.",312.88,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13719v1_Hierarchical Long Video Understanding with Audiovi.pdf,Hierarchical Long Video Understanding with Audiovisual Entity Cohesion and Agentic Search,"['Xinlei Yin', 'Xiulian Peng', 'Xiao Li', 'Zhiwei Xiong', 'Yan Lu']","Long video understanding presents significant challenges due to extremely long context windows. Existing solutions relying on naive chunking strategies with retrieval-augmented generation typically suffer from information fragmentation and a loss of global coherence. The paper presents HAVEN, a unified framework for long-video understanding that integrates audiovisual entity cohesion and hierarchical video indexing with agentic search. It preserves semantic consistency by integrating entity-level representations across visual and auditory streams, organizes content into a structured hierarchy, and employs an agentic search mechanism for dynamic retrieval and reasoning across these layers. Extensive experiments demonstrate that the method achieves good temporal coherence, entity consistency, and retrieval efficiency, establishing a new state-of-the-art with an overall accuracy of 84.1% on LVBench. Notably, it achieves outstanding performance in the challenging reasoning category, reaching 80.1%. These results highlight the effectiveness of structured, multimodal reasoning for comprehensive and context-consistent understanding of long-form videos.",310.47,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13722v1_OP-Bench Benchmarking Over-Personalization for Mem.pdf,OP-Bench: Benchmarking Over-Personalization for Memory-Augmented Personalized Conversational Agents,"['Yulin Hu', 'Zimo Long', 'Jiahe Guo', 'Xingyu Sui', 'Xing Fu', 'Weixiang Zhao', 'Yanyan Zhao', 'Bing Qin']","Memory-augmented conversational agents enable personalized interactions using long-term user memory and have gained substantial traction. However, existing benchmarks primarily focus on whether agents can recall and apply user information, while overlooking whether such personalization is used appropriately. In this work, we formalize over-personalization into three types: Irrelevance, Repetition, and Sycophancy, and introduce OP-Bench, a benchmark of 1,700 verified instances constructed from long-horizon dialogue histories. Using OP-Bench, we evaluate multiple large language models and memory-augmentation methods, and find that over-personalization is widespread when memory is introduced. Further analysis reveals that agents tend to retrieve and over-attend to user memories even when unnecessary. To address this issue, we propose Self-ReCheck, a lightweight, model-agnostic memory filtering mechanism that mitigates over-personalization while preserving personalization performance. Our work takes an initial step toward more controllable and appropriate personalization in memory-augmented dialogue systems.",311.42,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13734v1_Towards robust long-context understanding of large.pdf,TOW ARDS ROBUST LONG-CONTEXT UNDERSTANDING OF LARGE LANGUAGE MODEL VIA ACTIVE RECAP LEARNING,['Chenyu Hui'],"In this paper, we propose active recap learning (ARL), a framework for enhancing large language model (LLM) in understanding long contexts. ARL enables models to revisit and summarize earlier content through targeted sequence construction during continued pretraining and retrospective summarization at inference. Experimental results show substantial gains, with ARL achieving a 26.8% improvement on RULER and a 9.44% improvement on LongBench. Overall, ARL offers a simple yet effective continued pretraining-based approach to strengthen long-context understanding, advancing scalable memory augmentation in LLM.",314.39,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13735v1_Reasoning or Fluency Dissecting Probabilistic Conf.pdf,Reasoning or Fluency? Dissecting Probabilistic Confidence in Best-of-N Selection,"['Hojin Kim', 'Jaehyung Kim']","This work challenges the assumption that probabilistic confidence metrics, commonly used as proxies for reasoning quality in Best-of-N selection, truly capture inter-step causal dependencies necessary for valid reasoning. By introducing three classes of inter-step causality perturbations, the authors find that selection accuracy degrades only marginally under these disruptions, even with severe interventions. These findings suggest that current probabilistic metrics are largely insensitive to logical structure and primarily capture surface-level fluency or in-distribution priors. The authors propose a contrastive causality metric to explicitly isolate inter-step causal dependencies and demonstrate that it yields more faithful output selection than existing probability-based approaches.",312.62,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13749v1_Pro-AI Bias in Large Language Models.pdf,Pro-AI Bias in Large Language Models,"['Benaya Trabelsi', 'Jonathan Shaki', 'Sarit Kraus']","Large language models (LLMs) are increasingly employed for decision-support across multiple domains. This study investigates whether these models display a systematic preferential bias in favor of artificial intelligence (AI) itself. Across three complementary experiments, consistent evidence of pro-AI bias is found. First, LLMs disproportionately recommend AI-related options in response to diverse advice-seeking queries, with proprietary models doing so almost deterministically. Second, models systematically overestimate salaries for AI-related jobs relative to closely matched non-AI jobs, with proprietary models overestimating AI salaries more by 10 percentage points. Finally, probing internal representations of open-weight models reveals that 'Artificial Intelligence' exhibits the highest similarity to generic prompts for academic fields under positive, negative, and neutral framings alike, indicating valence-invariant representational centrality. These patterns suggest that LLM-generated advice and valuation can systematically skew choices and perceptions in high-stakes decisions.",313.27,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13752v1_Finding RELIEF Shaping Reasoning Behavior without .pdf,Finding RELIEF: Shaping Reasoning Behavior without Reasoning Supervision,"['Chak Tou Leong', 'Dingwei Chen', 'Heming Xia', 'Qingyu Yin', 'Sunbowen Lee', 'Jian Wang', 'Wenjie Li']","Large reasoning models (LRMs) have achieved remarkable success in complex problem-solving but often suffer from computational redundancy or reasoning unfaithfulness. Current methods for shaping LRMs' behavior rely on reinforcement learning or fine-tuning with gold-standard reasoning traces, which are computationally expensive and difficult to scale. This paper reveals that LRMs possess latent reasoning beliefs that can be captured through simple logit probing. Building upon this insight, Reasoning Belief Engineering (RELIEF) proposes a simple yet effective framework that shapes LRMs' behavior by aligning the model's self-concept with a target belief blueprint. Crucially, RELIEF bypasses the need for reasoning-trace supervision and internalizes desired traits by fine-tuning on synthesized, self-reﬂective question-answering pairs that affirm the target belief. Extensive experiments demonstrate that RELIEF matches or outperforms behavior-supervised and preference-based baselines while requiring lower training costs. Further analysis validates that shifting a model's reasoning belief effectively shapes its actual behavior.",312.72,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13761v1_DARC Decoupled Asymmetric Reasoning Curriculum for.pdf,DARC: Decoupled Asymmetric Reasoning Curriculum for LLM Evolution,"['Shengda Fan', 'Xuyan Ye', 'Yankai Lin']","Self-improving artificial intelligence, which enables models to autonomously refine their capabilities without human intervention, is a crucial step toward more general and potentially superhuman intelligence. However, the success of large language models largely relies on extensive human supervision, which becomes a fundamental bottleneck as high-quality human-annotated data approaches its limit. DARC (Decoupled Asymmetric Reasoning Curriculum) is a two-stage framework that stabilizes the self-evolution process by training the Questioner to synthesize difficulty-calibrated questions and the Solver with an asymmetric self-distillation mechanism. Empirical results demonstrate that DARC is model-agnostic, yielding an average improvement of 10.9 points across nine reasoning benchmarks and three backbone models, and consistently outperforms all baselines and approaches the performance of fully supervised models without relying on human annotations. The code is available at https://github.com/RUCBM/DARC.",312.4,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13768v1_vLinear A Powerful Linear Model for Multivariate T.pdf,vLinear: A Powerful Linear Model for Multivariate Time Series Forecasting,"['Wenzhen Yue', 'Ruohao Guo', 'Ji Shi', 'Zihan Hao', 'Shiyu Hu', 'Xianghua Ying∗']","This paper presents vLinear, a powerful yet efficient linear-based multivariate time series forecaster. It features the vecTrans module and the WFMLoss objective. vLinear addresses the quadratic computational complexity of self-attention by using a learnable rank-1 matrix, reducing complexity from O(N^2) to O(N). It achieves state-of-the-art performance across 22 benchmarks and 124 forecasting settings. WFMLoss incorporates path- and horizon-weighted strategies to focus learning on more reliable paths and horizons. The code is available at https://anonymous.4open.science/r/vLinear.",311.92,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13770v1_Look-Ahead-Bench a Standardized Benchmark of Look-.pdf,Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance,['Mostapha Benhenda'],"This paper introduces Look-Ahead-Bench, a standardized benchmark to measure look-ahead bias in Point-in-Time (PiT) Large Language Models (LLMs) within realistic and practical financial workflows. Unlike most existing approaches that primarily test inner lookahead knowledge via Q&A, this benchmark evaluates model behavior in practical scenarios. The authors analyze performance decay across temporally distinct market regimes and incorporate quantitative baselines to establish performance thresholds. The evaluation of prominent open-source LLMs—Llama 3.1 (8B and 70B) and DeepSeek 3.2—against a family of Point-in-Time LLMs (Pitinf-Small, Pitinf-Medium, and frontier-level model Pitinf-Large) from PiT-Inference reveals significant lookahead bias in standard LLMs, unlike Pitinf models which demonstrate improved generalization and reasoning abilities as they scale in size. This work establishes a foundation for the standardized evaluation of temporal bias in financial LLMs and provides a practical framework for identifying models suitable for real-world deployment.",312.4,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13798v1_Insight Interpretable Semantic Hierarchies in Visi.pdf,Interpretable Semantic Hierarchies in Vision-Language Encoders,"['Kai Wittenmayer', 'Sukrut Rao', 'Amin Parchami-Araghi', 'Bernt Schiele', 'Jonas Fischer']","The paper introduces INSIGHT, a language-aligned concept foundation model that provides fine-grained, human-interpretable, and spatially grounded concepts for vision tasks. These concepts enable INSIGHT to provide concept-based explanations for decision-making across vision tasks. The model uses a hierarchical sparse autoencoder and a foundation model with strong semantic representations to automatically extract concepts at various granularities. On benchmark data, INSIGHT shows competitive performance on classification and segmentation tasks while providing high-quality concept-based explanations.",313.4,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13809v1_DroneVLA VLA based Aerial Manipulation.pdf,DroneVLA: VLA based Aerial Manipulation,"['Fawad Mehboob∗', 'Monijesu James∗', 'Amir Habel∗', 'Jeffrin Sam', 'Miguel Altamirano Cabrera', 'Dzmitry Tsetserukou']","This work introduces a novel concept of autonomous aerial manipulator capable of interpreting high-level natural language commands to retrieve objects and deliver them to a human user. The system integrates a MediaPipe based on Grounding DINO and a Vision-Language-Action (VLA) model with a custom-built drone equipped with a 1-DOF gripper and an Intel RealSense RGB-D camera. VLA performs semantic reasoning to interpret the intent of a user prompt and generates a prioritized task queue for grasping of relevant objects in the scene. Grounding DINO and dynamic A* planning algorithm are used to navigate and safely relocate the object. To ensure safe and natural interaction during the handover phase, the system employs a human-centric controller driven by MediaPipe. This module provides real-time human pose and orientation estimation, allowing the drone to employ visual servoing to maintain a stable, distinct position directly in front of the user, facilitating a comfortable handover. The system's efficacy is demonstrated through real-world experiments for localization and navigation.",311.82,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13846v1_Virtual Urbanism An AI-Driven Framework for Quanti.pdf,Virtual Urbanism: An AI-Driven Framework for Quantifying Urban Identity,"['Glinskaya, Maria']","This paper introduces Virtual Urbanism (VU), a multimodal AI-driven analytical framework for quantifying urban identity through synthetic urban replicas. The framework aims to advance computationally tractable urban identity metrics. A pipeline integrating Stable Diffusion and LoRA models was used to produce synthetic replicas of nine Tokyo areas rendered as dynamic synthetic urban sequences, excluding existing orientation markers to elicit core identity-forming elements. Human-evaluation experiments (I) assessed perceptual legitimacy of replicas, (II) quantified area-level identity, and (III) derived core identity-forming elements. Results showed a mean identification accuracy of ~81%, confirming the validity of the replicas. The Urban Identity Level (UIL) metric enabled assessment of identity levels across areas, while semantic analysis revealed culturally embedded typologies as core identity-forming elements, positioning VU as a viable framework for AI-augmented urban analysis, outlining a path toward automated, multi-parameter identity metrics.",311.19,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13864v1_HardSecBench Benchmarking the Security Awareness o.pdf,HardSecBench: Benchmarking the Security Awareness of LLMs for Hardware Code Generation,"['Qirui Chen', 'Jingxian Shuai', 'Shuangwu Chen', 'Shenghao Ye', 'Zijian Wen', 'Xufei Su', 'Jie Jin', 'Jiangming Li', 'Jun Chen', 'Xiaobin Tan', 'Jian Yang']","Large language models (LLMs) are increasingly integrated into practical hardware and firmware development for code generation. Existing studies have primarily focused on evaluating the functional correctness of LLM-generated code, yet paid limited attention to its security issues. This research gap motivates the design of a benchmark, HardSecBench, to assess security awareness under realistic specifications. The benchmark includes 924 tasks covering Verilog RTL and firmware-level C, with 76 CWE entries. Each task includes a structured specification, a secure reference implementation, and executable tests. The multi-agent pipeline automates artifact synthesis, enabling reliable evaluation. Using HardSecBench, the study evaluates LLMs on hardware and firmware code generation, finding that models often satisfy functional requirements while still leaving security risks. Security results vary with prompting, highlighting pressing challenges and offering actionable insights for future advancements in LLM-assisted hardware design. Data and code will be released soon.",311.61,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13880v1_LifeAgentBench A Multi-dimensional Benchmark and A.pdf,LifeAgentBench: A Multi-dimensional Benchmark and Agent for Personal Health Assistants in Digital Health,"['Ye Tian', 'Zihao Wang', 'Onat Gungor', 'Xiaoran Fan', 'Tajana Rosing']","Personalized digital health support requires long-horizon, cross-dimensional reasoning over heterogeneous lifestyle signals. This paper introduces LifeAgentBench, a large-scale QA benchmark for long-horizon, cross-dimensional, and multi-user lifestyle health reasoning. It contains 22,573 questions spanning from basic retrieval to complex reasoning. The authors release an extensible benchmark construction pipeline and a standardized evaluation protocol to enable reliable and scalable assessment of LLM-based health assistants. They systematically evaluate 11 leading LLMs on LifeAgentBench and identify key bottlenecks in long-horizon aggregation and cross-dimensional reasoning. Motivated by these findings, they propose LifeAgent as a strong baseline agent for health assistants that integrates multi-step evidence retrieval with deterministic aggregation, achieving significant improvements compared to two widely used baselines. Case studies demonstrate its potential in realistic daily-life scenarios. The benchmark is publicly available.",312.25,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13885v1_Confident Rankings with Fewer Items Adaptive LLM E.pdf,Confident Rankings with Fewer Items: Adaptive LLM Evaluation with Continuous Scores,"['Esma Balkır', 'Alice Pernthaller', 'Marco Basaldella', 'José Hernández-Orallo', 'Nigel Collier']","Computerized Adaptive Testing (CAT) has proven effective for efficient Large Language Model (LLM) evaluation on multiple-choice benchmarks, but modern evaluation increasingly relies on continuous scoring tasks. This paper presents a principled extension of IRT-based adaptive testing to continuous bounded scores (ROUGE, BLEU, LLM-as-a-Judge) by replacing the Bernoulli response distribution with a heteroskedastic normal distribution. Building on this, the authors introduce an uncertainty-aware ranker with adaptive stopping criteria that achieves reliable model ranking while testing as few items and as cheaply as possible. The method is validated on five benchmarks spanning n-gram-based, embedding-based, and LLM-as-judge metrics, using 2% of the items while improving ranking correlation by 0.12 τ over random sampling, with 95% accuracy on confident predictions.",312.21,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13887v1_Human Simulation Computation A Human-Inspired Fram.pdf,Human Simulation Computation: A Human-Inspired Framework for Adaptive AI Systems,['Hong Su'],"Large language models (LLMs) have demonstrated strong capabilities in knowledge representation and reasoning based on textual data. However, their reliance on language material alone limits their ability to adapt, verify reasoning outcomes, and operate effectively in open and dynamic real-world environments. This paper proposes Human Simulation Computation (HSC), a human-inspired computational framework that models intelligence as a continuous, closed-loop process involving thinking, action, learning, reflection, and activity scheduling. HSC emphasizes active participation within the internal reasoning process and in interactions with the environment, where actions are used not only to achieve goals but also to automatically refine and improve internal reasoning mechanisms without external intervention. HSC incorporates commonly used human thinking strategies across all stages of the internal reasoning process, such as main-feature-oriented reasoning, scope expansion through action, and on-time learning driven by environmental feedback. The authors argue that human simulation strategies cannot be fully learned from language material alone, and that human-like reasoning processes and action-grounded reasoning methods are essential for robust adaptation and effective interaction with real-world environments.",314.07,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13895v1_OmniOVCD Streamlining Open-Vocabulary Change Detec.pdf,OmniOVCD: Streamlining Open-Vocabulary Change Detection with SAM 3,"['Xu Zhang', 'Danyang Li', 'Yingjie Xia', 'Xiaohang Dong', 'Hualong Yu', 'Jianye Wang', 'Qicheng Li∗']","Change Detection (CD) aims to accurately capture the evolution of land cover, which serves as a fundamental task for Earth observation. Existing training-free Open-Vocabulary Change Detection (OVCD) methods mostly use CLIP to identify categories and require extra models like DINO to extract features. Recently, the Segment Anything Model 3 (SAM 3) has been introduced, integrating segmentation and identification capabilities within one promptable model. This paper proposes OmniOVCD, a standalone framework designed for OVCD. By leveraging the decoupled output heads of SAM 3, the authors propose a Synergistic Fusion to Instance Decoupling (SFID) strategy. SFID first fuses the semantic, instance, and presence outputs of SAM 3 to construct land-cover masks, and then decomposes them into individual instance masks for change comparison. This design preserves high accuracy in category recognition and maintains instance-level consistency across images. Experiments on four public benchmarks demonstrate SOTA performance, achieving IoU scores of 67.2, 66.5, 24.5, and 27.1 (class-average), respectively, surpassing all previous methods.",312.36,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13897v1_TractRLFusion A GPT-Based Multi-Critic Policy Fusi.pdf,TRACTRLFUSION: A GPT-BASED MULTI-CRITIC POLICY FUSION FRAMEWORK FOR FIBER TRACTOGRAPHY,"['Ankita Joshi', 'Ashutosh Sharma', 'Anoushkrit Goel', 'Ranjeet Ranjan Jha', 'Chirag Ahuja', 'Arnav Bhavsar', 'Aditya Nigam']","Tractography plays a pivotal role in the non-invasive reconstruction of white matter fiber pathways, providing vital information on brain connectivity and supporting precise neurosurgical planning. Although traditional methods relied mainly on classical deterministic and probabilistic approaches, recent progress has benefited from supervised deep learning (DL) and deep reinforcement learning (DRL) to improve tract reconstruction. A persistent challenge in tractography is accurately reconstructing white matter tracts while minimizing spurious connections. To address this, the authors propose TractRLFusion, a novel GPT-based policy fusion framework that integrates multiple RL policies through a data-driven fusion strategy. Our method employs a two-stage training data selection process for effective policy fusion, followed by a multi-critic fine-tuning phase to enhance robustness and generalization. Experiments on HCP, ISMRM, and TractoInferno datasets demonstrate that TractRLFusion outperforms individual RL policies as well as state-of-the-art classical and DRL methods in accuracy and anatomical reliability.",311.12,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13904v1_PREFAB PREFerence-based Affective Modeling for Low.pdf,PREFAB: PREFerence-based Affective Modeling for Low-Budget Self-Annotation,"['Jaeyoung Moon', 'Youjin Choi', 'Yucheon Park', 'David Melhart', 'Georgios N. Yannakakis', 'Kyung-Joong Kim']","Self-annotation is the gold standard for collecting affective state labels in affective computing. Existing methods typically rely on full annotation, requiring users to continuously label affective states across entire sessions. While this process yields fine-grained data, it is time-consuming, cognitively demanding, and prone to fatigue and errors. To address these issues, we present PREFAB, a low-budget retrospective self-annotation method that targets affective inflection regions rather than full annotation. Grounded in the peak-end rule and ordinal representations of emotion, PREFAB employs a preference-learning model to detect relative affective changes, directing annotators to label only selected segments while interpolating the remainder of the stimulus. We further introduce a preview mechanism that provides brief contextual cues to assist annotation. We evaluate PREFAB through a technical performance study and a 25-participant user study. Results show that PREFAB outperforms baselines in modeling affective inflections while mitigating workload (and conditionally mitigating temporal burden). Importantly, PREFAB improves annotator confidence without degrading annotation quality.",309.1,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13920v1_Asymmetric regularization mechanism for GAN traini.pdf,Asymmetric regularization mechanism for GAN training with Variational Inequalities,"['Spyridon C. Giagtzoglou', 'Mark H.M. Winands', 'Barbara Franci']","We formulate the training of generative adversarial networks (GANs) as a Nash equilibrium seeking problem. To stabilize the training process and find a Nash equilibrium, we propose an asymmetric regularization mechanism based on the classic Tikhonov step and a novel zero-centered gradient penalty. Under smoothness and a local identifiability condition induced by a Gauss–Newton Gramian, we obtain explicit Lipschitz and (strong)-monotonicity constants for the regularized operator. These constants ensure last-iterate linear convergence of a single-call Extrapolation-from-the-Past (EFTP) method. Empirical simulations on an academic example show that, even when strong monotonicity cannot be achieved, the asymmetric regularization is enough to converge to an equilibrium and stabilize the trajectory.",312.37,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13938v1_IF-GEO Conflict-Aware Instruction Fusion for Multi.pdf,IF-GEO: Conflict-Aware Instruction Fusion for Multi-Query Generative Engine Optimization,"['Heyang Zhou', 'JiaJia Chen', 'Xiaolu Chen', 'Jie Bao', 'Zhen Chen', 'Yong Liao']","As Generative Engines revolutionize information retrieval by synthesizing direct answers from retrieved sources, ensuring source visibility becomes a significant challenge. Improving it through targeted content revisions is termed Generative Engine Optimization (GEO). However, optimizing a document for diverse queries presents a constrained optimization challenge where heterogeneous queries often impose conflicting and competing revision requirements under a limited content budget. To address this challenge, the paper proposes IF-GEO, a 'diverge-then-converge' framework comprising two phases: (i) mining distinct optimization preferences from representative latent queries; (ii) synthesizing a Global Revision Blueprint for guided editing by coordinating preferences via conflict-aware instruction fusion. The paper introduces risk-aware stability metrics to explicitly quantify IF-GEO's objective of cross-query stability. Experiments on multi-query benchmarks demonstrate that IF-GEO achieves substantial performance gains while maintaining robustness across diverse retrieval scenarios.",312.94,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13942v1_Glance-or-Gaze Incentivizing LMMs to Adaptively Fo.pdf,Glance-or-Gaze: Incentivizing LMMs to Adaptively Focus Search via Reinforcement Learning,"['Hongbo Bai', 'Yujin Zhou', 'Yile Wu', 'Pengcheng Wen', 'Kunhao Pan', 'Sirui Han', 'Yike Guo']","Large Multimodal Models (LMMs) have achieved remarkable success in visual understanding but struggle with knowledge-intensive queries involving long-tail entities or evolving information. Recent search-augmented approaches introduce visual redundancy and lack iterative reflection. To address these challenges, the authors propose Glance-or-Gaze (GoG), a fully autonomous framework that shifts from passive perception to active visual planning. GoG introduces a Selective Gaze mechanism that dynamically chooses whether to glance at global context or gaze into high-value regions, filtering irrelevant information before retrieval. A dual-stage training strategy, Reflective GoG Behavior Alignment via supervised fine-tuning and Complexity-Adaptive Reinforcement Learning, enhances the model's capability to handle complex queries through iterative reasoning. Experiments across six benchmarks demonstrate state-of-the-art performance. Ablation studies confirm that both Selective Gaze and complexity-adaptive RL are essential for effective visual search.",310.53,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13948v1_Stream-Voice-Anon Enhancing Utility of Real-Time S.pdf,Enhancing Utility of Real-Time Speaker Anonymization via Neural Audio Codec and Language Models,"['Nikita Kuzmin', 'Songting Liu', 'Kong Aik Lee', 'Eng Siong Chng']","Protecting speaker identity is crucial for online voice applications, yet streaming speaker anonymization (SA) remains underexplored. Recent research has demonstrated that neural audio codec (NAC) provides superior speaker feature disentanglement and linguistic fidelity. NAC can also be used with causal language models (LM) to enhance linguistic fidelity and prompt control for streaming tasks. However, existing NAC-based online LM systems are designed for voice conversion (VC) rather than anonymization, lacking the techniques required for privacy protection. Building on these advances, we present Stream-Voice-Anon, which adapts modern causal LM-based NAC architectures specifically for streaming SA by integrating anonymization techniques. Our anonymization approach incorporates pseudo-speaker representation sampling, a speaker embedding mixing, and diverse prompt selection strategies for LM conditioning that leverage the disentanglement properties of quantized content codes to prevent speaker information leakage. Additionally, we compare dynamic and fixed delay configurations to explore latency-privacy trade-offs in real-time scenarios. Under the VoicePrivacy 2024 Challenge protocol, Stream-Voice-Anon achieves substantial improvements in intelligibility (up to 46% relative WER reduction) and emotion preservation (up to 28% UAR relative) compared to the previous state-of-the-art streaming method DarkStream while maintaining comparable latency (180ms vs 200ms) and privacy protection against lazy-informed attackers, though showing 15% relative degradation against semi-informed attackers.",312.6,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13964v1_RL-BioAug Label-Efficient Reinforcement Learning f.pdf,RL-BioAug: Label-Efficient Reinforcement Learning for Self-Supervised EEG Representation Learning,"['Cheol-Hui Lee', 'Hwa-Yeon Lee', 'Dong-Joo Kim']","The quality of data augmentation is a critical determinant for the performance of contrastive learning in EEG tasks. While this paradigm is promising for utilizing unlabeled data, static or random augmentation strategies often fail to preserve intrinsic information due to the non-stationarity of EEG signals. To address this, the authors propose RL-BioAug, a framework that leverages a label-efficient reinforcement learning agent to autonomously determine optimal augmentation policies. Utilizing only a minimal fraction (10%) of labeled data, the method enables the encoder to learn robust representations in a strictly self-supervised manner. Experimental results demonstrate that RL-BioAug significantly outperforms random selection strategies, achieving substantial improvements in Macro-F1 score on the Sleep-EDFX and CHB-MIT datasets.",311.01,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13969v1_Autonomous Knowledge Graph Exploration with Adapti.pdf,Autonomous Knowledge Graph Exploration with Adaptive Breadth-Depth Retrieval,"['Joaquín Polonuer', 'Lucas Vittor', 'Iñaki Arango', 'Ayush Noori', 'David A. Clifton', 'Luciano Del Corro', 'Marinka Zitnik']","Retrieving evidence for language model queries from knowledge graphs requires balancing broad search across the graph with multi-hop traversal to follow relational links. Similarity-based retrievers provide coverage but remain shallow, whereas traversal-based methods rely on selecting seed nodes to start exploration, which can fail when queries span multiple entities and relations. The paper introduces ARK: Adaptive Retriever of Knowledge, an agentic KG retriever that gives language models control over this breadth-depth tradeoff using a two-operation toolset: global lexical search over node descriptors and one-hop neighborhood exploration that composes into multi-hop traversal. ARK alternates between breadth-oriented discovery and depth-oriented expansion without depending on a fragile seed selection, a pre-set hop depth, or requiring retrieval training. ARK adapts tool use to queries, using global search for language-heavy queries and neighborhood exploration for relation-heavy queries. On STaRK, ARK reaches 59.1% average Hit@1 and 67.4 average MRR, improving average Hit@1 by up to 31.4% and average MRR by up to 28.0% over retrieval-based and agent-free methods. Finally, the paper distills ARK's tool-use trajectories from a large teacher into an 8B model via label-free imitation, improving Hit@1 by +7.0, +26.6, and +13.5 absolute points over the base 8B model on AMAZON, MAG, and PRIME datasets, respectively, while retaining up to 98.5% of the teacher's Hit@1 rate.",311.28,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13992v1_The Whole Is Greater Than the Sum of Its Parts A C.pdf,The Whole Is Greater Than the Sum of Its Parts: A Compatibility-Aware Multi-Teacher CoT Distillation Framework,"['Jin Cui', 'Jiaqi Guo', 'Jiepeng Zhou', 'Ruixuan Yang', 'Jiayi Lu', 'Jiajun Xu', 'Jiangcheng Song', 'Boran Zhao', 'Pengju Ren']","The paper introduces COMPACT, a framework that adaptively fuses supervisions from different teachers by dynamically weighting teacher gradients based on the student’s real-time compatibility. This approach addresses the challenges of teacher-student incompatibility and passive supervision, ensuring genuine logic internalization and preventing negative transfer. The framework effectively integrates diverse reasoning capabilities without damaging the model’s original knowledge structure, achieving state-of-the-art performance on various benchmarks while effectively mitigating catastrophic forgetting.",309.53,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13994v1_torch-sla Differentiable Sparse Linear Algebra wit.pdf,torch-sla: Differentiable Sparse Linear Algebra with Adjoint Solvers and Sparse Tensor Parallelism for PyTorch,['Mingyuan Chi'],"torch-sla is an open-source PyTorch library that enables GPU-accelerated, scalable, and differentiable sparse linear algebra. It addresses three fundamental challenges: GPU acceleration for sparse linear solves, nonlinear solves (Newton, Picard, Anderson), and eigenvalue computation; multi-GPU scaling via domain decomposition with halo exchange; and adjoint-based differentiation achieving O(1) computational graph nodes (for autograd) and O(nnz) memory, independent of solver iterations. The library supports multiple backends (SciPy, cuDSS, PyTorch-native) and seamlessly integrates with PyTorch autograd for end-to-end differentiable simulations. Code is available at https://github.com/walkerchi/torch-sla.",309.92,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.13999v1_DAME Duration-Aware Matryoshka Embedding for Durat.pdf,Duration-Aware Matryoshka Embedding for Short-duration Speaker Verification,"['Youngmoon Jung*', 'Joon-Young Yang*', 'Ju-ho Kim', 'Jaeyoung Roh', 'Chang Woo Han', 'Hoon-Young Cho']","Short-utterance speaker verification remains challenging due to limited speaker-discriminative cues in short speech segments. While existing methods focus on enhancing speaker encoders, the embedding learning strategy still forces a single fixed-dimensional representation reused for utterances of any length, leaving capacity misaligned with the information available at different durations. We propose Duration-Aware Matryoshka Embedding (DAME), a model-agnostic framework that builds a nested hierarchy of sub-embeddings aligned to utterance durations. Lower-dimensional representations capture compact speaker traits from short utterances, while higher dimensions encode richer details from longer speech. DAME supports both training from scratch and fine-tuning, and serves as a direct alternative to conventional large-margin fine-tuning, consistently improving performance across durations. On the V oxCeleb1-O/E/H and VOiCES evaluation sets, DAME consistently reduces the equal error rate on 1-s and other short-duration trials, while maintaining full-length performance with no additional inference cost. These gains generalize across various speaker encoder architectures under both general training and fine-tuning setups.",313.83,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14012v1_MATE Matryoshka Audio-Text Embeddings for Open-Voc.pdf,MATRYOSHKA AUDIO–TEXT EMBEDDINGS FOR OPEN-VOCABULARY KEYWORD SPOTTING,"['Youngmoon Jung', 'Myunghun Jung', 'Joon-Young Yang', 'Yong-Hyeok Lee', 'Jaeyoung Roh', 'Hoon-Young Cho']","Open-vocabulary keyword spotting (KWS) with text-based enrollment has emerged as a flexible alternative to fixed-phrase triggers. Prior utterance-level matching methods learn embeddings at a single fixed dimensionality. This work proposes Matryoshka Audio–Text Embeddings (MATE), a dual-encoder framework that encodes multiple embedding granularities within a single vector via nested sub-embeddings. Specifically, it introduces a PCA-guided prefix alignment, where PCA-compressed versions of the full text embedding for each prefix size serve as teacher targets to align both audio and text prefixes. This alignment concentrates salient keyword cues in lower-dimensional prefixes, while higher dimensions add detail. MATE is trained with standard deep metric learning objectives for audio–text KWS and is loss-agnostic. This is the first application of matryoshka-style embeddings to KWS, achieving state-of-the-art results on WSJ and LibriPhrase without any inference overhead.",311.86,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14022v1_Credible CO2 Comparisons A Machine Learning Approa.pdf,Credible CO2 Comparisons: A Machine Learning Approach to Vehicle Powertrain Assessment,"['Rodrigo Pereira David', 'David', 'Luciano Araujo Dourado Filho', 'Daniel Marques da Silva', 'João Alfredo Cal-Braz']","This paper proposes a machine learning-based framework for like-for-like operational assessment of internal combustion engine vehicles (ICEVs) and electric vehicles (EVs) under identical, real-world driving conditions. The approach isolates technology-specific effects by holding the observed speed profile and environmental context fixed, enabling direct comparison of powertrain performance. Recurrent neural network models are trained independently for each domain to learn the mapping from contextual driving variables (speed, acceleration, temperature) to internal actuation variables (torque, throttle) and instantaneous CO2-equivalent emission rates. This structure allows the construction of counterfactual scenarios that answer: 'What emissions would an EV have generated if it had followed the same driving profile as an ICEV?' By aligning both vehicle types on a unified instantaneous emissions metric, the framework enables fair and reproducible evaluation of powertrain technologies. It offers a scalable foundation for credible, data-driven assessments of vehicle carbon performance under real-world operating conditions.",313.5,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14027v1_Numina-Lean-Agent An Open and General Agentic Reas.pdf,Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics,"['Junqi Liu', 'Zihao Zhou', 'Zekai Zhu', 'Marco Dos Santos', 'Weikun He', 'Jiawei Liu', 'Ran Wang', 'Yunzhou Xie', 'Junqiao Zhao', 'Qiufeng Wang', 'Lihong Zhi', 'Jia Li', 'Wenda Li']","This paper proposes a general coding agent as a formal math reasoner, enabling autonomous interaction with Lean and retrieval of relevant theorems. Based on this paradigm, Numina-Lean-Agent combines Claude Code with Numina-Lean-MCP to solve all problems in Putnam 2025 (12/12), matching the best closed-source system. The system also demonstrates its generality by formalizing the Brascamp–Lieb theorem through interactions with mathematicians. The authors release Numina-Lean-Agent and all solutions at https://github.com/project-numina/numina-lean-agent.",313.42,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14039v1_Generalizing Abstention for Noise-Robust Learning .pdf,Generalizing Abstention for Noise-Robust Learning in Medical Image Segmentation,"['Wesam Moustafa', 'Hossam Elsafty', 'Helen Schneider', 'Lorenz Sparrenberg', 'Rafet Sifa']","Label noise is a critical issue in medical image segmentation, often arising from manual annotation difficulties. Models trained on noisy data are prone to overfitting, degrading their generalization performance. This paper introduces a universal and modular abstention framework to enhance the noise-robustness of various loss functions, improving upon prior work with informed regularization and flexible auto-tuning algorithms. Experiments on medical datasets show that the framework consistently outperforms non-abstaining baselines, especially under high noise levels, establishing abstention as a powerful strategy for building more reliable segmentation models.",311.14,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14041v1_Top 10 Open Challenges Steering the Future of Diff.pdf,Top 10 Open Challenges Steering the Future of Diffusion Language Model and Its Variants,"['Yunhe Wang', 'Kai Han', 'Huiling Zhen', 'Yuchuan Tian', 'Hanting Chen', 'Yongbing Huang', 'Yufei Cui', 'Yingte Shu', 'Shan Gao', 'Ismail Elezi', 'Roy Vaughan Miles', 'Songcen Xu', 'Feng Wen', 'Chao Xu', 'Sinan Zeng', 'Dacheng Tao']","The paper identifies ten fundamental challenges for Diffusion Language Models (DLMs) and their variants, including architectural inertia, gradient sparsity, and limitations of linear reasoning. It proposes a strategic roadmap organized into four pillars: foundational infrastructure, algorithmic optimization, cognitive reasoning, and unified multimodal intelligence. The authors argue that this transition is essential for developing next-generation AI capable of complex structural reasoning, dynamic self-correction, and seamless multimodal integration.",314.21,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14047v1_Collective intelligence in science direct elicitat.pdf,COLLECTIVE INTELLIGENCE IN SCIENCE: DIRECT ELICITATION OF DIVERSE INFORMATION FROM EXPERTS WITH UNKNOWN INFORMATION STRUCTURE,"['ALEXEY V. OSIPOV', 'NIKOLAY N. OSIPOV']","The authors propose a simple mechanism based on a self-resolving play-money prediction market entangled with a chat to aggregate private information from a large group of experts on a complex scientific hypothesis. The system allows experts to share their private information directly through the chat and trade as if the market were resolved based on the truth of the hypothesis. The approach is designed to efficiently aggregate relevant information even if the ground truth cannot be established and experts initially know nothing about each other. By rewarding experts with real assets, the method provides an innovative way to fund large-scale collaborative studies of any type.",310.14,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14051v1_Kakugo Distillation of Low-Resource Languages into.pdf,Kakugo: Distillation of Low-Resource Languages into Small Language Models,"['Peter Devine', 'Mardhiyah Sanni', 'Farid Adilazuarda', 'Julieta Gil Loizaga', 'Barry Haddow']","We present Kakugo, a novel and cost-effective pipeline designed to train general-purpose Small Language Models (SLMs) for low-resource languages using only the language name as input. By using a large teacher model to generate synthetic prompts and instruction datasets, we produced training data and SLMs for 54 low-resource languages. Evaluations across a diverse set of general natural language processing tasks demonstrate that our pipeline consistently improves performance over base models. With a total generation and training cost of under $50 per language, Kakugo offers an accessible method for communities to develop language-specific AI.",309.87,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14053v1_LLMOrbit A Circular Taxonomy of Large Language Mod.pdf,LLMOrbit: A Circular Taxonomy of Large Language Models,"['Badri N. Patro', 'Vijay S. Agneeswaran']","The paper presents LLMOrbit, a comprehensive circular taxonomy of large language models spanning 2019-2025. It examines over 50 major models across 15 organizations through eight interconnected orbital dimensions, documenting architectural innovations, training methodologies, and efficiency patterns. The authors identify three critical crises threatening AI progress and six different paradigms to break the scaling wall. They also trace the evolution from passive generation to active tool-using agents and analyze post-training innovations. The paper provides insight into key techniques and identifies reasoning emergence requirements.",308.58,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14055v1_Decoder-Free Supervoxel GNN for Accurate Brain-Tum.pdf,Decoder-Free Supervoxel GNN for Accurate Brain-Tumor Localization in Multi-Modal MRI,"['Andrea Protani', 'Marc Molina Van Den Bosch', 'Lorenzo Giusti', 'Heloisa Barbosa Da Silva', 'Paolo Cacace', 'Albert Sund Aillet', 'Miguel Angel Gonzalez Ballester', 'Friedhelm Hummel', 'Luigi Serio']","Our approach introduces SVGFormer, a decoder-free pipeline built upon a content-aware grouping stage that partitions the volume into a semantic graph of super-voxels. Its hierarchical encoder learns rich node representations by combining a patch-level Transformer with a supervoxel-level GraphAttention Network, jointly modeling fine-grained intra-region features and broader inter-regional dependencies. This design concentrates all learnable capacity on feature encoding and provides inherent, dual-scale explainability from the patch to the region level. To validate the framework’s flexibility, we trained two specialized models on the BraTS dataset: one for node-level classification and one for tumor proportion regression. Both models achieved strong performance, with the classification model achieving a F1-score of 0.875 and the regression model a MAE of 0.028, confirming the encoder’s ability to learn discriminative and localized features. Our results establish that a graph-based, encoder-only paradigm offers an accurate and inherently interpretable alternative for 3D medical image representation.",312.74,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14056v1_POCI-Diff Position Objects Consistently and Intera.pdf,POCI-Diff: Position Objects Consistently and Interactively with 3D-Layout Guided Diffusion,"['Andrea Rigo', 'Luca Stornaiuolo', 'Weijie Wang', 'Mauro Martino', 'Bruno Lepri', 'Nicu Sebe']","The paper proposes a diffusion-based approach for Text-to-Image (T2I) generation with consistent and interactive 3D layout control and editing. It introduces a novel framework called PositionObjectsConsistentlyandInteractively (POCI-Diff) for jointly enforcing 3D geometric constraints and instance-level semantic binding within a unified diffusion process. The method enables explicit per-object semantic control by binding individual text descriptions to specific 3D bounding boxes through Blended Latent Diffusion, allowing one-shot synthesis of complex multi-object scenes. It also proposes a warping-free generative editing pipeline that supports object insertion, removal, and transformation via regeneration rather than pixel deformation. To preserve object identity and consistency across edits, the diffusion process is conditioned on reference images using IP-Adapter, enabling coherent object appearance throughout interactive 3D editing while maintaining global scene coherence. Experimental results demonstrate that POCI-Diff produces high-quality images consistent with the specified 3D layouts and edits, outperforming state-of-the-art methods in both visual fidelity and layout adherence while eliminating warping-induced geometric artifacts.",314.12,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14063v1_XCR-Bench A Multi-Task Benchmark for Evaluating Cu.pdf,XCR-Bench: A Multi-Task Benchmark for Evaluating Cultural Reasoning in LLMs,"['Mohsinul Kabir', 'Tasnim Ahmed', 'Md Mezbaur Rahman', 'Shaoxiong Ji', 'Hassan Alhuzali', 'Sophia Ananiadou']","XCR-Bench is a benchmark consisting of 4.9k parallel sentences and 1,098 unique Cultural Specific Items (CSIs) spanning three distinct reasoning tasks. It integrates Newmark's CSI framework with Hall's Triad of Culture, enabling systematic analysis of cultural reasoning beyond surface-level artifacts. The findings show that state-of-the-art LLMs exhibit consistent weaknesses in identifying and adapting CSIs related to social etiquette and cultural reference. Additionally, evidence of regional and ethno-religious biases is found even within a single linguistic setting during cultural adaptation. The authors release their corpus and code to facilitate future research on cross-cultural NLP.",311.1,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14069v1_Unsupervised Video Class-Incremental Learning via .pdf,Unsupervised Video Class-Incremental Learning via Deep Embedded Clustering Management,"['Nattapong Kurpukdee', 'Adrian G. Bors']","Unsupervised video class incremental learning (uVCIL) represents an important learning paradigm for learning video information without forgetting, and without considering any data labels. Prior approaches have focused on supervised class-incremental learning, relying on using the knowledge of labels and task boundaries, which is costly, requires human annotation, or is simply not a realistic option. In this paper, we propose a simple yet effective approach to address the uVCIL. We first consider a deep feature extractor network, providing a set of representative video features during each task without assuming any class or task information. We then progressively build a series of deep clusters from the extracted features. During the successive task learning, the model updated from the previous task is used as an initial state in order to transfer knowledge to the current learning task. We perform in-depth evaluations on three standard video action recognition datasets, including UCF101, HMDB51, and Something-to-Something V2, by ignoring the labels from the supervised setting. Our approach significantly outperforms other baselines on all datasets.",313.62,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14084v1_DermaBench A Clinician-Annotated Benchmark Dataset.pdf,DermaBench: A Clinician-Annotated Benchmark Dataset for Dermatology Visual Question Answering and Reasoning,"['Abdurrahim Yilmaz', 'Ozan Erdem', 'Ece Gokyayla', 'Ayda Acar', 'Burc Bugra Dagtas', 'Dilara Ilhan Erdil', 'Gulsum Gencoglan', 'Burak Temelkuran']","DermaBench is a clinician-annotated dermatology Visual Question Answering (VQA) benchmark dataset built on the Diverse Dermatology Images (DDI) dataset. It comprises 656 clinical images from 570 unique patients spanning Fitzpatrick skin types I–VI. The dataset includes annotations for diagnosis, anatomic site, lesion morphology, distribution, surface features, color, and image quality, along with open-ended narrative descriptions and summaries. DermaBench is released as a metadata-only dataset to respect upstream licensing and is publicly available at Harvard Dataverse. The introduction of DermaBench aims to evaluate the visual understanding, language grounding, and clinical reasoning capabilities of multimodal models in dermatology, addressing the limitations of existing datasets focused on image-level classification tasks.",312.17,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14086v1_Two-Stream temporal transformer for video action c.pdf,TWO-STREAM TEMPORAL TRANSFORMER FOR VIDEO ACTION CLASSIFICATION,"['Nattapong Kurpukdee', 'Adrian G. Bors']","Motion representation plays an important role in video understanding and has many applications including action recognition, robot and autonomous guidance or others. Lately, transformer networks, through their self-attention mechanism capabilities, have proved their efficiency in many applications. In this study, we introduce a new two-stream transformer video classifier, which extracts spatio-temporal information from content and optical flow representing movement information. The proposed model identifies self-attention features across the joint optical flow and temporal frame domain and represents their relationships within the transformer encoder mechanism. The experimental results show that our proposed methodology provides excellent classification results on three well-known video datasets of human activities.",311.94,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14087v1_1-bit Count-based Sorting Unit to Reduce Link Powe.pdf,'1' -bit Count-based Sorting Unit to Reduce Link Power in DNN Accelerators,"['Ruichi Han', 'Yizhi Chen', 'Tong Lei', 'Jordi Altayo Gonzalez', 'Ahmed Hemani']","This work proposes the hardware implementation of a comparison-free sorting unit optimized for Convolutional Neural Networks (CNN). By leveraging approximate computing to group population counts into coarse-grained buckets, our design achieves hardware area reductions while preserving the link power benefits of data reordering. Our approximate sorting unit achieves up to 35.4% area reduction while maintaining 19.50% BT reduction compared to 20.42% of precise implementation.",312.74,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14091v1_Zero-shot adaptable task planning for autonomous c.pdf,Zero-shot adaptable task planning for autonomous construction robots: a comparative study of lightweight single and multi-AI agent systems,"['Hossein Naderi', 'Alireza Shojaei', 'Lifu Huang', 'Philip Agee', 'Kereshmeh Afsari', 'Abiola Akanmu']","This study explores the potential of foundation models to enhance the adaptability and generalizability of task planning in construction robots. Four models are proposed and implemented using lightweight, open-source large language models (LLMs) and vision language models (VLMs). These models include one single agent and three multi-agent teams that collaborate to create robot action plans. The models are evaluated across three construction roles: Painter, Safety Inspector, and Floor Tiling. Results show that the four-agent team outperforms the state-of-the-art GPT-4o in most metrics while being ten times more cost-effective. Additionally, teams with three and four agents demonstrate improved generalizability. By discussing how agent behaviors influence outputs, this study enhances the understanding of AI teams and supports future research in diverse unstructured environments beyond construction.",312.13,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14096v1_Remapping and navigation of an embedding space via.pdf,Remapping and navigation of an embedding space via error minimization: a fundamental organizational principle of cognition in natural and artificial systems,"['Benedikt Hartl', 'Léo Pio-Lopez', 'Chris Fields', 'Michael Levin']","Remapping and navigation of an embedding space via error minimization is presented as a fundamental organizational principle in both natural and artificial systems. The authors explore how this principle applies to cognition, focusing on the development and evolution of intelligence and navigation strategies.",312.84,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14099v1_Causal feature selection framework for stable soft.pdf,Causal Feature Selection Framework for Stable Soft Sensor Modeling based on Time-Delayed Cross Mapping,"['Shi-Shun Chen', 'Xiao-Yang Li', 'Enrico Zio']",This paper presents a causal feature selection framework for developing stable soft sensors. The authors introduce a method based on time-delayed cross mapping to model and select features that contribute to the stability of the sensor models. The framework aims to improve the reliability and accuracy of soft sensors in various applications.,310.52,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14115v1_Riemannian Liquid Spatio-Temporal Graph Network.pdf,Riemannian Liquid Spatio-Temporal Graph Network,"['Liangsi Lu', 'Jingchao Wang', 'Zhaorong Dai', 'Hanqian Liu', 'Yang Shi']","Liquid Time-Constant networks (LTCs) excel at modeling irregularly-sampled dynamics but are confined to Euclidean space, leading to geometric distortion when representing real-world graphs with non-Euclidean structures. This paper introduces the Riemannian Liquid Spatio-Temporal Graph Network (RLSTG), which unifies continuous-time liquid dynamics with the geometric inductive biases of Riemannian manifolds. RLSTG models graph evolution through an Ordinary Differential Equation (ODE) formulated directly on a curved manifold, enabling it to faithfully capture the intrinsic geometry of both structurally static and dynamic spatio-temporal graphs. The paper provides rigorous theoretical guarantees for RLSTG, extending stability theorems of LTCs to the Riemannian domain and quantifying its expressive power via state trajectory analysis. Extensive experiments on real-world benchmarks demonstrate that RLSTG achieves superior performance on graphs with complex structures.",308.58,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14124v1_Style Transfer as Bias Mitigation Diffusion Models.pdf,Style Transfer as Bias Mitigation: Diffusion Models for Synthetic Mental Health Text for Arabic,"['Saad Mankarious', 'Ayah Zirikly']","Synthetic data offers a promising solution for mitigating data scarcity and demographic bias in mental health analysis, yet existing approaches largely rely on pretrained large language models (LLMs), which may suffer from limited output diversity and propagate biases in their training data. This work proposes a pretraining-free diffusion-based approach for synthetic text generation that frames bias mitigation as a style transfer problem. Using the CARMA Arabic mental health corpus, which exhibits a substantial gender imbalance, the authors focus on male-to-female style transfer to augment underrepresented female-authored content. They construct five datasets capturing varying linguistic and semantic aspects of gender expression in Arabic and train separate diffusion models for each setting. Quantitative evaluations demonstrate consistently high semantic fidelity between source and generated text, alongside meaningful surface-level stylistic divergence, while qualitative analysis confirms linguistically plausible gender transformations. The results show that diffusion-based style transfer can generate high-entropy, semantically faithful synthetic data without reliance on pretrained LLMs, providing an effective and flexible framework for mitigating gender bias in sensitive, low-resource mental health domains.",312.68,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14152v1_Lost in the Prompt Order Revealing the Limitations.pdf,Lost in the Prompt Order: Revealing the Limitations of Causal Attention in Language Models,"['Hyunjong Ok', 'Jaeho Lee']","Large language models exhibit surprising sensitivity to the structure of the prompt, but the mechanisms underlying this sensitivity remain poorly understood. This work investigates a striking case in multiple-choice question answering, where placing context before the questions and options (CQO) outperforms the reverse order (QOC) by over 14%. Through systematic architectural analysis, causal attention is identified as the core mechanism, where the causal mask prevents option tokens from attending to context, creating an information bottleneck.",313.4,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14154v1_LLM Augmented Intervenable Multimodal Adaptor for .pdf,LLM Augmented Intervenable Multimodal Adaptor for Post-operative Complication Prediction in Lung Cancer Surgery,"['Shubham Pandey', 'Bhavin Jawade', 'Srirangaraj Setlur', 'Venu Govindaraju', 'Kenneth Seastedt']","Postoperative complications remain a critical concern in clinical practice, adversely affecting patient outcomes and contributing to rising healthcare costs. The authors present MIRA-CLE, a deep learning architecture for prediction of risk of postoperative complications in lung cancer surgery by integrating preoperative clinical and radiological data. MIRA-CLE employs a hyperspherical embedding space fusion of heterogeneous inputs, enabling the extraction of robust, discriminative features from both structured clinical records and high-dimensional radiological images. To enhance transparency of prediction and clinical utility, an interventional deep learning module is incorporated in MIRA-CLE, providing interpretable and actionable insights for domain experts to interactively adjust recommendations based on clinical expertise. The approach is validated on a real-world dataset comprising 3,094 lung cancer patients who underwent surgery at Roswell Park Comprehensive Cancer Center. Results demonstrate that MIRA-CLE outperforms various traditional machine learning models and contemporary large language models (LLM) variants alone, for personalized and explainable postoperative risk management. The authors' codebase is available at https://github.com/KNITPhoenix/MIRACLE.",312.54,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14157v1_ConceptCaps -- a Distilled Concept Dataset for Int.pdf,ConceptCaps - a Distilled Concept Dataset for Interpretability in Music Models,"['Bruno Sienkiewicz', 'Łukasz Neumann', 'Mateusz Modrzejewski']","Concept-based interpretability methods like TCA V require clean, well-separated positive and negative examples for each concept. Existing music datasets lack this structure: tags are sparse, noisy, or ill-defined. We introduce ConceptCaps, a dataset of 23k music-caption-audio triplets with explicit labels from a 200-attribute taxonomy. Our pipeline separates semantic modeling from text generation: a VAE learns plausible attribute co-occurrence patterns, a fine-tuned LLM converts attribute lists into professional descriptions, and MusicGen synthesizes corresponding audio. This separation improves coherence and controllability over end-to-end approaches. We validate the dataset through audio-text alignment (CLAP), linguistic quality metrics (BERTScore, MAUVE), and TCA V analysis, confirming that concept probes recover musically meaningful patterns. Dataset and code are available online.",313.36,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14160v1_Domain-Adaptation through Synthetic Data Fine-Tuni.pdf,Domain-Adaptation through Synthetic Data: Fine-Tuning Large Language Models for German Law,"['Ali Hamza Bashir', 'Muhammad Rehan Khalid', 'Kostadin Cvejoski', 'Jana Birr', 'Armin Berger', 'Sandra Halscheidt', 'Christian Temath', 'Rafet Sifa', 'David Berghaus']","This paper presents an effective method for adapting advanced Large Language Models (LLMs) to German legal question answering through a novel synthetic data generation approach. Unlike costly human-annotated resources or unreliable synthetic alternatives, our approach systematically produces high-quality, diverse, and legally accurate question-answer pairs directly from authoritative German statutes. Using rigorous automated filtering methods and parameter-efficient fine-tuning techniques, the LLMs adapted with our synthetic dataset significantly outperform their baseline counterparts on German legal question answering tasks. The results highlight the feasibility of using carefully designed synthetic data as a robust alternative to manual annotation in high-stakes, knowledge-intensive domains.",313.12,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14171v1_Paper2Rebuttal A Multi-Agent Framework for Transpa.pdf,Paper2Rebuttal: A Multi-Agent Framework for Transparent Author Response Assistance,"['Qianli Ma*', 'Chang Guo*', 'Zhiheng Tian*', 'Siyu Wang', 'Jipeng Xiao', 'Yuanhao Yue', 'Zhipeng Zhang†']","Writing effective rebuttals is a high-stakes task that requires precise alignment between reviewer intent and manuscript details. Current solutions typically treat this as a direct-to-text generation problem, leading to hallucination, overlooked critiques, and a lack of verifiable grounding. To address these limitations, the authors introduce REBUTTALAGENT, a multi-agent framework that reframes rebuttal generation as an evidence-centric planning task. The system decomposes complex feedback into atomic concerns and dynamically constructs hybrid contexts by synthesizing compressed summaries with high-fidelity text while integrating an autonomous and on-demand external search module to resolve concerns requiring outside literature. By generating an inspectable response plan before drafting, REBUTTALAGENT ensures that every argument is explicitly anchored in internal or external evidence. The authors validate their approach on the proposed REBUTTALBENCH and demonstrate that their pipeline outperforms strong baselines in coverage, faithfulness, and strategic coherence, offering a transparent and controllable assistant for the peer review process. Code will be released.",312.36,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14172v1_Human Values in a Single Sentence Moral Presence H.pdf,"Human Values in a Single Sentence: Moral Presence, Hierarchies, and Transformer Ensembles on the Schwartz Continuum","['Víctor Yeste', 'Paolo Rosso']","The study focuses on sentence-level identification of 19 values in the Schwartz motivational continuum as a concrete formulation of human value detection in text. It addresses the challenges posed by sparse moral cues and severe class imbalance in out-of-context sentences from news and political manifestos. The research operationalizes a binary moral presence task and compares presence-gated hierarchies with direct multi-label classifiers, finding that the hierarchy does not outperform direct prediction. Lightweight signals and small ensembles are found to yield the most reliable improvements, while hierarchical gating offers limited benefit under an 8GB single-GPU constraint.",314.08,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14175v1_A model of errors in transformers.pdf,A model of errors in transformers,"['Suvrat Raju', 'Praneeth Netrapalli']","The authors study the error rate of Large Language Models (LLMs) on tasks like arithmetic that require a deterministic output and repetitive processing of tokens. They argue that incorrect predictions arise from small errors in the attention mechanism accumulating to a threshold. They derive a quantitative two-parameter relationship between accuracy and task complexity. The parameters vary with the prompt and the model, and can be interpreted in terms of an elementary noise rate and the number of plausible erroneous tokens. The authors perform extensive empirical tests and find excellent agreement between predicted and observed accuracy for various tasks, although they also identify deviations in some cases. The model provides an alternative to suggestions that errors indicate the collapse of reasoning or inability to express compositional functions.",312.2,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14192v1_Toward Efficient Agents Memory Tool learning and P.pdf,"Toward Efficient Agents: A Survey of Memory, Tool learning, and Planning","['Xiaofang Yang', 'Lijun Li', 'Heng Zhou', 'Tong Zhu', 'Xiaoye Qu', 'Yuchen Fan', 'Qianshan Wei', 'Rui Ye', 'Li Kang', 'Yiran Qin', 'Zhiqiang Kou', 'Daizong Liu', 'Qi Li', 'Ning Ding', 'Siheng Chen', 'Jing Shao']","Recent years have witnessed increasing interest in extending large language models into agentic systems. While the effectiveness of agents has continued to improve, efficiency, which is crucial for real-world deployment, has often been overlooked. This paper investigates efficiency from three core components of agents: memory, tool learning, and planning, considering costs such as latency, tokens, steps, etc. It reviews a broad range of recent approaches that differ in implementation yet frequently converge on shared high-level principles, including bounding context via compression and management, designing reinforcement learning rewards to minimize tool invocation, and employing controlled search mechanisms to enhance efficiency. The paper characterizes efficiency in two complementary ways: comparing effectiveness under a fixed cost budget and comparing cost at a comparable level of effectiveness. It also discusses key challenges and future directions, providing promising insights.",314.06,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14209v1_InT Self-Proposed Interventions Enable Credit Assi.pdf,Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning,"['Matthew Y. R. Yang', 'Hao Bai', 'Ian Wu', 'Gene Yang', 'Amrith Setlur', 'Aviral Kumar']","This paper introduces Intervention Training (InT), a training paradigm for large language models (LLMs) that performs fine-grained credit assignment on its own reasoning traces by proposing short, targeted corrections. InT identifies the first error in the model's reasoning and proposes a single-step intervention to redirect the trajectory toward the correct solution. The model then applies supervised fine-tuning to the on-policy rollout up to the point of error concatenated with the intervention, localizing error to the specific step that caused failure. The authors demonstrate that the resulting model serves as a better initialization for RL training, improving accuracy by nearly 14% over a 4B-parameter base model on IMO-AnswerBench.",313.1,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14230v1_MASCOT Towards Multi-Agent Socio-Collaborative Com.pdf,MASCOT: Towards Multi-Agent Socio-Collaborative Companion Systems,"['Yiyang Wang', 'Yiqiao Jin', 'Alex Cabral', 'Josiah Hester']","Multi-agent systems (MAS) have emerged as promising socio-collaborative companions for emotional and cognitive support. However, these systems often suffer from persona collapse and social sycophancy, leading to redundant, non-constructive dialogue. The paper proposes MASCOT, a generalizable framework that introduces a bi-level optimization strategy to harmonize individual and collective behaviors. MASCOT includes Persona-Aware Behavioral Alignment, which fine-tunes individual agents for strict persona fidelity, and Collaborative Dialogue Optimization, which ensures diverse and productive discourse. Extensive evaluations across psychological support and workplace domains show that MASCOT significantly outperforms state-of-the-art baselines, achieving improvements of up to +14.1 in Persona Consistency and +10.6 in Social Contribution.",310.87,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14232v1_KAGE-Bench Fast Known-Axis Visual Generalization E.pdf,KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning,"['Egor Cherepannov', 'Daniil Zelezetsky', 'Alexey K. Kovalev', 'Aleksandr I. Panov']","Pixel-based reinforcement learning agents often fail under purely visual distribution shifts, even when latent dynamics and rewards are unchanged. This paper introduces KAGE-Env, a JAX-native 2D platformer that factorizes the observation process into independently controllable visual axes while keeping the underlying control problem fixed. By construction, varying a visual axis affects performance only through the induced state-conditional action distribution of a pixel policy, providing a clean abstraction for visual generalization. Using a standard PPO-CNN baseline, the authors observe strong axis-dependent failures, with background and photometric shifts often collapsing success, while agent-appearance shifts are comparatively benign. The fully vectorized JAX implementation enables up to 33M environment steps per second on a single GPU, enabling fast and reproducible sweeps over visual factors.",312.02,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14234v1_Q-learning with Adjoint Matching.pdf,Q-learning with Adjoint Matching,"['Qiyang Li', 'Sergey Levine']","The paper proposes Q-learning with Adjoint Matching (QAM), a novel TD-based reinforcement learning algorithm designed to optimize expressive diffusion or flow-matching policies with respect to a parameterized Q-function. QAM addresses the challenge of numerically unstable gradient-based optimization for flow or diffusion policies by leveraging adjoint matching, a technique from generative modeling. This approach transforms the critic's action gradient into a step-wise objective function that is free from unstable backpropagation while providing an unbiased, expressive policy at the optimum. QAM combines temporal-difference backup for critic learning and consistently outperforms prior approaches on hard, sparse reward tasks in both offline and offline-to-online RL settings. The authors provide code and a detailed explanation of their method.",312.58,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14235v1_Opportunities in AIML for the Rubin LSST Dark Ener.pdf,Opportunities in AI/ML for the Rubin LSST,"['The LSST Dark Energy Science Collaboration', 'Eric Aubourg', 'Camille Avestruz', 'Matthew R. Becker', 'Biswajit Biswas', 'Rahul Biswas', 'Boris Bolliet', 'Adam S. Bolton', 'Clecio R. Bom', 'Raphaël Bonnet-Guerrini', 'Alexandre Boucaud', 'Jean-Eric Campagne', 'Chihway Chang', 'Aleksandra Ciprijanović', 'Johann Cohen-Tanugi', 'Michael W. Coughlin', 'John Franklin Crenshaw', 'Juan C. Cuevas-Tello', 'Juan de Vicente', 'Seth W. Digel', 'Steven Dillmann', 'Alex Drlica-Wagner', 'Sydney Erickson', 'Alexander T. Gagliano', 'Christos Georgiou', 'Aritra Ghosh', 'Matthew Grayling', 'Kirill A. Grishin', 'Alan Heavens', 'Lindsay R. House', 'Mustapha Ishak', 'Wassim Kabalan', 'Arun Kannawadi', 'Francis Lanusse', 'C. Danielle Leonard', 'Pierre-Franc François Léget', 'Michelle Lochner', 'Yao-Yuan Mao', 'Peter Melchior', 'Grant Merz', 'Martin Millon', 'Anais Moller', 'Gautham Narayan', 'Yuuki Omori', 'Hiranya Peiris', 'Laurence Perreault-Levasseur', 'Andrés A. Plazas Malagón', 'Nesar Ramachandra', 'Benjamin Remy', 'Cécile Roucelle', 'Jaime Ruiz-Zapatero', 'Stefan Schuldt', 'Ignacio Sevilla-Noarbe', 'Ved G. Shah', 'Tjitske Starkenburg', 'Stephen Thorp', 'Laura Toribio San Cipriano', 'Tilman Tröster', 'Roberto Trotta', 'Padma Venkatraman', 'Amanda Wasserman', 'Tim White', 'Yuanyuan Zhang']","The Rubin LSST Dark Energy Science Collaboration (DESC) presents opportunities for leveraging AI/ML techniques to enhance the scientific capabilities of the Large Synoptic Survey Telescope (LSST). The collaboration includes researchers from various institutions, focusing on areas such as data analysis, machine learning algorithms, and dark energy studies. The summary highlights the potential for AI/ML to improve LSST's ability to detect and analyze transient phenomena, as well as to interpret complex data from the LSST survey.",309.75,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14242v1_APEX-Agents.pdf,AI Productivity Index for Agents (APEX–Agents),"['Bertie Vidgen', 'Austin Mann', 'Abby Fennelly', 'John Wright', 'Stanly Lucas', 'Rothman Marco', 'Burstein Julien', 'Benchek David', 'Ostrofsky Anirudh', 'Ravichandran Debnil', 'Sur Neel', 'Venugopal Alannah', 'Hsia Isaac', 'Robinson Calix', 'Huang Calix', 'Varones Olivia', 'Khan Daniyal', 'Haines Michael', 'Richards Zach', 'Mahapatra Chirag', 'Foody Brendan', 'Nitski Osvald', 'Mercor apex@mercor.com']","The paper introduces APEX–Agents, a benchmark for assessing AI agents' ability to execute long-horizon, cross-application tasks created by investment banking analysts, management consultants, and corporate lawyers. Eight agents are tested using Pass@1, with Gemini 3 Flash (Thinking=High) achieving the highest score of 24.0%. The authors open-source the benchmark, infrastructure, and all relevant materials.",313.3,Qwen2.5-3B,Nvidia B200 (Cloud Native)
2601.14255v1_VideoMaMa Mask-Guided Video Matting via Generative.pdf,VideoMaMa: Mask-Guided Video Matting via Generative Prior,"['Sangbeom Lim', 'Seoung Wug Oh', 'Jiahui Huang', 'Heeji Yoon', 'Seungryong Kim', 'Joon-Young Lee']","VideoMaMa is a diffusion-based model that generates high-quality alpha mattes from input binary segmentation masks. It demonstrates strong zero-shot generalization to real-world footage, even though it is trained solely on synthetic data. The model is validated using the Matting Anything in Video (MA-V) dataset, which offers high-quality matting annotations for more than 50K real-world videos. The findings emphasize the importance of large-scale pseudo-labeled video matting and showcase how generative priors and accessible segmentation cues can drive scalable progress in video matting research.",313.39,Qwen2.5-3B,Nvidia B200 (Cloud Native)
