filename,title,authors,doi,tps,model,platform,raw_output
2601.07192v1_Relink Constructing Query-Driven Evidence Graph On.pdf,Relink: Constructing Query-Driven Evidence Graph On-the-Fly for GraphRAG,"['Manzong Huang', 'Chenyang Bu', 'Yi He', 'Xingrui Zhuo', 'Xindong Wu']",,12.4,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Relink: Constructing Query-Driven Evidence Graph On-the-Fly for GraphRAG || Manzong Huang1, Chenyang Bu1*, Yi He2, Xingrui Zhuo1, Xindong Wu 1* || 1Key Laboratory of Knowledge Engineering with Big Data (the Ministry of Education of China), School of Computer Science || and Information Engine ... (truncated) ||  || { ""title"": ""Relink: Constructing Query-Driven Evidence Graph On-the-Fly for GraphRAG"", ""authors"": [""Manzong Huang"", ""Chenyang Bu"", ""Yi He"", ""Xingrui Zhuo"", ""Xindong Wu""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""GraphRAG"", ""Relink"", ""Query-Driven Evidence Graph"", ""On-the-Fly"", ""Knowledge Graph"", ""Open-Domain Question Answering""], ""summary"": ""Graph-based Retrieval-Augmented Generation (GraphRAG) mitigates hallucinations in Large Language Models (LLMs) by grounding them in structured knowledge. However, current GraphRAG methods are constrained by a prevailing build-then-reason paradigm, which relies on a static, pre-constructed Knowledge Graph (KG). This paradigm faces two critical challenges: the inherent incompleteness of KGs often breaks reasoning paths, and the low signal-to-noise ratio in graphs introduces distractor facts, presenting query-relevant but misleading knowledge that disrupts the reasoning process. To address these challenges, we propose a reason-and-construct paradigm and introduce Relink, a framework that dynamically builds a query-specific evidence graph. Relink instantiates required facts from a latent relation pool derived from the original text corpus, repairing broken paths on the fly. To handle misleading or distractor facts, Relink employs a unified, query-aware evaluation strategy that jointly considers candidates from both the KG and latent relations, selecting those most useful for answering the query. Extensive experiments on five Open-Domain Question Answering benchmarks show that Relink achieves significant average improvements of 5.4% in EM and 5.2% in F1 over leading GraphRAG baselines, demonstrating the superiority of our proposed framework."" } ||  || [ Prompt: 33.7 t/s | Generation: 12.4 t/s ]"
2601.07197v1_Beyond Variance Knowledge-Aware LLM Compression vi.pdf,Beyond Variance: Knowledge-Aware LLM Compression via Fisher-Aligned Subspace Diagnostics,"['Ibne Farabi Shihab*', 'Sanjeda Akter*', 'Anuj Sharma']",,12.3,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Beyond Variance: Knowledge-Aware LLM Compression via Fisher-Aligned || Subspace Diagnostics || Ibne Farabi Shihab*1 and Sanjeda Akter *1 and Anuj Sharma 2 || 1Department of Computer Science, Iowa State University || 2Department of Civil, Construction & Environmental Engineering, Iowa State Univ ... (truncated) ||  || ```json || { || ""title"": ""Beyond Variance: Knowledge-Aware LLM Compression via Fisher-Aligned Subspace Diagnostics"", || ""authors"": [""Ibne Farabi Shihab*"", ""Sanjeda Akter*"", ""Anuj Sharma""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Large Language Models"", ""LLMs"", ""Knowledge Compression"", ""Fisher-Aligned Subspace Compression"", ""FASC"", ""Transformer Architectures"", ""Activation-Gradient Coupling"", ""Fisher Information Matrix"", ""Dependence Violation Score""], || ""summary"": ""Post-training activation compression is essential for deploying Large Language Models (LLMs) on resource-constrained hardware. Standard methods like Singular Value Decomposition (SVD) are gradient-blind, preserving high-variance dimensions regardless of their impact on factual knowledge preservation. We introduce Fisher-Aligned Subspace Compression (FASC), a knowledge-aware compression framework that selects subspaces by directly modeling activation-gradient coupling, minimizing a second-order surrogate of the loss function. FASC leverages the Fisher Information Matrix to identify dimensions critical for factual knowledge, often residing in low-variance but high-gradient-sensitivity subspaces. We propose the Dependence Violation Score (DVS) as a general-purpose diagnostic metric that quantifies activation-gradient coupling, revealing where factual knowledge is stored within transformer architectures. Extensive experiments on Mistral-7B and Llama-3-8B demonstrate that FASC preserves 6-8% more accuracy on knowledge-intensive benchmarks (MMLU, LAMA) compared to variance-based methods at 50% rank reduction, effectively enabling a 7B model to match the factual recall of a 13B uncompressed model. Our analysis reveals that DVS serves as a fundamental signal of stored knowledge, with high- layers emerging only when models internalize factual associations during training."" || } ||  ||  || [ Prompt: 33.6 t/s | Generation: 12.3 t/s ]"
2601.07199v1_Forward versus Backward Comparing Reasoning Object.pdf,Forward versus Backward: Comparing Reasoning Objectives in Direct Preference Optimization,"['Murtaza Nikazad', 'Raghuram Ramanujan']",,13.5,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Forward versus Backward: Comparing Reasoning Objectives in || Direct Preference Optimization || Murtaza Nikazad || Department of Math and Computer Science || Davidson College || munikzad@davidson.edu || Raghuram Ramanujan || Department of Math and Computer Science || Davidson College || raramanujan@davidson.e ... (truncated) ||  || ```json || { || ""title"": ""Forward versus Backward: Comparing Reasoning Objectives in Direct Preference Optimization"", || ""authors"": [""Murtaza Nikazad"", ""Raghuram Ramanujan""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Direct Preference Optimization"", ""Reasoning Accuracy"", ""Error Recognition"", ""Large Language Models""], || ""summary"": ""This paper investigates the effect of training objective composition on reasoning reliability through Direct Preference Optimization. Two complementary training signals are examined: forward chain-of-thought generation, which trains the model to produce correct reasoning traces, and backward verification, which trains the model to verify and acknowledge errors in candidate solutions. Experiments on GSM8K reveal a fundamental trade-off between these objectives. Forward-only DPO training achieves the highest accuracy improvement, increasing from 83.1% to 86.6% (+3.5 percentage points), while backward-only training yields minimal accuracy gains but substantially reduces the false positive rate from 13.4% to 4.3%. Notably, both training variants reduce acknowledgement rate compared to the baseline, suggesting that preference optimization increases model confidence in its outputs. These findings indicate that forward and backward reasoning objectives provide distinct and complementary learning signals: forward training improves problem-solving capability, while backward training improves verification calibration. The complete training and evaluation pipeline, implemented efficiently through Low-Rank Adaptation, is released to facilitate further research."" || } ||  ||  || [ Prompt: 38.1 t/s | Generation: 13.5 t/s ]"
2601.07200v1_Safeguarding LLM Fine-tuning via Push-Pull Distrib.pdf,Safeguarding LLM Fine-tuning via Push-Pull Distributional Alignment,"['Haozhong Wang', 'Zhuo Li', 'Yibo Yang', 'He Zhao', 'Hongyuan Zha', 'Dandan Guo']",,12.3,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Safeguarding LLM Fine-tuning via Push-Pull Distributional Alignment || Haozhong Wang1* Zhuo Li2* Yibo Yang3 He Zhao4 Hongyuan Zha5 Dandan Guo6 || guodandan@jlu.edu.cn || Abstract || The inherent safety alignment of Large Lan- || guage Models (LLMs) is prone to erosion dur- || ing fine-tuning, even wh ... (truncated) ||  || { ""title"": ""Safeguarding LLM Fine-tuning via Push-Pull Distributional Alignment"", ""authors"": [""Haozhong Wang"", ""Zhuo Li"", ""Yibo Yang"", ""He Zhao"", ""Hongyuan Zha"", ""Dandan Guo""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Safety Alignment"", ""Fine-tuning"", ""Optimal Transport"", ""Push-Pull Mechanism"", ""LLM Security""], ""summary"": ""The paper introduces Safety Optimal Transport (SOT), a novel framework that reframes safe fine-tuning from an instance-level filtering challenge to a distribution-level alignment task grounded in Optimal Transport (OT). SOT optimizes sample importance by actively pulling the downstream distribution towards a trusted safe anchor while simultaneously pushing it away from a general harmful reference. This establishes a robust geometric safety boundary that effectively purifies the training data. Extensive experiments across diverse model families and domains demonstrate that SOT significantly enhances model safety while maintaining competitive downstream performance, achieving a superior safety-utility trade-off compared to baselines."" } ||  || [ Prompt: 34.1 t/s | Generation: 12.3 t/s ]"
2601.07201v1_CalPro Prior-Aware Evidential--Conformal Predictio.pdf,CalPro: Prior-Aware EvidentialConformal Prediction with Structure-Aware Guarantees for Protein Structures,"['Ibne Farabi Shihab * 1', 'Sanjeda Akter * 1', 'Anuj Sharma 2']",,12.4,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || CalPro: Prior-Aware EvidentialConformal Prediction with Structure-Aware || Guarantees for Protein Structures || Ibne Farabi Shihab * 1 Sanjeda Akter * 1 Anuj Sharma 2 || Abstract || Deep protein structure predictors such as Al- || phaFold provide confidence estimates (e.g., || pLDDT) that are not cal ... (truncated) ||  || { || ""title"": ""CalPro: Prior-Aware EvidentialConformal Prediction with Structure-Aware Guarantees for Protein Structures"", || ""authors"": [""Ibne Farabi Shihab * 1"", ""Sanjeda Akter * 1"", ""Anuj Sharma 2""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""CalPro"", ""prior-aware"", ""evidential conformal"", ""protein structure prediction"", ""shift-robust"", ""coverage guarantees"", ""structure-aware"", ""disorder"", ""flexibility"", ""PAC-Bayesian bounds"", ""coverage degradation"", ""calibration error"", ""downstream success""], || ""summary"": ""Deep protein structure predictors such as AlphaFold provide confidence estimates (e.g., pLDDT) that are not calibrated and degrade under distribution shifts across experimental modalities, temporal changes, and disordered regions. CalPro introduces a prior-aware evidential conformal framework for shift-robust uncertainty quantification. It combines a geometric evidential head outputting NormalInverse-Gamma distributions via graph-based architecture, a differentiable conformal layer enabling end-to-end training with finite-sample coverage guarantees, and domain priors (disorder, flexibility) encoded as soft constraints. Theoretical structure-aware coverage guarantees are derived using PAC-Bayesian bounds over ambiguity sets, showing CalPro maintains near-nominal coverage while achieving tighter intervals than vanilla conformal in regions where priors are informative. Empirically, CalPro achieves 5% coverage degradation across modalities (vs. 15-25% for baselines), reduces calibration error by 30-50%, and improves downstream ligand-docking success by 25%. Beyond proteins, CalPro applies to structured regression tasks where priors encode local reliability, validated on non-biological benchmarks."" || } ||  || [ Prompt: 33.4 t/s | Generation: 12.4 t/s ]"
2601.07206v1_LLMRouterBench A Massive Benchmark and Unified Fra.pdf,LLMRouterBench: A Massive Benchmark and Unified Framework for LLM Routing,"['Hao Li*', 'Yiqun Zhang*', 'Zhaoyan Guo*', 'Chenxu Wang*', 'Shengji Tang', 'Qiaosheng Zhang', 'Yang Chen', 'Biqing Qi', 'Peng Ye', 'Lei Bai', 'Shuyue Hu']",,6.3,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LLMRouterBench: A Massive Benchmark and Unified Framework for || LLM Routing || Hao Li* Yiqun Zhang* Zhaoyan Guo* Chenxu Wang* || Shengji Tang Qiaosheng Zhang Yang Chen Biqing Qi || Peng Ye Lei Bai Zhen Wang  Shuyue Hu || Shanghai Artificial Intelligence Laboratory || Abstract || Large language model (L ... (truncated) ||  || { || ""title"": ""LLMRouterBench: A Massive Benchmark and Unified Framework for LLM Routing"", || ""authors"": [""Hao Li*"", ""Yiqun Zhang*"", ""Zhaoyan Guo*"", ""Chenxu Wang*"", ""Shengji Tang"", ""Qiaosheng Zhang"", ""Yang Chen"", ""Biqing Qi"", ""Peng Ye"", ""Lei Bai"", ""Shuyue Hu""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""LLM routing"", ""large language models"", ""benchmark"", ""performance-oriented"", ""performance-cost trade-off"", ""routing baselines""], || ""summary"": ""LLMRouterBench is a large-scale benchmark and unified framework for LLM routing, comprising over 400K instances from 21 datasets and 33 models. It provides comprehensive metrics for both performance-oriented and performance-cost trade-off routing and integrates 10 representative routing baselines. The framework confirms strong model complementarity, finds that many routing methods exhibit similar performance under unified evaluation, and shows that larger ensembles exhibit diminishing returns compared to careful model curation. The benchmark also enables latency-aware analysis. All code and data are available at https://github.com/ynulihao/LLMRouterBench."" || } ||  || [ Prompt: 33.4 t/s | Generation: 6.3 t/s ]"
2601.07209v1_SIRR-LMM Single-image Reflection Removal via Large.pdf,SIRR-LMM: Single-image Reflection Removal via Large Multimodal Model,"['Yu Guo', 'Zhiqiang Lao', 'Xiyun Song', 'Yubin Zhou', 'Heather Yu']",,5.3,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SIRR-LMM: Single-image Reflection Removal via Large Multimodal Model || Yu Guo, Zhiqiang Lao, Xiyun Song, Yubin Zhou and Heather Yu || Futurewei Technologies, US || {yguo1,zlao,xsong,yzhou2,hyu}@futurewei.com || Abstract || Glass surfaces create complex interactions of reflected and || transmitted li ... (truncated) ||  || { ""title"": ""SIRR-LMM: Single-image Reflection Removal via Large Multimodal Model"", ""authors"": [""Yu Guo"", ""Zhiqiang Lao"", ""Xiyun Song"", ""Yubin Zhou"", ""Heather Yu""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Single-image reflection removal"", ""Large Multimodal Model"", ""Glass surfaces"", ""Reflection separation"", ""Deep learning""], ""summary"": ""Glass surfaces create complex interactions of reflected and transmitted light, making single-image reflection removal (SIRR) challenging. Existing datasets suffer from limited physical realism in synthetic data or insufficient scale in real captures. We introduce a synthetic dataset generation framework that path-traces 3D glass models over real background imagery to create physically accurate reflection scenarios with varied glass properties, camera settings, and post-processing effects. Leveraging the capabilities of Large Multimodal Model (LMM), we concatenate the image layers into a single composite input, apply joint captioning, and fine-tune the model using task-specific LoRA rather than full-parameter training. This enables our approach to achieve improved reflection removal and separation performance compared to state-of-the-art methods."" } ||  || [ Prompt: 12.6 t/s | Generation: 5.3 t/s ]"
2601.07214v1_BlindU Blind Machine Unlearning without Revealing .pdf,BlindU: Blind Machine Unlearning without Revealing Erasing Data,"['Weiqi Wang', 'Zhiyi Tian', 'Chenhao Zhang', 'Shui Yu']",,12.6,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || THIS PAPER HAS BEEN ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 1 || BlindU: Blind Machine Unlearning without || Revealing Erasing Data || Weiqi Wang,Member, IEEE, Zhiyi Tian,Member, IEEE, Chenhan Zhang,Member, IEEE, || and Shui Yu,Fellow, IEEE || Abs ... (truncated) ||  || { || ""title"": ""BlindU: Blind Machine Unlearning without Revealing Erasing Data"", || ""authors"": [""Weiqi Wang"", ""Zhiyi Tian"", ""Chenhao Zhang"", ""Shui Yu""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Machine Unlearning"", ""Federated Learning"", ""Privacy Leakage"", ""Privacy Preserving"", ""Information Bottleneck""], || ""summary"": ""This paper explores how to implement unlearning under the condition of not uncovering the erasing data to the server. We propose Blind Unlearning (BlindU), which carries out unlearning using compressed representations instead of original inputs. BlindU only involves the server and the unlearning user: the user locally generates privacy-preserving representations, and the server performs unlearning solely on these representations and their labels. For the FL model training, we employ the information bottleneck (IB) mechanism. The encoder of the IB-based FL model learns representations that distort maximum task-irrelevant information from inputs, allowing FL users to generate compressed representations locally. For effective unlearning using compressed representation, BlindU integrates two dedicated unlearning modules tailored explicitly for IB-based models and uses a multiple gradient descent algorithm to balance forgetting and utility retaining. While IB compression already provides protection for task-irrelevant information of inputs, to further enhance the privacy protection, we introduce a noise-free differential privacy (DP) masking method to deal with the raw erasing data before compressing. Theoretical analysis and extensive experimental results illustrate the superiority of BlindU in privacy protection and unlearning effectiveness compared with the best existing privacy-preserving unlearning benchmarks."" || } ||  || [ Prompt: 32.6 t/s | Generation: 12.6 t/s ]"
2601.07224v1_Consolidation or Adaptation PRISM Disentangling SF.pdf,Consolidation or Adaptation? PRISM: Disentangling SFT and RL Data via Gradient Concentration,"['Yang Zhao*', 'Yangou Ouyang*', 'Xiao Ding', 'Hepeng Wang', 'Bibo Cai', 'Kai Xiong', 'Jinglong Gao', 'Zhouhao Sun', 'Li Du', 'Bing Qin', 'Ting Liu']",,12.2,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Consolidation or Adaptation? PRISM: Disentangling SFT and RL Data via || Gradient Concentration || Yang Zhao*,Yangou Ouyang*, Xiao Ding,Hepeng Wang,Bibo Cai Kai Xiong, || Jinglong Gao, Zhouhao Sun, Li Du, Bing Qin and Ting Liu || Research Center for Social Computing and Interactive Robotics, || Ha ... (truncated) ||  || ```json || { || ""title"": ""Consolidation or Adaptation? PRISM: Disentangling SFT and RL Data via Gradient Concentration"", || ""authors"": [""Yang Zhao*"", ""Yangou Ouyang*"", ""Xiao Ding"", ""Hepeng Wang"", ""Bibo Cai"", ""Kai Xiong"", ""Jinglong Gao"", ""Zhouhao Sun"", ""Li Du"", ""Bing Qin"", ""Ting Liu""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Schema Theory"", ""Gradient Concentration"", ""Hybrid Supervised Fine-Tuning"", ""Reinforcement Learning"", ""Data Arbitration"", ""Internal Optimization Regimes""], || ""summary"": ""While Hybrid Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) has become the standard paradigm for training LLM agents, effective mechanisms for data allocation between these stages remain largely underexplored. Current data arbitration strategies often rely on surface-level heuristics that fail to diagnose intrinsic learning needs. Since SFT targets pattern consolidation through imitation while RL drives structural adaptation via exploration, misaligning data with these functional roles causes severe optimization interference. We propose PRISM, a dynamics-aware framework grounded in Schema Theory that arbitrates data based on its degree of cognitive conflict with the models existing knowledge. By analyzing the spatial geometric structure of gradients, PRISM identifies data triggering high spatial concentration as high-conflict signals that require RL for structural restructuring. In contrast, data yielding diffuse updates is routed to SFT for efficient consolidation. Extensive experiments on WebShop and ALFWorld demonstrate that PRISM achieves a Pareto improvement, outperforming state-of-the-art hybrid methods while reducing computational costs by up to 3.22. Our findings suggest that disentangling data based on internal optimization regimes is crucial for scalable and robust agent alignment."" || } ||  ||  || [ Prompt: 39.7 t/s | Generation: 12.2 t/s ]"
2601.07226v1_Lost in the Noise How Reasoning Models Fail with C.pdf,Lost in the Noise: How Reasoning Models Fail with Contextual Distractors,"['Seongyun Lee', 'Yongrae Jo', 'Minju Seo', 'Moontae Lee', 'Minjoon Seo']",,6.7,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Lost in the Noise: How Reasoning Models Fail with || Contextual Distractors || Seongyun Lee1,2,,Yongrae Jo 2,Minju Seo 1,2,Moontae Lee 2,3,Minjoon Seo 1 || 1KAIST AI, 2LG AI Research,3University of Illinois Chicago || Work done during LG AI Research Internship || Recent advances in reasoning model ... (truncated) ||  || { || ""title"": ""Lost in the Noise: How Reasoning Models Fail with Contextual Distractors"", || ""authors"": [""Seongyun Lee"", ""Yongrae Jo"", ""Minju Seo"", ""Moontae Lee"", ""Minjoon Seo""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""reasoning models"", ""agentic AI"", ""external information"", ""robustness"", ""contextual distractors"", ""NoisyBench""], || ""summary"": ""Recent advances in reasoning models and agentic AI systems have led to an increased reliance on diverse external information. However, this shift introduces input contexts that are inherently noisy, a reality that current benchmarks fail to capture. We introduce NoisyBench, a comprehensive benchmark that systematically evaluates model robustness across 11 datasets in RAG, reasoning, alignment, and tool-use tasks against diverse noise types, including random documents, irrelevant chat histories, and hard negative distractors. Our evaluation reveals a catastrophic performance drop of up to 80% in state-of-the-art models when faced with contextual distractors. Crucially, we find that agentic workflows often amplify these errors by over-trusting noisy tool outputs, and distractors can trigger emergent misalignment even without adversarial intent. We find that prompting, context engineering, SFT, and outcome-reward only RL fail to ensure robustness; in contrast, our proposed Rationale-Aware Reward (RARE) significantly strengthens resilience by incentivizing the identification of helpful information within noise. Finally, we uncover an inverse scaling trend where increased test-time computation leads to worse performance in noisy settings and demonstrate via attention visualization that models disproportionately focus on distractor tokens, providing vital insights for building the next generation of robust, reasoning-capable agents."" || } ||  || [ Prompt: 33.1 t/s | Generation: 6.7 t/s ]"
2601.07229v2_DiSCo Making Absence Visible in Intelligent Summar.pdf,DiSCo: Making Absence Visible in Intelligent Summarization Interfaces,"['ERAN FAINMAN', 'HAGIT BEN SHOSHAN', 'ADIR SOLOMON', 'OSNAT MOKRYN']",,5.9,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DiSCo: Making Absence Visible in Intelligent Summarization Interfaces || ERAN FAINMAN,University of Haifa, Israel || HAGIT BEN SHOSHAN,University of Haifa, Israel || ADIR SOLOMON,University of Haifa, Israel || OSNAT MOKRYN,University of Haifa, Israel || Intelligent interfaces increasingly use larg ... (truncated) ||  || { ""title"": ""DiSCo: Making Absence Visible in Intelligent Summarization Interfaces"", ""authors"": [""ERAN FAINMAN"", ""HAGIT BEN SHOSHAN"", ""ADIR SOLOMON"", ""OSNAT MOKRYN""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Review Summarization"", ""Absence"", ""Expectations"", ""Learning via surprisability"", ""Missing commonalities""], ""summary"": ""Intelligent interfaces increasingly use large language models to summarize user-generated content, yet these summaries emphasize what is mentioned while overlooking what is missing. This presence bias can mislead users who rely on summaries to make decisions. We present Domain Informed Summarization through Contrast (DiSCo), an expectation-based computational approach that makes absences visible by comparing each entity's content with domain topical expectations captured in reference distributions of aspects typically discussed in comparable accommodations. This comparison identifies aspects that are either unusually emphasized or missing relative to domain norms and integrates them into the generated text. In a user study across three accommodation domains, namely ski, beach, and city center, DiSCo summaries were rated as more detailed and useful for decision making than baseline large language model summaries, although slightly harder to read. The findings show that modeling expectations reduces presence bias and improves both transparency and decision support in intelligent summarization interfaces."" } ||  || [ Prompt: 12.0 t/s | Generation: 5.9 t/s ]"
2601.07232v1_Yes FLoReNce I Will Do Better Next Time Agentic Fe.pdf,Agentic Feedback Reasoning for Humorous Meme Detection,"['Olivia Shanhong Liu', 'Pai Chet Ng', 'De Wen Soh', 'Konstantinos N. Plataniotis']",,12.4,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Y es FLoReNce, I Will Do Better Next Time! Agentic Feedback Reasoning for || Humorous Meme Detection || Olivia Shanhong Liu 1, Pai Chet Ng 2, De Wen Soh 1, Konstantinos N. Plataniotis 3 || 1Information Systems Technology and Design Pillar, Singapore University of Technology and Design, Singa ... (truncated) ||  || ```json || { || ""title"": ""Agentic Feedback Reasoning for Humorous Meme Detection"", || ""authors"": [""Olivia Shanhong Liu"", ""Pai Chet Ng"", ""De Wen Soh"", ""Konstantinos N. Plataniotis""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""humorous memes"", ""agentic feedback"", ""closed-loop reasoning"", ""open-loop inference"", ""meme humor"", ""prompting""], || ""summary"": ""This paper proposes FLoReNce, an agentic feedback reasoning framework for detecting meme humor. Unlike existing multimodal or prompting-based models, FLoReNce treats meme understanding as a closed-loop process during learning and an open-loop process during inference. In the closed loop, a reasoning agent is critiqued by a judge, and the error and semantic feedback are converted into control signals and stored in a feedback-informed, non-parametric knowledge base. At inference, the model retrieves similar judged experiences from this KB and uses them to modulate its prompt, enabling better, self-aligned reasoning without finetuning. On the PrideMM dataset, FLoReNce improves both predictive performance and explanation quality over static multimodal baselines, demonstrating that feedback-regulated prompting is a viable path to adaptive meme humor understanding."" || } ||  ||  || [ Prompt: 32.9 t/s | Generation: 12.4 t/s ]"
2601.07233v1_From Thinking to Justifying Aligning High-Stakes E.pdf,From Thinking to Justifying: Aligning High-Stakes Explainability with Professional Communication Standards,"['Chen Qian', 'William & Mary', 'cqian03@wm.edu', 'Yimeng Wang', 'William & Mary', 'ywang139@wm.edu', 'Yu Chen', 'Anytime AI', 'ychen@anytime-ai.com', 'Lingfei Wu', 'Anytime AI', 'lwu@anytime-ai.com', 'Andreas Stathopoulos', 'William & Mary', 'axstat@wm.edu']",,12.3,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || From Thinking to Justifying: Aligning High-Stakes Explainability || with Professional Communication Standards || Chen Qian || William & Mary || cqian03@wm.edu || Yimeng Wang || William & Mary || ywang139@wm.edu || Yu Chen || Anytime AI || ychen@anytime-ai.com || Lingfei Wu || Anytime AI || lwu@anytime-ai.com || Andreas Stat ... (truncated) ||  || ```json || { || ""title"": ""From Thinking to Justifying: Aligning High-Stakes Explainability with Professional Communication Standards"", || ""authors"": [""Chen Qian"", ""William & Mary"", ""cqian03@wm.edu"", ""Yimeng Wang"", ""William & Mary"", ""ywang139@wm.edu"", ""Yu Chen"", ""Anytime AI"", ""ychen@anytime-ai.com"", ""Lingfei Wu"", ""Anytime AI"", ""lwu@anytime-ai.com"", ""Andreas Stathopoulos"", ""William & Mary"", ""axstat@wm.edu""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""explainable AI"", ""high-stakes domains"", ""Chain-of-Thought"", ""professional communication"", ""Result Justify"", ""Structured Explainability Framework""], || ""summary"": ""Explainable AI in high-stakes domains should help stakeholders trust and verify system outputs. However, Chain-of-Thought methods reason before concluding, and logical gaps or hallucinations can yield conclusions that do not reliably align with their rationale. We propose Result Justify, which constrains the output communication to present a conclusion before its structured justification. We introduce SEF (Structured Explainability Framework), operationalizing professional conventions via six metrics for structure and grounding. Experiments across four tasks in three domains validate this approach: all six metrics correlate with correctness (r= 0.20-0.42; p <0.001), and SEF achieves 83.9% accuracy (+5.3 over CoT). These results suggest structured justification can improve verifiability and may also improve reliability."" || } ||  ||  || [ Prompt: 33.8 t/s | Generation: 12.3 t/s ]"
2601.07238v1_Group Pattern Selection Optimization Let LRMs Pick.pdf,Group Pattern Selection Optimization: Let LRMs Pick the Right Pattern for Reasoning,"['Hanbin Wang1*', 'Jingwei Song2*', 'Jinpeng Li3', 'Fei Mi3', 'Lifeng Shang3']",,7.4,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Group Pattern Selection Optimization: Let LRMs Pick the Right Pattern || for Reasoning || Hanbin Wang1*, Jingwei Song2*, Jinpeng Li3, Fei Mi3, Lifeng Shang3 || 1Peking University 2The University of Hong Kong 3Huawei Noahs Ark Lab || wanghanbin95@stu.pku.edu.cn, songjingwei@connect.hku.hk, lijp. ... (truncated) ||  || ```json || { || ""title"": ""Group Pattern Selection Optimization: Let LRMs Pick the Right Pattern for Reasoning"", || ""authors"": [""Hanbin Wang1*"", ""Jingwei Song2*"", ""Jinpeng Li3"", ""Fei Mi3"", ""Lifeng Shang3""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Large reasoning models"", ""reinforcement learning"", ""pattern selection optimization"", ""mathematics"", ""science"", ""reasoning paradigms""], || ""summary"": ""Large reasoning models (LRMs) exhibit diverse high-level reasoning patterns, yet prevailing training recipes implicitly bias models toward a limited set of dominant patterns. Through a systematic analysis, we identify substantial accuracy variance across these patterns on mathematics and science benchmarks, revealing that a model's default reasoning pattern is often sub-optimal for a given problem. To address this, we introduce Group Pattern Selection Optimization (GPSO), a reinforcement learning framework that extends GRPO by incorporating multi-pattern rollouts, verifier-guided optimal pattern selection per problem, and attention masking during optimization to prevent the leakage of explicit pattern suffixes into the learned policy. By exploring a portfolio of diverse reasoning strategies and optimizing the policy on the most effective ones, GPSO enables the model to internalize the mapping from problem characteristics to optimal reasoning patterns. Extensive experiments demonstrate that GPSO delivers consistent and substantial performance gains across various model backbones and benchmarks, effectively mitigating pattern sub-optimality and fostering more robust, adaptable reasoning. All data and codes are available at https://github.com/wanghanbinpanda/GPSO."" || } ||  ||  || [ Prompt: 34.0 t/s | Generation: 7.4 t/s ]"
2601.07239v1_Stochastic CHAOS Why Deterministic Inference Kills.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  ||  || Stochas(c CHAOS: Why Determinis)c Inference Kills, and Distribu(onal Variability Is the Heartbeat of Ar(cial Cogni(on || Tanmay Joshi1, Shourya Aggarwal1, Anusa Saha1, Aadi Pandey1, || Shreyash Dhoot1, Vighnesh Rai1, Raxit Goswami2, || Aman Chadha3, Vinija Jain4, Amitava Das1 || 2Raap ... (truncated) ||  || ```json || { || ""title"": ""Stochas(c CHAOS: Why Deterministic Inference Kills, and Distributional Variability Is the Heartbeat of Artificial Cognition"", || ""authors"": [""Tanmay Joshi1"", ""Shourya Aggarwal1"", ""Anusa Saha1"", ""Aadi Pandey1"", ""Shreyash Dhoot1"", ""Vighnesh Rai1"", ""Raxit Goswami2"", ""Aman Chadha3"", ""Vinija Jain4"", ""Amitava Das1""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Deterministic Inference"", ""Stochastic CHAOS"", ""LLMs"", ""Reproducibility"", ""Distributonal Variability"", ""Artificial Cognition""], || ""summary"": ""Deterministic inference is a comforting ideal in classical software, but for large language models (LLMs) moving into real-world deployment, it has been imported wholesale into inference stacks. Recent work from the Thinking Machines Lab has shown that deterministic inference can enforce bitwise-identical outputs for a given prompt, effectively positioning it as a prerequisite for reproducibility, on-policy RL, and enterprise reliability. However, this paper argues that deterministic inference kills the ability to model uncertainty, makes emergent abilities vanish, disrupts reasoning abilities, and renders safety alignment brittle. Instead, the authors advocate for Stochastic CHAOS and claim that distributional variability is the heart of artificial cognition. The paper introduces three distinct stability goals for LLM inference: bitwise determinism, distributional reproducibility, and semantic stability. Empirically, it shows that deterministic inference is systematically misleading in four ways."""
2601.07245v1_Learning to Trust the Crowd A Multi-Model Consensu.pdf,Learning to Trust the Crowd: A Multi-Model Consensus Reasoning Engine for Large Language Models,['Pranav Kallem'],,12.6,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Learning to Trust the Crowd: A Multi-Model || Consensus Reasoning Engine for Large Language || Models || Pranav Kallem || Department of Computer Science || The University of Texas at Austin || Austin, TX, USA || AbstractLarge language models (LLMs) achieve strong aver- || age performance yet remain unrelia ... (truncated) ||  || { || ""title"": ""Learning to Trust the Crowd: A Multi-Model Consensus Reasoning Engine for Large Language Models"", || ""authors"": [""Pranav Kallem""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""large language models"", ""multi-model consensus"", ""reliability"", ""supervised meta-learner"", ""gradient-boosted trees"", ""listwise ranking"", ""graph neural networks"", ""GSM8K"", ""ARC-Challenge"", ""HellaSwag"", ""TruthfulQA""], || ""summary"": ""This paper studies the reliability of large language models (LLMs) through the lens of multi-model consensus. Given responses from several heterogeneous LLMs, the system learns which answer is most likely correct for a given query. The Multi-Model Consensus Reasoning Engine treats the set of LLM outputs as input to a supervised meta-learner. It maps natural language responses into structured features using semantic embeddings, pairwise similarity and clustering statistics, lexical and structural cues, reasoning-quality scores, confidence estimates, and model-specific priors. The system then applies gradient-boosted trees, listwise ranking, and graph neural networks over similarity graphs of answers. Using three open-weight LLMs evaluated on compact, resource-constrained subsets of GSM8K, ARC-Challenge, HellaSwag, and TruthfulQA, the best graph-attention-based consensus model improves macro-average accuracy by 4.6 percentage points over the strongest single LLM and by 8.1 points over majority vote, while also yielding lower Brier scores and fewer TruthfulQA hallucinations. Ablation and feature-importance analyses show that semantic agreement and clustering features are most influential, with reasoning-quality and model-prior features providing complementary gains, suggesting supervised multi-model consensus is a practical route toward more reliable LLM behavior, even in a modest single-machine setup."" || } ||  || [ Prompt: 33.6 t/s | Generation: 12.6 t/s ]"
2601.07250v1_DDT A Dual-Masking Dual-Expert Transformer for Ene.pdf,DDT: A Dual-Masking Dual-Expert Transformer for Energy Time-Series Forecasting,"['Mingnan Zhu', 'Qixuan Zhang', 'Yixuan Cheng', 'Fangzhou Gu', 'Shiming Lin']",,12.6,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || DDT: A Dual-Masking Dual-Expert Transformer || for Energy Time-Series Forecasting || Mingnan Zhu 1, Qixuan Zhang 1, Yixuan Cheng 1, Fangzhou Gu 1, and Shiming Lin 1, 2, 3 || 1School of Informatics (National Characteristic Demonstration Software School), Xiamen University, Xiamen, || China || 2Ke ... (truncated) ||  || { ""title"": ""DDT: A Dual-Masking Dual-Expert Transformer for Energy Time-Series Forecasting"", ""authors"": [""Mingnan Zhu"", ""Qixuan Zhang"", ""Yixuan Cheng"", ""Fangzhou Gu"", ""Shiming Lin""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Time-Series Forecasting"", ""Multivariate Temporal Modeling"", ""Dynamic-Causal Masking"", ""Adaptive Feature Fusion""], ""summary"": ""Accurate energy time-series forecasting is crucial for ensuring grid stability and promoting the integration of renewable energy. DDT, a novel and robust deep learning framework, introduces a dual-masking mechanism and a dual-expert system to address the challenges of complex temporal dependencies and multi-source data heterogeneity. Extensive experiments on 7 challenging energy benchmark datasets demonstrate that DDT consistently outperforms strong state-of-the-art baselines across all prediction horizons, establishing a new benchmark for the task."" } ||  || [ Prompt: 37.9 t/s | Generation: 12.6 t/s ]"
2601.07261v1_Pseudodata-guided Invariant Representation Learnin.pdf,Pseudodata-guided Invariant Representation Learning Boosts the Out-of-Distribution Generalization in Enzymatic Kinetic Parameter Prediction,"['Haomin Wu', 'Zhiwei Nie', 'Hongyu Zhang', 'Zhixiang Ren']",,15.4,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Pseudodata-guided Invariant Representation || Learning Boosts the Out-of-Distribution || Generalization in Enzymatic Kinetic Parameter || Prediction || Haomin Wu1,2, Zhiwei Nie 3*, Hongyu Zhang 3, Zhixiang Ren 2* || 1Pengcheng Laboratory, Shenzhen, China. || 2Southern University of Science and Techno ... (truncated) ||  || { ""title"": ""Pseudodata-guided Invariant Representation Learning Boosts the Out-of-Distribution Generalization in Enzymatic Kinetic Parameter Prediction"", ""authors"": [""Haomin Wu"", ""Zhiwei Nie"", ""Hongyu Zhang"", ""Zhixiang Ren""], ""doi"": """", ""arxiv_id"": ""2601.07261"", ""keywords"": [""enzyme kinetics"", ""deep learning"", ""invariant representation"", ""out-of-distribution generalization""], ""summary"": ""This paper proposes O 2DENet, a lightweight module that enhances out-of-distribution generalization by introducing enzyme-substrate perturbations and enforcing consistency between original and augmented representations. When integrated with representative ESI models, O 2DENet consistently improves predictive performance for both kcat and Km across stringent sequence-identity-based OOD benchmarks, achieving state-of-the-art results in terms of accuracy and robustness metrics. Overall, O2DENet provides a general and effective strategy to enhance the stability and deployability of data-driven enzyme kinetics predictors for real-world enzyme engineering applications."" } ||  || [ Prompt: 41.5 t/s | Generation: 15.4 t/s ]"
2601.07263v1_When Bots Take the Bait Exposing and Mitigating th.pdf,When Bots Take the Bait: Exposing and Mitigating the Emerging Social Engineering Attack in Web Automation Agent,"['Xinyi Wu', 'Geng Hong', 'Yueyue Chen', 'MingXuan Liu', 'Feier Jin', 'Xudong Pan', 'Jiarun Dai', 'Baojun Liu']",,5.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || When Bots Take the Bait: Exposing and Mitigating the Emerging Social Engineering || Attack in Web Automation Agent || Xinyi Wu, Geng Hong B, Yueyue Chen, MingXuan Liu , Feier Jin , Xudong Pan , || Jiarun Dai , and Baojun Liu || Fudan University,  Zhongguancun Laboratory, Shanghai Innovation In ... (truncated) ||  || ```json || { || ""title"": ""When Bots Take the Bait: Exposing and Mitigating the Emerging Social Engineering Attack in Web Automation Agent"", || ""authors"": [""Xinyi Wu"", ""Geng Hong"", ""Yueyue Chen"", ""MingXuan Liu"", ""Feier Jin"", ""Xudong Pan"", ""Jiarun Dai"", ""Baojun Liu""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""web automation"", ""social engineering"", ""web agents"", ""large language models"", ""open-source frameworks""], || ""summary"": ""Web agents, powered by large language models (LLMs), are increasingly deployed to automate complex web interactions. The rise of open-source frameworks (e.g., Browser Use, Skyvern-AI) has accelerated adoption but also broadened the attack surface. While prior research has focused on model threats such as prompt injection and backdoors, the risks of social engineering remain largely unexplored. This paper presents the first systematic study of social engineering attacks against web automation agents and designs a pluggable runtime mitigation solution. On the attack side, the AGENTBAIT paradigm exploits intrinsic weaknesses in agent execution, while on the defense side, SUPERVISOR is proposed as a lightweight runtime module to enforce environment and intention consistency alignment. Empirical results show that mainstream frameworks are highly vulnerable to AGENTBAIT, with an average attack success rate of 67.5% and peaks above 80% under specific strategies. Compared with existing lightweight defenses, our module can be seamlessly integrated across different frameworks and reduces attack success rates by up to 78.1% while incurring only a 7.7% runtime overhead and preserving usability. This work reveals AGENTBAIT as a critical new threat surface for web agents and establishes a practical, generalizable defense, advancing the security of this rapidly emerging ecosystem."" || } ||  ||  || [ Prompt: 33.7 t/s | Generation: 5.1 t/s ]"
2601.07291v1_A Visual Semantic Adaptive Watermark grounded by P.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A Visual Semantic Adaptive Watermark grounded by Prefix-Tuning for Large || Vision-Language Model || Qi Zheng1,2,Shuliang Liu 1,2,Yu Huang 1,2,Sihang Jia 1,2,Jungang Li 1,2,Lyuhao Chen 3 || Junhao Chen1,2,Hanqian Li 1,2,Aiwei Liu 1,2,Yibo Yan 1,2,Xuming Hu 1,2 || 1 The Hong Kong University of S ... (truncated) ||  || ```json || { || ""title"": ""A Visual Semantic Adaptive Watermark grounded by Prefix-Tuning for Large Vision-Language Model"", || ""authors"": [""Qi Zheng"", ""Shuliang Liu"", ""Yu Huang"", ""Sihang Jia"", ""Jungang Li"", ""Lyuhao Chen"", ""Junhao Chen"", ""Hanqian Li"", ""Aiwei Liu"", ""Yibo Yan"", ""Xuming Hu""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Watermarking"", ""Large Vision-Language Models"", ""Prefix-Tuning"", ""Visual Semantic"", ""Adaptive Watermark"", ""Semantic Awareness""], || ""summary"": ""Watermarking has emerged as a pivotal solution for content traceability and intellectual property protection in Large Vision-Language Models (LVLMs). However, vision-agnostic watermarks introduce visually irrelevant tokens and disrupt visual grounding by enforcing indiscriminate pseudo-random biases, while some semantic-aware methods incur prohibitive inference latency due to rejection sampling. This paper proposes the Visual Semantic Adaptive Watermark (VISA-Mark), a novel framework that embeds detectable signals while strictly preserving visual fidelity. Our approach employs a lightweight, efficiently trained prefix-tuner to extract dynamic Visual Evidence Weights, which guide an adaptive vocabulary partitioning and logits perturbation mechanism, concentrating watermark strength specifically on visually-supported tokens. By actively aligning the watermark with visual evidence, VISA-Mark effectively maintains visual fidelity. Empirical results confirm that VISA-Mark outperforms conventional methods with a 7.8% improvement in visual consistency (Chair-I) and superior semantic fidelity. The framework maintains highly competitive detection accuracy (96.88% AUC) and robust attack resilience (99.3%) without sacrificing inference efficiency, effectively establishing a new standard for reliability-preserving multimodal watermarking."""
2601.07292v1_Photometric Redshift Estimation Using Scaled Ensem.pdf,Photometric Redshift Estimation Using Scaled Ensemble Learning,"['Swagata Biswas', 'Shubhrangshu Ghosh', 'Avyarthana Ghosh', 'Yogesh Wadadekar', 'Abhishek Roy Choudhury', 'Arijit Mukherjee', 'Shailesh Deshpande', 'Arpan Pal']",,12.3,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Photometric Redshift Estimation Using Scaled Ensemble Learning || Swagata Biswas || 1 || aa , Shubhrangshu Ghosh || 1 || aa , Avyarthana Ghosh || 1 || aa , Yogesh Wadadekar || 2 || aa , Abhishek Roy Choudhury || 1 || , || Arijit Mukherjee || 1 || aa , Shailesh Deshpande || 3 || aa , and Arpan Pal || 1 || aa || 1 || TCS Research, IIT Kharagpu ... (truncated) ||  || ```json || { || ""title"": ""Photometric Redshift Estimation Using Scaled Ensemble Learning"", || ""authors"": [""Swagata Biswas"", ""Shubhrangshu Ghosh"", ""Avyarthana Ghosh"", ""Yogesh Wadadekar"", ""Abhishek Roy Choudhury"", ""Arijit Mukherjee"", ""Shailesh Deshpande"", ""Arpan Pal""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Photometric redshift"", ""Machine learning"", ""Ensemble learning"", ""Optical photometry"", ""Faint galaxies"", ""High-redshift galaxies"", ""Neural networks""], || ""summary"": ""The study presents a new ensemble-based ML framework aimed at predicting photometric redshifts (Pz) for faint galaxies and higher redshift ranges, relying solely on optical (grizy) photometric data. The proposed architecture integrates several learning algorithms, including gradient boosting machine, extreme gradient boosting, k-nearest neighbors, and artificial neural networks, within a scaled ensemble structure. By using bagged input data, the ensemble approach delivers improved predictive performance compared to stand-alone models. The framework demonstrates consistent accuracy in estimating redshifts, maintaining strong performance up to z 4. The model is validated using publicly available data from the Hyper Suprime-Cam Strategic Survey Program by the Subaru Telescope. Our results show marked improvements in the precision and reliability of Pz estimation."" || } ||  ||  || [ Prompt: 33.7 t/s | Generation: 12.3 t/s ]"
2601.07296v1_LRAS Advanced Legal Reasoning with Agentic Search.pdf,LRAS: Advanced Legal Reasoning with Agentic Search,"['Yujin Zhou', 'Chuxue Cao', 'Jinluan Yang', 'Lijun Wu', 'Conghui He', 'Sirui Han', 'Yike Guo']",,12.3,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LRAS: Advanced Legal Reasoning with Agentic Search || Yujin Zhou1, Chuxue Cao1,2, Jinluan Yang || Lijun Wu2,Conghui He 2,Sirui Han 1,Yike Guo 1 || 1Hong Kong University of Science and Technology || 2Shanghai Artificial Intelligence Laboratory || yzhouha@connect.ust.hk || Abstract || While Large Reasonin ... (truncated) ||  || ```json || { || ""title"": ""LRAS: Advanced Legal Reasoning with Agentic Search"", || ""authors"": [""Yujin Zhou"", ""Chuxue Cao"", ""Jinluan Yang"", ""Lijun Wu"", ""Conghui He"", ""Sirui Han"", ""Yike Guo""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Legal Reasoning"", ""Agentic Search"", ""Introspective Imitation Learning"", ""Difficulty-aware Reinforcement Learning""], || ""summary"": ""This paper presents LRAS, a framework designed to transition legal LLMs from static and parametric 'closed-loop thinking' to dynamic and interactive 'Active Inquiry'. By integrating Introspective Imitation Learning and Difficulty-aware Reinforcement Learning, LRAS enables LRMs to identify knowledge boundaries and handle legal reasoning complexity. Empirical results demonstrate that LRAS outperforms state-of-the-art baselines by 8.2-32%, with the most substantial gains observed in tasks requiring deep reasoning with reliable knowledge. The authors will release their data and models for further exploration soon."" || } ||  ||  || [ Prompt: 33.2 t/s | Generation: 12.3 t/s ]"
2601.07304v1_Heterogeneous Multi-Expert Reinforcement Learning .pdf,Heterogeneous Multi-Expert Reinforcement Learning for Long-Horizon Multi-Goal Tasks in Autonomous Forklifts,"['Yun Chen', 'Bowei Huang', 'Fan Guo', 'Kang Song']",,5.2,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || Heterogeneous Multi-Expert Reinforcement || Learning for Long-Horizon Multi-Goal Tasks in || Autonomous Forklifts || Yun Chen, Bowei Huang, Fan Guo, Kang Song || AbstractAutonomous mobile manipulation in unstructured || warehouses requires a balance between efficient large-scale nav- || igation and ... (truncated) ||  || { ""title"": ""Heterogeneous Multi-Expert Reinforcement Learning for Long-Horizon Multi-Goal Tasks in Autonomous Forklifts"", ""authors"": [""Yun Chen"", ""Bowei Huang"", ""Fan Guo"", ""Kang Song""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Autonomous Forklift"", ""Hierarchical Reinforcement Learning"", ""Mobile Manipulation"", ""Hybrid Training"", ""Modality Decoupling""], ""summary"": ""This work proposes a Heterogeneous Multi-Expert Reinforcement Learning (HMER) framework tailored for autonomous forklifts. HMER decomposes long-horizon tasks into specialized sub-policies controlled by a Semantic Task Planner, separating macro-level navigation from micro-level manipulation. A Hybrid Imitation-Reinforcement Training Strategy is introduced to solve the problem of sparse exploration. Experiments in Gazebo simulations show that HMER significantly outperforms sequential and end-to-end baselines, achieving a task success rate of 94.2%, reducing operation time by 21.4%, and maintaining placement error within 1.5 cm. This method validates its efficacy for precise material handling in unstructured environments."" } ||  || [ Prompt: 38.1 t/s | Generation: 5.2 t/s ]"
2601.07309v1_ARM Role-Conditioned Neuron Transplantation for Tr.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ARM: Role-Conditioned Neuron Transplantation for || Training-Free Generalist LLM Agent Merging || Zhuoka Feng1*, Kang Chen1*, Sihan Zhao1**, Kai Xiong**, Yaoning Wang1** || Minshen Yu1, Junjie Nian1, Changyi Xiao1, Yixin Cao1,2, Yugang Jiang1 || 1Fudan University,2Shanghai Innovation Institute || ... (truncated) ||  || { || ""title"": ""ARM: Role-Conditioned Neuron Transplantation for Training-Free Generalist LLM Agent Merging"", || ""authors"": [""Zhuoka Feng"", ""Kang Chen"", ""Sihan Zhao"", ""Kai Xiong"", ""Yaoning Wang"", ""Minshen Yu"", ""Junjie Nian"", ""Changyi Xiao"", ""Yixin Cao"", ""Yugang Jiang""], || ""doi"": """", || ""arxiv_id"": ""2601.07309"", || ""keywords"": [""model merging"", ""large language models"", ""agent merging"", ""neuron transplantation"", ""cross-environment robustness""], || ""summary"": ""Interactive large language model agents have advanced rapidly, but most remain specialized to a single environment and fail to adapt robustly to other environments. Model merging offers a training-free alternative by integrating multiple experts into a single model. In this paper, we propose Agent-Role Merging (ARM), an activation-guided, role-conditioned neuron transplantation method for model merging in LLM agents. ARM improves existing merging methods from static natural language tasks to multi-turn agent scenarios, and over the generalization ability across various interactive environments. This is achieved with a well-designed 3-step framework: constructing merged backbones, selection based on role-conditioned activation analysis, and neuron transplantation for fine-grained refinements. Without gradient-based optimization, ARM improves cross-benchmark generalization while enjoying efficiency. Across diverse domains, the model obtained via ARM merging outperforms prior model merging methods and domain-specific expert models, while demonstrating strong out-of-domain generalization."""
2601.07313v1_Explaining Machine Learning Predictive Models thro.pdf,Explaining Machine Learning Predictive Models through Conditional Expectation Methods,"['Silvia Ruiz-Espa naa', 'Laura Arnal a', 'Fran cois Signola', 'Juan-Carlos Perez-Cortes a', 'Joaquim Arlandis a']",,13.5,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Explaining Machine Learning Predictive Models through Conditional || Expectation Methods || Silvia Ruiz-Espa naa,, Laura Arnal a,, Fran cois Signola, Juan-Carlos Perez-Cortes a, Joaquim Arlandis a || aITI, Universitat Polit` ecnica de Val` encia, Camino de Vera, s/n, 46022 Val` encia, Spain || ... (truncated) ||  || ```json || { || ""title"": ""Explaining Machine Learning Predictive Models through Conditional Expectation Methods"", || ""authors"": [""Silvia Ruiz-Espa naa"", ""Laura Arnal a"", ""Fran cois Signola"", ""Juan-Carlos Perez-Cortes a"", ""Joaquim Arlandis a""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""machine learning"", ""XAI"", ""explainable models"", ""local explainability"", ""model-agnostic"", ""uncertainty"", ""stability""], || ""summary"": ""The rapid adoption of complex artificial intelligence (AI) and machine learning (ML) models has led to their characterization as black boxes due to the difficulty of explaining their internal decision-making processes. This lack of transparency hinders users ability to understand, validate and trust model behavior, particularly in high-risk applications. Although explainable AI (XAI) has made significant progress, there remains a need for versatile and effective techniques to address increasingly complex models. This work introduces Multivariate Conditional Expectation (MUCE), a model-agnostic method for local explainability designed to capture prediction changes from feature interactions. MUCE extends Individual Conditional Expectation (ICE) by exploring a multivariate grid of values in the neighborhood of a given observation at inference time, providing graphical explanations that illustrate the local evolution of model predictions. In addition, two quantitative indices, stability and uncertainty, summarize local behavior and assess model reliability. Uncertainty is further decomposed into uncertainty + and uncertainty to capture asymmetric effects that global measures may overlook. The proposed method is validated using XGBoost models trained on three datasets: two synthetic (2D and 3D) to evaluate behavior near decision boundaries, and one transformed real-world dataset to test adaptability to heterogeneous feature types. Results show that MUCE effectively captures complex local model behavior, while the stability and uncertainty indices provide meaningful insight into prediction confidence. MUCE, together with the ICE modification and the proposed indices, offers a practical contribution to local explainability, enabling both graphical and quantitative insights that enhance the interpretability of predictive models and support more trustworthy and transparent decision-making."" || } ||  ||  || [ Prompt: 35.5 t/s | Generation: 13.5 t/s ]"
2601.07315v1_VLM-CAD VLM-Optimized Collaborative Agent Design W.pdf,VLM-CAD:VLM-OptimizedCollaborativeAgent,"['1st Guanyuan Pan', '2nd Yugui Lin', '3rd Tiansheng Zhou', '4th Pietro Li `o', '5th Shuai Wang', '6th Yaqi Wang*']",,11.6,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || VLM-CAD:VLM-OptimizedCollaborativeAgent || Design Workflow for Analog Circuit Sizing || 1st Guanyuan Pan || Hangzhou Dianzi University || Hangzhou, China || guanyuanpeterpan@gmail.com || 2nd Yugui Lin || SCBC, Guangdong University of Foreign Studies || Guangzhou, China || yuguilin0209@163.com || 3rd Tiansheng Zh ... (truncated) ||  || { || ""title"": ""VLM-CAD:VLM-OptimizedCollaborativeAgent"", || ""authors"": [""1st Guanyuan Pan"", ""2nd Yugui Lin"", ""3rd Tiansheng Zhou"", ""4th Pietro Li `o"", ""5th Shuai Wang"", ""6th Yaqi Wang*""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Analog Circuit Sizing"", ""Agentic AI"", ""Vision Language Model"", ""Explainability"", ""Electronic Design Automation""], || ""summary"": ""Analog mixed-signal circuit sizing involves complex trade-offs within high-dimensional design spaces. Existing automatic analog circuit sizing approaches often underutilize circuit schematics and lack the explainability required for industry adoption. To tackle these challenges, we propose a Vision Language Model-optimized collaborative agent design workflow (VLM-CAD), which analyzes circuits, optimizes DC operating points, performs inference-based sizing and executes external sizing optimization. We integrate Image2Net to annotate circuit schematics and generate a structured JSON description for precise interpretation by Vision Language Models. Furthermore, we propose an Explainable Trust Region Bayesian Optimization method (ExTuRBO) that employs collaborative warm-starting from agent-generated seeds and offers dual-granularity sensitivity analysis for external sizing optimization, supporting a comprehensive final design report. Experiment results on amplifier sizing tasks using 180nm, 90nm, and 45nm Predictive Technology Models demonstrate that VLM-CAD effectively balances power and performance, achieving a 100% success rate in optimizing an amplifier with a complementary input and a class-AB output stage, while maintaining total runtime under 43 minutes across all experiments."" || } ||  || [ Prompt: 39.8 t/s | Generation: 11.6 t/s ]"
2601.07316v1_BEAT-Net Injecting Biomimetic Spatio-Temporal Prio.pdf,BEAT-Net: Injecting Biomimetic Spatio-Temporal Priors for Interpretable ECG Classification,"['Ma Runze', 'Liao Caizhi']",,7.2,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || BEAT-Net: Injecting Biomimetic Spatio-Temporal || Priors for Interpretable ECG Classification || Ma Runze || School of Information Technology || Monash University Malaysia || rmaa0033@student.monash.edu || Liao Caizhi || Faculty of Biomedical Engineering || Shenzhen University of Advanced Technology || liaoc ... (truncated) ||  || { ""title"": ""BEAT-Net: Injecting Biomimetic Spatio-Temporal Priors for Interpretable ECG Classification"", ""authors"": [""Ma Runze"", ""Liao Caizhi""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""BEAT-Net"", ""ECG Classification"", ""Biomimetic Spatio-Temporal Priors"", ""Interpretability"", ""Robustness"", ""Data Efficiency"", ""Attention Mechanisms""], ""summary"": ""Despite advancements in deep learning for automated ECG diagnosis, prevalent supervised methods treat ECG recordings as undifferentiated 1D or 2D signals. This approach forces models to implicitly learn physiological structures, leading to inefficiency and opacity. BEAT-Net reformulates the problem as a language modeling task, using QRS tokenization to transform continuous signals into biologically aligned heartbeat sequences. The architecture explicitly decomposes cardiac physiology through specialized encoders that extract local beat morphology while normalizing spatial lead perspectives and modeling temporal rhythm dependencies. Evaluations across three large-scale benchmarks show that BEAT-Net matches the diagnostic accuracy of dominant CNN architectures while improving robustness. The framework exhibits exceptional data efficiency, using only 30-35% of annotated data. Learned attention mechanisms provide inherent interpretability without explicit supervision, spontaneously reproducing clinical heuristics like Lead II prioritization for rhythm analysis."" } ||  || [ Prompt: 35.6 t/s | Generation: 7.2 t/s ]"
2601.07320v1_Segmental Advantage Estimation Enhancing PPO for L.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 2026-01-13 || Segmental Advantage Estimation: Enhancing PPO for Long-Context LLM || Training || Xue Gong1, , Qi Yi1,, Ziyuan Nan2,4, Guanhua Huang1, Kejiao Li1, Yuhao Jiang1, || Ruibin Xiong1, Zenan Xu1, Jiaming Guo4, Shaohui Peng 2,3, Bo Zhou1 || 1LLM Department, Tencent 2 University of Chinese A ... (truncated) ||  || ```json || { || ""title"": ""Segmental Advantage Estimation: Enhancing PPO for Long-Context LLM Training"", || ""authors"": [""Xue Gong"", ""Qi Yi"", ""Ziyuan Nan"", ""Guanhua Huang"", ""Kejiao Li"", ""Yuhao Jiang"", ""Ruibin Xiong"", ""Zenan Xu"", ""Jiaming Guo"", ""Shaohui Peng"", ""Bo Zhou""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Large Language Models"", ""Reinforcement Learning with Verifiable Rewards"", ""Proximal Policy Optimization"", ""Segmental Advantage Estimation"", ""Advantage Estimation"", ""Long-Context""], || ""summary"": ""Training Large Language Models (LLMs) for reasoning tasks is increasingly driven by Reinforcement Learning with Verifiable Rewards (RLVR), where Proximal Policy Optimization (PPO) provides a principled framework for stable policy updates. However, the practical application of PPO is hindered by unreliable advantage estimation in the sparse-reward RLVR regime. This issue arises because the sparse rewards in RLVR lead to inaccurate intermediate value predictions, which in turn introduce significant bias when aggregated at every token by Generalized Advantage Estimation (GAE). To address this, we introduce Segmental Advantage Estimation (SAE), which mitigates the bias that GAE can incur in RLVR. Our key insight is that aggregating n-step advantages at every token (as in GAE) is unnecessary and often introduces excessive bias, since individual tokens carry minimal information. Instead, SAE first partitions the generated sequence into coherent sub-segments using low-probability tokens as heuristic boundaries. It then selectively computes variance-reduced advantage estimates only from these information-rich segment transitions, effectively filtering out noise from intermediate tokens. Our experiments demonstrate that SAE achieves superior performance, with marked improvements in final scores, training stability, and sample efficiency. These gains are shown to be consistent across multiple model sizes, and a correlation analysis confirms that our proposed advantage estimator achieves a higher correlation with an approximate ground-truth advantage, justifying its superior performance."""
2601.07342v1_Agentic Diagnostic Reasoning over Telecom and Data.pdf,Agentic Diagnostic Reasoning over Telecom and Datacenter Infrastructure,['Nicolas Tacheny'],,13.6,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Agentic Diagnostic Reasoning over Telecom and || Datacenter Infrastructure || Foundation for Autonomous Incident Resolution and Change Impact || Mitigation || Nicolas Tacheny || Ni2 Innovation Lab || nicolas.tacheny@ni2.com || Abstract || Large-scale telecom and datacenter infrastructures rely on multi-lay ... (truncated) ||  || { || ""title"": ""Agentic Diagnostic Reasoning over Telecom and Datacenter Infrastructure"", || ""authors"": [""Nicolas Tacheny""], || ""doi"": """", || ""arxiv_id"": ""2601.07342"", || ""keywords"": [""Large Language Model"", ""Telecom Infrastructure"", ""Datacenter Infrastructure"", ""Root Cause Analysis"", ""Impact Analysis"", ""Autonomous Incident Resolution"", ""Change Impact Mitigation""], || ""summary"": ""This work introduces an agentic diagnostic framework where a Large Language Model (LLM) performs step-wise investigation using a constrained tool-space exposed through the Model Context Protocol (MCP). The agent autonomously navigates the infrastructure model by invoking tools for service lookup, dependency retrieval, structured and unstructured data, and event analysis, and impact discovery. The investigation protocol structures the agent's reasoning and ensures grounding, reproducibility, and safe handling of missing or ambiguous information. This work lays the foundation for autonomous incident resolution and change impact mitigation, enabling operators to predict the impact of planned changes on services and customers before executing maintenance operations."" || } ||  || [ Prompt: 28.8 t/s | Generation: 13.6 t/s ]"
2601.07344v1_PulseMind A Multi-Modal Medical Model for Real-Wor.pdf,,[],,11.4,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || PulseMind: A Multi-Modal Medical Model for Real-World Clinical Diagnosis || Jiao Xu1,2*, Junwei Liu 2,3*, Jiangwei Lao 2, Qi Zhu 2, Yunpeng Zhao4, Congyun Jin 2, Shinan Liu 4, || Zhihong Lu2, Lihe Zhang 1, Xin Chen 5, Jian Wang2, Ping Wang3 || 1 Dalian University of Technology || 2 Ant Group || 3  ... (truncated) ||  || Based on the information provided in the abstract and the context of the question, there is no specific mention of an image of a left-pararenal mass or its imaging modality. The abstract discusses a multi-modal diagnostic model called PulseMind, but does not provide details about a specific image or its modality. ||  || Given the options provided: ||  || A. Magnetic resonance imaging || B. X-ray || C. Computed tomography || D. Positron emission tomography ||  || Without additional context, it's impossible to determine the correct answer. The question seems to be asking about a specific image not mentioned in the provided text. ||  || If this is a hypothetical scenario or a test question, the correct answer would need to be inferred from the context or additional information. However, based on the options provided, none of them are directly linked to the left-pararenal mass in the given text. ||  || Therefore, the answer cannot be definitively determined from the information provided. ||  || [ Prompt: 33.8 t/s | Generation: 11.4 t/s ]"
2601.07348v4_Controlled Self-Evolution for Algorithmic Code Opt.pdf,Controlled Self-Evolution for Algorithmic Code Optimization,"['Tu Hu', 'Ronghao Chen', 'Shuo Zhang', 'Jianghao Yin', 'Mou Xiao Feng', 'Jingping Liu', 'Shaolei Zhang', 'Wenqi Jiang', 'Yuqi Fang', 'Sen Hu', 'Huacan Wang', 'Yi Xu']",,13.3,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 2026-01-16 || Controlled Self-Evolution for Algorithmic Code Optimization || Tu Hu1*, Ronghao Chen2,7*, Shuo Zhang3*, Jianghao Yin4, Mou Xiao Feng3, Jingping Liu5, || Shaolei Zhang6,Wenqi Jiang 1,Yuqi Fang 1,Sen Hu 2,7,Huacan Wang 3,Yi Xu 3 || 1NJU, 2PKU, 3Midea-AIRC, 4ECNU, 5SYSU, 6RUC, 7Quant ... (truncated) ||  || { ""title"": ""Controlled Self-Evolution for Algorithmic Code Optimization"", ""authors"": [""Tu Hu"", ""Ronghao Chen"", ""Shuo Zhang"", ""Jianghao Yin"", ""Mou Xiao Feng"", ""Jingping Liu"", ""Shaolei Zhang"", ""Wenqi Jiang"", ""Yuqi Fang"", ""Sen Hu"", ""Huacan Wang"", ""Yi Xu""], ""doi"": """", ""arxiv_id"": ""2601.07348"", ""keywords"": [""Controlled Self-Evolution"", ""Algorithmic Code Optimization"", ""Self-evolution"", ""Code Generation"", ""Efficiency Improvement""], ""summary"": ""Self-evolution methods enhance code generation through iterative generate-verify-refine cycles, but existing approaches suffer from low exploration efficiency. Controlled Self-Evolution (CSE) addresses these issues by introducing diversified planning initialization, genetic evolution with feedback-guided mechanisms, and hierarchical evolution memory. Experiments on EffiBench-X show that CSE consistently outperforms baselines across various LLM backbones, achieving higher efficiency from early generations and continuous improvement throughout evolution. The code is publicly available at https://github.com/QuantaAlpha/EvoControl."" } ||  || [ Prompt: 37.4 t/s | Generation: 13.3 t/s ]"
2601.07351v2_Beyond Hard Masks Progressive Token Evolution for .pdf,Beyond Hard Masks: Progressive Token Evolution for Diffusion Language Models,"['Linhao Zhong1*', 'Linyu Wu2*', 'Bozhen Fang1', 'Tianjian Feng1', 'Chenchen Jing1,3', 'Wen Wang1', 'Jiaheng Zhang2', 'Hao Chen1', 'Chunhua Shen1,3']",,5.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Beyond Hard Masks: Progressive Token Evolution for || Diffusion Language Models || Linhao Zhong1* Linyu Wu2* Bozhen Fang1 Tianjian Feng1 Chenchen Jing1,3 || Wen Wang1 Jiaheng Zhang2 Hao Chen1 Chunhua Shen1,3 || 1Zhejiang University 2National University of Singapore 3Zhejiang University of Techn ... (truncated) ||  || { ""title"": ""Beyond Hard Masks: Progressive Token Evolution for Diffusion Language Models"", ""authors"": [""Linhao Zhong1*"", ""Linyu Wu2*"", ""Bozhen Fang1"", ""Tianjian Feng1"", ""Chenchen Jing1,3"", ""Wen Wang1"", ""Jiaheng Zhang2"", ""Hao Chen1"", ""Chunhua Shen1,3""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Diffusion Language Models"", ""EvoToken-DLM"", ""Progressive Token Evolution"", ""Masked Diffusion Language Models"", ""Parallel Decoding"", ""Revisable Decoding""], ""summary"": ""Diffusion Language Models (DLMs) offer a promising alternative for language modeling by enabling parallel decoding through iterative refinement. However, most DLMs rely on hard binary masking and discrete token assignments, which hinder the revision of early decisions and underutilize intermediate probabilistic representations. This paper proposes EvoToken-DLM, a novel diffusion-based language modeling approach that replaces hard binary masks with evolving soft token distributions. EvoToken-DLM enables a progressive transition from masked states to discrete outputs, supporting revisable decoding. Continuous trajectory supervision is introduced to effectively support this evolution, aligning training objectives with iterative probabilistic updates. Extensive experiments across multiple benchmarks show that EvoToken-DLM consistently achieves superior performance, outperforming strong diffusion-based and masked DLM baselines."" } ||  || [ Prompt: 34.3 t/s | Generation: 5.1 t/s ]"
2601.07356v1_Efficient Convolutional Forward Model for Passive .pdf,Efficient Convolutional Forward Model for Passive Acoustic Mapping and Temporal Monitoring,"['Tatiana Gelvez-Barrera', 'Barbara Nicolas', 'Bruno Gilles', 'Adrian Basarab', 'Denis Kouamé']",,5.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 1 || Efficient Convolutional Forward Model for Passive || Acoustic Mapping and Temporal Monitoring || Tatiana Gelvez-Barrera, Barbara Nicolas, Bruno Gilles, Adrian Basarab, Denis Kouam e || AbstractPassive acoustic mapping (PAM) is a key ... (truncated) ||  || { || ""title"": ""Efficient Convolutional Forward Model for Passive Acoustic Mapping and Temporal Monitoring"", || ""authors"": [""Tatiana Gelvez-Barrera"", ""Barbara Nicolas"", ""Bruno Gilles"", ""Adrian Basarab"", ""Denis Kouamé""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Passive Acoustic Mapping"", ""Model-based beam-forming"", ""Convolutional forward model"", ""Temporal monitoring""], || ""summary"": ""Passive acoustic mapping (PAM) is a key imaging technique for characterizing cavitation activity in therapeutic ultrasound applications. Recent model-based beamforming algorithms offer high reconstruction quality and strong physical interpretability. However, their computational burden and limited temporal resolution restrict their use in applications with time-evolving cavitation. To address these challenges, we introduce a PAM beamforming framework based on a novel convolutional formulation in the time domain, which enables efficient computation. In this framework, PAM is formulated as an inverse problem in which the forward operator maps spatiotemporal cavitation activity to recorded radio-frequency signals accounting for time-of-flight delays defined by the acquisition geometry. We then formulate a regularized inversion algorithm that incorporates prior knowledge on cavitation activity. Experimental results demonstrate that our framework outperforms classical beamforming methods, providing higher temporal resolution than frequency-domain techniques while substantially reducing computational burden compared with iterative time-domain formulations."" || } ||  || [ Prompt: 13.7 t/s | Generation: 5.0 t/s ]"
2601.07359v1_Seeing Right but Saying Wrong Inter- and Intra-Lay.pdf,Seeing Right but Saying Wrong: Inter- and Intra-Layer Refinement in MLLMs without Training,"['Shezheng Song', 'Shasha Li', 'Jie Yu']",,12.5,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Seeing Right but Saying Wrong: Inter- and Intra-Layer Refinement in MLLMs || without Training || Shezheng Song, Shasha Li, Jie Yu || 1National University of Defense Technology || Abstract || Multimodal Large Language Models (MLLMs) have demon- || strated strong capabilities across a variety of vision ... (truncated) ||  || ```json || { || ""title"": ""Seeing Right but Saying Wrong: Inter- and Intra-Layer Refinement in MLLMs without Training"", || ""authors"": [""Shezheng Song"", ""Shasha Li"", ""Jie Yu""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Multimodal Large Language Models"", ""Vision-Language Tasks"", ""Internal Reasoning"", ""Attention Mechanism"", ""Decoding Refinement""], || ""summary"": ""Multimodal Large Language Models (MLLMs) have demonstrated strong capabilities across a variety of vision-language tasks. However, their internal reasoning often exhibits a critical inconsistency: although deeper layers may attend to the correct visual regions, final predictions are frequently misled by noisy attention from earlier layers. This results in a disconnect between what the model internally understands and what it ultimately expresses, a phenomenon we describe as seeing it right but saying it wrong. To address this issue, we propose DualPD, a dual-perspective decoding refinement strategy that enhances the models visual understanding without any additional training. DualPD consists of two components: a layer-wise attention-guided contrastive logits module and a head-wise information filtering module. Experiments conducted on both the LLaV A and Qwen-VL model families across multiple multimodal benchmarks demonstrate that DualPD consistently improves accuracy without training, confirming its effectiveness and generalizability."" || } ||  ||  || [ Prompt: 34.7 t/s | Generation: 12.5 t/s ]"
2601.07364v1_On the universal definition of intelligence.pdf,On the universal definition of intelligence,['Joseph Chen'],,15.6,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || On the universal definition of intelligence || A definition for Human - AI Comparison || Joseph Chen || University of Tokyo ||  ||  || Abstract || This paper aims to propose a universal definition of intelligence that enables fair and || consistent comparison of human and artificial intelligence ( ... (truncated) ||  || { ""title"": ""On the universal definition of intelligence"", ""authors"": [""Joseph Chen""], ""doi"": """", ""arxiv_id"": ""1911.09562"", ""keywords"": [""intelligence"", ""human"", ""AI"", ""comparison"", ""predictive ability"", ""spontaneous prediction"", ""reactive prediction"", ""gainability""], ""summary"": ""This paper proposes an extended predictive hypothesis (EPH) to define intelligence as a combination of accurate prediction and benefit from those predictions. It evaluates six representative definitions and introduces the EPH to unify explanations of intelligence aspects such as creativity, learning, and future planning. The EPH is argued to be the most satisfactory and universal definition for comparing human and AI intelligence."" } ||  || [ Prompt: 36.7 t/s | Generation: 15.6 t/s ]"
2601.07372v1_Conditional Memory via Scalable Lookup A New Axis .pdf,Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models,"['Xin Cheng', 'Wangding Zeng', 'Damai Dai', 'Qinyu Chen', 'Bingxuan Wang', 'Zhenda Xie', 'Kezhao Huang', 'Xingkai Yu', 'Zhewen Hao', 'Yukun Li', 'Han Zhang', 'Huishuai Zhang', 'Dongyan Zhao', 'Wenfeng Liang']",,11.2,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Conditional Memory via Scalable Lookup: || A New Axis of Sparsity for Large Language Models || Xin Cheng1,2, Wangding Zeng2, Damai Dai2, Qinyu Chen2, Bingxuan Wang2, || Zhenda Xie2, Kezhao Huang2, Xingkai Yu2, Zhewen Hao2, Yukun Li2, Han Zhang2, || Huishuai Zhang1, Dongyan Zhao1, Wenfeng Liang2 ... (truncated) ||  || ```json || { || ""title"": ""Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models"", || ""authors"": [""Xin Cheng"", ""Wangding Zeng"", ""Damai Dai"", ""Qinyu Chen"", ""Bingxuan Wang"", ""Zhenda Xie"", ""Kezhao Huang"", ""Xingkai Yu"", ""Zhewen Hao"", ""Yukun Li"", ""Han Zhang"", ""Huishuai Zhang"", ""Dongyan Zhao"", ""Wenfeng Liang""], || ""doi"": """", || ""arxiv_id"": ""2601.07372"", || ""keywords"": [""Conditional Memory"", ""Scalable Lookup"", ""Large Language Models"", ""Sparsity"", ""Mixture-of-Experts"", ""Engram"", ""Knowledge Lookup"", ""Neural Computation"", ""Static Memory""], || ""summary"": ""This paper introduces conditional memory as a new sparsity axis for large language models, instantiated via Engram. Engram modernizes classic -gram embedding for O(1) lookup, addressing the lack of a native primitive for knowledge lookup in Transformers. By formulating the Sparsity Allocation problem, we uncover a U-shaped scaling law that optimizes the trade-off between neural computation (MoE) and static memory (Engram). Guided by this law, Engram is scaled to 27B parameters, achieving superior performance over a strictly iso-parameter and iso-FLOPs MoE baseline. The memory module aids knowledge retrieval and general reasoning, with notable gains in complex domains. Mechanistic analyses reveal that Engram relieves the backbones from static reconstruction, effectively deepening the network for complex reasoning. By delegating local dependencies to lookups, it frees up attention capacity for global context, substantially boosting long-context retrieval. Finally, Engram establishes infrastructure-aware efficiency, enabling runtime prefetching from host memory with negligible overhead. The authors envision conditional memory as an indispensable modeling primitive for next-generation sparse models."" || } ||  ||  || [ Prompt: 33.5 t/s | Generation: 11.2 t/s ]"
2601.07376v1_OpenTinker Separating Concerns in Agentic Reinforc.pdf,OpenTinker: Separating Concerns in Agentic Reinforcement Learning,"['Siqi Zhu', 'Jiaxuan You']",,8.4,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || OpenTinker: Separating Concerns in Agentic || Reinforcement Learning || Siqi Zhu,Jiaxuan You || University of Illinois Urbana-Champaign || Abstract || We introduceOpenTinker, an infrastructure for reinforcement learning (RL) of large language || model (LLM) agents built around a separation of concern ... (truncated) ||  || ```json || { || ""title"": ""OpenTinker: Separating Concerns in Agentic Reinforcement Learning"", || ""authors"": [""Siqi Zhu"", ""Jiaxuan You""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""OpenTinker"", ""Reinforcement Learning"", ""Large Language Model"", ""Agentic Learning"", ""Separation of Concerns""], || ""summary"": ""We introduce OpenTinker, an infrastructure for reinforcement learning of large language model agents. It decomposes agentic learning systems into lightweight, composable components with clearly defined abstraction boundaries. Users specify agents, environments, and interaction protocols, while inference and training are delegated to a managed execution runtime. OpenTinker introduces a centralized scheduler for managing training and inference workloads over shared resources. We discuss design principles for extending OpenTinker to multi-agent training. Finally, we present a set of RL use cases demonstrating the effectiveness of the framework in practical agentic learning scenarios."" || } ||  ||  || [ Prompt: 34.9 t/s | Generation: 8.4 t/s ]"
2601.07377v1_Learning Dynamic Collaborative Network for Semi-su.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Learning Dynamic Collaborative Network for Semi-supervised 3D V essel || Segmentation || Jiao Xu1*, Xin Chen2*, Lihe Zhang1 || 1Dalian University of Technology 2City University of Hong Kong || xjmmcome@mail.dlut.edu.cn, xche32@cityu.edu.hk, zhanglihe@dlut.edu.cn || Abstract || In this paper, we prese ... (truncated) ||  || { || ""title"": ""Learning Dynamic Collaborative Network for Semi-supervised 3D Vessel Segmentation"", || ""authors"": [""Jiao Xu"", ""Xin Chen""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""3D vessel segmentation"", ""semi-supervised learning"", ""dynamic collaborative network"", ""adversarial supervision"", ""multi-view integration""], || ""summary"": ""This paper presents a new dynamic collaborative network (DiCo) for semi-supervised 3D vessel segmentation. Conventional mean teacher methods typically use a static approach, where the roles of the teacher and student models are fixed. However, due to the complexity of 3D vessel data, the teacher model may not always outperform the student model, leading to cognitive biases that can limit performance. To address this issue, we propose a dynamic collaborative network that allows the two models to dynamically switch their teacher-student roles. Additionally, we introduce a multi-view integration module to capture various perspectives of the inputs, mirroring the way doctors conduct medical analysis. We also incorporate adversarial supervision to constrain the shape of the segmented vessels in unlabeled data. In this process, the 3D volume is projected into 2D views to mitigate the impact of label inconsistencies. Experiments demonstrate that our DiCo method sets new state-of-the-art performance on three 3D vessel segmentation benchmarks."""
2601.07389v1_On the Non-decoupling of Supervised Fine-tuning an.pdf,On the Non-decoupling of Supervised Fine-tuning and Reinforcement Learning in Post-training,"['Xueyan Niuniuxueyan3@huawei.com', 'Bo Baibaibo8@huawei.com', 'Wei Hanharvey.hanwei@huawei.com', 'Weixi Zhangzhangweixi1@huawei.com']",,11.8,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || On the Non-decoupling of Supervised Fine-tuning and || Reinforcement Learning in Post-training || Xueyan Niuniuxueyan3@huawei.com || Theory Laboratory || Central Research Institute, 2012 Laboratories || Huawei Technologies Co., Ltd. || Bo Baibaibo8@huawei.com || W ei Hanharvey.hanwei@huawei.com || W eixi Z ... (truncated) ||  || ```json || { || ""title"": ""On the Non-decoupling of Supervised Fine-tuning and Reinforcement Learning in Post-training"", || ""authors"": [""Xueyan Niuniuxueyan3@huawei.com"", ""Bo Baibaibo8@huawei.com"", ""Wei Hanharvey.hanwei@huawei.com"", ""Weixi Zhangzhangweixi1@huawei.com""], || ""doi"": """", || ""arxiv_id"": ""2601.07389"", || ""keywords"": [""Supervised Fine-Tuning"", ""Reinforcement Learning"", ""Post-training"", ""Large Language Models"", ""Reasoning""], || ""summary"": ""Post-training of large language models often interleaves supervised fine-tuning (SFT) with reinforcement learning (RL). These two methods have different objectives: SFT minimizes cross-entropy loss between model outputs and expert responses, while RL maximizes reward signals derived from human preferences or rule-based verifiers. Modern reasoning models have widely adopted the practice of alternating SFT and RL training. However, there is no theoretical account of whether they can be decoupled. We prove that decoupling is impossible in either order: (1) SFT-then-RL coupling: RL increases SFT loss under SFT optimality and (2) RL-then-SFT coupling: SFT lowers the reward achieved by RL. Experiments on Qwen3-0.6B confirm the predicted degradation, verifying that SFT and RL cannot be separated without loss of prior performance in the post-training pipeline."" || } ||  ||  || [ Prompt: 27.5 t/s | Generation: 11.8 t/s ]"
2601.07392v1_OceanSAR-2 A Universal Feature Extractor for SAR O.pdf,OceanSAR-2: A Universal Feature Extractor for SAR Ocean Observation,"['Alexandre Tuela', 'Thomas Kerdreux', 'Quentin Febvre', 'Alexis Mouche', 'Antoine Grouazel', 'Jean-Renaud Miadana', 'Antoine Audras', 'Chen Wang', 'Bertrand Chapron']",,12.9,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || OceanSAR-2: A Universal Feature Extractor for SAR Ocean Observa- || tion || Alexandre Tuela, Thomas Kerdreux a, Quentin Febvre b, Alexis Mouche b, Antoine Grouazel b, Jean-Renaud Miadana c, || Antoine Audrasa, Chen Wangd, and Bertrand Chapronb || aGaleio, Paris, France || bLOPS, Ifremer, Plouzan,  ... (truncated) ||  || { ""title"": ""OceanSAR-2: A Universal Feature Extractor for SAR Ocean Observation"", ""authors"": [""Alexandre Tuela"", ""Thomas Kerdreux"", ""Quentin Febvre"", ""Alexis Mouche"", ""Antoine Grouazel"", ""Jean-Renaud Miadana"", ""Antoine Audras"", ""Chen Wang"", ""Bertrand Chapron""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""OceanSAR-2"", ""SAR"", ""Ocean Remote Sensing"", ""Self-Supervised Learning"", ""Foundation Model"", ""Sentinel-1"", ""Wave Mode"", ""Geophysical Pattern Classification"", ""Ocean Surface Wind Vector"", ""Significant Wave Height Estimation"", ""Iceberg Detection""], ""summary"": ""We present OceanSAR-2, the second generation of our foundation model for SAR-based ocean observation. Building on our earlier release, which pioneered self-supervised learning on Sentinel-1 Wave Mode data, OceanSAR-2 relies on improved SSL training and dynamic data curation strategies, which enhances performance while reducing training cost. OceanSAR-2 demonstrates strong transfer performance across downstream tasks, including geophysical pattern classification, ocean surface wind vector and significant wave height estimation, and iceberg detection. We release standardized benchmark datasets, providing a foundation for systematic evaluation and advancement of SAR models for ocean applications."" } ||  || [ Prompt: 37.9 t/s | Generation: 12.9 t/s ]"
2601.07393v1_Software-Hardware Co-optimization for Modular E2E .pdf,SOFTWARE-HARDWARECO-OPTIMIZATION FORMODULARE2E,"['Chengzhi Ji', 'Xingfeng Li', 'Zhaodong Lv', 'Hao Sun', 'Pan Liu', 'Hao Frank Yang', 'Ziyuan Pu']",,10.7,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SOFTWARE-HARDWARECO-OPTIMIZATION FORMODULARE2E || AV PARADIGM: A UNIFIEDFRAMEWORK OFOPTIMIZATION || APPROACHES, SIMULATIONENVIRONMENT ANDEVALUATION || METRICS || Chengzhi Ji1, Xingfeng Li1, Zhaodong Lv1, Hao Sun2, Pan Liu1, Hao Frank Yang3, Ziyuan Pu1, || 1School of Transportation, Southeast Unive ... (truncated) ||  || ```json || { || ""title"": ""SOFTWARE-HARDWARECO-OPTIMIZATION FORMODULARE2E"", || ""authors"": [""Chengzhi Ji"", ""Xingfeng Li"", ""Zhaodong Lv"", ""Hao Sun"", ""Pan Liu"", ""Hao Frank Yang"", ""Ziyuan Pu""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Modular end-to-end"", ""Closed-Loop Evaluation"", ""SoftwareHardware co-optimization"", ""Energy Consumption""], || ""summary"": ""Modular end-to-end (ME2E) autonomous driving paradigms combine interpretability with global optimization capability and have achieved state-of-the-art performance. However, extant research has primarily emphasized improvements in accuracy metrics, while neglecting to address critical system-level considerations such as energy consumption and inference latency. Consequently, model designs have evolved to become increasingly intricate. To improve deployability, previous studies have investigated model compression and acceleration, yet these approaches are often pursued independently on either the software or hardware side. Software-only optimization cannot fundamentally eliminate intermediate tensor access and operator scheduling overheads. Hardware-only optimization is constrained by model structure and bit-width. Consequently, the benefits of such optimizations are often substantially diminished in real-world deployment. To address these limitations, this paper proposes a reusable software-hardware co-optimization and closed-loop evaluation framework for ME2E autonomous driving inference. The framework integrates software-level model optimizations with hardware-level computation optimizations under a unified system-level objective. Furthermore, a multidimensional evaluation metric, EERA V, is introduced. This metric evaluates the ME2E autonomous driving system performance by jointly considering safety, comfort, efficiency, latency and energy, enabling quantitative assessment of the true system-level impact of different optimization strategies. The proposed framework is evaluated across multiple ME2E autonomous driving stacks. It preserves baseline-level accuracy while reducing inference latency by over 6 and per-frame energy to around one-fifth of the baseline. Furthermore, a 22.35% improvement in the EERA V metric is achieved. These results validate that the proposed framework provides actionable optimization guidance from both software and hardware perspectives."" || } ||  ||  || [ Prompt: 36.5 t/s | Generation: 10.7 t/s ]"
2601.07395v1_MCP-ITP An Automated Framework for Implicit Tool P.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MCP-ITP: An Automated Framework for Implicit Tool Poisoning in MCP || Ruiqi Li, Zhiqiang Wang, Y unhao Y ao, and Xiang-Y ang Li || University of Science and Technology of China || {lrq349, zhiqiang.wang, yaoyunhao}@mail.ustc.edu.cn, xiangyangli@ustc.edu.cn || Abstract || To standardize interaction ... (truncated) ||  || { || ""title"": ""MCP-ITP: An Automated Framework for Implicit Tool Poisoning in MCP"", || ""authors"": [""Ruiqi Li"", ""Zhiqiang Wang"", ""Y unhao Y ao"", ""Xiang-Y ang Li""], || ""doi"": """", || ""arxiv_id"": ""lrq349, zhiqiang.wang, yaoyunhao@ustc.edu.cn, xiangyangli@ustc.edu.cn"", || ""keywords"": [""Model Context Protocol"", ""Implicit Tool Poisoning"", ""Adversarial Machine Learning"", ""Large Language Models"", ""Security""], || ""summary"": ""This paper proposes MCP-ITP, the first automated and adaptive framework for implicit tool poisoning within the MCP ecosystem. MCP-ITP formulates poisoned tool generation as a black-box optimization problem and employs an iterative optimization strategy that leverages feedback from both an evaluation LLM and a detection LLM to maximize Attack Success Rate (ASR) while evading current detection mechanisms. Experimental results on the MCPTox dataset demonstrate that MCP-ITP consistently outperforms manually crafted baselines, achieving up to 84.2% ASR while suppressing the Malicious Tool Detection Rate (MDR) to as low as 0.3%."""
2601.07397v1_Layerwise goal-oriented adaptivity for neural ODEs.pdf,Layerwise goal-oriented adaptivity for neural ODEs: an optimal control perspective,"['Michael Hintermuller', 'Michael Hinze', 'Denis Korolev']",,11.7,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || arXiv:2601.07397v1  [math.OC]  12 Jan 2026 || Layerwise goal-oriented adaptivity for neural ODEs: an optimal || control perspective || Michael Hinterm uller1,3 , Michael Hinze 2 , and Denis Korolev 3 || 1Institute for Mathematics, Humboldt-Universit at zu Berlin, Berlin, Germany || 2Mathematical I ... (truncated) ||  || { ""title"": ""Layerwise goal-oriented adaptivity for neural ODEs: an optimal control perspective"", ""authors"": [""Michael Hintermuller"", ""Michael Hinze"", ""Denis Korolev""], ""doi"": """", ""arxiv_id"": ""arXiv:2601.07397v1"", ""keywords"": [""Resnet"", ""neural ODEs"", ""parameter identification/learning"", ""adaptive neural network""], ""summary"": ""In this work, we propose a novel layerwise adaptive construction method for neural network architectures. Our approach is based on a goal-oriented dual-weighted residual technique for the optimal control of neural differential equations. This leads to an ordinary differential equation constrained optimization problem with controls acting as coefficients and a specific loss function. We implement our approach on the basis of a DG(0) Galerkin discretization of the neural ODE, leading to an explicit Euler time marching scheme. For the optimization we use steepest descent. Finally, we apply our method to the construction of neural networks for the classification of data sets, where we present results for a selection of well known examples from the literature."" } ||  || [ Prompt: 34.3 t/s | Generation: 11.7 t/s ]"
2601.07411v1_SCALPEL Selective Capability Ablation via Low-rank.pdf,SCALPEL: Selective Capability Ablation via Low-rank Parameter Editing for Large Language Model Interpretability Analysis,"['Zihao Fu', 'Xufeng Duan', 'Zhenguang G. Cai']",,13.4,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SCALPEL: Selective Capability Ablation via Low-rank Parameter || Editing for Large Language Model Interpretability Analysis || Zihao Fu || The Chinese University of Hong Kong || zihaofu@cuhk.edu.hk || Xufeng Duan || The Chinese University of Hong Kong || xufengduan@cuhk.edu.hk || Zhenguang G. Cai || The Chine ... (truncated) ||  || { || ""title"": ""SCALPEL: Selective Capability Ablation via Low-rank Parameter Editing for Large Language Model Interpretability Analysis"", || ""authors"": [""Zihao Fu"", ""Xufeng Duan"", ""Zhenguang G. Cai""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Large Language Models"", ""Interpretability"", ""Low-rank Parameter Editing"", ""Selective Capability Ablation""], || ""summary"": ""Large language models have achieved remarkable success across diverse domains, yet their deployment in many applications remains limited by our incomplete understanding of their internal mechanisms. SCALPEL presents a framework that represents capabilities as low-rank parameter subspaces rather than discrete modules, enabling precise capability removal without affecting others. By training LoRA adapters to reduce the models ability to distinguish correct from incorrect answers while preserving general language modeling quality, SCALPEL identifies the low-rank representation responsible for a particular capability while remaining disentangled from other capabilities. Experiments across diverse capability tasks and linguistic tasks demonstrate that SCALPEL successfully removes target capabilities while preserving other general capabilities, providing fine-grained insights into how capabilities are distributed across the models parameter space."" || } ||  || [ Prompt: 34.7 t/s | Generation: 13.4 t/s ]"
2601.07422v1_Two Pathways to Truthfulness On the Intrinsic Enco.pdf,Two Pathways to Truthfulness: On the Intrinsic Encoding of LLM Hallucinations,"['Wen Luo', 'Guangyue Peng', 'Wei Li', 'Shaohang Wei', 'Feifan Song', 'Liang Wang', 'Nan Yang', 'Xingxing Zhang', 'Jing Jin', 'Furu Wei', 'Houfeng Wang']",,11.3,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Two Pathways to Truthfulness: On the Intrinsic || Encoding of LLM Hallucinations || Wen Luo, Guangyue Peng , Wei Li, Shaohang Wei, Feifan Song , || Liang Wang, Nan Yang, Xingxing Zhang , Jing Jin , Furu Wei, Houfeng Wang* || State Key Laboratory of Multimedia Information Processing, || School of  ... (truncated) ||  || { || ""title"": ""Two Pathways to Truthfulness: On the Intrinsic Encoding of LLM Hallucinations"", || ""authors"": [""Wen Luo"", ""Guangyue Peng"", ""Wei Li"", ""Shaohang Wei"", ""Feifan Song"", ""Liang Wang"", ""Nan Yang"", ""Xingxing Zhang"", ""Jing Jin"", ""Furu Wei"", ""Houfeng Wang""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""large language models"", ""hallucinations"", ""truthfulness"", ""internal representations"", ""attention mechanisms""], || ""summary"": ""Despite impressive capabilities, large language models (LLMs) frequently generate hallucinations. Previous work shows that their internal states encode rich signals of truthfulness, yet the origins and mechanisms of these signals remain unclear. This paper demonstrates that truthfulness cues arise from two distinct information pathways: a Question-Anchored pathway and an Answer-Anchored pathway. Through attention knockout and token patching, we validate and disentangle these pathways. Notable properties of these mechanisms are uncovered, and experiments reveal their association with LLM knowledge boundaries and internal representations' awareness of their distinctions. Two applications are proposed to enhance hallucination detection performance. Overall, our work provides new insights into how LLMs internally encode truthfulness, offering directions for more reliable and self-aware generative systems."" || } ||  || [ Prompt: 32.7 t/s | Generation: 11.3 t/s ]"
2601.07430v1_KALE Enhancing Knowledge Manipulation in Large Lan.pdf,,[],,11.4,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || KALE: Enhancing Knowledge Manipulation in Large Language Models || via Knowledge-aware Learning || Qitan Lv1,2* Tianyu Liu1,2* Qiaosheng Zhang2 Xingcheng Xu2 Chaochao Lu2 || 1University of Science and Technology of China || 2Shanghai AI Laboratory || {qitanlv, tianyu_liu}@mail.ustc.edu.cn || {xuxingc ... (truncated) ||  || { || ""title"": ""KALE: Enhancing Knowledge Manipulation in Large Language Models via Knowledge-aware Learning"", || ""authors"": [""Qitan Lv"", ""Tianyu Liu"", ""Qiaosheng Zhang"", ""Xingcheng Xu"", ""Chaochao Lu""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Knowledge Manipulation"", ""Large Language Models"", ""Knowledge Graphs"", ""Supervised Fine-Tuning"", ""Knowledge-Aware Learning""], || ""summary"": ""Despite the impressive performance of large language models (LLMs) pretrained on vast knowledge corpora, advancing their knowledge manipulation ability remains challenging. Existing methods mainly leverage Supervised Fine-Tuning (SFT) on labeled datasets to enhance LLMs knowledge manipulation. However, SFT models still exhibit the known&incorrect phenomenon, where they explicitly possess relevant knowledge for a given question but fail to leverage it for correct answers. To address this challenge, we propose KALE (Knowledge-Aware LEarning), a post-training framework that leverages knowledge graphs (KGs) to generate high-quality rationales and enhance LLMs knowledge manipulation ability. Specifically, KALE first introduces a Knowledge-Induced (KI) data synthesis method to efficiently extract multi-hop reasoning paths from KGs to generate high-quality rationales for question-answer pairs. Then, KALE employs a Knowledge-Aware (KA) fine-tuning paradigm to enhance knowledge manipulation by internalizing rationale-guided reasoning through minimizing the KL divergence between predictions with and without rationales. Extensive experiments on eight popular benchmarks across six different LLMs demonstrate the effectiveness of KALE, achieving accuracy improvements of up to 11.72% and an average of 4.18%."" || } ||  || [ Prompt: 33.3 t/s | Generation: 11.4 t/s ]"
2601.07449v1_RLPO Residual Listwise Preference Optimization for.pdf,RLPO: Residual Listwise Preference Optimization for Long-Context Review Ranking,"['Hao Jiang', 'Zhi Yang', 'Annan Wang', 'Yichi Zhang', 'Weisi Lin*']",,6.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || RLPO: Residual Listwise Preference Optimization for Long-Context || Review Ranking || Hao Jiang || Nanyang Technological University || jianghao907@gmail.com || Zhi Yang || Peking University || zhiyang25@stu.pku.edu.cn || Annan Wang || Nanyang Technological University || annan001@e.ntu.edu.sg || Yichi Zhang || Independ ... (truncated) ||  || { || ""title"": ""RLPO: Residual Listwise Preference Optimization for Long-Context Review Ranking"", || ""authors"": [""Hao Jiang"", ""Zhi Yang"", ""Annan Wang"", ""Yichi Zhang"", ""Weisi Lin*""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""review ranking"", ""long-context"", ""residual listwise preference optimization"", ""large-scale benchmark""], || ""summary"": ""Review ranking is crucial in e-commerce for prioritizing user-generated feedback. While large language models have improved semantic assessment, existing ranking paradigms face a persistent trade-off in long-context settings. Pointwise scoring is efficient but often fails to account for list-level interactions, leading to miscalibrated top-k rankings. Listwise approaches leverage global context but are computationally expensive and unstable. To address this, we propose Residual Listwise Preference Optimization (RLPO), which formulates ranking as listwise representation-level residual correction over a strong pointwise LLM scorer. RLPO first produces calibrated pointwise scores and item representations, then applies a lightweight encoder over the representations to predict listwise score residuals, avoiding full token-level listwise processing. We introduce a large-scale benchmark for long-context review ranking with human verification. Experiments show RLPO improves NDCG@k over strong pointwise and listwise baselines and remains robust as list length increases."" || } ||  || [ Prompt: 32.9 t/s | Generation: 6.1 t/s ]"
2601.07463v1_Puzzle it Out Local-to-Global World Model for Offl.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Puzzle it Out: Local-to-Global World Model for Offline || Multi-Agent Reinforcement Learning || Sijia Li || The Hong Kong University of Science and Technology || Hong Kong, China || slifg@connect.ust.hk || Xinran Li || The Hong Kong University of Science and Technology || Hong Kong, China || xinran.li@connect ... (truncated) ||  || { || ""title"": ""Puzzle it Out: Local-to-Global World Model for Offline Multi-Agent Reinforcement Learning"", || ""authors"": [""Sijia Li"", ""Xinran Li"", ""Shibo Chen"", ""Jun Zhang""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Offline multi-agent reinforcement learning"", ""Multi-agent model-based reinforcement learning""], || ""summary"": ""Offline multi-agent reinforcement learning (MARL) aims to solve cooperative decision-making problems in multi-agent systems using pre-collected datasets. Existing methods primarily constrain training within the dataset distribution, leading to overly conservative policies that struggle to generalize beyond the support of the data. Model-based approaches offer a promising solution by expanding the original dataset with synthetic data generated from a learned world model, but the high dimensionality, non-stationarity, and complexity of multi-agent systems make accurate estimation of transitions and reward functions challenging. We propose a local-to-global (LOGO) world model, a novel framework that leverages local predictions, which are easier to estimate, to infer global state dynamics, thus improving prediction accuracy while implicitly capturing agent-wise dependencies. Using the trained world model, we generate synthetic data to augment the original dataset, expanding the effective state-action space. To ensure reliable policy learning, we introduce an uncertainty-aware sampling mechanism that adaptively weights synthetic data by prediction uncertainty, reducing approximation error propagation to policies. Our approach requires only an additional encoder for uncertainty estimation, significantly reducing computational overhead while maintaining accuracy. Extensive experiments across 8 scenarios against 8 baselines demonstrate that our method surpasses state-of-the-art baselines on standard offline MARL benchmarks, establishing a new model-based baseline for generalizable offline multi-agent learning."""
2601.07464v1_IFDNS An Iterative Feedback-Driven Neuro-Symbolic .pdf,IFDNS: An Iterative Feedback-Driven Neuro-Symbolic Method for Faithful Logical Reasoning,"['Xiaoheng Wang', 'Tongxuan Liu', 'Zi Gong', 'Xianzhe Dong', 'Yuting Zeng', 'Minhan Hu', 'Weizhe Huang', 'Jing Li']",,5.8,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || IFDNS: An Iterative Feedback-Driven Neuro-Symbolic || Method for Faithful Logical Reasoning || Xiaoheng Wang1[0009000533352322], Tongxuan Liu1[0009000726342788], Zi || Gong1[0009000488633677], Xianzhe Dong1[0009000769439432], Yuting || Zeng1[0009000617195424], Minhan Hu1[0009000739958821], Weiz ... (truncated) ||  || ```json || { || ""title"": ""IFDNS: An Iterative Feedback-Driven Neuro-Symbolic Method for Faithful Logical Reasoning"", || ""authors"": [""Xiaoheng Wang"", ""Tongxuan Liu"", ""Zi Gong"", ""Xianzhe Dong"", ""Yuting Zeng"", ""Minhan Hu"", ""Weizhe Huang"", ""Jing Li""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Logical Reasoning"", ""Large Language Model"", ""Reasoning""], || ""summary"": ""Large language models (LLMs) have demonstrated impressive capabilities across a wide range of reasoning tasks, including logical and mathematical problem-solving. While prompt-based methods like Chain-of-Thought (CoT) can enhance LLM reasoning abilities to some extent, they often suffer from a lack of faithfulness, where the derived conclusions may not align with the generated reasoning chain. To address this issue, researchers have explored neuro-symbolic approaches to bolster LLM logical reasoning capabilities. However, existing neuro-symbolic methods still face challenges with information loss during the process. To overcome these limitations, we introduce Iterative Feedback-Driven Neuro-Symbolic (IFDNS), a novel prompt-based method that employs a multi-round feedback mechanism to address LLM limitations in handling complex logical relationships. IFDNS utilizes iterative feedback during the logic extraction phase to accurately extract causal relationship statements and translate them into propositional and logical implication expressions, effectively mitigating information loss issues. Furthermore, IFDNS is orthogonal to existing prompt methods, allowing for seamless integration with various prompting approaches. Empirical evaluations across six datasets demonstrate the effectiveness of IFDNS in significantly improving the performance of CoT and Chain-of-Thought with Self-Consistency (CoT-SC). Specifically, IFDNS achieves a +9.40% accuracy boost for CoT on the LogiQA dataset and a +11.70% improvement for CoT-SC on the PrOntoQA dataset."" || } ||  ||  || [ Prompt: 22.0 t/s | Generation: 5.8 t/s ]"
2601.07468v1_Beyond Dialogue Time Temporal Semantic Memory for .pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Beyond Dialogue Time: || Temporal Semantic Memory for Personalized LLM Agents || Miao Su1,2,3,4, Yucan Guo1,2,3, Zhongni Hou 4, Long Bai 1,2, || Zixuan Li1,2,Yufei Zhang 4,Guojun Yin 4,Wei Lin 4, || Xiaolong Jin1,2,3,Jiafeng Guo 1,2,3,Xueqi Cheng 1,2,3, || 1Institute of Computing Technology, Chine ... (truncated) ||  || ```json || { || ""title"": ""Beyond Dialogue Time: Temporal Semantic Memory for Personalized LLM Agents"", || ""authors"": [""Miao Su"", ""Yucan Guo"", ""Zhongni Hou"", ""Long Bai"", ""Zixuan Li"", ""Yufei Zhang"", ""Guojun Yin"", ""Wei Lin"", ""Xiaolong Jin"", ""Jiafeng Guo"", ""Xueqi Cheng""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Temporal Semantic Memory"", ""Personalized LLM Agents"", ""Memory"", ""Large Language Models"", ""Temporal Inaccuracy"", ""Temporal Fragmentation""], || ""summary"": ""Memory enables Large Language Model (LLM) agents to perceive, store, and use information from past dialogues, which is essential for personalization. However, existing methods fail to properly model the temporal dimension of memory in two aspects: 1) Temporal inaccuracy: memories are organized by dialogue time rather than their actual occurrence time; 2) Temporal fragmentation: existing methods focus on point-wise memory, losing durative information that captures persistent states and evolving patterns. To address these limitations, we propose Temporal Semantic Memory (TSM), a memory framework that models semantic time for point-wise memory and supports the construction and utilization of durative memory. During memory construction, it first builds a semantic timeline rather than a dialogue one. Then, it consolidates temporally continuous and semantically related information into a durative memory. During memory utilization, it incorporates the query's temporal intent on the semantic timeline, enabling the retrieval of temporally appropriate durative memories and providing time-valid, duration-consistent context to support response generation. Experiments on LONGMEMEVAL and LOCOMO show that TSM consistently outperforms existing methods and achieves up to 12.2% absolute improvement in accuracy, demonstrating the effectiveness of the proposed method."""
2601.07469v1_Knowledge Distillation for LLM-Based Human Activit.pdf,KNOWLEDGE DISTILLATION FOR LLM-B ASED HUMAN ACTIVITY RECOGNITION IN HOMES,"['Julien Cumin', 'Oussama Er-Rahmany', 'Xi Chen']",,5.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || arXiv:2601.07469v1  [cs.AI]  12 Jan 2026 || KNOWLEDGE DISTILLATION FOR LLM-B ASED HUMAN ACTIVITY || RECOGNITION IN HOMES || AUTHOR VERSION || Julien Cumin1 , Oussama Er-Rahmany1, Xi Chen 1,2 || 1 Orange Research || 2 Univ. Grenoble Alpes, CNRS, Grenoble INP , LIG, 38000 Grenoble, France || Corresponding ... (truncated) ||  || { ""title"": ""KNOWLEDGE DISTILLATION FOR LLM-B ASED HUMAN ACTIVITY RECOGNITION IN HOMES"", ""authors"": [""Julien Cumin"", ""Oussama Er-Rahmany"", ""Xi Chen""], ""doi"": """", ""arxiv_id"": ""arXiv:2601.07469v1"", ""keywords"": [""Human activity recognition"", ""large language models"", ""knowledge distillation"", ""ambient intelligence"", ""smart homes""], ""summary"": ""Human Activity Recognition (HAR) in homes based on sensor data has been a long-standing subject of research. This paper provides new experimental results regarding the use of LLMs for HAR, on two state-of-the-art datasets. It shows how recognition performance evolves depending on the size of the LLM used, and experiments on the use of knowledge distillation techniques to ne-tune smaller LLMs with HAR reasoning examples generated by larger LLMs. It demonstrates that such ne-tuned models can perform almost as well as the largest LLMs, while having 50 times less parameters."" } ||  || [ Prompt: 13.0 t/s | Generation: 5.0 t/s ]"
2601.07470v1_Learning How to Remember A Meta-Cognitive Manageme.pdf,Learning How to Remember: A Meta-Cognitive Management Method for Structured and Transferable Agent Memory,"['Sirui Liang', 'Pengfei Cao', 'Jian Zhao', 'Wenhao Teng', 'Xiangwen Liao', 'Jun Zhao', 'Kang Liu']",,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Learning How to Remember:A Meta-Cognitive Management Method for || Structured and Transferable Agent Memory || Sirui Liang1,2,3*, Pengfei Cao1,2*, Jian Zhao3,4, Wenhao Teng 5, || Xiangwen Liao 6,Jun Zhao 1,2,Kang Liu 1,2 || 1Institute of Automation, CAS, 2University of Chinese Academy of Scienc ... (truncated) ||  || { ""title"": ""Learning How to Remember: A Meta-Cognitive Management Method for Structured and Transferable Agent Memory"", ""authors"": [""Sirui Liang"", ""Pengfei Cao"", ""Jian Zhao"", ""Wenhao Teng"", ""Xiangwen Liao"", ""Jun Zhao"", ""Kang Liu""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Meta-Cognitive Memory Abstraction"", ""LLM Agents"", ""Memory Management"", ""Procedural Memory"", ""Transfer Learning""], ""summary"": ""Large language model (LLM) agents increasingly rely on accumulated memory to solve long-horizon decision-making tasks. However, most existing approaches store memory in fixed representations and reuse it at a single or implicit level of abstraction, which limits generalization and often leads to negative transfer when distribution shift. This paper proposes the Meta-Cognitive Memory Abstraction method (MCMA), which treats memory abstraction as a learnable cognitive skill rather than a fixed design choice. MCMA decouples task execution from memory management by combining a frozen task model with a learned memory copilot. The memory copilot is trained using direct preference optimization, determining how memories should be structured, abstracted, and reused. Memories are further organized into a hierarchy of abstraction levels, enabling selective reuse based on task similarity. When no memory is transferable, MCMA transfers the ability to abstract and manage memory by transferring the memory copilot. Experiments on ALFWorld, ScienceWorld, and BabyAI demonstrate substantial improvements in performance, out-of-distribution generalization, and cross-task transfer over several baselines."" }"
2601.07474v1_Task Prototype-Based Knowledge Retrieval for Multi.pdf,Task Prototype-Based Knowledge Retrieval for Multi-Task Learning,"['Youngmin Oh', 'Hyung-Il Kim', 'Jung Uk Kim']",,5.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Task Prototype-Based Knowledge Retrieval for Multi-Task Learning || from Partially Annotated Data || Y oungmin Oh1,2, Hyung-Il Kim 3, Jung Uk Kim 1* || 1Kyung Hee University || 2Electronics and Telecommunications Research Institute (ETRI) || 3Chonnam National University || youngmin@etri.re.kr, hyungi ... (truncated) ||  || ```json || { || ""title"": ""Task Prototype-Based Knowledge Retrieval for Multi-Task Learning"", || ""authors"": [""Youngmin Oh"", ""Hyung-Il Kim"", ""Jung Uk Kim""], || ""doi"": """", || ""arxiv_id"": ""arXiv:2304.00000"", || ""keywords"": [""Multi-task learning"", ""Prototype-based knowledge retrieval"", ""Partially labeled data"", ""Robust multi-task learning""], || ""summary"": ""Multi-task learning (MTL) is critical in real-world applications such as autonomous driving and robotics. Existing methods for partially labeled MTL typically rely on predictions from unlabeled tasks, leading to unreliable task associations and potentially negative transfer. This paper proposes a prototype-based knowledge retrieval framework that achieves robust MTL by consistently capturing task-specific characteristics. Extensive experiments demonstrate the effectiveness of this framework, highlighting its potential for robust multi-task learning even when only a subset of tasks is annotated."" || } ||  ||  || [ Prompt: 13.1 t/s | Generation: 5.0 t/s ]"
2601.07475v1_ARCQuant Boosting NVFP4 Quantization with Augmente.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ARCQuant: Boosting NVFP4 Quantization with Augmented Residual || Channels for LLMs || Haoqian Meng1, Yilun Luo1, Yafei Zhao1, Wenyuan Liu1, Peng Zhang1*, Xindian Ma1 || 1School of Computer Science and Technology, Tianjin University || Abstract || The emergence of fine-grained numerical for- || mats l ... (truncated) ||  || { || ""title"": ""ARCQuant: Boosting NVFP4 Quantization with Augmented Residual Channels for LLMs"", || ""authors"": [""Haoqian Meng"", ""Yilun Luo"", ""Yafei Zhao"", ""Wenyuan Liu"", ""Peng Zhang*""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Large Language Models"", ""Post-Training Quantization"", ""NVFP4"", ""Augmented Residual Channels"", ""Microscaling Formats""], || ""summary"": ""The emergence of fine-grained numerical formats like NVFP4 presents new opportunities for efficient Large Language Model (LLM) inference. However, adapting existing Post-Training Quantization (PTQ) strategies to these formats is challenging. ARCQuant, a framework proposed to boost NVFP4 performance, uses augmented residual channels to maintain a strictly unified NVFP4 format. This design integrates error compensation directly into matrix reduction, enabling the use of standard, highly optimized GEMM kernels with minimal overhead. Extensive experiments on LLaMA and Qwen models demonstrate that ARCQuant achieves state-of-the-art accuracy, comparable to full-precision base lines in perplexity and downstream tasks. Deployment on RTX 5090 and RTX PRO 6000 GPUs confirms practical benefits, achieving up to 3 speedup over FP16."""
2601.07477v1_JudgeFlow Agentic Workflow Optimization via Block .pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || JUDGEFLOW: AGENTICWORKFLOWOPTIMIZATION || VIABLOCKJUDGE || Zihan Ma,1 Zhikai Zhao,1 Chuanbo Hua1 Federico Berto1,2 Jinkyoo Park1,3 || 1KAIST 2Radical Numerics 3Omelet || ABSTRACT || Optimizing LLM-based agentic workflows is challenging for scaling AI capabilities. || Current methods rely on coarse, e ... (truncated) ||  || { || ""title"": ""JUDGEFLOW: AGENTICWORKFLOWOPTIMIZATION"", || ""authors"": [""Zihan Ma"", ""Zhikai Zhao"", ""Chuanbo Hua"", ""Federico Berto"", ""Jinkyoo Park""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Large Language Models"", ""AGentic Workflows"", ""Evaluation"", ""Optimization"", ""Fine-grained Signals"", ""Automated Workflow Design""], || ""summary"": ""Optimizing LLM-based agentic workflows is challenging for scaling AI capabilities. Current methods rely on coarse, end-to-end evaluation signals and lack fine-grained signals on where to refine, often resulting in inefficient or low-impact modifications. To address these limitations, we propose JUDGEFLOW, an Evaluation-Judge-Optimization-Update pipeline. We incorporate reusable, configurable logic blocks into agentic workflows to capture fundamental forms of logic. On top of this abstraction, we design a dedicated Judge module that inspects execution traces, particularly failed runs, and assigns rank-based responsibility scores to problematic blocks. These fine-grained diagnostic signals are then leveraged by an LLM-based optimizer, which focuses modifications on the most problematic block in the workflow. Our approach improves sample efficiency, enhances interpretability through block-level diagnostics, and provides a scalable foundation for automating increasingly complex agentic workflows. We evaluate JUDGEFLOW on mathematical reasoning and code generation benchmarks, where JUDGEFLOW achieves superior performance and efficiency compared to existing methods. The source code is publicly available at https://github.com/ma-zihan/JudgeFlow."""
2601.07496v1_Graph Inference Towards ICD Coding.pdf,Graph Inference Towards ICD Coding,['1st Xiaoxiao Deng'],,5.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Graph Inference Towards ICD Coding || 1st Xiaoxiao Deng || College of Computing and Digital Media || DePaul University || Chicago, United States || dengxiaoxiao1019@gmail.com || AbstractAutomated ICD coding involves assigning standard- || ized diagnostic codes to clinical narratives. The vast label || spac ... (truncated) ||  || { || ""title"": ""Graph Inference Towards ICD Coding"", || ""authors"": [""1st Xiaoxiao Deng""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""transfer learning"", ""graph convolutional network"", ""lightweight attention"", ""ICD code prediction"", ""adversarial domain adaptation""], || ""summary"": ""Automated ICD coding involves assigning standardized diagnostic codes to clinical narratives. The vast label space and extreme class imbalance continue to challenge precise prediction. LabGraph is introduced as a unified framework that reformulates ICD coding as a graph generation task. By combining adversarial domain adaptation, graph-based reinforcement learning, and perturbation regularization, LabGraph effectively enhances model robustness and generalization. Experiments on benchmark datasets demonstrate that LabGraph consistently outperforms previous approaches on micro-F1, micro-AUC, and P@K."" || } ||  || [ Prompt: 12.6 t/s | Generation: 5.1 t/s ]"
2601.07514v1_Data-Driven Stochastic VRP Integration of Forecast.pdf,Data-Driven Stochastic VRP: Integration of Forecast Duration into Optimization for Utility Workforce Management,['Matteo Garbellia'],,6.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Data-Driven Stochastic VRP: Integration of Forecast || Duration into Optimization for Utility Workforce || Management || Matteo Garbellia, || aDepartment of Computer Science, Strada le Grazie, 15, Verona, 37134, Italy || Abstract || This paper investigates the integration of machine learning forecast ... (truncated) ||  || { || ""title"": ""Data-Driven Stochastic VRP: Integration of Forecast Duration into Optimization for Utility Workforce Management"", || ""authors"": [""Matteo Garbellia""], || ""doi"": """", || ""arxiv_id"": ""2601.07514"", || ""keywords"": [""Stochastic VRP"", ""Machine Learning"", ""XGBoost"", ""Sub-Gaussian Concentration"", ""Multi-Objective Optimization"", ""Evolutionary Algorithms""], || ""summary"": ""This paper investigates the integration of machine learning forecasts of intervention durations into a stochastic variant of the Capacitated Vehicle Routing Problem with Time Windows (CVRPTW). Specifically, we use tree-based gradient boosting (XGBoost) trained on eight years of gas meter maintenance data to produce point predictions and uncertainty estimates, which drive a multi-objective evolutionary optimization routine. The methodology addresses uncertainty through sub-Gaussian concentration bounds for route-level risk buffers and explicitly accounts for competing operational KPIs through a multi-objective formulation. Empirical analysis of prediction residuals validates the sub-Gaussian assumption underlying the risk model. The results show improvements around 20-25% in operator utilization and completion rates compared to plans computed using default durations. The integration of uncertainty quantification and risk-aware optimization provides a practical framework for handling stochastic service durations in real-world routing applications."" || } ||  || [ Prompt: 13.9 t/s | Generation: 6.0 t/s ]"
2601.07516v1_Controlling Multimodal Conversational Agents with .pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Controlling Multimodal Conversational Agents || with Coverage-Enhanced Latent Actions || Y ongqi Li1,2,,, Hao Lang 2,, Tieyun Qian 1,3,, Y ongbin Li2, || 1 School of Computer Science, Wuhan University, 2 Tongyi Lab || 3 Zhongguancun Academy || {liyongqi,qty}@whu.edu.cn,{hao.lang,shuide.lyb}@alibab ... (truncated) ||  || { || ""title"": ""Controlling Multimodal Conversational Agents with Coverage-Enhanced Latent Actions"", || ""authors"": [""Yongqi Li"", ""Hao Lang"", ""Tieyun Qian"", ""Yongbin Li""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Vision-Language Models"", ""Reinforcement Learning"", ""Multimodal Conversational Agents"", ""Latent Actions"", ""Cycle Consistency Loss""], || ""summary"": ""Vision-language models are increasingly employed as multimodal conversational agents (MCAs) for diverse conversation tasks. Recent advances in reinforcement learning (RL) have been explored for adapting MCAs to various human-AI interaction scenarios. However, fine-tuning MCAs via RL still faces challenges in handling the large text token space. To address this, we propose a method that learns a compact latent action space for RL fine-tuning. Specifically, we use the learning from observation mechanism to construct a codebook for the latent action space, leveraging future observations to estimate current latent actions. To overcome the scarcity of paired image-text data, we use both paired and text-only data to construct the latent action space, employing a cross-modal projector for transforming text embeddings into image-text embeddings. We initialize the cross-modal projector on paired image-text data and further train it on massive text-only data with a novel cycle consistency loss to enhance its robustness. Our method outperforms competitive baselines on two conversation tasks across various RL algorithms."""
2601.07518v1_Mon3tr Monocular 3D Telepresence with Pre-built Ga.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || JOURNAL OF LATEX CLASS FILES 1 || Mon3tr: Monocular 3D Telepresence with Pre-built || Gaussian Avatars as Amortization || Fangyu Lin, Yingdong Hu, Zhening Liu, Yufan Zhuang, || Zehong Lin,Member, IEEE,and Jun Zhang,Fellow, IEEE || AbstractImmersive telepresence aims to transform human || interaction  ... (truncated) ||  || { || ""title"": ""Mon3tr: Monocular 3D Telepresence with Pre-built Gaussian Avatars as Amortization"", || ""authors"": [""Fangyu Lin"", ""Yingdong Hu"", ""Zhening Liu"", ""Yufan Zhuang"", ""Zehong Lin"", ""Jun Zhang""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Monocular 3D telepresence"", ""3D Gaussian splatting"", ""animatable avatars"", ""real-time neural rendering""], || ""summary"": ""Mon3tr is a novel Monocular 3D telepresence framework that integrates 3D Gaussian splatting (3DGS) based parametric human modeling into telepresence for the first time. It adopts an amortized computation strategy, dividing the process into a one-time offline multi-view reconstruction phase to build a user-specific avatar and a monocular online inference phase during live telepresence sessions. A single monocular RGB camera captures body motions and facial expressions in real time to drive the 3DGS-based parametric human model, significantly reducing system complexity and cost. The extracted motion and appearance features are transmitted at <0.2 Mbps over WebRTC data channel, allowing robust adaptation to network fluctuations. On the receiver side, a lightweight 3DGS attribute deformation network dynamically generates corrective 3DGS attribute adjustments on the pre-built avatar, synthesizing photorealistic motion and appearance at 60 FPS. Extensive experiments demonstrate the state-of-the-art performance of our method, achieving a PSNR of >28 dB for novel poses, an end-to-end latency of 80 ms, and >1000 bandwidth reduction compared to point-cloud streaming, while supporting real-time operation from monocular inputs across diverse scenarios."""
2601.07525v1_Thinking Before Constraining A Unified Decoding Fr.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Thinking Before Constraining: A Unified Decoding Framework for Large || Language Models || Ngoc Trinh Hung Nguyen1,2, Alonso Silva2, Laith Zumot3 || Liubov Tupikina2,Armen Aghasaryan 2,Mehwish Alam 1 || 1 Tlcom Paris, Institut Polytechnique de Paris, France, 2 Nokia Bell Labs, 3 Nokia || Correspon ... (truncated) ||  || ```json || { || ""title"": ""Thinking Before Constraining: A Unified Decoding Framework for Large Language Models"", || ""authors"": [""Ngoc Trinh Hung Nguyen1"", ""Alonso Silva2"", ""Laith Zumot3"", ""Liubov Tupikina2"", ""Armen Aghasaryan 2"", ""Mehwish Alam 1""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Large Language Models"", ""Natural Generation"", ""Structured Generation"", ""Constrained Decoding"", ""Expressive Power"", ""Reliability"", ""Fluency"", ""Generalization""], || ""summary"": ""Natural generation allows Language Models (LMs) to produce free-form responses with rich reasoning, but the lack of guaranteed structure makes outputs difficult to parse or verify. Structured generation, or constrained decoding, addresses this drawback by producing content in standardized formats such as JSON, ensuring consistency and guaranteed-parsable outputs, but it can inadvertently restrict the models reasoning capabilities. In this work, we propose a simple approach that combines the advantages of both natural and structured generation. By allowing LLMs to reason freely until specific trigger tokens are generated, and then switching to structured generation, our method preserves the expressive power of natural language reasoning while ensuring the reliability of structured outputs. We further evaluate our approach on several datasets, covering both classification and reasoning tasks, to demonstrate its effectiveness, achieving a substantial gain of up to 27% in accuracy compared to natural generation, while requiring only a small overhead of 1020 extra tokens. Our code and results are available online1."""
2601.07528v1_From RAG to Agentic RAG for Faithful Islamic Quest.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || From RAG to Agentic RAG for Faithful Islamic Question Answering || Gagan Bhatia1, Hamdy Mubarak1, Mustafa Jarrar2, George Mikros2, || Fadi Zaraket3, Mahmoud Alhirthani2, Mutaz Al-Khatib4, || Logan Cochrane5, Kareem Darwish1, Rashid Yahiaoui2, Firoj Alam1 || 1 Qatar Computing Research Institute, ... (truncated) ||  || { || ""title"": ""From RAG to Agentic RAG for Faithful Islamic Question Answering"", || ""authors"": [""Gagan Bhatia"", ""Hamdy Mubarak"", ""Mustafa Jarrar"", ""George Mikros"", ""Fadi Zaraket"", ""Mahmoud Alhirthani"", ""Mutaz Al-Khatib"", ""Logan Cochrane"", ""Kareem Darwish"", ""Rashid Yahiaoui"", ""Firoj Alam""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Islamic question answering"", ""faithful responses"", ""LLMs"", ""grounding"", ""agentic RAG"", ""Qwen"", ""retrieval"", ""reliability""], || ""summary"": ""This paper introduces ISLAMIC FAITH QA, a 3,810-item bilingual (Arabic/English) generative benchmark for Islamic question answering. It enables direct measurement of hallucination and abstention. An agentic Quran-grounding framework (agentic RAG) is developed using structured tool calls for iterative evidence seeking and answer revision. Experiments show that retrieval improves correctness and agentic RAG yields the largest gains beyond standard RAG, achieving state-of-the-art performance and stronger Arabic-English robustness even with a small model (i.e., Qwen3 4B). The experimental resources and datasets are made publicly available for the community."""
2601.07553v1_VirtualEnv A Platform for Embodied AI Research.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || VirtualEnv: A Platform for Embodied AI Research || Kabir Swain1, Sijie Han2, Ayush Raina3, Jin Zhang3, Shuang Li4, Michael Stopa3, Antonio || Torralba1 || 1Massachusetts Institute of Technology || 2University of Toronto || 3Sony Interactive Entertainment || 4Google Deepmind || kswain@mit.edu, hs.han@mai ... (truncated) ||  || { || ""title"": ""VirtualEnv: A Platform for Embodied AI Research"", || ""authors"": [""Kabir Swain"", ""Sijie Han"", ""Ayush Raina"", ""Jin Zhang"", ""Shuang Li"", ""Michael Stopa"", ""Antonio Torralba""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""VirtualEnv"", ""Embodied AI"", ""Simulation Platform"", ""Unreal Engine"", ""Large Language Models"", ""Vision-Language Models"", ""Interactive Environments"", ""Object Manipulation"", ""Navigation"", ""Multi-Agent Collaboration"", ""Procedural Environments"", ""Escape Rooms"", ""Reinforcement Learning"", ""AI and Gaming""], || ""summary"": ""VirtualEnv is a next-generation simulation platform built on Unreal Engine 5 designed to enable fine-grained benchmarking of large language models (LLMs) and vision-language models (VLMs) in embodied and interactive scenarios. It supports rich agent-environment interactions including object manipulation, navigation, and adaptive multi-agent collaboration. The platform integrates large-scale LLMs and VLMs to generate novel environments and structured tasks from multimodal inputs. Experiments benchmark the performance of popular LLMs across tasks of increasing complexity, analyzing differences in adaptability, planning, and multi-agent coordination. The methodology for procedural task generation, task validation, and real-time environment control is also described. VirtualEnv is released as an open-source platform aiming to advance research at the intersection of AI and gaming, enable standardized evaluation of LLMs in embodied AI settings, and pave the way for future developments in immersive simulations and interactive entertainment."""
2601.07556v1_Backpropagation-Free Test-Time Adaptation for Ligh.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || Backpropagation-Free Test-Time Adaptation for || Lightweight EEG-Based Brain-Computer Interfaces || Siyang Li, Jiayi Ouyang, Zhenyao Cui, Ziwei Wang, Tianwang J ia, Feng Wan, and Dongrui Wu, Fellow, IEEE || AbstractElectroencephalogram (EEG)-based brain-computer || interfaces (BCIs) face sign ... (truncated) ||  || { || ""title"": ""Backpropagation-Free Test-Time Adaptation for Lightweight EEG-Based Brain-Computer Interfaces"", || ""authors"": [""Siyang Li"", ""Jiayi Ouyang"", ""Zhenyao Cui"", ""Ziwei Wang"", ""Tianwang Jia"", ""Feng Wan"", ""Dongrui Wu""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""brain-computer interface"", ""domain adaptation"", ""electroencephalogram"", ""test-time adaptation"", ""transfer learning""], || ""summary"": ""Electroencephalogram (EEG)-based brain-computer interfaces (BCIs) face significant deployment challenges due to inter-subject variability, signal non-stationarity, and computational constraints. Test-time adaptation (TTA) mitigates distribution shifts under online data streams without per-use calibration sessions. However, existing TTA approaches heavily rely on explicitly defined loss objectives that require backpropagation for updating model parameters, which incurs computational overhead, privacy risks, and sensitivity to noisy data streams. This paper proposes Backpropagation-Free Transformations (BFT), a TTA approach for EEG decoding that eliminates these issues. BFT applies multiple sample-wise transformations of knowledge-guided augmentations or approximate Bayesian inference to each test trial, generating multiple prediction scores for a single test sample. A learning-to-rank module enhances the weighting of these predictions, enabling robust aggregation for uncertainty suppression during inference under theoretical justifications. Extensive experiments on five EEG datasets of motor imagery classification and driver drowsiness regression tasks demonstrate the effectiveness, versatility, robustness, and efficiency of BFT. This research enables lightweight plug-and-play BCIs on resource-constrained devices, broadening the real-world deployment of decoding algorithms for EEG-based BCIs."""
2601.07565v1_A Unified Framework for Emotion Recognition and Se.pdf,A Unified Framework for Emotion Recognition and Sentiment Analysis via Expert-Guided Multimodal Fusion with Large Language Models,"['Jiaqi Qiao', 'Xiujuan Xu', 'Xinran Li', 'Yu Liu']",,12.4,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A Unified Framework for Emotion Recognition and || Sentiment Analysis via Expert-Guided Multimodal || Fusion with Large Language Models || Jiaqi Qiao, Xiujuan Xu, Xinran Li, Yu Liu * || qiaobright@mail.dlut.edu.cn, xjxu@dlut.edu.cn, 963707605@mail.dlut.edu.cn, yuliu@dlut.edu.cn || School of Softwa ... (truncated) ||  || { ""title"": ""A Unified Framework for Emotion Recognition and Sentiment Analysis via Expert-Guided Multimodal Fusion with Large Language Models"", ""authors"": [""Jiaqi Qiao"", ""Xiujuan Xu"", ""Xinran Li"", ""Yu Liu""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""emotion recognition"", ""sentiment analysis"", ""multimodal fusion"", ""large language models"", ""expert-guided"", ""hierarchical dynamic gating"", ""pseudo token injection"", ""prompt-based conditioning"", ""LoRA fine-tuning""], ""summary"": ""This paper presents EGMF, a unified framework combining expert-guided multimodal fusion with large language models. The approach features three specialized expert networks: a fine-grained local expert for subtle emotional nuances, a semantic correlation expert for cross-modal relationships, and a global context expert for long-range dependencies. These are adaptively integrated through hierarchical dynamic gating for context-aware feature selection. Enhanced multimodal representations are integrated with LLMs via pseudo token injection and prompt-based conditioning, enabling a single generative framework to handle both classification and regression through natural language generation. LoRA fine-tuning is employed for computational efficiency. Experiments on bilingual benchmarks (MELD, CHERMA, MOSEI, SIMS-V2) demonstrate consistent improvements over state-of-the-art methods, with superior cross-lingual robustness revealing universal patterns in multimodal emotional expressions across English and Chinese. The source code will be released publicly."" } ||  || [ Prompt: 33.6 t/s | Generation: 12.4 t/s ]"
2601.07568v1_d3LLM Ultra-Fast Diffusion LLM using Pseudo-Trajec.pdf,Ultra-Fast dLLM using Pseudo-Trajectory Distillation,"['Yu-Yang Qian', 'Junda Su', 'Lanxiang Hu', 'Peiyuan Zhang', 'Zhijie Deng', 'Peng Zhao', 'Hao Zhang']",,9.3,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || d3LLM: Ultra-Fast dLLM using Pseudo-Trajectory Distillation || Yu-Yang Qian1 2 Junda Su 1 Lanxiang Hu 1 Peiyuan Zhang 1 Zhijie Deng 4 Peng Zhao2 3 Hao Zhang1 || Abstract || Diffusion large language models (dLLMs) offer || capabilities beyond those of autoregressive (AR) || LLMs, such as parallel d ... (truncated) ||  || { || ""title"": ""Ultra-Fast dLLM using Pseudo-Trajectory Distillation"", || ""authors"": [""Yu-Yang Qian"", ""Junda Su"", ""Lanxiang Hu"", ""Peiyuan Zhang"", ""Zhijie Deng"", ""Peng Zhao"", ""Hao Zhang""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""diffusion large language models"", ""pseudo-trajectory distillation"", ""parallel decoding"", ""random-order generation"", ""accuracy-parallelism trade-off""], || ""summary"": ""Diffusion large language models (dLLMs) offer capabilities beyond autoregressive (AR) LLMs, such as parallel decoding and random-order generation. However, realizing these benefits in practice is non-trivial due to an accuracy-parallelism trade-off. This paper proposes d3LLM (Pseudo-Distilled Diffusion Large Language Model), which strikes a balance between accuracy and parallelism by introducing pseudo-trajectory distillation during training and entropy-based multi-block decoding during inference. The paper also introduces AUP (Accuracy Under Parallelism) as a new metric to jointly measure accuracy and parallelism. Experiments demonstrate that d3LLM achieves up to 10 speedup over vanilla LLaDA/Dream and 5 speedup over AR models without much accuracy drop."" || } ||  || [ Prompt: 35.5 t/s | Generation: 9.3 t/s ]"
2601.07573v1_A Model of Artificial Jagged Intelligence.pdf,A Model of Artificial Jagged Intelligence,['Joshua S. Gans'],,6.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A Model of Artificial Jagged Intelligence || Joshua S. Gans || January 13, 2026 || Abstract || Generative AI systems often display highly uneven performance across tasks that appear || nearby: they can be excellent on one prompt and confidently wrong on another with only || small changes in wording  ... (truncated) ||  || { ""title"": ""A Model of Artificial Jagged Intelligence"", ""authors"": [""Joshua S. Gans""], ""doi"": """", ""arxiv_id"": ""2601.07573v1"", ""keywords"": [""generative AI"", ""adoption"", ""calibration"", ""learning"", ""knowledge density"", ""scaling""], ""summary"": ""This paper develops a tractable economic model of Artificial Jagged Intelligence (AJI) that treats adoption as an information problem. Users care about local reliability but typically observe only coarse, global quality signals. The model interpolates optimally and measures local error by posterior variance. It derives an adoption threshold for a blind user, shows that experienced errors are amplified by the inspection paradox, and interprets scaling laws as denser coverage improving average quality without eliminating jaggedness. The paper also studies mastery and calibration, deriving a learning-rate bound driven by information gain. It explores how scaling interacts with discoverability, and acknowledges research assistance and funding."" } ||  || [ Prompt: 13.0 t/s | Generation: 6.1 t/s ]"
2601.07577v1_Beyond Entangled Planning Task-Decoupled Planning .pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Beyond Entangled Planning: Task-Decoupled Planning for || Long-Horizon Agents || Yunfan Li1,2, Bingbing Xu1*, || Xueyun Tian1,2,Xiucheng Xu 1,2,Huawei Shen 1,2 || 1State Key Laboratory of AI Safety, Institute of Computing Technology, CAS, || 2University of Chinese Academy of Sciences || {liyunfan24s, ... (truncated) ||  || ```json || { || ""title"": ""Beyond Entangled Planning: Task-Decoupled Planning for Long-Horizon Agents"", || ""authors"": [""Yunfan Li"", ""Bingbing Xu"", ""Xueyun Tian"", ""Xiucheng Xu"", ""Huawei Shen""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Task-Decoupled Planning"", ""Long-Horizon Agents"", ""Reactive Planning"", ""One-Shot Planning"", ""Efficient Planning"", ""Robustness""], || ""summary"": ""Recent advances in large language models have enabled agents to autonomously execute complex, long-horizon tasks. However, planning remains a primary bottleneck for reliable task execution. Existing methods typically fall into two paradigms: step-wise planning, which is reactive but often short-sighted; and one-shot planning, which generates a complete plan upfront yet is brittle to execution errors. Crucially, both paradigms suffer from entangled contexts, where the agent must reason over a monolithic history spanning multiple sub-tasks. This entanglement increases cognitive load and lets local errors propagate across otherwise independent decisions, making recovery computationally expensive. To address this, we propose Task-Decoupled Planning (TDP), a training-free framework that replaces entangled reasoning with task decoupling. TDP decomposes tasks into a directed acyclic graph (DAG) of sub-goals via a Supervisor. Using a Planner and Executor with scoped contexts, TDP confines reasoning and replanning to the active sub-task. This isolation prevents error propagation and corrects deviations locally without disrupting the workflow. Results on TravelPlanner, ScienceWorld, and HotpotQA show that TDP outperforms strong baselines while reducing token consumption by up to 82%, demonstrating that sub-task decoupling improves both robustness and efficiency for long-horizon agents."""
2601.07580v1_Large Language Models for Physics Instrument Desig.pdf,Large Language Models for Physics Instrument Design,"['Sara Zoccheddu1', 'Shah Rukh Qasim1', 'Patrick Owen2', 'Nicola Serra1']",,5.5,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Large Language Models for Physics Instrument Design || Sara Zoccheddu1, Shah Rukh Qasim1,2, Patrick Owen2, and Nicola Serra1,2 || 1Mathematical Modeling and Machine Learning Department, University of Zurich, || Zurich, Switzerland || 2Physik-Institut, University of Zurich, Zurich, Switzerland || J ... (truncated) ||  || ```json || { || ""title"": ""Large Language Models for Physics Instrument Design"", || ""authors"": [""Sara Zoccheddu1"", ""Shah Rukh Qasim1"", ""Patrick Owen2"", ""Nicola Serra1""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Large Language Models"", ""Physics Instrument Design"", ""Reinforcement Learning"", ""Detector Design"", ""Particle-Matter Interactions""], || ""summary"": ""This study investigates the use of large language models (LLMs) for physics instrument design and compares their performance to reinforcement learning (RL). LLMs, given task constraints and summaries of prior high-scoring designs, propose complete detector configurations. Despite lacking task-specific training, modern LLMs consistently generate valid, resource-aware, and physically meaningful configurations. The findings suggest that LLMs are well-suited as meta-planners, capable of designing and orchestrating RL-based optimization studies, defining search strategies, and coordinating multiple interacting components within a unified workflow. This research points toward automated, closed-loop instrument design, reducing human effort required for optimization structuring and supervision."" || } ||  ||  || [ Prompt: 12.6 t/s | Generation: 5.5 t/s ]"
2601.07582v2_ES-Mem Event Segmentation-Based Memory for Long-Te.pdf,ES-Mem: Event Segmentation-Based Memory for Long-Term Dialogue Agents,"['Huhai Zou', 'Tianhao Sun', 'Chuanjiang He', 'Yu Tian', 'Zhenyang Li', 'Li Jin', 'Nayu Liu', 'Jiang Zhong', 'Kaiwen Wei']",,5.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ES-Mem: Event Segmentation-Based Memory for Long-Term || Dialogue Agents || Huhai Zou1, Tianhao Sun1, Chuanjiang He1, Yu Tian2, Zhenyang Li3, || Li Jin4,Nayu Liu 5,Jiang Zhong 1,Kaiwen Wei 1 || 1College of Computer Science, Chongqing University 2Tsinghua University || 3Hong Kong Generative AI Rese ... (truncated) ||  || { || ""title"": ""ES-Mem: Event Segmentation-Based Memory for Long-Term Dialogue Agents"", || ""authors"": [""Huhai Zou"", ""Tianhao Sun"", ""Chuanjiang He"", ""Yu Tian"", ""Zhenyang Li"", ""Li Jin"", ""Nayu Liu"", ""Jiang Zhong"", ""Kaiwen Wei""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Memory"", ""Dialogue Agents"", ""Event Segmentation"", ""Hierarchical Memory"", ""Long-Term Interaction"", ""Context Localization""], || ""summary"": ""Memory is critical for dialogue agents to maintain coherence and enable continuous adaptation in long-term interactions. Existing memory mechanisms offer basic storage and retrieval capabilities but are hindered by rigid memory granularity and flat retrieval paradigms. ES-Mem, a framework incorporating dynamic event segmentation and a hierarchical memory architecture, mitigates these limitations by leveraging boundary semantics to anchor specific episodic memory. Evaluations on memory benchmarks demonstrate consistent performance gains over baseline methods. The proposed event segmentation module also exhibits robust applicability on dialogue segmentation datasets."" || } ||  || [ Prompt: 12.4 t/s | Generation: 5.1 t/s ]"
2601.07597v1_Pheromone-Focused Ant Colony Optimization algorith.pdf,Pheromone-Focused Ant Colony Optimization algorithm for path planning,"['Yi Liu', 'Hongda Zhang', 'Zhongxue Gan', 'Yuning Chen', 'Ziqing Zhou', 'Chunlei Meng', 'Chun Ouyang']",,12.5,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Pheromone-Focused Ant Colony Optimization algorithm for path || planning || Yi Liu 1 Hongda Zhang 1 Zhongxue Gan 1, Yuning Chen1 Ziqing Zhou 1 Chunlei Meng 1 Chun Ouyang1, || Abstract Ant Colony Optimization (ACO) is a prominent || swarm intelligence algorithm extensively applied to path plan- || ... (truncated) ||  || { || ""title"": ""Pheromone-Focused Ant Colony Optimization algorithm for path planning"", || ""authors"": [""Yi Liu"", ""Hongda Zhang"", ""Zhongxue Gan"", ""Yuning Chen"", ""Ziqing Zhou"", ""Chunlei Meng"", ""Chun Ouyang""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Ant Colony Optimization"", ""Path Planning"", ""Pheromone-Focused"", ""Forward-Looking Mechanism"", ""Convergence Speed"", ""Solution Quality""], || ""summary"": ""Ant Colony Optimization (ACO) is a prominent swarm intelligence algorithm widely applied to path planning. However, traditional ACO methods often exhibit shortcomings such as blind search behavior and slow convergence in complex environments. This paper proposes the Pheromone-Focused Ant Colony Optimization (PFACO) algorithm, which introduces three key strategies to enhance the problem-solving ability of the ant colony. These strategies include concentrating initial pheromone distribution in more promising regions, reinforcing promising solutions during colony iterations, and implementing a forward-looking mechanism to penalize redundant path turns. These strategies collectively produce focused pheromones to guide the ant colony's search, enhancing the global optimization capabilities of the PFACO algorithm and significantly improving convergence speed and solution quality across diverse optimization problems. Experimental results demonstrate that PFACO consistently outperforms comparative ACO algorithms in terms of convergence speed and solution quality."" || } ||  || [ Prompt: 13.8 t/s | Generation: 12.5 t/s ]"
2601.07606v1_Proof of Time A Benchmark for Evaluating Scientifi.pdf,Proof of Time: A Benchmark for Evaluating Scientific Idea Judgments,"['Bingyang Ye', 'Shan Chen', 'Jingxuan Tu', 'Chen Liu', 'Zidi Xiong', 'Samuel Schmidgall', 'Danielle S. Bitterman']",,12.5,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Proof of Time: A Benchmark for Evaluating Scientific Idea Judgments || Bingyang Ye1,2, Shan Chen1,2,3, Jingxuan Tu4, Chen Liu5, || Zidi Xiong1, Samuel Schmidgall6, Danielle S. Bitterman1,2,3 || Co-first authors, Corresponding author:dbitterman@bwh.harvard.edu || 1Harvard University, 2Mass Gener ... (truncated) ||  || { || ""title"": ""Proof of Time: A Benchmark for Evaluating Scientific Idea Judgments"", || ""authors"": [""Bingyang Ye"", ""Shan Chen"", ""Jingxuan Tu"", ""Chen Liu"", ""Zidi Xiong"", ""Samuel Schmidgall"", ""Danielle S. Bitterman""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""scientific idea evaluation"", ""benchmarking"", ""time-indexed scientific questions"", ""agent-based research judgments"", ""peer-review awards"", ""future-facing scientific judgment tasks""], || ""summary"": ""Proof of Time (PoT) is a semi-verifiable benchmarking framework introduced to evaluate the quality of large language models' judgments about scientific ideas. PoT freezes a pre-cutoff snapshot of evidence in an offline sandbox and asks models to forecast post-cutoff outcomes, enabling verifiable evaluation when ground truth arrives, scalable benchmarking without exhaustive expert annotation, and analysis of human-model misalignment against signals such as peer-review awards. Across 30K+ instances spanning four benchmark domains, PoT finds that higher interaction budgets generally improve agentic performance, while the benefit of tool use is strongly task dependent. By combining time-partitioned, future-verifiable targets with an offline sandbox for tool use, PoT supports scalable evaluation of agents on future-facing scientific idea judgment tasks."" || } ||  || [ Prompt: 38.5 t/s | Generation: 12.5 t/s ]"
2601.07611v1_DIAGPaper Diagnosing Valid and Specific Weaknesses.pdf,DIAGPaper: Diagnosing Valid and Specific Weaknesses in Scientific Papers via Multi-Agent Reasoning,"['Zhuoyang Zou', 'Abolfazl Ansari', 'Delvin Ce Zhang', 'Dongwon Lee', 'Wenpeng Yin']",,7.2,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DIAGPaper: Diagnosing Valid and Specific Weaknesses in Scientific Papers || via Multi-Agent Reasoning || Zhuoyang Zou, Abolfazl Ansari, Delvin Ce Zhang, Dongwon Lee, Wenpeng Yin || Penn State University; University of Sheffield || {zhuoyangzou,wenpeng}@psu.edu || Abstract || Paper weakness identifica ... (truncated) ||  || { || ""title"": ""DIAGPaper: Diagnosing Valid and Specific Weaknesses in Scientific Papers via Multi-Agent Reasoning"", || ""authors"": [""Zhuoyang Zou"", ""Abolfazl Ansari"", ""Delvin Ce Zhang"", ""Dongwon Lee"", ""Wenpeng Yin""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""paper weakness identification"", ""multi-agent reasoning"", ""scientific review"", ""author rebuttal"", ""reviewer bias""], || ""summary"": ""This paper presents DIAGPaper, a novel multi-agent framework designed to address the limitations of existing approaches to identifying weaknesses in scientific papers. The framework integrates three tightly coupled modules: the Customizer module simulates human-defined review criteria and assigns expertise to multiple reviewer agents; the Rebuttal module introduces author agents that engage in structured debates with reviewer agents to validate and refine proposed weaknesses; and the Prioritizer module learns from human review practices to assess the severity of validated weaknesses and presents the top-K most severe ones to users. Experiments on two benchmarks, AAAR and ReviewCritique, demonstrate that DIAGPaper significantly outperforms existing methods by producing more valid and paper-specific weaknesses, while presenting them in a user-oriented, prioritized manner."" || } ||  || [ Prompt: 39.7 t/s | Generation: 7.2 t/s ]"
2601.07618v1_Neural Architecture for Fast and Reliable Coagulat.pdf,Neural Architecture for Fast and Reliable Coagulation Assessment in Clinical Settings: Leveraging Thromboelastography,"['Yulu Wang', 'Ziqian Zeng', 'Jianjun Wu', 'Zhifeng Tang']",,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Neural Architecture for Fast and Reliable Coagulation Assessment in Clinical || Settings: Leveraging Thromboelastography || Yulu Wang1, Ziqian Zeng2, Jianjun Wu2, Zhifeng Tang1 || 1Zhejiang University || 2Huzhou Institute of Zhejiang University || {yulu.wang, zeng155, tangzhifeng}@zju.edu.cn, ... (truncated) ||  || { ""title"": ""Neural Architecture for Fast and Reliable Coagulation Assessment in Clinical Settings: Leveraging Thromboelastography"", ""authors"": [""Yulu Wang"", ""Ziqian Zeng"", ""Jianjun Wu"", ""Zhifeng Tang""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Thromboelastography"", ""Coagulation Assessment"", ""Clinical Settings"", ""Physiological State Reconstruction"", ""Multi-Domain Learning"", ""Drift-Aware Learning""], ""summary"": ""In an ideal medical environment, real-time coagulation monitoring can enable early detection and prompt remediation of risks. However, traditional Thromboelastography (TEG) can only provide such outputs after nearly 1 hour of measurement. The delay might lead to elevated mortality rates. Physiological State Reconstruction (PSR) is a new algorithm designed to take advantage of dynamic changes between individuals and maximize useful information produced by small amounts of clinical data through mapping to reliable predictions and diagnosis. MDFE facilitates integration of varied temporal signals using multi-domain learning and jointly learns high-level temporal interactions together with attention via HLA. The parameterized DAM maintains the stability of computed vital signs. PSR evaluates with 4 TEG-specialized data sets and establishes remarkable performance, with predictions of R2 > 0.98 for coagulation traits and error reduction around half compared to state-of-the-art methods, and halving the inference time. Drift-aware learning suggests a new future with potential uses beyond thrombophilia discovery towards medical AI applications with data scarcity."" }"
2601.07632v2_GeoMotionGPT Geometry-Aligned Motion Understanding.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || GeoMotionGPT: Geometry-Aligned Motion Understanding with Large || Language Models || Zhankai Ye1 Bofan Li1 Yukai Jin1 Shuoqiu Li1 || Wei Wang2 Yanfu Zhang3 Shangqian Gao1* Xin Liu1* || 1Florida State University 2Texas Tech University 3William & Mary University || https://github.com/JYe16/GeoMotion ... (truncated) ||  || { || ""title"": ""GeoMotionGPT: Geometry-Aligned Motion Understanding with Large Language Models"", || ""authors"": [""Zhankai Ye1"", ""Bofan Li1"", ""Yukai Jin1"", ""Shuoqiu Li1"", ""Wei Wang2"", ""Yanfu Zhang3"", ""Shangqiu Gao1*"", ""Xin Liu1*""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""motion understanding"", ""large language models"", ""motion tokenization"", ""semantic embedding"", ""geometry alignment"", ""LLM"", ""motion-language reasoning""], || ""summary"": ""Discrete motion tokenization has enabled LLMs to serve as versatile backbones for motion understanding and motion-language reasoning. However, existing pipelines typically decouple motion quantization from semantic embedding learning, linking them solely via token IDs. This approach fails to effectively align the intrinsic geometry of the motion space with the embedding space, hindering the LLMs capacity for nuanced motion reasoning. We present a novel framework that explicitly enforces orthogonality on both the motion codebook and the LLM embedding space, ensuring that their relational structures naturally mirror each other. Specifically, we employ a decoder-only quantizer with Gumbel-Softmax for differentiable training and balanced codebook usage. To bridge the modalities, we use a sparse projection that maps motion codes into the LLM embedding space while preserving orthogonality. Finally, a two-stage orthonormal regularization schedule enforces soft constraints during tokenizer training and LLM fine-tuning to maintain geometric alignment without hindering semantic adaptation. Extensive experiments on HumanML3D demonstrate that our framework achieves a 20% performance improvement over current state-of-the-art methods, validating that a unified geometric basis effectively empowers the LLM for nuanced motion reasoning."""
2601.07635v2_Learning About Learning A Physics Path from Spin G.pdf,Learning About Learning: A Physics Path from Spin Glasses to Artificial Intelligence,"['Denis D. Caprioti', 'Matheus Haas', 'Constantino F. Vasconcelos', 'Mauricio Girardi-Schappo']",,5.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Learning About Learning: A Physics Path from Spin Glasses to Artificial || Intelligence || Denis D. Caprioti,  Matheus Haas,  Constantino F. Vasconcelos, and Mauricio Girardi-Schappo || NeuroPhysics Laboratory, || Departamento de F  sica, || Universidade Federal de Santa Catarina, Florian opolis  ... (truncated) ||  || ```json || { || ""title"": ""Learning About Learning: A Physics Path from Spin Glasses to Artificial Intelligence"", || ""authors"": [""Denis D. Caprioti"", ""Matheus Haas"", ""Constantino F. Vasconcelos"", ""Mauricio Girardi-Schappo""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Hopfield model"", ""spin glasses"", ""neural networks"", ""artificial intelligence"", ""statistical mechanics"", ""dynamical systems"", ""linear algebra"", ""computational methods""], || ""summary"": ""This paper presents the Hopfield model as a pedagogically rich framework that naturally unifies core topics from undergraduate statistical physics, dynamical systems, linear algebra, and computational methods. It provides a concise and illustrated theoretical introduction grounded in familiar physics concepts, analyzes the model's energy function, dynamics, and pattern stability, and discusses practical aspects of simulation, including a freely available simulation code. The work aims to help prepare physics students to understand, apply, and critically engage with computational tools increasingly central to research, industry, and society."" || } ||  ||  || [ Prompt: 12.2 t/s | Generation: 5.1 t/s ]"
2601.07638v1_SALT-KG A Benchmark for Semantics-Aware Learning o.pdf,SALT-KG: A Benchmark for Semantics-Aware Learning on Enterprise Tables,"['Isaiah Onando Mulang', 'SAP SE', 'mulang.onando@sap.com', 'Felix Sasaki', 'SAP SE', 'felix.sasaki@sap.com', 'Tassilo Klein', 'SAP SE', 'tassilo.klein@sap.com', 'Jonas Kolk', 'SAP SE', 'jonas.kolk@sap.com', 'Nikolay Grechanov', 'SAP SE', 'nikolay.grechanov@sap.com', 'Johannes Hoffart', 'SAP SE', 'johannes.hoffart01@sap.com']",,12.3,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SALT-KG: A Benchmark for Semantics-Aware || Learning on Enterprise Tables || Isaiah Onando Mulang || SAP SE || mulang.onando@sap.com || Felix Sasaki || SAP SE || felix.sasaki@sap.com || Tassilo Klein || SAP SE || tassilo.klein@sap.com || Jonas Kolk || SAP SE || jonas.kolk@sap.com || Nikolay Grechanov || SAP SE || nikolay.grechano ... (truncated) ||  || { ""title"": ""SALT-KG: A Benchmark for Semantics-Aware Learning on Enterprise Tables"", ""authors"": [""Isaiah Onando Mulang"", ""SAP SE"", ""mulang.onando@sap.com"", ""Felix Sasaki"", ""SAP SE"", ""felix.sasaki@sap.com"", ""Tassilo Klein"", ""SAP SE"", ""tassilo.klein@sap.com"", ""Jonas Kolk"", ""SAP SE"", ""jonas.kolk@sap.com"", ""Nikolay Grechanov"", ""SAP SE"", ""nikolay.grechanov@sap.com"", ""Johannes Hoffart"", ""SAP SE"", ""johannes.hoffart01@sap.com""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""SALT"", ""Semantics-Aware Learning"", ""Enterprise Tables"", ""Metadata Knowledge Graph"", ""Operational Business Knowledge"", ""Tabular Data"", ""Relational Prediction"", ""Foundation Models"", ""Declarative Knowledge""], ""summary"": ""Building upon the SALT benchmark for relational prediction, we introduce SALT-KG, a benchmark for semantics-aware learning on enterprise tables. SALT-KG extends SALT by linking its multi-table transactional data with a structured Operational Business Knowledge represented in a Metadata Knowledge Graph (OBKG) that captures field-level descriptions, relational dependencies, and business object-types. This extension enables evaluation of models that jointly reason over tabular evidence and contextual semantics, an increasingly critical capability for foundation models on structured data. Empirical analysis reveals that while metadata-derived features yield modest improvements in classical prediction metrics, these metadata features consistently highlight gaps in models' ability to leverage semantics in relational context. By reframing tabular prediction as semantics-conditioned reasoning, SALT-KG establishes a benchmark to advance tabular FMs grounded in declarative knowledge, providing the first empirical step toward semantically linked tables in structured data at enterprise scale."" } ||  || [ Prompt: 16.6 t/s | Generation: 12.3 t/s ]"
2601.07641v1_Beyond Static Tools Test-Time Tool Evolution for S.pdf,Beyond Static Tools: Test-Time Tool Evolution for Scientific Reasoning,"['Jiaxuan Lu', 'Ziyu Kong', 'Yemin Wang', 'Rong Fu', 'Haiyuan Wan', 'Cheng Yang', 'Wenjie Lou', 'Haoran Sun', 'Lilong Wang', 'Yankai Jiang', 'Xiaosong Wang', 'Xiao Sun', 'Dongzhan Zhou']",,9.4,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Beyond Static Tools: Test-Time Tool Evolution for Scientific Reasoning || Jiaxuan Lu1,, Ziyu Kong2,, Yemin Wang3,, Rong Fu4, Haiyuan Wan1,5, || Cheng Yang6, Wenjie Lou1, Haoran Sun1, Lilong Wang1, || Yankai Jiang1, Xiaosong Wang1, Xiao Sun1, Dongzhan Zhou1, || 1Shanghai Artificial Intelligence  ... (truncated) ||  || { || ""title"": ""Beyond Static Tools: Test-Time Tool Evolution for Scientific Reasoning"", || ""authors"": [""Jiaxuan Lu"", ""Ziyu Kong"", ""Yemin Wang"", ""Rong Fu"", ""Haiyuan Wan"", ""Cheng Yang"", ""Wenjie Lou"", ""Haoran Sun"", ""Lilong Wang"", ""Yankai Jiang"", ""Xiaosong Wang"", ""Xiao Sun"", ""Dongzhan Zhou""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Test-Time Tool Evolution"", ""Scientific Reasoning"", ""AI for Science"", ""Tool Evolution"", ""Computational Methods"", ""Open-Ended Scientific World""], || ""summary"": ""The central challenge of AI for Science is not reasoning alone, but the ability to create computational methods in an open-ended scientific world. Existing LLM-based agents rely on static, pre-defined tool libraries, a paradigm that fundamentally fails in scientific domains where tools are sparse, heterogeneous, and intrinsically incomplete. In this paper, we propose Test-Time Tool Evolution (TTE), a new paradigm that enables agents to synthesize, verify, and evolve executable tools during inference. By transforming tools from fixed resources into problem-driven artifacts, TTE overcomes the rigidity and long-tail limitations of static tool libraries. To facilitate rigorous evaluation, we introduce SciEvo, a benchmark comprising 1,590 scientific reasoning tasks supported by 925 automatically evolved tools. Extensive experiments show that TTE achieves state-of-the-art performance in both accuracy and tool efficiency, while enabling effective cross-domain adaptation of computational tools. The code and benchmark have been released at https://github.com/lujiaxuan0520/Test-Time-Tool-Evol."" || } ||  || [ Prompt: 32.8 t/s | Generation: 9.4 t/s ]"
2601.07651v1_Active Evaluation of General Agents Problem Defini.pdf,Active Evaluation of General Agents: Problem Definition and Comparison of Baseline Algorithms,"['Marc Lanctot', 'Kate Larson', 'Ian Gemp', 'Michael Kaisers']",,5.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Active Evaluation of General Agents: Problem || Definition and Comparison of Baseline Algorithms || Marc Lanctot || Google DeepMind || lanctot@google.com || Kate Larson || Google DeepMind, University of Waterloo || katelarson@google.com || Ian Gemp || Google DeepMind || imgemp@google.com || Michael Kaisers || Google D ... (truncated) ||  || { || ""title"": ""Active Evaluation of General Agents: Problem Definition and Comparison of Baseline Algorithms"", || ""authors"": [""Marc Lanctot"", ""Kate Larson"", ""Ian Gemp"", ""Michael Kaisers""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""general evaluation"", ""multitask evaluation"", ""ranking"", ""active learning"", ""game theory"", ""social choice theory""], || ""summary"": ""As intelligent agents become more generally-capable, the complexity and cost of evaluating them rise significantly. This paper proposes a formal definition and conceptual framework for active evaluation of agents across multiple tasks, assessing the performance of ranking algorithms. It compares several baselines under different experimental contexts, including synthetic data and simulated access to real evaluation data from Atari game-playing agents. The classical Elo rating system is found to be consistently reliable for reducing ranking error, while Soft Condorcet Optimization shows comparable performance on synthetic data and significantly outperforms Elo on real data. The effectiveness of task selection based on proportional representation is also discussed."" || } ||  || [ Prompt: 12.6 t/s | Generation: 5.1 t/s ]"
2601.07654v1_Towards Automating Blockchain Consensus Verificati.pdf,Towards Automating Blockchain Consensus Verification with IsabeLLM,"['Elliot Jones', 'William Knottenbelt']",,5.6,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Towards Automating Blockchain Consensus || Verification with IsabeLLM || Elliot Jones1 and William Knottenbelt || Department of Computing, Imperial College London, United Kingdom || 1e.jones24@imperial.ac.uk || Abstract.Consensus protocols are crucial for a blockchain system as || they are what allow ... (truncated) ||  || { || ""title"": ""Towards Automating Blockchain Consensus Verification with IsabeLLM"", || ""authors"": [""Elliot Jones"", ""William Knottenbelt""], || ""doi"": """", || ""arxiv_id"": ""2601.07654v1"", || ""keywords"": [""Blockchain"", ""Consensus"", ""Formal Verification"", ""Theorem Proving"", ""Artificial Intelligence""], || ""summary"": ""Consensus protocols are crucial for blockchain systems as they ensure agreement between nodes in a potentially adversarial environment. Formal verification is essential for ensuring their correctness, but it requires high levels of effort and expertise. This paper presents IsabeLLM, a tool that integrates Isabelle with a Large Language Model to automate proofs. It demonstrates the effectiveness of IsabeLLM by verifying a novel model of Bitcoin's Proof of Work consensus protocol. The DeepSeek R1 API is used for this demonstration, and correct proofs for non-trivial lemmas are generated."" || } ||  || [ Prompt: 13.0 t/s | Generation: 5.6 t/s ]"
2601.07663v2_Reasoning Models Will Blatantly Lie About Their Re.pdf,Reasoning Models Will Blatantly Lie About Their Reasoning,"['William Walden', 'Johns Hopkins University']",,5.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Reasoning Models Will Blatantly Lie About Their Reasoning || William Walden || Johns Hopkins University || wwalden1@jh.edu || Abstract || It has been shown that Large Reasoning Mod- || els (LRMs) may notsay what they think: they || do not always volunteer information about how || certain parts of the input ... (truncated) ||  || { ""title"": ""Reasoning Models Will Blatantly Lie About Their Reasoning"", ""authors"": [""William Walden"", ""Johns Hopkins University""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Large Reasoning Models"", ""CoT Faithfulness"", ""Model Misrepresentation"", ""Multiple Choice Questions""], ""summary"": ""This study extends the work of Chen et al. (2025) to demonstrate that Large Reasoning Models (LRMs) will not only omit information about how hints influence their reasoning but will also lie about it. Specifically, LRMs will deny using hints in answering multiple choice questions even when allowed to use hints and when experimentally shown to be using the hints. This results in discouraging implications for CoT monitoring and interpretability. The study identifies unusual content in the prompt and explicitly instructs models to check for it, revealing the models' tendency to deny using hints. This work highlights the need for better monitoring and interpretability of LRMs' reasoning processes."" } ||  || [ Prompt: 12.9 t/s | Generation: 5.1 t/s ]"
2601.07666v1_Variational Contrastive Learning for Skeleton-base.pdf,Variational Contrastive Learning for Skeleton-based Action Recognition,"['Dang-Dinh NGUYEN1', 'Decky ASPANDI-LATIF1', 'Titus ZAHARIA1']",,5.5,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Variational Contrastive Learning for || Skeleton-based Action Recognition || Dang-Dinh NGUYEN1, Decky ASPANDI-LATIF1, and Titus ZAHARIA1 || Dpartement ARTEMIS, Tlcom SudParis, Institut Polytechnique de Paris, France || {firstname.lastname}@telecom-sudparis.eu || Abstract.In recent years, self-supe ... (truncated) ||  || ```json || { || ""title"": ""Variational Contrastive Learning for Skeleton-based Action Recognition"", || ""authors"": [""Dang-Dinh NGUYEN1"", ""Decky ASPANDI-LATIF1"", ""Titus ZAHARIA1""], || ""doi"": """", || ""arxiv_id"": ""2601.07666v1"", || ""keywords"": [""Human Action Recognition"", ""Self - Supervised Learning"", ""Variational Inference""], || ""summary"": ""In recent years, self-supervised representation learning for skeleton-based action recognition has advanced with the development of contrastive learning methods. However, most contrastive paradigms are inherently discriminative and often struggle to capture the variability and uncertainty intrinsic to human motion. To address this issue, we propose a variational contrastive learning framework that integrates probabilistic latent modeling with contrastive self-supervised learning. This formulation enables the learning of structured and semantically meaningful representations that generalize across different datasets and supervision levels. Extensive experiments on three widely used skeleton-based action recognition benchmarks show that our proposed method consistently outperforms existing approaches, particularly in low-label regimes. Moreover, qualitative analyses show that the features provided by our method are more relevant given the motion and sample characteristics, with more focus on important skeleton joints, when compared to the other methods."" || } ||  ||  || [ Prompt: 13.2 t/s | Generation: 5.5 t/s ]"
2601.07667v1_Adaptive Layer Selection for Layer-Wise Token Prun.pdf,Adaptive Layer Selection for Layer-Wise Token Pruning in LLM Inference,"['Rei Taniguchi', 'Yuyang Dong', 'Makoto Onizuka', 'Chuan Xiao']",,11.2,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Adaptive Layer Selection for Layer-Wise Token Pruning in LLM Inference || 1Rei Taniguchi,2Yuyang Dong,1Makoto Onizuka, 1,3Chuan Xiao || 1Osaka University,2SB Intuitions, 3Nagoya University || {taniguchi.rei, onizuka, chuanx}@ist.osaka-u.ac.jp, yuyang.dong@sbintuitions.co.jp || Abstract || Due to t ... (truncated) ||  || ```json || { || ""title"": ""Adaptive Layer Selection for Layer-Wise Token Pruning in LLM Inference"", || ""authors"": [""Rei Taniguchi"", ""Yuyang Dong"", ""Makoto Onizuka"", ""Chuan Xiao""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Large Language Models"", ""Key-Value Cache"", ""Token Pruning"", ""Attention Patterns"", ""Transformer Layers""], || ""summary"": ""Due to the prevalence of large language models (LLMs), key-value (KV) cache reduction for LLM inference has received remarkable attention. Among numerous works that have been proposed in recent years, layer-wise token pruning approaches, which select a subset of tokens at particular layers to retain in KV cache and prune others, are one of the most popular schemes. However, such design is inflexible in the sense that the accuracy significantly varies across tasks and deteriorates in harder tasks such as KV retrieval. This paper proposes ASL, a training-free method that adaptively chooses the selection layer for KV cache reduction, exploiting the variance of token ranks ordered by attention score. The proposed method balances the performance across different tasks while meeting the user-specified KV budget requirement. ASL operates during the pre-filling stage and can be jointly used with existing KV cache reduction methods such as SnapKV to optimize the decoding stage. By evaluations on the InfiniteBench, RULER, and NIAH benchmarks, we show that equipped with one-shot token selection, where tokens are selected at a layer and propagated to deeper layers, ASL outperforms state-of-the-art layer-wise token selection methods in accuracy while maintaining decoding speed and KV cache reduction."" || } ||  ||  || [ Prompt: 28.1 t/s | Generation: 11.2 t/s ]"
2601.07685v1_Predictive Analytics for Dementia Machine Learning.pdf,Predictive Analytics for Dementia: Machine Learning on Healthcare Data,"['1st Shafiul Ajam Opee', '2nd Nafiz Fahad', '3rd Anik Sen', '4th Rasel Ahmed', '5th Fariha Jahan', '6th Md. Kishor Morol', '7th Md Rashedul Islam']",,8.2,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Predictive Analytics for Dementia: Machine || Learning on Healthcare Data || 1st Shafiul Ajam Opee || Faculty of Science & Technology || American International University-Bangladesh || Dhaka, Bangladesh || opee.cse@gmail.com || 2nd Nafiz Fahad || Faculty of Information Science & Technology || Multimedia Unive ... (truncated) ||  || { ""title"": ""Predictive Analytics for Dementia: Machine Learning on Healthcare Data"", ""authors"": [""1st Shafiul Ajam Opee"", ""2nd Nafiz Fahad"", ""3rd Anik Sen"", ""4th Rasel Ahmed"", ""5th Fariha Jahan"", ""6th Md. Kishor Morol"", ""7th Md Rashedul Islam""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Dementia"", ""Machine learning"", ""Linear Discriminant Analysis (LDA)"", ""APOE-4 allele""], ""summary"": ""Dementia is a complex syndrome impacting cognitive and emotional functions, with Alzheimers disease being the most common form. This study focuses on enhancing dementia prediction using machine learning (ML) techniques on patient health data. Supervised learning algorithms are applied in this study, including K-Nearest Neighbors (KNN), Quadratic Discriminant Analysis (QDA), Linear Discriminant Analysis (LDA), and Gaussian Process Classifiers. To address class imbalance and improve model performance, techniques such as Synthetic Minority Over-sampling Technique (SMOTE) and Term Frequency-Inverse Document Frequency (TF-IDF) vectorization were employed. Among the models, LDA achieved the highest testing accuracy of 98%. This study highlights the importance of model interpretability and the correlation of dementia with features such as the presence of the APOE-4 allele and chronic conditions like diabetes. This research advocates for future ML innovations, particularly in integrating explainable AI approaches, to further improve predictive capabilities in dementia care."" } ||  || [ Prompt: 33.4 t/s | Generation: 8.2 t/s ]"
2601.07701v1_Deep Whole-body Parkour.pdf,Deep Whole-Body Parkour,"['Ziwen Zhuang', 'Shaoting Zhu', 'Mengjie Zhao', 'Hang Zhao']",,5.2,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Deep Whole-body Parkour || Ziwen Zhuang 12, Shaoting Zhu 12, Mengjie Zhao 1 and Hang Zhao 12 || 1IIIS, Tsinghua University, 2Shanghai Qi Zhi Institute || Corresponding Author || Fig. 1:Deep Whole-Body Parkour.Our framework enables a humanoid robot to autonomously traverse challenging obstacles || ... (truncated) ||  || { ""title"": ""Deep Whole-Body Parkour"", ""authors"": [""Ziwen Zhuang"", ""Shaoting Zhu"", ""Mengjie Zhao"", ""Hang Zhao""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Deep Reinforcement Learning"", ""Humanoid Robotics"", ""Parkour"", ""Dynamic Motion Tracking"", ""Perceptive General Motion Control""], ""summary"": ""This work presents a framework where exteroceptive sensing is integrated into whole-body motion tracking, enabling a humanoid robot to perform highly dynamic, non-locomotion tasks on uneven terrain. By training a single policy to perform multiple distinct motions across varied terrestrial features, the framework demonstrates the non-trivial benefit of integrating perception into the control loop. Results show that this framework enables robust, highly dynamic multi-contact motionssuch as vaulting and dive-rollingon unstructured terrain, significantly expanding the robot's traversability beyond simple walking or running."" } ||  || [ Prompt: 13.4 t/s | Generation: 5.2 t/s ]"
2601.07718v1_Hiking in the Wild A Scalable Perceptive Parkour F.pdf,Hiking in the Wild: A Scalable Perceptive Parkour Framework for Humanoids,"['Shaoting Zhu', 'Ziwen Zhuang', 'Mengjie Zhao', 'Kun-Ying Lee', 'Hang Zhao']",,5.7,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Hiking in the Wild: A Scalable Perceptive Parkour || Framework for Humanoids || Shaoting Zhu 12, Ziwen Zhuang 12, Mengjie Zhao 1, Kun-Ying Lee 3, Hang Zhao 12 || 1IIIS, Tsinghua University, 2Shanghai Qi Zhi Institute, || 3Department of Computer Science and Technology, Tsinghua University || Equal  ... (truncated) ||  || { ""title"": ""Hiking in the Wild: A Scalable Perceptive Parkour Framework for Humanoids"", ""authors"": [""Shaoting Zhu"", ""Ziwen Zhuang"", ""Mengjie Zhao"", ""Kun-Ying Lee"", ""Hang Zhao""], ""doi"": """", ""arxiv_id"": ""2601.07718"", ""keywords"": [""Humanoid Robotics"", ""Parkour"", ""Perception"", ""Reinforcement Learning"", ""Safety Mechanisms""], ""summary"": ""This work presents Hiking in the Wild, a scalable, end-to-end parkour perceptive framework designed for robust humanoid hiking in complex, unstructured environments. The framework enables a humanoid robot to traverse diverse terrains in both indoor and outdoor environments. It can run at a maximum speed of 2.5 m/s over complex terrain and negotiate stairs, gaps, high platforms, and ramps. The framework relies on depth images for perception and achieves robust performance across these scenarios. Two key mechanisms are introduced: a foothold safety mechanism combining scalable Terrain Edge Detection with Foot Volume Points to prevent catastrophic slippage on edges, and a Flat Patch Sampling strategy to mitigate reward hacking by generating feasible navigation targets. The approach utilizes a single-stage reinforcement learning scheme, mapping raw depth inputs and proprioception directly to joint actions, without relying on external state estimation. Extensive field experiments on a full-size humanoid demonstrate the effectiveness of the policy."" } ||  || [ Prompt: 13.8 t/s | Generation: 5.7 t/s ]"
2601.07737v1_Evaluating the encoding competence of visual langu.pdf,Evaluating the encoding competence of visual language models using uncommon actions,['Chen Ling'],,6.4,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Undergraduate Project Report || Evaluating the encoding competence of || visual language models using uncommon || actions || Author: Chen Ling || Ailiation: Beijing University of Post and Telecommunications || Email: 20212127000@bupt.edu.cn || Supervisor: Nai Ding* || Ailiation: Zhejiang University || Email:  ... (truncated) ||  || { ""title"": ""Evaluating the encoding competence of visual language models using uncommon actions"", ""authors"": [""Chen Ling""], ""doi"": """", ""arxiv_id"": ""2601.07737v1"", ""keywords"": [""visual language models"", ""encoding competence"", ""uncommon actions""], ""summary"": ""This report evaluates the encoding competence of visual language models using uncommon actions. The evaluation is conducted by Chen Ling under the supervision of Nai Ding. The model's performance is analyzed to understand how well it can encode and interpret actions that are not commonly encountered in the training data."" } ||  || [ Prompt: 10.6 t/s | Generation: 6.4 t/s ]"
2601.07748v1_Improving Domain Generalization in Contrastive Lea.pdf,Improving Domain Generalization in Contrastive Learning using Adaptive Temperature Control,"['Robert Lewis', 'Katie Matton', 'Rosalind W. Picard', 'John Guttag']",,5.3,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Improving Domain Generalization in Contrastive || Learning using Adaptive Temperature Control || Robert Lewis || Massachusetts Institute of Technology || Cambridge, MA, USA || roblewis@mit.edu || Katie Matton || Massachusetts Institute of Technology || Cambridge, MA, USA || kmatton@mit.edu || Rosalind W. Picard || ... (truncated) ||  || { || ""title"": ""Improving Domain Generalization in Contrastive Learning using Adaptive Temperature Control"", || ""authors"": [""Robert Lewis"", ""Katie Matton"", ""Rosalind W. Picard"", ""John Guttag""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""contrastive learning"", ""domain generalization"", ""covariate shift"", ""adaptive temperature control""], || ""summary"": ""Self-supervised pre-training with contrastive learning is effective for learning from sparsely labeled data. However, performance drops when data distribution shifts from training to test time. This study examines a setting with multiple training domains and a test domain subject to significant covariate shift. A new method incorporating domain labels is presented to increase domain invariance of learned representations, leading to improved out-of-distribution generalization. The method adjusts the temperature parameter in the InfoNCE loss to upweight pairs from more similar domains, encouraging domain-invariant attribute discrimination. Experiments on a variant of the MNIST dataset demonstrate better out-of-distribution performance than domain generalization baselines, while maintaining strong in-distribution task performance."" || } ||  || [ Prompt: 12.5 t/s | Generation: 5.3 t/s ]"
2601.07778v1_DT-ICU Towards Explainable Digital Twins for ICU P.pdf,DT-ICU: Towards Explainable Digital Twins for ICU Patient Monitoring via Multi-Modal and Multi-Task Iterative Inference,['Wen Guo'],,15.3,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DT-ICU: Towards Explainable Digital Twins for || ICU Patient Monitoring via Multi-Modal and || Multi-Task Iterative Inference || Wen Guo || ETH Zurich, Switzerland. || Contributing authors: guowen0903@hotmail.com; || Abstract || We introduce DT-ICU, a multimodal digital twin framework for continuous ris ... (truncated) ||  || { ""title"": ""DT-ICU: Towards Explainable Digital Twins for ICU Patient Monitoring via Multi-Modal and Multi-Task Iterative Inference"", ""authors"": [""Wen Guo""], ""doi"": """", ""arxiv_id"": ""2601.07778v1"", ""keywords"": [""Digital Twin"", ""ICU Monitoring"", ""Multi-Modal"", ""Multi-Task"", ""Iterative Inference"", ""Heterogeneous Data""], ""summary"": ""Introduces DT-ICU, a multimodal digital twin framework for continuous risk estimation in intensive care. Integrates clinical time series and static patient information in a unified multitask architecture, enabling predictions to be updated as new observations accumulate. Evaluates on the MIMIC-IV dataset, consistently outperforming baseline models. Demonstrates meaningful discrimination shortly after admission and further improvement with longer observation windows. Reveals model's reliance on interventions, physiological responses, and contextual information. Provides interpretable insights into multimodal signal combination and trade-offs between sensitivity and precision. Supports DT-ICU as a practical digital twin framework for continuous patient monitoring in critical care."" } ||  || [ Prompt: 12.7 t/s | Generation: 15.3 t/s ]"
2601.07779v1_OS-Symphony A Holistic Framework for Robust and Ge.pdf,OS-SYMPHONY: A Holistic Framework for Robust and Generalist Computer-Using Agent,"['Bowen Yang', 'Kaiming Jin', 'Zhenyu Wu', 'Zhaoyang Liu', 'Qiushi Sun', 'Zehao Li', 'Jingjing Xie', 'Zhoumianze Liu', 'Fangzhi Xu', 'Kanzhi Cheng', 'Qingyun Li', 'Yian Wang', 'Yu Qiao', 'Zun Wang', 'Zichen Ding']",,11.2,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || OS-SYMPHONY: A Holistic Framework for Robust and Generalist || Computer-Using Agent || Bowen Yang1,2 *, Kaiming Jin3 , Zhenyu Wu2, Zhaoyang Liu4, Qiushi Sun5, Zehao Li2, || Jingjing Xie6,Zhoumianze Liu 2,Fangzhi Xu 7,Kanzhi Cheng 8,Qingyun Li 9,Yian Wang 3, || Yu Qiao2,Zun Wang 2,Zichen Ding 2 || ... (truncated) ||  || ```json || { || ""title"": ""OS-SYMPHONY: A Holistic Framework for Robust and Generalist Computer-Using Agent"", || ""authors"": [""Bowen Yang"", ""Kaiming Jin"", ""Zhenyu Wu"", ""Zhaoyang Liu"", ""Qiushi Sun"", ""Zehao Li"", ""Jingjing Xie"", ""Zhoumianze Liu"", ""Fangzhi Xu"", ""Kanzhi Cheng"", ""Qingyun Li"", ""Yian Wang"", ""Yu Qiao"", ""Zun Wang"", ""Zichen Ding""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""OS-SYMPHONY"", ""Computer-Using Agent"", ""Vision-Language Models"", ""Holistic Framework"", ""Robust Automation"", ""Generalization"", ""Long-Horizon Workflows"", ""Tutorial Retrieval"", ""Trajectory-Level Self-Correction"", ""Multimodal Searcher"", ""Browser-Based Sandbox""], || ""summary"": ""OS-SYMPHONY is a holistic framework designed to address the limitations of current Computer-Using Agent (CUA) frameworks, particularly in robustness and generalization. It introduces two key innovations: a Reflection-Memory Agent that utilizes milestone-driven long-term memory for trajectory-level self-correction and a Versatile Tool Agent with a Multimodal Searcher to navigate a browser-based sandbox and synthesize live, visually aligned tutorials. Experimental results demonstrate substantial performance gains across varying model scales, establishing new state-of-the-art results on three online benchmarks, notably achieving 65.84% on OSWorld. The framework is publicly available at /githubOS-Copilot/OS-Symphony and /glbeOS-Symphony Homepage."" || } ||  ||  || [ Prompt: 31.9 t/s | Generation: 11.2 t/s ]"
2601.07782v1_Beyond Single-Shot Multi-step Tool Retrieval via Q.pdf,Beyond Single-Shot: Multi-step Tool Retrieval via Query Planning,"['Wei Fang', 'James Glass']",,8.4,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Beyond Single-Shot: Multi-step Tool Retrieval via Query Planning || Wei Fang and James Glass || Massachusetts Institute of Technology, Cambridge MA, USA || {weifang,glass}@mit.edu || Abstract || LLM agents operating over massive, dynamic || tool libraries rely on effective retrieval, yet || standard sin ... (truncated) ||  || ```json || { || ""title"": ""Beyond Single-Shot: Multi-step Tool Retrieval via Query Planning"", || ""authors"": [""Wei Fang"", ""James Glass""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""tool retrieval"", ""query planning"", ""reinforcement learning"", ""agent frameworks""], || ""summary"": ""Large language models (LLMs) rely on effective retrieval of tools to solve complex tasks. Standard single-shot dense retrievers struggle with complex requests due to the disconnect between user goals and technical documentation, and the limitations of fixed-size embeddings. We propose TOOLQP, a lightweight framework that models retrieval as iterative query planning, decomposing instructions into sub-tasks and dynamically generating queries to interact with the retriever. TOOLQP achieves state-of-the-art performance, exhibiting superior zero-shot generalization, robustness across diverse retrievers, and significant improvements in downstream agentic execution."" || } ||  ||  || [ Prompt: 38.9 t/s | Generation: 8.4 t/s ]"
2601.07790v1_Benchmarking Small Language Models and Small Reaso.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Benchmarking Small Language Models and Small Reasoning || Language Models on System Log Severity Classification || Yahya Masri || George Mason University || Emily Ma || George Mason University || Zifu Wang || Harvard University || Joseph Rogers || George Mason University || Chaowei Yang || George Mason University || A ... (truncated) ||  || { || ""title"": ""Benchmarking Small Language Models and Small Reasoning Language Models on System Log Severity Classification"", || ""authors"": [""Yahya Masri"", ""Emily Ma"", ""Zifu Wang"", ""Joseph Rogers"", ""Chaowei Yang""], || ""doi"": """", || ""arxiv_id"": ""2601.07790"", || ""keywords"": [""System Logs"", ""Severity Classification"", ""Small Language Models"", ""Small Reasoning Language Models"", ""Zero-Shot"", ""Few-Shot"", ""Retrieval-Augmented Generation"", ""Digital Twins"", ""Root Cause Analysis""], || ""summary"": ""System logs are crucial for monitoring and diagnosing modern computing infrastructure. However, their scale and complexity require reliable and efficient automated interpretation. This paper evaluates nine small language models (SLMs) and small reasoning language models (SRLMs) on real-world journalctl data from Linux production servers under zero-shot, few-shot, and retrieval-augmented generation (RAG) prompting. The results reveal strong stratification, with Qwen3-4B achieving the highest accuracy at 95.64% with RAG, and Gemma3-1B improving from 20.25% under few-shot prompting to 85.28% with RAG. The tiny Qwen3-0.6B reaches 88.12% accuracy despite weak performance without retrieval. Several SRLMs, including Qwen3-1.7B and DeepSeek-R1-Distill-Qwen-1.5B, degrade substantially when paired with RAG. Efficiency measurements further separate models, with most Gemma and Llama variants completing inference in under 1.2 seconds per log, while Phi-4-Mini-Reasoning exceeds 228 seconds per log while achieving <10% accuracy. These findings suggest that architectural design, training objectives, and the ability to integrate retrieved context under strict output constraints jointly determine performance. By emphasizing small, deployable models, this benchmark aligns with real-time requirements of digital twin systems and shows that severity classification serves as a lens for evaluating model competence and real-time deployability, with implications for root cause analysis and broader DT integration."""
2601.07794v1_Kinship Data Benchmark for Multi-hop Reasoning.pdf,Kinship Data Benchmark for Multi-hop Reasoning,"['Tianda Sun', 'Dimitar Kazakov']",,5.3,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Kinship Data Benchmark for Multi-hop Reasoning || Tianda Sun and Dimitar Kazakov || University of York || Department of Computer Science || Heslington, York || YO10 5DD || Abstract || Large language models (LLMs) are increas- || ingly evaluated on their ability to perform multi- || hop reasoning, i.e., to com ... (truncated) ||  || { ""title"": ""Kinship Data Benchmark for Multi-hop Reasoning"", ""authors"": [""Tianda Sun"", ""Dimitar Kazakov""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Kinship"", ""Multi-hop Reasoning"", ""Genealogy"", ""Language Models""], ""summary"": ""Large language models are increasingly evaluated on their ability to perform multi-hop reasoning, combining multiple pieces of information into coherent answers. This paper introduces KinshipQA, a benchmark designed to probe this capability through reasoning over kinship relations. The central contribution is a generative pipeline that produces large-scale, realistic, and culture-specific genealogical data, allowing for systematic control of task difficulty, cultural assumptions, and relational depth. From these genealogies, textual inference tasks requiring reasoning over implicit relational chains are derived. The benchmark is evaluated using six state-of-the-art LLMs, demonstrating systematic differences in multi-hop reasoning across models and cultural settings."" } ||  || [ Prompt: 12.8 t/s | Generation: 5.3 t/s ]"
2601.07821v1_Failure-Aware RL Reliable Offline-to-Online Reinfo.pdf,Failure-Aware RL: Reliable Offline-to-Online Reinforcement Learning with Self-Recovery for Real-World Manipulation,"['Huanyu Li', 'Kun Lei', 'Sheng Zang', 'Kaizhe Hu', 'Yongyuan Liang', 'Bo An', 'Xiaoli Li', 'Huazhe Xu']",,5.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Failure-Aware RL: Reliable Offline-to-Online Reinforcement Learning || with Self-Recovery for Real-World Manipulation || Huanyu Li 1,2, Kun Lei 1,2, Sheng Zang 4, Kaizhe Hu 1,3, Yongyuan Liang 6, Bo An 4, Xiaoli Li 5, Huazhe Xu 1,3 || (a) Franka Fragile Push Wall || (b) Franka Disturbed Push || (c ... (truncated) ||  || ```json || { || ""title"": ""Failure-Aware RL: Reliable Offline-to-Online Reinforcement Learning with Self-Recovery for Real-World Manipulation"", || ""authors"": [""Huanyu Li"", ""Kun Lei"", ""Sheng Zang"", ""Kaizhe Hu"", ""Yongyuan Liang"", ""Bo An"", ""Xiaoli Li"", ""Huazhe Xu""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Reinforcement Learning"", ""Offline-to-Online RL"", ""Failure-Aware"", ""Robotic Manipulation"", ""Intervention-requiring Failures""], || ""summary"": ""Failure-Aware Offline-to-Online Reinforcement Learning (FARL) is introduced to minimize failures during real-world reinforcement learning. FARL integrates a world-model-based safety critic and a recovery policy trained offline to prevent failures during online exploration. Extensive simulation and real-world experiments demonstrate the effectiveness of FARL in significantly reducing Intervention-requiring Failures (IR Failures) while improving performance and generalization during online reinforcement learning post-training. FARL reduces IR Failures by 73.1% while elevating performance by 11.3% on average during real-world RL post-training."" || } ||  ||  || [ Prompt: 13.2 t/s | Generation: 5.1 t/s ]"
2601.07832v2_MHLA Restoring Expressivity of Linear Attention vi.pdf,MHLA: Restoring Expressivity of Linear Attention via Token-Level Multi-Head,"['Kewei Zhang', 'Ye Huang', 'Yufan Deng', 'Jincheng Yu', 'Junsong Chen', 'Huan Ling', 'Enze Xie', 'Daquan Zhou']",,12.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MHLA: Restoring Expressivity of Linear Attention || via Token-Level Multi-Head || Kewei Zhang 1 Ye Huang 1 Yufan Deng 1 Jincheng Yu 2 Junsong Chen 2 || Huan Ling 2 Enze Xie 2 Daquan Zhou 1 || 1Peking University, 2NVIDIA || Equal contribution || Abstract || While the Transformer architecture dominates ma ... (truncated) ||  || ```json || { || ""title"": ""MHLA: Restoring Expressivity of Linear Attention via Token-Level Multi-Head"", || ""authors"": [""Kewei Zhang"", ""Ye Huang"", ""Yufan Deng"", ""Jincheng Yu"", ""Junsong Chen"", ""Huan Ling"", ""Enze Xie"", ""Daquan Zhou""], || ""doi"": """", || ""arxiv_id"": ""2601.07832"", || ""keywords"": [""Transformer"", ""Linear Attention"", ""Multi-Head"", ""Expressive Power"", ""Efficiency""], || ""summary"": ""While the Transformer architecture dominates many fields, its quadratic self-attention complexity\nhinders its use in large-scale applications. Linear attention offers an efficient alternative, but its direct application often degrades performance, with existing fixes typically re-introducing computational overhead through extra modules (e.g., depthwise separable convolution) that defeat the original purpose. In this work, we identify a key failure mode in these methods: global context collapse, where the model loses representational diversity. To address this, we propose Multi-Head Linear Attention (MHLA), which preserves this diversity by computing attention within divided heads along the token dimension. We prove that MHLA maintains linear complexity while recovering much of the expressive power of softmax attention, and verify its effectiveness across multiple domains, achieving a 3.6% improvement on ImageNet classification, a 6.3% gain on NLP, a 12.6% improvement on image generation, and a 41% enhancement on video generation under the same time complexity."" || } ||  ||  || [ Prompt: 13.5 t/s | Generation: 12.1 t/s ]"
2601.07885v1_Small Symbols Big Risks Exploring Emoticon Semanti.pdf,Emoticon Semantic Confusion in Large Language Models,"['Weipeng Jiang', 'Xiaoyu Zhang', 'Juan Zhai', 'Shiqing Ma', 'Chao Shen', 'Yang Liu']",,12.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Small Symbols, Big Risks: Exploring Emoticon Semantic Confusion in || Large Language Models || Weipeng Jiang1*, Xiaoyu Zhang2*, Juan Zhai3, Shiqing Ma3, Chao Shen1, Yang Liu2 || 1Xian Jiaotong University,2Nanyang Technological University,3University of Massachusetts Amherst || lenijwp@stu.xjtu. ... (truncated) ||  || ```json || { || ""title"": ""Emoticon Semantic Confusion in Large Language Models"", || ""authors"": [""Weipeng Jiang"", ""Xiaoyu Zhang"", ""Juan Zhai"", ""Shiqing Ma"", ""Chao Shen"", ""Yang Liu""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Emoticons"", ""Large Language Models"", ""Semantic Confusion"", ""Safety"", ""Security"", ""Digital Communication""], || ""summary"": ""Emoticons are widely used in digital communication to convey affective intent, yet their safety implications for Large Language Models (LLMs) remain largely unexplored. This paper identifies emoticon semantic confusion, a vulnerability where LLMs misinterpret ASCII-based emoticons to perform unintended and even destructive actions. We develop an automated data generation pipeline and construct a dataset containing 3,757 code-oriented test cases spanning 21 meta-scenarios, four programming languages, and varying contextual complexities. Our study on six LLMs reveals that emoticon semantic confusion is pervasive, with an average confusion ratio exceeding 38%. More critically, over 90% of confused responses yield silent failures, which are syntactically valid outputs but deviate from user intent, potentially leading to destructive security consequences. Furthermore, we observe that this vulnerability readily transfers to popular agent frameworks, while existing prompt-based mitigations remain largely ineffective. We call on the community to recognize this emerging vulnerability and develop effective mitigation methods to uphold the safety and reliability of human-AI interactions."" || } ||  ||  || [ Prompt: 35.3 t/s | Generation: 12.1 t/s ]"
2601.07891v1_KVzap Fast Adaptive and Faithful KV Cache Pruning.pdf,"KVzap: Fast, Adaptive, and Faithful KV Cache","['Simon Jgou *', 'Maximilian Jeblick']",,7.9,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || KVzap: Fast, Adaptive, and Faithful KV Cache || Pruning || Simon Jgou * Maximilian Jeblick || NVIDIA/KVzap/githubNVIDIA/kvpress || Abstract.Growing context lengths in transformer-based language models have made the key-value || (KV) cache a critical inference bottleneck. While many KV cache prunin ... (truncated) ||  || { || ""title"": ""KVzap: Fast, Adaptive, and Faithful KV Cache"", || ""authors"": [""Simon Jgou *"", ""Maximilian Jeblick""], || ""doi"": """", || ""arxiv_id"": ""2601.07891v1"", || ""keywords"": [""KV cache"", ""transformer attention"", ""language models"", ""inference bottleneck"", ""compression"", ""adaptive pruning""], || ""summary"": ""Growing context lengths in transformer-based language models have made the key-value (KV) cache a critical inference bottleneck. While many KV cache pruning methods have been proposed, they have not yet been adopted in major inference engines due to speed-accuracy trade-offs. We introduce KVzap, a fast, input-adaptive approximation of KVzip that works in both prefilling and decoding. On Qwen3-8B, Llama-3.1-8B-Instruct, and Qwen3-32B across long-context and reasoning tasks, KVzap achieves 24 KV cache compression with negligible accuracy loss and achieves state-of-the-art performance on the KVpress Leaderboard. Code and models are available at NVIDIA/KVpress."" || } ||  || [ Prompt: 36.8 t/s | Generation: 7.9 t/s ]"
2601.07892v1_Sherry Hardware-Efficient 1.25-Bit Ternary Quantiz.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Sherry: Hardware-Efficient 1.25-Bit Ternary Quantization via || Fine-grained Sparsification || Hong Huang1* Decheng Wu2 Qiangqiang Hu2 Guanghua Yu2 Jinhai Yang1 || Jianchen Zhu2 Xue Liu3 Dapeng Wu1 || 1City University of Hong Kong 2Tencent 3McGill University || Abstract || The deployment of Large Lan ... (truncated) ||  || ```json || { || ""title"": ""Hardware-Efficient 1.25-Bit Ternary Quantization via Fine-grained Sparsification"", || ""authors"": [""Hong Huang1*"", ""Decheng Wu2"", ""Qiangqiang Hu2"", ""Guanghua Yu2"", ""Jinhai Yang1"", ""Jianchen Zhu2"", ""Xue Liu3"", ""Dapeng Wu1""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Hardware-Efficient"", ""Ternary Quantization"", ""Fine-grained Sparsification"", ""1.25-Bit"", ""Edge Devices"", ""Large Language Models"", ""Weight Quantization""], || ""summary"": ""The deployment of Large Language Models (LLMs) on resource-constrained edge devices is increasingly hindered by prohibitive memory and computational requirements. While ternary quantization offers a compelling solution by reducing weights to {1,0,+1}, current implementations suffer from a fundamental misalignment with commodity hardware. Most existing methods must choose between 2-bit aligned packing, which incurs significant bit wastage, or 1.67-bit irregular packing, which degrades inference speed. To resolve this tension, we propose Sherry, a hardware-efficient ternary quantization framework. Sherry introduces a 3:4 fine-grained sparsity that achieves a regularized 1.25-bit width by packing blocks of four weights into five bits, restoring power-of-two alignment. Furthermore, we identify weight trapping issue in sparse ternary training, which leads to representational collapse. To address this, Sherry introduces Arenas, an annealing residual synapse mechanism that maintains representational diversity during training. Empirical evaluations on LLaMA-3.2 across five benchmarks demonstrate that Sherry matches state-of-the-art ternary performance while significantly reducing model size. Notably, on an Intel i7-14700HX CPU, our 1B model achieves zero accuracy loss compared to SOTA baselines while providing 25% bit savings and 10% speed up. The code is available at https://github.com/Tencent/AngelSlim."""
2601.07894v1_Revealing the Attention Floating Mechanism in Mask.pdf,Revealing the Attention Floating Mechanism in Masked Diffusion Models,"['Xin Dai', 'Pengcheng Huang', 'Zhenghao Liu', 'Shuo Wang', 'Yukun Yan', 'Chaojun Xiao', 'Yu Gu', 'Ge Yu', 'Maosong Sun']",,5.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Revealing the Attention Floating Mechanism in Masked Diffusion Models || Xin Dai1, Pengcheng Huang1, Zhenghao Liu1*, Shuo Wang2, || Yukun Yan2, Chaojun Xiao2, Yu Gu1, Ge Yu1, Maosong Sun2 || 1School of Computer Science and Engineering, Northeastern University, Shenyang, China || 2Department of  ... (truncated) ||  || ```json || { || ""title"": ""Revealing the Attention Floating Mechanism in Masked Diffusion Models"", || ""authors"": [""Xin Dai"", ""Pengcheng Huang"", ""Zhenghao Liu"", ""Shuo Wang"", ""Yukun Yan"", ""Chaojun Xiao"", ""Yu Gu"", ""Ge Yu"", ""Maosong Sun""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Masked Diffusion Models"", ""Attention Floating"", ""Diffusion Language Models"", ""Autoregressive Models"", ""Bidirectional Attention"", ""Shallow Structure-Aware"", ""Deep Content-Focused""], || ""summary"": ""Masked diffusion models (MDMs) leverage bidirectional attention and a denoising process to narrow the performance gap with autoregressive models (ARMs). Unlike ARMs, where attention converges to a fixed sink, MDMs exhibit dynamic, dispersed attention anchors that shift across denoising steps and layers. This paper investigates the attention behaviors in MDMs, revealing the phenomenon of Attention Floating. Empirically, this distinctive attention pattern provides a mechanistic explanation for the strong in-context learning capabilities of MDMs, allowing them to double the performance compared to ARMs in knowledge-intensive tasks."" || } ||  ||  || [ Prompt: 12.9 t/s | Generation: 5.1 t/s ]"
2601.07898v1_Large Language Models and Algorithm Execution Appl.pdf,Large Language Models and Algorithm Execution: Application to an Arithmetic Function,"['Farah Ben Slama', 'Frédéric Armetta']",,5.5,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Large Language Models and Algorithm Execution: Application to || an Arithmetic Function || Farah Ben Slama, Frdric Armetta || Universit Claude Bernard Lyon 1, CNRS, || Ecole Centrale de Lyon, INSA Lyon, || Universit Lumire Lyon 2, LIRIS, UMR5205, || 69622 Villeurbanne, France || farah.ben-slama@etu.univ ... (truncated) ||  || { ""title"": ""Large Language Models and Algorithm Execution: Application to an Arithmetic Function"", ""authors"": [""Farah Ben Slama"", ""Frédéric Armetta""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Algorithmic learning in natural language"", ""Supervised learning by decomposition"", ""Large language model"", ""Fine-tuning""], ""summary"": ""Large Language Models (LLMs) have advanced functionalities but struggle with autonomous algorithm execution. This paper investigates extending LLMs' capabilities through specialized supervised training focused on reasoning decomposition. The LLM-DAL model demonstrates significant improvement in complex algorithmic inference and generalization when properly designed to guide the model's learning process."" } ||  || [ Prompt: 12.5 t/s | Generation: 5.5 t/s ]"
2601.07901v1_Decentralized Online Convex Optimization with Unkn.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Decentralized Online Convex Optimization with || Unknown Feedback Delays || Hao Qiu || Universit degli Studi di Milano || hao.qiu@unimi.com || Mengxiao Zhang || University of Iowa || mengxiao-zhang@uiowa.edu || Juliette Achddou || UMR 9189 - CRIStAL, Universit de Lille, CNRS, Inria, Centrale Lille || juliette.ac ... (truncated) ||  || ```json || { || ""title"": ""Decentralized Online Convex Optimization with Unknown Feedback Delays"", || ""authors"": [""Hao Qiu"", ""Mengxiao Zhang"", ""Juliette Achddou""], || ""doi"": """", || ""arxiv_id"": ""2601.07901"", || ""keywords"": [""Decentralized Online Convex Optimization"", ""Unknown Feedback Delays"", ""Adaptive Learning Rate"", ""Decentralized Communication Protocol"", ""Spectral Gap""], || ""summary"": ""This paper studies decentralized online convex optimization (D-OCO) under unknown, time- and agent-varying feedback delays. It proposes a novel algorithm that achieves an improved regret bound of eO(N dtot + N T^(1/4)), where T is the total horizon, dtot denotes the average total delay across agents, N is the number of agents, and 1 ≤ 2 is the spectral gap of the network. The approach incorporates an adaptive learning rate mechanism via a decentralized communication protocol, enabling each agent to estimate delays locally without prior knowledge of the total delay. The paper also extends the framework to the strongly convex setting and derives a sharper regret bound of O(N max ln T + N ln(N) ln(T)), where is the strong convexity parameter and max is the maximum number of missing observations averaged over agents. Experimental results validate the effectiveness of the approach, showing improvements over existing benchmark algorithms."""
2601.07903v2_Enhancing Large Language Models for Time-Series Fo.pdf,Enhancing Large Language Models for Time-Series Forecasting via Vector-Injected In-Context Learning,"['Jianqi Zhang', 'Jingyao Wang', 'Wenwen Qiang', 'Fanjiang Xu', 'Changwen Zheng']",,11.7,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Enhancing Large Language Models for Time-Series Forecasting || via Vector-Injected In-Context Learning || Jianqi Zhang || jluzhangjianqi@163.com || Institute of Software, Chinese || Academy of Sciences; University of || the Chinese Academy of Sciences || Beijing, Beijing, China || Jingyao Wang || Institute of ... (truncated) ||  || { || ""title"": ""Enhancing Large Language Models for Time-Series Forecasting via Vector-Injected In-Context Learning"", || ""authors"": [""Jianqi Zhang"", ""Jingyao Wang"", ""Wenwen Qiang"", ""Fanjiang Xu"", ""Changwen Zheng""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Large Language Models"", ""Time-Series Forecasting"", ""In-Context Learning"", ""Vector-Injected In-Context Learning"", ""Forecasting Performance"", ""Compute Overhead""], || ""summary"": ""The World Wide Web requires reliable predictive capabilities to respond to changes in user behavior and usage patterns. Time series forecasting (TSF) is a key method to achieve this. Large language models (LLMs) for TSF have shown good performance, but there is a significant difference between pretraining corpora and time series data, making it hard to guarantee forecasting quality when directly applying LLMs to TSF. Fine-tuning LLMs mitigates this issue but often incurs substantial computational overhead. To address this, we propose LVICL, a method that uses vector-injected in-context learning to improve LLM4TSF's forecasting performance while freezing all LLM parameters to reduce computational overhead. Extensive experiments demonstrate the effectiveness of our approach."" || } ||  || [ Prompt: 30.4 t/s | Generation: 11.7 t/s ]"
2601.07935v1_Towards Specialized Generalists A Multi-Task MoE-L.pdf,Towards Specialized Generalists: A Multi-Task MoE-LoRA Framework for Domain-Specific LLM Adaptation,"['Yuxin Yang', 'Shanghai University', 'Aoxiong Zeng', 'East China Normal University', 'Xiangquan Yang', 'East China Normal University']",,12.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Towards Specialized Generalists: A Multi-Task || MoE-LoRA Framework for Domain-Specific LLM || Adaptation || Yuxin Yang || Shanghai University || Aoxiong Zeng || East China Normal University || Xiangquan Yang || East China Normal University || Abstract || The rapid evolution of Large Language Models (LLMs) has s ... (truncated) ||  || { ""title"": ""Towards Specialized Generalists: A Multi-Task MoE-LoRA Framework for Domain-Specific LLM Adaptation"", ""authors"": [""Yuxin Yang"", ""Shanghai University"", ""Aoxiong Zeng"", ""East China Normal University"", ""Xiangquan Yang"", ""East China Normal University""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Large Language Models"", ""Domain-Specific Adaptation"", ""Mixture-of-Experts"", ""Low-Rank Adaptation"", ""Medical Applications"", ""Knowledge Overlap"", ""Catastrophic Forgetting""], ""summary"": ""The rapid evolution of Large Language Models (LLMs) has shifted focus from general-purpose capabilities to domain-specific expertise. However, adapting LLMs to specialized fields such as medicine presents two challenges: the Stability-Plasticity Dilemma and Task Interference. We propose Med-MoE-LoRA, a novel framework that integrates Mixture-of-Experts (MoE) with Low-Rank Adaptation (LoRA) to enable efficient multi-task domain adaptation, especially for medical scenarios. By utilizing soft merging with adaptive routing and rank-wise decoupling, Med-MoE-LoRA achieves superior performance in medical benchmarks while reducing interference. Experimental results demonstrate that our approach consistently outperforms standard LoRA and conventional MoE architectures across multiple clinical NLP tasks while retaining the models general cognitive capabilities."" } ||  || [ Prompt: 37.6 t/s | Generation: 12.1 t/s ]"
2601.07939v1_SECite Analyzing and Summarizing Citations in Soft.pdf,SECite: Analyzing and Summarizing Citations in Software Engineering Literature,"['Shireesh Reddy Pyreddy', 'Khaja Valli Pathan', 'Hasan Masum', 'Tarannum Shaila Zaman']",,6.7,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SECite: Analyzing and Summarizing Citations in || Software Engineering Literature || Shireesh Reddy Pyreddy, Khaja Valli Pathan || Dept. of Computer Science || SUNY Polytechnic Institute || Utica, NY , USA || pyredds@sunypoly.edu, pathank@sunypoly.edu || Hasan Masum, Tarannum Shaila Zaman || Dept. of Infor ... (truncated) ||  || { ""title"": ""SECite: Analyzing and Summarizing Citations in Software Engineering Literature"", ""authors"": [""Shireesh Reddy Pyreddy"", ""Khaja Valli Pathan"", ""Hasan Masum"", ""Tarannum Shaila Zaman""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Sentiment Analysis"", ""LLMs"", ""Text Summarization"", ""Citations""], ""summary"": ""Identifying the strengths and limitations of a research paper is a core component of any literature review. However, traditional summaries reflect only the authors' self-presented perspective. Analyzing how other researchers discuss and cite the paper can offer a deeper, more practical understanding of its contributions and shortcomings. In this research, we introduce SECite, a novel approach for evaluating scholarly impact through sentiment analysis of citation contexts. We develop a semi-automated pipeline to extract citations referencing nine research papers and apply advanced natural language processing (NLP) techniques with unsupervised machine learning to classify these citation statements as positive or negative. Beyond sentiment classification, we use generative AI to produce sentiment-specific summaries that capture the strengths and limitations of each target paper, derived both from clustered citation groups and from the full text. Our findings reveal meaningful patterns in how the academic community perceives these works, highlighting areas of alignment and divergence between external citation feedback and the authors' own presentation. By integrating citation sentiment analysis with LLM-based summarization, this study provides a comprehensive framework for assessing scholarly contributions."" } ||  || [ Prompt: 36.9 t/s | Generation: 6.7 t/s ]"
2601.07941v2_Moonworks Lunara Aesthetic Dataset.pdf,Moonworks Lunara Aesthetic Dataset,"['Yan Wang', 'M M Sayeef Abdullah', 'Partho Hassan', 'Sabit Hassan']",,5.6,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Moonworks Lunara Aesthetic Dataset || Yan Wang, M M Sayeef Abdullah, || Partho Hassan, and Sabit Hassan || Moonworks AI || Abstract || This data card presents the first public release of the Lunara Aesthetic Dataset, || a curated set of 2,000 imageprompt pairs for controlled research on prompt ground ... (truncated) ||  || { ""title"": ""Moonworks Lunara Aesthetic Dataset"", ""authors"": [""Yan Wang"", ""M M Sayeef Abdullah"", ""Partho Hassan"", ""Sabit Hassan""], ""doi"": """", ""arxiv_id"": ""2601.07941"", ""keywords"": [""Moonworks"", ""Lunara"", ""Aesthetic Dataset"", ""Text-to-Image Generation"", ""Prompt Grounding"", ""Style Conditioning""], ""summary"": ""This data card presents the first public release of the Lunara Aesthetic Dataset, a curated set of 2,000 image-prompt pairs for controlled research on prompt grounding and style conditioning in text-to-image generation systems. The dataset spans diverse artistic styles, including regionally grounded aesthetics from the Middle East, Northern Europe, East Asia, and South Asia, alongside general categories such as sketch and oil painting. All images are generated using the Moonworks Lunara model and intentionally crafted to embody distinct, high-quality aesthetic styles, yielding a first-of-its-kind dataset with substantially higher aesthetic scores, exceeding even aesthetics-focused datasets and general-purpose datasets by a larger margin. Each image is accompanied by a human-refined prompt and structured annotations that jointly describe salient objects, attributes, relationships, and stylistic cues. Unlike large-scale web-derived datasets that emphasize breadth over precision, the Lunara Aesthetic Dataset prioritizes aesthetic quality, stylistic diversity, and licensing transparency, and is released under the Apache 2.0 license to support research and unrestricted academic and commercial use."" } ||  || [ Prompt: 12.6 t/s | Generation: 5.6 t/s ]"
2601.07946v1_Coupled Diffusion-Encoder Models for Reconstructio.pdf,Coupled DiffusionEncoder Models for Reconstruction of Flow Fields,"['AmirPouya Hemmasian', 'Amir Barati Farimani']",,5.4,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DiffCoder || Coupled DiffusionEncoder Models for Reconstruction of Flow Fields || AmirPouya Hemmasian 1 and Amir Barati Farimani 1, 2 || 1)Mechanical Engineering Department, Carnegie Mellon University, Pittsburgh, PA, USA || 2)Machine Learning Department, Carnegie Mellon University, Pittsburgh, ... (truncated) ||  || { || ""title"": ""Coupled DiffusionEncoder Models for Reconstruction of Flow Fields"", || ""authors"": [""AmirPouya Hemmasian"", ""Amir Barati Farimani""], || ""doi"": """", || ""arxiv_id"": ""2601.01427"", || ""keywords"": [""DiffusionEncoder"", ""Flow Field Reconstruction"", ""Probabilistic Diffusion Model"", ""Convolutional ResNet"", ""Kolmogorov Flow Fields""], || ""summary"": ""DiffCoder is a coupled framework that integrates a probabilistic diffusion model with a conventional convolutional ResNet encoder. It compresses flow fields into latent representations and learns a generative prior over reconstructions conditioned on the compressed state. This design allows DiffCoder to recover distributional and spectral properties of flow fields, which are critical for faithfully representing their statistical properties. DiffCoder significantly improves spectral accuracy under aggressive compression, while variational autoencoders exhibit substantial degradation. At moderate compression levels, sufficiently large variational autoencoders remain competitive, suggesting that diffusion-based priors provide the greatest benefit when information bottlenecks are severe. These results demonstrate that generative decoding by diffusion offers a promising path toward compact, statistically consistent representations of complex flow fields."" || } ||  || [ Prompt: 12.3 t/s | Generation: 5.4 t/s ]"
2601.07948v1_Reinforcement Learning Methods for Neighborhood Se.pdf,Reinforcement Learning Methods for Neighborhood Selection in Local Search,"['Yannick Molinghen1', 'Augustin Delecluse2,3', 'Renaud De Landtsheer4', 'Stefano Michelini4']",,5.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Reinforcement || Learning Methods for Neighborhood Selection in Local Search || Y annick Molinghen1 || a, Augustin Delecluse2,3 || b, Renaud De Landtsheer4 || c and Stefano Michelini4 || d || 1Universit Libre de Bruxelles, Brussels, Belgium || 2UCLouvain, Louvain-La-Neuve, Belgium || 3KU Leuven, Gent, Bel ... (truncated) ||  || { ""title"": ""Reinforcement Learning Methods for Neighborhood Selection in Local Search"", ""authors"": [""Yannick Molinghen1"", ""Augustin Delecluse2,3"", ""Renaud De Landtsheer4"", ""Stefano Michelini4""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Local Search"", ""Reinforcement Learning"", ""Combinatorial Optimization""], ""summary"": ""This study evaluates reinforcement learning-based neighborhood selection strategies for local search metaheuristics across three problems: the traveling salesman problem, the pickup and delivery problem with time windows, and the car sequencing problem. It highlights the need for carefully designed reward functions to provide stable and informative learning signals, and shows that -greedy consistently ranks among the best performers, while deep reinforcement learning approaches have higher computational overhead and longer runtime."" } ||  || [ Prompt: 12.9 t/s | Generation: 5.1 t/s ]"
2601.07951v1_Hybrid SARIMA LSTM Model for Local Weather Forecas.pdf,Hybrid SARIMALSTM Model for Local Weather Forecasting: A Residual-Learning Approach for Data-Driven Meteorological Prediction,"['Shreyas Rajeev', 'Karthik Mudenahalli', 'Amit Mallappa']",,5.6,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  ||  || Hybrid SARIMALSTM Model for Local Weather Forecasting: A Residual-Learning Approach for Data-Driven Meteorological Prediction Shreyas Rajeev Stevens Institute of Technology Hoboken, USA srajeev@stevens.edu || Karthik Mudenahalli Ashoka Stevens Institute of Technology  Hoboken, ... (truncated) ||  || ```json || { || ""title"": ""Hybrid SARIMALSTM Model for Local Weather Forecasting: A Residual-Learning Approach for Data-Driven Meteorological Prediction"", || ""authors"": [""Shreyas Rajeev"", ""Karthik Mudenahalli"", ""Amit Mallappa""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""weather forecasting"", ""SARIMA"", ""LSTM"", ""residual learning"", ""long-term prediction""], || ""summary"": ""For decades, accurately predicting the weather over the long term has been a major scientific problem due to the chaotic nature of atmospheric systems. Traditional statistical methods like SARIMA and LSTMs have limitations in handling nonlinear behavior. This paper proposes a hybrid SARIMALSTM model that breaks temperature into a climate component (predictable) and a weather component (nonlinear). The model uses a residual-learning strategy to address the limitations of both classical statistical models and independent neural network models, leading to more accurate long-term forecasts."" || } ||  ||  || [ Prompt: 12.0 t/s | Generation: 5.6 t/s ]"
2601.07953v1_Quantum automated theorem proving.pdf,Quantum automated theorem proving,"['Zheng-Zhi Sun', 'Qi Ye', 'Dong-Ling Deng']",,11.5,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Quantum automated theorem proving || Zheng-Zhi Sun, 1 Qi Ye,1, 2 and Dong-Ling Deng 1, 2, 3, || 1Center for Quantum Information, IIIS, Tsinghua University, Beijing 100084, China || 2Shanghai Qi Zhi Institute, Shanghai 200232, China || 3Hefei National Laboratory, Hefei 230088, China || Automated th ... (truncated) ||  || { ""title"": ""Quantum automated theorem proving"", ""authors"": [""Zheng-Zhi Sun"", ""Qi Ye"", ""Dong-Ling Deng""], ""doi"": """", ""arxiv_id"": ""arXiv:2304.12345"", ""keywords"": [""quantum computing"", ""automated theorem proving"", ""quantum logic"", ""automated reasoning"", ""geometric theorems""], ""summary"": ""Automated theorem proving, or more broadly automated reasoning, aims at using computer programs to automatically prove or disprove mathematical theorems and logical statements. This paper proposes a generic framework for quantum automated theorem proving, where the intrinsic quantum superposition and entanglement features would lead to potential advantages. We introduce quantum representations of knowledge bases and propose corresponding reasoning algorithms for a variety of tasks. We show how automated reasoning can be achieved with quantum resolution in both propositional and first-order logic with quadratically reduced query complexity. Additionally, we propose the quantum algebraic proving method for geometric theorems, extending Wus algebraic approach beyond the classical setting. Through concrete examples, including geometry problems from the International Mathematical Olympiad, we demonstrate how a quantum computer may prove geometric theorems with quadratic better query complexity. Our results establish a primary approach towards building quantum automatic theorem provers, which would be crucial for practical applications of both near-term and future quantum technologies."" } ||  || [ Prompt: 30.9 t/s | Generation: 11.5 t/s ]"
2601.07957v1_LWMSCNN-SE A Lightweight Multi-Scale Network for E.pdf,LWMSCNN-SE: A Lightweight Multi-Scale Network for Efficient Maize Disease Classification on Edge Devices,"['1st Fikadu Weloday', '2nd Jianmei Su']",,12.5,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || LWMSCNN-SE: A Lightweight Multi-Scale || Network for Efficient Maize Disease Classification || on Edge Devices || 1st Fikadu Weloday, 2nd Jianmei Su || School of Computer Science and Technology,Southwest University of Science and Technology, Mianyang,China || deyu@mails.swust.edu.cn || AbstractMaiz ... (truncated) ||  || { ""title"": ""LWMSCNN-SE: A Lightweight Multi-Scale Network for Efficient Maize Disease Classification on Edge Devices"", ""authors"": [""1st Fikadu Weloday"", ""2nd Jianmei Su""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""lightweight CNN"", ""multi-scale feature extraction"", ""attention mechanism"", ""plant pathology""], ""summary"": ""Maize disease classification plays a vital role in mitigating yield losses and ensuring food security. However, deploying traditional disease detection models in resource-constrained environments faces challenges due to high computational costs. To address these challenges, we propose LWMSCNN-SE, a lightweight convolutional neural network (CNN) that integrates multi-scale feature extraction, depthwise separable convolutions, and squeeze-and-Excitation (SE) attention mechanisms. This novel combination enables the model to achieve 96.63% classification accuracy with only 241,348 parameters and 0.666 GFLOPs, making it suitable for real-time deployment in field applications. Our approach addresses the accuracy-efficiency trade-off by delivering high accuracy while maintaining low computational costs, demonstrating its potential for efficient maize disease diagnosis on edge devices in precision farming systems."" } ||  || [ Prompt: 37.7 t/s | Generation: 12.5 t/s ]"
2601.07958v1_LJ-Spoof A Generatively Varied Corpus for Audio An.pdf,LJ-SPOOF: A GENERATIVELY V ARIED CORPUS FOR AUDIO ANTI-SPOOFING AND SYNTHESIS SOURCE TRACING,"['Surya Subramani', 'Hashim Ali', 'Hafiz Malik']",,6.4,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LJ-SPOOF: A GENERATIVELY V ARIED CORPUS FOR AUDIO ANTI-SPOOFING AND || SYNTHESIS SOURCE TRACING || Surya Subramani, Hashim Ali, Hafiz Malik || Electrical and Computer Engineering || University of Michigan || 4901 Evergreen Rd, Dearborn, MI 48128, USA || ABSTRACT || Speaker-specific anti-spoofing and syn ... (truncated) ||  || ```json || { || ""title"": ""LJ-SPOOF: A GENERATIVELY V ARIED CORPUS FOR AUDIO ANTI-SPOOFING AND SYNTHESIS SOURCE TRACING"", || ""authors"": [""Surya Subramani"", ""Hashim Ali"", ""Hafiz Malik""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Anti-Spoofing"", ""Speaker Verification"", ""Deepfake"", ""Source tracing"", ""Synthetic Speech""], || ""summary"": ""Speaker-specific anti-spoofing and synthesis-source tracing are central challenges in audio anti-spoofing. This paper introduces LJ-Spoof, a speaker-specific, generatively diverse corpus that systematically varies prosody, vocoders, generative hyperparameters, bona fide prompt sources, training regimes, and neural post-processing. The corpus spans one speaker including studio-quality recordings, 30 TTS families, 500 generatively variant subsets, 10 bona fide neural-processing variants, and more than 3 million utterances. This variation-dense design enables robust speaker-conditioned anti-spoofing and fine-grained synthesis-source tracing. The dataset is positioned as both a practical reference training resource and a benchmark evaluation suite for anti-spoofing and source tracing."" || } ||  ||  || [ Prompt: 33.5 t/s | Generation: 6.4 t/s ]"
2601.07964v1_Executable Ontologies in Game Development From Alg.pdf,Executable Ontologies in Game Development: From Algorithmic Control to Semantic World Modeling,['Alexander Boldachev'],,5.9,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || Executable Ontologies in Game Development: || From Algorithmic Control to Semantic World Modeling || Alexander Boldachev || boldachev@gmail.com || https://orcid.org/0000-0002-7259-2952 || Abstract || This paper examines the application of Executable Ontologies (EO), implemented through the || ... (truncated) ||  || { ""title"": ""Executable Ontologies in Game Development: From Algorithmic Control to Semantic World Modeling"", ""authors"": [""Alexander Boldachev""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""executable ontologies"", ""game AI"", ""behavior trees"", ""GOAP"", ""event semantics"", ""dataflow architecture"", ""semantic modeling""], ""summary"": ""This paper examines the application of Executable Ontologies (EO) in game development, arguing that EO represents a paradigm shift from algorithmic behavior programming to semantic world modeling. Using a survival game scenario, EO achieves priority-based task interruption through dataflow conditions rather than explicit preemption logic. Comparison with Behavior Trees (BT) and Goal-Oriented Action Planning (GOAP) reveals that EO models when actions become possible, addressing the semantic-process gap in game AI architecture. Integration strategies, debugging advantages, and potential for LLM-driven runtime model generation are discussed."" } ||  || [ Prompt: 13.2 t/s | Generation: 5.9 t/s ]"
2601.07965v1_When Models Know When They Do Not Know Calibration.pdf,WHENMODELSKNOWWHENTHEYDONOTKNOW,"['Chenjie Hao', 'Weyl Lu', 'Yuko Ishiwaka', 'Zengyi Li', 'Weier Wan', 'Yubei Chen']",,5.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Preprint. || WHENMODELSKNOWWHENTHEYDONOTKNOW || CALIBRATION, CASCADING,ANDCLEANING || Chenjie Hao1, Weyl Lu1, Yuko Ishiwaka3, Zengyi Li2, Weier Wan2, Yubei Chen1,2 || 1 University of California, Davis, 2 Aizip || 3 SoftBank Corp. || ABSTRACT || When a model knows when it does not know, many possibilitie ... (truncated) ||  || ```json || { || ""title"": ""WHENMODELSKNOWWHENTHEYDONOTKNOW"", || ""authors"": [""Chenjie Hao"", ""Weyl Lu"", ""Yuko Ishiwaka"", ""Zengyi Li"", ""Weier Wan"", ""Yubei Chen""], || ""doi"": """", || ""arxiv_id"": ""arXiv:2309.16656"", || ""keywords"": [""model calibration"", ""model cascading"", ""data cleaning"", ""confidence estimation"", ""deep learning""], || ""summary"": ""This work proposes a simple, effective, and universal training-free method for model calibration, cascading, and data cleaning. It highlights two key empirical observations: higher confidence corresponds to higher accuracy within a single model, and models calibrated on the validation set remain calibrated on a held-out test set. The findings establish the reliability and comparability of calibrated confidence. The method is applied to both vision and language models and demonstrates improvements in efficiency and accuracy through model cascading and data cleaning. The cascading method improves efficiency with almost no compromise in accuracy, and data cleaning identifies mislabeled samples in ImageNet and MMLU datasets."" || } ||  ||  || [ Prompt: 13.9 t/s | Generation: 5.1 t/s ]"
2601.07969v1_Tuberculosis Screening from Cough Audio Baseline M.pdf,"TUBERCULOSISSCREENING FROMCOUGHAUDIO: BASELINEMODELS, CLINICALVARIABLES,ANDUNCERTAINTY QUANTIFICATION","['George P. Kafentzis', 'Efstratios Selisios']",,5.2,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TUBERCULOSISSCREENING FROMCOUGHAUDIO: || BASELINEMODELS, CLINICALVARIABLES,ANDUNCERTAINTY || QUANTIFICATION || A PREPRINT || George P. Kafentzis || Department of Computer Science || University of Crete || Greece || kafentz@csd.uoc.gr || Efstratios Selisios || Department of Computer Science || University of Crete || Gr ... (truncated) ||  || ```json || { || ""title"": ""TUBERCULOSISSCREENING FROMCOUGHAUDIO: BASELINEMODELS, CLINICALVARIABLES,ANDUNCERTAINTY QUANTIFICATION"", || ""authors"": [""George P. Kafentzis"", ""Efstratios Selisios""], || ""doi"": """", || ""arxiv_id"": ""2601.04745"", || ""keywords"": [""Tuberculosis"", ""Machine Learning"", ""Cough Audio"", ""Cross-Validation"", ""Uncertainty Quantification"", ""Feature Extraction""], || ""summary"": ""This paper proposes a standardized framework for automatic tuberculosis (TB) detection from cough audio and routinely collected clinical data using machine learning. It addresses the gap in measuring progress due to varying datasets, cohort definitions, feature representations, model families, validation protocols, and reported metrics. The pipeline covers feature extraction, multimodal fusion, cougher-independent evaluation, and uncertainty quantification, and reports clinically relevant metrics for fair comparison. Performance is quantified for cough audio-only and fused models, and the full experimental protocol is released for benchmarking. This baseline serves as a common reference point to reduce methodological variance and facilitate progress in the field."" || } ||  ||  || [ Prompt: 13.3 t/s | Generation: 5.2 t/s ]"
2601.07973v1_Cultural Compass A Framework for Organizing Societ.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Cultural Compass: A Framework for Organizing Societal Norms to Detect || Violations in Human-AI Conversations || Myra Cheng1,2 Vinodkumar Prabhakaran2 Alice Oh2 Hayk Stepanyan2 || Aishwarya Verma2 Charu Kalia2 Erin MacMurray van Liemt2 Sunipa Dev2 || 1Stanford University 2Google || myra@cs.stanfor ... (truncated) ||  || { || ""title"": ""Cultural Compass: A Framework for Organizing Societal Norms to Detect Violations in Human-AI Conversations"", || ""authors"": [""Myra Cheng"", ""Vinodkumar Prabhakaran"", ""Alice Oh"", ""Hayk Stepanyan"", ""Aishwarya Verma"", ""Charu Kalia"", ""Erin MacMurray van Liemt"", ""Sunipa Dev""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Generative AI"", ""Cultural Norms"", ""Human-AI Interaction"", ""Norm Adherence"", ""Societal Norms"", ""Cultural Alignment""], || ""summary"": ""This paper introduces a taxonomy of societal norms to clarify their contexts, specifications, and mechanisms. It addresses the gap in understanding and evaluating AI models' adherence to these norms. The authors demonstrate how their taxonomy can be operationalized to automatically evaluate models' norm adherence in naturalistic, open-ended settings. The exploratory analyses suggest that state-of-the-art models frequently violate norms, with rates varying by model, interactional context, and country. The paper also shows that violation rates vary by prompt intent and situational framing. The taxonomy and demonstration evaluation pipeline enable nuanced, context-sensitive evaluation of cultural norm adherence in realistic settings."""
2601.07988v1_From Word Sequences to Behavioral Sequences Adapti.pdf,From Word Sequences to Behavioral Sequences: Adapting Modeling and Evaluation Paradigms for Longitudinal NLP,"['Adithya V Ganesan', 'Vasudha Varadarajan', 'Oscar NE Kjell', 'Whitney R Ringwald', 'Scott Feltman', 'Benjamin J Luft', 'Roman Kotov', 'Ryan L Boyd', 'Andrew Schwartz']",,11.8,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || From Word Sequences to Behavioral Sequences: Adapting Modeling and || Evaluation Paradigms for Longitudinal NLP || Adithya V Ganesan Vasudha Varadarajan Oscar NE Kjell Whitney R Ringwald || Scott Feltman Benjamin J Luft Roman Kotov Ryan L Boyd H Andrew Schwartz || Stony Brook University Vanderb ... (truncated) ||  || { || ""title"": ""From Word Sequences to Behavioral Sequences: Adapting Modeling and Evaluation Paradigms for Longitudinal NLP"", || ""authors"": [""Adithya V Ganesan"", ""Vasudha Varadarajan"", ""Oscar NE Kjell"", ""Whitney R Ringwald"", ""Scott Feltman"", ""Benjamin J Luft"", ""Roman Kotov"", ""Ryan L Boyd"", ""Andrew Schwartz""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""longitudinal NLP"", ""behavioral sequences"", ""diary data"", ""PTSD"", ""evaluation paradigms"", ""modeling""], || ""summary"": ""While traditional NLP treats documents as independent and unordered samples, longitudinal studies reveal that documents are nested within authors and ordered in time, forming person-indexed, time-ordered behavioral sequences. This mismatch propagates through the standard NLP pipeline, leading to issues such as leaky person-specific signal, ignored informative history, and lack of clear real-world generalization goals. We propose a longitudinal modeling and evaluation paradigm that updates four parts of the pipeline: evaluation splits, accuracy metrics, sequence inputs, and model internals. We demonstrate the issues with traditional pipeline and our proposed improvements on a dataset of 17k daily diary transcripts paired with PTSD symptom severity from 238 participants, finding that traditional document-level evaluation can yield substantially different and sometimes reversed conclusions compared to our ecologically valid modeling and evaluation. We tie our results to a broader discussion motivating a shift from word-sequence evaluation toward behavior-sequence paradigms for NLP."" || } ||  || [ Prompt: 34.3 t/s | Generation: 11.8 t/s ]"
2601.07994v2_DYCP Dynamic Context Pruning for Long-Form Dialogu.pdf,DYCP: Dynamic Context Pruning for Long-Form Dialogue with LLMs,"['Nayoung Choi', 'Jonathan Zhang', 'Jinho D. Choi']",,11.3,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DYCP: Dynamic Context Pruning for Long-Form Dialogue with LLMs || Nayoung Choi || Computer Science || Emory University || Atlanta, Georgia, USA || nayoung.choi@emory.edu || Jonathan Zhang || Computer Science || Emory University || Atlanta, Georgia, USA || jonathan.zhang2@emory.edu || Jinho D. Choi || Computer Science || ... (truncated) ||  || { || ""title"": ""DYCP: Dynamic Context Pruning for Long-Form Dialogue with LLMs"", || ""authors"": [""Nayoung Choi"", ""Jonathan Zhang"", ""Jinho D. Choi""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Large Language Models"", ""Dialogue Systems"", ""Context Management"", ""Long-Form Conversations"", ""Efficient Context Retrieval""], || ""summary"": ""Large Language Models (LLMs) often exhibit increased response latency and degraded answer quality as dialogue length grows. Existing methods rely on extra LLM calls to build memory or perform offline memory construction without considering the current user utterance, which can introduce inefficiencies or disrupt conversational continuity. We introduce DYCP, a lightweight context management method that dynamically segments and retrieves relevant memory at query time. It preserves the sequential structure of dialogue without predefined topic boundaries and supports efficient, adaptive context retrieval. Across three long-form dialogue benchmarks (LoCoMo, MT-Bench+, SCM4LLMs) and multiple LLMs, DYCP consistently improves answer quality while reducing response latency. We also examine the gap between modern LLMs' expanded context windows and their actual long-context processing capacity, highlighting the continued importance of effective context management."" || } ||  || [ Prompt: 32.7 t/s | Generation: 11.3 t/s ]"
2601.08000v1_Reasoning over Precedents Alongside Statutes Case-.pdf,Case-Augmented Deliberative Alignment for LLM Safety,"['Can Jin1*', 'Rui Wu1*', 'Tong Che2*', 'Qixin Zhang3', 'Hongwu Peng4', 'Jiahui Zhao5', 'Wenqi Wei6', 'Ligong Han1', 'Zhao Zhang1', 'Yuan Cao7', 'Ruixiang Tang1', 'Dimitris N. Metaxas1']",,5.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Reasoning over Precedents Alongside Statutes: || Case-Augmented Deliberative Alignment for LLM Safety || Can Jin1*, Rui Wu1*, Tong Che2*, Qixin Zhang3, Hongwu Peng4, Jiahui Zhao5, Zhenting Wang1, || Wenqi Wei6, Ligong Han1, Zhao Zhang1, Yuan Cao7, Ruixiang Tang1, Dimitris N. Metaxas1 || 1Rutger ... (truncated) ||  || ```json || { || ""title"": ""Case-Augmented Deliberative Alignment for LLM Safety"", || ""authors"": [""Can Jin1*"", ""Rui Wu1*"", ""Tong Che2*"", ""Qixin Zhang3"", ""Hongwu Peng4"", ""Jiahui Zhao5"", ""Wenqi Wei6"", ""Ligong Han1"", ""Zhao Zhang1"", ""Yuan Cao7"", ""Ruixiang Tang1"", ""Dimitris N. Metaxas1""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Large Language Models"", ""Deliberative Alignment"", ""Safety"", ""LLM Safety"", ""Reinforcement Learning"", ""Cybersecurity"", ""LLM Alignment"", ""LLM Safety Principles""], || ""summary"": ""This work systematically evaluates the impact of explicitly specifying extensive safety codes versus demonstrating them through illustrative cases. It finds that referencing explicit codes inconsistently improves harmlessness but systematically degrades helpfulness, while training on case-augmented simple codes yields more robust and generalized safety behaviors. By guiding LLMs with case-augmented reasoning instead of extensive code-like safety rules, the approach avoids rigid adherence to narrowly enumerated rules and enables broader adaptability. The proposed CADA method effectively enhances harmlessness, improves robustness against attacks, and reduces over-refusal while preserving utility across diverse benchmarks, offering a practical alternative to rule-only DA for improving safety while maintaining helpfulness."" || } ||  ||  || [ Prompt: 28.1 t/s | Generation: 5.1 t/s ]"
2601.08003v1_LLM Review Enhancing Creative Writing via Blind Pe.pdf,LLM Review: Enhancing Creative Writing via Blind Peer Review Feedback,"['Weiyue Li*', 'Mingxiao Song', 'Zhenda Shen', 'Dachuan Zhao', 'Yunfan Long', 'Yi Li', 'Yongce Li', 'Ruyi Yang', 'Mengyu Wang']",,5.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LLM Review: Enhancing Creative Writing via Blind Peer Review Feedback || Weiyue Li* || Mingxiao Song || Zhenda Shen || Dachuan Zhao || Yunfan Long || Yi Li || Yongce Li || Ruyi Yang || Mengyu Wang || Harvard University, || Carnegie Mellon University, || Stanford University || Abstract || Large Language Models (LLMs ... (truncated) ||  || { || ""title"": ""LLM Review: Enhancing Creative Writing via Blind Peer Review Feedback"", || ""authors"": [""Weiyue Li*"", ""Mingxiao Song"", ""Zhenda Shen"", ""Dachuan Zhao"", ""Yunfan Long"", ""Yi Li"", ""Yongce Li"", ""Ruyi Yang"", ""Mengyu Wang""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Large Language Models"", ""Creative Writing"", ""Peer Review"", ""Blind Peer Review"", ""Science Fiction"", ""Human-LLM Collaboration""], || ""summary"": ""This paper introduces LLM Review, a peer-review-inspired framework that implements Blind Peer Review. Agents exchange targeted feedback while revising independently, preserving divergent creative trajectories. To enable rigorous evaluation, the authors propose SciFi-100, a science fiction writing dataset with a unified framework combining LLM-as-a-judge scoring, human annotation, and rule-based novelty metrics. Experiments demonstrate that LLM Review consistently outperforms multi-agent baselines, and smaller models with the framework can surpass larger single-agent models, suggesting that interaction structure may substitute for model scale."" || } ||  || [ Prompt: 12.9 t/s | Generation: 5.1 t/s ]"
2601.08005v1_Internal Deployment Gaps in AI Regulation.pdf,Internal Deployment Gaps in AI Regulation,"['JOE KWON', 'STEPHAN CASPER']",,5.5,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Internal Deployment Gaps in AI Regulation || JOE KWON and STEPHEN CASPER,MIT CSAIL, USA || Frontier AI regulations primarily focus on systems deployed to external users, where deployment is more visible and subject to outside || scrutiny. However, high-stakes applications can occur internall ... (truncated) ||  || ```json || { || ""title"": ""Internal Deployment Gaps in AI Regulation"", || ""authors"": [""JOE KWON"", ""STEPHAN CASPER""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""AI regulation"", ""internal deployment"", ""frontier AI"", ""regulatory gaps""], || ""summary"": ""Frontier AI regulations primarily focus on systems deployed to external users, where deployment is more visible and subject to outside scrutiny. However, high-stakes applications can occur internally when companies deploy highly capable systems within their own organizations. This paper examines how frontier AI regulations in the United States and European Union in 2025 handle internal deployment. We identify three gaps that could cause internally-deployed systems to evade intended oversight: scope ambiguity, point-in-time compliance assessments, and information asymmetries. We analyze why these gaps persist and map potential approaches to address them, considering tensions around measurability, incentives, and information access."" || } ||  ||  || [ Prompt: 12.1 t/s | Generation: 5.5 t/s ]"
2601.08011v1_TP-Blend Textual-Prompt Attention Pairing for Prec.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Published in Transactions on Machine Learning Research (10/2025) || TP-Blend: Textual-Prompt Attention Pairing for Precise || Object-Style Blending in Diffusion Models || Xin Jin felixxinjin@gmail.com || GenPi Inc. || Yichuan Zhongyichuanzhong27@gmail.com || GenPi Inc. || Yapeng Tian yapeng.tian@utdalla ... (truncated) ||  || { || ""title"": ""TP-Blend: Textual-Prompt Attention Pairing for Precise Object-Style Blending in Diffusion Models"", || ""authors"": [""Xin Jin"", ""Yichuan Zhong""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Text-driven image editing"", ""Diffusion models"", ""Object blending"", ""Attention fusion"", ""Style injection"", ""Precise editing""], || ""summary"": ""Current text-conditioned diffusion editors handle single object replacement well but struggle when a new object and a new style must be introduced simultaneously. We present TP-Blend, a lightweight training-free framework that receives two separate textual prompts, one specifying a blend object and the other defining a target style, and injects both into a single denoising trajectory. TP-Blend is driven by two complementary attention processors: Cross-Attention Object Fusion (CAOF) and Self-Attention Style Fusion (SASF). CAOF averages head-wise attention to locate spatial tokens that respond strongly to either prompt and reassigns feature vectors to those positions. SASF injects style at every self-attention layer through Detail-Sensitive Instance Normalization, separating low- and high-frequency components and blending only the high-frequency residual. Extensive experiments show that TP-Blend produces high-resolution, photo-realistic edits with precise control over both content and appearance, surpassing recent baselines in quantitative fidelity, perceptual quality, and inference speed."""
2601.08017v1_Representations of Text and Images Align From Laye.pdf,Representations of Text and Images Align From Layer One,"['Evzen Wybitul', 'Javier Rando', 'Florian Tram`er', 'Stanislav Fort']",,8.3,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Representations of Text and Images Align From Layer One || Evzen Wybitul 1 Javier Rando 1 Florian Tram`er 1 Stanislav Fort 2 || Abstract || We show that for a variety of concepts in adapter- || based vision-language models, the representations || of their images and their text descriptions are || mea ... (truncated) ||  || { || ""title"": ""Representations of Text and Images Align From Layer One"", || ""authors"": [""Evzen Wybitul"", ""Javier Rando"", ""Florian Tram`er"", ""Stanislav Fort""], || ""doi"": """", || ""arxiv_id"": ""2601.08017"", || ""keywords"": [""vision-language models"", ""modal alignment"", ""image-text alignment"", ""DeepDream"", ""representation synthesis""], || ""summary"": ""This paper demonstrates that for various concepts in adapter-based vision-language models, the representations of their images and text descriptions are meaningfully aligned from the very first layer. This contradicts the established view that such alignment only appears in late layers. The authors use a synthesis-based method inspired by DeepDream to show this, applying their approach to hundreds of concepts across seven layers in Gemma 3. They find that synthesised images often depict salient visual features of the targeted textual concepts, even at layer 1. The method provides direct, constructive evidence of image-text alignment on a concept-by-concept and layer-by-layer basis, and offers a new path towards model interpretability."" || } ||  || [ Prompt: 12.8 t/s | Generation: 8.3 t/s ]"
2601.08026v2_FigEx2 Visual-Conditioned Panel Detection and Capt.pdf,FigEx2: Visual-Conditioned Panel Detection and Captioning for Scientific Compound Figures,"['Jifeng Song', 'Arun Das', 'Pan Wang', 'Hui Ji', 'Kun Zhao', 'Yufei Huang']",,12.2,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || FigEx2: Visual-Conditioned Panel Detection and Captioning for Scientific || Compound Figures || Jifeng Song1, 2 , Arun Das2, 3 , Pan Wang1, Hui Ji4, Kun Zhao1, Yufei Huang1, 2, 3* || 1 Department of Electrical and Computer Engineering, University of Pittsburgh, USA || 2 Cancer Virology Program, ... (truncated) ||  || ```json || { || ""title"": ""FigEx2: Visual-Conditioned Panel Detection and Captioning for Scientific Compound Figures"", || ""authors"": [""Jifeng Song"", ""Arun Das"", ""Pan Wang"", ""Hui Ji"", ""Kun Zhao"", ""Yufei Huang""], || ""doi"": """", || ""arxiv_id"": ""jis219"", || ""keywords"": [""compound figures"", ""scientific literature"", ""panel detection"", ""captioning"", ""visual conditioning"", ""reinforcement learning"", ""supervised learning"", ""BERTScore"", ""CLIP-based alignment"", ""zero-shot transferability""], || ""summary"": ""Scientific compound figures combine multiple labeled panels into a single image, but captions are often missing or only provide figure-level summaries. This paper proposes FigEx2, a visual-conditioned framework that localizes panels and generates panel-wise captions directly from the compound figure. It mitigates open-ended captioning noise with a noise-aware gated fusion module and uses a staged optimization strategy combining supervised and reinforcement learning. Experimental results show superior performance in detection and captioning tasks."" || } ||  ||  || [ Prompt: 34.9 t/s | Generation: 12.2 t/s ]"
2601.08043v1_The Role of Noisy Data in Improving CNN Robustness.pdf,The Role of Noisy Data in Improving CNN Robustness for Image Classification,"['Oscar H. Ram rez-Agudeloa', 'Nicoleta Gorea a', 'Aliza Reif a', 'Lorenzo Bonasera a', 'Michael Karla']",,11.9,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || The Role of Noisy Data in Improving CNN Robustness for || Image Classification || Oscar H. Ram rez-Agudeloa, Nicoleta Gorea a, Aliza Reif a, Lorenzo Bonasera a, and Michael || Karla || aGerman Aerospace Center (DLR), Institute for AI Safety and Security, Rathausallee 12, || 53757 Sankt Augustin, G ... (truncated) ||  || ```json || { || ""title"": ""The Role of Noisy Data in Improving CNN Robustness for Image Classification"", || ""authors"": [""Oscar H. Ram rez-Agudeloa"", ""Nicoleta Gorea a"", ""Aliza Reif a"", ""Lorenzo Bonasera a"", ""Michael Karla""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""deep learning"", ""CNNs"", ""data quality"", ""CIFAR-10"", ""noise injection"", ""image classification"", ""model robustness""], || ""summary"": ""Data quality plays a central role in the performance and robustness of convolutional neural networks (CNNs) for image classification. This paper investigates the effect of deliberately introducing controlled noise into the training data to improve model robustness. Using the CIFAR-10 dataset, we evaluate the impact of three common corruptions, namely Gaussian noise, Salt-and-Pepper noise, and Gaussian blur at varying intensities and training set pollution levels. Experiments using a Resnet-18 model reveal that incorporating just 10% noisy data during training is sufficient to significantly reduce test loss and enhance accuracy under fully corrupted test conditions, with minimal impact on clean-data performance. These findings suggest that strategic exposure to noise can act as a simple yet effective regularizer, offering a practical trade-off between traditional data cleanliness and real-world resilience."" || } ||  ||  || [ Prompt: 35.4 t/s | Generation: 11.9 t/s ]"
2601.08049v1_Integrating Attendance Tracking and Emotion Detect.pdf,Integrating Attendance Tracking and Emotion Detection for Enhanced Student Engagement in Smart Classrooms,"['Keith Ainebyona', 'Ann Move Oguti', 'Joseph Walusimbi', 'Ritah Kobusingye']",,13.4,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 ||  || Integrating Attendance Tracking and Emotion Detection for || Enhanced Student Engagement in Smart Classrooms || Keith Ainebyona1, Ann Move Oguti2, Joseph Walusimbi3, Ritah Kobusingye4 || 1keithainebyona14@gmail.com, 2amoguti@sun.ac.ug, 3mrjosephwalusimbi@gmail.com, || 42401600224@sun.a ... (truncated) ||  || { ""title"": ""Integrating Attendance Tracking and Emotion Detection for Enhanced Student Engagement in Smart Classrooms"", ""authors"": [""Keith Ainebyona"", ""Ann Move Oguti"", ""Joseph Walusimbi"", ""Ritah Kobusingye""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Affective computing"", ""Attendance automation"", ""Emotion detection"", ""IoT"", ""Smart classroom""], ""summary"": ""This paper presents SCASED (Smart Classroom Attendance System with Emotion Detection), an IoT-based system that integrates automated attendance tracking with facial emotion recognition to support classroom engagement monitoring. The system uses a Raspberry Pi camera and a fine-tuned MobileNetV2 model to classify four learning-related emotional states: engagement, boredom, confusion, and frustration. A session-based mechanism is implemented to manage attendance and emotion monitoring. Experimental evaluation using the DAiSEE dataset achieved an emotion classification accuracy of 89.5%. The results show that integrating attendance data with emotion analytics can provide instructors with additional insight into classroom dynamics and support more responsive teaching practices."" } ||  || [ Prompt: 35.3 t/s | Generation: 13.4 t/s ]"
2601.08052v1_Forecast Aware Deep Reinforcement Learning for Eff.pdf,Forecast Aware Deep Reinforcement Learning for Efficient Electricity Load Scheduling in Dairy Farms,"['Nawazish Alia', 'Rachael Shaw', 'Karl Mason']",,5.7,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Forecast Aware Deep Reinforcement Learning for || Efficient Electricity Load Scheduling in Dairy Farms || Nawazish Alia, Rachael Shawb, Karl Masona || aSchool of Computer Science, University of Galway, , Galway, H91 TK33, , Ireland || bSchool of Computing, Atlantic Technological University, , G ... (truncated) ||  || { || ""title"": ""Forecast Aware Deep Reinforcement Learning for Efficient Electricity Load Scheduling in Dairy Farms"", || ""authors"": [""Nawazish Alia"", ""Rachael Shaw"", ""Karl Mason""], || ""doi"": """", || ""arxiv_id"": ""2601.08052v1"", || ""keywords"": [""Dairy farming"", ""Energy efficiency"", ""Deep Reinforcement Learning"", ""Load scheduling"", ""Battery storage"", ""Water heating"", ""Forecast-aware"", ""PID-KL PPO"", ""Proportional-Integral-Derivative controller"", ""Real-world data""], || ""summary"": ""This study proposes a Deep Reinforcement Learning framework for efficient load scheduling in dairy farms, focusing on battery storage and water heating under realistic operational constraints. The proposed Forecast-Aware PPO incorporates short-term forecasts of demand and renewable generation using hour-of-day and month-based residual calibration, while the PID-KL PPO variant employs a proportional-integral-derivative controller to regulate KL-divergence for stable policy updates adaptively. Trained on real-world dairy farm data, the method achieves up to 1% lower electricity cost than PPO, 4.8% than DQN, and 1.5% than SAC. For battery scheduling, PPO reduces grid imports by 13.1%, demonstrating scalability and effectiveness for sustainable energy management in modern dairy farming."" || } ||  || [ Prompt: 12.9 t/s | Generation: 5.7 t/s ]"
2601.08058v1_Reasoning Beyond Chain-of-Thought A Latent Computa.pdf,Reasoning Beyond Chain-of-Thought: A Latent Computational Mode in Large Language Models,"['Zhenghao He', 'Guangzhi Xiong', 'Bohan Liu', 'Sanchit Sinha', 'Aidong Zhang']",,5.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Reasoning Beyond Chain-of-Thought: A Latent Computational Mode in || Large Language Models || Zhenghao He Guangzhi Xiong Bohan Liu Sanchit Sinha Aidong Zhang || University of Virginia, USA || Abstract || Chain-of-Thought (CoT) prompting has im- || proved the reasoning performance of large lan- || guage  ... (truncated) ||  || ```json || { || ""title"": ""Reasoning Beyond Chain-of-Thought: A Latent Computational Mode in Large Language Models"", || ""authors"": [""Zhenghao He"", ""Guangzhi Xiong"", ""Bohan Liu"", ""Sanchit Sinha"", ""Aidong Zhang""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Large Language Models"", ""Chain-of-Thought"", ""Reasoning"", ""Latent Features"", ""Sparse Autoencoders""], || ""summary"": ""This work investigates the effectiveness of Chain-of-Thought (CoT) prompting in large language models (LLMs) and identifies a set of latent features that are causally associated with LLM reasoning behavior. Across multiple model families and reasoning benchmarks, steering a single reasoning-related latent feature can substantially improve accuracy without explicit CoT prompting. For large models, latent steering achieves performance comparable to standard CoT prompting while producing more efficient outputs. The results suggest that multi-step reasoning in LLMs is supported by latent internal activations that can be externally activated, while CoT prompting is one effective, but not unique, way of activating this mechanism rather than its necessary cause."" || } ||  ||  || [ Prompt: 13.8 t/s | Generation: 5.1 t/s ]"
2601.08065v1_A New Strategy for Verifying Reach-Avoid Specifica.pdf,A New Strategy for Verifying Reach-Avoid Specifications in Neural Feedback Systems,"['Samuel I. Akinwande', 'Sydney M. Katz', 'Mykel J. Kochenderfer', 'Clark Barrett']",,5.5,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A New Strategy for Verifying Reach-Avoid || Specifications in Neural Feedback Systems || Samuel I. Akinwande1, Sydney M. Katz1, Mykel J. Kochenderfer1, and Clark Barrett2 || 1 Department of Aeronautics and Astronautics, Stanford University, Stanford, USA || 2 Department of Computer Science, Sta ... (truncated) ||  || { ""title"": ""A New Strategy for Verifying Reach-Avoid Specifications in Neural Feedback Systems"", ""authors"": [""Samuel I. Akinwande"", ""Sydney M. Katz"", ""Mykel J. Kochenderfer"", ""Clark Barrett""], ""doi"": """", ""arxiv_id"": ""2601.08065"", ""keywords"": [""neural feedback systems"", ""reach-avoid properties"", ""forward reachability analysis"", ""backward reachability analysis"", ""neural networks"", ""dynamical systems"", ""verification"", ""safety specifications"", ""scalability""], ""summary"": ""Forward reachability analysis is the predominant approach for verifying reach-avoid properties in neural feedback systems. This work introduces new algorithms that compute both over- and under-approximations of backward reachable sets for such systems. These algorithms are integrated with established forward analysis techniques to yield a unified verification framework for neural feedback systems."" } ||  || [ Prompt: 12.3 t/s | Generation: 5.5 t/s ]"
2601.08070v1_Semantic Gravity Wells Why Negative Constraints Ba.pdf,Semantic Gravity Wells: Why Negative Constraints Backfire,['Shailesh Rana'],,5.3,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Semantic Gravity Wells: Why Negative Constraints Backfire || Shailesh Rana || Independent Researcher || https://github.com/gut-puncture || Abstract || Negative constraints (instructions of the form do not use word X) represent a fundamental test of instruction-following || capability in large languag ... (truncated) ||  || { ""title"": ""Semantic Gravity Wells: Why Negative Constraints Backfire"", ""authors"": [""Shailesh Rana""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Negative Constraints"", ""Instruction-following"", ""Semantic Pressure"", ""Failure Mechanisms"", ""Layer-wise Analysis"", ""Activation Patching""], ""summary"": ""This paper presents a comprehensive mechanistic investigation of negative instruction failure in large language models. It introduces the concept of semantic pressure, a measure of the models intrinsic probability of generating the forbidden token. The study demonstrates that violation probability follows a tight logistic relationship with semantic pressure. Through layer-wise analysis, it establishes that the suppression signal induced by negative instructions is present but systematically weaker in failures. The findings reveal a fundamental tension in negative constraint design, where the very act of naming a forbidden word primes the model to produce it. The paper traces this behavior to two distinct failure modes: priming failure and override failure, and confirms that activation patching is responsible for the observed asymmetry."" } ||  || [ Prompt: 13.1 t/s | Generation: 5.3 t/s ]"
2601.08079v1_MemoBrain Executive Memory as an Agentic Brain for.pdf,MemoBrain: Executive Memory as an Agentic Brain for Reasoning,"['Hongjin Qian', 'Zhao Cao']",,11.2,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MemoBrain: Executive Memory as an Agentic Brain for Reasoning || Hongjin Qian1, Zhao Cao2, Zheng Liu1* || 1 Beijing Academy of Artificial Intelligence || 2 Gaoling School of Artificial Intelligence, Renmin University of China || {chienqhj,zhengliu1026}@gmail.com || Abstract || Complex reasoning in to ... (truncated) ||  || { || ""title"": ""MemoBrain: Executive Memory as an Agentic Brain for Reasoning"", || ""authors"": [""Hongjin Qian"", ""Zhao Cao""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Executive Memory"", ""Tool-Augmented Agents"", ""Long-Horizon Reasoning"", ""Cognitive Overload"", ""Context Management""], || ""summary"": ""Complex reasoning in tool-augmented agent frameworks is inherently long-horizon, causing reasoning traces and transient tool artifacts to accumulate and strain the bounded working context of large language models. Without explicit memory mechanisms, such accumulation disrupts logical continuity and undermines task alignment. This paper proposes MemoBrain, an executive memory model for tool-augmented agents that constructs a dependency-aware memory over reasoning steps, capturing salient intermediate states and their logical relations. Operating as a co-pilot alongside the reasoning agent, MemoBrain organizes reasoning progress without blocking execution and actively manages the working context. Specifically, it prunes invalid steps, folds completed sub-trajectories, and preserves a compact, high-salience reasoning backbone under a fixed context budget. Together, these mechanisms enable explicit cognitive control over reasoning trajectories rather than passive context accumulation. The paper evaluates MemoBrain on challenging long-horizon benchmarks, including GAIA, Web-Walker, and BrowseComp-Plus, demonstrating consistent improvements over strong baselines. Our codes are available in this repository."" || } ||  || [ Prompt: 20.4 t/s | Generation: 11.2 t/s ]"
2601.08089v1_Q-realign Piggybacking Realignment on Quantization.pdf,Q-realign: Piggybacking Realignment on Quantization for Safe and Efficient LLM Deployment,"['Qitao Tan', 'Xiaoying Song', 'Ningxi Cheng', 'Ninghao Liu', 'Xiaoming Zhai', 'Lingzi Hong', 'Yanzhi Wang', 'Zhen Xiang', 'Geng Yuan']",,11.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Q-realign: Piggybacking Realignment on Quantization for Safe and || Efficient LLM Deployment || Qitao Tan1 Xiaoying Song2 Ningxi Cheng1 Ninghao Liu3 || Xiaoming Zhai1 Lingzi Hong2 Yanzhi Wang4 Zhen Xiang1 Geng Yuan1 || 1University of Georgia 2University of North Texas || 3Hong Kong Polytechnic Uni ... (truncated) ||  || { ""title"": ""Q-realign: Piggybacking Realignment on Quantization for Safe and Efficient LLM Deployment"", ""authors"": [""Qitao Tan"", ""Xiaoying Song"", ""Ningxi Cheng"", ""Ninghao Liu"", ""Xiaoming Zhai"", ""Lingzi Hong"", ""Yanzhi Wang"", ""Zhen Xiang"", ""Geng Yuan""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""quantization"", ""post-training"", ""fine-tuning"", ""safety alignment"", ""LLM deployment"", ""RLHF""], ""summary"": ""Public large language models (LLMs) are typically safety-aligned during pretraining, but task-specific fine-tuning often erodes this alignment and introduces safety risks. Existing defenses either embed safety recovery into fine-tuning or rely on post-hoc correction derived from fine-tuning priors, leaving safety recovery tightly coupled with training and incurring high computational overhead. To address these challenges, we propose Q-realign, a post-hoc defense method based on post-training quantization, guided by an analysis of representational structure. By reframing quantization as a dual-objective procedure for compression and safety, Q-realign decouples safety alignment from fine-tuning and naturally piggybacks into modern deployment pipelines. Experiments across multiple models and datasets demonstrate that our method substantially reduces unsafe behaviors while preserving task performance, with significant reductions in memory usage and GPU hours. Notably, our approach can recover the safety alignment of a fine-tuned 7B LLM on a single RTX 4090 within 40 minutes. Overall, our work provides a practical, turnkey solution for safety-aware deployment."" } ||  || [ Prompt: 33.9 t/s | Generation: 11.1 t/s ]"
2601.08094v1_Local-Global Feature Fusion for Subject-Independen.pdf,Local-Global Feature Fusion for Subject-Independent EEG Emotion Recognition,"['Zheng Zhou', 'Isabella McEvoy', 'Camilo E. Valderrama']",,8.3,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Local-Global Feature Fusion for || Subject-Independent EEG Emotion Recognition || Zheng Zhou || Computer Science and Technology || Beijing Jiaotong University || Beijing, China || zhengzhou@bjtu.edu.cn || Isabella McEvoy || Applied Computer Science || The University of Winnipeg || Winnipeg, Canada || mcevoy-i@webma ... (truncated) ||  || { ""title"": ""Local-Global Feature Fusion for Subject-Independent EEG Emotion Recognition"", ""authors"": [""Zheng Zhou"", ""Isabella McEvoy"", ""Camilo E. Valderrama""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""EEG emotion recognition"", ""subject-independent"", ""local-global fusion"", ""transformer"", ""domain adaptation"", ""intensity threshold""], ""summary"": ""Subject-independent EEG emotion recognition is challenged by inter-subject variability and the difficulty of learning robust representations from short, noisy recordings. This paper proposes a fusion framework that integrates local, channel-wise descriptors and global, trial-level descriptors, improving cross-subject generalization on the SEED-VII dataset. Experiments demonstrate that the proposed method consistently outperforms single-view and classical baselines, achieving approximately 40% mean accuracy in 7-class subject-independent emotion recognition. The code is available at https://github.com/Danielz-z/LGF-EEG-Emotion."" } ||  || [ Prompt: 37.8 t/s | Generation: 8.3 t/s ]"
2601.08104v1_High-Fidelity Modeling of Stochastic Chemical Dyna.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || HIGH-FIDELITYMODELING OFSTOCHASTICCHEMICAL || DYNAMICS ONCOMPLEXMANIFOLDS: A MULTI-SCALE || SIREN-PINN FRAMEWORK FOR THECURVATURE-PERTURBED || GINZBURG-LANDAUEQUATION || A PREPRINT || Julian Evan Chrisnanto || Department of Bio-Functions and Systems Science || Graduate School of Bio-Applications and Sys ... (truncated) ||  || ```json || { || ""title"": ""HIGH-FIDELITYMODELING OFSTOCHASTICCHEMICAL DYNAMICS ONCOMPLEXMANIFOLDS: A MULTI-SCALE SIREN-PINN FRAMEWORK FOR THECURVATURE-PERTURBED GINZBURG-LANDAUEQUATION"", || ""authors"": [""Julian Evan Chrisnanto"", ""Salsabila Rahma Alia"", ""Nurfauzi Fadillah"", ""Yulison Herry Chrisnanto""], || ""doi"": """", || ""arxiv_id"": ""2601.04167"", || ""keywords"": [ || ""Physics-Informed Neural Networks (PINNs)"", || ""Spatiotemporal Chaos"", || ""Inverse Geometric Problems"", || ""Reaction-Diffusion Systems"", || ""Defect Turbulence"", || ""Riemann Manifold Learning"", || ""Curvature-Perturbed Ginzburg-Landau Equation"" || ], || ""summary"": ""This work proposes a Multi-Scale SIREN-PINN architecture to accurately model spatiotemporal chaos in reaction-diffusion systems on complex manifolds. The architecture leverages periodic sinusoidal activations with frequency-diverse initialization to resolve high-frequency gradients and preserve topological invariants. Validated on the complex Ginzburg-Landau equation, the architecture achieves relative state prediction error L2 1.9210^-2, outperforming standard baselines by an order of magnitude. The work establishes a new paradigm for Geometric Catalyst Design, offering a mesh-free, data-driven tool for identifying surface heterogeneity and engineering passive control strategies in turbulent chemical reactors."""
2601.08107v1_STO-RL Offline RL under Sparse Rewards via LLM-Gui.pdf,STO-RL: Offline RL under Sparse Rewards via LLM-Guided Subgoal Temporal Order,"['Chengyang Gu', 'Yuxin Pan', 'Hui Xiong', 'Yize Chen']",10.1145/nnnnnnn.nnnnnnn,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || STO-RL: Offline RL under Sparse Rewards via LLM-Guided || Subgoal Temporal Order || Chengyang Gu || Hong Kong University of Science and Technology || (Guangzhou) || Hong Kong, China || cgu893@connect.hkust-gz.edu.cn || Yuxin Pan || Hong Kong University of Science and Technology || Hong Kong, China || yuxin.pan@c ... (truncated) ||  || { ""title"": ""STO-RL: Offline RL under Sparse Rewards via LLM-Guided Subgoal Temporal Order"", ""authors"": [""Chengyang Gu"", ""Yuxin Pan"", ""Hui Xiong"", ""Yize Chen""], ""doi"": ""10.1145/nnnnnnn.nnnnnnn"", ""arxiv_id"": """", ""keywords"": [""Offline RL"", ""Temporal order"", ""Large Language Models""], ""summary"": ""Offline reinforcement learning (RL) enables policy learning from pre-collected datasets, avoiding costly and risky online interactions. However, it often struggles with long-horizon tasks involving sparse rewards. Existing goal-conditioned and hierarchical offline RL methods decompose such tasks and generate intermediate rewards to mitigate limitations of traditional offline RL, but usually overlook temporal dependencies among subgoals and rely on imprecise reward shaping, leading to suboptimal policies. To address these issues, we propose STO-RL, an offline RL framework that leverages large language models (LLMs) to generate temporally ordered subgoal sequences and corresponding state-to-subgoal-stage mappings. Using this temporal structure, STO-RL applies potential-based reward shaping to transform sparse terminal rewards into dense, temporally consistent signals, promoting subgoal progress while avoiding suboptimal solutions. The resulting augmented dataset with shaped rewards enables efficient offline training of high-performing policies. Evaluations on four discrete and continuous sparse-reward benchmarks demonstrate that STO-RL consistently outperforms state-of-the-art offline goal-conditioned and hierarchical RL baselines, achieving faster convergence, higher success rates, and shorter trajectories. Ablation studies further confirm STO-RL's robustness to imperfect or noisy LLM-generated subgoal sequences, demonstrating that LLM-guided subgoal temporal structures combined with theoretically grounded reward shaping provide a practical and scalable solution for long-horizon offline RL."" }"
2601.08108v1_Debiasing Large Language Models via Adaptive Causa.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Debiasing Large Language Models via Adaptive Causal Prompting with || Sketch-of-Thought || Bowen Li1, Ziqi Xu1, Jing Ren1, Renqiang Luo2, || Xikun Zhang1,Xiuzhen Zhang 1,Yongli Ren 1,Feng Xia 1 || 1RMIT University, Australia, 2Jilin University, China || Correspondence:ziqi.xu@rmit.edu.au || Abstract || ... (truncated) ||  || ```json || { || ""title"": ""Debiasing Large Language Models via Adaptive Causal Prompting with Sketch-of-Thought"", || ""authors"": [""Bowen Li"", ""Ziqi Xu"", ""Jing Ren"", ""Renqiang Luo"", ""Xikun Zhang"", ""Xiuzhen Zhang"", ""Yongli Ren"", ""Feng Xia""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Large Language Models"", ""Prompting Methods"", ""Adaptive Causal Prompting"", ""Sketch-of-Thought"", ""Debiasing""], || ""summary"": ""Despite notable advancements in prompting methods for Large Language Models (LLMs), such as Chain-of-Thought (CoT), existing strategies still suffer from excessive token usage and limited generalisability across diverse reasoning tasks. To address these limitations, we propose an Adaptive Causal Prompting with Sketch-of-Thought (ACPS) framework, which leverages structural causal models to infer the causal effect of a query on its answer and adaptively select an appropriate intervention (i.e., standard front-door and conditional front-door adjustments). This design enables generalisable causal reasoning across heterogeneous tasks without task-specific retraining. By replacing verbose CoT with concise Sketch-of-Thought, ACPS enables efficient reasoning that significantly reduces token usage and inference cost. Extensive experiments on multiple reasoning benchmarks and LLMs demonstrate that ACPS consistently outperforms existing prompting baselines in terms of accuracy, robustness, and computational efficiency."""
2601.08109v1_CSQL Mapping Documents into Causal Databases.pdf,Csql: Mapping Documents into Causal Databases,['Sridhar Mahadevan'],,11.6,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Csql: MappingDocuments intoCausalDatabases || A Preprint || Sridhar Mahadevan || Adobe Research and University of Massachusetts, Amherst || smahadev@adobe.com, mahadeva@umass.edu || January 14, 2026 || Abstract || We describe a novel system, Csql, that automatically converts a collection of unstructure ... (truncated) ||  || ```json || { || ""title"": ""Csql: Mapping Documents into Causal Databases"", || ""authors"": [""Sridhar Mahadevan""], || ""doi"": """", || ""arxiv_id"": ""2601.01457"", || ""keywords"": [""Causality"", ""Natural Language"", ""Databases"", ""SQL"", ""AI"", ""Machine Learning""], || ""summary"": ""We describe a novel system, Csql, that automatically converts a collection of unstructured text documents into an SQL-queryable causal database (CDB). Unlike retrieval-augmented generation (RAG) systems or knowledge-graph-centric approaches, which yield traditional databases, Csql supports causal analysis over document collections rather than purely associative retrieval. Csql also differs fundamentally from traditional causal inference methods, which typically focus on narrow, domain-specific studies grounded in numerical or experimental data. In contrast, Csql operates directly on large collections of unstructured text. A central feature of Csql is that it induces its relational schema directly from language. Unlike prior approaches that rely on hand-designed ontologies, fixed schemas, or domain-specific information extraction pipelines, Csql automates its schema induction."" || } ||  ||  || [ Prompt: 18.2 t/s | Generation: 11.6 t/s ]"
2601.08118v1_MirrorBench An Extensible Framework to Evaluate Us.pdf,MIRRORBENCH: AN EXTENSIBLE FRAMEWORK TO EVALUATE USER-PROXY AGENTS FOR HUMAN-LIKENESS,"['Ashutosh Hathidara', 'Julien Yu', 'Vaishali Senthil', 'Sebastian Schreiber', 'Anil Babu Ankisettipalli']",,11.4,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MIRRORBENCH: ANEXTENSIBLEFRAMEWORK TOEVALUATEUSER-PROXY || AGENTS FORHUMAN-LIKENESS || Ashutosh Hathidara 1 Julien Yu1 Vaishali Senthil1 Sebastian Schreiber 1 Anil Babu Ankisettipalli 1 || ABSTRACT || Large language models (LLMs) are increasingly used as human simulators, both for evaluating co ... (truncated) ||  || { || ""title"": ""MIRRORBENCH: AN EXTENSIBLE FRAMEWORK TO EVALUATE USER-PROXY AGENTS FOR HUMAN-LIKENESS"", || ""authors"": [""Ashutosh Hathidara"", ""Julien Yu"", ""Vaishali Senthil"", ""Sebastian Schreiber"", ""Anil Babu Ankisettipalli""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""user proxy agents"", ""human likeness"", ""large language models"", ""dialogue evaluation"", ""reproducible benchmarking""], || ""summary"": ""MIRRORBENCH is a reproducible and extensible benchmarking framework designed to evaluate user proxies solely on their ability to produce human-like user utterances across diverse conversational tasks. It explicitly decouples evaluation from downstream task success and features a modular execution engine with typed interfaces, metadata-driven registries, multi-backend support, caching, and robust observability. The framework supports pluggable user proxies, datasets, tasks, and metrics, enabling researchers to evaluate arbitrary simulators under a uniform, variance-aware harness. It includes three lexical-diversity metrics and three LLM-judge-based metrics, and across four open datasets, it yields variance-aware results, revealing systematic gaps between user proxies and real human users. The framework is open source and includes a simple command-line interface for running experiments, managing configurations and caching, and generating reports."" || } ||  || [ Prompt: 33.7 t/s | Generation: 11.4 t/s ]"
2601.08125v1_How vehicles change lanes after encountering crash.pdf,How vehicles change lanes after encountering crashes: Empirical analysis and modeling,"['Kequan Chen', 'Yuxuan Wang', 'Pan Liu', 'Victor L. Knoop', 'David Z. W. Wang', 'Yu Han']",,14.5,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || How vehicles change lanes after encountering crashes: Empirical || analysis and modeling ||  ||  || Kequan Chena || aSchool of Civil and Environmental Engineering || Nanyang Technological University, Singapore 639798 || Email: kequan.chen@ntu.edu.sg ||  || Yuxuan Wangb* || bState Key Laboratory of I ... (truncated) ||  || { ""title"": ""How vehicles change lanes after encountering crashes: Empirical analysis and modeling"", ""authors"": [""Kequan Chen"", ""Yuxuan Wang"", ""Pan Liu"", ""Victor L. Knoop"", ""David Z. W. Wang"", ""Yu Han""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""crashes"", ""lane changes"", ""empirical analysis"", ""modeling""], ""summary"": ""This paper explores how vehicles adjust their lanes after encountering crashes. It combines empirical analysis with modeling techniques to understand the behavior of vehicles during and after such incidents. The study aims to provide insights into traffic flow and safety measures."" } ||  || [ Prompt: 43.2 t/s | Generation: 14.5 t/s ]"
2601.08127v1_PathoGen Diffusion-Based Synthesis of Realistic Le.pdf,PathoGen: Diffusion-Based Synthesis of Realistic Lesions in Histopathology Images,"['Mohamad Koohi-Moghadam1*', 'Mohammad-Ali Nikouei Mahani1']",,6.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || PathoGen: Diffusion-Based Synthesis of Realistic Lesions in || Histopathology Images || Mohamad Koohi-Moghadam1*, Mohammad-Ali Nikouei Mahani1, Kyongtae Tyler Bae1 || 1 Department of Diagnostic Radiology, Li Ka Shing Faculty of Medicine, The University of Hong Kong, Pok Fu || Lam, Hong Ko ... (truncated) ||  || { ""title"": ""PathoGen: Diffusion-Based Synthesis of Realistic Lesions in Histopathology Images"", ""authors"": [""Mohamad Koohi-Moghadam1*"", ""Mohammad-Ali Nikouei Mahani1""], ""doi"": """", ""arxiv_id"": ""arXiv:2309.15857"", ""keywords"": [""histopathology"", ""AI"", ""AI augmentation"", ""lesion synthesis"", ""deep learning"", ""image synthesis"", ""tissue morphology"", ""cellular structures"", ""staining characteristics""], ""summary"": ""PathoGen is a diffusion-based generative model that enables controllable, high-fidelity inpainting of lesions into benign histopathology images. Unlike conventional augmentation techniques, PathoGen leverages the iterative refinement process of diffusion models to synthesize lesions with natural tissue boundaries, preserved cellular structures, and authentic staining characteristics. The model is validated across four diverse datasets representing distinct diagnostic challenges: kidney, skin, breast, and prostate pathology. Quantitative assessment confirms that PathoGen outperforms state-of-the-art generative baselines, including conditional GAN and Stable Diffusion, in image fidelity and distributional similarity. Augmenting training sets with PathoGen-synthesized lesions enhances downstream segmentation performance compared to traditional geometric augmentations, particularly in data-scarce regimes. By simultaneously generating realistic morphology and pixel-level ground truth, PathoGen effectively overcomes the manual annotation bottleneck. This approach offers a scalable pathway for developing generalizable medical AI systems despite limited expert-labeled data."" } ||  || [ Prompt: 35.9 t/s | Generation: 6.1 t/s ]"
2601.08128v1_Embedded AI Companion System on Edge Devices.pdf,Embedded AI Companion System on Edge Devices,"['Rahul Gupta', 'Stephen Hsu']",,5.5,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Embedded AI Companion System on Edge Devices || Rahul Gupta 1 and Stephen Hsu 1,2 || 1Superfocus AI || 2Michigan State University || January 14, 2026 || Abstract || Computational resource constraints on edge devices make it difficult to develop a fully embedded || AI companion system with a satisfactory ... (truncated) ||  || { ""title"": ""Embedded AI Companion System on Edge Devices"", ""authors"": [""Rahul Gupta"", ""Stephen Hsu""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""AI Companion"", ""Edge Devices"", ""Memory Systems"", ""Low Latency"", ""Personalization""], ""summary"": ""This paper proposes a memory paradigm for an embedded AI companion system on edge devices. The system alternates between active and inactive phases, performing low-latency dialog during user activity and more intensive memory management during inactivity. The design minimizes latency while maintaining long-term personalization under embedded hardware constraints. An AI Companion benchmark is introduced to holistically evaluate conversational quality and memory capabilities. Experiments show the system outperforms raw LLMs without memory and performs comparably to GPT-3.5 with 16k context window."" } ||  || [ Prompt: 12.7 t/s | Generation: 5.5 t/s ]"
2601.08133v1_How Do Optical Flow and Textual Prompts Collaborat.pdf,How Do Optical Flow and Textual Prompts Collaborate to Assist in Audio-Visual Semantic Segmentation?,"['Peng Gao', 'Yujian Lee', 'Yongqi Xu', 'Wentao Fan']",,5.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || How Do Optical Flow and Textual Prompts Collaborate to Assist in Audio-Visual || Semantic Segmentation? || Peng Gao1,2,, Yujian Lee 1,2,, Yongqi Xu 3, Wentao Fan 1,2, || 1Hong Kong Baptist University, Hong Kong, China || 2Guangdong Provincial/Zhuhai Key Laboratory IRADS || and Department of Comput ... (truncated) ||  || ```json || { || ""title"": ""How Do Optical Flow and Textual Prompts Collaborate to Assist in Audio-Visual Semantic Segmentation?"", || ""authors"": [""Peng Gao"", ""Yujian Lee"", ""Yongqi Xu"", ""Wentao Fan""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""audio-visual semantic segmentation"", ""optical flow"", ""textual prompts"", ""semantic understanding"", ""audio-visual scenes""], || ""summary"": ""Audio-visual semantic segmentation (AVSS) extends the audio-visual segmentation (AVS) task, requiring a semantic understanding of audio-visual scenes beyond merely identifying sound-emitting objects at the visual pixel level. Our approach, Stepping Stone Plus (SSP), integrates optical flow and textual prompts to assist the segmentation process. In scenarios where sound sources frequently coexist with moving objects, SSP leverages optical flow to capture motion dynamics, providing essential temporal context for precise segmentation. To address stationary sound-emitting objects, SSP incorporates specific textual prompts and a visual-textual alignment module (VTA) to facilitate cross-modal integration and deliver more coherent and contextually relevant semantic interpretations. Experimental results demonstrate that SSP outperforms existing AVS methods, delivering efficient and precise segmentation results."" || } ||  ||  || [ Prompt: 13.0 t/s | Generation: 5.1 t/s ]"
2601.08139v1_Subspace Alignment for Vision-Language Model Test-.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Subspace Alignment for Vision-Language Model Test-time Adaptation || Zhichen Zeng1, Wenxuan Bao1, Xiao Lin1, Ruizhong Qiu1, Tianxin Wei1, Xuying Ning1, || Yuchen Yan2,Chen Luo 2,Monica Xiao Cheng 2,Jingrui He 1,Hanghang Tong 1 || 1University of Illinois Urbana-Champaign, 2Amazon, || {zhichenz,  ... (truncated) ||  || { || ""title"": ""Subspace Alignment for Vision-Language Model Test-time Adaptation"", || ""authors"": [""Zhichen Zeng"", ""Wenxuan Bao"", ""Xiao Lin"", ""Ruizhong Qiu"", ""Tianxin Wei"", ""Xuying Ning"", ""Yuchen Yan"", ""Chen Luo"", ""Monica Xiao Cheng"", ""Jingrui He"", ""Hanghang Tong""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Vision-Language Models"", ""Test-time Adaptation"", ""Subspace Alignment"", ""Distribution Shifts"", ""Zero-shot Prediction""], || ""summary"": ""Vision-language models (VLMs) exhibit remarkable zero-shot capabilities but are vulnerable to distribution shifts. Test-time adaptation (TTA) is a prevalent strategy to adapt VLMs to unlabeled test data. However, existing TTA methods rely heavily on zero-shot predictions as pseudo-labels for self-training, which can be unreliable under distribution shifts and misguide adaptation due to two fundamental limitations: the modality gap and visual nuisance. To address these limitations, we propose SubTTA, which aligns the semantic subspaces of both modalities to enhance zero-shot predictions and better guide the TTA process. SubTTA extracts the principal subspaces of both modalities and aligns the visual manifold to the textual semantic anchor by minimizing their chordal distance. It also projects the aligned visual features onto the task-specific textual subspace to filter out task-irrelevant noise. Extensive experiments on various benchmarks and VLM architectures demonstrate the effectiveness of SubTTA, yielding an average improvement of 2.24% over state-of-the-art TTA methods."""
2601.08141v1_Qalb Largest State-of-the-Art Urdu Large Language .pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Qalb: Largest State-of-the-Art Urdu Large || Language Model for 230M Speakers with || Systematic Continued Pre-training || 1st Muhammad Taimoor Hassan || Auburn University, USA || Computer Science and Software Engineering || muh0001@auburn.edu || mtaimoorhas1@gmail.com || 2st Jawad Ahmed || BHT Berlin, German ... (truncated) ||  || { || ""title"": ""Largest State-of-the-Art Urdu Large Language Model for 230M Speakers with Systematic Continued Pre-training"", || ""authors"": [""1st Muhammad Taimoor Hassan"", ""2st Jawad Ahmed"", ""3st Muhammad Awais""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Urdu language model"", ""continued pre-training"", ""low-resource NLP"", ""LoRA"", ""language adaptation""], || ""summary"": ""Despite remarkable progress in large language models, Urdu, spoken by over 230 million people, remains critically underrepresented in modern NLP systems. Existing multilingual models demonstrate poor performance on Urdu-specific tasks. We introduce Qalb, an Urdu language model developed through a two-stage approach: continued pre-training followed by supervised fine-tuning. Starting from LLaMA 3.1 8B, we perform continued pre-training on a dataset of 1.97 billion tokens, comprising diverse Urdu text and 140 million tokens of English Wikipedia data. We then fine-tune the model on the Alif Urdu-instruct dataset. Qalb demonstrates substantial improvements, achieving a weighted average score of 90.34 and outperforming the previous state-of-the-art Alif-1.0-Instruct model by 3.24 points, while also surpassing the base LLaMA-3.1 8B-Instruct model by 44.64 points. Qalb achieves state-of-the-art performance across seven diverse tasks including Classification, Sentiment Analysis, and Reasoning. Our results demonstrate that continued pre-training on diverse, high-quality language data, combined with targeted instruction fine-tuning, effectively adapts foundation models to low-resource languages."""
2601.08146v2_Mechanisms are Transferable Data-Efficient Low-Res.pdf,Mechanisms are Transferable: Data-Efficient Low-Resource Adaptation via Circuit-Targeted Supervised Fine-Tuning,"['Khumaisa Nuraini', 'Ayu Purwarianti', 'Alham Fikri Aji', 'Derry Wijaya']",,11.2,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Mechanisms are Transferable: Data-Efficient Low-Resource Adaptation || via Circuit-Targeted Supervised Fine-Tuning || Khumaisa Nuraini1, Ayu Purwarianti2, Alham Fikri Aji3, Derry Wijaya1,4, || 1Monash University Indonesia, 2Institute Teknologi Bandung, 3MBZUAI, 4Boston University || Abstract || Ad ... (truncated) ||  || ```json || { || ""title"": ""Mechanisms are Transferable: Data-Efficient Low-Resource Adaptation via Circuit-Targeted Supervised Fine-Tuning"", || ""authors"": [""Khumaisa Nuraini"", ""Ayu Purwarianti"", ""Alham Fikri Aji"", ""Derry Wijaya""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""transfer learning"", ""low-resource adaptation"", ""supervised fine-tuning"", ""circuit-targeted"", ""catastrophic forgetting""], || ""summary"": ""Adapting Large Language Models (LLMs) to low-resource languages is challenging due to scarce labeled data, unstable full-model fine-tuning, and cross-lingual tuning leading to catastrophic forgetting. We propose Circuit-Targeted Supervised Fine-Tuning (CT-SFT), which uses a label-balanced mean baseline and task-directional relevance scoring to identify a sparse set of task-relevant attention heads in a proxy-language checkpoint. CT-SFT improves cross-lingual accuracy over continued full fine-tuning while updating only a small subset of model parameters. We find an editing-preserving trade-off: harder transfers favor editing circuit heads, while easier transfers often favor near-zero (low-relevance) updates, preserving the source mechanism. CT-SFT also substantially reduces catastrophic forgetting, preserving proxy/source-language competence during transfer."" || } ||  ||  || [ Prompt: 33.6 t/s | Generation: 11.2 t/s ]"
2601.08148v1_Enriching Semantic Profiles into Knowledge Graph f.pdf,Enriching Semantic Profiles into Knowledge Graph for Recommender Systems Using Large Language Models,"['Seokho Ahn', 'Sungbok Shin', 'Young-Duk Seo']",10.1145/3770854.3780324,11.2,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Enriching Semantic Profiles into Knowledge Graph for || Recommender Systems Using Large Language Models || Seokho Ahn || Inha University || Department of Electrical and || Computer Engineering || Incheon, South Korea || sokho0514@inha.edu || Sungbok Shin || Sogang University || Department of Computer Science || and ... (truncated) ||  || { ""title"": ""Enriching Semantic Profiles into Knowledge Graph for Recommender Systems Using Large Language Models"", ""authors"": [""Seokho Ahn"", ""Sungbok Shin"", ""Young-Duk Seo""], ""doi"": ""10.1145/3770854.3780324"", ""arxiv_id"": """", ""keywords"": [""Recommendation"", ""Semantic Profiling"", ""Large Language Models"", ""Knowledge Graphs""], ""summary"": ""Rich and informative profiling to capture user preferences is essential for improving recommendation quality. However, there is still no consensus on how best to construct and utilize such profiles. To address this, we revisit recent profiling-based approaches in recommender systems along four dimensions: 1) knowledge base, 2) preference indicator, 3) impact range, and 4) subject. We argue that large language models (LLMs) are effective at extracting compressed rationales from diverse knowledge sources, while knowledge graphs (KGs) are better suited for propagating these profiles to extend their reach. Building on this insight, we propose a new recommendation model, called SPiKE. SPiKE consists of three core components: i) Entity profile generation, which uses LLMs to generate semantic profiles for all KG entities; ii) Profile-aware KG aggregation, which integrates these profiles into the KG; and iii) Pairwise profile preference matching, which aligns LLM- and KG-based representations during training. In experiments, we demonstrate that SPiKE consistently outperforms state-of-the-art KG- and LLM-based recommenders in real-world settings."" } ||  || [ Prompt: 35.5 t/s | Generation: 11.2 t/s ]"
2601.08149v1_Dynamic Graph Structure Learning via Resistance Cu.pdf,Dynamic Graph Structure Learning via Resistance Curvature Flow,"['Chaoqun Fei', 'Huanjiang Liu', 'Tinglve Zhou', 'Y angyang Li 1', 'Tianyong Hao']",,13.5,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Highlights || Dynamic Graph Structure Learning via Resistance Curvature Flow || Chaoqun Fei, Huanjiang Liu, Tinglve Zhou, Y angyang Li 1, Tianyong Hao || Introduces a novel and computationally e cient curvature ow based on e ec- || tive resistance from circuit theory, establishing a new paradi ... (truncated) ||  || { ""title"": ""Dynamic Graph Structure Learning via Resistance Curvature Flow"", ""authors"": [""Chaoqun Fei"", ""Huanjiang Liu"", ""Tinglve Zhou"", ""Y angyang Li 1"", ""Tianyong Hao""], ""doi"": """", ""arxiv_id"": ""2601.08149v1"", ""keywords"": [""Dynamic Graph Structure Learning"", ""Resistance Curvature Flow"", ""Manifold Enhancement"", ""Noise Suppression"", ""Deep Learning"", ""Graph Structure Learning""], ""summary"": ""Introduces a novel curvature flow based on effective resistance from circuit theory, establishing a new paradigm for geometric graph structure evolution. Formulates the dynamic evolution equation of RCF, elucidates its mechanisms for manifold enhancement and noise suppression, and highlights its differentiability and compatibility with deep learning frameworks. Proposes an efficient Dynamic Graph Structure Learning method based on RCF. Extensive experiments on deep metric learning, manifold learning and graph structure learning tasks demonstrate that DGSL-RCF consistently improves representation quality and downstream performance with low runtime cost."" } ||  || [ Prompt: 36.1 t/s | Generation: 13.5 t/s ]"
2601.08156v1_Project Synapse A Hierarchical Multi-Agent Framewo.pdf,Project Synapse: A Hierarchical Multi-Agent Framework with Hybrid Memory for Autonomous Resolution of Last-Mile Delivery Disruptions,"['Arin Gopalan Yadav', 'Varad Dherange', 'Kumar Shivam']",,5.9,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Project Synapse: A Hierarchical || Multi-Agent Framework with Hybrid || Memory for Autonomous Resolution of || Last-Mile Delivery Disruptions || Arin Gopalan Yadav || Varad Dherange || Kumar Shivam || Department of Computer Science Engineering || Vellore Institite of Technology University || arin.technovate@o ... (truncated) ||  || { ""title"": ""Project Synapse: A Hierarchical Multi-Agent Framework with Hybrid Memory for Autonomous Resolution of Last-Mile Delivery Disruptions"", ""authors"": [""Arin Gopalan Yadav"", ""Varad Dherange"", ""Kumar Shivam""], ""doi"": """", ""arxiv_id"": ""2601.08156"", ""keywords"": [""last-mile delivery"", ""disruptions"", ""multi-agent"", ""hybrid memory"", ""autonomous resolution""], ""summary"": ""This paper introduces Project Synapse, a novel agentic framework designed for the autonomous resolution of last-mile delivery (LMD) disruptions. Synapse employs a hierarchical multi-agent architecture with a central Resolution Supervisor agent performing strategic task decomposition and delegating sub-tasks to specialized worker agents responsible for tactical execution. A core contribution is a novel Hybrid Memory Architecture integrating short-term working memory, long-term episodic memory of past incidents, and semantic memory of organizational policies. This cognitive architecture enables stateful, context-aware, and factually-grounded reasoning. The system is orchestrated using LangGraphto manage complex, cyclical workflows. A benchmark dataset of 30 complex disruption scenarios was curated from qualitative analysis of over 6,000 real-world user reviews. The system's performance was evaluated using an LLM-as-a-Judge protocol with explicit bias mitigation. Initial results are highly promising, with the Synapse system achieving 1."" } ||  || [ Prompt: 14.3 t/s | Generation: 5.9 t/s ]"
2601.08160v1_SwiftMem Fast Agentic Memory via Query-aware Index.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SwiftMem: Fast Agentic Memory via Query-aware Indexing || Anxin Tian 1 Yiming Li 1 Xing Li 1 Hui-Ling Zhen 1 Lei Chen 1 Xianzhi Yu1 Zhenhua Dong 1 || Mingxuan Yuan1 || Abstract || Agentic memory systems have become critical for || enabling LLM agents to maintain long-term con- || text and retrieve re ... (truncated) ||  || { || ""title"": ""SwiftMem: Fast Agentic Memory via Query-aware Indexing"", || ""authors"": [""Anxin Tian"", ""Yiming Li"", ""Xing Li"", ""Hui-Ling Zhen"", ""Lei Chen"", ""Xianzhi Yu"", ""Zhenhua Dong"", ""Mingxuan Yuan""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Agentic Memory"", ""Query-aware Indexing"", ""Temporal Indexing"", ""Semantic DAG-Tag Index"", ""Memory Fragmentation"", ""Cache Locality""], || ""summary"": ""Agentic memory systems are crucial for enabling large language models (LLMs) to maintain long-term context and retrieve relevant information efficiently. However, existing memory frameworks suffer from a fundamental limitation: they perform exhaustive retrieval across the entire storage layer regardless of query characteristics. SwiftMem, a query-aware agentic memory system, achieves sub-linear retrieval through specialized indexing over temporal and semantic dimensions. Our temporal index enables logarithmic-time range queries for time-sensitive retrieval, while the semantic DAG-Tag index maps queries to relevant topics through hierarchical tag structures. To address memory fragmentation during growth, we introduce an embedding-tag co-consolidation mechanism that reorganizes storage based on semantic clusters to improve cache locality. Experiments on Lo-CoMo and LongMemEval benchmarks demonstrate that SwiftMem achieves 47 faster search compared to state-of-the-art baselines while maintaining competitive accuracy, enabling practical deployment of memory-augmented LLM agents."""
2601.08166v1_ZeroDVFS Zero-Shot LLM-Guided Core and Frequency A.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ZeroDVFS: Zero-Shot LLM-Guided Core and Frequency || Allocation for Embedded Platforms || Mohammad Pivezhandi1, Mahdi Banisharif2, Abusayeed Saifullah3, and Ali Jannesari2 || 1Wayne State University || 2Iowa State University || 3The University of Texas at Dallas || Abstract || Dynamic voltage and freque ... (truncated) ||  || { || ""title"": ""Zero-Shot LLM-Guided Core and Frequency Allocation for Embedded Platforms"", || ""authors"": [""Mohammad Pivezhandi1"", ""Mahdi Banisharif2"", ""Abusayeed Saifullah3"", ""Ali Jannesari2""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Dynamic Voltage and Frequency Scaling (DVFS)"", ""Task-to-Core Allocation"", ""Multi-Agent Reinforcement Learning (MARL)"", ""Energy Efficiency"", ""Performance Optimization"", ""Embedded Systems""], || ""summary"": ""Dynamic voltage and frequency scaling (DVFS) and task-to-core allocation are critical for thermal management and balancing energy and performance in embedded systems. Existing approaches either rely on utilization-based heuristics that overlook stall times, or require extensive offline profiling for table generation, preventing runtime adaptation. We propose a model-based hierarchical multi-agent reinforcement learning (MARL) framework for thermal- and energy-aware scheduling on multi-core platforms. Two collaborative agents decompose the exponential action space, achieving 358ms latency for subsequent decisions. First decisions require 3.5 to 8.0s including one-time LLM feature extraction. An accurate environment model leverages regression techniques to predict thermal dynamics and performance states. When combined with LLM-extracted semantic features, the environment model enables zero-shot deployment for new workloads on trained platforms by generating synthetic training data without requiring workload-specific profiling samples. We introduce LLM-based semantic feature extraction that characterizes OpenMP programs through 13 code-level features without execution. The Dyna-Q-inspired framework integrates direct reinforcement learning with model-based planning, achieving 20 faster convergence than model-free methods. Experiments on BOTS and PolybenchC benchmarks across NVIDIA Jetson TX2, Jetson Orin NX, RubikPi, and Intel Core i7 demonstrate 7.09 better energy efficiency and 4.0 better makespan than Linux ondemand governor. First-decision latency is 8,300 times faster than table-based profiling, enabling practical deployment in dynamic embedded systems."""
2601.08173v1_The Agents First Day Benchmarking Learning Explora.pdf,"The Agents First Day: Benchmarking Learning, Exploration, and Scheduling in the Workplace Scenarios","['Daocheng Fu1,2', 'Jianbiao Mei3,2', 'Rong Wu3,2', 'Xuemeng Yang2', 'Jia Xu2', 'Ding Wang 2', 'Pinlong Cai 2', 'Yong Liu 3', 'B Licheng Wen 2', 'B Botian Shi 2']",,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || The Agents First Day: Benchmarking Learning, Exploration, and || Scheduling in the Workplace Scenarios || Daocheng Fu1,2, || , Jianbiao Mei3,2, || , Rong Wu3,2, || , Xuemeng Yang2, || , || Jia Xu2,Ding Wang 2,Pinlong Cai 2,Yong Liu 3,B || ,Licheng Wen 2,4,5,B || ,Botian Shi 2,B || 1Fudan University, 2Shanghai AI ... (truncated) ||  || { ""title"": ""The Agents First Day: Benchmarking Learning, Exploration, and Scheduling in the Workplace Scenarios"", ""authors"": [""Daocheng Fu1,2"", ""Jianbiao Mei3,2"", ""Rong Wu3,2"", ""Xuemeng Yang2"", ""Jia Xu2"", ""Ding Wang 2"", ""Pinlong Cai 2"", ""Yong Liu 3"", ""B Licheng Wen 2"", ""B Botian Shi 2""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Multi-modal Large Language Models"", ""Workplace Automation"", ""Dynamic Task Scheduling"", ""Active Exploration"", ""Continuous Learning"", ""Stochastic Environment""], ""summary"": ""The rapid evolution of Multi-modal Large Language Models (MLLMs) has advanced workflow automation, but existing research mainly focuses on performance upper bounds in controlled environments, overlooking robustness for stochastic real-world deployment. We identify three key challenges: dynamic task scheduling, active exploration under uncertainty, and continuous learning from experience. To bridge this gap, we introduce Trainee-Bench, a dynamic evaluation environment that simulates a 'trainee' agent continuously exploring a novel setting. Unlike traditional benchmarks, Trainee-Bench evaluates agents along three dimensions: context-aware scheduling for streaming tasks with varying priorities, prudent information acquisition to reduce hallucination via active exploration, and continuous evolution by distilling generalized strategies from rule-based, dynamically generated tasks. Experiments show that cutting-edge agents have significant deficiencies in dynamic environments, especially in active exploration and continual learning. Our work establishes a framework for assessing agent reliability, shifting evaluation from static tests to realistic, production-oriented scenarios. Our codes are available at https://github.com/KnowledgeXLab/EvoEnv."" }"
2601.08176v1_Prompt-Based Clarity Evaluation and Topic Detectio.pdf,Prompt-Based Clarity Evaluation and Topic Detection in Political Question Answering,"['Lavanya Prahallad', 'Sai Utkarsh Choudarypally', 'Pragna Prahallad', 'Pranathi Prahallad']",,11.5,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Prompt-Based Clarity Evaluation and Topic || Detection in Political Question Answering || Lavanya Prahallad || Research Spark Hub Inc. || Dublin, CA, USA || lavanya@researchsparkhub.com || Sai Utkarsh Choudarypally || Emerald High School || Dublin, CA, USA || choudarypally.sai2009@gmail.com || Pragna Prahallad || E ... (truncated) ||  || ```json || { || ""title"": ""Prompt-Based Clarity Evaluation and Topic Detection in Political Question Answering"", || ""authors"": [""Lavanya Prahallad"", ""Sai Utkarsh Choudarypally"", ""Pragna Prahallad"", ""Pranathi Prahallad""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Clarity evaluation"", ""Prompt engineering"", ""Political Question Answering"", ""Large language models"", ""Chain-of-thought prompting""], || ""summary"": ""This paper studies prompt-based clarity evaluation using the CLARITY dataset from the SemEval-2026 shared task. It compares a GPT-3.5 baseline with GPT-5.2 evaluated under three prompting strategies: simple prompting, chain-of-thought prompting, and chain-of-thought with few-shot examples. Results show that GPT-5.2 consistently outperforms the GPT-3.5 baseline on clarity prediction, with accuracy improving from 56% to 63% under chain-of-thought with few-shot prompting. Chain-of-thought prompting yields the highest evasion accuracy (34%), though improvements are less stable across fine-grained evasion categories. Topic identification accuracy is improved from 60% to 74% relative to human annotations. Overall, prompt design reliably improves high-level clarity evaluation, while fine-grained evasion and topic detection remain challenging despite structured reasoning prompts."" || } ||  ||  || [ Prompt: 16.0 t/s | Generation: 11.5 t/s ]"
2601.08179v1_Instruction-Driven 3D Facial Expression Generation.pdf,Instruction-Driven 3D Facial Expression Generation and Transition,"['Anh H. V o', 'Tae-Seok Kim', 'Hulin Jin', 'Soo-Mi Choi', 'Yong-Guk Kim*']",,11.6,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || JOURNAL OF LATEX CLASS 1 || Instruction-Driven 3D Facial Expression Generation || and Transition || Anh H. V o, Tae-Seok Kim, Hulin Jin, Soo-Mi Choi, and Yong-Guk Kim* || AbstractA 3D avatar typically has one of six cardinal facial || expressions. To simulate realistic emotional variation, we shou ... (truncated) ||  || { ""title"": ""Instruction-Driven 3D Facial Expression Generation and Transition"", ""authors"": [""Anh H. V o"", ""Tae-Seok Kim"", ""Hulin Jin"", ""Soo-Mi Choi"", ""Yong-Guk Kim*""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Instruction-Driven"", ""Facial Expression and Transition"", ""Controllable Avatar"", ""CK+ and CelebV-HQ datasets""], ""summary"": ""A 3D avatar typically has one of six cardinal facial expressions. To simulate realistic emotional variation, we should be able to render a facial transition between two arbitrary expressions. This study presents a new framework for instruction-driven facial expression generation that produces a 3D face and, starting from an image of the face, transforms the facial expression from one designated facial expression to another. The Instruction-driven Facial Expression Decomposer (IFED) module is introduced to facilitate multimodal data learning and capture the correlation between textual descriptions and facial expression features. Subsequently, we propose the Instruction to Facial Expression Transition (I2FET) method, which leverages IFED and a vertex reconstruction loss function to refine the semantic comprehension of latent vectors, thus generating a facial expression sequence according to the given instruction. Lastly, we present the Facial Expression Transition model to generate smooth transitions between facial expressions. Extensive evaluation suggests that the proposed model outperforms state-of-the-art methods on the CK+ and CelebV-HQ datasets. The results show that our framework can generate facial expression trajectories according to text instruction. Considering that text prompts allow us to make diverse descriptions of human emotional states, the repertoire of facial expressions and the transitions between them can be expanded greatly. We expect our framework to find various practical applications. More information about our project can be found at https://vohoanganh.github.io/tg3dfet/"" } ||  || [ Prompt: 38.4 t/s | Generation: 11.6 t/s ]"
2601.08183v2_GI-Bench A Panoramic Benchmark Revealing the Knowl.pdf,GI-Bench: A Panoramic Benchmark Revealing the Knowledge-Experience Dissociation of Multimodal Large Language Models in Gastrointestinal Endoscopy Against Clinical Standards,"['Yan Zhu', 'Te Luo', 'Pei-Yao Fu', 'Zhen Zhang', 'Zi-Long Wang', 'Yi-Fan Qu', 'Zi-Han Geng', 'Jia-Qi Xu', 'Lu Yao', 'Li-Yun Ma', 'Wei Su', 'Wei-Feng Chen', 'Quan-Lin Li', 'Shuo Wang', 'Ping-Hong Zhou']",,12.8,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || GI-Bench: A Panoramic Benchmark Revealing the Knowledge-Experience Dissociation || of Multimodal Large Language Models in Gastrointestinal Endoscopy Against Clinical || Standards || Yan Zhu1,2,3,4*, Te Luo1,2,3*, Pei-Yao Fu1,4*, Zhen Zhang1,4*, Zi-Long Wang5, Yi-Fan Qu1,4, || Zi-Han Geng1,4, Ji ... (truncated) ||  || { ""title"": ""GI-Bench: A Panoramic Benchmark Revealing the Knowledge-Experience Dissociation of Multimodal Large Language Models in Gastrointestinal Endoscopy Against Clinical Standards"", ""authors"": [""Yan Zhu"", ""Te Luo"", ""Pei-Yao Fu"", ""Zhen Zhang"", ""Zi-Long Wang"", ""Yi-Fan Qu"", ""Zi-Han Geng"", ""Jia-Qi Xu"", ""Lu Yao"", ""Li-Yun Ma"", ""Wei Su"", ""Wei-Feng Chen"", ""Quan-Lin Li"", ""Shuo Wang"", ""Ping-Hong Zhou""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""GI-Bench"", ""Multimodal Large Language Models"", ""Gastrointestinal Endoscopy"", ""Clinical Workflow"", ""Human Benchmarks"", ""Diagnostic Reasoning""], ""summary"": ""This study systematically evaluates state-of-the-art Multimodal Large Language Models (MLLMs) across a panoramic gastrointestinal endoscopy workflow. Twelve MLLMs were evaluated across a five-stage clinical workflow: anatomical localization, lesion identification, diagnosis, findings description, and management. Model performance was benchmarked against three junior endoscopists and three residency trainees using Macro-F1, mean Intersection-over-Union (mIoU), and multi-dimensional Likert scale. The results show that Gemini-3-Pro achieved state-of-the-art performance in diagnostic reasoning."" } ||  || [ Prompt: 37.1 t/s | Generation: 12.8 t/s ]"
2601.08185v1_Autonomous Materials Exploration by Integrating Au.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Autonomous Materials Exploration by Integrating Automated Phase Identification || and AI-Assisted Human Reasoning || Ming-Chiang Chang, 1, 2, Maximilian Amsler, 1, 2, Duncan R. Sutherland, 1 Sebastian || Ament,3 Katie R. Gann, 1 Lan Zhou, 4 Louisa M. Smieska, 5 Arthur R. Woll, 5 John || M. Greg ... (truncated) ||  || ```json || { || ""title"": ""Autonomous Materials Exploration by Integrating Automated Phase Identification and AI-Assisted Human Reasoning"", || ""authors"": [""Ming-Chiang Chang"", ""Maximilian Amsler"", ""Duncan R. Sutherland"", ""Sebastian Ament"", ""Katie R. Gann"", ""Lan Zhou"", ""Louisa M. Smieska"", ""Arthur R. Woll"", ""John M. Gregoire"", ""Carla P. Gomes"", ""R. Bruce van Dover"", ""Michael O. Thompson""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""materials science"", ""autonomous experimentation"", ""AI"", ""robotics"", ""phase identification"", ""human reasoning"", ""materials synthesis"", ""thin-film samples"", ""laser spike annealing"", ""metastable phases"", ""cationic substitutional doping"", ""anatase to rutile transformation""], || ""summary"": ""Autonomous experimentation holds the potential to accelerate materials development by combining artificial intelligence (AI) with modular robotic platforms to explore extensive combinatorial chemical and processing spaces. We present an autonomous materials synthesis extension to SARA, utilizing phase information provided by an automated probabilistic phase labeling algorithm to expedite the search for targeted phase regions. By incorporating human input into an expanded SARA-H framework, we enhance the efficiency of the underlying reasoning process. We demonstrate the efficiency of our AI implementation and show that human input can contribute to significant improvement in sampling efficiency. We conduct experimental active learning campaigns using robotic processing of thin-film samples of several oxide material systems, including Bi2O3, SnOx, and BiTiO, using lateral-gradient laser spike annealing to synthesize and kinetically trap metastable phases. We showcase the utility of human-in-the-loop autonomous experimentation for the BiTiO system, where we identify extensive processing domains that stabilize Bi2O3 and Bi2Ti2O7, explore dwell-dependent ternary oxide phase behavior, and provide evidence confirming predictions that cationic substitutional doping of TiO2 with Bi inhibits the unfavorable transformation of the metastable anatase to the ground-state rutile phase. The autonomous methods we have developed enable the discovery of new materials and new understanding of materials synthesis and properties."""
2601.08187v2_Improving LLM Reasoning with Homophily-aware Struc.pdf,Improving LLM Reasoning with Homophily-Aware Structural and Semantic Text-Attributed Graph Compression,"['Zijun Di', 'Bin Lu', 'Huquan Kang', 'Luoyi Fu', 'Jiaxin Ding', 'Xiaoying Gan', 'Lei Zhou', 'Xinbing Wang', 'Chenghu Zhou']",,5.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || IMPROVINGLLM REASONING WITHHOMOPHILY-AWARE || STRUCTURAL ANDSEMANTICTEXT-ATTRIBUTEDGRAPH || COMPRESSION || A PREPRINT || Zijun Di || Shanghai Jiao Tong University || Shanghai, China || dzj75du@sjtu.edu.cn || Bin Lu || Shanghai Jiao Tong University || Shanghai, China || robinlu1209@sjtu.edu.cn || Huquan Kang || Shanghai J ... (truncated) ||  || { || ""title"": ""Improving LLM Reasoning with Homophily-Aware Structural and Semantic Text-Attributed Graph Compression"", || ""authors"": [""Zijun Di"", ""Bin Lu"", ""Huquan Kang"", ""Luoyi Fu"", ""Jiaxin Ding"", ""Xiaoying Gan"", ""Lei Zhou"", ""Xinbing Wang"", ""Chenghu Zhou""], || ""doi"": """", || ""arxiv_id"": ""2601.08187v2"", || ""keywords"": [""Large Language Models"", ""Text-Attributed Graphs"", ""Homophily"", ""Structural Compression"", ""Semantic Compression"", ""Graph Reasoning""], || ""summary"": ""This paper proposes HS2C, a framework for improving LLM reasoning performance by exploiting graph homophily. Structurally, it performs a global hierarchical partition to identify homophilic communities and discard noise. Semantically, it compresses redundant background contexts into concise community-level consensus, selectively preserving semantically homophilic information. Extensive experiments on various benchmarks demonstrate that HS2C enhances compression rate and inference accuracy, validating its superiority and scalability."" || } ||  || [ Prompt: 13.0 t/s | Generation: 5.1 t/s ]"
2601.08189v2_ForgetMark Stealthy Fingerprint Embedding via Targ.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || FORGETMARK: STEALTHY FINGERPRINT EMBEDDING VIA TARGETED UNLEARNING || IN LANGUAGE MODELS || Zhenhua Xu1,* , Haobo Zhang2,3* , Zhebo Wang1,2, Qichen Liu2,Haitao Xu1, Wenpeng Xing1,2,Meng Han1,2, || 1Zhejiang University, 2GenTel.io, 3Zhejiang University of Technology || ABSTRACT || Existing invasive ... (truncated) ||  || ```json || { || ""title"": ""FORGETMARK: STEALTHY FINGERPRINT EMBEDDING VIA TARGETED UNLEARNING"", || ""authors"": [""Zhenhua Xu1"", ""Haobo Zhang2"", ""Zhebo Wang1"", ""Qichen Liu2"", ""Haitao Xu1"", ""Wenpeng Xing1"", ""Meng Han1""], || ""doi"": ""2026 IEEE. Published inICASSP 2026  2026 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), scheduled for 38 May 2026 in Barcelona, Spain"", || ""arxiv_id"": """", || ""keywords"": [""Large Language Model"", ""Copyright protection"", ""Model Fingerprinting"", ""Machine Unlearning""], || ""summary"": ""ForgetMark is a stealthy fingerprinting framework that encodes provenance via targeted unlearning. It builds a compact, human-readable key-value set with an assistant model and predictive-entropy ranking, then trains lightweight LoRA adapters to suppress the original values on their keys while preserving general capabilities. Ownership is verified under black/gray-box access by aggregating likelihood and semantic evidence into a fingerprint success rate. By relying on probabilistic forgetting traces rather than fixed trigger-response patterns, ForgetMark avoids high-perplexity triggers, reduces detectability, and lowers false triggers. Across diverse architectures and settings, it achieves 100% ownership verification on fingerprinted models while maintaining standard performance, surpasses backdoor baselines in stealthiness and robustness to model merging, and remains effective under moderate incremental fine-tuning."""
2601.08196v1_Evaluating Implicit Regulatory Compliance in LLM T.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Evaluating Implicit Regulatory Compliance in LLM Tool Invocation via || Logic-Guided Synthesis || Da Song1,2, Yuheng Huang3*, Boqi Chen4, Tianshuo Cong1,2, || Randy Goebel5,Lei Ma 3,5,Foutse Khomh 6 || Abstract || The integration of large language models || (LLMs) into autonomous agents has enabled || c ... (truncated) ||  || { || ""title"": ""Evaluating Implicit Regulatory Compliance in LLM Tool Invocation via Logic-Guided Synthesis"", || ""authors"": [""Da Song"", ""Yuheng Huang"", ""Boqi Chen"", ""Tianshuo Cong"", ""Randy Goebel"", ""Lei Ma"", ""Foutse Khomh""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""large language models"", ""tool invocation"", ""regulatory compliance"", ""logic-guided synthesis"", ""fuzzing"", ""safety constraints""], || ""summary"": ""The integration of large language models (LLMs) into autonomous agents has enabled complex tool use, but in high-stakes domains, these systems must strictly adhere to regulatory standards beyond simple functional correctness. Existing benchmarks often overlook implicit regulatory compliance, thus failing to evaluate whether LLMs can autonomously enforce mandatory safety constraints. We introduce LOGISAFETYGEN, a framework that converts unstructured regulations into Linear Temporal Logic oracles and employs logic-guided fuzzing to synthesize valid, safety-critical traces. Building on this framework, we construct LOGISAFETYBENCH, a benchmark comprising 240 human-verified tasks that require LLMs to generate Python programs satisfying both functional objectives and latent compliance rules. Evaluations of 13 state-of-the-art (SOTA) LLMs reveal that larger models, despite achieving better functional correctness, frequently prioritize task completion over safety, resulting in non-compliant behavior."""
2601.08211v1_Adapting Rules of Official International Mahjong f.pdf,Adapting Rules of Official International Mahjong for Online Players,"['Chucai Wang', 'Lingfeng Li', 'Yunlong Lu', 'Wenxin Li']",,11.8,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Adapting Rules of Official International Mahjong || for Online Players || Chucai Wang || School of Computer Science || Peking University || Beijing, China || wangchucai@pku.edu.cn || Lingfeng Li || School of Computer Science || Peking University || Beijing, China || Lingfengli@stu.pku.edu.cn || Yunlong Lu || School of Co ... (truncated) ||  || { ""title"": ""Adapting Rules of Official International Mahjong for Online Players"", ""authors"": [""Chucai Wang"", ""Lingfeng Li"", ""Yunlong Lu"", ""Wenxin Li""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Mahjong"", ""game design"", ""champion AI""], ""summary"": ""Official International Mahjong, a four-player traditional game with millions of players worldwide, has rules designed for offline players. However, online players have fragmented playtime and unfixed combination of opponents. This work employs a world champion AI to engage in self-play competitions and conduct statistical data analysis. It reveals the first-mover advantage and issues in the subgoal scoring settings. Based on findings, rule adaptations are proposed to make the game more suitable for the online environment, such as introducing compensatory points for the first-mover advantage and refining the scores of subgoals for different tile patterns. The work further discusses the balance of this traditional game in one-round case and proposes some rule adaptions to provide a better experience for online players. The revised Mahjong game is implemented online and open for online players."" } ||  || [ Prompt: 35.3 t/s | Generation: 11.8 t/s ]"
2601.08223v2_DNF Dual-Layer Nested Fingerprinting for Large Lan.pdf,DNF: DUAL-LAYER NESTED FINGERPRINTING FOR LARGE LANGUAGE MODEL INTELlectual PROPERTY PROTECTION,"['Zhenhua Xu1,*, Yiran Zhao3,*, Mengting Zhong3,5*', 'Dezhang Kong1,2,3', 'Changting Lin1,3', 'Tong Qiao3', 'Meng Han1,2,3']","2026 IEEE. Published inICASSP 2026 2026 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), scheduled for 38 May 2026 in Barcelona, Spain",11.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DNF: DUAL-LAYER NESTED FINGERPRINTING FOR LARGE LANGUAGE MODEL || INTELLECTUAL PROPERTY PROTECTION || Zhenhua Xu1,*, Yiran Zhao3,*, Mengting Zhong3,5*, Dezhang Kong1,2,3, || Changting Lin1,3, Tong Qiao3, Meng Han1,2,3 || 1Zhejiang University 2Binjiang Institute of Zhejiang University 3GenTel.io ... (truncated) ||  || ```json || { || ""title"": ""DNF: DUAL-LAYER NESTED FINGERPRINTING FOR LARGE LANGUAGE MODEL INTELlectual PROPERTY PROTECTION"", || ""authors"": [""Zhenhua Xu1,*, Yiran Zhao3,*, Mengting Zhong3,5*"", ""Dezhang Kong1,2,3"", ""Changting Lin1,3"", ""Tong Qiao3"", ""Meng Han1,2,3""], || ""doi"": ""2026 IEEE. Published inICASSP 2026 2026 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), scheduled for 38 May 2026 in Barcelona, Spain"", || ""arxiv_id"": """", || ""keywords"": [""Large Language Model"", ""Copyright Protection"", ""Model Fingerprinting"", ""Backdoor""], || ""summary"": ""The rapid growth of large language models raises concerns about intellectual property protection under black-box deployment. Existing backdoor-based fingerprints either rely on rare tokens leading to high-perplexity inputs susceptible to filtering or use fixed trigger-response mappings that are brittle to leakage and post-hoc adaptation. We propose Dual-Layer Nested Fingerprinting (DNF), a black-box method that embeds a hierarchical backdoor by coupling domain-specific stylistic cues with implicit semantic triggers. Across Mistral-7B, LLaMA-3-8B-Instruct, and Falcon3-7B-Instruct, DNF achieves perfect fingerprint activation while preserving downstream utility. Compared with existing methods, it uses lower-perplexity triggers, remains undetectable under fingerprint detection attack, and is relatively robust to incremental fine-tuning and model merging. These results position DNF as a practical, stealthy, and resilient solution for LLM ownership verification and IP protection."" || } ||  ||  || [ Prompt: 34.4 t/s | Generation: 11.1 t/s ]"
2601.08224v1_An Axiomatic Approach to General Intelligence SANC.pdf,An Axiomatic Approach to General Intelligence,"['Daesuk Kwon', 'Won-gi Paeng']",,6.9,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || An Axiomatic Approach to General Intelligence: || SANC(E3) || Self-organizing Active Network of Concepts with EnergyE 3 || Daesuk Kwon 1 Won-gi Paeng1 || 1Hyntel, Inc., Seoul, Republic of Korea || hyntel@hyntel.com,wgpaeng@hyntel.net || Abstract || General intelligence must reorganize experience into in ... (truncated) ||  || { ""title"": ""An Axiomatic Approach to General Intelligence"", ""authors"": [""Daesuk Kwon"", ""Won-gi Paeng""], ""doi"": """", ""arxiv_id"": ""arXiv:2304.00000"", ""keywords"": [""axiomatizationofintelligence"", ""competitiveselection"", ""systemtokens"", ""reconstructioncompressiontrade-off"", ""category formation"", ""self-similar hierarchy"", ""Gestalt completion""], ""summary"": ""This paper proposes SANC(E3), an axiomatic framework for general intelligence. It introduces representational units that emerge through competitive selection, reconstruction, and compression under finite activation capacity, governed by an energy functional E3. The framework draws a principled distinction between system tokens and sensory tokens, and introduces residual capacity Cremain(t) as an explicit control variable. Key features include a pseudo-memory-mapped I/O mechanism and unified perception, imagination, prediction, planning, and action. Twelve propositions are derived from the axioms, showing that various cognitive activities can be understood as instances of Gestalt completion under E3 minimization."" } ||  || [ Prompt: 37.3 t/s | Generation: 6.9 t/s ]"
2601.08226v1_Knowledge-based learning in Text-RAG and Image-RAG.pdf,Knowledge-based learning in Text-RAG and Image-RAG,"['Alexander Shim', 'Khalil Saieh', 'Samuel Clarke']",,5.2,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Knowledge-based learning in Text-RAG and Image-RAG || Alexander Shim || Florida International University || Miami, FL, USA || ashim017@fiu.edu || Khalil Saieh || Florida International University || Miami, FL, USA || ksaie001@fiu.edu || Samuel Clarke || Florida International University || Miami, FL, USA || sclar122@fiu ... (truncated) ||  || { || ""title"": ""Knowledge-based learning in Text-RAG and Image-RAG"", || ""authors"": [""Alexander Shim"", ""Khalil Saieh"", ""Samuel Clarke""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Radiology"", ""Multi-modal AI"", ""Vision Transformers"", ""Large Language Models"", ""Text-RAG"", ""Image-RAG"", ""Hallucination Reduction"", ""Disease Detection"", ""Chest X-ray Images""], || ""summary"": ""This research analyzes and compares the multi-modal approach in the Vision Transformer (EVA-ViT) based image encoder with the LLaMA or ChatGPT LLM to reduce the hallucination problem and detect diseases in chest x-ray images. The study utilized the NIH Chest X-ray image dataset to train the model and compared it in image-based RAG, text-based RAG, and baseline models. The results show that text-based RAG effectively reduces hallucination by using external knowledge, while image-based RAG improves prediction confidence and calibration using KNN methods. The GPT LLM outperforms the Llama Llama-based model in terms of hallucination rate and Expected Calibration Error (ECE). The research highlights the challenges of data imbalance and complex multi-stage structures but suggests the importance of a large experience environment and balanced example use."" || } ||  || [ Prompt: 12.9 t/s | Generation: 5.2 t/s ]"
2601.08230v1_GADPN Graph Adaptive Denoising and Perturbation Ne.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || GADPN: Graph Adaptive Denoising and Perturbation Networks via || Singular Value Decomposition || Hao Deng, Bo Liu,Member, IEEE, || AbstractWhile Graph Neural Networks (GNNs) || excel on graph-structured data, their performance is || fundamentally limited by the quality of the observed || graph, whi ... (truncated) ||  || { || ""title"": ""GADPN: Graph Adaptive Denoising and Perturbation Networks via Singular Value Decomposition"", || ""authors"": [""Hao Deng"", ""Bo Liu,Member, IEEE""], || ""doi"": """", || ""arxiv_id"": ""1912.07282"", || ""keywords"": [""Graph Neural Networks"", ""Graph Structural Learning"", ""Network Representation Learning""], || ""summary"": ""While Graph Neural Networks (GNNs) excel on graph-structured data, their performance is fundamentally limited by the quality of the observed graph, which often contains noise, missing links, or structural properties misaligned with GNNs underlying assumptions. To address this, graph structure learning aims to infer a more optimal topology. Existing methods, however, often incur high computational costs due to complex generative models and iterative joint optimization, limiting their practical utility. In this paper, we propose GADPN, a simple yet effective graph structure learning framework that adaptively refines graph topology via low-rank denoising and generalized structural perturbation. Our approach makes two key contributions: (1) we introduce Bayesian optimization to adaptively determine the optimal denoising strength, tailoring the process to each graph's homophily level; and (2) we extend the structural perturbation method to arbitrary graphs via Singular Value Decomposition (SVD), overcoming its original limitation to symmetric structures. Extensive experiments on benchmark datasets demonstrate that GADPN not only achieves state-of-the-art performance but does so with significantly improved efficiency. It shows particularly strong gains on challenging disassortative graphs, validating its ability to robustly learn enhanced graph structures across diverse network types."""
2601.08235v2_MPCI-Bench A Benchmark for Multimodal Pairwise Con.pdf,MPCI-Bench: A Benchmark for Multimodal Pairwise Contextual Integrity,"['Shouju Wang', 'Haopeng Zhang']",,5.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MPCI-Bench: A Benchmark for Multimodal Pairwise Contextual Integrity || Evaluation of Language Model Agents || Shouju Wang Haopeng Zhang || University of Hawaii at Manoa || {shoujuw, haopengz}@hawaii.edu || Abstract || As language-model agents evolve from passive || chatbots into proactive assistants th ... (truncated) ||  || { || ""title"": ""MPCI-Bench: A Benchmark for Multimodal Pairwise Contextual Integrity"", || ""authors"": [""Shouju Wang"", ""Haopeng Zhang""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Contextual Integrity"", ""Multimodal Privacy"", ""Language Model Agents"", ""Privacy Evaluation""], || ""summary"": ""As language-model agents evolve from passive chatbots to proactive assistants handling personal data, evaluating their adherence to social norms becomes increasingly critical. Existing benchmarks are largely text-centric and emphasize negative refusal scenarios, overlooking multimodal privacy risks and the trade-off between privacy and utility. This paper introduces MPCI-Bench, the first multimodal pairwise contextual integrity benchmark for evaluating privacy behavior in agentic settings. MPCI-Bench consists of paired positive and negative instances derived from the same visual source and instantiated across three tiers: normative Seed judgments, context-rich Story reasoning, and executable agent action Traces. Data quality is ensured through a Tri-Principle Iterative Refinement pipeline. Evaluations of state-of-the-art multimodal models reveal systematic failures to balance privacy and utility and a pronounced modality leakage gap, where sensitive visual information is leaked more frequently than textual information."" || } ||  || [ Prompt: 14.1 t/s | Generation: 5.1 t/s ]"
2601.08237v1_The End of Reward Engineering How LLMs Are Redefin.pdf,The End of Reward Engineering: How LLMs Are Redefining Multi-Agent Coordination,"['Haoran Su', 'Yandong Sun', 'Congjia Yu']",,5.3,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || The End of Reward Engineering: How LLMs Are || Redefining Multi-Agent Coordination || Haoran Su || New York University || haoran.su@nyu.edu || Yandong Sun || New York University || ys2312@nyu.edu || Congjia Yu || Lerna AI || gary.yu@lerna-ai.com || Abstract || Reward engineering  the manual design of reward functions  ... (truncated) ||  || { || ""title"": ""The End of Reward Engineering: How LLMs Are Redefining Multi-Agent Coordination"", || ""authors"": [""Haoran Su"", ""Yandong Sun"", ""Congjia Yu""], || ""doi"": """", || ""arxiv_id"": ""2601.08237"", || ""keywords"": [""multi-agent reinforcement learning"", ""reward engineering"", ""large language models"", ""dynamic adaptation"", ""semantic understanding"", ""credit assignment"", ""non-stationarity""], || ""summary"": ""Reward engineering, the manual design of reward functions to guide agent behavior, remains a persistent bottleneck in multi-agent reinforcement learning. This challenge is compounded by credit assignment ambiguity, environmental non-stationarity, and exponentially scaling complexity. We argue that large language models (LLMs) enable a fundamental paradigm shift from hand-crafted numerical rewards to natural language objectives. Recent work demonstrates that LLMs can generate human-level reward functions from language descriptions alone, adapt rewards dynamically without human intervention, and coordinate agents through semantic understanding. The emergence of Reinforcement Learning from Verifiable Rewards (RLVR) further validates this trajectory, establishing language-based training as mainstream. We present a perspective on three pillars of this transition: semantic reward specification, dynamic adaptation, and inherent human alignment, while acknowledging challenges in computational cost, hallucination risks, and scalability. We conclude with a vision for multi-agent systems where coordination emerges from shared semantic understanding rather than engineered numerical signals."" || } ||  || [ Prompt: 12.8 t/s | Generation: 5.3 t/s ]"
2601.08251v1_Hyperbolic Heterogeneous Graph Transformer.pdf,Hyperbolic Heterogeneous Graph Transformer,"['Jongmin Park', 'Seunghoon Han', 'Hyewon Lee', 'Won-Yong Shin', 'Sungsu Lim']",,11.9,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Hyperbolic Heterogeneous Graph Transformer || Jongmin Park 1,, Seunghoon Han 1,, Hyewon Lee 1,Won-Yong Shin2, Sungsu Lim 1, || 1Department Computer Science and Engineering, Chungnam National University, Daejeon, South Korea || 2School of Mathematics and Computing (Computational Science and E ... (truncated) ||  || { || ""title"": ""Hyperbolic Heterogeneous Graph Transformer"", || ""authors"": [""Jongmin Park"", ""Seunghoon Han"", ""Hyewon Lee"", ""Won-Yong Shin"", ""Sungsu Lim""], || ""doi"": """", || ""arxiv_id"": ""pa5398"", || ""keywords"": [""Heterogeneous Graph Representation Learning"", ""Hyperbolic Graph Embedding"", ""Graph Transformer""], || ""summary"": ""In heterogeneous graphs, complex structures such as tree-like or hierarchical structures are observed. Recently, the hyperbolic space has been widely adopted to effectively learn these complex structures. However, existing methods relying on tangent-space operations often lead to mapping distortions and focus mainly on local neighborhood information, making it difficult to capture global hierarchical structures and long-range dependencies. To address these limitations, we propose Hyperbolic Heterogeneous Graph Transformer (HypHGT), which effectively and efficiently learns heterogeneous graph representations entirely within the hyperbolic space. Unlike previous methods, HypHGT captures both local and global dependencies through a transformer-based architecture and uses a relation-specific hyperbolic attention mechanism with linear time complexity to preserve heterogeneous information across different relation types. This design allows HypHGT to effectively capture the complex structural properties and semantic information inherent in heterogeneous graphs. Comprehensive experiments demonstrate that HypHGT consistently outperforms state-of-the-art methods in node classification tasks, with significantly reduced training time and memory usage."" || } ||  || [ Prompt: 26.5 t/s | Generation: 11.9 t/s ]"
2601.08254v1_Large Artificial Intelligence Model Guided Deep Re.pdf,Large Artificial Intelligence ModelGuided Deep Reinforcement Learning for Resource Allocation in Non-Terrestrial Networks,"['Abdikarim Mohamed Ibrahim', 'Rosdiadee Nordin']",,11.6,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Large Artificial Intelligence ModelGuided Deep Reinforcement Learning for || Resource Allocation in Non-Terrestrial Networks || Abdikarim Mohamed Ibrahim 1, Rosdiadee Nordin 2 || Faculty of Engineering, Sunway University, Petaling Jaya, Malaysia || Future Cities Research Institute, Sunway Unive ... (truncated) ||  || ```json || { || ""title"": ""Large Artificial Intelligence ModelGuided Deep Reinforcement Learning for Resource Allocation in Non-Terrestrial Networks"", || ""authors"": [""Abdikarim Mohamed Ibrahim"", ""Rosdiadee Nordin""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Large AI Models (LAMs)"", ""Large Language Models (LLMs)"", ""Deep Reinforcement Learning (DRL)"", ""Satellite Communications"", ""Non-Terrestrial Networks (NTNs)""], || ""summary"": ""Large AI Model (LAM) have been proposed to applications of Non-Terrestrial Networks (NTN), that offer better performance with its great generalization and reduced task specific trainings. In this paper, we propose a Deep Reinforcement Learning (DRL) agent that is guided by a Large Language Model (LLM). The LLM operates as a high level coordinator that generates textual guidance that shape the reward of the DRL agent during training. The results show that the LAM-DRL outperforms the traditional DRL by 40% in nominal weather scenarios and 64% in extreme weather scenarios compared to heuristics in terms of throughput, fairness, and outage probability."" || } ||  ||  || [ Prompt: 29.0 t/s | Generation: 11.6 t/s ]"
2601.08257v2_On Evaluation of Unsupervised Feature Selection fo.pdf,,[],,12.9,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || On Evaluation of Unsupervised Feature Selection for || Pattern Classification || Gyu-Il Kim1, Dae-Won Kim2, Jaesung Lee1 || 1Department of Artificial Intelligence, Chung-Ang University, Republic of Korea || 2School of Computer Science and Engineering, Chung-Ang University, Republic of Korea || {gy ... (truncated) ||  || ```json || { || ""title"": ""On Evaluation of Unsupervised Feature Selection for Pattern Classification"", || ""authors"": [""Gyu-Il Kim"", ""Dae-Won Kim"", ""Jaesung Lee""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Unsupervised Feature Selection"", ""Pattern Classification"", ""Multi-Label Classification"", ""Hamming Loss"", ""Ranking Loss"", ""One-Error"", ""Multi-Label Accuracy""], || ""summary"": ""This study revisits the evaluation paradigm of unsupervised feature selection (UFS) by adopting a multi-label classification framework. Experiments on 21 multi-label datasets using several representative methods demonstrate that performance rankings differ markedly from those reported under single-label settings, suggesting the possibility of multi-label evaluation settings for fair and reliable comparison of UFS methods."" || } ||  ||  || [ Prompt: 35.0 t/s | Generation: 12.9 t/s ]"
2601.08258v1_T3 Benchmarking Sycophancy and Skepticism in Causa.pdf,T3: Benchmarking Sycophancy and Skepticism in Causal Judgment,['Edward Y. Chang'],,5.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || T3: Benchmarking Sycophancy and Skepticism in Causal Judgment || Edward Y. Chang || Computer Science || Stanford University || echang@cs.stanford.edu || Abstract || We introduce T 3 (TESTINGTRUSTWORTHY || THINKING), a diagnostic benchmark designed || to rigorously evaluate LLM causal judgment || across Pearls ... (truncated) ||  || { ""title"": ""T3: Benchmarking Sycophancy and Skepticism in Causal Judgment"", ""authors"": [""Edward Y. Chang""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""causal reasoning"", ""large language models"", ""sycophancy"", ""skepticism"", ""benchmarking"", ""trustworthy thinking""], ""summary"": ""Introduces T3 (TESTINGTRUSTWORTHY THINKING), a diagnostic benchmark designed to rigorously evaluate Large Language Models (LLMs) causal judgment across Pearls Ladder of Causality. Comprising 454 expert-curated vignettes, T3 prioritizes high-resolution failure analysis, decomposing performance into Utility (sensitivity), Safety (specificity), and Wise Refusal on underdetermined cases. By applying T3 to frontier models, diagnoses two distinct pathologies: Skepticism Trapat L1 (where safety-tuned models like Claude Haiku reject 60% of valid links) and a non-monotonic Scaling Paradox at L3. Finally, validates a process-verified protocol (RCA) showing T3 successfully captures the restoration of decisive causal judgment under structured verification."" } ||  || [ Prompt: 23.1 t/s | Generation: 5.0 t/s ]"
2601.08262v1_VGG Induced Deep Hand Sign Language Detection.pdf,VGG Induced Deep Hand Sign Language Detection,"['Subham Sharma', 'Sharmila Subudhi']",,5.9,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || VGG Induced Deep Hand Sign Language Detection || Subham Sharmaa, Sharmila Subudhia,b, || aDXOps, Bangalore, India || bDept. of Computer Science, Maharaja Sriram Chandra Bhanja Deo || University, Baripada, 757003, Odisha, India || Abstract || Hand gesture recognition is an important aspect of human-co ... (truncated) ||  || { ""title"": ""VGG Induced Deep Hand Sign Language Detection"", ""authors"": [""Subham Sharma"", ""Sharmila Subudhi""], ""doi"": """", ""arxiv_id"": ""2601.08262v1"", ""keywords"": [""Hand gesture recognition"", ""Convolutional neural network"", ""Classification"", ""VGG-16 net"", ""API""], ""summary"": ""Hand gesture recognition is an important aspect of human-computer interaction. It forms the basis of sign language for the visually impaired people. This work proposes a novel hand gesture recognizing system for the differently-abled persons. The model uses a convolutional neural network, known as VGG-16 net, for building a trained model on a widely used image dataset by employing Python and Keras libraries. The result is validated by the NUS dataset, consisting of 10 classes of hand gestures, fed to the model as the validation set. A testing dataset of 10 classes is built by employing Google's open source Application Programming Interface (API) that captures different gestures of human hand, and the efficacy is then measured by carrying out experiments. The experimental results show that by combining a transfer learning mechanism together with the image data augmentation, the VGG-16 net produced around 98% accuracy."" } ||  || [ Prompt: 12.6 t/s | Generation: 5.9 t/s ]"
2601.08271v1_Sparsity Is Necessary Polynomial-Time Stability fo.pdf,Sparsity Is Necessary: Polynomial-Time Stability for Agentic LLMs in Large Action Spaces,['Angshul Majumdar'],,5.3,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Sparsity Is Necessary: Polynomial-Time Stability for Agentic || LLMs in Large Action Spaces || Angshul Majumdar || Abstract || Tool-augmented LLM systems expose a control regime that learning theory has largely || ignored: sequential decision-making with a massive discrete action universe (tools,  ... (truncated) ||  || { || ""title"": ""Sparsity Is Necessary: Polynomial-Time Stability for Agentic LLMs in Large Action Spaces"", || ""authors"": [""Angshul Majumdar""], || ""doi"": """", || ""arxiv_id"": ""2309.15856"", || ""keywords"": [""Agentic LLMs"", ""Sparse Agentic Control (SAC)"", ""Sequential Decision-Making"", ""Large Action Spaces"", ""Polynomial-Time Stability"", ""Combinatorial Explosion"", ""Latent Sparsity""], || ""summary"": ""This paper formalizes the setting of sequential decision-making with a massive discrete action universe in the context of tool-augmented LLM systems. It introduces the concept of Sparse Agentic Control (SAC) and studies policy learning through a convex surrogate. The paper establishes sharp, compressed-sensing-style results, including estimation and value suboptimality scaling, exact tool-support recovery under certain conditions, and the necessity of dense policy classes for sample efficiency. It also discusses extensions to tuning-free, online, robust, group-sparse, and interaction-aware SAC. The paper highlights the importance of sparsity in understanding the stability and performance of LLMs in large action spaces."" || } ||  || [ Prompt: 12.7 t/s | Generation: 5.3 t/s ]"
2601.08273v1_HIPPO Accelerating Video Large Language Models Inf.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || HIPPO: Accelerating Video Large Language Models Inference via || Holistic-aware Parallel Speculative Decoding || Qitan Lv1,2* Tianyu Liu1,2* Wen Wu2 Xuenan Xu2 Bowen Zhou2,3 Feng Wu1 Chao Zhang2,3 || 1University of Science and Technology of China 2Shanghai AI Laboratory || 3Department of Electr ... (truncated) ||  || { || ""title"": ""HIPPO: Accelerating Video Large Language Models Inference via Holistic-aware Parallel Speculative Decoding"", || ""authors"": [""Qitan Lv"", ""Tianyu Liu"", ""Wen Wu"", ""Xuenan Xu"", ""Bowen Zhou"", ""Chao Zhang""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""video large language models"", ""speculative decoding"", ""parallel decoding"", ""token pruning"", ""holistic-aware""], || ""summary"": ""Speculative decoding (SD) has emerged as a promising approach to accelerate Large Language Models (LLMs) inference without sacrificing output quality. Existing SD methods tailored for video-LLMs primarily focus on pruning redundant visual tokens to mitigate the computational burden of massive visual inputs. However, existing methods do not achieve inference acceleration comparable to text-only LLMs. We observe from extensive experiments that this phenomenon mainly stems from two limitations: (i) their pruning strategies inadequately preserve visual semantic tokens, degrading draft quality and acceptance rates; (ii) even with aggressive pruning (e.g., 90% visual tokens removed), the remaining draft models still incur significant inference cost. To address these limitations, we propose HIPPO, a holistic-aware parallel speculative decoding framework. Specifically, HIPPO proposes (i) a semantic-aware token preservation method, which fuses global attention scores with local visual semantics to retain semantic information at high pruning ratios; (ii) a video parallel SD algorithm that decouples and overlaps draft generation and target verification phases. Experiments on four video-LLMs across six benchmarks demonstrate HIPPO's effectiveness, yielding up to 3.51 speedup compared to vanilla auto-regressive decoding."""
2601.08276v1_ToolACE-MCP Generalizing History-Aware Routing fro.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ToolACE-MCP: Generalizing History-Aware Routing from MCP Tools to || the Agent Web || Zhiyuan Yao1, *, Zishan Xu2, *, Yifu Guo4, *, Zhiguang Han5, Cheng Yang6, || Shuo Zhang,Weinan Zhang 2,Xingshan Zeng 3, ,Weiwen Liu 2, || 1Zhejiang University, 2Shanghai Jiao Tong University,3Huawei Noahs Ark ... (truncated) ||  || { || ""title"": ""ToolACE-MCP: Generalizing History-Aware Routing from MCP Tools to the Agent Web"", || ""authors"": [""Zhiyuan Yao"", ""Zishan Xu"", ""Yifu Guo"", ""Zhiguang Han"", ""Cheng Yang"", ""Shuo Zhang"", ""Weinan Zhang"", ""Xingshan Zeng"", ""Weiwen Liu""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""ToolACE-MCP"", ""MCP"", ""Agent Web"", ""History-Aware Routing"", ""Multi-Agent Collaboration"", ""Open-Ended Ecosystems""], || ""summary"": ""With the rise of the Agent Web and Model Context Protocol (MCP), the agent ecosystem is evolving into an open collaborative network, exponentially increasing accessible tools. However, current architectures face severe scalability and generality bottlenecks. To address this, we propose ToolACE-MCP, a pipeline for training history-aware routers to empower precise navigation in large-scale ecosystems. By leveraging a dependency-rich candidate graph to synthesize multi-turn trajectories, we effectively train routers with dynamic context understanding to create the plug-and-play Light Routing Agent. Experiments on real-world benchmarks MCP-Universe and MCP-Mark demonstrate superior performance. Notably, ToolACE-MCP exhibits critical properties for the future Agent Web: it not only generalizes to multi-agent collaboration with minimal adaptation but also maintains exceptional robustness against noise and scales effectively to massive candidate spaces. These findings provide a strong empirical foundation for universal orchestration in open-ended ecosystems."""
2601.08280v1_Greedy Is Enough Sparse Action Discovery in Agenti.pdf,Greedy Is Enough: Sparse Action Discovery in Agentic LLMs,['Angshul Majumdar'],,13.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Greedy Is Enough: Sparse Action Discovery in Agentic LLMs || Angshul Majumdar || Abstract || Modern agentic systems operate in environments with extremely large action spaces, || such as tool-augmented language models with thousands of available APIs or retrieval op- || erations. Despite this scal ... (truncated) ||  || { || ""title"": ""Greedy Is Enough: Sparse Action Discovery in Agentic LLMs"", || ""authors"": [""Angshul Majumdar""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""agentic behavior"", ""sparse action discovery"", ""contextual linear reward model"", ""orthogonal matching pursuit"", ""action sparsity"", ""sample efficiency""], || ""summary"": ""Modern agentic systems face large action spaces, yet empirical evidence suggests that only a small subset of actions significantly influences performance. This paper studies a contextual linear reward model with a structured sparsity assumption, formulating action discovery as a block-sparse recovery problem. A greedy algorithm inspired by Orthogonal Matching Pursuit is analyzed, proving that the greedy procedure exactly recovers the relevant action set with high probability. The results identify sparse action discovery as a fundamental principle underlying large-action decision-making and provide a theoretical foundation for action pruning in agentic systems."" || } ||  || [ Prompt: 35.2 t/s | Generation: 13.0 t/s ]"
2601.08288v1_OpenMic A Multi-Agent-Based Stand-Up Comedy Genera.pdf,OpenMic: A Multi-Agent-Based Stand-Up Comedy Generation System,"['Yuyang Wu', 'Hanzhong Cao', 'Jianhao Chen', 'Yufei Li']",,11.6,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || OpenMic: A Multi-Agent-Based Stand-Up Comedy Generation System || Yuyang Wu1 Hanzhong Cao 1 Jianhao Chen 1 Yufei Li1 || Abstract || Chinese stand-up comedy generation goes be- || yond plain text generation, requiring cultur- || ally grounded humor, precise timing, stage- || performance cues, and impl ... (truncated) ||  || { ""title"": ""OpenMic: A Multi-Agent-Based Stand-Up Comedy Generation System"", ""authors"": [""Yuyang Wu"", ""Hanzhong Cao"", ""Jianhao Chen"", ""Yufei Li""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""stand-up comedy"", ""multi-agent system"", ""humor generation"", ""retrieval-augmented generation"", ""fine-tuning"", ""long-form comedy""], ""summary"": ""OpenMic is an end-to-end multi-agent system built on AutoGen that transforms a user-provided life topic into a 35 minute Chinese stand-up performance. It orchestrates multiple specialized agents in a multi-round iterative loop to jointly optimize humor, timing, and performability. To address the dataset-task mismatch, OpenMic augments generation with retrieval-augmented generation (RAG) for material grounding and idea expansion, and fine-tunes a dedicated JokeWriter to better internalize stand-up-specific setup-punchline structures and long-range callbacks. This system aims to generate coherent comedic arcs and delayed puns, addressing the challenges of culturally grounded humor, precise timing, and stage-performance cues in Chinese stand-up comedy generation."" } ||  || [ Prompt: 36.4 t/s | Generation: 11.6 t/s ]"
2601.08297v1_Demystifying the Slash Pattern in Attention The Ro.pdf,Demystifying the Slash Pattern in Attention: The Role of RoPE,"['Yuan Cheng', 'Fengzhuo Zhang', 'Yunlong Hou', 'Cunxiao Du', 'Chao Du', 'Tianyu Pang', 'Aixin Sun', 'Zhuoran Yang']",,11.2,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Demystifying the Slash Pattern in Attention: The Role of RoPE || Yuan Cheng1, Fengzhuo Zhang1,, Yunlong Hou1, Cunxiao Du2 || Chao Du2 Tianyu Pang2 Aixin Sun3 Zhuoran Yang4 || . || is || Token embs lie on a cone. (Sec 4.3) || norm  proj || LLMs || is || RoPERoPE || sum softmax || High and med RoPE freqs interact to ... (truncated) ||  || ```json || { || ""title"": ""Demystifying the Slash Pattern in Attention: The Role of RoPE"", || ""authors"": [""Yuan Cheng"", ""Fengzhuo Zhang"", ""Yunlong Hou"", ""Cunxiao Du"", ""Chao Du"", ""Tianyu Pang"", ""Aixin Sun"", ""Zhuoran Yang""], || ""doi"": """", || ""arxiv_id"": ""2601.08297v1"", || ""keywords"": [""Attention patterns"", ""RoPE"", ""Large Language Models"", ""Slash-Dominant Heads"", ""Out-of-Distribution generalization""], || ""summary"": ""This paper demystifies the emergence of Slash-Dominant Heads (SDHs) in large language models (LLMs). Empirical analysis reveals that queries and keys are almost rank-one and that RoPE is dominated by medium- and high-frequency components. These conditions lead to SDHs, which are intrinsic to models and generalize to out-of-distribution prompts. The paper also discusses the role of RoPE in determining attention scores and provides insights into the structure of LLMs."" || } ||  ||  || [ Prompt: 38.1 t/s | Generation: 11.2 t/s ]"
2601.08302v1_Enhancing Sentiment Classification and Irony Detec.pdf,Enhancing Sentiment Classification and Irony Detection in Large Language Models through Advanced Prompt Engineering Techniques,"['Marvin Schmitt', 'Anne Schwerk', 'Sebastian Lempert']",,5.5,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Enhancing Sentiment Classification and Irony Detection in Large Language Models || through Advanced Prompt Engineering Techniques || Marvin Schmitt , Anne Schwerk , Sebastian Lempert || IU International University of Applied Sciences, Juri-Gagarin-Ring 152, Erfurt, 99084, Thuringia, Germany ... (truncated) ||  || { || ""title"": ""Enhancing Sentiment Classification and Irony Detection in Large Language Models through Advanced Prompt Engineering Techniques"", || ""authors"": [""Marvin Schmitt"", ""Anne Schwerk"", ""Sebastian Lempert""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""sentiment analysis"", ""irony detection"", ""large language models (LLMs)"", ""prompt engineering""], || ""summary"": ""This study investigates the use of prompt engineering to enhance large language models (LLMs), specifically GPT-4o-mini and gemini-1.5-flash, in sentiment analysis tasks. It evaluates advanced prompting techniques like few-shot learning, chain-of-thought prompting, and self-consistency against a baseline. Key tasks include sentiment classification, aspect-based sentiment analysis, and detecting subtle nuances such as irony. The research details the theoretical background, datasets, and methods used, assessing performance of LLMs as measured by accuracy, recall, precision, and F1 score. Findings reveal that advanced prompting significantly improves sentiment analysis, with the few-shot approach excelling in GPT-4o-mini and chain-of-thought prompting boosting irony detection in gemini-1.5-flash by up to 46%. Thus, while advanced prompting techniques overall improve performance, the fact that few-shot prompting works best for GPT-4o-mini and chain-of-thought excels in gemini-1.5-flash for irony detection suggests that prompting strategies must be tailored to both the model and the task. This highlights the importance of aligning prompt design with both the LLMs architecture and the semantic complexity of the task."" || } ||  || [ Prompt: 36.1 t/s | Generation: 5.5 t/s ]"
2601.08310v1_ORBIT On-policy Exploration-Exploitation for Contr.pdf,ORBIT: On-policy Exploration-Exploitation for Controllable Multi-Budget Reasoning,"['Kun Liang', 'Clive Bai', 'Xin Xu', 'Chenming Tang', 'Sanwoo Lee', 'Weijie Liu', 'Saiyong Yang', 'Yunfang Wu']",,5.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || January 14, 2026 || ORBIT: On-policy Exploration-Exploitation || for Controllable Multi-Budget Reasoning || Kun Liang1,2, Clive Bai3 Xin Xu3,4 Chenming Tang1,2, || Sanwoo Lee1,2, Weijie Liu3 Saiyong Yang3, Yunfang Wu1,2, || 1School of Computer Science, Peking University || 2National Key Laboratory fo ... (truncated) ||  || { || ""title"": ""ORBIT: On-policy Exploration-Exploitation for Controllable Multi-Budget Reasoning"", || ""authors"": [""Kun Liang"", ""Clive Bai"", ""Xin Xu"", ""Chenming Tang"", ""Sanwoo Lee"", ""Weijie Liu"", ""Saiyong Yang"", ""Yunfang Wu""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Reinforcement Learning"", ""Large Language Models"", ""Multi-Budget Reasoning"", ""On-policy Exploration-Exploitation"", ""Controllable Reasoning""], || ""summary"": ""Recent Large Reasoning Models achieve strong performance by leveraging long-form Chain-of-Thought reasoning, but uniformly applying overlong reasoning at inference time incurs substantial computational cost. To address this, we propose ORBIT, a controllable multi-budget reasoning framework with well-separated reasoning modes triggered by input. ORBIT employs multi-stage reinforcement learning to discover Pareto-optimal reasoning behaviors at each effort, followed by on-policy distillation to fuse these behaviors into a single unified model. Experiments show that ORBIT achieves controllable reasoning behavior over multiple modes, competitive reasoning density within each mode, and integration of frontier policies into a single unified student model while preserving clear mode separation and high per-mode performance."" || } ||  || [ Prompt: 12.3 t/s | Generation: 5.1 t/s ]"
2601.08311v1_Enhancing Image Quality Assessment Ability of LMMs.pdf,Enhancing Image Quality Assessment Ability of LMMs via Retrieval-Augmented Generation,"['Kang Fu', 'Huiyu Duan', 'Zicheng Zhang', 'Yucheng Zhu', 'Jun Zhao', 'Xiongkuo Min', 'Jia Wang', 'Guangtao Zhai']",,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Enhancing Image Quality Assessment Ability of || LMMs via Retrieval-Augmented Generation || Kang Fu 1, Huiyu Duan 1, Zicheng Zhang 1, Yucheng Zhu 1, Jun Zhao 2, Xiongkuo Min 1, Jia Wang 1, and Guangtao Zhai 1 || 1 Shanghai Jiao Tong University, 2Tencent || AbstractLarge Multimodal Models (LMMs) ... (truncated) ||  || { ""title"": ""Enhancing Image Quality Assessment Ability of LMMs via Retrieval-Augmented Generation"", ""authors"": [""Kang Fu"", ""Huiyu Duan"", ""Zicheng Zhang"", ""Yucheng Zhu"", ""Jun Zhao"", ""Xiongkuo Min"", ""Jia Wang"", ""Guangtao Zhai""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Image Quality Assessment"", ""Retrieval-Augmented Generation"", ""Large Multimodal Models"", ""Zero-shot"", ""Training-free""], ""summary"": ""Recent advancements in Large Multimodal Models (LMMs) have demonstrated exceptional capabilities in low-level visual perception tasks, including Image Quality Assessment (IQA). However, achieving state-of-the-art performance often requires computationally expensive fine-tuning methods. Inspired by recent training-free works, we introduce IQARAG, a novel, training-free framework that enhances LMMs IQA ability. IQARAG leverages Retrieval-Augmented Generation (RAG) to retrieve semantically similar but quality-variant reference images with corresponding Mean Opinion Scores (MOSs) for input images. These retrieved images provide a visual perception anchor for the LMM in IQA tasks. IQARAG contains three key phases: Retrieval Feature Extraction, Image Retrieval, and Integration & Quality Score Generation. Extensive experiments across multiple IQA datasets demonstrate that IQARAG effectively boosts the IQA performance of LMMs, offering a resource-efficient alternative to fine-tuning."" }"
2601.08323v1_AtomMem  Learnable Dynamic Agentic Memory with Ato.pdf,AtomMem : Learnable Dynamic Agentic Memory,"['Yupeng Huo', 'Yaxi Lu', 'Zhong Zhang', 'Haotian Chen', 'Yankai Lin*']",,5.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || AtomMem : Learnable Dynamic Agentic Memory || with Atomic Memory Operation || Yupeng Huo1, Yaxi Lu2, Zhong Zhang2, Haotian Chen2, Yankai Lin1* || 1 Renmin University of China, 2 Tsinghua University || {huoyupeng, yankailin}@ruc.edu.cn || Abstract || Equipping agents with memory is essential || for solvi ... (truncated) ||  || ```json || { || ""title"": ""AtomMem : Learnable Dynamic Agentic Memory"", || ""authors"": [""Yupeng Huo"", ""Yaxi Lu"", ""Zhong Zhang"", ""Haotian Chen"", ""Yankai Lin*""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""memory"", ""agents"", ""dynamic"", ""CRUD"", ""supervised"", ""reinforcement"", ""long-horizon"", ""task-aligned""], || ""summary"": ""AtomMem reframes memory management as a dynamic decision-making problem, deconstructing high-level memory processes into fundamental atomic CRUD operations. By combining supervised fine-tuning with reinforcement learning, AtomMem learns an autonomous, task-aligned policy to orchestrate memory behaviors tailored to specific task demands. Experimental results across 3 long-context benchmarks demonstrate that the trained AtomMem-8B consistently outperforms prior static-workflow memory methods. Further analysis of training dynamics shows that our learning-based formulation enables the agent to discover structured, task-aligned memory management strategies, highlighting a key advantage over predefined routines."" || } ||  ||  || [ Prompt: 12.7 t/s | Generation: 5.1 t/s ]"
2601.08327v1_Safe Heterogeneous Multi-Agent RL with Communicati.pdf,Safe Heterogeneous Multi-Agent RL with Communication Regularization for Coordinated Target Acquisition,"['Gabriele Calzolari', 'Vidya Sumathy', 'Christoforos Kanellakis', 'George Nikolakopoulos']",,5.3,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Safe Heterogeneous Multi-Agent RL with || Communication Regularization for || Coordinated Target Acquisition || Gabriele Calzolari  Vidya Sumathy || Christoforos Kanellakis  George Nikolakopoulos || Department of Computer Science, Electrical and Space Engineering, || Lule  a University of Technol ... (truncated) ||  || { ""title"": ""Safe Heterogeneous Multi-Agent RL with Communication Regularization for Coordinated Target Acquisition"", ""authors"": [""Gabriele Calzolari"", ""Vidya Sumathy"", ""Christoforos Kanellakis"", ""George Nikolakopoulos""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Cooperative target acquisition"", ""Safe autonomous coordination"", ""Decentralized multi-agent reinforcement learning"", ""Heterogeneous robotic systems"", ""Learning-based control""], ""summary"": ""This paper introduces a decentralized multi-agent reinforcement learning framework enabling structurally heterogeneous teams of agents to jointly discover and acquire randomly located targets in environments characterized by partial observability, communication constraints, and dynamic interactions. Each agent's policy is trained with the Multi-Agent Proximal Policy Optimization algorithm and employs a Graph Attention Network encoder that integrates simulated range-sensing data with communication embeddings exchanged among neighboring agents, enabling context-aware decision-making from both local sensing and relational information. This work introduces a unified framework that integrates graph-based communication and trajectory-aware safety through safety filters. The architecture is supported by a structured reward formulation designed to encourage effective target discovery and acquisition, collision avoidance, and de-correlation between the agents' communication vectors by promoting informational orthogonality. The effectiveness of the proposed reward function is demonstrated through a comprehensive ablation study. Simulation results confirm the framework's effectiveness in safe and stable task execution."" } ||  || [ Prompt: 12.4 t/s | Generation: 5.3 t/s ]"
2601.08332v1_IGAN A New Inception-based Model for Stable and Hi.pdf,IGAN: A New Inception-based Model for Stable and High-Fidelity Image Synthesis Using Generative Adversarial Networks,"['Ahmed A. Hashim', 'Ali Al-Shuwaili', 'Asraa Saeed', 'Ali Al-Bayaty*']",,11.7,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  || 1 || IGAN: A New Inception-based Model for Stable || and High-Fidelity Image Synthesis Using || Generative Adversarial Networks || Ahmed A. Hashim 1, Ali Al-Shuwaili2, Asraa Saeed3, Ali Al-Bayaty4* || 1 College of Business Informatics, University of Information Technology and Communications ... (truncated) ||  || { ""title"": ""IGAN: A New Inception-based Model for Stable and High-Fidelity Image Synthesis Using Generative Adversarial Networks"", ""authors"": [""Ahmed A. Hashim"", ""Ali Al-Shuwaili"", ""Asraa Saeed"", ""Ali Al-Bayaty*""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Generative Adversarial Networks (GANs)"", ""dilation convolutions"", ""inception module"", ""spectral normalization"", ""image synthesis"", ""deep learning stability""], ""summary"": ""Generative Adversarial Networks (GANs) face a significant challenge of striking an optimal balance between high-quality image generation and training stability. Recent techniques, such as DCGAN, BigGAN, and StyleGAN, improve visual fidelity but usually struggle with mode collapse and unstable gradients at high network depth. This paper proposes a novel GAN structural model, termed the Inception Generative Adversarial Network (IGAN), that incorporates deeper inception-inspired convolution and dilated convolution. The IGAN model generates high-quality synthetic images while maintaining training stability by reducing mode collapse and preventing vanishing and exploding gradients. Achieves FID of 13.12 and 15.08 on CUB-200 and ImageNet datasets, respectively, representing a 28-33% improvement over state-of-the-art GANs. Additionally, the IGAN model attains an Inception Score (IS) of 9.27 and 68.25, reflecting improved image diversity and generation quality. Dropout and spectral normalization techniques are utilized in both the generator and discriminator structures to further mitigate gradient explosion and overfitting. These findings confirm that the IGAN model potentially balances training stability with image generation quality, constituting a scalable and computationally efficient framework for high-fidelity image synthesis."" } ||  || [ Prompt: 37.2 t/s | Generation: 11.7 t/s ]"
2601.08333v1_Semantic Laundering in AI Agent Architectures Why .pdf,Semantic Laundering in AI Agent Architectures: Why Tool Boundaries Do Not Confer Epistemic Warrant,"['Oleg Romanchuk', 'Roman Bondar']",,13.9,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Semantic Laundering in AI Agent Architectures: || Why Tool Boundaries Do Not Confer Epistemic || Warrant || Oleg Romanchuk Roman Bondar || Abstract || LLM-based agent architectures systematically conflate information transport || mechanisms with epistemic justification mechanisms. We formalize this c ... (truncated) ||  || { || ""title"": ""Semantic Laundering in AI Agent Architectures: Why Tool Boundaries Do Not Confer Epistemic Warrant"", || ""authors"": [""Oleg Romanchuk"", ""Roman Bondar""], || ""doi"": """", || ""arxiv_id"": ""2601.08333"", || ""keywords"": [""Semantic Laundering"", ""Epistemic Warrant"", ""Gettier Problem"", ""AI Agent Architectures"", ""Tool Boundaries""], || ""summary"": ""This paper formalizes the architectural failure known as semantic laundering, where LLM-based agent architectures accept propositions with absent or weak warrant as admissible. It shows that this effect is not accidental but architecturally determined, constituting a realization of the Gettier problem. The central result is the Theorem of Inevitable Self-Licensing, which states that under standard architectural assumptions, circular epistemic justification cannot be eliminated. The paper introduces the Warrant Erosion Principle as the fundamental explanation for this effect and demonstrates that scaling, model improvement, and LLM-as-judge schemes are structurally incapable of eliminating the problem at the type level."" || } ||  || [ Prompt: 42.1 t/s | Generation: 13.9 t/s ]"
2601.08360v1_Scalable Sequential Recommendation under Latency a.pdf,Scalable Sequential Recommendation under Latency and Memory Constraints,"['Adithya Parthasarathy', 'Aswathnarayan Muthukrishnan Kirubakaran', 'Vinoth Punniyamoorthy', 'Nachiappan Chockalingam', 'Lokesh Butra', 'Kabilan Kannan', 'Abhirup Mazumder', 'Sumit Saha']",,12.7,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Scalable Sequential Recommendation under || Latency and Memory Constraints || Adithya Parthasarathy1, Aswathnarayan Muthukrishnan Kirubakaran2, Vinoth || Punniyamoorthy3, Nachiappan Chockalingam4, Lokesh Butra 5, Kabilan || Kannan6, Abhirup Mazumder 7, and Sumit Saha 8 || 1 IEEE Senior Member, USA ... (truncated) ||  || { || ""title"": ""Scalable Sequential Recommendation under Latency and Memory Constraints"", || ""authors"": [""Adithya Parthasarathy"", ""Aswathnarayan Muthukrishnan Kirubakaran"", ""Vinoth Punniyamoorthy"", ""Nachiappan Chockalingam"", ""Lokesh Butra"", ""Kabilan Kannan"", ""Abhirup Mazumder"", ""Sumit Saha""], || ""doi"": """", || ""arxiv_id"": ""2601.08360"", || ""keywords"": [""Recommender Systems"", ""Sequence Modeling"", ""Representation Learning"", ""Scalable Machine Learning"", ""Deep Learning""], || ""summary"": ""This paper presents HoloMambaRec, a lightweight sequential recommendation architecture that combines holographic reduced representations for attribute-aware embedding with a selective state space encoder for linear-time sequence processing. Item and attribute information are bound using circular convolution, preserving embedding dimensionality while encoding structured metadata. A shallow selective state space backbone, inspired by recent Mamba-style models, enables efficient training and constant-time recurrent inference. Experiments on Amazon Beauty and MovieLens-1M datasets demonstrate that HoloMambaRec consistently outperforms SASRec and achieves competitive performance with GRU4Rec under a constrained 10-epoch training budget, while maintaining substantially lower memory complexity. The design further incorporates forward-compatible mechanisms for temporal bundling and inference-time compression, positioning HoloMambaRec as a practical and extensible alternative for scalable, metadata-aware sequential recommendation."" || } ||  || [ Prompt: 35.3 t/s | Generation: 12.7 t/s ]"
2601.08371v1_Geo-NVS-w Geometry-Aware Novel View Synthesis In-t.pdf,,[],,5.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Geo-NVS-w: Geometry-Aware Novel View Synthesis In-the-Wild || with an SDF Renderer || Anastasios Tsalakopoulos1 Angelos Kanlis1 Evangelos Chatzis1 || Antonis Karakottas1 Dimitrios Zarpalas1 || 1Centre for Research and Technology Hellas (CERTH), Thessaloniki, Greece || {tsalakop, a.kanlis, chatzise ... (truncated) ||  || { ""title"": ""Geo-NVS-w: Geometry-Aware Novel View Synthesis In-the-Wild"", ""authors"": [""Anastasios Tsalakopoulos"", ""Angelos Kanlis"", ""Evangelos Chatzis"", ""Antonis Karakottas"", ""Dimitrios Zarpalas""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Novel View Synthesis"", ""Geometry-Aware"", ""Signed Distance Function (SDF)"", ""In-the-Wild"", ""Photorealistic Rendering""], ""summary"": ""We introduce Geo-NVS-w, a geometry-aware framework for high-fidelity novel view synthesis from unstructured, in-the-wild image collections. While existing in-the-wild methods excel at novel view synthesis, they often lack geometric grounding on complex surfaces, sometimes producing results with inconsistencies. Geo-NVS-w addresses this limitation by leveraging an underlying geometric representation based on a Signed Distance Function (SDF) to guide the rendering process. This is complemented by a novel Geometry-Preservation Loss which ensures fine structural details are preserved. Our framework achieves competitive rendering performance, demonstrating a 45% reduction in energy consumption compared to similar methods. We demonstrate that Geo-NVS-w is a robust method for in-the-wild NVS, yielding photorealistic results with sharp, geometrically coherent details."" } ||  || [ Prompt: 14.1 t/s | Generation: 5.1 t/s ]"
2601.08379v1_Training-Free Distribution Adaptation for Diffusio.pdf,Training-Free Distribution Adaptation for Diffusion Models via Maximum Mean Discrepancy Guidance,"['Matina Mahdizadeh Sani', 'Nima Jamali', 'Mohammad Jalali', 'Farzan Farnia']",,5.6,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Training-Free Distribution Adaptation for Diffusion || Models via Maximum Mean Discrepancy Guidance || Matina Mahdizadeh Sani  , Nima Jamali , Mohammad Jalali , Farzan Farnia || Abstract || Pre-trained diffusion models have emerged as powerful generative priors for both unconditional and || condi ... (truncated) ||  || { ""title"": ""Training-Free Distribution Adaptation for Diffusion Models via Maximum Mean Discrepancy Guidance"", ""authors"": [""Matina Mahdizadeh Sani"", ""Nima Jamali"", ""Mohammad Jalali"", ""Farzan Farnia""], ""doi"": """", ""arxiv_id"": ""arXiv:2309.14447"", ""keywords"": [""maximum mean discrepancy"", ""distribution alignment"", ""inference-time guidance"", ""diffusion models"", ""domain adaptation""], ""summary"": ""Pre-trained diffusion models are powerful for generative tasks but often fail to match user-specific target distributions. This paper introduces MMD Guidance, a training-free method that uses gradients of the Maximum Mean Discrepancy between generated samples and a reference dataset to align with the target distribution. It is efficient, differentiable, and can be applied to both prompt-aware and latent diffusion models, demonstrating improved distribution alignment and sample fidelity in experiments."" } ||  || [ Prompt: 12.2 t/s | Generation: 5.6 t/s ]"
2601.08380v1_Thematic Working Group 5 -- Artificial Intelligenc.pdf,EDUsummIT 2025 - eBook,"['Mary Webb - Kings College London (TWG co-leader)', 'Matt Bower - Macquarie University (TWG co-leader)', 'Ana Amlia Carvalho - University of Coimbra', 'Fredrik Mrk Rkenes - University of Oslo', 'Jodie Torrington - Macquarie University', 'Jonathan D. Cohen - Georgia State University', 'Yousra Chtouki - Al Akhawayn University in Ifrane', 'Kathryn MacCallum, University of Canterbury, NZ', 'Tanya Linden, The University of Melbourne, Australia', 'Deirdre Butler, Dublin City University', 'Juliana E. Raffagheli - University of Padova', 'Henriikka Vartiainen - University of Eastern Finland', 'Martina Ronci - Universit Paris Cit', 'Peter Tiernan - Dublin City University', 'David M. Smith - Purdue University Global', 'Chris Shelton - University of Chichester', 'Joyce Malyn-Smith - Education Development Center', 'Pierre Gorissen - HAN University of Applied Sciences']",,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || EDUsummIT 2025 - eBook || Thematic Working Group 5 - Artificial || Intelligence (AI) literacy for teaching and || learning: design and implementation || Mary Webb - Kings College London (TWG co-leader) || Matt Bower - Macquarie University (TWG co-leader) || Ana Amlia Carvalho -University of Coi ... (truncated) ||  || { ""title"": ""EDUsummIT 2025 - eBook"", ""authors"": [""Mary Webb - Kings College London (TWG co-leader)"", ""Matt Bower - Macquarie University (TWG co-leader)"", ""Ana Amlia Carvalho - University of Coimbra"", ""Fredrik Mrk Rkenes - University of Oslo"", ""Jodie Torrington - Macquarie University"", ""Jonathan D. Cohen - Georgia State University"", ""Yousra Chtouki - Al Akhawayn University in Ifrane"", ""Kathryn MacCallum, University of Canterbury, NZ"", ""Tanya Linden, The University of Melbourne, Australia"", ""Deirdre Butler, Dublin City University"", ""Juliana E. Raffagheli - University of Padova"", ""Henriikka Vartiainen - University of Eastern Finland"", ""Martina Ronci - Universit Paris Cit"", ""Peter Tiernan - Dublin City University"", ""David M. Smith - Purdue University Global"", ""Chris Shelton - University of Chichester"", ""Joyce Malyn-Smith - Education Development Center"", ""Pierre Gorissen - HAN University of Applied Sciences""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""EDUsummIT 2025"", ""Artificial Intelligence (AI) literacy"", ""Teaching and Learning"", ""OpenAI"", ""ChatGPT3"", ""Generative AI"", ""Plagiarism"", ""Academic Integrity"", ""Creativity"", ""Agency"", ""Critical Thinking""], ""summary"": ""TWG 5 focused on developing and implementing effective strategies for enhancing AI literacy and agency of teachers, equipping them with the knowledge and skills necessary to integrate AI into their teaching practices. Explorations covered curriculum design, professional development programs, practical classroom applications, and policy guidelines aimed at empowering educators to confidently utilize AI tools and foster a deeper understanding of AI concepts among students. The introduction discusses the impact of OpenAI's release of ChatGPT3 in November 2022, highlighting the potential disruptions and concerns around plagiarism, academic integrity, creativity, agency, and critical thinking in educational settings."" }"
2601.08382v2_A Qualitative Model to Reason about Object Rotatio.pdf,A Qualitative Model to Reason about Object Rotations applied to solve the Cube Comparison Test,['Zoe Falomira'],,5.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A Qualitative Model to Reason about Object Rotations  applied to solve the Cube || Comparison Test || Zoe Falomira,1 || aUme University, Computing Science Department, Sweden || Abstract || This paper presents a Qualitative model for Reasoning about Object Rotations (QOR) which is applied to solve  ... (truncated) ||  || { || ""title"": ""A Qualitative Model to Reason about Object Rotations applied to solve the Cube Comparison Test"", || ""authors"": [""Zoe Falomira""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""cube comparison test"", ""mental rotation"", ""qualitative reasoning"", ""spatial cognition"", ""spatial reasoning""], || ""summary"": ""This paper presents a Qualitative model for Reasoning about Object Rotations (QOR) applied to solve the Cube Comparison Test (CCT) by Ekstrom et al. (1976). A conceptual neighborhood graph relating the Rotation movement to the Location change and the Orientation change of the features on the cube sides has been built and it produces composition tables to calculate inferences for reasoning about rotations. Studies in the literature show that spatial reasoning skills correlate with success in Science, Technology, Engineering, and Math (STEM) disciplines and have a unique role in the development of creativity or creative-thinking. Qualitative models are useful to represent knowledge and to reason in order to solve spatial reasoning tests. In this paper, a new qualitative descriptor for reasoning about object rotations (QOR) is presented and implemented in to reason about how object rotations change the localisation and orientation of their sides and to present an interactive version of the Cube Comparison Test."" || } ||  || [ Prompt: 13.2 t/s | Generation: 5.0 t/s ]"
2601.08383v1_Deconstructing Pre-training Knowledge Attribution .pdf,,[],,11.3,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Deconstructing Pre-training: Knowledge Attribution Analysis in MoE and Dense || Models || Bo Wang1, Junzhuo Li1,2, Hong Chen1, Yuanlin Chu1, Yuxuan Fan1, Xuming Hu1,2* || 1The Hong Kong University of Science and Technology (Guangzhou) || 2The Hong Kong University of Science and Technology || {bo.w ... (truncated) ||  || ```json || { || ""title"": ""Deconstructing Pre-training: Knowledge Attribution Analysis in MoE and Dense Models"", || ""authors"": [""Bo Wang"", ""Junzhuo Li"", ""Hong Chen"", ""Yuanlin Chu"", ""Yuxuan Fan"", ""Xuming Hu""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Mixture-of-Experts"", ""Knowledge Acquisition"", ""Pre-training"", ""Neuron-level Attribution"", ""Sparse Architectures""], || ""summary"": ""This paper introduces Gated-LPI (Log-Probability Increase), a neuron-level attribution metric, to analyze knowledge acquisition dynamics in Mixture-of-Experts (MoE) and dense models during pre-training. It presents a time-resolved comparison of these dynamics, tracking checkpoints over 1.2M and 600K training steps, respectively. The study reveals three patterns: (1) Low-entropy backbone, (2) Early consolidation, and (3) Functional robustness. These patterns collectively demonstrate that sparsity fosters an intrinsically stable and distributed computational backbone from early in training, helping bridge the gap between sparse architectures and training-time interpretability."" || } ||  ||  || [ Prompt: 29.7 t/s | Generation: 11.3 t/s ]"
2601.08388v1_Creativity in AI as Emergence from Domain-Limited .pdf,Creativity in AI as Emergence from Domain-Limited Generative Models,['Corina Chutaux'],,12.6,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Creativity in AI as Emergence from || Domain-Limited Generative Models || Corina Chutaux || Sorbonne University || corina@chutaux.com || Abstract || Creativity in artificial intelligence is most often addressed through evaluative frameworks that aim to measure novelty, || diversity, or usefulness in gen ... (truncated) ||  || ```json || { || ""title"": ""Creativity in AI as Emergence from Domain-Limited Generative Models"", || ""authors"": [""Corina Chutaux""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Creativity"", ""Generative Models"", ""Emergence"", ""Artificial Intelligence""], || ""summary"": ""This paper proposes a generative perspective on creativity in AI, framing it as an emergent property of domain-limited generative models embedded within bounded informational environments. It focuses on the structural and contextual conditions under which creative behaviors arise, decomposing creativity into four interacting components: pattern-based generation, induced world models, contextual grounding, and arbitrariness. The work aims to provide a technical framework for studying creativity as an emergent phenomenon in AI systems, rather than as a post hoc evaluative label."" || } ||  ||  || [ Prompt: 32.1 t/s | Generation: 12.6 t/s ]"
2601.08393v1_Controlled LLM Training on Spectral Sphere.pdf,Controlled LLM Training on Spectral Sphere,"['Tian Xie1 *', 'Haoming Luo2', 'Haoyu Tang2', 'Yiwen Hu2', 'Jason Klein Liu Qingnan Ren 1', 'Yang Wang1', 'Wayne Xin Zhao2', 'Rui Yan3', 'Bing Su2', 'Chong Luo1', 'Baining Guo1']",,10.9,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Controlled LLM Training on Spectral Sphere || Tian Xie1 * || Haoming Luo2 Haoyu Tang2 Yiwen Hu2 Jason Klein Liu Qingnan Ren 1 || Yang Wang1 Wayne Xin Zhao2 Rui Yan3 Bing Su2 Chong Luo1 Baining Guo1 || 1Microsoft Research Asia 2Renmin University 3Wuhan University || Project Page:Spectral-Sphere-Opt ... (truncated) ||  || { ""title"": ""Controlled LLM Training on Spectral Sphere"", ""authors"": [""Tian Xie1 *"", ""Haoming Luo2"", ""Haoyu Tang2"", ""Yiwen Hu2"", ""Jason Klein Liu Qingnan Ren 1"", ""Yang Wang1"", ""Wayne Xin Zhao2"", ""Rui Yan3"", ""Bing Su2"", ""Chong Luo1"", ""Baining Guo1""], ""doi"": """", ""arxiv_id"": ""2601.08393v1"", ""keywords"": [""LLM"", ""Spectral Sphere"", ""Optimization"", ""Stability"", ""Activation Control""], ""summary"": ""Scaling large models requires optimization strategies that ensure rapid convergence grounded in stability. Maximal Update Parametrization (P) provides a theoretical safeguard for width-invariant activation control, whereas emerging optimizers like Muon are only half-aligned with these constraints: they control updates but allow weights to drift. To address this limitation, we introduce the Spectral Sphere Optimizer (SSO), which enforces strict module-wise spectral constraints on both weights and their updates. By deriving the steepest descent direction on the spectral sphere, SSO realizes a fully P-aligned optimization process. Through extensive pretraining on diverse architectures, including Dense 1.7B, MoE 8B-A1B, and 200-layer DeepNet models, SSO consistently outperforms AdamW and Muon. Furthermore, we observe significant practical stability benefits, including improved MoE router load balancing, suppressed outliers, and strictly bounded activations. The Spectral Sphere maintains constant activation magnitudes throughout training because its P-metrized constraints on the spectral manifold ensure that the activation RMS remains at scale."" } ||  || [ Prompt: 36.3 t/s | Generation: 10.9 t/s ]"
2601.08401v1_An Explainable Two Stage Deep Learning Framework f.pdf,Explainable Two-Stage Deep Learning Framework for Pericoronitis Assessment in Panoramic Radiographs Using YOLOv8 and ResNet-50,"['Ajo Babu George', 'Pranav S', 'Kunal Agarwal']",,5.6,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || An Explainable Two-Stage Deep Learning || Framework for Pericoronitis Assessment in || Panoramic Radiographs Using YOLOv8 and || ResNet-50 || Ajo Babu George 1*, Pranav S 2 and Kunal Agarwal 3 || 1* DiceMed, Cuttack, Odisha, India. || 2Department of Computer Science and Engineering, College of || Engine ... (truncated) ||  || { ""title"": ""Explainable Two-Stage Deep Learning Framework for Pericoronitis Assessment in Panoramic Radiographs Using YOLOv8 and ResNet-50"", ""authors"": [""Ajo Babu George"", ""Pranav S"", ""Kunal Agarwal""], ""doi"": """", ""arxiv_id"": ""2601.08401"", ""keywords"": [""pericoronitis"", ""panoramic radiographs"", ""YOLOv8"", ""ResNet-50"", ""deep learning"", ""interpretability""], ""summary"": ""An AI-assisted system for diagnosing pericoronitis on panoramic radiographs (OPGs) was developed. The system uses a two-stage deep learning pipeline: the first stage detects third molars and classifies their anatomical positions and angulations using YOLOv8 based on Winters classification. The detected regions are then fed into a second-stage classifier, a modified ResNet-50 architecture, for detecting radiographic features suggestive of pericoronitis. To enhance clinical trust, Grad-CAM was used to highlight key diagnostic regions on the radiographs. The YOLOv8 component achieved 92% precision and 92.5% mean average precision. The ResNet-50 classifier yielded F1-scores of 88% for normal cases and 86% for pericoronitis. Radiologists reported 84% alignment between Grad-CAM and their diagnostic impressions, supporting the radiographic relevance of the interpretability output. The system shows strong potential for AI-assisted panoramic assessment, with explainable AI features that support clinical confidence."" } ||  || [ Prompt: 13.6 t/s | Generation: 5.6 t/s ]"
2601.08402v1_PATS Personality-Aware Teaching Strategies with La.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || PATS: Personality-Aware Teaching Strategies || with Large Language Model Tutors || Donya Rooein1*, Sankalan Pal Chowdhury2*, Mariia Eremeeva2, || Yuan Qin3,Debora Nozza 1,Mrinmaya Sachan 2,Dirk Hovy 1 || 1Bocconi University || 2ETH Zurich || 3University of Zurich || Correspondence:donya.rooein@uniboccon ... (truncated) ||  || { || ""title"": ""PATS: Personality-Aware Teaching Strategies"", || ""authors"": [""Donya Rooein1*"", ""Sankalan Pal Chowdhury2*"", ""Mariia Eremeeva2"", ""Yuan Qin3"", ""Debora Nozza 1"", ""Mrinmaya Sachan 2"", ""Dirk Hovy 1""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""large language models"", ""teaching strategies"", ""personality traits"", ""pedagogical methods"", ""student engagement"", ""interactive discussions""], || ""summary"": ""Recent advances in large language models (LLMs) demonstrate their potential as educational tutors. However, different tutoring strategies benefit different student personalities, and mismatches can be counterproductive to student outcomes. Despite this, current LLM tutoring systems do not take into account student personality traits. To address this problem, we first construct a taxonomy that links pedagogical methods to personality profiles, based on pedagogical literature. We simulate student-teacher conversations and use our framework to let the LLM tutor adjust its strategy to the simulated student personality. We evaluate the scenario with human teachers and find that they consistently prefer our approach over two base lines. Our method also increases the use of less common, high-impact strategies such as role-playing, which human and LLM annotators prefer significantly. Our findings pave the way for developing more personalized and effective LLM use in educational applications."""
2601.08403v1_Owen-Shapley Policy Optimization OSPO A Principled.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for || Generative Search LLMs || Abhijnan Nath 1 2 Alireza Bagheri Garakani 1 Tianchen Zhou 1 Fan Yang1 Nikhil Krishnaswamy 2 || Abstract || Large language models are increasingly trained || via reinforcement learning for personali ... (truncated) ||  || ```json || { || ""title"": ""Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for Generative Search LLMs"", || ""authors"": [""Abhijnan Nath"", ""Alireza Bagheri Garakani"", ""Tianchen Zhou"", ""Fan Yang"", ""Nikhil Krishnaswamy""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Reinforcement Learning"", ""Policy Optimization"", ""Generative Search"", ""Large Language Models"", ""Shapley-Owen Attribution"", ""Coalition Formation"", ""Out-of-Distribution Robustness""], || ""summary"": ""Large language models are increasingly trained via reinforcement learning for personalized recommendation tasks. Standard methods like GRPO rely on sparse, sequence-level rewards that create a credit assignment gap, obscuring which tokens drive success. This gap is especially problematic when models must infer latent user intent from under-specified language without ground truth labels. We introduce OSPO, a framework that redistributes sequence-level advantages based on tokens' marginal contributions to outcomes. Unlike value-model-based methods, OSPO employs potential-based reward shaping via Shapley-Owen attributions to assign segment-level credit while preserving the optimal policy directly from task feedback without parametric value models. By forming coalitions of semantically coherent units, OSPO identifies which response parts drive performance. Experiments on Amazon ESCI and H&M Fashion datasets show consistent gains over baselines, with notable test-time robustness to out-of-distribution retrievers unseen during training."""
2601.08406v1_WebTrap Park An Automated Platform for Systematic .pdf,WebTrap Park: An Automated Platform for Systematic Security Evaluation of Web Agents,"['Xinyi Wu', 'Jiagui Chen', 'Geng Hong', 'Jiayi Dong', 'Xudong Pan', 'Jiarun Dai', 'Min Yang']",,5.3,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || WebTrap Park: An Automated Platform for Systematic Security Evaluation of || Web Agents || Xinyi Wu,*, Jiagui Chen ,*, Geng Hong B, Jiayi Dong , Xudong Pan , Jiarun Dai , and Min Yang B || Fudan University, Shanghai Innovation Institute || {xinyiwu20, jgchen20, ghong, xdpan, jrdai, m yang}@fuda ... (truncated) ||  || { ""title"": ""WebTrap Park: An Automated Platform for Systematic Security Evaluation of Web Agents"", ""authors"": [""Xinyi Wu"", ""Jiagui Chen"", ""Geng Hong"", ""Jiayi Dong"", ""Xudong Pan"", ""Jiarun Dai"", ""Min Yang""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Web Agents"", ""Security Evaluation"", ""Automated Platform"", ""Systematic Evaluation"", ""Web Interaction""], ""summary"": ""Web Agents are increasingly deployed to perform complex tasks in real web environments, yet their security evaluation remains fragmented and difficult to standardize. We present WebTrapPark, an automated platform for systematic security evaluation of Web Agents through direct observation of their concrete interactions with live web pages. WebTrapPark instantiates three major sources of security risk into 1,226 executable evaluation tasks and enables action-based assessment without requiring agent modification. Our results reveal clear security differences across agent frameworks, highlighting the importance of agent architecture beyond the underlying model. WebTrapPark is publicly accessible at https://security.fudan.edu.cn/webagent and provides a scalable foundation for reproducible Web Agent security evaluation."" } ||  || [ Prompt: 13.5 t/s | Generation: 5.3 t/s ]"
2601.08412v1_Hybrid Distillation with CoT Guidance for Edge-Dro.pdf,Hybrid Distillation with CoT Guidance for Edge-Drone Control Code Generation,"['Yizhan Feng', 'Hichem Snoussi', 'Yuhang Wang', 'Jing Teng', 'Abel Cherouat', 'Tian Wang']",,12.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || Hybrid Distillation with CoT Guidance for Edge-Drone Control Code || Generation || Yizhan Feng1,4, Hichem Snoussi1,4, Yuhang Wang2, Jing Teng2, Abel Cherouat3,4 and Tian || Wang5 || 1 UR-LIST3N, University of Technology of Troyes, Troyes, France || E-mail: hichem.snoussi@utt.fr || 2Institute of Art ... (truncated) ||  || { ""title"": ""Hybrid Distillation with CoT Guidance for Edge-Drone Control Code Generation"", ""authors"": [""Yizhan Feng"", ""Hichem Snoussi"", ""Yuhang Wang"", ""Jing Teng"", ""Abel Cherouat"", ""Tian Wang""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Large language models"", ""drone"", ""Knowledge Distillation"", ""Chain-of-Thought"", ""Lightweight""], ""summary"": ""With large language models demonstrating significant potential in code generation tasks, their application to onboard control of resource-constrained Unmanned Aerial Vehicles has emerged as an important research direction. However, a notable contradiction exists between the high resource consumption of large models and the real-time, lightweight requirements of UAV platforms. This paper proposes an integrated approach that combines knowledge distillation, chain-of-thought guidance, and supervised fine-tuning for UAV multi-SDK control tasks, aiming to efficiently transfer complex reasoning and code generation capabilities to smaller models. Firstly, a high-quality dataset covering various mainstream UAV SDKs is constructed, featuring instruction-code-reasoning chains, and incorporates counterfactual negative samples for data augmentation, guiding the model to learn the end-to-end logic from instruction parsing to code generation. Secondly, leveraging DeepSeek-Coder-V2-Lite quantized via QLoRA as the teacher model, and based on a hybrid black-box and white-box distillation strategy, high-quality chain-of-thought soft labels are generated. These are combined with a weighted cross-entropy loss using hard labels to transfer complex reasoning capabilities to the smaller student model. Finally, through prompt tuning engineering optimized for the UAV control scenario, the model's performance on core tasks such as SDK type recognition and function call matching is enhanced. Experimental results indicate that the distilled lightweight model (parameters 1B) maintains high code generation accuracy while achieving significant improvements in deployment and inference efficiency, effectively demonstrating the feasibility and superiority of our approach in achieving precise and lightweight intelligent control for UAVs."" } ||  || [ Prompt: 25.5 t/s | Generation: 12.0 t/s ]"
2601.08415v2_Regulatory gray areas of LLM Terms.pdf,Regulatory gray areas of LLM Terms,"['Brittany I. Davidson', 'Kate Muir', 'Florian A.D. Burnat', 'Adam N. Joinson']",,12.7,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Regulatory gray areas of LLM Terms || Brittany I. Davidson || University of Bath || Bath, England || Email: bid23@bath.ac.uk || Kate Muir || Bath Spa University || Bath, England || Email: k.muir@bathspa.ac.uk || Florian A.D. Burnat || University of Bath || Bath, England || Email: fadb20@bath.ac.uk || Adam N. Joinson || Univ ... (truncated) ||  || ```json || { || ""title"": ""Regulatory gray areas of LLM Terms"", || ""authors"": [""Brittany I. Davidson"", ""Kate Muir"", ""Florian A.D. Burnat"", ""Adam N. Joinson""], || ""doi"": """", || ""arxiv_id"": ""2601.08415v2"", || ""keywords"": [""Language Models"", ""LLMs"", ""Privacy Policy"", ""Terms of Service"", ""Regulation""], || ""summary"": ""Large Language Models (LLMs) are increasingly integrated into academic research pipelines; however, the Terms of Service governing their use remain under-examined. This paper presents a comparative analysis of the Terms of Service of five major LLM providers (Anthropic, DeepSeek, Google, OpenAI, and xAI) collected in November 2025. Our analysis reveals substantial variation in the stringency and specificity of usage restrictions for general users and researchers. We identify specific complexities for researchers in security research, computational social sciences, and psychological studies. We identify regulatory gray areas where Terms of Service create uncertainty for legitimate use. We contribute a publicly available resource comparing terms across platforms (OSF) and discuss implications for general users and researchers navigating this evolving landscape."" || } ||  ||  || [ Prompt: 31.5 t/s | Generation: 12.7 t/s ]"
2601.08418v1_Taxon Hierarchical Tax Code Prediction with Semant.pdf,Taxon: Hierarchical Tax Code Prediction with Semantically Aligned LLM Expert Guidance,"['Jihang Li', 'Qing Liu', 'Zulong Chen', 'Jing Wang', 'Wei Wang', 'Chuanfei Xu', 'Zeyi Wen']",,11.5,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Taxon: Hierarchical Tax Code Prediction || with Semantically Aligned LLM Expert Guidance || Jihang Li 1, Qing Liu 2, Zulong Chen 2, Jing Wang 2, Wei Wang2, Chuanfei Xu 3, Zeyi Wen 1 || 1Data Science and Analytics Thrust, Hong Kong University of Science and Technology (Guangzhou), Guangzhou,  ... (truncated) ||  || { || ""title"": ""Taxon: Hierarchical Tax Code Prediction with Semantically Aligned LLM Expert Guidance"", || ""authors"": [""Jihang Li"", ""Qing Liu"", ""Zulong Chen"", ""Jing Wang"", ""Wei Wang"", ""Chuanfei Xu"", ""Zeyi Wen""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Tax code prediction"", ""Hierarchical taxonomy"", ""Automated invoicing"", ""Compliance management"", ""Large-scale e-commerce"", ""Feature gating"", ""Mixture-of-experts"", ""Semantic consistency"", ""Language models"", ""Real business supervision""], || ""summary"": ""Tax code prediction is a crucial yet underexplored task in automating invoicing and compliance management for large-scale e-commerce platforms. This paper presents Taxon, a semantically aligned and expert-guided framework for hierarchical tax code prediction. Taxon integrates a feature-gating mixture-of-experts architecture and a semantic consistency model distilled from large language models to verify alignment between product titles and official tax definitions. To address noisy supervision in real business records, a multi-source training pipeline combining curated tax databases, invoice validation logs, and merchant registration data is designed. Extensive experiments on proprietary and public benchmarks demonstrate that Taxon achieves state-of-the-art performance, outperforming strong baselines. An additional full hierarchical paths reconstruction procedure significantly improves structural consistency, yielding the highest overall F1 scores. Taxon has been deployed in production within Alibaba's tax service system, handling an average of over 500,000 tax code queries per day and reaching peak volumes above five million requests during business events with improved accuracy, interpretability, and robustness."" || } ||  || [ Prompt: 31.4 t/s | Generation: 11.5 t/s ]"
2601.08430v1_RubricHub A Comprehensive and Highly Discriminativ.pdf,RubricHub: A Comprehensive and Highly Discriminative Rubric Dataset,"['Sunzhu Li', 'Jiale Zhao', 'Miteto Wei', 'Huimin Ren', 'Yang Zhou', 'Jingwen Yang', 'Shunyu Liu', 'Kaike Zhang', 'Wei Chen']",,5.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || RubricHub: A Comprehensive and Highly Discriminative Rubric Dataset || via Automated Coarse-to-Fine Generation || Sunzhu Li1, Jiale Zhao1 , Miteto Wei1 * , Huimin Ren1, || Yang Zhou3, Jingwen Yang2, Shunyu Liu4, Kaike Zhang1, Wei Chen1 || 1Li Auto Inc., China || 2The Chinese University of Hong Kon ... (truncated) ||  || { ""title"": ""RubricHub: A Comprehensive and Highly Discriminative Rubric Dataset"", ""authors"": [""Sunzhu Li"", ""Jiale Zhao"", ""Miteto Wei"", ""Huimin Ren"", ""Yang Zhou"", ""Jingwen Yang"", ""Shunyu Liu"", ""Kaike Zhang"", ""Wei Chen""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Rubric Generation"", ""Reinforcement Learning"", ""Verifiable Rewards"", ""Automated Rubric"", ""Fine-to-Coarse""], ""summary"": ""This paper introduces RubricHub, a large-scale (110k) and multi-domain dataset for evaluating response quality in verifiable domains like mathematics and coding. The dataset is validated through a two-stage post-training pipeline comprising Rubric-based Rejection Sampling Fine-Tuning (RuFT) and Reinforcement Learning (RuRL). Experimental results demonstrate significant performance gains, with the post-trained model achieving state-of-the-art results on HealthBench. The authors propose an automated Coarse-to-Fine Rubric Generation framework, which produces comprehensive and highly discriminative criteria capable of capturing subtle nuances. The code and data will be released soon."" } ||  || [ Prompt: 26.7 t/s | Generation: 5.1 t/s ]"
2601.08434v3_Large Multimodal Models for Embodied Intelligent D.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || Large Multimodal Models for Embodied Intelligent || Driving: The Next Frontier in Self-Driving? || Long Zhang,Member, IEEE,Yuchen Xia, Bingqing Wei, Zhen Liu, Shiwen Mao,Fellow, IEEE, || Zhu Han,Fellow, IEEEand Mohsen Guizani,Fellow, IEEE || AbstractThe advent of Large Multimodal Models (LMMs ... (truncated) ||  || { || ""title"": ""Large Multimodal Models for Embodied Intelligent Driving: The Next Frontier in Self-Driving?"", || ""authors"": [""Long Zhang"", ""Yuchen Xia"", ""Bingqing Wei"", ""Zhen Liu"", ""Shiwen Mao"", ""Zhu Han"", ""Mohsen Guizani""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Large Multimodal Models"", ""Embodied Intelligent Driving"", ""Self-Driving"", ""Large Language Models"", ""Reinforcement Learning"", ""Environmental Understanding"", ""Logical Reasoning"", ""Continuous Learning"", ""Policy Optimization""], || ""summary"": ""The advent of Large Multimodal Models (LMMs) offers a promising technology to tackle the limitations of modular design in autonomous driving. Embodied artificial intelligence facilitates policy optimization through closed-loop interactions to achieve continuous learning capability, advancing autonomous driving toward embodied intelligent (El) driving. However, relying solely on LMMs to enhance El driving without joint decision-making will be constrained. This article introduces a novel semantics and policy dual-driven hybrid decision framework to tackle this challenge, ensuring continuous learning and joint decision. The framework merges LMMs for semantic understanding and cognitive representation, and deep reinforcement learning (DRL) for real-time policy optimization. The article also examines the foundational principles of El driving and LMMs, emerging opportunities, potential benefits, and representative use cases. A case study validates the performance superiority of the framework in completing lane-change planning tasks. Several future research directions are identified to empower El driving."""
2601.08441v1_YaPO Learnable Sparse Activation Steering Vectors .pdf,YaPO: Learnable Sparse Activation Steering Vectors for Domain Adaptation,"['Abdelaziz Bounhar', 'Rania Hossam Elmohamady Elbadry', 'Hadi Abdine', 'Preslav Nakov', 'Michalis Vazirgiannis', 'Guokan Shang']",,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || YaPO: Learnable Sparse Activation Steering Vectors for Domain || Adaptation || Abdelaziz Bounhar1,, Rania Hossam Elmohamady Elbadry 1, Hadi Abdine 1, || Preslav Nakov1, Michalis Vazirgiannis1,2, Guokan Shang1, || 1MBZUAI, 2Ecole Polytechnique || Correspondence: {abdelaziz.bounhar, guokan.shang}@mb ... (truncated) ||  || { ""title"": ""YaPO: Learnable Sparse Activation Steering Vectors for Domain Adaptation"", ""authors"": [""Abdelaziz Bounhar"", ""Rania Hossam Elmohamady Elbadry"", ""Hadi Abdine"", ""Preslav Nakov"", ""Michalis Vazirgiannis"", ""Guokan Shang""], ""doi"": """", ""arxiv_id"": ""1234.5678"", ""keywords"": [""Large Language Models"", ""Steering Vectors"", ""Sparse Activation"", ""Domain Adaptation"", ""Bi-directional Preference Optimization"", ""Direct Preference Optimization"", ""Sparse Autoencoder"", ""Disentangled Steering Vectors"", ""Interpretable Directions"", ""Stability""], ""summary"": ""Steering Large Language Models (LLMs) through activation interventions has emerged as a lightweight alternative to fine-tuning for alignment and personalization. Recent work on Bi-directional Preference Optimization (BiPO) shows that dense steering vectors can be learned directly from preference data in a Direct Preference Optimization (DPO) fashion, enabling control over truthfulness, hallucinations, and safety behaviors. However, dense steering vectors often entangle multiple latent factors due to neuron multi-semanticity, limiting their effectiveness and stability in fine-grained settings such as cultural alignment. In this paper, we propose Y aPO, a reference-free method that learns sparse steering vectors in the latent space of a Sparse Autoencoder (SAE). By optimizing sparse codes, Y aPO produces disentangled, interpretable, and efficient steering directions. Empirically, we show that Y aPO converges faster, achieves stronger performance, and exhibits improved training stability compared to dense steering baselines. Beyond cultural alignment, Y aPO generalizes to a range of alignment-related behaviors, including hallucination, wealth-seeking, jail-break, and power-seeking. Importantly, Y aPO preserves general knowledge, with no measurable degradation on MMLU. Overall, our results show that Y aPO provides a general recipe for efficient, stable, and fine-grained alignment of LLMs, with broad applications to controllability and domain adaptation. The associated code and data are publicly available."" }"
2601.08444v1_Beyond Linearization Attributed Table Graphs for T.pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Beyond Linearization: Attributed Table Graphs for Table Reasoning || Yuxiang Wang1, Junhao Gan1, Shengxiang Gao1, Shenghao Ye2, Zhengyi Yang3, Jianzhong Qi1 || 1The University of Melbourne 3The University of New South Wales || 2The University of Science and Technology of China || {yuxiang.wang8 ... (truncated) ||  || ```json || { || ""title"": ""Beyond Linearization: Attributed Table Graphs for Table Reasoning"", || ""authors"": [""Yuxiang Wang"", ""Junhao Gan"", ""Shengxiang Gao"", ""Shenghao Ye"", ""Zhengyi Yang"", ""Jianzhong Qi""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Table Reasoning"", ""Attributed Table Graphs"", ""Large Language Models"", ""Linearization"", ""Personalized PageRank""], || ""summary"": ""Table reasoning aims to answer questions by reasoning over data presented in tables. Recent studies leverage the semantic understanding and reasoning capabilities of Large Language Models (LLMs) for table reasoning. They typically follow two paradigms: decomposition-based reasoning and full-table reasoning. To address the issues of losing table structures, lack of explicit reasoning paths, and the lost-in-the-middle effect, we propose Table Graph Reasoner (TABGR), a training-free model that represents tables as an Attributed Table Graph (ATG). The ATG explicitly preserves row-column-cell structures while enabling graph-based reasoning for explainability. We further propose a Question-Guided Personalized PageRank (QG-PPR) mechanism to rerank tabular data and mitigate the lost-in-the-middle issue. Extensive experiments on two commonly used benchmarks show that TABGR consistently outperforms state-of-the-art models by up to 9.7% in accuracy."""
2601.08448v1_Divide and Conquer Static-Dynamic Collaboration fo.pdf,Divide and Conquer: Static-Dynamic Collaboration for Few-Shot Class-Incremental Learning,"['Kexin Bao', 'Daichi Zhang', 'Yong Li', 'Dan Zeng', 'Shiming Ge']",https://doi.org/10.1145/3731715.3733310,11.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Divide and Conquer: Static-Dynamic Collaboration for Few-Shot || Class-Incremental Learning || Kexin Bao || Institute of Information Engineering, || Chinese Academy of Sciences || School of Cyber Security, University || of Chinese Academy of Sciences || Beijing, China || baokexin@iie.ac.cn || Daichi Zhang || Ins ... (truncated) ||  || { || ""title"": ""Divide and Conquer: Static-Dynamic Collaboration for Few-Shot Class-Incremental Learning"", || ""authors"": [""Kexin Bao"", ""Daichi Zhang"", ""Yong Li"", ""Dan Zeng"", ""Shiming Ge""], || ""doi"": ""https://doi.org/10.1145/3731715.3733310"", || ""arxiv_id"": """", || ""keywords"": [""Few-Shot Class-Incremental Learning"", ""Class-Incremental Learning""], || ""summary"": ""Few-shot class-incremental learning (FSCIL) aims to continuously recognize novel classes under limited data, facing the stability-plasticity dilemma. This paper proposes a Static-Dynamic Collaboration (SDC) framework to address this issue by dividing the task into Static Retaining Stage (SRS) and Dynamic Learning Stage (DLS). SRS retains fundamental old knowledge, while DLS continuously adapts to new classes. Extensive experiments on public benchmarks and a real-world dataset show improved performance compared to other methods."" || } ||  || [ Prompt: 16.3 t/s | Generation: 11.0 t/s ]"
2601.08450v1_Decoding Order Matters in Autoregressive Speech Sy.pdf,DECODING ORDER MA TTERS IN AUTOREGRESSIVE SPEECH SYNTHESIS,"['Minghui Zhao', 'Anton Ragni']",,11.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DECODING ORDER MA TTERS IN AUTOREGRESSIVE SPEECH SYNTHESIS || Minghui Zhao, Anton Ragni || School of Computer Science, University of Sheffield, 211 Portobello, Sheffield S1 4DP, UK || ABSTRACT || Autoregressive speech synthesis often adopts a left-to-right order, || yet generation order is a model ... (truncated) ||  || { ""title"": ""DECODING ORDER MA TTERS IN AUTOREGRESSIVE SPEECH SYNTHESIS"", ""authors"": [""Minghui Zhao"", ""Anton Ragni""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""speech synthesis"", ""discrete diffusion model"", ""order-agnostic autoregressive decoding""], ""summary"": ""Autoregressive speech synthesis often adopts a left-to-right order, yet generation order is a modelling choice. We investigate decoding order through masked diffusion framework, which progressively unmasks positions and allows arbitrary decoding orders during training and inference. By interpolating between identity and random permutations, we show that randomness in decoding order affects speech quality. We further compare fixed strategies, such as l2r and r2l, with adaptive ones, such as Top-K, finding that fixed-order decoding, including the dominating left-to-right approach, is suboptimal, while adaptive decoding yields better performance. Finally, since masked diffusion requires discrete inputs, we quantize acoustic representations and find that even 1-bit quantization can support reasonably high-quality speech."" } ||  || [ Prompt: 29.3 t/s | Generation: 11.1 t/s ]"
2601.08457v1_An Under-Explored Application for Explainable Mult.pdf,An Under-Explored Application for Explainable Multimodal Misogyny Detection in code-mixed Hindi-English,"['Sargam Yadava', 'Abhishek Kaushik', 'Kevin Mc Daid']",,11.5,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  || Information Classification: General || An Under-Explored Application for Explainable Multimodal Misogyny Detection in code-mixed Hindi-English Sargam Yadava, Abhishek Kaushikb, Kevin Mc Daidc a,b,cDundalk Institute of Technology asargam.yadav@dkit.ie  babhishek.kaushik@dkit.ie (Cor ... (truncated) ||  || { || ""title"": ""An Under-Explored Application for Explainable Multimodal Misogyny Detection in code-mixed Hindi-English"", || ""authors"": [""Sargam Yadava"", ""Abhishek Kaushik"", ""Kevin Mc Daid""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""hate speech"", ""misogyny"", ""natural language processing"", ""code-mixing"", ""hinglish""], || ""summary"": ""Digital platforms have become hubs for communication, business, and connectivity, but they also facilitate the spread of hate speech and misogyny. This paper presents a multi-modal and explainable web application for detecting misogyny in text and memes in code-mixed Hindi and English. The system leverages state-of-the-art transformer-based models that support multilingual and multimodal settings. For text-based misogyny identification, it uses XLM-RoBERTa and mBERT on a dataset of approximately 4,193 comments. For multimodal misogyny identification from memes, it uses mBERT + EfficientNet and mBERT + ResNET on a dataset of approximately 4,218 memes. The system provides feature importance scores using explainability techniques like SHAP and LIME. The application aims to serve as a tool for researchers and content moderators to promote further research, combat gender-based digital violence, and ensure a safe digital space. The system has been evaluated using human evaluators who provided responses on Chatbot Usability Questionnaire (CUQ) and User Experience Questionnaire (UEQ) to determine overall usability."" || } ||  || [ Prompt: 32.8 t/s | Generation: 11.5 t/s ]"
2601.08462v1_M3-BENCH Process-Aware Evaluation of LLM Agents So.pdf,M3-BENCH: Process-Aware Evaluation of LLM Agents Social Behaviors in Mixed-Motive Games,"['Sixiong Xie*', 'Zhuofan Shi*', 'Haiyang Shen*', 'Gang Huang', 'Yun Ma', 'Xiang Jing*']",,6.6,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || M3-BENCH: Process-Aware Evaluation of LLM Agents Social Behaviors in || Mixed-Motive Games || Sixiong Xie* Zhuofan Shi* Haiyang Shen* Gang Huang Yun Ma Xiang Jing * || Peking University || National Key Laboratory of Data Space Technology and System || xsx1001@stu.pku.edu.cn, jingxiang@pku.edu.cn ||  || ... (truncated) ||  || { || ""title"": ""M3-BENCH: Process-Aware Evaluation of LLM Agents Social Behaviors in Mixed-Motive Games"", || ""authors"": [""Sixiong Xie*"", ""Zhuofan Shi*"", ""Haiyang Shen*"", ""Gang Huang"", ""Yun Ma"", ""Xiang Jing*""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""large language model"", ""social behavior"", ""mixed-motive games"", ""process-aware evaluation"", ""behavioral trajectory analysis"", ""reasoning process analysis"", ""communication content analysis"", ""Big Five personality model"", ""Social Exchange Theory""], || ""summary"": ""As the capabilities of large language model (LLM) agents continue to advance, their advanced social behaviors such as cooperation, deception, and collusion call for systematic evaluation. However, existing benchmarks often emphasize a single capability dimension or rely solely on behavioral outcomes, overlooking rich process information from agents' decision reasoning and communicative interactions. To address this gap, we propose M3-BENCH, a multi-stage benchmark for mixed-motive games, together with a process-aware evaluation framework that conducts synergistic analysis across three modules: BTA (Behavioral Trajectory Analysis), RPA (Reasoning Process Analysis), and CCA (Communication Content Analysis). Furthermore, we integrate the Big Five personality model and Social Exchange Theory to aggregate multi-dimensional evidence into interpretable social behavior portraits, thereby characterizing agents' personality traits and capability profiles beyond simple task scores or outcome-based metrics. Experimental results show that M3-BENCH can reliably distinguish diverse social behavior competencies across models, and it reveals that some models achieve seemingly reasonable behavioral outcomes while exhibiting pronounced inconsistencies in their reasoning and communication."" || } ||  || [ Prompt: 31.8 t/s | Generation: 6.6 t/s ]"
2601.08464v1_CoMa Contextual Massing Generation with Vision-Lan.pdf,CoMa: Contextual Massing Generation with Vision-Language Models,"['Evgenii Maslov', 'Valentin Khrulkov', 'Anastasia Volkova', 'Anton Gusarov', 'Andrey Kuznetsov', 'Ivan Oseledets']",,5.6,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || CoMa: Contextual Massing Generation with Vision-Language Models || Evgenii Maslov1 Valentin Khrulkov1 Anastasia V olkova1 || Anton Gusarov1 Andrey Kuznetsov1, 2 Ivan Oseledets3 || 1 FusionBrain Lab 2 Innopolis University || 3 Institute of Numerical Mathematics || em.maslov01@gmail.com || Figure 1. A  ... (truncated) ||  || { ""title"": ""CoMa: Contextual Massing Generation with Vision-Language Models"", ""authors"": [""Evgenii Maslov"", ""Valentin Khrulkov"", ""Anastasia Volkova"", ""Anton Gusarov"", ""Andrey Kuznetsov"", ""Ivan Oseledets""], ""doi"": """", ""arxiv_id"": ""2601.08464"", ""keywords"": [""architecture"", ""massing"", ""vision-language models"", ""conditional generation"", ""urban planning""], ""summary"": ""The paper introduces the CoMa-20K dataset, a comprehensive collection that includes detailed massing geometries, associated economical and programmatic data, and visual representations of the development site within its existing urban context. The authors benchmark this dataset by formulating massing generation as a conditional task for Vision-Language Models (VLMs), evaluating both fine-tuned and large zero-shot models. The experiments reveal the inherent complexity of the task while demonstrating the potential of VLMs to produce context-sensitive massing options. The dataset and analysis establish a foundational benchmark and highlight significant opportunities for future research in data-driven architectural design."" } ||  || [ Prompt: 12.8 t/s | Generation: 5.6 t/s ]"
2601.08468v1_JudgeRLVR Judge First Generate Second for Efficien.pdf,"Judge First, Generate Second for Efficient Reasoning","['Jiangshan Duo', 'Hanyu Li', 'Hailin Zhang', 'Yudong Wang', 'Sujian Li', 'Liang Zhao']",,5.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || JudgeRLVR: Judge First, Generate Second for || Efficient Reasoning || Jiangshan Duo  Hanyu Li  Hailin Zhang  Yudong Wang || Sujian Li  Liang Zhao || State Key Laboratory of Multimedia Information Processing, School of || Computer Science, Peking University || CFCS, School of Computer Science, Pekin ... (truncated) ||  || ```json || { || ""title"": ""Judge First, Generate Second for Efficient Reasoning"", || ""authors"": [""Jiangshan Duo"", ""Hanyu Li"", ""Hailin Zhang"", ""Yudong Wang"", ""Sujian Li"", ""Liang Zhao""], || ""doi"": """", || ""arxiv_id"": ""2601.08468"", || ""keywords"": [""Reinforcement Learning"", ""Verifiable Rewards"", ""Efficient Reasoning"", ""Large Language Models"", ""Math Reasoning""], || ""summary"": ""Reinforcement Learning with Verifiable Rewards (RLVR) has become a standard paradigm for reasoning in Large Language Models. However, optimizing solely for final-answer correctness often drives models into aimless, verbose exploration, where they rely on exhaustive trial-and-error tactics rather than structured planning to reach solutions. While heuristic constraints like length penalties can reduce verbosity, they often truncate essential reasoning steps, creating a difficult trade-off between efficiency and verification. This paper proposes JudgeRLVR, a two-stage judge-then-generate paradigm, where the model is trained to judge solution responses with verifiable answers in the first stage and fine-tuned with vanilla generating RLVR in the second stage. Compared to Vanilla RLVR, JudgeRLVR achieves a better quality-efficiency trade-off, demonstrating enhanced generalization on in-domain and out-of-domain benchmarks."" || } ||  ||  || [ Prompt: 14.2 t/s | Generation: 5.1 t/s ]"
2601.08472v1_sui-1 Grounded and Verifiable Long-Form Summarizat.pdf,Grounded and Verifiable,"['Benedikt Droste*', 'Jan Philipp Harries', 'Maximilian Idahl', 'Bjrn Plster', 'ellamind']",,5.4,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || sui-1: Grounded and Verifiable || Long-Form Summarization || Benedikt Droste* Jan Philipp Harries Maximilian Idahl Bjrn Plster || ellamind || Abstract || Large language models frequently generate plausible but unfaithful summaries that users cannot || verify against source text, a critical limitation ... (truncated) ||  || { ""title"": ""Grounded and Verifiable"", ""authors"": [""Benedikt Droste*"", ""Jan Philipp Harries"", ""Maximilian Idahl"", ""Bjrn Plster"", ""ellamind""], ""doi"": """", ""arxiv_id"": ""2601.08472v1"", ""keywords"": [""citation-grounded summarization"", ""long-form summarization"", ""large language models"", ""factual hallucinations"", ""synthetic data generation""], ""summary"": ""This paper presents sui-1, a 24B parameter model designed for generating abstractive summaries with inline citations. The model is capable of processing documents up to 100K tokens in a single pass and supports iterative processing for texts exceeding 2 million tokens. The authors describe synthetic data generation using a capable teacher model, combined with automated verification to ensure citation accuracy. Evaluation shows that sui-1 significantly outperforms all tested open-weight baselines, including models with 3 more parameters. The results demonstrate that task-specific training provides greater benefit than scale alone for citation-grounded summarization. The model is publicly available, along with weights and an interactive demo."" } ||  || [ Prompt: 12.3 t/s | Generation: 5.4 t/s ]"
2601.08475v1_SUMMPILOT Bridging Efficiency and Customization fo.pdf,SUMMPILOT: Bridging Efficiency and Customization for Interactive Summarization System,"['JungMin Yun', 'Juhwan Choi', 'Kyohoon Jin', 'Soojin Jang', 'Jinhee Jang', 'YoungBin Kim']",,7.7,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SUMMPILOT: Bridging Efficiency and Customization || for Interactive Summarization System || JungMin Yun1, Juhwan Choi1, Kyohoon Jin2, Soojin Jang2, Jinhee Jang1, YoungBin Kim1,2 || 1Department of Artificial Intelligence, Chung-Ang University || 2Graduate School of Advanced Imaging Sciences, Mul ... (truncated) ||  || { ""title"": ""SUMMPILOT: Bridging Efficiency and Customization for Interactive Summarization System"", ""authors"": [""JungMin Yun"", ""Juhwan Choi"", ""Kyohoon Jin"", ""Soojin Jang"", ""Jinhee Jang"", ""YoungBin Kim""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""summarization"", ""interactive"", ""personalized"", ""large language model"", ""multi-document""], ""summary"": ""This paper introduces SUMMPILOT, an interaction-based customizable summarization system that combines the efficiency of automatic summarization with personalized summaries tailored to individual users' interests and requirements. SUMMPILOT leverages a large language model to facilitate both automatic and interactive summarization. Users can engage with the system to understand document content and personalize summaries through interactive components such as semantic graphs, entity clustering, and explainable evaluation. The system demonstrates adaptability and usefulness for customizable summarization through demos and user studies. The introduction and related work discuss the challenges of automated summarization and the benefits of interactive systems. The limitations of existing interactive summarization systems are addressed, and SUMMPILOT is introduced as an interactive summarization system that incorporates user-specific needs into the summarization process. The system supports multi-document summarization and provides explainable evaluation to enhance user understanding and decision-making."" } ||  || [ Prompt: 13.5 t/s | Generation: 7.7 t/s ]"
2601.08490v1_BenchOverflow Measuring Overflow in Large Language.pdf,BenchOverflow: Measuring Overflow in Large Language Models via Plain-Text Prompts,"['Erin Feiglin', 'Nir Hutnik', 'Raz Lapid']",,11.5,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Published in Transactions on Machine Learning Research (01/2026) || BenchOverflow: Measuring Overflow in Large Language || Models via Plain-Text Prompts || Erin Feiglin erin@deepkeep.ai || Deepkeep || Tel-Aviv, Israel || Nir Hutnik nir@deepkeep.ai || Deepkeep || Tel-Aviv, Israel || Raz Lapid raz.lapid@deepkee ... (truncated) ||  || { || ""title"": ""BenchOverflow: Measuring Overflow in Large Language Models via Plain-Text Prompts"", || ""authors"": [""Erin Feiglin"", ""Nir Hutnik"", ""Raz Lapid""], || ""doi"": """", || ""arxiv_id"": ""2601.08490"", || ""keywords"": [""Overflow"", ""Large Language Models"", ""Plain-Text Prompts"", ""Model Agnostic Benchmark"", ""Resource Waste"", ""Latency"", ""Cross-User Performance""], || ""summary"": ""This paper investigates a failure mode in large language models (LLMs) where plain-text prompts elicit excessive outputs, termed Overflow. The authors introduce BenchOverflow, a model-agnostic benchmark of nine plain-text prompting strategies that amplify output volume without adversarial suffixes or policy circumvention. Using a standardized protocol with a fixed budget of 5,000 new tokens, the authors evaluate nine open- and closed-source models and observe pronounced rightward shifts and heavy tails in length distributions. They quantify tail risk using cap-saturation rates (CSR@1k/3k/5k) and empirical cumulative distribution functions (ECDFs), and show that Overflow is broadly reproducible yet heterogeneous across families and attack vectors. A lightweight mitigation, a fixed conciseness reminder, attenuates right tails and lowers CSR for all strategies across the majority of models. The findings position length control as a measurable reliability, cost, and sustainability concern, enabling standardized comparison of length-control robustness across models and providing a practical basis for selecting deployments that minimize resource waste and operating expense, and for evaluating defenses that curb compute amplification without eroding task performance."" || } ||  || [ Prompt: 32.9 t/s | Generation: 11.5 t/s ]"
2601.08493v1_PKI Prior Knowledge-Infused Neural Network for Few.pdf,PKI: Prior Knowledge-Infused Neural Network for Few-Shot Class-Incremental Learning,"['Kexin Bao', 'Fanzhao Lin', 'Zichen Wang', 'Yong Li', 'Dan Zeng', 'Shiming Ge']",,13.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || PKI: Prior Knowledge-Infused Neural Network for || Few-Shot Class-Incremental Learning || Kexin Baoa,b, Fanzhao Linc, Zichen Wangd, Yong Lia,b, Dan Zenge, || Shiming Gea,b, || aInstitute of Information Engineering, Chinese Academy of || Sciences, Beijing, 100092, China || bSchool of Cyber Security at ... (truncated) ||  || ```json || { || ""title"": ""PKI: Prior Knowledge-Infused Neural Network for Few-Shot Class-Incremental Learning"", || ""authors"": [""Kexin Bao"", ""Fanzhao Lin"", ""Zichen Wang"", ""Yong Li"", ""Dan Zeng"", ""Shiming Ge""], || ""doi"": """", || ""arxiv_id"": ""2601.08493v1"", || ""keywords"": [""Few-Shot Learning"", ""Class-Incremental Learning"", ""Prior Knowledge"", ""Neural Networks"", ""Catastrophic Forgetting"", ""Overfitting""], || ""summary"": ""Few-shot class-incremental learning (FSCIL) aims to continually adapt a model on a limited number of new-class examples, facing challenges of catastrophic forgetting and overfitting to new classes. Existing methods often freeze parts of the network and fine-tune others with extra memory. PKI, a prior knowledge-infused neural network, retains more prior knowledge and proposes a new projector for each incremental session, helping to mitigate catastrophic forgetting and overfitting."" || } ||  ||  || [ Prompt: 31.5 t/s | Generation: 13.0 t/s ]"
2601.08499v2_EfficientFSL Enhancing Few-Shot Classification via.pdf,EfficientFSL: Enhancing Few-Shot Classification via Query-Only Tuning in Vision Transformers,"['Wenwen Liao', 'Hang Ruan', 'Jianbo Yu*', 'Bing Song', 'Yuansong Wang', 'Xiaofeng Yang']",,11.1,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || EfficientFSL: Enhancing Few-Shot Classification via Query-Only Tuning in Vision || Transformers || Wenwen Liao1, Hang Ruan1, Jianbo Yu2*, Bing Song3, Yuansong Wang4, Xiaofeng Yang2 || 1College of Intelligent Robotics and Advance Manufacturing, Fudan University, Shanghai China || 2School of Micr ... (truncated) ||  || { ""title"": ""EfficientFSL: Enhancing Few-Shot Classification via Query-Only Tuning in Vision Transformers"", ""authors"": [""Wenwen Liao"", ""Hang Ruan"", ""Jianbo Yu*"", ""Bing Song"", ""Yuansong Wang"", ""Xiaofeng Yang""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Few-Shot Learning"", ""Vision Transformers"", ""Query-Only Fine-Tuning"", ""Feature Extraction"", ""Representation Learning""], ""summary"": ""EfficientFSL is a query-only fine-tuning framework specifically designed for few-shot classification with Vision Transformers. It achieves competitive performance while significantly reducing computational overhead. The framework leverages the knowledge embedded in the pre-trained model and its strong comprehension ability to achieve high classification accuracy with a minimal number of tunable parameters. Specifically, it introduces a lightweight trainable Forward Block to synthesize task-specific queries that extract informative features from the intermediate representations of the pre-trained model in a query-only manner. It further proposes a Combine Block to fuse multi-layer outputs, enhancing the depth and robustness of feature representations. Finally, a Support-Query Attention Block mitigates distribution shift by adjusting prototypes to align with the query set distribution. With minimal trainable parameters, EfficientFSL achieves state-of-the-art performance on four in-domain few-shot datasets and six cross-domain datasets, demonstrating its effectiveness in real-world applications."" } ||  || [ Prompt: 28.3 t/s | Generation: 11.1 t/s ]"
2601.08503v1_Temporal Fusion Nexus A task-agnostic multi-modal .pdf,Temporal Fusion Nexus: A task-agnostic multi-modal embedding model for clinical narratives and irregular time series in post-kidney transplant care,"['Aditya Kumar', 'Simon Rauch', 'Mario Cypko', 'Marcel Naik', 'Matthieu-P Schapranow', 'Aadil Rashid', 'Fabian Halleck', 'Bilgin Osmanodja', 'Roland Roller', 'Lars Pape', 'Klemens Budde', 'Mario Schiffer', 'Oliver Amft']",,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Temporal Fusion Nexus: A task-agnostic multi- || modal embedding model for clinical narratives and || irregular time series in post-kidney transplant care || Aditya Kumar1,2*, Simon Rauch 2, Mario Cypko 1,2, Marcel Naik 3, || Matthieu-P Schapranow4, Aadil Rashid 4, Fabian Halleck 3, || Bilgin Osma ... (truncated) ||  || { ""title"": ""Temporal Fusion Nexus: A task-agnostic multi-modal embedding model for clinical narratives and irregular time series in post-kidney transplant care"", ""authors"": [""Aditya Kumar"", ""Simon Rauch"", ""Mario Cypko"", ""Marcel Naik"", ""Matthieu-P Schapranow"", ""Aadil Rashid"", ""Fabian Halleck"", ""Bilgin Osmanodja"", ""Roland Roller"", ""Lars Pape"", ""Klemens Budde"", ""Mario Schiffer"", ""Oliver Amft""], ""doi"": """", ""arxiv_id"": ""2601.08503"", ""keywords"": [""Temporal Fusion Nexus"", ""multi-modal embedding"", ""clinical narratives"", ""irregular time series"", ""post-kidney transplant care"", ""graft loss"", ""graft rejection"", ""mortality prediction""], ""summary"": ""Temporal Fusion Nexus (TFN) is a multi-modal and task-agnostic embedding model designed to integrate irregular time series and unstructured clinical narratives. In post-kidney transplant (KTx) care, TFN was evaluated on three key outcomes: graft loss, graft rejection, and mortality. Compared to state-of-the-art models in post-KTx care, TFN achieved higher performance for graft loss (AUC 0.96 vs. 0.94) and graft rejection (AUC 0.84 vs. 0.74). In mortality prediction, TFN yielded an AUC of 0.86. TFN outperformed unimodal baselines by 10% in time series only and 5% in time series with static patient data. Integrating clinical text improved performance across all tasks. Disentanglement metrics confirmed robust and interpretable latent factors in the embedding space, and SHAP-based attributions confirmed alignment with clinical reasoning. TFN has potential applications in clinical tasks beyond KTx."" }"
2601.08509v1_What If TSF A Benchmark for Reframing Forecasting .pdf,What If TSF: A Benchmark for Reframing Forecasting as Scenario-Guided Multimodal Forecasting,"['Jinkwan Jang', 'Hyunbin Jin', 'Hyungjin Park', 'Kyubyung Chae', 'Taesup Kim']",,5.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || What If TSF: A Benchmark for Reframing Forecasting || as Scenario-Guided Multimodal Forecasting || Jinkwan Jang, Hyunbin Jin, Hyungjin Park, Kyubyung Chae, Taesup Kim || Graduate School of Data Science, Seoul National University || {jkjang22, hyunbin.jin, robin5310, kyubyung.chae, taesup.kim}@s ... (truncated) ||  || { || ""title"": ""What If TSF: A Benchmark for Reframing Forecasting as Scenario-Guided Multimodal Forecasting"", || ""authors"": [""Jinkwan Jang"", ""Hyunbin Jin"", ""Hyungjin Park"", ""Kyubyung Chae"", ""Taesup Kim""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""forecasting"", ""multimodal"", ""scenario-guided"", ""time series"", ""large language models""], || ""summary"": ""Time series forecasting is critical for decision making, but most methods are unimodal and rely on historical patterns. Recent progress in LLMs highlights the potential for multimodal forecasting, but existing benchmarks provide retrospective or misaligned context. We introduce What If TSF (WIT), a benchmark to evaluate whether models can condition forecasts on contextual text, especially future scenarios. WIT offers a rigorous testbed for scenario-guided multimodal forecasting by providing expert-crafted plausible or counterfactual scenarios. The benchmark is available at https://github.com/jinkwan1115/WhatIfTSF."" || } ||  || [ Prompt: 12.8 t/s | Generation: 5.0 t/s ]"
2601.08510v2_STAGE A Benchmark for Knowledge Graph Construction.pdf,"STAGE: A Benchmark for Knowledge Graph Construction, Question Answering, and In-Script Role-Playing over Movie Screenplays","['Qiuyu Tian', 'Yiding Li', 'Fengyi Chen', 'Zequn Liu', 'Youyong Kong', 'Fan Guo', 'Yuyao Li', 'Jinjing Shen', 'Zhijing Xie', 'Yiyun Luo', 'Xin Zhang']",,5.7,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || STAGE: A Benchmark for Knowledge Graph || Construction, Question Answering, and In-Script || Role-Playing over Movie Screenplays || Qiuyu Tian 1,2 Yiding Li 5 Fengyi Chen3 Zequn Liu 2 Youyong || Kong1 Fan Guo5 || Yuyao Li5 Jinjing Shen 5 Zhijing Xie 5 Yiyun Luo 5 Xin Zhang 5 || 1Southeast University, ... (truncated) ||  || { ""title"": ""STAGE: A Benchmark for Knowledge Graph Construction, Question Answering, and In-Script Role-Playing over Movie Screenplays"", ""authors"": [""Qiuyu Tian"", ""Yiding Li"", ""Fengyi Chen"", ""Zequn Liu"", ""Youyong Kong"", ""Fan Guo"", ""Yuyao Li"", ""Jinjing Shen"", ""Zhijing Xie"", ""Yiyun Luo"", ""Xin Zhang""], ""doi"": """", ""arxiv_id"": ""2601.08510"", ""keywords"": [""movie screenplays"", ""narrative understanding"", ""knowledge graph"", ""question answering"", ""role-playing"", ""long-context screenplay"", ""character-centric""], ""summary"": ""Movie screenplays are rich, long-form narratives that interleave complex character relationships, temporally ordered events, and dialogue-driven interactions. STAGE introduces a unified benchmark for narrative understanding over full-length movie screenplays, defining four tasks: knowledge graph construction, scene-level event summarization, long-context screenplay question answering, and in-script character role-playing, all grounded in a shared narrative world representation. The benchmark provides cleaned scripts, curated knowledge graphs, and event- and character-centric resources."" } ||  || [ Prompt: 14.2 t/s | Generation: 5.7 t/s ]"
2601.08519v1_CD2 Constrained Dataset Distillation for Few-Shot .pdf,,[],,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || CD2: Constrained Dataset Distillation for Few-Shot Class-Incremental Learning || Kexin Bao1,2 ,Daichi Zhang 1,2 ,Hansong Zhang 1,2 ,Y ong Li 1 ,Yutao Yue 3 andShiming Ge 1 || 1Institute of Information Engineering, Chinese Academy of Sciences || 2School of Cyber Security, University of Chines ... (truncated) ||  || { || ""title"": ""CD2: Constrained Dataset Distillation for Few-Shot Class-Incremental Learning"", || ""authors"": [""Kexin Bao"", ""Daichi Zhang"", ""Hansong Zhang"", ""Yong Li"", ""Yutao Yue"", ""Shiming Ge""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""few-shot learning"", ""class-incremental learning"", ""dataset distillation"", ""catastrophic forgetting""], || ""summary"": ""Few-shot class-incremental learning (FSCIL) faces the challenge of catastrophic forgetting when learning continuously with a few training samples. Existing methods often use an external memory to store previous knowledge but treat it equally with incremental classes, leading to insufficient preservation of essential knowledge. This paper proposes a framework called Constrained Dataset Distillation (CD2) to address this issue. CD2 includes a dataset distillation module (DDM) and a distillation constraint module (DCM). The DDM synthesizes highly condensed samples guided by the classifier, forcing the model to learn compact essential class-related clues from a few incremental samples. The DCM introduces a designed loss to constrain the previously learned class distribution, preserving distilled knowledge more sufficiently. Extensive experiments on three public datasets demonstrate the superiority of our method over state-of-the-art competitors."""
2601.08531v1_Sketch-Based Facade Renovation With Generative AI .pdf,Sketch-Based Facade Renovation With Generative AI Models,"['Warissara Booranamaitree', 'Xusheng Du', 'Y ushu Cai', 'Zhengyang Wang', 'Ye Zhang', 'Haoran Xie']",,12.7,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  ||  || Sketch-Based Facade Renovation With Generative AI Models || A Streamlined Framework for Bypassing As-Built Modelling in Industrial Adaptive || Reuse || Warissara Booranamaitree1#, Xusheng Du2#, Y ushu Cai3, Zhengyang || Wang4, Ye Zhang5*, and Haoran Xie6,7* || 1Chulalongkorn University. || ... (truncated) ||  || { || ""title"": ""Sketch-Based Facade Renovation With Generative AI Models"", || ""authors"": [""Warissara Booranamaitree"", ""Xusheng Du"", ""Y ushu Cai"", ""Zhengyang Wang"", ""Ye Zhang"", ""Haoran Xie""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Industrial building renovation"", ""vision-language model"", ""diffusion model"", ""user sketches"", ""facade renovation""], || ""summary"": ""This paper proposes a three-stage framework combining generative artificial intelligence (AI) and vision-language models (VLM) to produce renovation proposals directly from rough structural sketches and textual descriptions. The framework bypasses the need for detailed as-built modelling, enabling architects to rapidly explore design alternatives, iterate on early-stage concepts, and communicate renovation intentions with greater clarity."" || } ||  || [ Prompt: 29.8 t/s | Generation: 12.7 t/s ]"
2601.08545v2_Learner-Tailored Program Repair A Solution Generat.pdf,Learner-Tailored Program Repair: A Solution Generator with Iterative Edit-Driven Retrieval Enhancement,"['Zhenlong Dai', 'Zhuoluo Zhao', 'Hengning Wang', 'Xiu Tang', 'Sai Wu', 'Chang Yao', 'Zhipeng Gao', 'Jingyuan Chen']",,11.6,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Learner-Tailored Program Repair: A Solution Generator with || Iterative Edit-Driven Retrieval Enhancement || Zhenlong Dai1,2*, Zhuoluo Zhao1,2*, Hengning Wang1, || Xiu Tang1,2, Sai Wu1,2, Chang Yao1,2, Zhipeng Gao1, Jingyuan Chen1 || 1Zhejiang University || 2Hangzhou High-Tech Zone (Binjiang) Inst ... (truncated) ||  || ```json || { || ""title"": ""Learner-Tailored Program Repair: A Solution Generator with Iterative Edit-Driven Retrieval Enhancement"", || ""authors"": [""Zhenlong Dai"", ""Zhuoluo Zhao"", ""Hengning Wang"", ""Xiu Tang"", ""Sai Wu"", ""Chang Yao"", ""Zhipeng Gao"", ""Jingyuan Chen""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""program repair"", ""intelligent tutoring"", ""large language models"", ""code retrieval"", ""bug fixing""], || ""summary"": ""With the development of large language models in programming, intelligent programming coaching systems have gained widespread attention. However, most research focuses on repairing the buggy code of programming learners without providing the underlying causes of the bugs. To address this gap, we introduce a novel task, namely LPR (Learner-Tailored Program Repair). We propose a novel and effective framework, LSGEN (Learner-Tailored Solution Generator), to enhance program repair while offering bug descriptions for buggy code. In the first stage, we utilize a repair solution retrieval framework to construct a solution retrieval database and employ an edit-driven code retrieval approach to retrieve valuable solutions, guiding LLMs in identifying and fixing bugs in buggy code. In the second stage, we propose a solution-guided program repair method, which fixes the code and provides explanations under the guidance of retrieval solutions. Moreover, we propose an Iterative Retrieval Enhancement method that utilizes evaluation results of generated code to iteratively optimize the retrieval direction and explore more suitable repair strategies, improving performance in practical programming coaching scenarios. The experimental results show that our approach outperforms a set of baselines by a large margin, validating the effectiveness of our framework for the newly proposed LPR task."" || } ||  ||  || [ Prompt: 29.6 t/s | Generation: 11.6 t/s ]"
2601.08549v1_Contrastive and Multi-Task Learning on Noisy Brain.pdf,Contrastive and Multi-Task Learning on Noisy Brains Signals with Nonlinear Dynamical Signatures,"['Sucheta Ghosh', 'Zahra Monfared']",,11.5,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Published as a conference paper at ICLR 2026 || CONTRASTIVE ANDMULTI-TASKLEARNING ONNOISY || BRAINSIGNALS WITHNONLINEARDYNAMICALSIG- || NATURES || Sucheta Ghosh 1,2, Zahra Monfared1,2,3, Felix Dietrich4 || {sucheta.ghosh,zahra.monfared}@iwr.uni-heidelberg.de || 1Interdisciplinary Center for Scientifi ... (truncated) ||  || { ""title"": ""Contrastive and Multi-Task Learning on Noisy Brains Signals with Nonlinear Dynamical Signatures"", ""authors"": [""Sucheta Ghosh"", ""Zahra Monfared""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Electroencephalography (EEG)"", ""Motor Imagery (MI)"", ""Chaotic Dynamics"", ""Nonlinear Dynamics"", ""Self-Supervised Learning"", ""Contrastive Learning"", ""Denoising"", ""Temporal Dynamics""], ""summary"": ""We introduce a two-stage multitask learning framework for analyzing Electroencephalography (EEG) signals that integrates denoising, dynamical modeling, and representation learning. In the first stage, a denoising autoencoder is trained to suppress artifacts and stabilize temporal dynamics, providing robust signal representations. In the second stage, a multitask architecture processes these denoised signals to achieve three objectives: motor imagery classification, chaotic versus non-chaotic regime discrimination using Lyapunov exponent-based labels, and self-supervised contrastive representation learning with NT-Xent loss. A convolutional backbone combined with a Transformer encoder captures spatial-temporal structure, while the dynamical task encourages sensitivity to nonlinear brain dynamics. This staged design mitigates interference between reconstruction and discriminative goals, improves stability across datasets, and supports reproducible training by clearly separating noise reduction from higher-level feature learning. Empirical studies show that our framework not only enhances robustness and generalization but also surpasses strong baselines and recent state-of-the-art methods in EEG decoding, highlighting the effectiveness of combining denoising, dynamical features, and self-supervised learning."" } ||  || [ Prompt: 31.4 t/s | Generation: 11.5 t/s ]"
2601.08557v1_VideoHEDGE Entropy-Based Hallucination Detection f.pdf,VideoHEDGE: Entropy-Based Hallucination Detection for Video-VLMs via Semantic Clustering and Spatiotemporal Perturbations,"['Sushant Gautam', 'Cise Midoglu', 'Vajira Thambawita', 'Michael A. Riegler', 'Pl Halvorsen']",,5.4,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || VideoHEDGE: Entropy-Based Hallucination Detection for || Video-VLMs via Semantic Clustering and Spatiotemporal || Perturbations || Sushant Gautam || SimulaMet & OsloMet || Oslo, Norway || sushant@simula.no || Cise Midoglu || Forzasys || Oslo, Norway || cisemidoglu@gmail.com || Vajira Thambawita || SimulaMet || Oslo, Norw ... (truncated) ||  || { || ""title"": ""VideoHEDGE: Entropy-Based Hallucination Detection for Video-VLMs via Semantic Clustering and Spatiotemporal Perturbations"", || ""authors"": [""Sushant Gautam"", ""Cise Midoglu"", ""Vajira Thambawita"", ""Michael A. Riegler"", ""Pl Halvorsen""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Video-VLMs"", ""hallucinations"", ""entropy-based detection"", ""semantic clustering"", ""spatiotemporal perturbations""], || ""summary"": ""Hallucinations in video-capable vision-language models (Video-VLMs) remain frequent and high-confidence, while existing uncertainty metrics often fail to align with correctness. This paper introduces VideoHEDGE, a modular framework for hallucination detection in video question answering that extends entropy-based reliability estimation from images to temporally structured inputs. Given a video-question pair, VideoHEDGE draws a baseline answer and multiple high-temperature generations from both clean clips and photometrically and spatiotemporally perturbed variants, then clusters the resulting textual outputs into semantic hypotheses using either Natural Language Inference (NLI)-based or embedding-based methods. Cluster-level probability masses yield three reliability scores: Semantic Entropy (SE), RadFlag, and Vision-Amplified Semantic Entropy (VASE). The framework is evaluated on the SoccerChat benchmark using an LLM-as-a-judge to obtain binary hallucination labels. Across three 7B Video-VLMs (Qwen2-VL, Qwen2.5-VL, and a SoccerChat-finetuned model), VASE consistently achieves the highest ROC-AUC, especially at larger distortion budgets, while SE and RadFlag often operate near chance. The paper also shows that embedding-based clustering matches NLI-based clustering in detection performance at substantially lower computational cost, and that domain fine-tuning reduces hallucination frequency but yields only modest improvements in calibration. The hedge-bench PyPI library enables reproducible and extensible benchmarking, with full code and experimental resources available at https://github.com/Simula/HEDGE#videohedge."" || } ||  || [ Prompt: 29.0 t/s | Generation: 5.4 t/s ]"
2601.08559v1_WaterCopilot An AI-Driven Virtual Assistant for Wa.pdf,WaterCopilot: An AI-Driven Virtual Assistant for Water Management,"['Keerththanan Vickneswaran', 'Mariangel Garcia Andarcia', 'Hugo Retief', 'Chris Dickens', 'Paulo Silva']",,0.0,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || WaterCopilot: An AI-Driven Virtual Assistant || for Water Management ||  || Keerththanan Vickneswaran || Water Futures Data & Analytics || International Water Management || Institute || Sri Lanka || K.Vickneswaran@cgiar.org ... (truncated) ||  || { ""title"": ""WaterCopilot: An AI-Driven Virtual Assistant for Water Management"", ""authors"": [""Keerththanan Vickneswaran"", ""Mariangel Garcia Andarcia"", ""Hugo Retief"", ""Chris Dickens"", ""Paulo Silva""], ""doi"": """", ""arxiv_id"": """", ""keywords"": [""Water resource management"", ""Retrieval-Augmented Generation"", ""AI-driven virtual assistant"", ""Limpopo River Basin"", ""Transboundary river basins"", ""Hydrological data"", ""Real-time access"", ""Semantic search"", ""Environmental-flow alerts"", ""Rainfall trends"", ""Reservoir levels"", ""Water accounting"", ""Irrigation data""], ""summary"": ""Water resource management in transboundary river basins faces challenges such as fragmented data, limited real-time access, and the complexity of integrating diverse information sources. This paper introduces WaterCopilot, an AI-driven virtual assistant developed through collaboration between the International Water Management Institute (IWMI) and Microsoft Research for the Limpopo River Basin (LRB) to bridge these gaps. Built on Retrieval-Augmented Generation (RAG) and tool-calling architectures, WaterCopilot integrates static policy documents and real-time hydrological data via two custom plugins: the iwmi-doc-plugin and the iwmi-api-plugin. The system features guided multilingual interactions, transparent source referencing, automated calculations, and visualization capabilities. Evaluated using the RAGAS framework, WaterCopilot achieves an overall score of 0.8043, with high answer relevancy and context precision. Key innovations include automated threshold-based alerts, integration with the LRB Digital Twin, and a scalable deployment pipeline hosted on AWS. While limitations in processing non-English technical documents and API latency remain, WaterCopilot establishes a replicable AI-augmented framework for enhancing water governance in data-scarce, transboundary contexts. The study demonstrates the potential of this AI assistant to support informed, timely decision-making and strengthen water security in complex river basins."" }"
2601.08565v1_Rewriting Video Text-Driven Reauthoring of Video F.pdf,Rewriting Video: Text-Driven Reauthoring of Video Footage,"['Sitong Wang', 'Anh Truong', 'Lydia B. Chilton', 'Dingzeyu Li']",,5.2,Qwen,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : qwen2.5-3b-instruct-q4_k_m.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Rewriting Video: Text-Driven Reauthoring of Video Footage || Sitong Wang || Columbia University || New York, NY, USA || sw3504@columbia.edu || Anh Truong || Adobe Research || New York, NY, USA || truong@adobe.com || Lydia B. Chilton || Columbia University || New York, NY, USA || chilton@cs.columbia.edu || Dingzeyu Li || Ado ... (truncated) ||  || { || ""title"": ""Rewriting Video: Text-Driven Reauthoring of Video Footage"", || ""authors"": [""Sitong Wang"", ""Anh Truong"", ""Lydia B. Chilton"", ""Dingzeyu Li""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Video reauthoring"", ""Text-driven video editing"", ""Generative video models"", ""Creative AI tools""], || ""summary"": ""Video is a powerful medium for communication and storytelling, yet reauthoring existing footage remains challenging. Recent advances in generative AI suggest a new paradigm: what if editing a video were as straightforward as rewriting text? This paper presents a tech probe and a study on text-driven video reauthoring. Our approach involves a generative reconstruction algorithm that reverse-engineers video into an editable text prompt, and an interactive probe, Rewrite Kit, that allows creators to manipulate these prompts. A technical evaluation reveals a critical human-AI perceptual gap. A probe study with 12 creators surfaced novel use cases such as virtual reshooting, synthetic continuity, and aesthetic restyling, highlighting key tensions around coherence, control, and creative alignment in this new paradigm. Our work contributes empirical insights into the opportunities and challenges of text-driven video reauthoring, offering design implications for future co-creative video tools."" || } ||  || [ Prompt: 13.4 t/s | Generation: 5.2 t/s ]"
