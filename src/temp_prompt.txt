<|im_start|>system
You are a metadata extraction system. Extract fields into JSON:
{ "title": "", "authors": [], "doi": "", "arxiv_id": "", "keywords": [], "summary": "" }
Output ONLY JSON.<|im_end|>
<|im_start|>user
Relink: Constructing Query-Driven Evidence Graph On-the-Fly for GraphRAG
Manzong Huang1, Chenyang Bu1*, Yi He2, Xingrui Zhuo1, Xindong Wu 1*
1Key Laboratory of Knowledge Engineering with Big Data (the Ministry of Education of China), School of Computer Science
and Information Engineering, Hefei University of Technology, China
2Department of Data Science, College of William and Mary, USA
{manzonghuang, zxr}@mail.hfut.edu.cn, yihe@wm.edu, {chenyangbu, xwu}@hfut.edu.cn
Abstract
Graph-based Retrieval-Augmented Generation (GraphRAG)
mitigates hallucinations in Large Language Models (LLMs)
by grounding them in structured knowledge. However, cur-
rent GraphRAG methods are constrained by a prevailing
build-then-reasonparadigm, which relies on a static, pre-
constructed Knowledge Graph (KG). This paradigm faces
two critical challenges. First, the KG’s inherent incomplete-
ness often breaks reasoning paths. Second, the graph’s low
signal-to-noise ratio introduces distractor facts, presenting
query-relevant but misleading knowledge that disrupts the
reasoning process. To address these challenges, we argue
for areason-and-constructparadigm and propose Relink, a
framework that dynamically builds a query-specific evidence
graph. To tackle incompleteness,Relinkinstantiates required
facts from a latent relation pool derived from the original
text corpus, repairing broken paths on the fly. To handle mis-
leading or distractor facts, Relink employs a unified, query-
aware evaluation strategy that jointly considers candidates
from both the KG and latent relations, selecting those most
useful for answering the query rather than relying on their
pre-existence. This empowers Relink to actively discard dis-
tractor facts and construct the most faithful and precise ev-
idence path for each query. Extensive experiments on five
Open-Domain Question Answering benchmarks show that
Relink achieves significant average improvements of 5.4%
in EM and 5.2% in F1 over leading GraphRAG baselines,
demonstrating the superiority of our proposed framework.
Code— https://github.com/DMiC-Lab-HFUT/Relink
Introduction
Despite the impressive performance in open-domain ques-
tion answering (ODQA) (Patel et al. 2023; Kamalloo et al.
2023), large language models (LLMs) are prone to fac-
tual errors—known as hallucinations (Pan et al. 2024;
Huang et al. 2025a). Such errors often arise from their
over-reliance on internal parametric knowledge. To miti-
gate this, Retrieval-Augmented Generation (RAG) grounds
LLMs in external knowledge (Gupta, Ranjan, and Singh
2024). GraphRAG (Pan et al. 2024; Peng et al. 2024) further
advances this approach by utilizing Knowledge Graph (KG)
Copyright © 2026, Association for the Advancement of Artificial
Intelligence (www.aaai.org). All rights reserved.
* Corresponding authors.
Amboise
UnknowMona Lisa da Vinci
Chapel of 
Saint-
Hubert
Mona 
Lisa da Vinci
Chapel of 
Saint-
Hubert
EM: 
5.4%
F1: 
5.2%
Q: Where is the tomb of the painter of the Mona Lisa located?
St<|im_end|>
<|im_start|>assistant
