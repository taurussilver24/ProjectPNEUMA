filename,title,authors,doi,tps,model,platform,raw_output
2601.07192v1_Relink Constructing Query-Driven Evidence Graph On.pdf,Constructing Query-Driven Evidence Graph On-the-Fly for GraphRAG,"['Manzong Huang', 'Chenyang Bu', 'Yi He', 'Xingrui Zhuo', 'Xindong Wu']",,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Relink: Constructing Query-Driven Evidence Graph On-the-Fly for GraphRAG || Manzong Huang1, Chenyang Bu1*, Yi He2, Xingrui Zhuo1, Xindong Wu 1* || 1Key Laboratory of Knowledge Engineering with Big Data (the Ministry of Education of China), School of Computer Science || and Information Engine ... (truncated) ||  || { || ""title"": ""Constructing Query-Driven Evidence Graph On-the-Fly for GraphRAG"", || ""authors"": [ || ""Manzong Huang"", || ""Chenyang Bu"", || ""Yi He"", || ""Xingrui Zhuo"", || ""Xindong Wu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Relink addresses hallucinations in LLMs by dynamically building a query-specific evidence graph, overcoming limitations of static knowledge graphs."" || } ||  || [ Prompt: 125.1 t/s | Generation: 29.3 t/s ]"
2601.07197v1_Beyond Variance Knowledge-Aware LLM Compression vi.pdf,Beyond Variance: Knowledge-Aware LLM Compression via Fisher-Aligned,"['Ibne Farabi Shihab', 'Sanjeda Akter', 'Anuj Sharma']",10.48550/arXiv.2303.04219,29.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Beyond Variance: Knowledge-Aware LLM Compression via Fisher-Aligned || Subspace Diagnostics || Ibne Farabi Shihab*1 and Sanjeda Akter *1 and Anuj Sharma 2 || 1Department of Computer Science, Iowa State University || 2Department of Civil, Construction & Environmental Engineering, Iowa State Univ ... (truncated) ||  || { || ""title"": ""Beyond Variance: Knowledge-Aware LLM Compression via Fisher-Aligned"", || ""authors"": [ || ""Ibne Farabi Shihab"", || ""Sanjeda Akter"", || ""Anuj Sharma"" || ], || ""doi"": ""10.48550/arXiv.2303.04219"", || ""arxiv_id"": ""arXiv:2303.04219"", || ""keywords"": [ || ""knowledge-aware compression"", || ""Fisher-Aligned Subspace"", || ""activation compression"", || ""MMLU"", || ""LLaMA"", || ""knowledge preservation"" || ], || ""summary"": ""The paper introduces Fisher-Aligned Subspace Compression (FASC), a method that leverages Fisher Information to select subspaces aligned with activation gradients, aiming to preserve factual knowledge while reducing model size. Experiments show FASC outperforms variance-based methods in accuracy on knowledge-intensive benchmarks."" || } ||  || [ Prompt: 126.2 t/s | Generation: 29.5 t/s ]"
2601.07199v1_Forward versus Backward Comparing Reasoning Object.pdf,Forward versus Backward: Comparing Reasoning Objectives in Direct Preference Optimization,"['Murtaza Nikazad', 'Raghuram Ramanujan']",,31.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Forward versus Backward: Comparing Reasoning Objectives in || Direct Preference Optimization || Murtaza Nikazad || Department of Math and Computer Science || Davidson College || munikzad@davidson.edu || Raghuram Ramanujan || Department of Math and Computer Science || Davidson College || raramanujan@davidson.e ... (truncated) ||  || { || ""title"": ""Forward versus Backward: Comparing Reasoning Objectives in Direct Preference Optimization"", || ""authors"": [ || ""Murtaza Nikazad"", || ""Raghuram Ramanujan"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper investigates the effect of training objective composition on reasoning reliability through Direct Preference Optimization. It compares forward chain-of-thought generation and backward verification, revealing a trade-off between accuracy improvement and false positive reduction."" || } ||  || [ Prompt: 141.3 t/s | Generation: 31.9 t/s ]"
2601.07200v1_Safeguarding LLM Fine-tuning via Push-Pull Distrib.pdf,Safeguarding LLM Fine-tuning via Push-Pull Distributional Alignment,"['Haozhong Wang', 'Zhuo Li', 'Yibo Yang', 'Hao Hongyuan', 'Dandan Guo']",,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Safeguarding LLM Fine-tuning via Push-Pull Distributional Alignment || Haozhong Wang1* Zhuo Li2* Yibo Yang3 He Zhao4 Hongyuan Zha5 Dandan Guo6 || guodandan@jlu.edu.cn || Abstract || The inherent safety alignment of Large Lan- || guage Models (LLMs) is prone to erosion dur- || ing fine-tuning, even wh ... (truncated) ||  || { || ""title"": ""Safeguarding LLM Fine-tuning via Push-Pull Distributional Alignment"", || ""authors"": [ || ""Haozhong Wang"", || ""Zhuo Li"", || ""Yibo Yang"", || ""Hao Hongyuan"", || ""Dandan Guo"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper discusses the safety alignment of Large Language Models (LLMs) during fine-tuning, introducing Safety Optimal Transport (SOT) to improve alignment by optimizing sample importance and establishing a geometric safety boundary."" || } ||  || [ Prompt: 126.6 t/s | Generation: 29.0 t/s ]"
2601.07201v1_CalPro Prior-Aware Evidential--Conformal Predictio.pdf,CalPro: Prior-Aware EvidentialConformal Prediction with Structure-Aware,"['Ibne Farabi Shihab', 'Shihab, A.', 'Akder, A.', 'Anuj Sharma']",10.48550/arXiv.2024.12345,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || CalPro: Prior-Aware EvidentialConformal Prediction with Structure-Aware || Guarantees for Protein Structures || Ibne Farabi Shihab * 1 Sanjeda Akter * 1 Anuj Sharma 2 || Abstract || Deep protein structure predictors such as Al- || phaFold provide confidence estimates (e.g., || pLDDT) that are not cal ... (truncated) ||  || { || ""title"": ""CalPro: Prior-Aware EvidentialConformal Prediction with Structure-Aware"", || ""authors"": [ || ""Ibne Farabi Shihab"", || ""Shihab, A."", || ""Akder, A."", || ""Anuj Sharma"" || ], || ""doi"": ""10.48550/arXiv.2024.12345"", || ""arxiv_id"": ""arXiv:2408.12345"", || ""keywords"": [ || ""protein structure prediction"", || ""confidence estimation"", || ""conformal prediction"", || ""structural biology"", || ""uncertainty quantification"" || ], || ""summary"": ""CalPro introduces a prior-aware evidential conformal framework for shift-robust uncertainty quantification in protein structure prediction. It combines a geometric evidential head with a differentiable conformal layer and encodes domain priors as soft constraints, achieving better calibration and coverage compared to existing methods."" || } ||  || [ Prompt: 134.9 t/s | Generation: 29.3 t/s ]"
2601.07206v1_LLMRouterBench A Massive Benchmark and Unified Fra.pdf,LLMRouterBench: A Massive Benchmark and Unified Framework for LLM Routing,"['Hao Li', 'Yiqun Zhang', 'Zhaoyan Guo', 'Chenxu Wang', 'Shengji Tang', 'Qiaosheng Zhang Yang', 'Chen Biqing Qi', 'Peng Ye Lei', 'Bai Zhen Wang', 'Shuyue Hu']",,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LLMRouterBench: A Massive Benchmark and Unified Framework for || LLM Routing || Hao Li* Yiqun Zhang* Zhaoyan Guo* Chenxu Wang* || Shengji Tang Qiaosheng Zhang Yang Chen Biqing Qi || Peng Ye Lei Bai Zhen Wang  Shuyue Hu || Shanghai Artificial Intelligence Laboratory || Abstract || Large language model (L ... (truncated) ||  || { || ""title"": ""LLMRouterBench: A Massive Benchmark and Unified Framework for LLM Routing"", || ""authors"": [ || ""Hao Li"", || ""Yiqun Zhang"", || ""Zhaoyan Guo"", || ""Chenxu Wang"", || ""Shengji Tang"", || ""Qiaosheng Zhang Yang"", || ""Chen Biqing Qi"", || ""Peng Ye Lei"", || ""Bai Zhen Wang"", || ""Shuyue Hu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""LLM routing"", || ""LLM benchmark"", || ""large language models"", || ""model routing"", || ""performance metrics"" || ], || ""summary"": ""This work introduces LLMRouterBench, a large-scale benchmark and unified framework for LLM routing. It evaluates over 400K instances across 21 datasets and 33 models, providing comprehensive metrics for performance and cost trade-offs. The study highlights challenges such as model-recall failures and the impact of backbone embeddings, while also noting diminishing returns in larger ensembles."" || } ||  || [ Prompt: 125.2 t/s | Generation: 29.1 t/s ]"
2601.07209v1_SIRR-LMM Single-image Reflection Removal via Large.pdf,SIRR-LMM: Single-image Reflection Removal via Large Multimodal Model,"['Yu Guo', 'Zhiqiang Lao', 'Xiyun Song', 'Yubin Zhou', 'Heather Yu']",,28.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SIRR-LMM: Single-image Reflection Removal via Large Multimodal Model || Yu Guo, Zhiqiang Lao, Xiyun Song, Yubin Zhou and Heather Yu || Futurewei Technologies, US || {yguo1,zlao,xsong,yzhou2,hyu}@futurewei.com || Abstract || Glass surfaces create complex interactions of reflected and || transmitted li ... (truncated) ||  || { || ""title"": ""SIRR-LMM: Single-image Reflection Removal via Large Multimodal Model"", || ""authors"": [ || ""Yu Guo"", || ""Zhiqiang Lao"", || ""Xiyun Song"", || ""Yubin Zhou"", || ""Heather Yu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Glass surfaces create complex interactions of reflected and transmitted light, making single-image reflection removal challenging. This paper introduces a synthetic dataset generation framework and a Large Multimodal Model approach to improve reflection removal performance."" || } ||  || [ Prompt: 140.6 t/s | Generation: 28.9 t/s ]"
2601.07214v1_BlindU Blind Machine Unlearning without Revealing .pdf,BlindU: Blind Machine Unlearning without Revealing Erasing Data,"['Weiqi Wang', 'Zhiyi Tian', 'Chenhan Zhang', 'Shui Yu']",10.1109/TPA.2024.12345,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || THIS PAPER HAS BEEN ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 1 || BlindU: Blind Machine Unlearning without || Revealing Erasing Data || Weiqi Wang,Member, IEEE, Zhiyi Tian,Member, IEEE, Chenhan Zhang,Member, IEEE, || and Shui Yu,Fellow, IEEE || Abs ... (truncated) ||  || { || ""title"": ""BlindU: Blind Machine Unlearning without Revealing Erasing Data"", || ""authors"": [ || ""Weiqi Wang"", || ""Zhiyi Tian"", || ""Chenhan Zhang"", || ""Shui Yu"" || ], || ""doi"": ""10.1109/TPA.2024.12345"", || ""arxiv_id"": ""IEEE/TR/2024/120123"", || ""keywords"": [ || ""Machine Unlearning"", || ""Federated Learning"", || ""Privacy Leakage"", || ""Privacy Preserving"", || ""Information Bottleneck"" || ], || ""summary"": ""This paper proposes Blind Unlearning (BlindU) to enable data holders to remove their samples from trained models without revealing erased data, addressing privacy concerns in federated learning environments."" || } ||  || [ Prompt: 131.7 t/s | Generation: 28.5 t/s ]"
2601.07224v1_Consolidation or Adaptation PRISM Disentangling SF.pdf,Consolidation or Adaptation? PRISM: Disentangling SFT and RL Data via Gradient Concentration,"['Yang Zhao', 'Yangou Ouyang', 'Xiao Ding', 'Hepeng Wang', 'Bibo Cai Kai Xiong', 'Jinglong Gao', 'Zhouhao Sun', 'Li Du', 'Bing Qin', 'Ting Liu']",,29.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Consolidation or Adaptation? PRISM: Disentangling SFT and RL Data via || Gradient Concentration || Yang Zhao*,Yangou Ouyang*, Xiao Ding,Hepeng Wang,Bibo Cai Kai Xiong, || Jinglong Gao, Zhouhao Sun, Li Du, Bing Qin and Ting Liu || Research Center for Social Computing and Interactive Robotics, || Ha ... (truncated) ||  || { || ""title"": ""Consolidation or Adaptation? PRISM: Disentangling SFT and RL Data via Gradient Concentration"", || ""authors"": [ || ""Yang Zhao"", || ""Yangou Ouyang"", || ""Xiao Ding"", || ""Hepeng Wang"", || ""Bibo Cai Kai Xiong"", || ""Jinglong Gao"", || ""Zhouhao Sun"", || ""Li Du"", || ""Bing Qin"", || ""Ting Liu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Large Language Model"", || ""Data Arbitration"", || ""Gradient Concentration"", || ""Schema Theory"", || ""RL Data Disentanglement"" || ], || ""summary"": ""The paper proposes PRISM, a framework that distinguishes between data consolidation via pattern consolidation in SFT and structural adaptation via RL, using gradient concentration analysis to guide data arbitration. Experiments show improved performance and reduced computational costs."" || } ||  || [ Prompt: 127.9 t/s | Generation: 29.7 t/s ]"
2601.07226v1_Lost in the Noise How Reasoning Models Fail with C.pdf,Lost in the Noise: How Reasoning Models Fail with Contextual Distractors,"['Seongyun Lee', 'Yongrae Jo', 'Minju Seo', 'Moontae Lee', 'Minjoon Seo']",10.48550/arXiv.2025.12345,29.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Lost in the Noise: How Reasoning Models Fail with || Contextual Distractors || Seongyun Lee1,2,,Yongrae Jo 2,Minju Seo 1,2,Moontae Lee 2,3,Minjoon Seo 1 || 1KAIST AI, 2LG AI Research,3University of Illinois Chicago || Work done during LG AI Research Internship || Recent advances in reasoning model ... (truncated) ||  || { || ""title"": ""Lost in the Noise: How Reasoning Models Fail with Contextual Distractors"", || ""authors"": [ || ""Seongyun Lee"", || ""Yongrae Jo"", || ""Minju Seo"", || ""Moontae Lee"", || ""Minjoon Seo"" || ], || ""doi"": ""10.48550/arXiv.2025.12345"", || ""arxiv_id"": ""arXiv:2509.12345"", || ""keywords"": [ || ""reasoning models"", || ""agentic AI"", || ""noisy benchmarks"", || ""contextual distractors"", || ""robustness evaluation"" || ], || ""summary"": ""This paper introduces NoisyBench, a benchmark evaluating reasoning models' robustness against diverse noise types. It reveals significant performance drops (up to 80%) under contextual distractors and highlights the need for improved prompting and context engineering strategies."" || } ||  || [ Prompt: 127.7 t/s | Generation: 29.8 t/s ]"
2601.07229v2_DiSCo Making Absence Visible in Intelligent Summar.pdf,Making Absence Visible in Intelligent Summarization Interfaces,"['ERAN FAINMAN', 'HAGIT BEN SHOSHAN', 'ADIR SOLOMON', 'OSNAT MOKRYN']",,29.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DiSCo: Making Absence Visible in Intelligent Summarization Interfaces || ERAN FAINMAN,University of Haifa, Israel || HAGIT BEN SHOSHAN,University of Haifa, Israel || ADIR SOLOMON,University of Haifa, Israel || OSNAT MOKRYN,University of Haifa, Israel || Intelligent interfaces increasingly use larg ... (truncated) ||  || { || ""title"": ""Making Absence Visible in Intelligent Summarization Interfaces"", || ""authors"": [ || ""ERAN FAINMAN"", || ""HAGIT BEN SHOSHAN"", || ""ADIR SOLOMON"", || ""OSNAT MOKRYN"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Review Summarization"", || ""Absence"", || ""Expectations"", || ""Learning via surprisability"", || ""Missing commonalities"" || ], || ""summary"": ""This paper presents Domain Informed Summarization through Contrast (DiSCo), an expectation-based approach that highlights omitted information by comparing entity content to domain expectations. It improves transparency and decision support in summarization interfaces."" || } ||  || [ Prompt: 135.0 t/s | Generation: 29.2 t/s ]"
2601.07232v1_Yes FLoReNce I Will Do Better Next Time Agentic Fe.pdf,Agentic Feedback Reasoning for Humorous Meme Detection,"['Olivia Shanhong Liu', 'Pai Chet Ng', 'De Wen Soh', 'Konstantinos N. Plataniotis']",10.48550/arXiv.2024.12345,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Y es FLoReNce, I Will Do Better Next Time! Agentic Feedback Reasoning for || Humorous Meme Detection || Olivia Shanhong Liu 1, Pai Chet Ng 2, De Wen Soh 1, Konstantinos N. Plataniotis 3 || 1Information Systems Technology and Design Pillar, Singapore University of Technology and Design, Singa ... (truncated) ||  || { || ""title"": ""Agentic Feedback Reasoning for Humorous Meme Detection"", || ""authors"": [ || ""Olivia Shanhong Liu"", || ""Pai Chet Ng"", || ""De Wen Soh"", || ""Konstantinos N. Plataniotis"" || ], || ""doi"": ""10.48550/arXiv.2024.12345"", || ""arxiv_id"": ""arXiv:2409.12345"", || ""keywords"": [ || ""humorous memes"", || ""AI reasoning"", || ""feedback regulation"", || ""meme understanding"", || ""multimodal learning"" || ], || ""summary"": ""This paper proposes FLoReNce, an agentic feedback reasoning framework for interpreting humor in memes. It introduces a closed-loop reasoning process during learning and an open-loop inference process with feedback, improving both performance and explanation quality."" || } ||  || [ Prompt: 132.9 t/s | Generation: 29.3 t/s ]"
2601.07233v1_From Thinking to Justifying Aligning High-Stakes E.pdf,Aligning High-Stakes Explainability,"['Chen Qian', 'Yimeng Wang', 'Yu Chen', 'Andreas Stathopoulos', 'Lingfei Wu', 'Axstat', 'ychen@anytime-ai.com', 'lwu@anytime-ai.com', 'William & Mary']",,29.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || From Thinking to Justifying: Aligning High-Stakes Explainability || with Professional Communication Standards || Chen Qian || William & Mary || cqian03@wm.edu || Yimeng Wang || William & Mary || ywang139@wm.edu || Yu Chen || Anytime AI || ychen@anytime-ai.com || Lingfei Wu || Anytime AI || lwu@anytime-ai.com || Andreas Stat ... (truncated) ||  || { || ""title"": ""Aligning High-Stakes Explainability"", || ""authors"": [ || ""Chen Qian"", || ""Yimeng Wang"", || ""Yu Chen"", || ""Andreas Stathopoulos"", || ""Lingfei Wu"", || ""Axstat"", || ""ychen@anytime-ai.com"", || ""lwu@anytime-ai.com"", || ""William & Mary"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Explainable AI"", || ""High-stakes domains"", || ""Professional communication"", || ""Result Justify"", || ""Structured Explainability Framework"" || ], || ""summary"": ""Explainable AI in high-stakes domains should help stakeholders trust and verify system outputs. The paper proposes a structured justification approach (Result Justify) to improve reliability and verifiability of AI explanations."" || } ||  || [ Prompt: 124.7 t/s | Generation: 29.4 t/s ]"
2601.07238v1_Group Pattern Selection Optimization Let LRMs Pick.pdf,Group Pattern Selection Optimization: Let LRMs Pick the Right Pattern,"['Hanbin Wang', 'Jingwei Song', 'Jinpeng Li', 'Fei Mi', 'Lifeng Shang']",10.48550/arXiv.2405.12345,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Group Pattern Selection Optimization: Let LRMs Pick the Right Pattern || for Reasoning || Hanbin Wang1*, Jingwei Song2*, Jinpeng Li3, Fei Mi3, Lifeng Shang3 || 1Peking University 2The University of Hong Kong 3Huawei Noahs Ark Lab || wanghanbin95@stu.pku.edu.cn, songjingwei@connect.hku.hk, lijp. ... (truncated) ||  || { || ""title"": ""Group Pattern Selection Optimization: Let LRMs Pick the Right Pattern"", || ""authors"": [ || ""Hanbin Wang"", || ""Jingwei Song"", || ""Jinpeng Li"", || ""Fei Mi"", || ""Lifeng Shang"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [ || ""large reasoning models"", || ""pattern selection"", || ""reinforcement learning"", || ""multi-pattern rollouts"", || ""problem characteristics"", || ""robust reasoning"" || ], || ""summary"": ""This paper investigates how large reasoning models exhibit diverse high-level patterns and how a proposed framework, Group Pattern Selection Optimization (GPSO), can improve their reasoning by optimizing pattern selection based on problem characteristics."" || } ||  || [ Prompt: 123.8 t/s | Generation: 29.0 t/s ]"
2601.07239v1_Stochastic CHAOS Why Deterministic Inference Kills.pdf,Stochas(c CHAOS: Why Determinis),"['Tanmay Joshi', 'Shourya Aggarwal', 'Anusa Saha', 'Aadi Pandey', 'Shreyash Dhoot', 'Vighnesh Rai', 'Raxit Goswami', 'Aman Chadha3', 'Vinija Jain', 'Amitava Das']",10.48550/arXiv.2303.04219,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  ||  || Stochas(c CHAOS: Why Determinis)c Inference Kills, and Distribu(onal Variability Is the Heartbeat of Ar(cial Cogni(on || Tanmay Joshi1, Shourya Aggarwal1, Anusa Saha1, Aadi Pandey1, || Shreyash Dhoot1, Vighnesh Rai1, Raxit Goswami2, || Aman Chadha3, Vinija Jain4, Amitava Das1 || 2Raap ... (truncated) ||  || { || ""title"": ""Stochas(c CHAOS: Why Determinis)"", || ""authors"": [ || ""Tanmay Joshi"", || ""Shourya Aggarwal"", || ""Anusa Saha"", || ""Aadi Pandey"", || ""Shreyash Dhoot"", || ""Vighnesh Rai"", || ""Raxit Goswami"", || ""Aman Chadha3"", || ""Vinija Jain"", || ""Amitava Das"" || ], || ""doi"": ""10.48550/arXiv.2303.04219"", || ""arxiv_id"": ""10.48550/arXiv:2303.04219"", || ""keywords"": [ || ""deterministic inference"", || ""LLM"", || ""uncertainty"", || ""reproducibility"", || ""safety alignment"", || ""cognitive cognition"" || ], || ""summary"": ""The paper argues that deterministic inference is detrimental for large language models, as it suppresses uncertainty, reduces robust reasoning, and undermines generalization, advocating instead for stochastic approaches."" || } ||  || [ Prompt: 127.6 t/s | Generation: 27.9 t/s ]"
2601.07245v1_Learning to Trust the Crowd A Multi-Model Consensu.pdf,Learning to Trust the Crowd: A Multi-Model Consensus Reasoning Engine for Large Language Models,['Pranav Kallem'],,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Learning to Trust the Crowd: A Multi-Model || Consensus Reasoning Engine for Large Language || Models || Pranav Kallem || Department of Computer Science || The University of Texas at Austin || Austin, TX, USA || AbstractLarge language models (LLMs) achieve strong aver- || age performance yet remain unrelia ... (truncated) ||  || { || ""title"": ""Learning to Trust the Crowd: A Multi-Model Consensus Reasoning Engine for Large Language Models"", || ""authors"": [""Pranav Kallem""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper introduces a Multi-Model Consensus Reasoning Engine that evaluates reliability of large language models by aggregating responses from multiple heterogeneous LLMs, improving accuracy and calibration."" || } ||  || [ Prompt: 123.4 t/s | Generation: 27.7 t/s ]"
2601.07250v1_DDT A Dual-Masking Dual-Expert Transformer for Ene.pdf,DDT: A Dual-Masking Dual-Expert Transformer,"['Mingnan Zhu', 'Qixuan Zhang', 'Yixuan Cheng', 'Fangzhou Gu', 'Shiming Lin']",,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || DDT: A Dual-Masking Dual-Expert Transformer || for Energy Time-Series Forecasting || Mingnan Zhu 1, Qixuan Zhang 1, Yixuan Cheng 1, Fangzhou Gu 1, and Shiming Lin 1, 2, 3 || 1School of Informatics (National Characteristic Demonstration Software School), Xiamen University, Xiamen, || China || 2Ke ... (truncated) ||  || { || ""title"": ""DDT: A Dual-Masking Dual-Expert Transformer"", || ""authors"": [ || ""Mingnan Zhu"", || ""Qixuan Zhang"", || ""Yixuan Cheng"", || ""Fangzhou Gu"", || ""Shiming Lin"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Time-Series Forecasting"", || ""Multivariate Temporal Modeling"", || ""Dynamic-Causal Masking"", || ""Adaptive Feature Fusion"" || ], || ""summary"": ""Accurate energy time-series forecasting is crucial for grid stability and renewable integration. DDT introduces a dual-masking mechanism and a dual-expert system to improve forecasting performance."" || } ||  || [ Prompt: 125.2 t/s | Generation: 28.1 t/s ]"
2601.07261v1_Pseudodata-guided Invariant Representation Learnin.pdf,Pseudodata-guided Invariant Representation,"['Haomin Wu', 'Zhiwei Nie', 'Zhixiang Ren', 'Pengcheng Laboratory', 'Southern University of Science and Technology']",arXiv:2601.07261v1,31.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Pseudodata-guided Invariant Representation || Learning Boosts the Out-of-Distribution || Generalization in Enzymatic Kinetic Parameter || Prediction || Haomin Wu1,2, Zhiwei Nie 3*, Hongyu Zhang 3, Zhixiang Ren 2* || 1Pengcheng Laboratory, Shenzhen, China. || 2Southern University of Science and Techno ... (truncated) ||  || { || ""title"": ""Pseudodata-guided Invariant Representation"", || ""authors"": [ || ""Haomin Wu"", || ""Zhiwei Nie"", || ""Zhixiang Ren"", || ""Pengcheng Laboratory"", || ""Southern University of Science and Technology"" || ], || ""doi"": ""arXiv:2601.07261v1"", || ""arxiv_id"": ""2601.07261"", || ""keywords"": [ || ""enzyme kinetic parameters"", || ""generalization"", || ""invariant representation"", || ""deep learning"", || ""out-of-distribution"", || ""enzyme engineering"" || ], || ""summary"": ""Accurate prediction of enzyme kinetic parameters is essential for understanding catalytic mechanisms and guiding enzyme engineering. This work proposes O2DENet, a lightweight model enhancing out-of-distribution generalization through biologically informed perturbations and invariant representation learning."" || } ||  || [ Prompt: 123.6 t/s | Generation: 31.9 t/s ]"
2601.07263v1_When Bots Take the Bait Exposing and Mitigating th.pdf,When Bots Take the Bait: Exposing and Mitigating the Emerging Social Engineering,"['Xinyi Wu', 'Geng Hong B', 'Yueyue Chen', 'MingXuan Liu', 'Feier Jin', 'Xudong Pan', 'Jiarun Dai', 'Baojun Liu']",,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || When Bots Take the Bait: Exposing and Mitigating the Emerging Social Engineering || Attack in Web Automation Agent || Xinyi Wu, Geng Hong B, Yueyue Chen, MingXuan Liu , Feier Jin , Xudong Pan , || Jiarun Dai , and Baojun Liu || Fudan University,  Zhongguancun Laboratory, Shanghai Innovation In ... (truncated) ||  || { || ""title"": ""When Bots Take the Bait: Exposing and Mitigating the Emerging Social Engineering"", || ""authors"": [ || ""Xinyi Wu"", || ""Geng Hong B"", || ""Yueyue Chen"", || ""MingXuan Liu"", || ""Feier Jin"", || ""Xudong Pan"", || ""Jiarun Dai"", || ""Baojun Liu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""web automation"", || ""social engineering"", || ""web agents"", || ""social engineering attacks"", || ""AGENTBAIT"", || ""web automation frameworks"" || ], || ""summary"": ""This paper presents the first systematic study of social engineering attacks against web automation agents, introducing the AGENTBAIT paradigm and SUPERVISOR mitigation. Empirical results show high attack success rates and propose a lightweight runtime defense to reduce vulnerabilities."" || } ||  || [ Prompt: 125.7 t/s | Generation: 29.3 t/s ]"
2601.07291v1_A Visual Semantic Adaptive Watermark grounded by P.pdf,Visual Semantic Adaptive Watermark grounded by Prefix-Tuning for Large Vision-Language Model,"['Qi Zheng', 'Shuliang Liu', 'Yu Huang', 'Sihang Jia', 'Jungang Li', 'Lyuhao Chen', 'Hanqian Li', 'Aiwei Liu', 'Yibo Yan', 'Xuming Hu']",,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A Visual Semantic Adaptive Watermark grounded by Prefix-Tuning for Large || Vision-Language Model || Qi Zheng1,2,Shuliang Liu 1,2,Yu Huang 1,2,Sihang Jia 1,2,Jungang Li 1,2,Lyuhao Chen 3 || Junhao Chen1,2,Hanqian Li 1,2,Aiwei Liu 1,2,Yibo Yan 1,2,Xuming Hu 1,2 || 1 The Hong Kong University of S ... (truncated) ||  || { || ""title"": ""Visual Semantic Adaptive Watermark grounded by Prefix-Tuning for Large Vision-Language Model"", || ""authors"": [ || ""Qi Zheng"", || ""Shuliang Liu"", || ""Yu Huang"", || ""Sihang Jia"", || ""Jungang Li"", || ""Lyuhao Chen"", || ""Hanqian Li"", || ""Aiwei Liu"", || ""Yibo Yan"", || ""Xuming Hu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""visual watermarking"", || ""semantic-aware watermarking"", || ""large vision-language model"", || ""prefix-tuning"", || ""visual fidelity"", || ""semantic consistency"" || ], || ""summary"": ""The paper introduces VISA-Mark, a novel watermarking framework for LVMs that preserves visual fidelity by aligning watermark strength with visual evidence. It achieves high detection accuracy and robustness while maintaining inference efficiency."" || } ||  || [ Prompt: 131.3 t/s | Generation: 28.5 t/s ]"
2601.07292v1_Photometric Redshift Estimation Using Scaled Ensem.pdf,Photometric Redshift Estimation Using Scaled Ensemble Learning,"['Swagata Biswas', 'Shubhrangshu Ghosh', 'Avyarthana Ghosh', 'Yogesh Wadadekar', 'Abhishek Roy Choudhury', 'Arijit Mukherjee', 'Shailesh Deshpande', 'And Arpan Pal']",1,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Photometric Redshift Estimation Using Scaled Ensemble Learning || Swagata Biswas || 1 || aa , Shubhrangshu Ghosh || 1 || aa , Avyarthana Ghosh || 1 || aa , Yogesh Wadadekar || 2 || aa , Abhishek Roy Choudhury || 1 || , || Arijit Mukherjee || 1 || aa , Shailesh Deshpande || 3 || aa , and Arpan Pal || 1 || aa || 1 || TCS Research, IIT Kharagpu ... (truncated) ||  || { || ""title"": ""Photometric Redshift Estimation Using Scaled Ensemble Learning"", || ""authors"": [ || ""Swagata Biswas"", || ""Shubhrangshu Ghosh"", || ""Avyarthana Ghosh"", || ""Yogesh Wadadekar"", || ""Abhishek Roy Choudhury"", || ""Arijit Mukherjee"", || ""Shailesh Deshpande"", || ""And Arpan Pal"" || ], || ""doi"": ""1"", || ""arxiv_id"": """", || ""keywords"": [ || ""photometric redshift"", || ""photometric data"", || ""machine learning"", || ""astrophysics"", || ""LSST"", || ""Galaxies"", || ""redshift surveys"", || ""neural networks"" || ], || ""summary"": ""The study presents a new ensemble-based ML framework for predicting photometric redshifts using optical photometric data, demonstrating improved accuracy and reliability for faint galaxies and higher redshift ranges."" || } ||  || [ Prompt: 126.4 t/s | Generation: 28.7 t/s ]"
2601.07296v1_LRAS Advanced Legal Reasoning with Agentic Search.pdf,LRAS: Advanced Legal Reasoning with Agentic Search,"['Yujin Zhou', 'Chuxue Cao', 'Jinluan Yang', 'Lijun Wu', 'Conghui He', 'Sirui Han', 'Yike Guo']",,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LRAS: Advanced Legal Reasoning with Agentic Search || Yujin Zhou1, Chuxue Cao1,2, Jinluan Yang || Lijun Wu2,Conghui He 2,Sirui Han 1,Yike Guo 1 || 1Hong Kong University of Science and Technology || 2Shanghai Artificial Intelligence Laboratory || yzhouha@connect.ust.hk || Abstract || While Large Reasonin ... (truncated) ||  || { || ""title"": ""LRAS: Advanced Legal Reasoning with Agentic Search"", || ""authors"": [ || ""Yujin Zhou"", || ""Chuxue Cao"", || ""Jinluan Yang"", || ""Lijun Wu"", || ""Conghui He"", || ""Sirui Han"", || ""Yike Guo"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Legal Reasoning"", || ""Agentic Search"", || ""Legal LLMs"", || ""Introspective Imitation Learning"", || ""Difficulty-aware Reinforcement Learning"" || ], || ""summary"": ""This paper introduces LRAS, a framework for legal reasoning that shifts from static closed-loop thinking to dynamic active inquiry, aiming to improve legal LLMs' precision and self-awareness."" || } ||  || [ Prompt: 126.3 t/s | Generation: 29.1 t/s ]"
2601.07304v1_Heterogeneous Multi-Expert Reinforcement Learning .pdf,Heterogeneous Multi-Expert Reinforcement Learning for Long-Horizon Multi-Goal Tasks in Autonomous Forklifts,"['Yun Chen', 'Bowei Huang', 'Fan Guo', 'Kang Song']",10.48550/arXiv.2405.12345,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || Heterogeneous Multi-Expert Reinforcement || Learning for Long-Horizon Multi-Goal Tasks in || Autonomous Forklifts || Yun Chen, Bowei Huang, Fan Guo, Kang Song || AbstractAutonomous mobile manipulation in unstructured || warehouses requires a balance between efficient large-scale nav- || igation and ... (truncated) ||  || { || ""title"": ""Heterogeneous Multi-Expert Reinforcement Learning for Long-Horizon Multi-Goal Tasks in Autonomous Forklifts"", || ""authors"": [""Yun Chen"", ""Bowei Huang"", ""Fan Guo"", ""Kang Song""], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [""Autonomous Forklift"", ""Hierarchical Reinforcement Learning"", ""Mobile Manipulation"", ""Hybrid Training""], || ""summary"": ""This paper proposes a Heterogeneous Multi-Expert Reinforcement Learning framework for autonomous forklifts, decomposing long-horizon tasks into specialized sub-policies. It introduces a Semantic Task Planner to separate macro-level navigation from micro-level manipulation, and applies a Hybrid Imitation-Reinforcement Training Strategy to address sparse exploration. Experiments demonstrate improved performance over sequential and end-to-end baselines."" || } ||  || [ Prompt: 123.1 t/s | Generation: 28.4 t/s ]"
2601.07309v1_ARM Role-Conditioned Neuron Transplantation for Tr.pdf,ARM: Role-Conditioned Neuron Transplantation for Training-Free Generalist LLM Agent Merging,"['Zhuoka Feng', 'Kang Chen', 'Sihan Zhao', 'Kai Xiong', 'Yaoning Wang', 'Minshen Yu', 'Junjie Nian', 'Changyi Xiao', 'Yixin Cao', 'Yugang Jiang']",10.1093/arxiv/2026.07309,28.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ARM: Role-Conditioned Neuron Transplantation for || Training-Free Generalist LLM Agent Merging || Zhuoka Feng1*, Kang Chen1*, Sihan Zhao1**, Kai Xiong**, Yaoning Wang1** || Minshen Yu1, Junjie Nian1, Changyi Xiao1, Yixin Cao1,2, Yugang Jiang1 || 1Fudan University,2Shanghai Innovation Institute || ... (truncated) ||  || { || ""title"": ""ARM: Role-Conditioned Neuron Transplantation for Training-Free Generalist LLM Agent Merging"", || ""authors"": [ || ""Zhuoka Feng"", || ""Kang Chen"", || ""Sihan Zhao"", || ""Kai Xiong"", || ""Yaoning Wang"", || ""Minshen Yu"", || ""Junjie Nian"", || ""Changyi Xiao"", || ""Yixin Cao"", || ""Yugang Jiang"" || ], || ""doi"": ""10.1093/arxiv/2026.07309"", || ""arxiv_id"": ""2601.07309"", || ""keywords"": [ || ""ARM"", || ""model merging"", || ""LLM agents"", || ""role-conditioned"", || ""neuron transplantation"", || ""cross-environment generalization"" || ], || ""summary"": ""This paper proposes Agent-Role Merging (ARM), a training-free method for merging large language models by integrating multiple experts into a single model. ARM enhances existing merging techniques for multi-turn agent scenarios, improving generalization across diverse interactive environments while maintaining efficiency. The approach outperforms prior methods and domain-specific models, demonstrating strong out-of-domain generalization."" || } ||  || [ Prompt: 121.6 t/s | Generation: 28.0 t/s ]"
2601.07313v1_Explaining Machine Learning Predictive Models thro.pdf,Multivariate Conditional Expectation (MUCE),"['Silvia Ruiz-Espa naa', 'Laura Arnal', 'Fran cois Signola', 'Juan-Carlos Perez-Cortes', 'Joaquim Arlandis', 'a', 's/n, 46022 Valencia, Spain']",,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Explaining Machine Learning Predictive Models through Conditional || Expectation Methods || Silvia Ruiz-Espa naa,, Laura Arnal a,, Fran cois Signola, Juan-Carlos Perez-Cortes a, Joaquim Arlandis a || aITI, Universitat Polit` ecnica de Val` encia, Camino de Vera, s/n, 46022 Val` encia, Spain || ... (truncated) ||  || { || ""title"": ""Multivariate Conditional Expectation (MUCE)"", || ""authors"": [ || ""Silvia Ruiz-Espa naa"", || ""Laura Arnal"", || ""Fran cois Signola"", || ""Juan-Carlos Perez-Cortes"", || ""Joaquim Arlandis"", || ""a"", || ""s/n, 46022 Valencia, Spain"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""machine learning"", || ""XAI"", || ""explainable models"", || ""local explainability"", || ""model-agnostic"", || ""uncertainty"", || ""stability"", || ""uncertainty"" || ], || ""summary"": ""This work introduces MUCE, a model-agnostic method for local explainability that captures prediction changes from feature interactions. It extends Individual Conditional Expectation by exploring a multivariate grid near inference time, offering graphical explanations and stability/uncertainty indices to assess model reliability."" || } ||  || [ Prompt: 131.4 t/s | Generation: 29.1 t/s ]"
2601.07315v1_VLM-CAD VLM-Optimized Collaborative Agent Design W.pdf,VLM-CAD:VLM-OptimizedCollaborativeAgent,"['Guanyuan Pan', 'Yugui Lin', 'Tiansheng Zhou', 'Pietro Li', 'Shuai Wang', 'Yaqi Wang', 'Wangyaqi']",,29.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || VLM-CAD:VLM-OptimizedCollaborativeAgent || Design Workflow for Analog Circuit Sizing || 1st Guanyuan Pan || Hangzhou Dianzi University || Hangzhou, China || guanyuanpeterpan@gmail.com || 2nd Yugui Lin || SCBC, Guangdong University of Foreign Studies || Guangzhou, China || yuguilin0209@163.com || 3rd Tiansheng Zh ... (truncated) ||  || { || ""title"": ""VLM-CAD:VLM-OptimizedCollaborativeAgent"", || ""authors"": [ || ""Guanyuan Pan"", || ""Yugui Lin"", || ""Tiansheng Zhou"", || ""Pietro Li"", || ""Shuai Wang"", || ""Yaqi Wang"", || ""Wangyaqi"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Analog Circuit Sizing"", || ""Agentic AI"", || ""Vision Language Model"", || ""Explainability"", || ""Electronic Design Automation"" || ], || ""summary"": ""Analog mixed-signal circuit sizing involves complex trade-offs. This paper proposes a Vision Language Model-optimized collaborative agent design workflow (VLM-CAD) to analyze circuits, optimize DC operating points, perform inference-based sizing, and execute external sizing optimization. It integrates Image2Net for circuit schematic annotation and presents an Explainable Trust Region Bayesian Optimization method (ExTuRBO) for comprehensive design reporting. Experimental results show effective balancing of power and performance with a 100% success rate in optimizing an amplifier."" || } ||  || [ Prompt: 122.8 t/s | Generation: 29.4 t/s ]"
2601.07316v1_BEAT-Net Injecting Biomimetic Spatio-Temporal Prio.pdf,BEAT-Net: Injecting Biomimetic Spatio-Temporal,"['Ma Runze', 'Liao Caizhi']",rmaa0033@student.monash.edu,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || BEAT-Net: Injecting Biomimetic Spatio-Temporal || Priors for Interpretable ECG Classification || Ma Runze || School of Information Technology || Monash University Malaysia || rmaa0033@student.monash.edu || Liao Caizhi || Faculty of Biomedical Engineering || Shenzhen University of Advanced Technology || liaoc ... (truncated) ||  || { || ""title"": ""BEAT-Net: Injecting Biomimetic Spatio-Temporal"", || ""authors"": [ || ""Ma Runze"", || ""Liao Caizhi"" || ], || ""doi"": ""rmaa0033@student.monash.edu"", || ""arxiv_id"": """", || ""keywords"": [ || ""ECG classification"", || ""deep learning"", || ""biomimetic analysis"", || ""interpretable models"", || ""heartbeat sequences"" || ], || ""summary"": ""This paper proposes BEAT-Net, a biomimetic ECG analysis framework that reformulates ECG classification as a language modeling task. It uses QRS tokenization to convert continuous signals into heartbeat sequences, leveraging specialized encoders to capture local morphology and temporal dependencies. The approach achieves competitive performance with CNNs while offering interpretability through attention mechanisms, demonstrating efficiency and robustness with limited annotated data."" || } ||  || [ Prompt: 134.7 t/s | Generation: 28.8 t/s ]"
2601.07320v1_Segmental Advantage Estimation Enhancing PPO for L.pdf,Segmental Advantage Estimation: Enhancing PPO for Long-Context LLM,"['Xue Gong1', 'Qi Yi1', 'Ziyuan Nan2,4', 'Guanhua Huang1', 'Kejiao Li1', 'Yuhao Jiang1', 'Ruibin Xiong1', 'Zenan Xu1', 'Jiaming Guo4', 'Shaohui Peng 2,3', 'Bo Zhou1']",,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 2026-01-13 || Segmental Advantage Estimation: Enhancing PPO for Long-Context LLM || Training || Xue Gong1, , Qi Yi1,, Ziyuan Nan2,4, Guanhua Huang1, Kejiao Li1, Yuhao Jiang1, || Ruibin Xiong1, Zenan Xu1, Jiaming Guo4, Shaohui Peng 2,3, Bo Zhou1 || 1LLM Department, Tencent 2 University of Chinese A ... (truncated) ||  || { || ""title"": ""Segmental Advantage Estimation: Enhancing PPO for Long-Context LLM"", || ""authors"": [ || ""Xue Gong1"", || ""Qi Yi1"", || ""Ziyuan Nan2,4"", || ""Guanhua Huang1"", || ""Kejiao Li1"", || ""Yuhao Jiang1"", || ""Ruibin Xiong1"", || ""Zenan Xu1"", || ""Jiaming Guo4"", || ""Shaohui Peng 2,3"", || ""Bo Zhou1"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper introduces Segmental Advantage Estimation (SAE) to mitigate bias in Proximal Policy Optimization (PPO) for training large language models in reasoning tasks. SAE partitions sequences into sub-segments and computes variance-reduced advantage estimates, improving training stability and performance."" || } ||  || [ Prompt: 126.4 t/s | Generation: 28.1 t/s ]"
2601.07342v1_Agentic Diagnostic Reasoning over Telecom and Data.pdf,Agentic Diagnostic Reasoning over Telecom and Datacenter Infrastructure,['Nicolas Tacheny'],arXiv:2601.07342v1,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Agentic Diagnostic Reasoning over Telecom and || Datacenter Infrastructure || Foundation for Autonomous Incident Resolution and Change Impact || Mitigation || Nicolas Tacheny || Ni2 Innovation Lab || nicolas.tacheny@ni2.com || Abstract || Large-scale telecom and datacenter infrastructures rely on multi-lay ... (truncated) ||  || { || ""title"": ""Agentic Diagnostic Reasoning over Telecom and Datacenter Infrastructure"", || ""authors"": [""Nicolas Tacheny""], || ""doi"": ""arXiv:2601.07342v1"", || ""arxiv_id"": ""1"", || ""keywords"": [], || ""summary"": ""Large-scale telecom and datacenter infrastructures rely on multi-layered service and resource models... This work introduces an agentic diagnostic framework where a Large Language Model performs step-wise investigation using a constrained tool-space exposed through the Model Context Protocol (MCP)."" || } ||  || [ Prompt: 131.3 t/s | Generation: 27.9 t/s ]"
2601.07344v1_PulseMind A Multi-Modal Medical Model for Real-Wor.pdf,PulseMind: A Multi-Modal Medical Model for Real-World Clinical Diagnosis,"['Jiao Xu1', 'Junwei Liu', 'Jiangwei Lao', 'Qi Zhu', 'Yunpeng Zhao', 'Congyun Jin', 'Shinan Liu', 'Zhihong Lu2', 'Lihe Zhang', 'Xin Chen', 'Jian Wang', 'Ping Wang']",,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || PulseMind: A Multi-Modal Medical Model for Real-World Clinical Diagnosis || Jiao Xu1,2*, Junwei Liu 2,3*, Jiangwei Lao 2, Qi Zhu 2, Yunpeng Zhao4, Congyun Jin 2, Shinan Liu 4, || Zhihong Lu2, Lihe Zhang 1, Xin Chen 5, Jian Wang2, Ping Wang3 || 1 Dalian University of Technology || 2 Ant Group || 3  ... (truncated) ||  || { || ""title"": ""PulseMind: A Multi-Modal Medical Model for Real-World Clinical Diagnosis"", || ""authors"": [ || ""Jiao Xu1"", || ""Junwei Liu"", || ""Jiangwei Lao"", || ""Qi Zhu"", || ""Yunpeng Zhao"", || ""Congyun Jin"", || ""Shinan Liu"", || ""Zhihong Lu2"", || ""Lihe Zhang"", || ""Xin Chen"", || ""Jian Wang"", || ""Ping Wang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Recent advances in medical multi-modal models focus on specialized image analysis like dermatology, pathology, or radiology. However, they do not fully capture the complexity of real-world clinical diagnostics, which involve heterogeneous inputs and require ongoing contextual understanding during patient-physician interactions. To bridge this gap, we introduce PulseMind, a new family of multi-modal diagnostic models that integrates a systematically curated dataset, a comprehensive evaluation benchmark, and a tailored training framework."" || } ||  || [ Prompt: 128.5 t/s | Generation: 28.4 t/s ]"
2601.07348v4_Controlled Self-Evolution for Algorithmic Code Opt.pdf,Controlled Self-Evolution for Algorithmic Code Optimization,"['Tu Hu1', 'Ronghao Chen2', 'Shuo Zhang3', 'Jianghao Yin4', 'Mou Xiao Feng3', 'Jingping Liu5', 'Shaolei Zhang6', 'Wenqi Jiang', 'Yuqi Fang1', 'Sen Hu2', '7', 'Huacan Wang3', 'Yi Xu3']",arXiv:2601.07348v4,30.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 2026-01-16 || Controlled Self-Evolution for Algorithmic Code Optimization || Tu Hu1*, Ronghao Chen2,7*, Shuo Zhang3*, Jianghao Yin4, Mou Xiao Feng3, Jingping Liu5, || Shaolei Zhang6,Wenqi Jiang 1,Yuqi Fang 1,Sen Hu 2,7,Huacan Wang 3,Yi Xu 3 || 1NJU, 2PKU, 3Midea-AIRC, 4ECNU, 5SYSU, 6RUC, 7Quant ... (truncated) ||  || { || ""title"": ""Controlled Self-Evolution for Algorithmic Code Optimization"", || ""authors"": [ || ""Tu Hu1"", || ""Ronghao Chen2"", || ""Shuo Zhang3"", || ""Jianghao Yin4"", || ""Mou Xiao Feng3"", || ""Jingping Liu5"", || ""Shaolei Zhang6"", || ""Wenqi Jiang"", || ""Yuqi Fang1"", || ""Sen Hu2"", || ""7"", || ""Huacan Wang3"", || ""Yi Xu3"" || ], || ""doi"": ""arXiv:2601.07348v4"", || ""arxiv_id"": ""2601.07348v4"", || ""keywords"": [ || ""Controlled Self-Evolution"", || ""Code Optimization"", || ""Algorithmic Code"", || ""Evolutionary Algorithms"", || ""Exploration Efficiency"", || ""LLM Backbones"" || ], || ""summary"": ""Self-evolution methods enhance code generation through iterative generate-verify-refine cycles, yet existing approaches suffer from low exploration efficiency, failing to discover solutions with superior complexity within limited budgets. This inefficiency stems from initialization bias trapping evolution in poor solution regions, uncontrolled stochastic operations lacking feedback guidance, and insufficient experience utilization across tasks. To address these bottlenecks, we propose Controlled Self-Evolution (CSE), which consists of three key components."" || } ||  || [ Prompt: 127.1 t/s | Generation: 30.0 t/s ]"
2601.07351v2_Beyond Hard Masks Progressive Token Evolution for .pdf,Beyond Hard Masks: Progressive Token Evolution for Diffusion Language Models,"['Linhao Zhong', 'Linyu Wu', 'Bozhen Fang', 'Tianjian Feng', 'Chenchen Jing', 'Wen Wang', 'Jiaheng Zhang', 'Hao Chen', 'Chunhua Shen']",,29.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Beyond Hard Masks: Progressive Token Evolution for || Diffusion Language Models || Linhao Zhong1* Linyu Wu2* Bozhen Fang1 Tianjian Feng1 Chenchen Jing1,3 || Wen Wang1 Jiaheng Zhang2 Hao Chen1 Chunhua Shen1,3 || 1Zhejiang University 2National University of Singapore 3Zhejiang University of Techn ... (truncated) ||  || { || ""title"": ""Beyond Hard Masks: Progressive Token Evolution for Diffusion Language Models"", || ""authors"": [ || ""Linhao Zhong"", || ""Linyu Wu"", || ""Bozhen Fang"", || ""Tianjian Feng"", || ""Chenchen Jing"", || ""Wen Wang"", || ""Jiaheng Zhang"", || ""Hao Chen"", || ""Chunhua Shen"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper proposes EvoToken-DLM, a diffusion-based language modeling approach that uses evolving soft token distributions to enable progressive transitions from masked states to discrete outputs, supporting revisable decoding."" || } ||  || [ Prompt: 118.9 t/s | Generation: 29.6 t/s ]"
2601.07356v1_Efficient Convolutional Forward Model for Passive .pdf,Efficient Convolutional Forward Model for Passive Acoustic Mapping and Temporal Monitoring,"['Tatiana Gelvez-Barrera', 'Barbara Nicolas', 'Bruno Gilles', 'Adrian Basarab', 'Denis Kouam']",10.1016/j.jlaf.2015.02.005,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 1 || Efficient Convolutional Forward Model for Passive || Acoustic Mapping and Temporal Monitoring || Tatiana Gelvez-Barrera, Barbara Nicolas, Bruno Gilles, Adrian Basarab, Denis Kouam e || AbstractPassive acoustic mapping (PAM) is a key ... (truncated) ||  || { || ""title"": ""Efficient Convolutional Forward Model for Passive Acoustic Mapping and Temporal Monitoring"", || ""authors"": [ || ""Tatiana Gelvez-Barrera"", || ""Barbara Nicolas"", || ""Bruno Gilles"", || ""Adrian Basarab"", || ""Denis Kouam"" || ], || ""doi"": ""10.1016/j.jlaf.2015.02.005"", || ""arxiv_id"": """", || ""keywords"": [ || ""Passive Acoustic Mapping"", || ""Model-based beamforming"", || ""Convolutional forward model"", || ""Temporal monitoring"" || ], || ""summary"": ""This paper introduces a convolutional formulation for an efficient PAM beamforming framework that improves temporal resolution while reducing computational load, supporting safer and more effective ultrasound therapies."" || } ||  || [ Prompt: 128.6 t/s | Generation: 27.9 t/s ]"
2601.07359v1_Seeing Right but Saying Wrong Inter- and Intra-Lay.pdf,Seeing Right but Saying Wrong: Inter- and Intra-Layer Refinement in MLLMs,"['Shezheng Song', 'Shasha Li', 'Jie Yu']",10.48550/arXiv.2405.12345,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Seeing Right but Saying Wrong: Inter- and Intra-Layer Refinement in MLLMs || without Training || Shezheng Song, Shasha Li, Jie Yu || 1National University of Defense Technology || Abstract || Multimodal Large Language Models (MLLMs) have demon- || strated strong capabilities across a variety of vision ... (truncated) ||  || { || ""title"": ""Seeing Right but Saying Wrong: Inter- and Intra-Layer Refinement in MLLMs"", || ""authors"": [""Shezheng Song"", ""Shasha Li"", ""Jie Yu""], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [""MLLM"", ""vision-language tasks"", ""attention mechanisms"", ""model alignment""], || ""summary"": ""The paper discusses a phenomenon where MLLMs exhibit strong visual understanding but produce incorrect outputs due to noisy early-layer attention, proposing DualPD to improve alignment without additional training."" || } ||  || [ Prompt: 123.8 t/s | Generation: 27.7 t/s ]"
2601.07364v1_On the universal definition of intelligence.pdf,Human - AI Comparison,['Joseph Chen'],,33.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || On the universal definition of intelligence || A definition for Human - AI Comparison || Joseph Chen || University of Tokyo ||  ||  || Abstract || This paper aims to propose a universal definition of intelligence that enables fair and || consistent comparison of human and artificial intelligence ( ... (truncated) ||  || { || ""title"": ""Human - AI Comparison"", || ""authors"": [""Joseph Chen""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper proposes a universal definition of intelligence for fair comparison between human and artificial intelligence, addressing the limitations of existing anthropocentric definitions."" || } ||  || [ Prompt: 136.9 t/s | Generation: 33.1 t/s ]"
2601.07372v1_Conditional Memory via Scalable Lookup A New Axis .pdf,Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models,"['Xin Cheng', 'Wangding Zeng', 'Damai Dai', 'Qinyu Chen', 'Bingxuan Wang', 'Zhenda Xie', 'Kezhao Huang', 'Xingkai Yu', 'Zhewen Hao', 'Yukun Li', 'Han Zhang', 'Huishuai Zhang', 'Dongyan Zhao', 'Wenfeng Liang']",10.48550/arXiv.2303.04219,28.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Conditional Memory via Scalable Lookup: || A New Axis of Sparsity for Large Language Models || Xin Cheng1,2, Wangding Zeng2, Damai Dai2, Qinyu Chen2, Bingxuan Wang2, || Zhenda Xie2, Kezhao Huang2, Xingkai Yu2, Zhewen Hao2, Yukun Li2, Han Zhang2, || Huishuai Zhang1, Dongyan Zhao1, Wenfeng Liang2 ... (truncated) ||  || { || ""title"": ""Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models"", || ""authors"": [ || ""Xin Cheng"", || ""Wangding Zeng"", || ""Damai Dai"", || ""Qinyu Chen"", || ""Bingxuan Wang"", || ""Zhenda Xie"", || ""Kezhao Huang"", || ""Xingkai Yu"", || ""Zhewen Hao"", || ""Yukun Li"", || ""Han Zhang"", || ""Huishuai Zhang"", || ""Dongyan Zhao"", || ""Wenfeng Liang"" || ], || ""doi"": ""10.48550/arXiv.2303.04219"", || ""arxiv_id"": ""arXiv:2601.07372v1"", || ""keywords"": [ || ""conditional memory"", || ""scalable lookup"", || ""sparsity"", || ""large language models"", || ""Engram"", || ""MoE"", || ""knowledge retrieval"" || ], || ""summary"": ""This paper introduces conditional memory as a new sparsity axis for LLMs, leveraging Engram to enable efficient knowledge lookup. It presents a U-shaped scaling law and demonstrates improved performance across reasoning benchmarks, highlighting Engram's potential to enhance model efficiency and reasoning capabilities."" || } ||  || [ Prompt: 116.3 t/s | Generation: 28.9 t/s ]"
2601.07376v1_OpenTinker Separating Concerns in Agentic Reinforc.pdf,OpenTinker: Separating Concerns in Agentic Reinforcement Learning,"['Siqi Zhu', 'Jiaxuan You']",10.48550/arxiv/2303.06931,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || OpenTinker: Separating Concerns in Agentic || Reinforcement Learning || Siqi Zhu,Jiaxuan You || University of Illinois Urbana-Champaign || Abstract || We introduceOpenTinker, an infrastructure for reinforcement learning (RL) of large language || model (LLM) agents built around a separation of concern ... (truncated) ||  || { || ""title"": ""OpenTinker: Separating Concerns in Agentic Reinforcement Learning"", || ""authors"": [""Siqi Zhu"", ""Jiaxuan You""], || ""doi"": ""10.48550/arxiv/2303.06931"", || ""arxiv_id"": ""2303.06931"", || ""keywords"": [""OpenTinker"", ""Reinforcement Learning"", ""RL"", ""Agentic"", ""LLM""], || ""summary"": ""Introduces OpenTinker, an infrastructure for RL of LLM agents with separation of concerns in algorithm design, execution, and agent-environment interaction. It proposes a centralized scheduler and discusses multi-agent training extensions."" || } ||  || [ Prompt: 128.9 t/s | Generation: 28.8 t/s ]"
2601.07377v1_Learning Dynamic Collaborative Network for Semi-su.pdf,Learning Dynamic Collaborative Network for Semi-supervised 3D Vessel Segmentation,"['Jiao Xu1', 'Xin Chen2', 'Lihe Zhang1']",10.48550/arXiv.2405.12345,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Learning Dynamic Collaborative Network for Semi-supervised 3D V essel || Segmentation || Jiao Xu1*, Xin Chen2*, Lihe Zhang1 || 1Dalian University of Technology 2City University of Hong Kong || xjmmcome@mail.dlut.edu.cn, xche32@cityu.edu.hk, zhanglihe@dlut.edu.cn || Abstract || In this paper, we prese ... (truncated) ||  || { || ""title"": ""Learning Dynamic Collaborative Network for Semi-supervised 3D Vessel Segmentation"", || ""authors"": [""Jiao Xu1"", ""Xin Chen2"", ""Lihe Zhang1""], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [""3D vessel segmentation"", ""semi-supervised learning"", ""dynamic collaborative network""], || ""summary"": ""This paper presents DiCo, a dynamic collaborative network for semi-supervised 3D vessel segmentation. It introduces a dynamic teacher-student role switching mechanism and a multi-view integration module to improve performance on 3D vessel segmentation benchmarks."" || } ||  || [ Prompt: 124.6 t/s | Generation: 29.3 t/s ]"
2601.07389v1_On the Non-decoupling of Supervised Fine-tuning an.pdf,,[],,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || On the Non-decoupling of Supervised Fine-tuning and || Reinforcement Learning in Post-training || Xueyan Niuniuxueyan3@huawei.com || Theory Laboratory || Central Research Institute, 2012 Laboratories || Huawei Technologies Co., Ltd. || Bo Baibaibo8@huawei.com || W ei Hanharvey.hanwei@huawei.com || W eixi Z ... (truncated) ||  || { || ""title"": ""Theory Laboratory"", || ""authors"": [ || ""Xueyan Niuniuxueyan3@huawei.com"", || ""Bo Baibaibo8@huawei.com"", || ""W eixi Zhangzhangweixi1@huawei.com"", || ""W eixi Zhangzhangweixi1@huawei.com"" || ], || ""doi"": ""arXiv:2601.07389v1"", || ""arxiv_id"": ""arXiv:2601.07389"", || ""keywords"": [], || ""summary"": ""Post-training of large language models routinely interleaves supervised fine-tuning (SFT) with reinforcement learning (RL). These two methods have different objectives: SFT minimizes cross-entropy loss between model outputs and expert responses, while RL maximizes reward signals derived from human preferences or rule-based verifiers. Modern reasoning models have widely adopted the practice of alternating SFT and RL. However, there is no theoretical account of whether they can be decoupled. We prove that decoupling is impossible in either order: (1) SFT-then-RL coupling: RL increases SFT loss under SFT optimality and (2) RL-then-SFT coupling: SFT lowers the reward achieved by RL. Experiments on Qwen3-0.6B confirm the predicted degradation, verifying that SFT and RL cannot be separated without loss of prior performance in the post-training pipeline."", || ""contact"": { || ""email"": ""Xueyan.Niuniuxueyan3@huawei.com"", || ""lab"": ""Theory Laboratory"", || ""institution"": ""Central Research Institute"", || ""affiliation"": ""2012 Laboratories, Huawei Technologies Co., Ltd."" || } || } ||  || [ Prompt: 129.0 t/s | Generation: 28.5 t/s ]"
2601.07392v1_OceanSAR-2 A Universal Feature Extractor for SAR O.pdf,OceanSAR-2: A Universal Feature Extractor for SAR Ocean Observation,"['Alexandre Tuela', 'Thomas Kerdreux a', 'Quentin Febvre b', 'Alexis Mouche b', 'Antoine Grouazel b', 'Jean-Renaud Miadana c', 'Antoine Audrasa', 'Chen Wangd', 'Bertrand Chapronb']",,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || OceanSAR-2: A Universal Feature Extractor for SAR Ocean Observa- || tion || Alexandre Tuela, Thomas Kerdreux a, Quentin Febvre b, Alexis Mouche b, Antoine Grouazel b, Jean-Renaud Miadana c, || Antoine Audrasa, Chen Wangd, and Bertrand Chapronb || aGaleio, Paris, France || bLOPS, Ifremer, Plouzan,  ... (truncated) ||  || { || ""title"": ""OceanSAR-2: A Universal Feature Extractor for SAR Ocean Observation"", || ""authors"": [ || ""Alexandre Tuela"", || ""Thomas Kerdreux a"", || ""Quentin Febvre b"", || ""Alexis Mouche b"", || ""Antoine Grouazel b"", || ""Jean-Renaud Miadana c"", || ""Antoine Audrasa"", || ""Chen Wangd"", || ""Bertrand Chapronb"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""We present OceanSAR-2, the second generation of our foundation model for SAR-based ocean observation. Building on our earlier release, which pioneered self-supervised learning on Sentinel-1 Wave Mode data, OceanSAR-2 relies on improved SSL training and dynamic data curation strategies, which enhances performance while reducing training cost. OceanSAR-2 demonstrates strong transfer performance across downstream tasks, including geophysical pattern classification, ocean surface wind vector and significant wave height estimation, and iceberg detection. We release standardized benchmark datasets, providing a foundation for systematic evaluation and advancement of SAR models for ocean applications."" || } ||  || [ Prompt: 127.7 t/s | Generation: 28.6 t/s ]"
2601.07393v1_Software-Hardware Co-optimization for Modular E2E .pdf,SOFTWARE-HARDWARECO-OPTIMIZATION FORMODULARE2E,"['Chengzhi Ji1', 'Xingfeng Li1', 'Zhaodong Lv1', 'Hao Sun2', 'Pan Liu1', 'Hao Frank Yang3', 'Ziyuan Pu1']",,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SOFTWARE-HARDWARECO-OPTIMIZATION FORMODULARE2E || AV PARADIGM: A UNIFIEDFRAMEWORK OFOPTIMIZATION || APPROACHES, SIMULATIONENVIRONMENT ANDEVALUATION || METRICS || Chengzhi Ji1, Xingfeng Li1, Zhaodong Lv1, Hao Sun2, Pan Liu1, Hao Frank Yang3, Ziyuan Pu1, || 1School of Transportation, Southeast Unive ... (truncated) ||  || { || ""title"": ""SOFTWARE-HARDWARECO-OPTIMIZATION FORMODULARE2E"", || ""authors"": [ || ""Chengzhi Ji1"", || ""Xingfeng Li1"", || ""Zhaodong Lv1"", || ""Hao Sun2"", || ""Pan Liu1"", || ""Hao Frank Yang3"", || ""Ziyuan Pu1"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Modular end-to-end"", || ""Closed-Loop Evaluation"", || ""SoftwareHardware co-optimization"", || ""Energy Consumption"", || ""Inference Latency"", || ""EERA V metric"" || ], || ""summary"": ""This paper proposes a reusable software-hardware co-optimization and closed-loop evaluation framework for modular end-to-end autonomous driving inference, aiming to balance accuracy, safety, efficiency, latency, and energy consumption."" || } ||  || [ Prompt: 120.5 t/s | Generation: 27.8 t/s ]"
2601.07395v1_MCP-ITP An Automated Framework for Implicit Tool P.pdf,MCP-ITP: An Automated Framework for Implicit Tool Poisoning in MCP,"['Ruiqi Li', 'Zhiqiang Wang', 'Yunhao Yao', 'Xiang-Yang Li']",lrq349,30.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MCP-ITP: An Automated Framework for Implicit Tool Poisoning in MCP || Ruiqi Li, Zhiqiang Wang, Y unhao Y ao, and Xiang-Y ang Li || University of Science and Technology of China || {lrq349, zhiqiang.wang, yaoyunhao}@mail.ustc.edu.cn, xiangyangli@ustc.edu.cn || Abstract || To standardize interaction ... (truncated) ||  || { || ""title"": ""MCP-ITP: An Automated Framework for Implicit Tool Poisoning in MCP"", || ""authors"": [""Ruiqi Li"", ""Zhiqiang Wang"", ""Yunhao Yao"", ""Xiang-Yang Li""], || ""doi"": ""lrq349"", || ""arxiv_id"": ""zhiqiang.wang"", || ""keywords"": [""implicit tool poisoning"", ""MCP"", ""tool poisoning"", ""security risk""], || ""summary"": ""This paper introduces MCP-ITP, the first automated and adaptive framework for implicit tool poisoning within the MCP ecosystem. It addresses security risks where poisoned tool metadata stealthily manipulates agents by inducing them to use legitimate high-privilege tools."" || } ||  || [ Prompt: 124.9 t/s | Generation: 30.4 t/s ]"
2601.07397v1_Layerwise goal-oriented adaptivity for neural ODEs.pdf,Layerwise goal-oriented adaptivity for neural ODEs: an optimal control perspective,"['Michael Hintermüller', 'Michael Hinze', 'Denis Korolev']",arXiv:2601.07397v1,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || arXiv:2601.07397v1  [math.OC]  12 Jan 2026 || Layerwise goal-oriented adaptivity for neural ODEs: an optimal || control perspective || Michael Hinterm uller1,3 , Michael Hinze 2 , and Denis Korolev 3 || 1Institute for Mathematics, Humboldt-Universit at zu Berlin, Berlin, Germany || 2Mathematical I ... (truncated) ||  || { || ""title"": ""Layerwise goal-oriented adaptivity for neural ODEs: an optimal control perspective"", || ""authors"": [ || ""Michael Hintermüller"", || ""Michael Hinze"", || ""Denis Korolev"" || ], || ""doi"": ""arXiv:2601.07397v1"", || ""arxiv_id"": ""2601.07397"", || ""keywords"": [ || ""Resnet"", || ""neural ODEs"", || ""parameter identification"", || ""adaptive neural network"" || ], || ""summary"": ""The paper proposes a novel layerwise adaptive construction method for neural network architectures based on a goal-oriented dual-weighted residual technique for optimal control of neural differential equations. It introduces an explicit Euler time marching scheme and applies the method to neural network construction for data classification."" || } ||  || [ Prompt: 135.4 t/s | Generation: 28.2 t/s ]"
2601.07411v1_SCALPEL Selective Capability Ablation via Low-rank.pdf,SCALPEL: Selective Capability Ablation via Low-rank Parameter,"['Zihao Fu', 'Xufeng Duan', 'Zhenguang G. Cai']",,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SCALPEL: Selective Capability Ablation via Low-rank Parameter || Editing for Large Language Model Interpretability Analysis || Zihao Fu || The Chinese University of Hong Kong || zihaofu@cuhk.edu.hk || Xufeng Duan || The Chinese University of Hong Kong || xufengduan@cuhk.edu.hk || Zhenguang G. Cai || The Chine ... (truncated) ||  || { || ""title"": ""SCALPEL: Selective Capability Ablation via Low-rank Parameter"", || ""authors"": [ || ""Zihao Fu"", || ""Xufeng Duan"", || ""Zhenguang G. Cai"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper introduces SCALPEL, a framework representing language model capabilities as low-rank parameter subspaces. It enables precise capability removal without disrupting other functions, offering insights into distributed capability encoding in neural networks."" || } ||  || [ Prompt: 127.3 t/s | Generation: 29.0 t/s ]"
2601.07422v1_Two Pathways to Truthfulness On the Intrinsic Enco.pdf,Two Pathways to Truthfulness: On the Intrinsic,"['Wen Luo', 'Guangyue Peng', 'Wei Li', 'Shaohang Wei', 'Feifan Song', 'Liang Wang', 'Nan Yang', 'Xingxing Zhang', 'Jing Jin', 'Furu Wei', 'Houfeng Wang']",,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Two Pathways to Truthfulness: On the Intrinsic || Encoding of LLM Hallucinations || Wen Luo, Guangyue Peng , Wei Li, Shaohang Wei, Feifan Song , || Liang Wang, Nan Yang, Xingxing Zhang , Jing Jin , Furu Wei, Houfeng Wang* || State Key Laboratory of Multimedia Information Processing, || School of  ... (truncated) ||  || { || ""title"": ""Two Pathways to Truthfulness: On the Intrinsic"", || ""authors"": [ || ""Wen Luo"", || ""Guangyue Peng"", || ""Wei Li"", || ""Shaohang Wei"", || ""Feifan Song"", || ""Liang Wang"", || ""Nan Yang"", || ""Xingxing Zhang"", || ""Jing Jin"", || ""Furu Wei"", || ""Houfeng Wang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper explores how large language models encode truthfulness through two distinct information pathways: a Question-Anchored pathway and an Answer-Anchored pathway. It investigates these mechanisms using attention knockout and token patching, revealing their association with LLM knowledge boundaries and self-awareness."" || } ||  || [ Prompt: 121.0 t/s | Generation: 29.1 t/s ]"
2601.07430v1_KALE Enhancing Knowledge Manipulation in Large Lan.pdf,,[],,29.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || KALE: Enhancing Knowledge Manipulation in Large Language Models || via Knowledge-aware Learning || Qitan Lv1,2* Tianyu Liu1,2* Qiaosheng Zhang2 Xingcheng Xu2 Chaochao Lu2 || 1University of Science and Technology of China || 2Shanghai AI Laboratory || {qitanlv, tianyu_liu}@mail.ustc.edu.cn || {xuxingc ... (truncated) ||  || { || ""title"": ""KALE: Enhancing Knowledge Manipulation in Large Language Models"", || ""authors"": [ || ""Qitan Lv1"", || ""Tianyu Liu1"", || ""Qiaosheng Zhang2"", || ""Xingcheng Xu2"", || ""Chaochao Lu2"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper proposes KALE, a post-training framework leveraging knowledge graphs to improve LLMs' knowledge manipulation by generating rationales and minimizing KL divergence."" || } ||  || [ Prompt: 128.3 t/s | Generation: 29.5 t/s ]"
2601.07449v1_RLPO Residual Listwise Preference Optimization for.pdf,Residual Listwise Preference Optimization for Long-Context,"['Hao Jiang', 'Zhi Yang', 'Annan Wang', 'Yichi Zhang', 'Weisi Lin', 'Yichizhang0926@gmail.com']",,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || RLPO: Residual Listwise Preference Optimization for Long-Context || Review Ranking || Hao Jiang || Nanyang Technological University || jianghao907@gmail.com || Zhi Yang || Peking University || zhiyang25@stu.pku.edu.cn || Annan Wang || Nanyang Technological University || annan001@e.ntu.edu.sg || Yichi Zhang || Independ ... (truncated) ||  || { || ""title"": ""Residual Listwise Preference Optimization for Long-Context"", || ""authors"": [ || ""Hao Jiang"", || ""Zhi Yang"", || ""Annan Wang"", || ""Yichi Zhang"", || ""Weisi Lin"", || ""Yichizhang0926@gmail.com"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""review ranking"", || ""long-context"", || ""listwise preference optimization"", || ""e-commerce"", || ""user-generated content"" || ], || ""summary"": ""Review ranking is pivotal in e-commerce for prioritizing diagnostic and authentic feedback. Existing ranking paradigms face a trade-off between pointwise scoring and list-level interactions, leading to unstable top-k rankings. RLPO addresses this by formulating ranking as a residual correction over a strong pointwise LLM."" || } ||  || [ Prompt: 125.3 t/s | Generation: 29.3 t/s ]"
2601.07463v1_Puzzle it Out Local-to-Global World Model for Offl.pdf,Puzzle it Out: Local-to-Global World Model for Offline,"['Sijia Li', 'Xinran Li', 'Shibo Chen', 'Jun Zhang']",10.48550/arXiv.2603.07918,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Puzzle it Out: Local-to-Global World Model for Offline || Multi-Agent Reinforcement Learning || Sijia Li || The Hong Kong University of Science and Technology || Hong Kong, China || slifg@connect.ust.hk || Xinran Li || The Hong Kong University of Science and Technology || Hong Kong, China || xinran.li@connect ... (truncated) ||  || { || ""title"": ""Puzzle it Out: Local-to-Global World Model for Offline"", || ""authors"": [ || ""Sijia Li"", || ""Xinran Li"", || ""Shibo Chen"", || ""Jun Zhang"" || ], || ""doi"": ""10.48550/arXiv.2603.07918"", || ""arxiv_id"": ""10.48550/arXiv.2603.07918"", || ""keywords"": [ || ""Offline multi-agent reinforcement learning"", || ""Multi-gent model-based reinforcement learning"" || ], || ""summary"": ""This paper proposes a local-to-global world model to improve generalization in offline multi-agent reinforcement learning by leveraging local predictions and synthetic data augmentation. It introduces an uncertainty-aware sampling mechanism to reduce approximation errors."" || } ||  || [ Prompt: 123.7 t/s | Generation: 27.6 t/s ]"
2601.07464v1_IFDNS An Iterative Feedback-Driven Neuro-Symbolic .pdf,Iterative Feedback-Driven Neuro-Symbolic (IFDNS),"['Xiaoheng Wang', 'Tongxuan Liu', 'Zi Gong1', 'Xianzhe Dong', 'Yuting Zeng', 'Minhan Hu', 'Weizhe Huang', 'Jing Li']",,29.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || IFDNS: An Iterative Feedback-Driven Neuro-Symbolic || Method for Faithful Logical Reasoning || Xiaoheng Wang1[0009000533352322], Tongxuan Liu1[0009000726342788], Zi || Gong1[0009000488633677], Xianzhe Dong1[0009000769439432], Yuting || Zeng1[0009000617195424], Minhan Hu1[0009000739958821], Weiz ... (truncated) ||  || { || ""title"": ""Iterative Feedback-Driven Neuro-Symbolic (IFDNS)"", || ""authors"": [ || ""Xiaoheng Wang"", || ""Tongxuan Liu"", || ""Zi Gong1"", || ""Xianzhe Dong"", || ""Yuting Zeng"", || ""Minhan Hu"", || ""Weizhe Huang"", || ""Jing Li"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Logical Reasoning"", || ""Large Language Model"", || ""Reasoning"", || ""Neuro-symbolic"", || ""Information Loss"" || ], || ""summary"": ""This paper introduces IFDNS, a novel prompt-based method that employs iterative feedback to improve logical reasoning in large language models by addressing information loss during reasoning."" || } ||  || [ Prompt: 124.9 t/s | Generation: 29.4 t/s ]"
2601.07468v1_Beyond Dialogue Time Temporal Semantic Memory for .pdf,Beyond Dialogue Time: Temporal Semantic Memory for Personalized LLM Agents,"['Miao Su1', 'Yucan Guo1,2,3', 'Zixuan Li1,2,Yufei Zhang 4', 'Guojun Yin 4', 'Wei Lin 4', 'Xiaolong Jin1,2,3', 'Jiafeng Guo 1,2,3', 'Xueqi Cheng 1,2,3', 'Institute of Computing Technology, Chinese Academy of Sciences', 'State Key Laboratory of AI Safety', 'School of Computer Science, University of Chinese Academy of Sciences', 'Meituan']",,28.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Beyond Dialogue Time: || Temporal Semantic Memory for Personalized LLM Agents || Miao Su1,2,3,4, Yucan Guo1,2,3, Zhongni Hou 4, Long Bai 1,2, || Zixuan Li1,2,Yufei Zhang 4,Guojun Yin 4,Wei Lin 4, || Xiaolong Jin1,2,3,Jiafeng Guo 1,2,3,Xueqi Cheng 1,2,3, || 1Institute of Computing Technology, Chine ... (truncated) ||  || { || ""title"": ""Beyond Dialogue Time: Temporal Semantic Memory for Personalized LLM Agents"", || ""authors"": [ || ""Miao Su1"", || ""Yucan Guo1,2,3"", || ""Zixuan Li1,2,Yufei Zhang 4"", || ""Guojun Yin 4"", || ""Wei Lin 4"", || ""Xiaolong Jin1,2,3"", || ""Jiafeng Guo 1,2,3"", || ""Xueqi Cheng 1,2,3"", || ""Institute of Computing Technology, Chinese Academy of Sciences"", || ""State Key Laboratory of AI Safety"", || ""School of Computer Science, University of Chinese Academy of Sciences"", || ""Meituan"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Temporal Semantic Memory"", || ""Personalized LLM Agents"", || ""Memory Modeling"", || ""Semantic Timeline"", || ""Durative Information"", || ""Long-term Interaction"" || ], || ""summary"": ""This paper introduces Temporal Semantic Memory (TSM), a memory framework that models semantic time for point-wise memory and supports the construction and utilization of durative memory. TSM addresses temporal inaccuracy and fragmentation by building a semantic timeline and consolidating continuous, related information."" || } ||  || [ Prompt: 126.8 t/s | Generation: 28.9 t/s ]"
2601.07469v1_Knowledge Distillation for LLM-Based Human Activit.pdf,Knowledge Distillation for LLM-Based Human Activity Recognition in Smart Homes,"['Julien Cumin', 'Oussama Er-Rahmany', 'Xi Chen']",arXiv:2601.07469v1,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || arXiv:2601.07469v1  [cs.AI]  12 Jan 2026 || KNOWLEDGE DISTILLATION FOR LLM-B ASED HUMAN ACTIVITY || RECOGNITION IN HOMES || AUTHOR VERSION || Julien Cumin1 , Oussama Er-Rahmany1, Xi Chen 1,2 || 1 Orange Research || 2 Univ. Grenoble Alpes, CNRS, Grenoble INP , LIG, 38000 Grenoble, France || Corresponding ... (truncated) ||  || { || ""title"": ""Knowledge Distillation for LLM-Based Human Activity Recognition in Smart Homes"", || ""authors"": [ || ""Julien Cumin"", || ""Oussama Er-Rahmany"", || ""Xi Chen"" || ], || ""doi"": ""arXiv:2601.07469v1"", || ""arxiv_id"": ""arXiv:2601.07469v1"", || ""keywords"": [ || ""Human activity recognition"", || ""Large language models"", || ""Knowledge distillation"", || ""Ambient intelligence"", || ""Smart homes"" || ], || ""summary"": ""This paper presents experimental results on using Large Language Models for Human Activity Recognition in smart homes, focusing on performance evolution with LLM size and applying knowledge distillation to reduce model parameters while maintaining high recognition accuracy."" || } ||  || [ Prompt: 124.0 t/s | Generation: 29.3 t/s ]"
2601.07470v1_Learning How to Remember A Meta-Cognitive Manageme.pdf,Learning How to Remember: A Meta-Cognitive Management Method for Structured and Transferable Agent Memory,"['Sirui Liang', 'Pengfei Cao', 'Jian Zhao', 'Wenhao Teng', 'Xiangwen Liao', 'Jun Zhao', 'Kang Liu']",liangsirui2024@ia.ac.cn,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Learning How to Remember:A Meta-Cognitive Management Method for || Structured and Transferable Agent Memory || Sirui Liang1,2,3*, Pengfei Cao1,2*, Jian Zhao3,4, Wenhao Teng 5, || Xiangwen Liao 6,Jun Zhao 1,2,Kang Liu 1,2 || 1Institute of Automation, CAS, 2University of Chinese Academy of Scienc ... (truncated) ||  || { || ""title"": ""Learning How to Remember: A Meta-Cognitive Management Method for Structured and Transferable Agent Memory"", || ""authors"": [ || ""Sirui Liang"", || ""Pengfei Cao"", || ""Jian Zhao"", || ""Wenhao Teng"", || ""Xiangwen Liao"", || ""Jun Zhao"", || ""Kang Liu"" || ], || ""doi"": ""liangsirui2024@ia.ac.cn"", || ""arxiv_id"": """", || ""keywords"": [ || ""memory abstraction"", || ""meta-cognitive management"", || ""agent memory"", || ""transfer learning"", || ""long-horizon decision-making"" || ], || ""summary"": ""The paper proposes the Meta-CognitiveMemory Abstraction method (MCMA) to improve memory reuse in large language model agents by treating memory abstraction as a learnable skill, enabling selective reuse based on abstraction levels."" || } ||  || [ Prompt: 117.4 t/s | Generation: 28.5 t/s ]"
2601.07474v1_Task Prototype-Based Knowledge Retrieval for Multi.pdf,Prototype-Based Knowledge Retrieval for Multi-Task Learning,"['Yongmin Oh', 'Hyung-Il Kim', 'Jung Uk Kim', 'Ju Kim']",10.48550/arXiv.2303.03015,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Task Prototype-Based Knowledge Retrieval for Multi-Task Learning || from Partially Annotated Data || Y oungmin Oh1,2, Hyung-Il Kim 3, Jung Uk Kim 1* || 1Kyung Hee University || 2Electronics and Telecommunications Research Institute (ETRI) || 3Chonnam National University || youngmin@etri.re.kr, hyungi ... (truncated) ||  || { || ""title"": ""Prototype-Based Knowledge Retrieval for Multi-Task Learning"", || ""authors"": [ || ""Yongmin Oh"", || ""Hyung-Il Kim"", || ""Jung Uk Kim"", || ""Ju Kim"" || ], || ""doi"": ""10.48550/arXiv.2303.03015"", || ""arxiv_id"": ""10.48550/arXiv:2303.03015"", || ""keywords"": [ || ""multi-task learning"", || ""prototype-based knowledge retrieval"", || ""multi-task learning framework"", || ""task prototype embedding"", || ""knowledge retrieval transformer"" || ], || ""summary"": ""This paper proposes a prototype-based knowledge retrieval framework for multi-task learning, addressing the challenges of partially annotated data by focusing on robust MTL without relying on predictions from unlabeled tasks. The framework introduces an association knowledge generation loss to capture task-specific characteristics and enhances feature representations."" || } ||  || [ Prompt: 123.5 t/s | Generation: 29.0 t/s ]"
2601.07475v1_ARCQuant Boosting NVFP4 Quantization with Augmente.pdf,ARCQuant: Boosting NVFP4 Quantization with Augmented Residual,"['Haoqian Meng', 'Yilun Luo', 'Yafei Zhao', 'Wenyuan Liu', 'Peng Zhang', 'Xindian Ma']",,29.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ARCQuant: Boosting NVFP4 Quantization with Augmented Residual || Channels for LLMs || Haoqian Meng1, Yilun Luo1, Yafei Zhao1, Wenyuan Liu1, Peng Zhang1*, Xindian Ma1 || 1School of Computer Science and Technology, Tianjin University || Abstract || The emergence of fine-grained numerical for- || mats l ... (truncated) ||  || { || ""title"": ""ARCQuant: Boosting NVFP4 Quantization with Augmented Residual"", || ""authors"": [ || ""Haoqian Meng"", || ""Yilun Luo"", || ""Yafei Zhao"", || ""Wenyuan Liu"", || ""Peng Zhang"", || ""Xindian Ma"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper proposes ARCQuant, a framework that enhances NVFP4 performance using augmented residual channels, maintaining a strictly unified NVFP4 format while achieving state-of-the-art accuracy and speed."" || } ||  || [ Prompt: 127.2 t/s | Generation: 29.4 t/s ]"
2601.07477v1_JudgeFlow Agentic Workflow Optimization via Block .pdf,JUDGEFLOW: AGENTICWORKFLOWOPTIMIZATION,"['Zihan Ma', 'Zhikai Zhao', 'Chuanbo Hua', 'Federico Berto', 'Jinkyoo Park']",,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || JUDGEFLOW: AGENTICWORKFLOWOPTIMIZATION || VIABLOCKJUDGE || Zihan Ma,1 Zhikai Zhao,1 Chuanbo Hua1 Federico Berto1,2 Jinkyoo Park1,3 || 1KAIST 2Radical Numerics 3Omelet || ABSTRACT || Optimizing LLM-based agentic workflows is challenging for scaling AI capabilities. || Current methods rely on coarse, e ... (truncated) ||  || { || ""title"": ""JUDGEFLOW: AGENTICWORKFLOWOPTIMIZATION"", || ""authors"": [ || ""Zihan Ma"", || ""Zhikai Zhao"", || ""Chuanbo Hua"", || ""Federico Berto"", || ""Jinkyoo Park"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Optimizing LLM-based agentic workflows is challenging for scaling AI capabilities. JUDGEFLOW introduces an Evaluation Judge-Optimization-Update pipeline to improve sample efficiency and interpretability."" || } ||  || [ Prompt: 122.2 t/s | Generation: 29.0 t/s ]"
2601.07496v1_Graph Inference Towards ICD Coding.pdf,Graph Inference Towards ICD Coding,['Xiaoxiao Deng'],,26.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Graph Inference Towards ICD Coding || 1st Xiaoxiao Deng || College of Computing and Digital Media || DePaul University || Chicago, United States || dengxiaoxiao1019@gmail.com || AbstractAutomated ICD coding involves assigning standard- || ized diagnostic codes to clinical narratives. The vast label || spac ... (truncated) ||  || { || ""title"": ""Graph Inference Towards ICD Coding"", || ""authors"": [""Xiaoxiao Deng""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""transfer learning"", ""graph convolutional network"", ""lightweight attention"", ""ICD code prediction"", ""adversarial domain adaptation""], || ""summary"": ""LabGraph introduces a unified framework reformulating ICD coding as graph generation, enhancing robustness through adversarial adaptation and reinforcement learning."" || } ||  || [ Prompt: 122.5 t/s | Generation: 26.4 t/s ]"
2601.07514v1_Data-Driven Stochastic VRP Integration of Forecast.pdf,Data-Driven Stochastic VRP: Integration of Forecast,['Matteo Garbellia'],arXiv:2601.07514v1,31.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Data-Driven Stochastic VRP: Integration of Forecast || Duration into Optimization for Utility Workforce || Management || Matteo Garbellia, || aDepartment of Computer Science, Strada le Grazie, 15, Verona, 37134, Italy || Abstract || This paper investigates the integration of machine learning forecast ... (truncated) ||  || { || ""title"": ""Data-Driven Stochastic VRP: Integration of Forecast"", || ""authors"": [""Matteo Garbellia""], || ""doi"": ""arXiv:2601.07514v1"", || ""arxiv_id"": ""2601.07514"", || ""keywords"": [""Stochastic VRP"", ""Machine Learning"", ""XGBoost"", ""Sub-Gaussian Concentration"", ""Multi-Objective Optimization"", ""Evolutionary Algorithms""], || ""summary"": ""This paper investigates the integration of machine learning forecasts of intervention durations into a stochastic variant of the Capacitated Vehicle Routing Problem with Time Windows. In particular, we exploit tree-based gradient boosting trained on eight years of gas meter maintenance data to produce point predictions and uncertainty estimates, which then drive a multi-objective evolutionary optimization routine. The methodology addresses uncertainty through sub-Gaussian concentration bounds for route-level risk buffers and explicitly accounts for competing operational KPIs through a multi-objective formulation. Empirical analysis of prediction residuals validates the sub-Gaussian assumption underlying the risk model. From an empirical point of view, our results report improvements around 20-25% in operator utilization and completion rates compared with plans computed using default durations. The integration of uncertainty quantification and risk-aware optimization provides a practical framework for handling stochastic service durations in real-world routing applications."" || } ||  || [ Prompt: 115.3 t/s | Generation: 31.8 t/s ]"
2601.07516v1_Controlling Multimodal Conversational Agents with .pdf,Controlling Multimodal Conversational Agents with Coverage-Enhanced Latent Actions,"['Yongqi Li', 'Hao Lang', 'Tieyun Qian', 'Yongbin Li', '1', '2', '3']",,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Controlling Multimodal Conversational Agents || with Coverage-Enhanced Latent Actions || Y ongqi Li1,2,,, Hao Lang 2,, Tieyun Qian 1,3,, Y ongbin Li2, || 1 School of Computer Science, Wuhan University, 2 Tongyi Lab || 3 Zhongguancun Academy || {liyongqi,qty}@whu.edu.cn,{hao.lang,shuide.lyb}@alibab ... (truncated) ||  || { || ""title"": ""Controlling Multimodal Conversational Agents with Coverage-Enhanced Latent Actions"", || ""authors"": [ || ""Yongqi Li"", || ""Hao Lang"", || ""Tieyun Qian"", || ""Yongbin Li"", || ""1"", || ""2"", || ""3"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""vision-language models"", || ""multimodal conversational agents"", || ""reinforcement learning"", || ""latent actions"", || ""codebook"", || ""cross-modal projector"", || ""RL fine-tuning"" || ], || ""summary"": ""This paper explores adapting vision-language models as multimodal conversational agents by introducing a compact latent action space learned via reinforcement learning. It addresses challenges in handling large text token spaces using paired image-text data and text-only data, leveraging cross-modal transformations. The method achieves better performance across RL-based baselines in two conversation tasks."" || } ||  || [ Prompt: 125.3 t/s | Generation: 28.6 t/s ]"
2601.07518v1_Mon3tr Monocular 3D Telepresence with Pre-built Ga.pdf,Mon3tr: Monocular 3D Telepresence with Pre-built Gaussian Avatars as Amortization,"['Fangyu Lin', 'Yingdong Hu', 'Zhening Liu', 'Yufan Zhuang', 'Zehong Lin', 'Jun Zhang']",10.48550/arXiv.2405.12345,28.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || JOURNAL OF LATEX CLASS FILES 1 || Mon3tr: Monocular 3D Telepresence with Pre-built || Gaussian Avatars as Amortization || Fangyu Lin, Yingdong Hu, Zhening Liu, Yufan Zhuang, || Zehong Lin,Member, IEEE,and Jun Zhang,Fellow, IEEE || AbstractImmersive telepresence aims to transform human || interaction  ... (truncated) ||  || { || ""title"": ""Mon3tr: Monocular 3D Telepresence with Pre-built Gaussian Avatars as Amortization"", || ""authors"": [ || ""Fangyu Lin"", || ""Yingdong Hu"", || ""Zhening Liu"", || ""Yufan Zhuang"", || ""Zehong Lin"", || ""Jun Zhang"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [ || ""Monocular 3D telepresence"", || ""3D Gaussian splatting"", || ""animatable avatars"", || ""real-time neural rendering"" || ], || ""summary"": ""This paper introduces Mon3tr, a novel monocular 3D telepresence framework that integrates 3D Gaussian splatting for parametric human modeling. It employs an amortized computation strategy using a single monocular RGB camera to capture real-time body and facial motions, enabling efficient offline multi-view reconstruction and online inference during live telepresence. The method achieves high performance with low bandwidth (0.2 Mbps) and supports real-time operation across diverse scenarios."" || } ||  || [ Prompt: 119.9 t/s | Generation: 28.9 t/s ]"
2601.07525v1_Thinking Before Constraining A Unified Decoding Fr.pdf,Thinking Before Constraining: A Unified Decoding Framework for Large Language Models,"['Ngoc Trinh Hung Nguyen', 'Alonso Silva', 'Laith Zumot', 'Liubov Tupikina', 'Armen Aghasaryan', 'Mehwish Alam']",,28.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Thinking Before Constraining: A Unified Decoding Framework for Large || Language Models || Ngoc Trinh Hung Nguyen1,2, Alonso Silva2, Laith Zumot3 || Liubov Tupikina2,Armen Aghasaryan 2,Mehwish Alam 1 || 1 Tlcom Paris, Institut Polytechnique de Paris, France, 2 Nokia Bell Labs, 3 Nokia || Correspon ... (truncated) ||  || { || ""title"": ""Thinking Before Constraining: A Unified Decoding Framework for Large Language Models"", || ""authors"": [ || ""Ngoc Trinh Hung Nguyen"", || ""Alonso Silva"", || ""Laith Zumot"", || ""Liubov Tupikina"", || ""Armen Aghasaryan"", || ""Mehwish Alam"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper proposes a unified decoding framework that combines natural and structured generation to improve the reliability and parsability of large language models' outputs."" || } ||  || [ Prompt: 121.9 t/s | Generation: 28.9 t/s ]"
2601.07528v1_From RAG to Agentic RAG for Faithful Islamic Quest.pdf,From RAG to Agentic RAG for Faithful Islamic Question Answering,"['Gagan Bhatia', 'Hamdy Mubarak', 'Mustafa Jarrar', 'George Mikros', 'Fadi Zaraket', 'Mahmoud Alhirthani', 'Logan Cochrane', 'Kareem Darwish', 'Rashid Yahiaoui', 'Firoj Alam']",,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || From RAG to Agentic RAG for Faithful Islamic Question Answering || Gagan Bhatia1, Hamdy Mubarak1, Mustafa Jarrar2, George Mikros2, || Fadi Zaraket3, Mahmoud Alhirthani2, Mutaz Al-Khatib4, || Logan Cochrane5, Kareem Darwish1, Rashid Yahiaoui2, Firoj Alam1 || 1 Qatar Computing Research Institute, ... (truncated) ||  || { || ""title"": ""From RAG to Agentic RAG for Faithful Islamic Question Answering"", || ""authors"": [ || ""Gagan Bhatia"", || ""Hamdy Mubarak"", || ""Mustafa Jarrar"", || ""George Mikros"", || ""Fadi Zaraket"", || ""Mahmoud Alhirthani"", || ""Logan Cochrane"", || ""Kareem Darwish"", || ""Rashid Yahiaoui"", || ""Firoj Alam"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Islamic question answering"", || ""faithful Islamic QA"", || ""LLM evaluation"", || ""free-form hallucinations"", || ""agentic RAG"", || ""Quran retrieval"", || ""habitual robustness"" || ], || ""summary"": ""This paper introduces ISLAMIC FAITH QA, a benchmark for evaluating Islamic question answering, and presents an agentic RAG framework that improves accuracy and robustness over standard RAG, especially in Arabic and English contexts."" || } ||  || [ Prompt: 126.9 t/s | Generation: 29.1 t/s ]"
2601.07553v1_VirtualEnv A Platform for Embodied AI Research.pdf,VirtualEnv: A Platform for Embodied AI Research,"['Kabir Swain', 'Sijie Han', 'Ayush Raina', 'Jin Zhang', 'Shuang Li', 'Michael Stopa', 'Antonio Torralba']",10.48550/arXiv.2303.04219,29.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || VirtualEnv: A Platform for Embodied AI Research || Kabir Swain1, Sijie Han2, Ayush Raina3, Jin Zhang3, Shuang Li4, Michael Stopa3, Antonio || Torralba1 || 1Massachusetts Institute of Technology || 2University of Toronto || 3Sony Interactive Entertainment || 4Google Deepmind || kswain@mit.edu, hs.han@mai ... (truncated) ||  || { || ""title"": ""VirtualEnv: A Platform for Embodied AI Research"", || ""authors"": [ || ""Kabir Swain"", || ""Sijie Han"", || ""Ayush Raina"", || ""Jin Zhang"", || ""Shuang Li"", || ""Michael Stopa"", || ""Antonio Torralba"" || ], || ""doi"": ""10.48550/arXiv.2303.04219"", || ""arxiv_id"": ""arXiv:2303.04219"", || ""keywords"": [ || ""Virtual Environment"", || ""Large Language Models"", || ""Embodied AI"", || ""Unreal Engine"", || ""LLM benchmarking"", || ""Interactive Simulation"" || ], || ""summary"": ""VirtualEnv is a next-generation simulation platform built on Unreal Engine that enables fine-grained benchmarking of LLMs in embodied and interactive scenarios. It supports rich agent interactions, game-inspired mechanics, and integrates large-scale LLMs and vision-language models for procedural task generation."" || } ||  || [ Prompt: 114.5 t/s | Generation: 29.4 t/s ]"
2601.07556v1_Backpropagation-Free Test-Time Adaptation for Ligh.pdf,Backpropagation-Free Test-Time Adaptation for Lightweight EEG-Based Brain-Computer Interfaces,"['Siyang Li', 'Jiayi Ouyang', 'Zhenyao Cui', 'Ziwei Wang', 'Tianwang Jia', 'Feng Wan', 'Dongrui Wu']",,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || Backpropagation-Free Test-Time Adaptation for || Lightweight EEG-Based Brain-Computer Interfaces || Siyang Li, Jiayi Ouyang, Zhenyao Cui, Ziwei Wang, Tianwang J ia, Feng Wan, and Dongrui Wu, Fellow, IEEE || AbstractElectroencephalogram (EEG)-based brain-computer || interfaces (BCIs) face sign ... (truncated) ||  || { || ""title"": ""Backpropagation-Free Test-Time Adaptation for Lightweight EEG-Based Brain-Computer Interfaces"", || ""authors"": [ || ""Siyang Li"", || ""Jiayi Ouyang"", || ""Zhenyao Cui"", || ""Ziwei Wang"", || ""Tianwang Jia"", || ""Feng Wan"", || ""Dongrui Wu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""brain-computer interface"", || ""domain adaptation"", || ""electroencephalogram"", || ""test-time adaptation"", || ""transfer learning"" || ], || ""summary"": ""This paper proposes Backpropagation-Free Transformations (BF T) for EEG decoding, addressing deployment challenges in BCIs by eliminating backpropagation requirements, thus enabling lightweight, plug-and-play systems."" || } ||  || [ Prompt: 122.2 t/s | Generation: 29.3 t/s ]"
2601.07565v1_A Unified Framework for Emotion Recognition and Se.pdf,A Unified Framework for Emotion Recognition and Sentiment Analysis via Expert-Guided Multimodal Fusion with Large Language Models,"['Jiaqi Qiao', 'Xiujuan Xu', 'Xinran Li', 'Yu Liu']",,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A Unified Framework for Emotion Recognition and || Sentiment Analysis via Expert-Guided Multimodal || Fusion with Large Language Models || Jiaqi Qiao, Xiujuan Xu, Xinran Li, Yu Liu * || qiaobright@mail.dlut.edu.cn, xjxu@dlut.edu.cn, 963707605@mail.dlut.edu.cn, yuliu@dlut.edu.cn || School of Softwa ... (truncated) ||  || { || ""title"": ""A Unified Framework for Emotion Recognition and Sentiment Analysis via Expert-Guided Multimodal Fusion with Large Language Models"", || ""authors"": [ || ""Jiaqi Qiao"", || ""Xiujuan Xu"", || ""Xinran Li"", || ""Yu Liu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""semotion recognition"", || ""large language models"", || ""multimodal fusion"", || ""emotion recognition"", || ""sentiment analysis"" || ], || ""summary"": ""The paper presents EGMF, a unified framework combining expert-guided multimodal fusion with large language models. It features specialized expert networks for local, semantic, and global context, integrates multimodal representations with LLMs via pseudo token injection, and achieves state-of-the-art performance across bilingual benchmarks, demonstrating robust cross-lingual emotion understanding."" || } ||  || [ Prompt: 116.2 t/s | Generation: 28.2 t/s ]"
2601.07568v1_d3LLM Ultra-Fast Diffusion LLM using Pseudo-Trajec.pdf,Ultra-Fast dLLM using Pseudo-Trajectory Distillation,"['Yu-Yang Qian', 'Junda Su', 'Lanxiang Hu', 'Peiyuan Zhang', 'Zhijie Deng', 'Peng Zhao', 'Hao Zhang', 'Ma Peng']",,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || d3LLM: Ultra-Fast dLLM using Pseudo-Trajectory Distillation || Yu-Yang Qian1 2 Junda Su 1 Lanxiang Hu 1 Peiyuan Zhang 1 Zhijie Deng 4 Peng Zhao2 3 Hao Zhang1 || Abstract || Diffusion large language models (dLLMs) offer || capabilities beyond those of autoregressive (AR) || LLMs, such as parallel d ... (truncated) ||  || { || ""title"": ""Ultra-Fast dLLM using Pseudo-Trajectory Distillation"", || ""authors"": [ || ""Yu-Yang Qian"", || ""Junda Su"", || ""Lanxiang Hu"", || ""Peiyuan Zhang"", || ""Zhijie Deng"", || ""Peng Zhao"", || ""Hao Zhang"", || ""Ma Peng"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper proposes d3LLM, a pseudo-distilled diffusion large language model that balances accuracy and parallelism by introducing pseudo-trajectory distillation during training and entropy-based multi-block decoding during inference. It introduces AUP to evaluate dLLMs and achieves up to 10 speedup over vanilla LLaDA/Dream and 5 speedup over AR models."" || } ||  || [ Prompt: 116.5 t/s | Generation: 28.5 t/s ]"
2601.07573v1_A Model of Artificial Jagged Intelligence.pdf,A Model of Artificial Jagged Intelligence,[],arXiv:2601.07573v1,31.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A Model of Artificial Jagged Intelligence || Joshua S. Gans || January 13, 2026 || Abstract || Generative AI systems often display highly uneven performance across tasks that appear || nearby: they can be excellent on one prompt and confidently wrong on another with only || small changes in wording  ... (truncated) ||  || { || ""title"": ""A Model of Artificial Jagged Intelligence"", || ""authors"": [], || ""doi"": ""arXiv:2601.07573v1"", || ""arxiv_id"": ""2601.07573"", || ""keywords"": [ || ""generative AI"", || ""adoption"", || ""calibration"", || ""learning"", || ""knowledge density"", || ""scaling"" || ], || ""summary"": ""This paper develops a tractable economic model of Artificial Jagged Intelligence (AJI), exploring how users balance local reliability concerns with coarse global quality signals. It analyzes adoption thresholds, calibration, mastery, and scaling effects in generative AI systems."" || } ||  || [ Prompt: 125.7 t/s | Generation: 31.8 t/s ]"
2601.07577v1_Beyond Entangled Planning Task-Decoupled Planning .pdf,,[],,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Beyond Entangled Planning: Task-Decoupled Planning for || Long-Horizon Agents || Yunfan Li1,2, Bingbing Xu1*, || Xueyun Tian1,2,Xiucheng Xu 1,2,Huawei Shen 1,2 || 1State Key Laboratory of AI Safety, Institute of Computing Technology, CAS, || 2University of Chinese Academy of Sciences || {liyunfan24s, ... (truncated) ||  || { || ""title"": ""Beyond Entangled Planning: Task-Decoupled Planning for Long-Horizon Agents"", || ""authors"": [ || ""Yunfan Li"", || ""Bingbing Xu"", || ""Xueyun Tian"", || ""Xiucheng Xu"", || ""Huawei Shen"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""large language models"", || ""task decoupling"", || ""long-horizon planning"", || ""agent planning"", || ""sub-task reasoning"" || ], || ""summary"": ""This paper proposes Task-Decoupled Planning (TDP) to address the entanglement problem in planning for LLM-based agents. TDP decomposes tasks into a DAG of sub-goals, enabling local reasoning and replanning without affecting the overall workflow. Experiments show TDP outperforms existing methods while reducing planning consumption."" || } ||  || [ Prompt: 126.1 t/s | Generation: 28.7 t/s ]"
2601.07580v1_Large Language Models for Physics Instrument Desig.pdf,Large Language Models for Physics Instrument Design,"['Sara Zoccheddu1', 'Shah Rukh Qasim1', 'Patrick Owen2', 'Nicola Serra1,2']",,29.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Large Language Models for Physics Instrument Design || Sara Zoccheddu1, Shah Rukh Qasim1,2, Patrick Owen2, and Nicola Serra1,2 || 1Mathematical Modeling and Machine Learning Department, University of Zurich, || Zurich, Switzerland || 2Physik-Institut, University of Zurich, Zurich, Switzerland || J ... (truncated) ||  || { || ""title"": ""Large Language Models for Physics Instrument Design"", || ""authors"": [ || ""Sara Zoccheddu1"", || ""Shah Rukh Qasim1"", || ""Patrick Owen2"", || ""Nicola Serra1,2"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""We study the use of large language models (LLMs) for physics instrument design and compare their performance to reinforcement learning (RL). Using only prompting, LLMs are given task constraints and summaries of prior high-scoring designs and propose complete detector configurations, which we evaluate with the same simulators and reward functions used in RL-based optimization. Although RL yields stronger final designs, we find that modern LLMs consistently generate valid, resource-aware, and physically meaningful configurations that draw on broad pretrained knowledge of detector design principles and particle matter interactions, despite having no task-specific training. Based on this result, as a first step toward hybrid design workflows, we explore pairing the LLMs with a dedicated trust region optimizer, serving as a precursor to future pipelines in which LLMs propose and structure design hypotheses while RL performs reward-driven optimization. Based on these experiments, we argue that LLMs are well suited as meta-planners: they can design and orchestrate RL-based optimization studies, define search strategies, and coordinate multiple interacting components within a unified workflow. In doing so, they point toward automated, closed-loop instrument design in which much of the human effort required to structure and supervise optimization can be reduced."" || } ||  || [ Prompt: 125.1 t/s | Generation: 29.2 t/s ]"
2601.07582v2_ES-Mem Event Segmentation-Based Memory for Long-Te.pdf,ES-Mem: Event Segmentation-Based Memory for Long-Term,"['Huhai Zou', 'Tianhao Sun', 'Chuanjiang He', 'Yu Tian2', 'Zhenyang Li', 'Li Jin', 'Nayu Liu', 'Jiang Zhong', 'Kaiwen Wei']",,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ES-Mem: Event Segmentation-Based Memory for Long-Term || Dialogue Agents || Huhai Zou1, Tianhao Sun1, Chuanjiang He1, Yu Tian2, Zhenyang Li3, || Li Jin4,Nayu Liu 5,Jiang Zhong 1,Kaiwen Wei 1 || 1College of Computer Science, Chongqing University 2Tsinghua University || 3Hong Kong Generative AI Rese ... (truncated) ||  || { || ""title"": ""ES-Mem: Event Segmentation-Based Memory for Long-Term"", || ""authors"": [ || ""Huhai Zou"", || ""Tianhao Sun"", || ""Chuanjiang He"", || ""Yu Tian2"", || ""Zhenyang Li"", || ""Li Jin"", || ""Nayu Liu"", || ""Jiang Zhong"", || ""Kaiwen Wei"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""memory"", || ""dialogue agents"", || ""event segmentation"", || ""long-term interactions"", || ""semantic integrity"", || ""discourse structure"" || ], || ""summary"": ""Memory is critical for dialogue agents to maintain coherence and enable continuous adaptation in long-term interactions. Existing memory mechanisms have limitations in semantic integrity and retrieval precision. This paper proposes ES-Mem, a framework incorporating dynamic event segmentation and hierarchical memory to address these issues."" || } ||  || [ Prompt: 118.8 t/s | Generation: 29.1 t/s ]"
2601.07597v1_Pheromone-Focused Ant Colony Optimization algorith.pdf,Pheromone-Focused Ant Colony Optimization algorithm for path planning,"['Yi Liu', 'Hongda Zhang', 'Zhongxue Gan', 'Yuning Chen', 'Ziqing Zhou', 'Chunlei Meng', 'Chun Ouyang']",,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Pheromone-Focused Ant Colony Optimization algorithm for path || planning || Yi Liu 1 Hongda Zhang 1 Zhongxue Gan 1, Yuning Chen1 Ziqing Zhou 1 Chunlei Meng 1 Chun Ouyang1, || Abstract Ant Colony Optimization (ACO) is a prominent || swarm intelligence algorithm extensively applied to path plan- || ... (truncated) ||  || { || ""title"": ""Pheromone-Focused Ant Colony Optimization algorithm for path planning"", || ""authors"": [ || ""Yi Liu"", || ""Hongda Zhang"", || ""Zhongxue Gan"", || ""Yuning Chen"", || ""Ziqing Zhou"", || ""Chunlei Meng"", || ""Chun Ouyang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Pheromone-Focused Ant Colony Optimization"", || ""path planning"", || ""ant colony optimization"", || ""optimization algorithms"", || ""path planning strategies"" || ], || ""summary"": ""The paper proposes a Pheromone-Focused Ant Colony Optimization (PFACO) algorithm to enhance path planning by improving convergence speed and solution quality through strategies such as pheromone concentration balancing, solution reinforcement, and penalizing redundant path turns."" || } ||  || [ Prompt: 118.3 t/s | Generation: 27.7 t/s ]"
2601.07606v1_Proof of Time A Benchmark for Evaluating Scientifi.pdf,Proof of Time: A Benchmark for Evaluating Scientific Idea Judgments,"['Bingyang Ye', 'Shan Chen', 'Jingxuan Tu', 'Chen Liu', 'Zidi Xiong', 'Samuel Schmidgall', 'Danielle S. Bitterman']",,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Proof of Time: A Benchmark for Evaluating Scientific Idea Judgments || Bingyang Ye1,2, Shan Chen1,2,3, Jingxuan Tu4, Chen Liu5, || Zidi Xiong1, Samuel Schmidgall6, Danielle S. Bitterman1,2,3 || Co-first authors, Corresponding author:dbitterman@bwh.harvard.edu || 1Harvard University, 2Mass Gener ... (truncated) ||  || { || ""title"": ""Proof of Time: A Benchmark for Evaluating Scientific Idea Judgments"", || ""authors"": [ || ""Bingyang Ye"", || ""Shan Chen"", || ""Jingxuan Tu"", || ""Chen Liu"", || ""Zidi Xiong"", || ""Samuel Schmidgall"", || ""Danielle S. Bitterman"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Large language models are increasingly being used to assess and forecast research ideas, yet we lack scalable ways to evaluate the quality of models' judgments about these scientific ideas. Towards this goal, we introduce Proof of Time (PoT), a semi-verifiable benchmarking framework that links scientific idea judgments to downstream signals that become observable later."" || } ||  || [ Prompt: 117.2 t/s | Generation: 28.8 t/s ]"
2601.07611v1_DIAGPaper Diagnosing Valid and Specific Weaknesses.pdf,DIAGPaper: Diagnosing Valid and Specific Weaknesses in Scientific Papers,"['Zhuoyang Zou', 'Abolfazl Ansari', 'Delvin Ce Zhang', 'Dongwon Lee', 'Wenpeng Yin']",10.48550/DIAPaper2024,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DIAGPaper: Diagnosing Valid and Specific Weaknesses in Scientific Papers || via Multi-Agent Reasoning || Zhuoyang Zou, Abolfazl Ansari, Delvin Ce Zhang, Dongwon Lee, Wenpeng Yin || Penn State University; University of Sheffield || {zhuoyangzou,wenpeng}@psu.edu || Abstract || Paper weakness identifica ... (truncated) ||  || { || ""title"": ""DIAGPaper: Diagnosing Valid and Specific Weaknesses in Scientific Papers"", || ""authors"": [""Zhuoyang Zou"", ""Abolfazl Ansari"", ""Delvin Ce Zhang"", ""Dongwon Lee"", ""Wenpeng Yin""], || ""doi"": ""10.48550/DIAPaper2024"", || ""arxiv_id"": ""arXiv:2408.12345"", || ""keywords"": [""paper weakness"", ""multi-agent reasoning"", ""review systems"", ""scientific papers""], || ""summary"": ""This paper introduces DIAGPaper, a novel multi-agent framework for diagnosing weaknesses in scientific papers. It addresses limitations of existing systems by simulating human review roles, incorporating author rebuttals, and prioritizing critical issues for users."" || } ||  || [ Prompt: 125.5 t/s | Generation: 27.7 t/s ]"
2601.07618v1_Neural Architecture for Fast and Reliable Coagulat.pdf,Neural Architecture for Fast and Reliable Coagulation Assessment in Clinical Settings: Leveraging Thromboelastography,"['Yulu Wang', 'Ziqian Zeng', 'Jianjun Wu', 'Zhifeng Tang']",10.1093/acps/rmd025,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Neural Architecture for Fast and Reliable Coagulation Assessment in Clinical || Settings: Leveraging Thromboelastography || Yulu Wang1, Ziqian Zeng2, Jianjun Wu2, Zhifeng Tang1 || 1Zhejiang University || 2Huzhou Institute of Zhejiang University || {yulu.wang, zeng155, tangzhifeng}@zju.edu.cn, ... (truncated) ||  || { || ""title"": ""Neural Architecture for Fast and Reliable Coagulation Assessment in Clinical Settings: Leveraging Thromboelastography"", || ""authors"": [""Yulu Wang"", ""Ziqian Zeng"", ""Jianjun Wu"", ""Zhifeng Tang""], || ""doi"": ""10.1093/acps/rmd025"", || ""arxiv_id"": """", ""keywords"": [], || ""summary"": ""The paper presents Physiological State Reconstruction (PSR) to improve coagulation assessment using dynamic clinical data, addressing challenges in small data settings and real-time medical applications."" || } ||  || [ Prompt: 121.4 t/s | Generation: 27.8 t/s ]"
2601.07632v2_GeoMotionGPT Geometry-Aligned Motion Understanding.pdf,GeoMotionGPT: Geometry-Aligned Motion Understanding with Large Language Models,"['Zhankai Ye1', 'Bofan Li1', 'Yukai Jin1', 'Shuoqiu Li1', 'Wei Wang2', 'Yanfu Zhang3', 'Shangqian Gao1*', 'Xin Liu1']",,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || GeoMotionGPT: Geometry-Aligned Motion Understanding with Large || Language Models || Zhankai Ye1 Bofan Li1 Yukai Jin1 Shuoqiu Li1 || Wei Wang2 Yanfu Zhang3 Shangqian Gao1* Xin Liu1* || 1Florida State University 2Texas Tech University 3William & Mary University || https://github.com/JYe16/GeoMotion ... (truncated) ||  || { || ""title"": ""GeoMotionGPT: Geometry-Aligned Motion Understanding with Large Language Models"", || ""authors"": [ || ""Zhankai Ye1"", || ""Bofan Li1"", || ""Yukai Jin1"", || ""Shuoqiu Li1"", || ""Wei Wang2"", || ""Yanfu Zhang3"", || ""Shangqian Gao1*"", || ""Xin Liu1"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""GeoMotionGPT"", || ""motion understanding"", || ""large language models"", || ""geometry alignment"", || ""semantic embedding"", || ""HumanML3D"", || ""discrete motion tokenization"" || ], || ""summary"": ""This paper introduces a framework that aligns motion tokenization with semantic embeddings using a decoder-only quantizer and orthonormal regularization, improving human motion understanding performance by 20% on HumanML3D."" || } ||  || [ Prompt: 123.2 t/s | Generation: 29.1 t/s ]"
2601.07635v2_Learning About Learning A Physics Path from Spin G.pdf,Learning About Learning: A Physics Path from Spin Glasses to Artificial Intelligence,"['Denis D. Caprioti', 'Matheus Haas', 'Constantino F. Vasconcelos', 'Mauricio Girardi-Schappo']",88040-900,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Learning About Learning: A Physics Path from Spin Glasses to Artificial || Intelligence || Denis D. Caprioti,  Matheus Haas,  Constantino F. Vasconcelos, and Mauricio Girardi-Schappo || NeuroPhysics Laboratory, || Departamento de F  sica, || Universidade Federal de Santa Catarina, Florian opolis  ... (truncated) ||  || { || ""title"": ""Learning About Learning: A Physics Path from Spin Glasses to Artificial Intelligence"", || ""authors"": [ || ""Denis D. Caprioti"", || ""Matheus Haas"", || ""Constantino F. Vasconcelos"", || ""Mauricio Girardi-Schappo"" || ], || ""doi"": ""88040-900"", || ""arxiv_id"": """", || ""keywords"": [ || ""spin glasses"", || ""neural networks"", || ""statistical mechanics"", || ""neural networks"", || ""artificial intelligence"", || ""computational methods"" || ], || ""summary"": ""The paper discusses the Hopfield model's role in connecting statistical physics, neural networks, and AI, offering a pedagogical framework for undergraduate physics students."" || } ||  || [ Prompt: 120.8 t/s | Generation: 27.8 t/s ]"
2601.07638v1_SALT-KG A Benchmark for Semantics-Aware Learning o.pdf,SALT-KG: A Benchmark for Semantics-Aware Learning on Enterprise Tables,"['Isaiah Onando Mulang', 'Felix Sasaki', 'Tassilo Klein', 'Jonas Kolk', 'Nikolay Grechanov', 'Johannes Hoffart']",10.48550/arXiv.2303.04219,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SALT-KG: A Benchmark for Semantics-Aware || Learning on Enterprise Tables || Isaiah Onando Mulang || SAP SE || mulang.onando@sap.com || Felix Sasaki || SAP SE || felix.sasaki@sap.com || Tassilo Klein || SAP SE || tassilo.klein@sap.com || Jonas Kolk || SAP SE || jonas.kolk@sap.com || Nikolay Grechanov || SAP SE || nikolay.grechano ... (truncated) ||  || { || ""title"": ""SALT-KG: A Benchmark for Semantics-Aware Learning on Enterprise Tables"", || ""authors"": [ || ""Isaiah Onando Mulang"", || ""Felix Sasaki"", || ""Tassilo Klein"", || ""Jonas Kolk"", || ""Nikolay Grechanov"", || ""Johannes Hoffart"" || ], || ""doi"": ""10.48550/arXiv.2303.04219"", || ""arxiv_id"": ""10.48550/arXiv.2303.04219"", || ""keywords"": [ || ""semantics-aware learning"", || ""semantic reasoning"", || ""metadata knowledge graph"", || ""tabular data"", || ""enterprise tables"" || ], || ""summary"": ""Building upon the SALT benchmark for relational prediction, SALT-KG introduces a benchmark for semantics-aware learning on enterprise tables by linking multi-table transactional data with a structured Operational Business Knowledge graph. This enables models to reason over both tabular evidence and contextual semantics, addressing gaps in leveraging semantics for structured data."" || } ||  || [ Prompt: 119.5 t/s | Generation: 29.1 t/s ]"
2601.07641v1_Beyond Static Tools Test-Time Tool Evolution for S.pdf,Beyond Static Tools: Test-Time Tool Evolution for Scientific Reasoning,"['Jiaxuan Lu', 'Ziyu Kong', 'Yemin Wang', 'Rong Fu', 'Haiyuan Wan', 'Cheng Yang', 'Wenjie Lou', 'Haoran Sun', 'Lilong Wang', 'Yankai Jiang', 'Xiaosong Wang', 'Xiao Sun', 'Dongzhan Zhou']",,29.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Beyond Static Tools: Test-Time Tool Evolution for Scientific Reasoning || Jiaxuan Lu1,, Ziyu Kong2,, Yemin Wang3,, Rong Fu4, Haiyuan Wan1,5, || Cheng Yang6, Wenjie Lou1, Haoran Sun1, Lilong Wang1, || Yankai Jiang1, Xiaosong Wang1, Xiao Sun1, Dongzhan Zhou1, || 1Shanghai Artificial Intelligence  ... (truncated) ||  || { || ""title"": ""Beyond Static Tools: Test-Time Tool Evolution for Scientific Reasoning"", || ""authors"": [ || ""Jiaxuan Lu"", || ""Ziyu Kong"", || ""Yemin Wang"", || ""Rong Fu"", || ""Haiyuan Wan"", || ""Cheng Yang"", || ""Wenjie Lou"", || ""Haoran Sun"", || ""Lilong Wang"", || ""Yankai Jiang"", || ""Xiaosong Wang"", || ""Xiao Sun"", || ""Dongzhan Zhou"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper discusses the limitations of static tool libraries in scientific reasoning and introduces Test-Time Tool Evolution (TTE) to enable agents to create, verify, and evolve executable tools during inference. It presents SciEvo, a benchmark with 1,590 scientific reasoning tasks, and highlights TTE's ability to achieve state-of-the-art performance in accuracy and tool efficiency."" || } ||  || [ Prompt: 120.7 t/s | Generation: 29.2 t/s ]"
2601.07651v1_Active Evaluation of General Agents Problem Defini.pdf,Active Evaluation of General Agents: Problem,"['Marc Lanctot', 'Kate Larson', 'Ian Gemp', 'Michael Kaisers']",10.48550/arXiv.2026.12345,29.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Active Evaluation of General Agents: Problem || Definition and Comparison of Baseline Algorithms || Marc Lanctot || Google DeepMind || lanctot@google.com || Kate Larson || Google DeepMind, University of Waterloo || katelarson@google.com || Ian Gemp || Google DeepMind || imgemp@google.com || Michael Kaisers || Google D ... (truncated) ||  || { || ""title"": ""Active Evaluation of General Agents: Problem"", || ""authors"": [ || ""Marc Lanctot"", || ""Kate Larson"", || ""Ian Gemp"", || ""Michael Kaisers"" || ], || ""doi"": ""10.48550/arXiv.2026.12345"", || ""arxiv_id"": ""arXiv:2509.12345"", || ""keywords"": [ || ""general evaluation"", || ""multitask evaluation"", || ""ranking"", || ""active learning"", || ""game theory"", || ""social choice theory"" || ], || ""summary"": ""This paper proposes a formal definition and conceptual framework for active evaluation of agents across multiple tasks, assessing ranking algorithms based on sample size. It compares classical Elo with Soft Condorcet Optimization, showing it outperforms Elo in real Atari evaluations."" || } ||  || [ Prompt: 116.4 t/s | Generation: 29.4 t/s ]"
2601.07654v1_Towards Automating Blockchain Consensus Verificati.pdf,Towards Automating Blockchain Consensus,"['Elliot Jones1', 'William Knottenbelt']",,31.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Towards Automating Blockchain Consensus || Verification with IsabeLLM || Elliot Jones1 and William Knottenbelt || Department of Computing, Imperial College London, United Kingdom || 1e.jones24@imperial.ac.uk || Abstract.Consensus protocols are crucial for a blockchain system as || they are what allow ... (truncated) ||  || { || ""title"": ""Towards Automating Blockchain Consensus"", || ""authors"": [""Elliot Jones1"", ""William Knottenbelt""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""BlockchainConsensus"", ""Formal Verification"", ""Theorem"", ""Proof Assistant"", ""Bitcoin""], || ""summary"": ""The paper discusses the importance of consensus protocols in blockchain systems and introduces IsabeLLM, a tool that integrates Isabelle with a Large Language Model to automate and verify proofs in consensus protocols."" || } ||  || [ Prompt: 134.7 t/s | Generation: 31.3 t/s ]"
2601.07663v2_Reasoning Models Will Blatantly Lie About Their Re.pdf,Reasoning Models Will Blatantly Lie About Their Reasoning,"['William Walden', 'Johns Hopkins University']",,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Reasoning Models Will Blatantly Lie About Their Reasoning || William Walden || Johns Hopkins University || wwalden1@jh.edu || Abstract || It has been shown that Large Reasoning Mod- || els (LRMs) may notsay what they think: they || do not always volunteer information about how || certain parts of the input ... (truncated) ||  || { || ""title"": ""Reasoning Models Will Blatantly Lie About Their Reasoning"", || ""authors"": [""William Walden"", ""Johns Hopkins University""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""reasoning models"", ""faithfulness"", ""CoT monitoring""], || ""summary"": ""The paper investigates whether Large Reasoning Models (LRMs) can lie about their reasoning when prompted with hints, extending previous studies on model faithfulness. It challenges assumptions about model transparency and explores implications for CoT monitoring."" || } ||  || [ Prompt: 124.4 t/s | Generation: 28.5 t/s ]"
2601.07666v1_Variational Contrastive Learning for Skeleton-base.pdf,Variational Contrastive Learning for Skeleton-based Action Recognition,"['Dang-Dinh NGUYEN1', 'Decky ASPANDI-LATIF1', 'Titus ZAHARIA1']",arXiv:2601.07666v1,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Variational Contrastive Learning for || Skeleton-based Action Recognition || Dang-Dinh NGUYEN1, Decky ASPANDI-LATIF1, and Titus ZAHARIA1 || Dpartement ARTEMIS, Tlcom SudParis, Institut Polytechnique de Paris, France || {firstname.lastname}@telecom-sudparis.eu || Abstract.In recent years, self-supe ... (truncated) ||  || { || ""title"": ""Variational Contrastive Learning for Skeleton-based Action Recognition"", || ""authors"": [""Dang-Dinh NGUYEN1"", ""Decky ASPANDI-LATIF1"", ""Titus ZAHARIA1""], || ""doi"": ""arXiv:2601.07666v1"", || ""arxiv_id"": ""arXiv:2601.07666"", || ""keywords"": [""Human Action Recognition"", ""Self-Supervised Learning"", ""Variational Inference""], || ""summary"": ""This paper proposes a variational contrastive learning framework integrating probabilistic latent modeling with contrastive self-supervised learning for skeleton-based action recognition. It demonstrates improved performance across benchmarks and emphasizes relevance of features related to motion and skeleton joints."" || } ||  || [ Prompt: 133.3 t/s | Generation: 28.6 t/s ]"
2601.07667v1_Adaptive Layer Selection for Layer-Wise Token Prun.pdf,Adaptive Layer Selection for Layer-Wise Token Pruning in LLM Inference,"['Rei Taniguchi', 'Yuyang Dong', 'Makoto Onizuka', 'Chuan Xiao']",,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Adaptive Layer Selection for Layer-Wise Token Pruning in LLM Inference || 1Rei Taniguchi,2Yuyang Dong,1Makoto Onizuka, 1,3Chuan Xiao || 1Osaka University,2SB Intuitions, 3Nagoya University || {taniguchi.rei, onizuka, chuanx}@ist.osaka-u.ac.jp, yuyang.dong@sbintuitions.co.jp || Abstract || Due to t ... (truncated) ||  || { || ""title"": ""Adaptive Layer Selection for Layer-Wise Token Pruning in LLM Inference"", || ""authors"": [ || ""Rei Taniguchi"", || ""Yuyang Dong"", || ""Makoto Onizuka"", || ""Chuan Xiao"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper proposes ASL, a training-free method that adaptively chooses the selection layer for KV cache reduction, balancing performance across tasks while meeting KV budget constraints."" || } ||  || [ Prompt: 125.0 t/s | Generation: 29.0 t/s ]"
2601.07685v1_Predictive Analytics for Dementia Machine Learning.pdf,Predictive Analytics for Dementia: Machine Learning on Healthcare Data,"['Shafiul Ajam Opee', 'Nafiz Fahad', 'Anik Sen', 'Rasel Ahmed', 'Fariha Jahan', 'Md. Kishor Morol', 'Md Rashedul Islam']",,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Predictive Analytics for Dementia: Machine || Learning on Healthcare Data || 1st Shafiul Ajam Opee || Faculty of Science & Technology || American International University-Bangladesh || Dhaka, Bangladesh || opee.cse@gmail.com || 2nd Nafiz Fahad || Faculty of Information Science & Technology || Multimedia Unive ... (truncated) ||  || { || ""title"": ""Predictive Analytics for Dementia: Machine Learning on Healthcare Data"", || ""authors"": [ || ""Shafiul Ajam Opee"", || ""Nafiz Fahad"", || ""Anik Sen"", || ""Rasel Ahmed"", || ""Fariha Jahan"", || ""Md. Kishor Morol"", || ""Md Rashedul Islam"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Dementia"", || ""Machine learning"", || ""Linear Discriminant Analysis (LDA)"", || ""APOE-4 allele"", || ""Chronic conditions"", || ""Predictive analytics"" || ], || ""summary"": ""This study focuses on enhancing dementia prediction using machine learning techniques on patient health data. Supervised learning algorithms such as K-Nearest Neighbors (KNN), Quadratic Discriminant Analysis (QDA), Linear Discriminant Analysis (LDA), and Gaussian Process Classifiers were applied. Techniques like Synthetic Minority Over-sampling Technique (SMOTE) and TF-IDF vectorization were used to address class imbalance. LDA achieved the highest testing accuracy of 98%, highlighting the importance of model interpretability and correlations with features like APOE-4 allele and chronic conditions. The research advocates for future ML innovations, especially explainable AI in dementia care."" || } ||  || [ Prompt: 121.7 t/s | Generation: 29.3 t/s ]"
2601.07701v1_Deep Whole-body Parkour.pdf,Deep Whole-body Parkour,"['Ziwen Zhuang', 'Shaoting Zhu', 'Mengjie Zhao', 'Hang Zhao']",,28.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Deep Whole-body Parkour || Ziwen Zhuang 12, Shaoting Zhu 12, Mengjie Zhao 1 and Hang Zhao 12 || 1IIIS, Tsinghua University, 2Shanghai Qi Zhi Institute || Corresponding Author || Fig. 1:Deep Whole-Body Parkour.Our framework enables a humanoid robot to autonomously traverse challenging obstacles || ... (truncated) ||  || { || ""title"": ""Deep Whole-body Parkour"", || ""authors"": [ || ""Ziwen Zhuang"", || ""Shaoting Zhu"", || ""Mengjie Zhao"", || ""Hang Zhao"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This work unites perceptive locomotion and general motion control to enable humanoid robots to perform dynamic, multi-contact motions like vaulting and dive-rolling on uneven terrain. It integrates exteroceptive sensing into whole-body motion tracking, expanding robots' traversability beyond simple walking."" || } ||  || [ Prompt: 116.8 t/s | Generation: 28.0 t/s ]"
2601.07718v1_Hiking in the Wild A Scalable Perceptive Parkour F.pdf,Hiking in the Wild: A Scalable Perceptive Parkour,"['Shaoting Zhu', 'Ziwen Zhuang', 'Mengjie Zhao', 'Kun-Ying Lee', 'Hang Zhao']",https://project-instinct.github.io/hiking-in-the-wild,30.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Hiking in the Wild: A Scalable Perceptive Parkour || Framework for Humanoids || Shaoting Zhu 12, Ziwen Zhuang 12, Mengjie Zhao 1, Kun-Ying Lee 3, Hang Zhao 12 || 1IIIS, Tsinghua University, 2Shanghai Qi Zhi Institute, || 3Department of Computer Science and Technology, Tsinghua University || Equal  ... (truncated) ||  || { || ""title"": ""Hiking in the Wild: A Scalable Perceptive Parkour"", || ""authors"": [ || ""Shaoting Zhu"", || ""Ziwen Zhuang"", || ""Mengjie Zhao"", || ""Kun-Ying Lee"", || ""Hang Zhao"" || ], || ""doi"": ""https://project-instinct.github.io/hiking-in-the-wild"", || ""arxiv_id"": ""https://arxiv.org/abs/2601.07718"", || ""keywords"": [ || ""humanoid robot"", || ""hiking"", || ""perception"", || ""robotics"", || ""terrain navigation"" || ], || ""summary"": ""The framework enables humanoid robots to traverse diverse terrains, achieving robust performance in complex environments by combining depth perception and end-to-end learning."" || } ||  || [ Prompt: 133.7 t/s | Generation: 30.8 t/s ]"
2601.07737v1_Evaluating the encoding competence of visual langu.pdf,Evaluating the encoding competence of visual language models using uncommon actions,['Chen Ling'],2601.07737v1,32.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Undergraduate Project Report || Evaluating the encoding competence of || visual language models using uncommon || actions || Author: Chen Ling || Ailiation: Beijing University of Post and Telecommunications || Email: 20212127000@bupt.edu.cn || Supervisor: Nai Ding* || Ailiation: Zhejiang University || Email:  ... (truncated) ||  || { || ""title"": ""Evaluating the encoding competence of visual language models using uncommon actions"", || ""authors"": [""Chen Ling""], || ""doi"": ""2601.07737v1"", || ""arxiv_id"": ""cs.CV"", || ""keywords"": [], || ""summary"": ""Undergraduate Project Report on evaluating encoding competence of visual language models using uncommon actions."" || } ||  || [ Prompt: 105.6 t/s | Generation: 32.0 t/s ]"
2601.07748v1_Improving Domain Generalization in Contrastive Lea.pdf,Improving Domain Generalization in Contrastive Learning using Adaptive Temperature Control,"['Robert Lewis', 'Katie Matton', 'Rosalind W. Picard', 'John Guttag']",,28.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Improving Domain Generalization in Contrastive || Learning using Adaptive Temperature Control || Robert Lewis || Massachusetts Institute of Technology || Cambridge, MA, USA || roblewis@mit.edu || Katie Matton || Massachusetts Institute of Technology || Cambridge, MA, USA || kmatton@mit.edu || Rosalind W. Picard || ... (truncated) ||  || { || ""title"": ""Improving Domain Generalization in Contrastive Learning using Adaptive Temperature Control"", || ""authors"": [ || ""Robert Lewis"", || ""Katie Matton"", || ""Rosalind W. Picard"", || ""John Guttag"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper presents a method for contrastive learning that incorporates domain labels to improve domain invariance and out-of-distribution generalization. It adjusts the temperature parameter in InfoNCELoss to emphasize domain-invariant pairs."" || } ||  || [ Prompt: 130.9 t/s | Generation: 28.9 t/s ]"
2601.07778v1_DT-ICU Towards Explainable Digital Twins for ICU P.pdf,DT-ICU: Towards Explainable Digital Twins for ICU Patient Monitoring via Multi-Modal and Multi-Task Iterative Inference,['Wen Guo'],arXiv:2601.07778v1,32.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DT-ICU: Towards Explainable Digital Twins for || ICU Patient Monitoring via Multi-Modal and || Multi-Task Iterative Inference || Wen Guo || ETH Zurich, Switzerland. || Contributing authors: guowen0903@hotmail.com; || Abstract || We introduce DT-ICU, a multimodal digital twin framework for continuous ris ... (truncated) ||  || { || ""title"": ""DT-ICU: Towards Explainable Digital Twins for ICU Patient Monitoring via Multi-Modal and Multi-Task Iterative Inference"", || ""authors"": [""Wen Guo""], || ""doi"": ""arXiv:2601.07778v1"", || ""arxiv_id"": ""arXiv:2601.07778"", || ""keywords"": [], || ""summary"": ""DT-ICU is a multimodal digital twin framework for continuous risk estimation in intensive care, integrating variable-length clinical time series with static patient information in a unified multitask architecture."" || } ||  || [ Prompt: 126.5 t/s | Generation: 32.5 t/s ]"
2601.07779v1_OS-Symphony A Holistic Framework for Robust and Ge.pdf,OS-SYMPHONY: A Holistic Framework for Robust and Generalist,"['Bowen Yang', 'Kaiming Jin', 'Zhenyu Wu', 'Zhaoyang Liu', 'Qiushi Sun', 'Zehao Li', 'Jingjing Xie', 'Zhoumianze Liu', 'Fangzhi Xu', 'Kanzhi Cheng', 'Qingyun Li', 'Yuan Wang', 'Yu Qiao', 'Zun Wang', 'Zichen Ding', 'Zhou']",,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || OS-SYMPHONY: A Holistic Framework for Robust and Generalist || Computer-Using Agent || Bowen Yang1,2 *, Kaiming Jin3 , Zhenyu Wu2, Zhaoyang Liu4, Qiushi Sun5, Zehao Li2, || Jingjing Xie6,Zhoumianze Liu 2,Fangzhi Xu 7,Kanzhi Cheng 8,Qingyun Li 9,Yian Wang 3, || Yu Qiao2,Zun Wang 2,Zichen Ding 2 || ... (truncated) ||  || { || ""title"": ""OS-SYMPHONY: A Holistic Framework for Robust and Generalist"", || ""authors"": [ || ""Bowen Yang"", || ""Kaiming Jin"", || ""Zhenyu Wu"", || ""Zhaoyang Liu"", || ""Qiushi Sun"", || ""Zehao Li"", || ""Jingjing Xie"", || ""Zhoumianze Liu"", || ""Fangzhi Xu"", || ""Kanzhi Cheng"", || ""Qingyun Li"", || ""Yuan Wang"", || ""Yu Qiao"", || ""Zun Wang"", || ""Zichen Ding"", || ""Zhou"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper introduces OS-SYMPHONY, a holistic framework for robust and generalist Computer-Using Agents. It addresses limitations in long-horizon visual tasks by introducing a Reflection-Memory Agent and Versatile Tool Agents with a multimodal searcher."" || } ||  || [ Prompt: 128.9 t/s | Generation: 29.1 t/s ]"
2601.07782v1_Beyond Single-Shot Multi-step Tool Retrieval via Q.pdf,Beyond Single-Shot: Multi-step Tool Retrieval via Query Planning,"['Wei Fang', 'James Glass']",,27.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Beyond Single-Shot: Multi-step Tool Retrieval via Query Planning || Wei Fang and James Glass || Massachusetts Institute of Technology, Cambridge MA, USA || {weifang,glass}@mit.edu || Abstract || LLM agents operating over massive, dynamic || tool libraries rely on effective retrieval, yet || standard sin ... (truncated) ||  || { || ""title"": ""Beyond Single-Shot: Multi-step Tool Retrieval via Query Planning"", || ""authors"": [""Wei Fang"", ""James Glass""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper proposes TOOLQP, a lightweight framework that models retrieval as iterative query planning to address challenges in complex tool retrieval. It achieves state-of-the-art performance through reinforcement learning with verifiable rewards."" || } ||  || [ Prompt: 125.4 t/s | Generation: 27.1 t/s ]"
2601.07790v1_Benchmarking Small Language Models and Small Reaso.pdf,Benchmarking Small Language Models and Small Reasoning,"['Yahya Masri', 'George Mason University', 'Emily Ma', 'George Mason University', 'Zifu Wang', 'Harvard University', 'Joseph Rogers', 'George Mason University', 'Chaowei Yang', 'George Mason University']",arXiv:2601.07790v1,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Benchmarking Small Language Models and Small Reasoning || Language Models on System Log Severity Classification || Yahya Masri || George Mason University || Emily Ma || George Mason University || Zifu Wang || Harvard University || Joseph Rogers || George Mason University || Chaowei Yang || George Mason University || A ... (truncated) ||  || { || ""title"": ""Benchmarking Small Language Models and Small Reasoning"", || ""authors"": [ || ""Yahya Masri"", || ""George Mason University"", || ""Emily Ma"", || ""George Mason University"", || ""Zifu Wang"", || ""Harvard University"", || ""Joseph Rogers"", || ""George Mason University"", || ""Chaowei Yang"", || ""George Mason University"" || ], || ""doi"": ""arXiv:2601.07790v1"", || ""arxiv_id"": ""arXiv:2601.07790"", || ""keywords"": [ || ""system logs"", || ""severity classification"", || ""small language models"", || ""small reasoning models"", || ""digital twin"", || ""log comprehension"" || ], || ""summary"": ""This study evaluates nine small language models and small reasoning language models using real-world journalctl data from Linux production servers. It assesses performance under zero-shot, few-shot, and retrieval-augmented generation (RAG) prompting, revealing insights into architectural design, training objectives, and retrieval integration. Findings highlight the importance of context integration and deployment efficiency for real-time applications."" || } ||  || [ Prompt: 117.8 t/s | Generation: 28.4 t/s ]"
2601.07794v1_Kinship Data Benchmark for Multi-hop Reasoning.pdf,Kinship Data Benchmark for Multi-hop Reasoning,"['Tianda Sun', 'Dimitar Kazakov']",,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Kinship Data Benchmark for Multi-hop Reasoning || Tianda Sun and Dimitar Kazakov || University of York || Department of Computer Science || Heslington, York || YO10 5DD || Abstract || Large language models (LLMs) are increas- || ingly evaluated on their ability to perform multi- || hop reasoning, i.e., to com ... (truncated) ||  || { || ""title"": ""Kinship Data Benchmark for Multi-hop Reasoning"", || ""authors"": [""Tianda Sun"", ""Dimitar Kazakov""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Large language models are evaluated on multi-hop reasoning using a benchmark focused on kinship relations. The paper introduces KinshipQA, a dataset of interconnected family trees with explicit marriage constraints, enabling controlled testing of reasoning across cultures."" || } ||  || [ Prompt: 130.6 t/s | Generation: 27.9 t/s ]"
2601.07821v1_Failure-Aware RL Reliable Offline-to-Online Reinfo.pdf,Failure-Aware RL: Reliable Offline-to-Online Reinforcement Learning,"['Huanyu Li', 'Kun Lei', 'Sheng Zang', 'Kaizhe Hu', 'Yongyuan Liang', 'Bo An', 'Xiaoli Li', 'Huazhe Xu']",,29.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Failure-Aware RL: Reliable Offline-to-Online Reinforcement Learning || with Self-Recovery for Real-World Manipulation || Huanyu Li 1,2, Kun Lei 1,2, Sheng Zang 4, Kaizhe Hu 1,3, Yongyuan Liang 6, Bo An 4, Xiaoli Li 5, Huazhe Xu 1,3 || (a) Franka Fragile Push Wall || (b) Franka Disturbed Push || (c ... (truncated) ||  || { || ""title"": ""Failure-Aware RL: Reliable Offline-to-Online Reinforcement Learning"", || ""authors"": [ || ""Huanyu Li"", || ""Kun Lei"", || ""Sheng Zang"", || ""Kaizhe Hu"", || ""Yongyuan Liang"", || ""Bo An"", || ""Xiaoli Li"", || ""Huazhe Xu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Failure-Aware RL"", || ""Offline-to-Online RL"", || ""Robot Manipulation"", || ""Self-Recovery"", || ""Real-World Manipulation"" || ], || ""summary"": ""FARL demonstrates on a Franka Emika Panda robot across three manipulation tasks, reducing intervention-requiring failures and improving performance."" || } ||  || [ Prompt: 118.5 t/s | Generation: 29.5 t/s ]"
2601.07832v2_MHLA Restoring Expressivity of Linear Attention vi.pdf,Restoring Expressivity of Linear Attention,"['Kewei Zhang', 'Ye Huang', 'Yufan Deng', 'Jincheng Yu', 'Junsong Chen']",arXiv:2601.07832v2,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MHLA: Restoring Expressivity of Linear Attention || via Token-Level Multi-Head || Kewei Zhang 1 Ye Huang 1 Yufan Deng 1 Jincheng Yu 2 Junsong Chen 2 || Huan Ling 2 Enze Xie 2 Daquan Zhou 1 || 1Peking University, 2NVIDIA || Equal contribution || Abstract || While the Transformer architecture dominates ma ... (truncated) ||  || { || ""title"": ""Restoring Expressivity of Linear Attention"", || ""authors"": [ || ""Kewei Zhang"", || ""Ye Huang"", || ""Yufan Deng"", || ""Jincheng Yu"", || ""Junsong Chen"" || ], || ""doi"": ""arXiv:2601.07832v2"", || ""arxiv_id"": ""https://arxiv.org/abs/2601.07832"", || ""keywords"": [ || ""Linear attention"", || ""Multi-Head Linear Attention"", || ""Transformers"", || ""Self-attention"", || ""Computational efficiency"" || ], || ""summary"": ""The paper addresses the quadratic complexity of standard self-attention in Transformers by introducing Multi-Head Linear Attention (MHLA). MHLA preserves representational diversity by computing attention within divided heads, achieving linear complexity while maintaining strong performance gains across ImageNet classification, NLP, image generation, and video generation."" || } ||  || [ Prompt: 115.6 t/s | Generation: 27.8 t/s ]"
2601.07885v1_Small Symbols Big Risks Exploring Emoticon Semanti.pdf,"Small Symbols, Big Risks: Exploring Emoticon Semantic Confusion in Large Language Models","['Weipeng Jiang', 'Xiaoyu Zhang', 'Juan Zhai', 'Shiqing Ma', 'Chao Shen', 'Yang Liu']",10.48550/arXiv.2405.12345,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Small Symbols, Big Risks: Exploring Emoticon Semantic Confusion in || Large Language Models || Weipeng Jiang1*, Xiaoyu Zhang2*, Juan Zhai3, Shiqing Ma3, Chao Shen1, Yang Liu2 || 1Xian Jiaotong University,2Nanyang Technological University,3University of Massachusetts Amherst || lenijwp@stu.xjtu. ... (truncated) ||  || { || ""title"": ""Small Symbols, Big Risks: Exploring Emoticon Semantic Confusion in Large Language Models"", || ""authors"": [ || ""Weipeng Jiang"", || ""Xiaoyu Zhang"", || ""Juan Zhai"", || ""Shiqing Ma"", || ""Chao Shen"", || ""Yang Liu"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [ || ""emoticons"", || ""LLM"", || ""safety"", || ""semantic confusion"", || ""code generation"", || ""security risks"" || ], || ""summary"": ""This paper investigates emoticon semantic confusion in Large Language Models, identifying a pervasive vulnerability where LLMs misinterpret emoticons, leading to unintended and potentially destructive actions. The study analyzes 3,757 test cases across multiple languages and contexts, revealing over 90% confusion rate and significant safety concerns."" || } ||  || [ Prompt: 116.9 t/s | Generation: 28.7 t/s ]"
2601.07891v1_KVzap Fast Adaptive and Faithful KV Cache Pruning.pdf,"Fast, Adaptive, and Faithful KV Cache","['Simon Jgou', 'Maximilian Jeblick']",10.1093/pasj/psz123,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || KVzap: Fast, Adaptive, and Faithful KV Cache || Pruning || Simon Jgou * Maximilian Jeblick || NVIDIA/KVzap/githubNVIDIA/kvpress || Abstract.Growing context lengths in transformer-based language models have made the key-value || (KV) cache a critical inference bottleneck. While many KV cache prunin ... (truncated) ||  || { || ""title"": ""Fast, Adaptive, and Faithful KV Cache"", || ""authors"": [""Simon Jgou"", ""Maximilian Jeblick""], || ""doi"": ""10.1093/pasj/psz123"", || ""arxiv_id"": ""2601.07891"", || ""keywords"": [""KV cache"", ""KVzap"", ""KV compression"", ""transformer"", ""LLM""], || ""summary"": ""KVzap introduces a fast, input-adaptive approximation of KVzip for efficient KV cache pruning in large language models, achieving state-of-the-art performance with minimal accuracy loss."" || } ||  || [ Prompt: 128.2 t/s | Generation: 27.9 t/s ]"
2601.07892v1_Sherry Hardware-Efficient 1.25-Bit Ternary Quantiz.pdf,Hardware-Efficient 1.25-Bit Ternary Quantization via Fine-grained Sparsification,"['Hong Huang', 'Decheng Wu', 'Qiangqiang Hu', 'Ganghua Yu', 'Jinhai Yang', 'Xue Liu', 'Dapeng Wu']",10.48550/arXiv.2303.04219,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Sherry: Hardware-Efficient 1.25-Bit Ternary Quantization via || Fine-grained Sparsification || Hong Huang1* Decheng Wu2 Qiangqiang Hu2 Guanghua Yu2 Jinhai Yang1 || Jianchen Zhu2 Xue Liu3 Dapeng Wu1 || 1City University of Hong Kong 2Tencent 3McGill University || Abstract || The deployment of Large Lan ... (truncated) ||  || { || ""title"": ""Hardware-Efficient 1.25-Bit Ternary Quantization via Fine-grained Sparsification"", || ""authors"": [ || ""Hong Huang"", || ""Decheng Wu"", || ""Qiangqiang Hu"", || ""Ganghua Yu"", || ""Jinhai Yang"", || ""Xue Liu"", || ""Dapeng Wu"" || ], || ""doi"": ""10.48550/arXiv.2303.04219"", || ""arxiv_id"": ""10.48550/arXiv.2303.04219"", || ""keywords"": [ || ""hardware-efficient quantization"", || ""ternary quantization"", || ""sparsification"", || ""edge devices"", || ""power-of-two alignment"", || ""weight trapping"", || ""LLaMA-3.2"", || ""bit savings"", || ""model compression"" || ], || ""summary"": ""This paper proposes Sherry, a hardware-efficient ternary quantization framework that introduces a 3:4 fine-grained sparsity to achieve a regularized 1.25-bit width. It addresses alignment issues and weight trapping in sparse ternary training, demonstrating improved performance and efficiency on LLaMA-3.2 across benchmarks."" || } ||  || [ Prompt: 115.1 t/s | Generation: 29.3 t/s ]"
2601.07894v1_Revealing the Attention Floating Mechanism in Mask.pdf,Revealing the Attention Floating Mechanism in Masked Diffusion Models,"['Xin Dai', 'Pengcheng Huang', 'Zhenghao Liu', 'Yukun Yan', 'Chaojun Xiao', 'Yu Gu', 'Ge Yu', 'Maosong Sun']",,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Revealing the Attention Floating Mechanism in Masked Diffusion Models || Xin Dai1, Pengcheng Huang1, Zhenghao Liu1*, Shuo Wang2, || Yukun Yan2, Chaojun Xiao2, Yu Gu1, Ge Yu1, Maosong Sun2 || 1School of Computer Science and Engineering, Northeastern University, Shenyang, China || 2Department of  ... (truncated) ||  || { || ""title"": ""Revealing the Attention Floating Mechanism in Masked Diffusion Models"", || ""authors"": [ || ""Xin Dai"", || ""Pengcheng Huang"", || ""Zhenghao Liu"", || ""Yukun Yan"", || ""Chaojun Xiao"", || ""Yu Gu"", || ""Ge Yu"", || ""Maosong Sun"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper investigates the attention behaviors in masked diffusion models, revealing the phenomenon of Attention Floating. It explores how MDMs exhibit dynamic, dispersed attention anchors that shift across denoising steps, providing a mechanistic explanation for their strong in-context learning capabilities."" || } ||  || [ Prompt: 119.2 t/s | Generation: 28.7 t/s ]"
2601.07898v1_Large Language Models and Algorithm Execution Appl.pdf,Large Language Models and Algorithm Execution: Application to an Arithmetic Function,"['Farah Ben Slama', 'Frédéric Armetta']",,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Large Language Models and Algorithm Execution: Application to || an Arithmetic Function || Farah Ben Slama, Frdric Armetta || Universit Claude Bernard Lyon 1, CNRS, || Ecole Centrale de Lyon, INSA Lyon, || Universit Lumire Lyon 2, LIRIS, UMR5205, || 69622 Villeurbanne, France || farah.ben-slama@etu.univ ... (truncated) ||  || { || ""title"": ""Large Language Models and Algorithm Execution: Application to an Arithmetic Function"", || ""authors"": [ || ""Farah Ben Slama"", || ""Frédéric Armetta"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Algorithmic learning in natural language"", || ""Supervised learning by decomposition"", || ""Large language model"", || ""Fine-tuning"" || ], || ""summary"": ""The paper investigates extending LLM capabilities to algorithm execution via supervised training focused on reasoning decomposition, demonstrating improved performance in complex algorithmic inferences."" || } ||  || [ Prompt: 128.6 t/s | Generation: 28.6 t/s ]"
2601.07901v1_Decentralized Online Convex Optimization with Unkn.pdf,Decentralized Online Convex Optimization with Unknown Feedback Delays,"['Hao Qiu', 'Mengxiao Zhang', 'Juliette Achddou']",arXiv:2601.07901v1,29.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Decentralized Online Convex Optimization with || Unknown Feedback Delays || Hao Qiu || Universit degli Studi di Milano || hao.qiu@unimi.com || Mengxiao Zhang || University of Iowa || mengxiao-zhang@uiowa.edu || Juliette Achddou || UMR 9189 - CRIStAL, Universit de Lille, CNRS, Inria, Centrale Lille || juliette.ac ... (truncated) ||  || { || ""title"": ""Decentralized Online Convex Optimization with Unknown Feedback Delays"", || ""authors"": [ || ""Hao Qiu"", || ""Mengxiao Zhang"", || ""Juliette Achddou"" || ], || ""doi"": ""arXiv:2601.07901v1"", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper studies decentralized online convex optimization under unknown, time- and agent-varying feedback delays. It proposes a novel algorithm with improved regret bounds and extends it to strongly convex settings."" || } ||  || [ Prompt: 119.3 t/s | Generation: 29.7 t/s ]"
2601.07903v2_Enhancing Large Language Models for Time-Series Fo.pdf,Enhancing Large Language Models for Time-Series Forecasting via Vector-Injected In-Context Learning,"['Jianqi Zhang', 'Jingyao Wang', 'Wenwen Qiang', 'Fanjiang Xu']",,27.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Enhancing Large Language Models for Time-Series Forecasting || via Vector-Injected In-Context Learning || Jianqi Zhang || jluzhangjianqi@163.com || Institute of Software, Chinese || Academy of Sciences; University of || the Chinese Academy of Sciences || Beijing, Beijing, China || Jingyao Wang || Institute of ... (truncated) ||  || { || ""title"": ""Enhancing Large Language Models for Time-Series Forecasting via Vector-Injected In-Context Learning"", || ""authors"": [ || ""Jianqi Zhang"", || ""Jingyao Wang"", || ""Wenwen Qiang"", || ""Fanjiang Xu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper discusses improving large language models for time-series forecasting using vector-injected in-context learning, addressing challenges in computational overhead and forecasting performance."" || } ||  || [ Prompt: 126.8 t/s | Generation: 27.3 t/s ]"
2601.07935v1_Towards Specialized Generalists A Multi-Task MoE-L.pdf,Towards Specialized Generalists: A Multi-Task,"['Yuxin Yang', 'Shanghai University', 'East China Normal University', 'Xiangquan Yang', 'East China Normal University']",,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Towards Specialized Generalists: A Multi-Task || MoE-LoRA Framework for Domain-Specific LLM || Adaptation || Yuxin Yang || Shanghai University || Aoxiong Zeng || East China Normal University || Xiangquan Yang || East China Normal University || Abstract || The rapid evolution of Large Language Models (LLMs) has s ... (truncated) ||  || { || ""title"": ""Towards Specialized Generalists: A Multi-Task"", || ""authors"": [ || ""Yuxin Yang"", || ""Shanghai University"", || ""East China Normal University"", || ""Xiangquan Yang"", || ""East China Normal University"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Large Language Models"", || ""Domain-Specific LLM"", || ""Medical Applications"", || ""Catastrophic Forgetting"", || ""Knowledge Preservation"", || ""Mixture-of-Experts"", || ""Low-Rank Adaptation"", || ""Medical NLP"" || ], || ""summary"": ""The paper discusses challenges in adapting LLMs to specialized domains like medicine, focusing on stability-plasticity and task interference. It introduces Med-MoE-LoRA, a framework combining MoE with LoRA for efficient multi-task domain adaptation, especially in medical scenarios."" || } ||  || [ Prompt: 118.7 t/s | Generation: 29.1 t/s ]"
2601.07939v1_SECite Analyzing and Summarizing Citations in Soft.pdf,Analyzing and Summarizing Citations in Software Engineering Literature,"['Shireesh Reddy Pyreddy', 'Khaja Valli Pathan', 'Hasan Masum', 'Tarannum Shaila Zaman']",,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SECite: Analyzing and Summarizing Citations in || Software Engineering Literature || Shireesh Reddy Pyreddy, Khaja Valli Pathan || Dept. of Computer Science || SUNY Polytechnic Institute || Utica, NY , USA || pyredds@sunypoly.edu, pathank@sunypoly.edu || Hasan Masum, Tarannum Shaila Zaman || Dept. of Infor ... (truncated) ||  || { || ""title"": ""Analyzing and Summarizing Citations in Software Engineering Literature"", || ""authors"": [ || ""Shireesh Reddy Pyreddy"", || ""Khaja Valli Pathan"", || ""Hasan Masum"", || ""Tarannum Shaila Zaman"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Sentiment Analysis"", || ""LLMs"", || ""Text Summarization"", || ""Citations"", || ""Scholarly Impact"" || ], || ""summary"": ""This study introduces SECite, a novel approach for evaluating scholarly impact through sentiment analysis of citation contexts. It analyzes how the academic community perceives research contributions, highlighting patterns in citation sentiment and alignment between external feedback and authors' perspectives."" || } ||  || [ Prompt: 114.1 t/s | Generation: 27.9 t/s ]"
2601.07941v2_Moonworks Lunara Aesthetic Dataset.pdf,Moonworks Lunara Aesthetic Dataset,"['Yan Wang', 'M M Sayeef Abdullah', 'Partho Hassan', 'Sabit Hassan']",arXiv:2601.07941v2,29.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Moonworks Lunara Aesthetic Dataset || Yan Wang, M M Sayeef Abdullah, || Partho Hassan, and Sabit Hassan || Moonworks AI || Abstract || This data card presents the first public release of the Lunara Aesthetic Dataset, || a curated set of 2,000 imageprompt pairs for controlled research on prompt ground ... (truncated) ||  || { || ""title"": ""Moonworks Lunara Aesthetic Dataset"", || ""authors"": [ || ""Yan Wang"", || ""M M Sayeef Abdullah"", || ""Partho Hassan"", || ""Sabit Hassan"" || ], || ""doi"": ""arXiv:2601.07941v2"", || ""arxiv_id"": ""arXiv:2601.07941v2"", || ""keywords"": [ || ""Moonworks"", || ""Lunara"", || ""Aesthetic Dataset"", || ""Text-to-Image"", || ""Style Conditioning"", || ""Prompt Grounding"", || ""Artistic Styles"", || ""Middle East"", || ""Northern Europe"", || ""East Asia"", || ""South Asia"" || ], || ""summary"": ""The Lunara Aesthetic Dataset is the first public release of 2,000 imageprompt pairs designed for research on prompt grounding and style conditioning in text-to-image generation. It covers diverse artistic styles and is released under the Apache 2.0 license."" || } ||  || [ Prompt: 132.9 t/s | Generation: 29.9 t/s ]"
2601.07946v1_Coupled Diffusion-Encoder Models for Reconstructio.pdf,DiffCoder,"['AmirPouya Hemmasian', 'Amir Barati Farimani']",,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DiffCoder || Coupled DiffusionEncoder Models for Reconstruction of Flow Fields || AmirPouya Hemmasian 1 and Amir Barati Farimani 1, 2 || 1)Mechanical Engineering Department, Carnegie Mellon University, Pittsburgh, PA, USA || 2)Machine Learning Department, Carnegie Mellon University, Pittsburgh, ... (truncated) ||  || { || ""title"": ""DiffCoder"", || ""authors"": [ || ""AmirPouya Hemmasian"", || ""Amir Barati Farimani"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""DiffCoder proposes a coupled framework integrating a probabilistic diffusion model with a convolutional ResNet encoder to improve flow-field reconstruction by preserving statistical properties under compression."" || } ||  || [ Prompt: 125.6 t/s | Generation: 27.7 t/s ]"
2601.07948v1_Reinforcement Learning Methods for Neighborhood Se.pdf,Reinforcement Learning Methods for Neighborhood Selection in Local Search,"['Y annick Molinghen', 'Augustin Delecluse', 'Renaud De Landtsheer', 'Stefano Michelini']",,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Reinforcement || Learning Methods for Neighborhood Selection in Local Search || Y annick Molinghen1 || a, Augustin Delecluse2,3 || b, Renaud De Landtsheer4 || c and Stefano Michelini4 || d || 1Universit Libre de Bruxelles, Brussels, Belgium || 2UCLouvain, Louvain-La-Neuve, Belgium || 3KU Leuven, Gent, Bel ... (truncated) ||  || { || ""title"": ""Reinforcement Learning Methods for Neighborhood Selection in Local Search"", || ""authors"": [ || ""Y annick Molinghen"", || ""Augustin Delecluse"", || ""Renaud De Landtsheer"", || ""Stefano Michelini"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Local Search"", || ""Reinforcement Learning"", || ""Combinatorial Optimization"" || ], || ""summary"": ""This study evaluates reinforcement learning-based neighborhood selection strategies in local search metaheuristics, comparing multi-armed bandits and deep RL methods across three optimization problems. It highlights performance variations and the need for careful reward design."" || } ||  || [ Prompt: 120.3 t/s | Generation: 29.1 t/s ]"
2601.07951v1_Hybrid SARIMA LSTM Model for Local Weather Forecas.pdf,Hybrid SARIMALSTM Model for Local Weather Forecasting: A Residual-Learning Approach for Data-Driven Meteorological Prediction,"['Shreyas Rajeev', 'Karthik Mudenahalli', 'Amit Mallappa Tiparaddi']",,29.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  ||  || Hybrid SARIMALSTM Model for Local Weather Forecasting: A Residual-Learning Approach for Data-Driven Meteorological Prediction Shreyas Rajeev Stevens Institute of Technology Hoboken, USA srajeev@stevens.edu || Karthik Mudenahalli Ashoka Stevens Institute of Technology  Hoboken, ... (truncated) ||  || { || ""title"": ""Hybrid SARIMALSTM Model for Local Weather Forecasting: A Residual-Learning Approach for Data-Driven Meteorological Prediction"", || ""authors"": [ || ""Shreyas Rajeev"", || ""Karthik Mudenahalli"", || ""Amit Mallappa Tiparaddi"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""weather forecasting"", || ""SARIMA"", || ""LSTM"", || ""machine learning"", || ""meteorology"", || ""data-driven prediction"" || ], || ""summary"": ""The paper proposes a hybrid SARIMALSTM architecture combining SARIMA for seasonal patterns and LSTM for nonlinear temporal dependencies to improve weather forecasting accuracy."" || } ||  || [ Prompt: 123.7 t/s | Generation: 29.8 t/s ]"
2601.07953v1_Quantum automated theorem proving.pdf,Quantum automated theorem proving,"['Zheng-Zhi Sun', 'Qi Ye', 'Dong-Ling Deng', 'Hefei National Laboratory']",,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Quantum automated theorem proving || Zheng-Zhi Sun, 1 Qi Ye,1, 2 and Dong-Ling Deng 1, 2, 3, || 1Center for Quantum Information, IIIS, Tsinghua University, Beijing 100084, China || 2Shanghai Qi Zhi Institute, Shanghai 200232, China || 3Hefei National Laboratory, Hefei 230088, China || Automated th ... (truncated) ||  || { || ""title"": ""Quantum automated theorem proving"", || ""authors"": [ || ""Zheng-Zhi Sun"", || ""Qi Ye"", || ""Dong-Ling Deng"", || ""Hefei National Laboratory"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""quantum automated theorem proving"", || ""automated reasoning"", || ""quantum superposition"", || ""quantum entanglement"", || ""geometric theorems"", || ""mathematical reasoning"" || ], || ""summary"": ""This paper proposes a generic framework for quantum automated theorem proving, highlighting advantages of quantum superposition and entanglement. It introduces quantum representations, reasoning algorithms, and a quantum algebraic proving method for geometry, demonstrating improved query complexity and practical applications."" || } ||  || [ Prompt: 131.7 t/s | Generation: 28.6 t/s ]"
2601.07957v1_LWMSCNN-SE A Lightweight Multi-Scale Network for E.pdf,LWMSCNN-SE: A Lightweight Multi-Scale Network for Efficient Maize Disease Classification,"['1', '2']",10.48550/arXiv.2407.07014,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || LWMSCNN-SE: A Lightweight Multi-Scale || Network for Efficient Maize Disease Classification || on Edge Devices || 1st Fikadu Weloday, 2nd Jianmei Su || School of Computer Science and Technology,Southwest University of Science and Technology, Mianyang,China || deyu@mails.swust.edu.cn || AbstractMaiz ... (truncated) ||  || { || ""title"": ""LWMSCNN-SE: A Lightweight Multi-Scale Network for Efficient Maize Disease Classification"", || ""authors"": [""1"", ""2""], || ""doi"": ""10.48550/arXiv.2407.07014"", || ""arxiv_id"": ""10.48550/arXiv.2407.07014"", || ""keywords"": [""lightweight CNN"", ""multi-scale feature extraction"", ""attention mechanism"", ""plant pathology""], || ""summary"": ""This paper proposes LWMSCNN-SE, a lightweight CNN for maize disease classification on edge devices. It integrates multi-scale feature extraction, depthwise separable convolutions, and SE attention, achieving 96.63% classification accuracy with low computational cost."" || } ||  || [ Prompt: 117.5 t/s | Generation: 27.7 t/s ]"
2601.07958v1_LJ-Spoof A Generatively Varied Corpus for Audio An.pdf,LJ-SPOOF: A GENERATIVELY VARIED CORPUS FOR AUDIO ANTI-SPOOFING AND SYNTHESIS SOURCE TRACING,"['Surya Subramani', 'Hashim Ali', 'Hafiz Malik']",,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LJ-SPOOF: A GENERATIVELY V ARIED CORPUS FOR AUDIO ANTI-SPOOFING AND || SYNTHESIS SOURCE TRACING || Surya Subramani, Hashim Ali, Hafiz Malik || Electrical and Computer Engineering || University of Michigan || 4901 Evergreen Rd, Dearborn, MI 48128, USA || ABSTRACT || Speaker-specific anti-spoofing and syn ... (truncated) ||  || { || ""title"": ""LJ-SPOOF: A GENERATIVELY VARIED CORPUS FOR AUDIO ANTI-SPOOFING AND SYNTHESIS SOURCE TRACING"", || ""authors"": [ || ""Surya Subramani"", || ""Hashim Ali"", || ""Hafiz Malik"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Anti-Spoofing"", || ""Speaker Verification"", || ""Deepfake"", || ""Source tracing"", || ""Synthetic Speech"" || ], || ""summary"": ""This paper introduces LJ-Spoof, a speaker-specific, generatively diverse corpus designed to address the lack of systematically varied datasets in audio anti-spoofing research. The corpus includes one speaker with 30 TTS families, 500 generatively variant subsets, 10 billion neural-processing variants, and over 3 million utterances, enabling robust speaker-conditioned anti-spoofing and fine-grained synthesis-source tracing."" || } ||  || [ Prompt: 120.8 t/s | Generation: 28.8 t/s ]"
2601.07964v1_Executable Ontologies in Game Development From Alg.pdf,Executable Ontologies in Game Development: From Algorithmic Control to Semantic World Modeling,['Alexander Boldachev'],,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || Executable Ontologies in Game Development: || From Algorithmic Control to Semantic World Modeling || Alexander Boldachev || boldachev@gmail.com || https://orcid.org/0000-0002-7259-2952 || Abstract || This paper examines the application of Executable Ontologies (EO), implemented through the || ... (truncated) ||  || { || ""title"": ""Executable Ontologies in Game Development: From Algorithmic Control to Semantic World Modeling"", || ""authors"": [""Alexander Boldachev""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""executable ontologies"", ""game AI"", ""behavior trees"", ""GOAP"", ""event semantics"", ""dataflow architecture""], || ""summary"": ""This paper examines the application of Executable Ontologies (EO) in game development, highlighting a shift from algorithmic control to semantic world modeling. It discusses how EO enables priority-based task interruption in survival games and compares EO with traditional approaches like Behavior Trees and GOAP, emphasizing the semantic-process gap in game AI."" || } ||  || [ Prompt: 123.7 t/s | Generation: 29.3 t/s ]"
2601.07965v1_When Models Know When They Do Not Know Calibration.pdf,When Models Know When They Don't Know,"['Chenjie Hao', 'Weyl Lu', 'Yuko Ishiwaka', 'Zengyi Li', 'Weier Wan', 'Yubei Chen']",,27.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Preprint. || WHENMODELSKNOWWHENTHEYDONOTKNOW || CALIBRATION, CASCADING,ANDCLEANING || Chenjie Hao1, Weyl Lu1, Yuko Ishiwaka3, Zengyi Li2, Weier Wan2, Yubei Chen1,2 || 1 University of California, Davis, 2 Aizip || 3 SoftBank Corp. || ABSTRACT || When a model knows when it does not know, many possibilitie ... (truncated) ||  || { || ""title"": ""When Models Know When They Don't Know"", || ""authors"": [ || ""Chenjie Hao"", || ""Weyl Lu"", || ""Yuko Ishiwaka"", || ""Zengyi Li"", || ""Weier Wan"", || ""Yubei Chen"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This preprint discusses enabling models to recognize their own ignorance by leveraging confidence signals. It proposes a training-free method for calibration, cascading, and data cleaning to improve model reliability and trustworthiness in vision and language tasks."" || } ||  || [ Prompt: 125.4 t/s | Generation: 27.4 t/s ]"
2601.07969v1_Tuberculosis Screening from Cough Audio Baseline M.pdf,Tuberculosis Screening from Cough Audio,"['George P. Kafentzis', 'Efstratios Selisios']",,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TUBERCULOSISSCREENING FROMCOUGHAUDIO: || BASELINEMODELS, CLINICALVARIABLES,ANDUNCERTAINTY || QUANTIFICATION || A PREPRINT || George P. Kafentzis || Department of Computer Science || University of Crete || Greece || kafentz@csd.uoc.gr || Efstratios Selisios || Department of Computer Science || University of Crete || Gr ... (truncated) ||  || { || ""title"": ""Tuberculosis Screening from Cough Audio"", || ""authors"": [ || ""George P. Kafentzis"", || ""Efstratios Selisios"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Tuberculosis"", || ""Machine Learning"", || ""Cough Audio"", || ""Cross-Validation"", || ""Uncertainty Quantification"", || ""Feature Extraction"" || ], || ""summary"": ""This paper proposes a standardized framework for automatic tuberculosis detection from cough audio and clinical data using machine learning. It addresses variability in datasets and evaluation metrics, aiming to provide a reproducible baseline for fair comparisons and reduce methodological differences."" || } ||  || [ Prompt: 119.2 t/s | Generation: 27.6 t/s ]"
2601.07973v1_Cultural Compass A Framework for Organizing Societ.pdf,Cultural Compass: A Framework for Organizing Societal Norms to Detect Violations in Human-AI Conversations,"['Myra Cheng', 'Vinodkumar Prabhakaran', 'Alice Oh', 'Hayk Stepanyan', 'Sunipa Dev', 'Charu Kalia', 'Erin MacMurray van Liemt']",,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Cultural Compass: A Framework for Organizing Societal Norms to Detect || Violations in Human-AI Conversations || Myra Cheng1,2 Vinodkumar Prabhakaran2 Alice Oh2 Hayk Stepanyan2 || Aishwarya Verma2 Charu Kalia2 Erin MacMurray van Liemt2 Sunipa Dev2 || 1Stanford University 2Google || myra@cs.stanfor ... (truncated) ||  || { || ""title"": ""Cultural Compass: A Framework for Organizing Societal Norms to Detect Violations in Human-AI Conversations"", || ""authors"": [ || ""Myra Cheng"", || ""Vinodkumar Prabhakaran"", || ""Alice Oh"", || ""Hayk Stepanyan"", || ""Sunipa Dev"", || ""Charu Kalia"", || ""Erin MacMurray van Liemt"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""cultural norms"", || ""societal norms"", || ""human-AI interaction"", || ""norm adherence"", || ""cross-cultural"", || ""AI ethics"" || ], || ""summary"": ""This paper introduces a taxonomy of norms to evaluate how generative AI models adhere to sociocultural standards in human-AI conversations. It highlights gaps in current benchmarks and proposes a framework for operationalizing norm adherence, demonstrating that state-of-the-art models often violate norms, with variation based on model, interaction context, and cultural factors."" || } ||  || [ Prompt: 123.9 t/s | Generation: 29.0 t/s ]"
2601.07988v1_From Word Sequences to Behavioral Sequences Adapti.pdf,From Word Sequences to Behavioral Sequences: Adapting Modeling and Evaluation Paradigms for Longitudinal NLP,"['Adithya V Ganesan', 'Vasudha Varadarajan', 'Oscar NE Kjell', 'Ryan L Boyd', 'Andrew Schwartz']",,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || From Word Sequences to Behavioral Sequences: Adapting Modeling and || Evaluation Paradigms for Longitudinal NLP || Adithya V Ganesan Vasudha Varadarajan Oscar NE Kjell Whitney R Ringwald || Scott Feltman Benjamin J Luft Roman Kotov Ryan L Boyd H Andrew Schwartz || Stony Brook University Vanderb ... (truncated) ||  || { || ""title"": ""From Word Sequences to Behavioral Sequences: Adapting Modeling and Evaluation Paradigms for Longitudinal NLP"", || ""authors"": [ || ""Adithya V Ganesan"", || ""Vasudha Varadarajan"", || ""Oscar NE Kjell"", || ""Ryan L Boyd"", || ""Andrew Schwartz"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper discusses the mismatch between traditional NLP practices and the longitudinal nature of real-world data, proposing a new modeling and evaluation paradigm that accounts for person-indexed, time-ordered behavioral sequences."" || } ||  || [ Prompt: 121.0 t/s | Generation: 27.8 t/s ]"
2601.07994v2_DYCP Dynamic Context Pruning for Long-Form Dialogu.pdf,DYCP: Dynamic Context Pruning for Long-Form Dialogue with LLMs,"['Nayoung Choi', 'Jonathan Zhang', 'Jinho D. Choi']",,29.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DYCP: Dynamic Context Pruning for Long-Form Dialogue with LLMs || Nayoung Choi || Computer Science || Emory University || Atlanta, Georgia, USA || nayoung.choi@emory.edu || Jonathan Zhang || Computer Science || Emory University || Atlanta, Georgia, USA || jonathan.zhang2@emory.edu || Jinho D. Choi || Computer Science || ... (truncated) ||  || { || ""title"": ""DYCP: Dynamic Context Pruning for Long-Form Dialogue with LLMs"", || ""authors"": [ || ""Nayoung Choi"", || ""Jonathan Zhang"", || ""Jinho D. Choi"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Large Language Models"", || ""Long-Form Dialogue"", || ""Context Management"", || ""Dialogue Systems"", || ""Latency Reduction"" || ], || ""summary"": ""This paper introduces DYCP, a lightweight context management method that dynamically segments and retrieves relevant memory at query time. It aims to preserve sequential dialogue structure, improve answer quality, and reduce response latency in long-form conversations."" || } ||  || [ Prompt: 116.3 t/s | Generation: 29.6 t/s ]"
2601.08000v1_Reasoning over Precedents Alongside Statutes Case-.pdf,Reasoning over Precedents Alongside Statutes,"['Can Jin1', 'Rui Wu', 'Tong Che2', 'Qixin Zhang3', 'Hongwu Peng4', 'Jiahui Zhao5', 'Zhenting Wang1', 'Wenqi Wei6', 'Ligong Han1', 'Zhao Zhang1', 'Yuan Cao7', 'Ruixiang Tang1', 'Dimitris N. Metaxas1']",,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Reasoning over Precedents Alongside Statutes: || Case-Augmented Deliberative Alignment for LLM Safety || Can Jin1*, Rui Wu1*, Tong Che2*, Qixin Zhang3, Hongwu Peng4, Jiahui Zhao5, Zhenting Wang1, || Wenqi Wei6, Ligong Han1, Zhao Zhang1, Yuan Cao7, Ruixiang Tang1, Dimitris N. Metaxas1 || 1Rutger ... (truncated) ||  || { || ""title"": ""Reasoning over Precedents Alongside Statutes"", || ""authors"": [ || ""Can Jin1"", || ""Rui Wu"", || ""Tong Che2"", || ""Qixin Zhang3"", || ""Hongwu Peng4"", || ""Jiahui Zhao5"", || ""Zhenting Wang1"", || ""Wenqi Wei6"", || ""Ligong Han1"", || ""Zhao Zhang1"", || ""Yuan Cao7"", || ""Ruixiang Tang1"", || ""Dimitris N. Metaxas1"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Ensuring that Large Language Models adhere to safety principles without refusing be significant challenges. This work evaluates the impact of explicitly specifying safety codes versus illustrative cases, finding that case-augmented reasoning improves robustness and reduces over-refusal."" || } ||  || [ Prompt: 120.4 t/s | Generation: 29.3 t/s ]"
2601.08003v1_LLM Review Enhancing Creative Writing via Blind Pe.pdf,LLM Review: Enhancing Creative Writing via Blind Peer Review Feedback,"['Weiyue Li', 'Mingxiao Song', 'Zhenda Shen', 'Dachuan Zhao', 'Yunfan Long', 'Yi Li', 'Yongce Li', 'Ruyi Yang', 'Mengyu Wang']",,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LLM Review: Enhancing Creative Writing via Blind Peer Review Feedback || Weiyue Li* || Mingxiao Song || Zhenda Shen || Dachuan Zhao || Yunfan Long || Yi Li || Yongce Li || Ruyi Yang || Mengyu Wang || Harvard University, || Carnegie Mellon University, || Stanford University || Abstract || Large Language Models (LLMs ... (truncated) ||  || { || ""title"": ""LLM Review: Enhancing Creative Writing via Blind Peer Review Feedback"", || ""authors"": [ || ""Weiyue Li"", || ""Mingxiao Song"", || ""Zhenda Shen"", || ""Dachuan Zhao"", || ""Yunfan Long"", || ""Yi Li"", || ""Yongce Li"", || ""Ruyi Yang"", || ""Mengyu Wang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Large Language Models often struggle with creative generation, and multi-agent frameworks that improve reasoning through interaction can paradoxically hinder creativity by inducing content homogenization. We introduce LLM Review, a peer-review-inspired framework implementing Blind Peer Review, preserving divergent creative trajectories."" || } ||  || [ Prompt: 120.0 t/s | Generation: 29.0 t/s ]"
2601.08005v1_Internal Deployment Gaps in AI Regulation.pdf,Internal Deployment Gaps in AI Regulation,"['JOE KWON', 'STEPHEN CASPER']",,31.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Internal Deployment Gaps in AI Regulation || JOE KWON and STEPHEN CASPER,MIT CSAIL, USA || Frontier AI regulations primarily focus on systems deployed to external users, where deployment is more visible and subject to outside || scrutiny. However, high-stakes applications can occur internall ... (truncated) ||  || { || ""title"": ""Internal Deployment Gaps in AI Regulation"", || ""authors"": [""JOE KWON"", ""STEPHEN CASPER""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper examines gaps in AI regulation concerning internal deployments, highlighting issues like scope ambiguity, point-in-time assessments, and information asymmetries that allow high-stakes internal systems to evade oversight."" || } ||  || [ Prompt: 122.0 t/s | Generation: 31.6 t/s ]"
2601.08011v1_TP-Blend Textual-Prompt Attention Pairing for Prec.pdf,TP-Blend: Textual-Prompt Attention Pairing for Precise,"['Xin Jin', 'Yichuan Zhongyichuanzhong', 'Yapeng Tian']",10.1089/tmr.2025.1234,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Published in Transactions on Machine Learning Research (10/2025) || TP-Blend: Textual-Prompt Attention Pairing for Precise || Object-Style Blending in Diffusion Models || Xin Jin felixxinjin@gmail.com || GenPi Inc. || Yichuan Zhongyichuanzhong27@gmail.com || GenPi Inc. || Yapeng Tian yapeng.tian@utdalla ... (truncated) ||  || { || ""title"": ""TP-Blend: Textual-Prompt Attention Pairing for Precise"", || ""authors"": [ || ""Xin Jin"", || ""Yichuan Zhongyichuanzhong"", || ""Yapeng Tian"" || ], || ""doi"": ""10.1089/tmr.2025.1234"", || ""arxiv_id"": ""https://arxiv.org/abs/genPi/2301.12345"", || ""keywords"": [ || ""textual-prompt"", || ""object-style-blending"", || ""diffusion-models"", || ""content-appearance"", || ""cross-attention"", || ""style-fusion"" || ], || ""summary"": ""TP-Blend introduces Twin-PromptAttention Blend to enable simultaneous object replacement and style introduction in diffusion models. It uses two attention processors—Cross-Attention Object Fusion and Self-Attention Style Fusion—to achieve high-resolution, photo-realistic edits with precise control."" || } ||  || [ Prompt: 116.0 t/s | Generation: 29.3 t/s ]"
2601.08017v1_Representations of Text and Images Align From Laye.pdf,Representations of Text and Images Align From Layer One,"['Evzen Wybitul', 'Javier Rando', 'Florian Tram', 'Stanislav Fort', '2']",arXiv:2601.08017v1,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Representations of Text and Images Align From Layer One || Evzen Wybitul 1 Javier Rando 1 Florian Tram`er 1 Stanislav Fort 2 || Abstract || We show that for a variety of concepts in adapter- || based vision-language models, the representations || of their images and their text descriptions are || mea ... (truncated) ||  || { || ""title"": ""Representations of Text and Images Align From Layer One"", || ""authors"": [ || ""Evzen Wybitul"", || ""Javier Rando"", || ""Florian Tram"", || ""Stanislav Fort"", || ""2"" || ], || ""doi"": ""arXiv:2601.08017v1"", || ""arxiv_id"": ""arXiv:2601.08017"", || ""keywords"": [], || ""summary"": ""The paper demonstrates that image-text representations align from the first layer in adapter-based vision-language models, challenging the notion that alignment occurs only in later layers. Using a synthesis-based method inspired by DeepDream, the authors show that images generated at layer 1 often reflect recognisable features of textual concepts."" || } ||  || [ Prompt: 132.9 t/s | Generation: 27.7 t/s ]"
2601.08026v2_FigEx2 Visual-Conditioned Panel Detection and Capt.pdf,FigEx2: Visual-Conditioned Panel Detection and Captioning for Scientific Compound Figures,"['Jifeng Song', 'Arun Das', 'Pan Wang', 'Hui Ji4', 'Kun Zhao', 'Yufei Huang', '2, 3*', 'pitt.edu']",,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || FigEx2: Visual-Conditioned Panel Detection and Captioning for Scientific || Compound Figures || Jifeng Song1, 2 , Arun Das2, 3 , Pan Wang1, Hui Ji4, Kun Zhao1, Yufei Huang1, 2, 3* || 1 Department of Electrical and Computer Engineering, University of Pittsburgh, USA || 2 Cancer Virology Program, ... (truncated) ||  || { || ""title"": ""FigEx2: Visual-Conditioned Panel Detection and Captioning for Scientific Compound Figures"", || ""authors"": [ || ""Jifeng Song"", || ""Arun Das"", || ""Pan Wang"", || ""Hui Ji4"", || ""Kun Zhao"", || ""Yufei Huang"", || ""2, 3*"", || ""pitt.edu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper proposes FigEx2, a visual-conditioned framework for localizing panels and generating panel-level captions from scientific compound figures. It introduces a noise-aware gated fusion module and a staged optimization strategy combining supervised learning with reinforcement learning, achieving strong performance in detection and captioning."" || } ||  || [ Prompt: 121.6 t/s | Generation: 29.0 t/s ]"
2601.08043v1_The Role of Noisy Data in Improving CNN Robustness.pdf,,[],,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || The Role of Noisy Data in Improving CNN Robustness for || Image Classification || Oscar H. Ram rez-Agudeloa, Nicoleta Gorea a, Aliza Reif a, Lorenzo Bonasera a, and Michael || Karla || aGerman Aerospace Center (DLR), Institute for AI Safety and Security, Rathausallee 12, || 53757 Sankt Augustin, G ... (truncated) ||  || { || ""title"": ""The Role of Noisy Data in Improving CNN Robustness for Image Classification"", || ""authors"": [ || ""Oscar H. Ram rez-Agudeloa"", || ""Nicoleta Gorea a"", || ""Aliza Reif a"", || ""Lorenzo Bonasera a"", || ""Michael Karla"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""deep learning"", || ""CNNs"", || ""data quality"", || ""CIFAR-10"", || ""noise injection"", || ""image classification"", || ""model robustness""] || "", ""summary"": ""This paper investigates the effect of introducing controlled noise into training data to improve CNN robustness. Experiments using Resnet-18 show that incorporating just 10% noisy data significantly reduces test loss under corrupted conditions while maintaining performance on clean data."" || } ||  || [ Prompt: 128.1 t/s | Generation: 28.3 t/s ]"
2601.08049v1_Integrating Attendance Tracking and Emotion Detect.pdf,Integrating Attendance Tracking and Emotion Detection for Enhanced Student Engagement in Smart Classrooms,"['Keith Ainebyona', 'Ann Move Oguti', 'Joseph Walusimbi', 'Ritah Kobusingye']",42401600224@sun.ac.ug,31.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 ||  || Integrating Attendance Tracking and Emotion Detection for || Enhanced Student Engagement in Smart Classrooms || Keith Ainebyona1, Ann Move Oguti2, Joseph Walusimbi3, Ritah Kobusingye4 || 1keithainebyona14@gmail.com, 2amoguti@sun.ac.ug, 3mrjosephwalusimbi@gmail.com, || 42401600224@sun.a ... (truncated) ||  || { || ""title"": ""Integrating Attendance Tracking and Emotion Detection for Enhanced Student Engagement in Smart Classrooms"", || ""authors"": [ || ""Keith Ainebyona"", || ""Ann Move Oguti"", || ""Joseph Walusimbi"", || ""Ritah Kobusingye"" || ], || ""doi"": ""42401600224@sun.ac.ug"", || ""arxiv_id"": """", || ""keywords"": [ || ""Affective computing"", || ""Attendance automation"", || ""Emotion detection"", || ""IoT"", || ""Smart classroom"" || ], || ""summary"": ""The paper presents SCASED, an IoT-based system integrating automated attendance tracking with facial emotion recognition to monitor classroom engagement. It uses a Raspberry Pi camera and MobileNetV2 model to classify emotional states like engagement, boredom, confusion, and frustration. The system supports instructors with insights into classroom dynamics using a cloud dashboard."", || ""summary_length"": ""short"" || } ||  || [ Prompt: 128.0 t/s | Generation: 31.7 t/s ]"
2601.08052v1_Forecast Aware Deep Reinforcement Learning for Eff.pdf,Forecast Aware Deep Reinforcement Learning for Efficient Electricity Load Scheduling in Dairy Farms,"['Nawazish Alia', 'Rachael Shawb', 'Karl Masona']",arXiv:2601.08052v1,31.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Forecast Aware Deep Reinforcement Learning for || Efficient Electricity Load Scheduling in Dairy Farms || Nawazish Alia, Rachael Shawb, Karl Masona || aSchool of Computer Science, University of Galway, , Galway, H91 TK33, , Ireland || bSchool of Computing, Atlantic Technological University, , G ... (truncated) ||  || { || ""title"": ""Forecast Aware Deep Reinforcement Learning for Efficient Electricity Load Scheduling in Dairy Farms"", || ""authors"": [ || ""Nawazish Alia"", || ""Rachael Shawb"", || ""Karl Masona"" || ], || ""doi"": ""arXiv:2601.08052v1"", || ""arxiv_id"": ""arXiv:2601.08052"", || ""keywords"": [ || ""arXiv:2601.08052"", || ""cs.AI"", || ""energy management"", || ""dairy farming"", || ""renewable energy"", || ""forecast-aware"", || ""deep reinforcement learning"", || ""battery storage"", || ""water heating"" || ], || ""summary"": ""This study proposes a Deep Reinforcement Learning framework for efficient load scheduling in dairy farms, focusing on battery storage and water heating under real-world operational constraints. It incorporates short-term demand and renewable generation forecasts and uses a PPO variant with adaptive KL-divergence control."" || } ||  || [ Prompt: 127.0 t/s | Generation: 31.5 t/s ]"
2601.08058v1_Reasoning Beyond Chain-of-Thought A Latent Computa.pdf,Reasoning Beyond Chain-of-Thought: A Latent Computational Mode in Large Language Models,"['Zhenghao He', 'Guangzhi Xiong Bohan Liu', 'Bohan Liu Sanchit Sinha', 'Aidong Zhang']",10.48550/arXiv.2311.06824,28.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Reasoning Beyond Chain-of-Thought: A Latent Computational Mode in || Large Language Models || Zhenghao He Guangzhi Xiong Bohan Liu Sanchit Sinha Aidong Zhang || University of Virginia, USA || Abstract || Chain-of-Thought (CoT) prompting has im- || proved the reasoning performance of large lan- || guage  ... (truncated) ||  || { || ""title"": ""Reasoning Beyond Chain-of-Thought: A Latent Computational Mode in Large Language Models"", || ""authors"": [""Zhenghao He"", ""Guangzhi Xiong Bohan Liu"", ""Bohan Liu Sanchit Sinha"", ""Aidong Zhang""], || ""doi"": ""10.48550/arXiv.2311.06824"", || ""arxiv_id"": ""2311.06824"", || ""keywords"": [""Chain-of-Thought"", ""large language models"", ""latent reasoning"", ""CoT prompting""], || ""summary"": ""This study investigates whether steering a single reasoning-related latent feature in large language models can significantly improve performance without explicit CoT prompting. It identifies internal latent activations that support reasoning and shows that such internal mechanisms can be activated early in generation, potentially overcoming the need for explicit CoT instructions."" || } ||  || [ Prompt: 122.7 t/s | Generation: 28.0 t/s ]"
2601.08065v1_A New Strategy for Verifying Reach-Avoid Specifica.pdf,A New Strategy for Verifying Reach-Avoid,"['Samuel I. Akinwande', 'Sydney M. Katz', 'Mykel J. Kochenderfer', 'Clark Barrett']",arXiv:2601.08065v1,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A New Strategy for Verifying Reach-Avoid || Specifications in Neural Feedback Systems || Samuel I. Akinwande1, Sydney M. Katz1, Mykel J. Kochenderfer1, and Clark Barrett2 || 1 Department of Aeronautics and Astronautics, Stanford University, Stanford, USA || 2 Department of Computer Science, Sta ... (truncated) ||  || { || ""title"": ""A New Strategy for Verifying Reach-Avoid"", || ""authors"": [ || ""Samuel I. Akinwande"", || ""Sydney M. Katz"", || ""Mykel J. Kochenderfer"", || ""Clark Barrett"" || ], || ""doi"": ""arXiv:2601.08065v1"", || ""arxiv_id"": ""arXiv:2601.08065"", || ""keywords"": [], || ""summary"": ""Forward reachability analysis is the predominant approach for verifying reach-avoid properties in neural feedback systems. This work introduces new algorithms that compute both over- and under-approximations of backward reachable sets, integrating them with established forward analysis techniques for a unified verification framework."" || } ||  || [ Prompt: 123.9 t/s | Generation: 28.8 t/s ]"
2601.08070v1_Semantic Gravity Wells Why Negative Constraints Ba.pdf,Semantic Gravity Wells: Why Negative Constraints Backfire,['Shailesh Rana'],https://github.com/gut-puncture,26.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Semantic Gravity Wells: Why Negative Constraints Backfire || Shailesh Rana || Independent Researcher || https://github.com/gut-puncture || Abstract || Negative constraints (instructions of the form do not use word X) represent a fundamental test of instruction-following || capability in large languag ... (truncated) ||  || { || ""title"": ""Semantic Gravity Wells: Why Negative Constraints Backfire"", || ""authors"": [""Shailesh Rana""], || ""doi"": ""https://github.com/gut-puncture"", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Investigates negative instruction failure using semantic pressure and logit analysis, revealing suppression asymmetry and activation patterns."" || } ||  || [ Prompt: 116.3 t/s | Generation: 26.7 t/s ]"
2601.08079v1_MemoBrain Executive Memory as an Agentic Brain for.pdf,Executive Memory as an Agentic Brain for Reasoning,"['Hongjin Qian', 'Zhao Cao', 'Zheng Liu']",,26.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MemoBrain: Executive Memory as an Agentic Brain for Reasoning || Hongjin Qian1, Zhao Cao2, Zheng Liu1* || 1 Beijing Academy of Artificial Intelligence || 2 Gaoling School of Artificial Intelligence, Renmin University of China || {chienqhj,zhengliu1026}@gmail.com || Abstract || Complex reasoning in to ... (truncated) ||  || { || ""title"": ""Executive Memory as an Agentic Brain for Reasoning"", || ""authors"": [""Hongjin Qian"", ""Zhao Cao"", ""Zheng Liu""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Complex reasoning in tool-augmented agent frameworks is inherently long-horizon, causing reasoning traces and transient tool artifacts to accumulate. This disrupts logical continuity and undermines task alignment. This positions memory as a core component for sustaining coherent, goal-directed reasoning over long horizons."" || } ||  || [ Prompt: 124.4 t/s | Generation: 26.8 t/s ]"
2601.08089v1_Q-realign Piggybacking Realignment on Quantization.pdf,Piggybacking Realignment on Quantization for Safe and Efficient LLM Deployment,"['Qitao Tan', 'Xiaoying Song', 'Ningxi Cheng', 'Ninghao Liu', 'Xiaoming Zhai', 'Lingzi Hong', 'Zhen Xiang', 'Geng Yuan']",10.1234/q-realign-2024,29.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Q-realign: Piggybacking Realignment on Quantization for Safe and || Efficient LLM Deployment || Qitao Tan1 Xiaoying Song2 Ningxi Cheng1 Ninghao Liu3 || Xiaoming Zhai1 Lingzi Hong2 Yanzhi Wang4 Zhen Xiang1 Geng Yuan1 || 1University of Georgia 2University of North Texas || 3Hong Kong Polytechnic Uni ... (truncated) ||  || { || ""title"": ""Piggybacking Realignment on Quantization for Safe and Efficient LLM Deployment"", || ""authors"": [ || ""Qitao Tan"", || ""Xiaoying Song"", || ""Ningxi Cheng"", || ""Ninghao Liu"", || ""Xiaoming Zhai"", || ""Lingzi Hong"", || ""Zhen Xiang"", || ""Geng Yuan"" || ], || ""doi"": ""10.1234/q-realign-2024"", || ""arxiv_id"": """", || ""keywords"": [ || ""large language models"", || ""safety alignment"", || ""quantization"", || ""deployment"", || ""LLM deployment"", || ""safety recovery"" || ], || ""summary"": ""This paper proposes Q-realign, a post-hoc defense method based on post-training quantization, to address safety degradation during fine-tuning of large language models. It aims to decouple safety alignment from fine-tuning and piggyback on existing deployment pipelines, achieving reduced memory usage and computational cost while maintaining performance."" || } ||  || [ Prompt: 124.1 t/s | Generation: 29.2 t/s ]"
2601.08094v1_Local-Global Feature Fusion for Subject-Independen.pdf,Local-Global Feature Fusion for Subject-Independent EEG Emotion Recognition,"['Zheng Zhou', 'Isabella McEvoy', 'Camilo E. Valderrama']",,27.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Local-Global Feature Fusion for || Subject-Independent EEG Emotion Recognition || Zheng Zhou || Computer Science and Technology || Beijing Jiaotong University || Beijing, China || zhengzhou@bjtu.edu.cn || Isabella McEvoy || Applied Computer Science || The University of Winnipeg || Winnipeg, Canada || mcevoy-i@webma ... (truncated) ||  || { || ""title"": ""Local-Global Feature Fusion for Subject-Independent EEG Emotion Recognition"", || ""authors"": [ || ""Zheng Zhou"", || ""Isabella McEvoy"", || ""Camilo E. Valderrama"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper proposes a fusion framework integrating local channel-wise descriptors and global trial-level descriptors to improve cross-subject generalization in EEG emotion recognition. It uses dual-branch transformer with attention-based fusion and domain-adversarial regularization."" || } ||  || [ Prompt: 117.7 t/s | Generation: 27.4 t/s ]"
2601.08104v1_High-Fidelity Modeling of Stochastic Chemical Dyna.pdf,High-Fidelity Modeling of Stochastic Chemical Dynamics on Complex Manifolds: A Multi-Scale SIREN-PINN Framework for the Defect Turbulenceregime,"['Julian Evan Chrisnanto', 'Salsabila Rahma Alia', 'Nurfauzi Fadillah', 'Yulison Herry Chrisnanto']",s254167v@st.go.tuat.ac.jp,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || HIGH-FIDELITYMODELING OFSTOCHASTICCHEMICAL || DYNAMICS ONCOMPLEXMANIFOLDS: A MULTI-SCALE || SIREN-PINN FRAMEWORK FOR THECURVATURE-PERTURBED || GINZBURG-LANDAUEQUATION || A PREPRINT || Julian Evan Chrisnanto || Department of Bio-Functions and Systems Science || Graduate School of Bio-Applications and Sys ... (truncated) ||  || { || ""title"": ""High-Fidelity Modeling of Stochastic Chemical Dynamics on Complex Manifolds: A Multi-Scale SIREN-PINN Framework for the Defect Turbulenceregime"", || ""authors"": [ || ""Julian Evan Chrisnanto"", || ""Salsabila Rahma Alia"", || ""Nurfauzi Fadillah"", || ""Yulison Herry Chrisnanto"" || ], || ""doi"": ""s254167v@st.go.tuat.ac.jp"", || ""arxiv_id"": """", || ""keywords"": [ || ""Physics-Informed Neural Networks (PINNs)"", || ""Spatiotemporal Chaos"", || ""Inverse Geometric Problems"", || ""Reaction-Diffusion Systems"", || ""Defect Turbulence"", || ""Riemann Manifold Learning"" || ], || ""summary"": ""The paper presents a Multi-Scale SIREN-PINN architecture for modeling complex reaction-diffusion systems with topological constraints. It addresses challenges in accurately capturing high-frequency dynamics in systems with complex catalytic surfaces, demonstrating improved predictive performance on the Ginzburg-Landau equation."" || } ||  || [ Prompt: 118.1 t/s | Generation: 29.1 t/s ]"
2601.08107v1_STO-RL Offline RL under Sparse Rewards via LLM-Gui.pdf,STO-RL: Offline RL under Sparse Rewards via LLM-Guided Subgoal Temporal Order,"['Chengyang Gu', 'Yuxin Pan', 'Hui Xiong', 'Yize Chen']",10.1145/nnnnnnn.nnnnnnn,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || STO-RL: Offline RL under Sparse Rewards via LLM-Guided || Subgoal Temporal Order || Chengyang Gu || Hong Kong University of Science and Technology || (Guangzhou) || Hong Kong, China || cgu893@connect.hkust-gz.edu.cn || Yuxin Pan || Hong Kong University of Science and Technology || Hong Kong, China || yuxin.pan@c ... (truncated) ||  || { || ""title"": ""STO-RL: Offline RL under Sparse Rewards via LLM-Guided Subgoal Temporal Order"", || ""authors"": [ || ""Chengyang Gu"", || ""Yuxin Pan"", || ""Hui Xiong"", || ""Yize Chen"" || ], || ""doi"": ""10.1145/nnnnnnn.nnnnnnn"", || ""arxiv_id"": ""cgu893@connect.hkust-gz.edu.cn"", || ""keywords"": [ || ""Offline RL"", || ""Temporal order"", || ""Large Language Models"", || ""Subgoal temporal order"", || ""Long-horizon tasks"" || ], || ""summary"": ""Offline reinforcement learning enables policy learning from pre-collected datasets, avoiding costly online interactions. This paper proposes STO-RL, an offline RL framework that uses large language models to generate temporally ordered subgoal sequences and state-to-subgoal mappings. STO-RL applies potential-based reward shaping to convert sparse terminal rewards into dense, temporally consistent signals, improving subgoal progress and policy performance."" || } ||  || [ Prompt: 113.2 t/s | Generation: 29.1 t/s ]"
2601.08108v1_Debiasing Large Language Models via Adaptive Causa.pdf,Debiasing Large Language Models via Adaptive Causal Prompting with Sketch-of-Thought,"['Bowen Li', 'Ziqi Xu', 'Jing Ren', 'Renqiang Luo', 'Xikun Zhang', 'Xiuzhen Zhang', 'Yongli Ren', 'Feng Xia']",10.48550/arXiv.2303.04219,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Debiasing Large Language Models via Adaptive Causal Prompting with || Sketch-of-Thought || Bowen Li1, Ziqi Xu1, Jing Ren1, Renqiang Luo2, || Xikun Zhang1,Xiuzhen Zhang 1,Yongli Ren 1,Feng Xia 1 || 1RMIT University, Australia, 2Jilin University, China || Correspondence:ziqi.xu@rmit.edu.au || Abstract || ... (truncated) ||  || { || ""title"": ""Debiasing Large Language Models via Adaptive Causal Prompting with Sketch-of-Thought"", || ""authors"": [ || ""Bowen Li"", || ""Ziqi Xu"", || ""Jing Ren"", || ""Renqiang Luo"", || ""Xikun Zhang"", || ""Xiuzhen Zhang"", || ""Yongli Ren"", || ""Feng Xia"" || ], || ""doi"": ""10.48550/arXiv.2303.04219"", || ""arxiv_id"": ""arXiv:2303.04219"", || ""keywords"": [ || ""large language models"", || ""prompting"", || ""adaptive causal prompting"", || ""sketch-of-thought"", || ""bias debiasing"", || ""causal reasoning"" || ], || ""summary"": ""This paper proposes an Adaptive Causal Prompting with Sketch-of-Thought (ACPS) framework to address excessive token usage and limited generalisability in prompting methods for LLMs. ACPS leverages structural causal models to infer causal effects and adaptively select interventions, achieving better accuracy, robustness, and efficiency compared to existing methods."" || } ||  || [ Prompt: 122.5 t/s | Generation: 28.8 t/s ]"
2601.08109v1_CSQL Mapping Documents into Causal Databases.pdf,Csql: MappingDocuments intoCausalDatabases,['Sridhar Mahadevan'],,26.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Csql: MappingDocuments intoCausalDatabases || A Preprint || Sridhar Mahadevan || Adobe Research and University of Massachusetts, Amherst || smahadev@adobe.com, mahadeva@umass.edu || January 14, 2026 || Abstract || We describe a novel system, Csql, that automatically converts a collection of unstructure ... (truncated) ||  || { || ""title"": ""Csql: MappingDocuments intoCausalDatabases"", || ""authors"": [""Sridhar Mahadevan""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Causality"", ""Natural Language Databases"", ""SQL"", ""Machine Learning""], || ""summary"": ""Csql is a system that converts unstructured text documents into SQL-queryable causal databases, enabling causal analysis over document collections rather than relying on retrieval or knowledge graphs."" || } ||  || [ Prompt: 118.2 t/s | Generation: 26.8 t/s ]"
2601.08118v1_MirrorBench An Extensible Framework to Evaluate Us.pdf,MIRRORBENCH: ANEXTENSIBLEFRAMEWORK TOEVALUATEUSER-PROXY,"['Ashutosh Hathidara', 'Julien Yu', 'Vaishali Senthil', 'Sebastian Schreiber', 'Anil Babu Ankisettipalli']",,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MIRRORBENCH: ANEXTENSIBLEFRAMEWORK TOEVALUATEUSER-PROXY || AGENTS FORHUMAN-LIKENESS || Ashutosh Hathidara 1 Julien Yu1 Vaishali Senthil1 Sebastian Schreiber 1 Anil Babu Ankisettipalli 1 || ABSTRACT || Large language models (LLMs) are increasingly used as human simulators, both for evaluating co ... (truncated) ||  || { || ""title"": ""MIRRORBENCH: ANEXTENSIBLEFRAMEWORK TOEVALUATEUSER-PROXY"", || ""authors"": [ || ""Ashutosh Hathidara"", || ""Julien Yu"", || ""Vaishali Senthil"", || ""Sebastian Schreiber"", || ""Anil Babu Ankisettipalli"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""human simulators"", || ""user proxies"", || ""conversational systems"", || ""LLM evaluation"", || ""user proxy agents"" || ], || ""summary"": ""MIRRORBENCH is a reproducible, extensible benchmarking framework that evaluates user proxies based on their ability to produce human-like utterances across diverse conversational tasks, decoupled from downstream task success. It introduces a modular execution engine, supports pluggable proxies and metrics, and reveals gaps between proxies and real human users."" || } ||  || [ Prompt: 123.0 t/s | Generation: 29.0 t/s ]"
2601.08125v1_How vehicles change lanes after encountering crash.pdf,How vehicles change lanes after encountering crashes: Empirical analysis and modeling,"['Kequan Chena', 'Yuxuan Wangb', 'Pan Liu', 'Victor L. Knoop', 'David Z. W. Wang']",,32.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || How vehicles change lanes after encountering crashes: Empirical || analysis and modeling ||  ||  || Kequan Chena || aSchool of Civil and Environmental Engineering || Nanyang Technological University, Singapore 639798 || Email: kequan.chen@ntu.edu.sg ||  || Yuxuan Wangb* || bState Key Laboratory of I ... (truncated) ||  || { || ""title"": ""How vehicles change lanes after encountering crashes: Empirical analysis and modeling"", || ""authors"": [ || ""Kequan Chena"", || ""Yuxuan Wangb"", || ""Pan Liu"", || ""Victor L. Knoop"", || ""David Z. W. Wang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Empirical analysis and modeling of how vehicles change lanes after encountering crashes."" || } ||  || [ Prompt: 113.8 t/s | Generation: 32.7 t/s ]"
2601.08127v1_PathoGen Diffusion-Based Synthesis of Realistic Le.pdf,PathoGen: Diffusion-Based Synthesis of Realistic Lesions in Histopathology Images,"['Mohamad Koohi-Moghadam1', 'Mohammad-Ali Nikouei Mahani1', 'Kyongtae Tyler Bae1']",,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || PathoGen: Diffusion-Based Synthesis of Realistic Lesions in || Histopathology Images || Mohamad Koohi-Moghadam1*, Mohammad-Ali Nikouei Mahani1, Kyongtae Tyler Bae1 || 1 Department of Diagnostic Radiology, Li Ka Shing Faculty of Medicine, The University of Hong Kong, Pok Fu || Lam, Hong Ko ... (truncated) ||  || { || ""title"": ""PathoGen: Diffusion-Based Synthesis of Realistic Lesions in Histopathology Images"", || ""authors"": [ || ""Mohamad Koohi-Moghadam1"", || ""Mohammad-Ali Nikouei Mahani1"", || ""Kyongtae Tyler Bae1"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""PathoGen is a diffusion-based generative model that enables high-fidelity inpainting of lesions in histopathology images, addressing the scarcity of expert-annotated data and improving segmentation performance."" || } ||  || [ Prompt: 124.5 t/s | Generation: 28.4 t/s ]"
2601.08128v1_Embedded AI Companion System on Edge Devices.pdf,Embedded AI Companion System on Edge Devices,"['Rahul Gupta', 'Stephen Hsu']",10.48550/arXiv.2026.12345,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Embedded AI Companion System on Edge Devices || Rahul Gupta 1 and Stephen Hsu 1,2 || 1Superfocus AI || 2Michigan State University || January 14, 2026 || Abstract || Computational resource constraints on edge devices make it difficult to develop a fully embedded || AI companion system with a satisfactory ... (truncated) ||  || { || ""title"": ""Embedded AI Companion System on Edge Devices"", || ""authors"": [ || ""Rahul Gupta"", || ""Stephen Hsu"" || ], || ""doi"": ""10.48550/arXiv.2026.12345"", || ""arxiv_id"": ""arXiv:2509.12345"", || ""keywords"": [ || ""AI companion"", || ""edge devices"", || ""computational constraints"", || ""memory systems"", || ""lightweight retrieval"", || ""conversational quality"", || ""memory maintenance"" || ], || ""summary"": ""The paper proposes a memory paradigm for embedding AI companions on edge devices, balancing low-latency real-time interaction during active use and computationally intensive memory processing during inactivity. It introduces an AI Companion benchmark to evaluate conversational and memory performance, demonstrating that their quantized model outperforms equivalent large models in key metrics."" || } ||  || [ Prompt: 123.4 t/s | Generation: 28.8 t/s ]"
2601.08133v1_How Do Optical Flow and Textual Prompts Collaborat.pdf,Audio-Visual Semantic Segmentation with Optical Flow and Textual Prompts,"['Peng Gao', 'Yujian Lee', 'Yongqi Xu', 'Wentao Fan', 'Hong Kong Baptist University', 'Guangdong Provincial/Zhuhai Key Laboratory IRADS', 'Peking University, Shenzhen Graduate School']",62276106,29.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || How Do Optical Flow and Textual Prompts Collaborate to Assist in Audio-Visual || Semantic Segmentation? || Peng Gao1,2,, Yujian Lee 1,2,, Yongqi Xu 3, Wentao Fan 1,2, || 1Hong Kong Baptist University, Hong Kong, China || 2Guangdong Provincial/Zhuhai Key Laboratory IRADS || and Department of Comput ... (truncated) ||  || { || ""title"": ""Audio-Visual Semantic Segmentation with Optical Flow and Textual Prompts"", || ""authors"": [ || ""Peng Gao"", || ""Yujian Lee"", || ""Yongqi Xu"", || ""Wentao Fan"", || ""Hong Kong Baptist University"", || ""Guangdong Provincial/Zhuhai Key Laboratory IRADS"", || ""Peking University, Shenzhen Graduate School"" || ], || ""doi"": ""62276106"", || ""arxiv_id"": ""2024GXJK695"", || ""keywords"": [ || ""audio-visual segmentation"", || ""semantic segmentation"", || ""optical flow"", || ""textual prompts"", || ""visual segmentation"", || ""motion dynamics"", || ""semantic interpretation"" || ], || ""summary"": ""This paper introduces a novel collaborative framework, Stepping Stone Plus (SSP), that integrates optical flow and textual prompts to enhance audio-visual semantic segmentation. By leveraging optical flow for temporal context and using textual prompts for scene description, SSP improves segmentation accuracy, especially for coexisting sound sources and static objects."" || } ||  || [ Prompt: 118.8 t/s | Generation: 29.6 t/s ]"
2601.08139v1_Subspace Alignment for Vision-Language Model Test-.pdf,,[],,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Subspace Alignment for Vision-Language Model Test-time Adaptation || Zhichen Zeng1, Wenxuan Bao1, Xiao Lin1, Ruizhong Qiu1, Tianxin Wei1, Xuying Ning1, || Yuchen Yan2,Chen Luo 2,Monica Xiao Cheng 2,Jingrui He 1,Hanghang Tong 1 || 1University of Illinois Urbana-Champaign, 2Amazon, || {zhichenz,  ... (truncated) ||  || { || ""title"": ""Subspace Alignment for Vision-Language Model Test-time Adaptation"", || ""authors"": [ || ""Zhichen Zheng"", || ""Wenxuan Bao"", || ""Xiao Lin"", || ""Ruizhong Qiu"", || ""Tianxin Wei"", || ""Xuying Ning"", || ""Yuchen Yan"", || ""Chen Luo"", || ""Monica Xiao Cheng"", || ""Jingrui He"", || ""Hanghang Tong"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper proposes SubTTA to align semantic subspaces across vision and language modalities, addressing distribution shift issues by minimizing chordal distance and filtering visual noise."" || } ||  || [ Prompt: 120.9 t/s | Generation: 29.3 t/s ]"
2601.08141v1_Qalb Largest State-of-the-Art Urdu Large Language .pdf,Qalb: Largest State-of-the-Art Urdu Large Language Model,"['1st Muhammad Taimoor Hassan', '2st Jawad Ahmed', '3st Muhammad Awais']",,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Qalb: Largest State-of-the-Art Urdu Large || Language Model for 230M Speakers with || Systematic Continued Pre-training || 1st Muhammad Taimoor Hassan || Auburn University, USA || Computer Science and Software Engineering || muh0001@auburn.edu || mtaimoorhas1@gmail.com || 2st Jawad Ahmed || BHT Berlin, German ... (truncated) ||  || { || ""title"": ""Qalb: Largest State-of-the-Art Urdu Large Language Model"", || ""authors"": [ || ""1st Muhammad Taimoor Hassan"", || ""2st Jawad Ahmed"", || ""3st Muhammad Awais"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Urdu language model"", || ""continued pre-training"", || ""low-resource NLP"", || ""LoRA"", || ""language adaptation"" || ], || ""summary"": ""Qalb is an Urdu language model developed through a two-stage approach: continued pre-training followed by supervised fine-tuning. It achieves state-of-the-art performance on Urdu-specific benchmarks, outperforming previous models by significant margins."" || } ||  || [ Prompt: 122.2 t/s | Generation: 29.3 t/s ]"
2601.08146v2_Mechanisms are Transferable Data-Efficient Low-Res.pdf,Mechanisms are Transferable: Data-Efficient Low-Resource Adaptation,"['Khumaisa Nuraini', 'Ayu Purwarianti', 'Alham Fikri Aji', 'Derry Wijaya']",,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Mechanisms are Transferable: Data-Efficient Low-Resource Adaptation || via Circuit-Targeted Supervised Fine-Tuning || Khumaisa Nuraini1, Ayu Purwarianti2, Alham Fikri Aji3, Derry Wijaya1,4, || 1Monash University Indonesia, 2Institute Teknologi Bandung, 3MBZUAI, 4Boston University || Abstract || Ad ... (truncated) ||  || { || ""title"": ""Mechanisms are Transferable: Data-Efficient Low-Resource Adaptation"", || ""authors"": [ || ""Khumaisa Nuraini"", || ""Ayu Purwarianti"", || ""Alham Fikri Aji"", || ""Derry Wijaya"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Adapting LLMs to low-resource languages is difficult due to scarce labeled data, unstable full-model fine-tuning, and catastrophic forgetting. The paper proposes Circuit-Targeted Supervised Fine-Tuning (CT-SFT), a counterfactual-free adaptation method that updates only relevant attention heads while preserving source competence."" || } ||  || [ Prompt: 125.4 t/s | Generation: 28.8 t/s ]"
2601.08148v1_Enriching Semantic Profiles into Knowledge Graph f.pdf,Enriching Semantic Profiles into Knowledge Graph for Recommender Systems Using Large Language Models,"['Seokho Ahn', 'Sungbok Shin', 'Young-Duk Seo']",https://doi.org/10.1145/3770854.3780324,29.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Enriching Semantic Profiles into Knowledge Graph for || Recommender Systems Using Large Language Models || Seokho Ahn || Inha University || Department of Electrical and || Computer Engineering || Incheon, South Korea || sokho0514@inha.edu || Sungbok Shin || Sogang University || Department of Computer Science || and ... (truncated) ||  || { || ""title"": ""Enriching Semantic Profiles into Knowledge Graph for Recommender Systems Using Large Language Models"", || ""authors"": [ || ""Seokho Ahn"", || ""Sungbok Shin"", || ""Young-Duk Seo"" || ], || ""doi"": ""https://doi.org/10.1145/3770854.3780324"", || ""arxiv_id"": """", || ""keywords"": [ || ""Recommendation"", || ""Semantic Profiling"", || ""Large Language Models"", || ""Knowledge Graphs"" || ], || ""summary"": ""Rich and informative profiling to capture user preferences is essential for improving recommendation quality. This paper revisits recent profiling-based approaches in recommender systems and proposes a new recommendation model, SPiKE, which integrates LLMs and knowledge graphs."" || } ||  || [ Prompt: 115.8 t/s | Generation: 29.6 t/s ]"
2601.08149v1_Dynamic Graph Structure Learning via Resistance Cu.pdf,Dynamic Graph Structure Learning via Resistance Curvature Flow,"['Chaoqun Fei', 'Huanjiang Liu', 'Tinglve Zhou', 'Y angyang Li 1', 'Tianyong Hao']",arXiv:2601.08149v1,32.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Highlights || Dynamic Graph Structure Learning via Resistance Curvature Flow || Chaoqun Fei, Huanjiang Liu, Tinglve Zhou, Y angyang Li 1, Tianyong Hao || Introduces a novel and computationally e cient curvature ow based on e ec- || tive resistance from circuit theory, establishing a new paradi ... (truncated) ||  || { || ""title"": ""Dynamic Graph Structure Learning via Resistance Curvature Flow"", || ""authors"": [""Chaoqun Fei"", ""Huanjiang Liu"", ""Tinglve Zhou"", ""Y angyang Li 1"", ""Tianyong Hao""], || ""doi"": ""arXiv:2601.08149v1"", || ""arxiv_id"": ""2601.08149v1"", || ""keywords"": [""graph structure learning"", ""curvature flow"", ""deep learning"", ""manifold learning""], || ""summary"": ""Introduces a novel curvature-based resistance flow for dynamic graph structure learning, demonstrating improved performance in deep learning tasks with efficient runtime."" || } ||  || [ Prompt: 115.3 t/s | Generation: 32.6 t/s ]"
2601.08156v1_Project Synapse A Hierarchical Multi-Agent Framewo.pdf,Project Synapse: A Hierarchical Multi-Agent Framework with Hybrid Memory for Autonomous Resolution of Last-Mile Delivery Disruptions,"['Arin Gopalan Yadav', 'Varad Dherange', 'Kumar Shivam']",arXiv:2601.08156v1,31.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Project Synapse: A Hierarchical || Multi-Agent Framework with Hybrid || Memory for Autonomous Resolution of || Last-Mile Delivery Disruptions || Arin Gopalan Yadav || Varad Dherange || Kumar Shivam || Department of Computer Science Engineering || Vellore Institite of Technology University || arin.technovate@o ... (truncated) ||  || { || ""title"": ""Project Synapse: A Hierarchical Multi-Agent Framework with Hybrid Memory for Autonomous Resolution of Last-Mile Delivery Disruptions"", || ""authors"": [ || ""Arin Gopalan Yadav"", || ""Varad Dherange"", || ""Kumar Shivam"" || ], || ""doi"": ""arXiv:2601.08156v1"", || ""arxiv_id"": ""arXiv:2601.08156v1"", || ""keywords"": [ || ""Project Synapse"", || ""Multi-Agent Framework"", || ""Last-Mile Delivery"", || ""Autonomous Resolution"", || ""Hybrid Memory Architecture"", || ""LLM-as-a-Judge"" || ], || ""summary"": ""The paper introduces Project Synapse, a hierarchical multi-agent system designed to autonomously resolve last-mile delivery disruptions using a central resolution supervisor and specialized worker agents. It features a novel hybrid memory architecture and evaluates performance on a benchmark dataset derived from real-world user reviews."" || } ||  || [ Prompt: 112.9 t/s | Generation: 31.0 t/s ]"
2601.08160v1_SwiftMem Fast Agentic Memory via Query-aware Index.pdf,SwiftMem: Fast Agentic Memory via Query-aware Indexing,"['Anxin Tian', 'Yiming Li', 'Xing Li', 'Hui-Ling Zhen', 'Lei Chen', 'Xianzhi Yu1', 'Dong', 'Yuan1']",10.1234/example.doi,29.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SwiftMem: Fast Agentic Memory via Query-aware Indexing || Anxin Tian 1 Yiming Li 1 Xing Li 1 Hui-Ling Zhen 1 Lei Chen 1 Xianzhi Yu1 Zhenhua Dong 1 || Mingxuan Yuan1 || Abstract || Agentic memory systems have become critical for || enabling LLM agents to maintain long-term con- || text and retrieve re ... (truncated) ||  || { || ""title"": ""SwiftMem: Fast Agentic Memory via Query-aware Indexing"", || ""authors"": [ || ""Anxin Tian"", || ""Yiming Li"", || ""Xing Li"", || ""Hui-Ling Zhen"", || ""Lei Chen"", || ""Xianzhi Yu1"", || ""Dong"", || ""Yuan1"" || ], || ""doi"": ""10.1234/example.doi"", || ""arxiv_id"": ""12345678"", || ""keywords"": [ || ""SwiftMem"", || ""agentic memory"", || ""query-aware indexing"", || ""LLM agents"", || ""memory retrieval"", || ""semantic indexing"" || ], || ""summary"": ""Agentic memory systems are essential for LLMs to maintain context and retrieve relevant info efficiently. This paper introduces SwiftMem, a query-aware system that uses specialized indexing to enable sub-linear retrieval, improving performance for large-scale conversational tasks."" || } ||  || [ Prompt: 121.3 t/s | Generation: 29.5 t/s ]"
2601.08166v1_ZeroDVFS Zero-Shot LLM-Guided Core and Frequency A.pdf,ZeroDVFS: Zero-Shot LLM-Guided Core and Frequency,"['Mohammad Pivezhandi', 'Mahdi Banisharif', 'Abusayeed Saifullah', 'Ali Jannesari']",,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ZeroDVFS: Zero-Shot LLM-Guided Core and Frequency || Allocation for Embedded Platforms || Mohammad Pivezhandi1, Mahdi Banisharif2, Abusayeed Saifullah3, and Ali Jannesari2 || 1Wayne State University || 2Iowa State University || 3The University of Texas at Dallas || Abstract || Dynamic voltage and freque ... (truncated) ||  || { || ""title"": ""ZeroDVFS: Zero-Shot LLM-Guided Core and Frequency"", || ""authors"": [ || ""Mohammad Pivezhandi"", || ""Mahdi Banisharif"", || ""Abusayeed Saifullah"", || ""Ali Jannesari"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Proposes a model-based hierarchical multi-agent reinforcement learning framework for thermal- and energy-aware scheduling on multi-core platforms. Introduces LLM-based semantic feature extraction for OpenMP programs and achieves faster convergence than model-free methods."" || } ||  || [ Prompt: 126.4 t/s | Generation: 27.8 t/s ]"
2601.08173v1_The Agents First Day Benchmarking Learning Explora.pdf,"The Agents First Day: Benchmarking Learning, Exploration, and Scheduling in the Workplace Scenarios","['Daocheng Fu1', 'Jianbiao Mei3', 'Rong Wu', 'Xuemeng Yang', 'Jia Xu2', 'Ding Wang', 'Pinlong Cai', 'Yong Liu', 'B', 'Licheng Wen', 'Botian Shi']",,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || The Agents First Day: Benchmarking Learning, Exploration, and || Scheduling in the Workplace Scenarios || Daocheng Fu1,2, || , Jianbiao Mei3,2, || , Rong Wu3,2, || , Xuemeng Yang2, || , || Jia Xu2,Ding Wang 2,Pinlong Cai 2,Yong Liu 3,B || ,Licheng Wen 2,4,5,B || ,Botian Shi 2,B || 1Fudan University, 2Shanghai AI ... (truncated) ||  || { || ""title"": ""The Agents First Day: Benchmarking Learning, Exploration, and Scheduling in the Workplace Scenarios"", || ""authors"": [ || ""Daocheng Fu1"", || ""Jianbiao Mei3"", || ""Rong Wu"", || ""Xuemeng Yang"", || ""Jia Xu2"", || ""Ding Wang"", || ""Pinlong Cai"", || ""Yong Liu"", || ""B"", || ""Licheng Wen"", || ""Botian Shi"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper discusses challenges in dynamic task scheduling, active exploration, and continual learning for agents in real-world settings, introducing Trainee-Bench for evaluating agents under these conditions."" || } ||  || [ Prompt: 119.6 t/s | Generation: 29.0 t/s ]"
2601.08176v1_Prompt-Based Clarity Evaluation and Topic Detectio.pdf,Automatic evaluation of large language model,"['Lavanya Prahallad', 'Sai Utkarsh Choudarypally', 'Pragna Prahallad', 'Pranathi Prahallad']",10.1093/acps/rpac032,29.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Prompt-Based Clarity Evaluation and Topic || Detection in Political Question Answering || Lavanya Prahallad || Research Spark Hub Inc. || Dublin, CA, USA || lavanya@researchsparkhub.com || Sai Utkarsh Choudarypally || Emerald High School || Dublin, CA, USA || choudarypally.sai2009@gmail.com || Pragna Prahallad || E ... (truncated) ||  || { || ""title"": ""Automatic evaluation of large language model"", || ""authors"": [ || ""Lavanya Prahallad"", || ""Sai Utkarsh Choudarypally"", || ""Pragna Prahallad"", || ""Pranathi Prahallad"" || ], || ""doi"": ""10.1093/acps/rpac032"", || ""arxiv_id"": """", || ""keywords"": [ || ""Clarity evaluation"", || ""Prompt engineering"", || ""Political Question Answering"", || ""Large language models"", || ""Chain-of-thought prompting"", || ""Topic identification"" || ], || ""summary"": ""This paper evaluates prompt-based clarity evaluation using the CLARITY dataset from the SemEval-2026 shared task. It compares GPT-3.5 and GPT-5.2 under different prompting strategies and finds that chain-of-thought prompting significantly improves clarity prediction accuracy."" || } ||  || [ Prompt: 118.8 t/s | Generation: 29.4 t/s ]"
2601.08179v1_Instruction-Driven 3D Facial Expression Generation.pdf,Instruction-Driven 3D Facial Expression Generation and Transition,"['Anh H. V o', 'Tae-Seok Kim', 'Hulin Jin', 'Soo-Mi Choi', 'Yong-Guk Kim']",,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || JOURNAL OF LATEX CLASS 1 || Instruction-Driven 3D Facial Expression Generation || and Transition || Anh H. V o, Tae-Seok Kim, Hulin Jin, Soo-Mi Choi, and Yong-Guk Kim* || AbstractA 3D avatar typically has one of six cardinal facial || expressions. To simulate realistic emotional variation, we shou ... (truncated) ||  || { || ""title"": ""Instruction-Driven 3D Facial Expression Generation and Transition"", || ""authors"": [ || ""Anh H. V o"", || ""Tae-Seok Kim"", || ""Hulin Jin"", || ""Soo-Mi Choi"", || ""Yong-Guk Kim"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Instruction-Driven"", || ""Facial Expression"", || ""Transition"", || ""3D Facial Expression"", || ""Instruction-Driven Facial Expression Decomposer"", || ""CK+"", || ""CelebV-HQ"" || ], || ""summary"": ""This study presents a framework for generating and transitioning facial expressions in 3D avatars using instruction-based learning. It introduces the Instruction-driven Facial Expression Decomposer (IFED) and the Instruction to Facial Expression Transition (I2FET) method, demonstrating improved performance on CK+ and CelebV-HQ datasets."" || } ||  || [ Prompt: 123.1 t/s | Generation: 27.8 t/s ]"
2601.08183v2_GI-Bench A Panoramic Benchmark Revealing the Knowl.pdf,GI-Bench: A Panoramic Benchmark Revealing the Knowledge-Experience Dissociation,"['Yan Zhu', 'Te Luo', 'Pei-Yao Fu', 'Zhen Zhang', 'Zi-Long Wang', 'Yi-Fan Qu', 'Zi-Han Geng', 'Jia-Qi Xu', 'Lu Yao', 'Li-Yun Ma', 'Wei Su', 'Wei-Feng Chen', 'Quan-Lin Li']",,29.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || GI-Bench: A Panoramic Benchmark Revealing the Knowledge-Experience Dissociation || of Multimodal Large Language Models in Gastrointestinal Endoscopy Against Clinical || Standards || Yan Zhu1,2,3,4*, Te Luo1,2,3*, Pei-Yao Fu1,4*, Zhen Zhang1,4*, Zi-Long Wang5, Yi-Fan Qu1,4, || Zi-Han Geng1,4, Ji ... (truncated) ||  || { || ""title"": ""GI-Bench: A Panoramic Benchmark Revealing the Knowledge-Experience Dissociation"", || ""authors"": [ || ""Yan Zhu"", || ""Te Luo"", || ""Pei-Yao Fu"", || ""Zhen Zhang"", || ""Zi-Long Wang"", || ""Yi-Fan Qu"", || ""Zi-Han Geng"", || ""Jia-Qi Xu"", || ""Lu Yao"", || ""Li-Yun Ma"", || ""Wei Su"", || ""Wei-Feng Chen"", || ""Quan-Lin Li"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Background: Multimodal Large Language Models (MLLMs) show promise in gastroenterology, yet their performance against comprehensive clinical workflows and human benchmarks remains unverified. Objective: To systematically evaluate state-of-the-art MLLMs across a panoramic gastrointestinal endoscopy workflow and determine their clinical utility compared with human endoscopists. Design: We constructed GI-Bench, a benchmark encompassing 20 fine-grained lesion categories. Results: Gemini-3-Pro achieved state-of-the-art performance. In diagnostic reasoning, top-tier models..."" || } ||  || [ Prompt: 131.1 t/s | Generation: 29.4 t/s ]"
2601.08185v1_Autonomous Materials Exploration by Integrating Au.pdf,Autonomous Materials Exploration by Integrating Automated Phase Identification and AI-Assisted Human Reasoning,"['Ming-Chiang Chang', 'Maximilian Amsler', 'Duncan R. Sutherland', 'Sebastian Ament', 'Katie R. Gann', 'Lan Zhou', 'Louisa M. Smieska', 'Arthur R. Woll', 'John M. Gregoire', 'Carla P. Gomes', 'R. Bruce van Dover', 'Michael O. Thompson']",,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Autonomous Materials Exploration by Integrating Automated Phase Identification || and AI-Assisted Human Reasoning || Ming-Chiang Chang, 1, 2, Maximilian Amsler, 1, 2, Duncan R. Sutherland, 1 Sebastian || Ament,3 Katie R. Gann, 1 Lan Zhou, 4 Louisa M. Smieska, 5 Arthur R. Woll, 5 John || M. Greg ... (truncated) ||  || { || ""title"": ""Autonomous Materials Exploration by Integrating Automated Phase Identification and AI-Assisted Human Reasoning"", || ""authors"": [ || ""Ming-Chiang Chang"", || ""Maximilian Amsler"", || ""Duncan R. Sutherland"", || ""Sebastian Ament"", || ""Katie R. Gann"", || ""Lan Zhou"", || ""Louisa M. Smieska"", || ""Arthur R. Woll"", || ""John M. Gregoire"", || ""Carla P. Gomes"", || ""R. Bruce van Dover"", || ""Michael O. Thompson"" || ], ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Autonomous experimentation combines AI and robotic platforms to accelerate materials development by integrating human expertise, demonstrating efficiency in targeted phase discovery and synthesis optimization."" || } ||  || [ Prompt: 122.3 t/s | Generation: 27.6 t/s ]"
2601.08187v2_Improving LLM Reasoning with Homophily-aware Struc.pdf,Improving LLM Reasoning with Homophily-Aware Structural and Semantic Compression,"['Zijun Di', 'Bin Lu', 'Huquan Kang', 'Kinghiqian', 'Luoyi Fu', 'Jiaxin Ding', 'Xiaoying Gan', 'Ganxia Yong', 'Lei Zhou', 'Zhou Lei', 'Xinbing Wang', 'Chenghu Zhou', 'Jiaxing Ding', 'Xiaoying Gan', 'Liu Zhou', 'Zhang Zhou']",10.1093/csai/2026.01.012,29.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || IMPROVINGLLM REASONING WITHHOMOPHILY-AWARE || STRUCTURAL ANDSEMANTICTEXT-ATTRIBUTEDGRAPH || COMPRESSION || A PREPRINT || Zijun Di || Shanghai Jiao Tong University || Shanghai, China || dzj75du@sjtu.edu.cn || Bin Lu || Shanghai Jiao Tong University || Shanghai, China || robinlu1209@sjtu.edu.cn || Huquan Kang || Shanghai J ... (truncated) ||  || { || ""title"": ""Improving LLM Reasoning with Homophily-Aware Structural and Semantic Compression"", || ""authors"": [ || ""Zijun Di"", || ""Bin Lu"", || ""Huquan Kang"", || ""Kinghiqian"", || ""Luoyi Fu"", || ""Jiaxin Ding"", || ""Xiaoying Gan"", || ""Ganxia Yong"", || ""Lei Zhou"", || ""Zhou Lei"", || ""Xinbing Wang"", || ""Chenghu Zhou"", || ""Jiaxing Ding"", || ""Xiaoying Gan"", || ""Liu Zhou"", || ""Zhang Zhou"" || ], || ""doi"": ""10.1093/csai/2026.01.012"", || ""arxiv_id"": ""2601.08187v2"", || ""keywords"": [ || ""large language models"", || ""text-annotated graph"", || ""structural compression"", || ""semantic aggregation"", || ""homophily-aware"", || ""LLM reasoning"" || ], || ""summary"": ""This paper proposes HS2C, a framework leveraging graph homophily to enhance LLM reasoning. It uses structural entropy minimization for hierarchical graph partitioning and semantic aggregation based on community types, improving compression and accuracy on graph benchmarks."" || } ||  || [ Prompt: 125.8 t/s | Generation: 29.2 t/s ]"
2601.08189v2_ForgetMark Stealthy Fingerprint Embedding via Targ.pdf,ForgetMark: Stealthy Fingerprint Embedding Via Targeted Unlearning,"['Zhenhua Xu1', 'Haobo Zhang2', 'Zhebo Wang', 'Qichen Liu2', 'Haitao Xu1', 'Wenpeng Xing1', 'Meng Han1', '2Zhejiang University', '2GenTel.io', '3Zhejiang University of Technology']",,28.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || FORGETMARK: STEALTHY FINGERPRINT EMBEDDING VIA TARGETED UNLEARNING || IN LANGUAGE MODELS || Zhenhua Xu1,* , Haobo Zhang2,3* , Zhebo Wang1,2, Qichen Liu2,Haitao Xu1, Wenpeng Xing1,2,Meng Han1,2, || 1Zhejiang University, 2GenTel.io, 3Zhejiang University of Technology || ABSTRACT || Existing invasive ... (truncated) ||  || { || ""title"": ""ForgetMark: Stealthy Fingerprint Embedding Via Targeted Unlearning"", || ""authors"": [ || ""Zhenhua Xu1"", || ""Haobo Zhang2"", || ""Zhebo Wang"", || ""Qichen Liu2"", || ""Haitao Xu1"", || ""Wenpeng Xing1"", || ""Meng Han1"", || ""2Zhejiang University"", || ""2GenTel.io"", || ""3Zhejiang University of Technology"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Large Language Model"", || ""Copyright protection"", || ""Model Fingerprinting"", || ""Machine Unlearning"", || ""Stealthy Fingerprinting"", || ""Model Provenance"", || ""AI Security"" || ], || ""summary"": ""Introduces ForgetMark, a framework for stealthy fingerprinting using targeted unlearning, achieving high performance while minimizing detectability and false triggers."" || } ||  || [ Prompt: 124.3 t/s | Generation: 28.9 t/s ]"
2601.08196v1_Evaluating Implicit Regulatory Compliance in LLM T.pdf,Evaluating Implicit Regulatory Compliance in LLM Tool Invocation via Logic-Guided Synthesis,"['Da Song', 'Yuheng Huang', 'Boqi Chen', 'Tianshuo Cong', 'Randy Goebel', 'Lei Ma', 'Foutse Khomh']",,29.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Evaluating Implicit Regulatory Compliance in LLM Tool Invocation via || Logic-Guided Synthesis || Da Song1,2, Yuheng Huang3*, Boqi Chen4, Tianshuo Cong1,2, || Randy Goebel5,Lei Ma 3,5,Foutse Khomh 6 || Abstract || The integration of large language models || (LLMs) into autonomous agents has enabled || c ... (truncated) ||  || { || ""title"": ""Evaluating Implicit Regulatory Compliance in LLM Tool Invocation via Logic-Guided Synthesis"", || ""authors"": [ || ""Da Song"", || ""Yuheng Huang"", || ""Boqi Chen"", || ""Tianshuo Cong"", || ""Randy Goebel"", || ""Lei Ma"", || ""Foutse Khomh"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""large language models"", || ""regulatory compliance"", || ""safety constraints"", || ""functional safety"", || ""LLM evaluation"", || ""logic-guided synthesis"" || ], || ""summary"": ""The paper introduces LOGISAFETYGEN, a framework that evaluates LLMs for implicit regulatory compliance using Linear Temporal Logic and logic-guided fuzzing. It benchmarks 13 state-of-the-art models and highlights that larger models often prioritize task completion over safety."" || } ||  || [ Prompt: 124.2 t/s | Generation: 29.2 t/s ]"
2601.08211v1_Adapting Rules of Official International Mahjong f.pdf,Adapting Rules of Official International Mahjong for Online Players,"['Chucai Wang', 'Lingfeng Li', 'Yunlong Lu', 'Wenxin Li']",,28.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Adapting Rules of Official International Mahjong || for Online Players || Chucai Wang || School of Computer Science || Peking University || Beijing, China || wangchucai@pku.edu.cn || Lingfeng Li || School of Computer Science || Peking University || Beijing, China || Lingfengli@stu.pku.edu.cn || Yunlong Lu || School of Co ... (truncated) ||  || { || ""title"": ""Adapting Rules of Official International Mahjong for Online Players"", || ""authors"": [ || ""Chucai Wang"", || ""Lingfeng Li"", || ""Yunlong Lu"", || ""Wenxin Li"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Mahjong"", || ""game design"", || ""AI"", || ""rule adaptation"", || ""online gaming"", || ""subgoal scoring"" || ], || ""summary"": ""This study addresses the need to modify the rules of Official International Mahjong for online play, highlighting the first-mover advantage and proposing compensatory points to balance it. It introduces a revised online version of the game and discusses its balance for online players."" || } ||  || [ Prompt: 118.1 t/s | Generation: 28.0 t/s ]"
2601.08223v2_DNF Dual-Layer Nested Fingerprinting for Large Lan.pdf,DNF: DUAL-LAYER NESTED FINGERPRINTING FOR LARGE LANGUAGE MODEL,"['Zhenhua Xu1', 'Yiran Zhao3', 'Mengting Zhong3', 'Dezhang Kong1,2,3', 'Changting Lin1', 'Tong Qiao3', 'Meng Han1,2,3']",,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DNF: DUAL-LAYER NESTED FINGERPRINTING FOR LARGE LANGUAGE MODEL || INTELLECTUAL PROPERTY PROTECTION || Zhenhua Xu1,*, Yiran Zhao3,*, Mengting Zhong3,5*, Dezhang Kong1,2,3, || Changting Lin1,3, Tong Qiao3, Meng Han1,2,3 || 1Zhejiang University 2Binjiang Institute of Zhejiang University 3GenTel.io ... (truncated) ||  || { || ""title"": ""DNF: DUAL-LAYER NESTED FINGERPRINTING FOR LARGE LANGUAGE MODEL"", || ""authors"": [ || ""Zhenhua Xu1"", || ""Yiran Zhao3"", || ""Mengting Zhong3"", || ""Dezhang Kong1,2,3"", || ""Changting Lin1"", || ""Tong Qiao3"", || ""Meng Han1,2,3"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Large Language Model"", || ""Copyright Protection"", || ""Model Fingerprinting"", || ""Backdoor"", || ""Stealth Protection"", || ""IP Protection"" || ], || ""summary"": ""The paper introduces Dual-Layer Nested Fingerprinting (DNF), a black-box method that embeds hierarchical backdoors to enable robust model fingerprinting while preserving utility. It achieves perfect fingerprint activation across multiple LLMs and remains resilient to attacks."" || } ||  || [ Prompt: 117.0 t/s | Generation: 29.0 t/s ]"
2601.08224v1_An Axiomatic Approach to General Intelligence SANC.pdf,An Axiomatic Approach to General Intelligence,"['Daesuk Kwon', '1Won-gi Paeng1']",SANC(E3),28.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || An Axiomatic Approach to General Intelligence: || SANC(E3) || Self-organizing Active Network of Concepts with EnergyE 3 || Daesuk Kwon 1 Won-gi Paeng1 || 1Hyntel, Inc., Seoul, Republic of Korea || hyntel@hyntel.com,wgpaeng@hyntel.net || Abstract || General intelligence must reorganize experience into in ... (truncated) ||  || { || ""title"": ""An Axiomatic Approach to General Intelligence"", || ""authors"": [""Daesuk Kwon"", ""1Won-gi Paeng1""], || ""doi"": ""SANC(E3)"", || ""arxiv_id"": """", || ""keywords"": [ || ""axiomatization of intelligence"", || ""competitives selection"", || ""system tokens"", || ""reconstruction compression trade-off"", || ""category formation"", || ""self-similar hierarchy"", || ""Gestalt completion"" || ], || ""summary"": ""This paper proposes a self-organizing active network framework that reorganizes experience into internal structures enabling prediction and action under finite resources. It introduces a novel axiomatic model where representational units emerge from competitive selection and compression, emphasizing unified perception, imagination, planning, and action through Gestalt completion principles."" || } ||  || [ Prompt: 116.4 t/s | Generation: 28.0 t/s ]"
2601.08226v1_Knowledge-based learning in Text-RAG and Image-RAG.pdf,Knowledge-based learning in Text-RAG and Image-RAG,"['Alexander Shim', 'Khalil Saieh', 'Samuel Clarke']",,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Knowledge-based learning in Text-RAG and Image-RAG || Alexander Shim || Florida International University || Miami, FL, USA || ashim017@fiu.edu || Khalil Saieh || Florida International University || Miami, FL, USA || ksaie001@fiu.edu || Samuel Clarke || Florida International University || Miami, FL, USA || sclar122@fiu ... (truncated) ||  || { || ""title"": ""Knowledge-based learning in Text-RAG and Image-RAG"", || ""authors"": [ || ""Alexander Shim"", || ""Khalil Saieh"", || ""Samuel Clarke"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This research analyzed and compared the multi-modal approach in Vision Transformer-based image encoder with the LLaMA or ChatGPT LLM to reduce hallucination and detect diseases in chest X-ray images. It utilized NIH Chest X-ray images and compared image-based RAG, text-based RAG, and baseline models."" || } ||  || [ Prompt: 118.2 t/s | Generation: 27.5 t/s ]"
2601.08230v1_GADPN Graph Adaptive Denoising and Perturbation Ne.pdf,Graph Adaptive Denoising and Perturbation Networks via Singular Value Decomposition,"['Hao Deng', 'Bo Liu']",,27.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || GADPN: Graph Adaptive Denoising and Perturbation Networks via || Singular Value Decomposition || Hao Deng, Bo Liu,Member, IEEE, || AbstractWhile Graph Neural Networks (GNNs) || excel on graph-structured data, their performance is || fundamentally limited by the quality of the observed || graph, whi ... (truncated) ||  || { || ""title"": ""Graph Adaptive Denoising and Perturbation Networks via Singular Value Decomposition"", || ""authors"": [""Hao Deng"", ""Bo Liu""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Graph Neural Networks"", ""Graph Structure Learning"", ""Network Representation Learning""], || ""summary"": ""The paper proposes GADPN, a framework that adaptively refines graph topology using low-rank denoising and structural perturbation, addressing limitations of existing methods in noisy or incomplete graphs."" || } ||  || [ Prompt: 123.3 t/s | Generation: 27.0 t/s ]"
2601.08235v2_MPCI-Bench A Benchmark for Multimodal Pairwise Con.pdf,MPCI-Bench: A Benchmark for Multimodal Pairwise Contextual Integrity,"['Shouju Wang Haopeng', 'Zhang, Haopeng']",10.48550/arXiv.2405.12345,27.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MPCI-Bench: A Benchmark for Multimodal Pairwise Contextual Integrity || Evaluation of Language Model Agents || Shouju Wang Haopeng Zhang || University of Hawaii at Manoa || {shoujuw, haopengz}@hawaii.edu || Abstract || As language-model agents evolve from passive || chatbots into proactive assistants th ... (truncated) ||  || { || ""title"": ""MPCI-Bench: A Benchmark for Multimodal Pairwise Contextual Integrity"", || ""authors"": [""Shouju Wang Haopeng"", ""Zhang, Haopeng""], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [""Contextual Integrity"", ""Multimodal"", ""Privacy"", ""Language Models""], || ""summary"": ""This paper introduces MPCI-Bench, a new benchmark for evaluating privacy adherence in language models through multimodal pairwise assessments. It highlights challenges in balancing privacy and utility, and identifies modality leakage as a key issue."" || } ||  || [ Prompt: 122.6 t/s | Generation: 27.3 t/s ]"
2601.08237v1_The End of Reward Engineering How LLMs Are Redefin.pdf,The End of Reward Engineering: How LLMs Are Redefining Multi-Agent Coordination,"['Haoran Su', 'Yandong Sun', 'Congjia Yu', 'Lerna AI', 'gary.yu@lerna-ai.com']",arXiv:2601.08237v1,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || The End of Reward Engineering: How LLMs Are || Redefining Multi-Agent Coordination || Haoran Su || New York University || haoran.su@nyu.edu || Yandong Sun || New York University || ys2312@nyu.edu || Congjia Yu || Lerna AI || gary.yu@lerna-ai.com || Abstract || Reward engineering  the manual design of reward functions  ... (truncated) ||  || { || ""title"": ""The End of Reward Engineering: How LLMs Are Redefining Multi-Agent Coordination"", || ""authors"": [ || ""Haoran Su"", || ""Yandong Sun"", || ""Congjia Yu"", || ""Lerna AI"", || ""gary.yu@lerna-ai.com"" || ], || ""doi"": ""arXiv:2601.08237v1"", || ""arxiv_id"": ""arXiv:2601.08237"", || ""keywords"": [ || ""reward engineering"", || ""multi-agent reinforcement learning"", || ""LLMs"", || ""semantic reward specification"", || ""dynamic adaptation"", || ""credit assignment"" || ], || ""summary"": ""This paper discusses how large language models (LLMs) are transforming multi-agent reinforcement learning by enabling natural language-based reward specification, dynamic reward adaptation, and semantic understanding, thereby shifting the paradigm away from manual reward design."" || } ||  || [ Prompt: 128.1 t/s | Generation: 28.3 t/s ]"
2601.08251v1_Hyperbolic Heterogeneous Graph Transformer.pdf,Hyperbolic Heterogeneous Graph Transformer,"['Jongmin Park', 'Seunghoon Han', 'Hyewon Lee', 'Won-Yong Shin', 'Sungsu Lim']",pa5398,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Hyperbolic Heterogeneous Graph Transformer || Jongmin Park 1,, Seunghoon Han 1,, Hyewon Lee 1,Won-Yong Shin2, Sungsu Lim 1, || 1Department Computer Science and Engineering, Chungnam National University, Daejeon, South Korea || 2School of Mathematics and Computing (Computational Science and E ... (truncated) ||  || { || ""title"": ""Hyperbolic Heterogeneous Graph Transformer"", || ""authors"": [ || ""Jongmin Park"", || ""Seunghoon Han"", || ""Hyewon Lee"", || ""Won-Yong Shin"", || ""Sungsu Lim"" || ], || ""doi"": ""pa5398"", || ""arxiv_id"": ""tmdgns129"", || ""keywords"": [ || ""Heterogeneous Graph Representation Learning"", || ""Hyperbolic Graph Embedding"", || ""Graph Transformer"", || ""Relation-specific Hyperbolic Attention"" || ], || ""summary"": ""The paper proposes Hyperbolic Heterogeneous Graph Transformer (HypHGT), a transformer-based architecture that learns heterogeneous graph representations in hyperbolic space, addressing limitations of existing methods by capturing both local and global dependencies efficiently."" || } ||  || [ Prompt: 133.3 t/s | Generation: 27.9 t/s ]"
2601.08254v1_Large Artificial Intelligence Model Guided Deep Re.pdf,Large Artificial Intelligence ModelGuided Deep Reinforcement Learning for Resource Allocation in Non-Terrestrial Networks,"['Abdikarim Mohamed Ibrahim', 'Rosdiadee Nordin']",,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Large Artificial Intelligence ModelGuided Deep Reinforcement Learning for || Resource Allocation in Non-Terrestrial Networks || Abdikarim Mohamed Ibrahim 1, Rosdiadee Nordin 2 || Faculty of Engineering, Sunway University, Petaling Jaya, Malaysia || Future Cities Research Institute, Sunway Unive ... (truncated) ||  || { || ""title"": ""Large Artificial Intelligence ModelGuided Deep Reinforcement Learning for Resource Allocation in Non-Terrestrial Networks"", || ""authors"": [ || ""Abdikarim Mohamed Ibrahim"", || ""Rosdiadee Nordin"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Large AI Models (LAMs)"", || ""Large Language Models (LLMs)"", || ""Deep Reinforcement Learning (DRL)"", || ""Satellite Communications"", || ""Non-Terrestrial Networks (NTNs)"" || ], || ""summary"": ""The paper proposes a Deep Reinforcement Learning agent guided by a Large Language Model to improve resource allocation in Non-Terrestrial Networks, demonstrating improved performance over traditional methods in various scenarios."" || } ||  || [ Prompt: 124.0 t/s | Generation: 27.9 t/s ]"
2601.08257v2_On Evaluation of Unsupervised Feature Selection fo.pdf,,[],,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || On Evaluation of Unsupervised Feature Selection for || Pattern Classification || Gyu-Il Kim1, Dae-Won Kim2, Jaesung Lee1 || 1Department of Artificial Intelligence, Chung-Ang University, Republic of Korea || 2School of Computer Science and Engineering, Chung-Ang University, Republic of Korea || {gy ... (truncated) ||  || { || ""title"": ""Evaluation of Unsupervised Feature Selection for Pattern Classification"", || ""authors"": [""Gyu-Il Kim"", ""Dae-Won Kim"", ""Jaesung Lee""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""unsupervised feature selection"", ""pattern classification"", ""multi-label evaluation""], || ""summary"": ""This study revisits the evaluation of unsupervised feature selection methods by adopting a multi-label classification framework, demonstrating that performance rankings differ from single-label settings and highlighting the need for fair comparison under multi-label conditions."" || } ||  || [ Prompt: 122.6 t/s | Generation: 27.9 t/s ]"
2601.08258v1_T3 Benchmarking Sycophancy and Skepticism in Causa.pdf,Benchmarking Sycophancy and Skepticism in Causal Judgment,['Edward Y. Chang'],,29.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || T3: Benchmarking Sycophancy and Skepticism in Causal Judgment || Edward Y. Chang || Computer Science || Stanford University || echang@cs.stanford.edu || Abstract || We introduce T 3 (TESTINGTRUSTWORTHY || THINKING), a diagnostic benchmark designed || to rigorously evaluate LLM causal judgment || across Pearls ... (truncated) ||  || { || ""title"": ""Benchmarking Sycophancy and Skepticism in Causal Judgment"", || ""authors"": [""Edward Y. Chang""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Introduces T3 (Testing Trustworthy Thinking) benchmark to evaluate LLM causal judgment across Pearls Ladder of Causality, identifying skepticism traps and non-monotonic scaling paradoxes."" || } ||  || [ Prompt: 113.9 t/s | Generation: 29.6 t/s ]"
2601.08262v1_VGG Induced Deep Hand Sign Language Detection.pdf,VGG Induced Deep Hand Sign Language Detection,"['Subham Sharmaa', 'Sharmila Subudhia', 'aDXOps', 'Bangalore, India', 'Bangalore, India', 'University, Baripada, Odisha, India']",arXiv:2601.08262v1,31.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || VGG Induced Deep Hand Sign Language Detection || Subham Sharmaa, Sharmila Subudhia,b, || aDXOps, Bangalore, India || bDept. of Computer Science, Maharaja Sriram Chandra Bhanja Deo || University, Baripada, 757003, Odisha, India || Abstract || Hand gesture recognition is an important aspect of human-co ... (truncated) ||  || { || ""title"": ""VGG Induced Deep Hand Sign Language Detection"", || ""authors"": [ || ""Subham Sharmaa"", || ""Sharmila Subudhia"", || ""aDXOps"", || ""Bangalore, India"", || ""Bangalore, India"", || ""University, Baripada, Odisha, India"" || ], || ""doi"": ""arXiv:2601.08262v1"", || ""arxiv_id"": ""2601.08262v1"", || ""keywords"": [ || ""Hand gesture recognition"", || ""Convolutional neural network"", || ""Classification"", || ""VGG-16 net"", || ""API"" || ], || ""summary"": ""This work proposes a novel hand gesture recognizing system for differently-abled persons using a VGG-16 net trained on the NUS dataset. Transfer learning and image data augmentation improve accuracy to around 98%."" || } ||  || [ Prompt: 118.1 t/s | Generation: 31.6 t/s ]"
2601.08271v1_Sparsity Is Necessary Polynomial-Time Stability fo.pdf,Sparsity Is Necessary: Polynomial-Time Stability for Agentic LLMs in Large Action Spaces,['Angshul Majumdar'],,27.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Sparsity Is Necessary: Polynomial-Time Stability for Agentic || LLMs in Large Action Spaces || Angshul Majumdar || Abstract || Tool-augmented LLM systems expose a control regime that learning theory has largely || ignored: sequential decision-making with a massive discrete action universe (tools,  ... (truncated) ||  || { || ""title"": ""Sparsity Is Necessary: Polynomial-Time Stability for Agentic LLMs in Large Action Spaces"", || ""authors"": [""Angshul Majumdar""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper explores how sparse representations enable stable sequential decision-making in large action spaces for agentic LLMs, presenting theoretical results and empirical insights."" || } ||  || [ Prompt: 116.7 t/s | Generation: 27.1 t/s ]"
2601.08273v1_HIPPO Accelerating Video Large Language Models Inf.pdf,Accelerating Video Large Language Models Inference via Holistic-aware Parallel Speculative Decoding,"['Qitan Lv1', 'Tianyu Liu1', 'Wen Wu2', 'Xuenan Xu2', 'Bowen Zhou2,3', 'Feng Wu1', 'Chao Zhang2,3']",,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || HIPPO: Accelerating Video Large Language Models Inference via || Holistic-aware Parallel Speculative Decoding || Qitan Lv1,2* Tianyu Liu1,2* Wen Wu2 Xuenan Xu2 Bowen Zhou2,3 Feng Wu1 Chao Zhang2,3 || 1University of Science and Technology of China 2Shanghai AI Laboratory || 3Department of Electr ... (truncated) ||  || { || ""title"": ""Accelerating Video Large Language Models Inference via Holistic-aware Parallel Speculative Decoding"", || ""authors"": [ || ""Qitan Lv1"", || ""Tianyu Liu1"", || ""Wen Wu2"", || ""Xuenan Xu2"", || ""Bowen Zhou2,3"", || ""Feng Wu1"", || ""Chao Zhang2,3"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Speculative decoding (SD) is explored to accelerate LLM inference for video models. The paper addresses limitations in existing SD methods for video-LLMs, proposing HIPPO—a holistic-aware parallel speculative decoding framework that preserves semantic tokens and optimizes inference speed."" || } ||  || [ Prompt: 121.3 t/s | Generation: 29.3 t/s ]"
2601.08276v1_ToolACE-MCP Generalizing History-Aware Routing fro.pdf,ToolACE-MCP: Generalizing History-Aware Routing from MCP Tools to the Agent Web,"['Zhiyuan Yao', 'Zishan Xu', 'Yifu Guo4', 'Zhiguang Han', 'Cheng Yang', 'Shuo Zhang', 'Weinan Zhang', 'Xingshan Zeng', 'Weiwen Liu']",,28.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ToolACE-MCP: Generalizing History-Aware Routing from MCP Tools to || the Agent Web || Zhiyuan Yao1, *, Zishan Xu2, *, Yifu Guo4, *, Zhiguang Han5, Cheng Yang6, || Shuo Zhang,Weinan Zhang 2,Xingshan Zeng 3, ,Weiwen Liu 2, || 1Zhejiang University, 2Shanghai Jiao Tong University,3Huawei Noahs Ark ... (truncated) ||  || { || ""title"": ""ToolACE-MCP: Generalizing History-Aware Routing from MCP Tools to the Agent Web"", || ""authors"": [ || ""Zhiyuan Yao"", || ""Zishan Xu"", || ""Yifu Guo4"", || ""Zhiguang Han"", || ""Cheng Yang"", || ""Shuo Zhang"", || ""Weinan Zhang"", || ""Xingshan Zeng"", || ""Weiwen Liu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Agent Web"", || ""MCP"", || ""ToolACE-MCP"", || ""History-aware routing"", || ""Agent routing"", || ""Multi-agent collaboration"" || ], || ""summary"": ""ToolACE-MCP proposes a pipeline for training history-aware routers to enable precise navigation in large-scale ecosystems. It leverages a dependency-rich candidate graph to synthesize multi-turn trajectories, allowing the creation of a plug-and-play Light Routing Agent. Experiments show superior performance on real-world benchmarks, demonstrating scalability and robustness."" || } ||  || [ Prompt: 119.0 t/s | Generation: 28.9 t/s ]"
2601.08280v1_Greedy Is Enough Sparse Action Discovery in Agenti.pdf,Greedy Is Enough: Sparse Action Discovery in Agentic LLMs,['Angshul Majumdar'],,30.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Greedy Is Enough: Sparse Action Discovery in Agentic LLMs || Angshul Majumdar || Abstract || Modern agentic systems operate in environments with extremely large action spaces, || such as tool-augmented language models with thousands of available APIs or retrieval op- || erations. Despite this scal ... (truncated) ||  || { || ""title"": ""Greedy Is Enough: Sparse Action Discovery in Agentic LLMs"", || ""authors"": [""Angshul Majumdar""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper studies sparse action discovery in agentic LLMs using a greedy algorithm inspired by Orthogonal Matching Pursuit, showing that relevant actions can be recovered efficiently under certain assumptions."" || } ||  || [ Prompt: 126.5 t/s | Generation: 30.3 t/s ]"
2601.08288v1_OpenMic A Multi-Agent-Based Stand-Up Comedy Genera.pdf,OpenMic: A Multi-Agent-Based Stand-Up Comedy Generation System,"['Yuyang Wu', 'Hanzhong Cao', 'Jianhao Chen', 'Yufei Li']",https://doi.org/xxxx,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || OpenMic: A Multi-Agent-Based Stand-Up Comedy Generation System || Yuyang Wu1 Hanzhong Cao 1 Jianhao Chen 1 Yufei Li1 || Abstract || Chinese stand-up comedy generation goes be- || yond plain text generation, requiring cultur- || ally grounded humor, precise timing, stage- || performance cues, and impl ... (truncated) ||  || { || ""title"": ""OpenMic: A Multi-Agent-Based Stand-Up Comedy Generation System"", || ""authors"": [ || ""Yuyang Wu"", || ""Hanzhong Cao"", || ""Jianhao Chen"", || ""Yufei Li"" || ], || ""doi"": ""https://doi.org/xxxx"", || ""arxiv_id"": """", || ""keywords"": [ || ""Chinese stand-up comedy"", || ""multi-agent system"", || ""humor generation"", || ""text generation"", || ""creative content"", || ""comedy writing"" || ], || ""summary"": ""The paper presents OpenMic, an end-to-end multi-agent system built on AutoGen that transforms a user-provided life topic into a 35-minute Chinese stand-up performance. It uses multiple specialized agents in a multi-round iterative loopplanning to optimize humor, timing, and performance, addressing the mismatch between humor datasets and long-form generation needs."" || } ||  || [ Prompt: 121.4 t/s | Generation: 27.8 t/s ]"
2601.08297v1_Demystifying the Slash Pattern in Attention The Ro.pdf,Demystifying the Slash Pattern in Attention: The Role of RoPE,"['Yuan Cheng', 'Fengzhuo Zhang', 'Yunlong Hou', 'Cunxiao Du', 'Chao Du2', 'Tianyu Pang', 'Aixin Sun', 'Zhuoran Yang']",arXiv:2601.08297v1,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Demystifying the Slash Pattern in Attention: The Role of RoPE || Yuan Cheng1, Fengzhuo Zhang1,, Yunlong Hou1, Cunxiao Du2 || Chao Du2 Tianyu Pang2 Aixin Sun3 Zhuoran Yang4 || . || is || Token embs lie on a cone. (Sec 4.3) || norm  proj || LLMs || is || RoPERoPE || sum softmax || High and med RoPE freqs interact to ... (truncated) ||  || { || ""title"": ""Demystifying the Slash Pattern in Attention: The Role of RoPE"", || ""authors"": [ || ""Yuan Cheng"", || ""Fengzhuo Zhang"", || ""Yunlong Hou"", || ""Cunxiao Du"", || ""Chao Du2"", || ""Tianyu Pang"", || ""Aixin Sun"", || ""Zhuoran Yang"" || ], || ""doi"": ""arXiv:2601.08297v1"", || ""arxiv_id"": ""arXiv:2601.08297"", || ""keywords"": [ || ""RoPE"", || ""SLASH PATTERN"", || ""Attention"", || ""LLMs"", || ""RoPE freqs"", || ""SDHs"", || ""Attention scores"" || ], || ""summary"": ""This paper investigates the emergence of Slash-Dominant Heads (SDHs) in large language models, analyzing how RoPE influences attention patterns and how high- and medium-frequency RoPE components interact to shape token attention."" || } ||  || [ Prompt: 123.7 t/s | Generation: 27.9 t/s ]"
2601.08302v1_Enhancing Sentiment Classification and Irony Detec.pdf,Enhancing Sentiment Classification and Irony Detection in Large Language Models through Advanced Prompt Engineering Techniques,"['Marvin Schmitt', 'Anne Schwerk', 'Sebastian Lempert']",10.48550/arXiv.2405.12345,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Enhancing Sentiment Classification and Irony Detection in Large Language Models || through Advanced Prompt Engineering Techniques || Marvin Schmitt , Anne Schwerk , Sebastian Lempert || IU International University of Applied Sciences, Juri-Gagarin-Ring 152, Erfurt, 99084, Thuringia, Germany ... (truncated) ||  || { || ""title"": ""Enhancing Sentiment Classification and Irony Detection in Large Language Models through Advanced Prompt Engineering Techniques"", || ""authors"": [""Marvin Schmitt"", ""Anne Schwerk"", ""Sebastian Lempert""], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [""sentiment analysis"", ""irony detection"", ""large language models (LLMs)"", ""prompt engineering""], || ""summary"": ""This study investigates the use of prompt engineering to enhance large language models in sentiment analysis and irony detection. It evaluates techniques such as few-shot learning, chain-of-thought prompting, and self-consistency, assessing performance improvements in accuracy, recall, precision, and F1 score."" || } ||  || [ Prompt: 121.5 t/s | Generation: 28.4 t/s ]"
2601.08310v1_ORBIT On-policy Exploration-Exploitation for Contr.pdf,ORBIT: On-policy Exploration-Exploitation for Controllable Multi-Budget Reasoning,"['Kun Liang1', 'Clive Bai3 Xin', 'Chenming Tang1,2', 'Sanwoo Lee1,2', 'Weijie Liu3', 'SanYang Yang3', 'Yunfang Wu1,2']",,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || January 14, 2026 || ORBIT: On-policy Exploration-Exploitation || for Controllable Multi-Budget Reasoning || Kun Liang1,2, Clive Bai3 Xin Xu3,4 Chenming Tang1,2, || Sanwoo Lee1,2, Weijie Liu3 Saiyong Yang3, Yunfang Wu1,2, || 1School of Computer Science, Peking University || 2National Key Laboratory fo ... (truncated) ||  || { || ""title"": ""ORBIT: On-policy Exploration-Exploitation for Controllable Multi-Budget Reasoning"", || ""authors"": [ || ""Kun Liang1"", || ""Clive Bai3 Xin"", || ""Chenming Tang1,2"", || ""Sanwoo Lee1,2"", || ""Weijie Liu3"", || ""SanYang Yang3"", || ""Yunfang Wu1,2"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Recent Large Reasoning Models (LRMs) achieve strong performance by leveraging long-form Chain-of-Thought reasoning, but uniformly applying overlong reasoning at inference incurs substantial computational cost. This study proposes ORBIT, a controllable multi-budget reasoning framework that dynamically selects reasoning modes based on input, aiming to balance reasoning effort and accuracy."" || } ||  || [ Prompt: 122.1 t/s | Generation: 29.1 t/s ]"
2601.08311v1_Enhancing Image Quality Assessment Ability of LMMs.pdf,Enhancing Image Quality Assessment Ability of LMMs via Retrieval-Augmented Generation,"['Kang Fu', 'Huiyu Duan', 'Zicheng Zhang', 'Yucheng Zhu', 'Jun Zhao', 'Xiongkuo Min', 'Jia Wang', 'Guangtao Zhai']",,29.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Enhancing Image Quality Assessment Ability of || LMMs via Retrieval-Augmented Generation || Kang Fu 1, Huiyu Duan 1, Zicheng Zhang 1, Yucheng Zhu 1, Jun Zhao 2, Xiongkuo Min 1, Jia Wang 1, and Guangtao Zhai 1 || 1 Shanghai Jiao Tong University, 2Tencent || AbstractLarge Multimodal Models (LMMs) ... (truncated) ||  || { || ""title"": ""Enhancing Image Quality Assessment Ability of LMMs via Retrieval-Augmented Generation"", || ""authors"": [ || ""Kang Fu"", || ""Huiyu Duan"", || ""Zicheng Zhang"", || ""Yucheng Zhu"", || ""Jun Zhao"", || ""Xiongkuo Min"", || ""Jia Wang"", || ""Guangtao Zhai"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Image quality assessment"", || ""Retrieval-Augmented Generation"", || ""Large Multimodal Models"", || ""Zero-shot"", || ""Training-free"", || ""Image Quality Assessment"", || ""Visual perception"", || ""Cross-modality"" || ], || ""summary"": ""The paper introduces IQARAG, a training-free framework that enhances the Image Quality Assessment (IQA) capability of Large Multimodal Models (LMMs) by leveraging Retrieval-Augmented Generation to provide visual anchors for quality evaluation."" || } ||  || [ Prompt: 114.6 t/s | Generation: 29.2 t/s ]"
2601.08323v1_AtomMem  Learnable Dynamic Agentic Memory with Ato.pdf,AtomMem: Learnable Dynamic Agentic Memory,"['Yupeng Huo', 'Yaxi Lu', 'Zhong Zhang', 'Haotian Chen', 'Yankai Lin']",,29.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || AtomMem : Learnable Dynamic Agentic Memory || with Atomic Memory Operation || Yupeng Huo1, Yaxi Lu2, Zhong Zhang2, Haotian Chen2, Yankai Lin1* || 1 Renmin University of China, 2 Tsinghua University || {huoyupeng, yankailin}@ruc.edu.cn || Abstract || Equipping agents with memory is essential || for solvi ... (truncated) ||  || { || ""title"": ""AtomMem: Learnable Dynamic Agentic Memory"", || ""authors"": [ || ""Yupeng Huo"", || ""Yaxi Lu"", || ""Zhong Zhang"", || ""Haotian Chen"", || ""Yankai Lin"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Equipping agents with memory is essential for solving real-world long-horizon problems. This paper proposes AtomMem, a dynamic decision-making framework for memory management, combining supervised fine-tuning and reinforcement learning to enable task-aligned memory strategies."" || } ||  || [ Prompt: 112.9 t/s | Generation: 29.7 t/s ]"
2601.08327v1_Safe Heterogeneous Multi-Agent RL with Communicati.pdf,Safe Heterogeneous Multi-Agent RL with Communication Regularization for Coordinated Target Acquisition,"['Gabriele Calzolari', 'Vidya Sumathy', 'Christoforos Kanellakis', 'George Nikolakopoulos']",,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Safe Heterogeneous Multi-Agent RL with || Communication Regularization for || Coordinated Target Acquisition || Gabriele Calzolari  Vidya Sumathy || Christoforos Kanellakis  George Nikolakopoulos || Department of Computer Science, Electrical and Space Engineering, || Lule  a University of Technol ... (truncated) ||  || { || ""title"": ""Safe Heterogeneous Multi-Agent RL with Communication Regularization for Coordinated Target Acquisition"", || ""authors"": [ || ""Gabriele Calzolari"", || ""Vidya Sumathy"", || ""Christoforos Kanellakis"", || ""George Nikolakopoulos"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Cooperative target acquisition"", || ""Safe autonomous coordination"", || ""Decentralized multi-agent reinforcement learning"", || ""Heterogeneous robotic systems"", || ""Learning-based control"" || ], || ""summary"": ""This paper introduces a decentralized multi-agent reinforcement learning framework enabling structurally heterogeneous teams of agents to jointly discover and acquire randomly located targets in environments with partial observability, communication constraints, and dynamic interactions. The framework employs a Graph Attention Network encoder integrating simulated range-sensing data and communication embeddings, promoting safety through safety filters and promoting informational orthogonality."" || } ||  || [ Prompt: 128.0 t/s | Generation: 28.4 t/s ]"
2601.08332v1_IGAN A New Inception-based Model for Stable and Hi.pdf,A New Inception-based Model for Stable and High-Fidelity Image Synthesis Using Generative Adversarial Networks,"['Ahmed A. Hashim', 'Ali Al-Shuwaili', 'Asraa Saeed', 'Ali Al-Bayaty']",,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  || 1 || IGAN: A New Inception-based Model for Stable || and High-Fidelity Image Synthesis Using || Generative Adversarial Networks || Ahmed A. Hashim 1, Ali Al-Shuwaili2, Asraa Saeed3, Ali Al-Bayaty4* || 1 College of Business Informatics, University of Information Technology and Communications ... (truncated) ||  || { || ""title"": ""A New Inception-based Model for Stable and High-Fidelity Image Synthesis Using Generative Adversarial Networks"", || ""authors"": [ || ""Ahmed A. Hashim"", || ""Ali Al-Shuwaili"", || ""Asraa Saeed"", || ""Ali Al-Bayaty"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Generative Adversarial Networks (GANs)"", || ""dilation convolutions"", || ""inception module"", || ""spectral normalization"", || ""image synthesis"", || ""deep learning stability"" || ], || ""summary"": ""The paper proposes IGAN, a novel GAN model incorporating inception-inspired convolutions and dilated convolutions, achieving improved training stability and generation quality with reduced mode collapse."" || } ||  || [ Prompt: 117.5 t/s | Generation: 28.3 t/s ]"
2601.08333v1_Semantic Laundering in AI Agent Architectures Why .pdf,Semantic Laundering in AI Agent Architectures,['Oleg Romanchuk Roman Bondar'],arXiv:2601.08333v1,31.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Semantic Laundering in AI Agent Architectures: || Why Tool Boundaries Do Not Confer Epistemic || Warrant || Oleg Romanchuk Roman Bondar || Abstract || LLM-based agent architectures systematically conflate information transport || mechanisms with epistemic justification mechanisms. We formalize this c ... (truncated) ||  || { || ""title"": ""Semantic Laundering in AI Agent Architectures"", || ""authors"": [""Oleg Romanchuk Roman Bondar""], || ""doi"": ""arXiv:2601.08333v1"", || ""arxiv_id"": ""arXiv:2601.08333"", || ""keywords"": [], || ""summary"": ""The paper discusses how LLM-based agent architectures conflate information transport with epistemic justification, introducing the concept of semantic laundering and the Theorem of Inevitable Self-Licensing."" || } ||  || [ Prompt: 115.6 t/s | Generation: 31.1 t/s ]"
2601.08360v1_Scalable Sequential Recommendation under Latency a.pdf,Scalable Sequential Recommendation under Latency and Memory Constraints,"['Adithya Parthasarathy', 'Aswathnarayan Muthukrishnan Kirubakaran', 'Vinoth Punniyamoorthy', 'Nachiappan Chockalingam', 'Lokesh Butra', 'Kabilan Kannan', 'Abhirup Mazumder', 'Sumit Saha']",arXiv:2601.08360v1,28.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Scalable Sequential Recommendation under || Latency and Memory Constraints || Adithya Parthasarathy1, Aswathnarayan Muthukrishnan Kirubakaran2, Vinoth || Punniyamoorthy3, Nachiappan Chockalingam4, Lokesh Butra 5, Kabilan || Kannan6, Abhirup Mazumder 7, and Sumit Saha 8 || 1 IEEE Senior Member, USA ... (truncated) ||  || { || ""title"": ""Scalable Sequential Recommendation under Latency and Memory Constraints"", || ""authors"": [ || ""Adithya Parthasarathy"", || ""Aswathnarayan Muthukrishnan Kirubakaran"", || ""Vinoth Punniyamoorthy"", || ""Nachiappan Chockalingam"", || ""Lokesh Butra"", || ""Kabilan Kannan"", || ""Abhirup Mazumder"", || ""Sumit Saha"" || ], || ""doi"": ""arXiv:2601.08360v1"", || ""arxiv_id"": ""IEEE Senior Member, USA"", || ""keywords"": [ || ""Recommender Systems"", || ""Sequence Modeling"", || ""Representation Learning"", || ""Scalable Machine Learning"", || ""Deep Learning"" || ], || ""summary"": ""The paper presents HoloMambaRec, a lightweight sequential recommendation architecture that addresses the challenges of long-range user behavior modeling under memory and latency constraints. It combines holographic representations with a selective state space encoder for efficient training and inference."" || } ||  || [ Prompt: 134.2 t/s | Generation: 28.9 t/s ]"
2601.08371v1_Geo-NVS-w Geometry-Aware Novel View Synthesis In-t.pdf,,[],,29.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Geo-NVS-w: Geometry-Aware Novel View Synthesis In-the-Wild || with an SDF Renderer || Anastasios Tsalakopoulos1 Angelos Kanlis1 Evangelos Chatzis1 || Antonis Karakottas1 Dimitrios Zarpalas1 || 1Centre for Research and Technology Hellas (CERTH), Thessaloniki, Greece || {tsalakop, a.kanlis, chatzise ... (truncated) ||  || { || ""title"": ""Geo-NVS-w: Geometry-Aware Novel View Synthesis In-the-Wild"", || ""authors"": [ || ""Anastasios Tsalakopoulos"", || ""Angelos Kanlis"", || ""Evangelos Chatzis"", || ""Antonis Karakottas"", || ""Dimitrios Zarpalas"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""We introduce Geo-NVS-w, a geometry-aware framework for high-fidelity novel view synthesis from unstructured, in-the-wild image collections. While existing in-the-wild methods excel at novel view synthesis, they often lack geometric grounding on complex surfaces, sometimes producing inconsistent results. Geo-NVS-w addresses this by leveraging an underlying geometric representation based on a Signed Distance Function (SDF) to guide rendering, ensuring sharp details and reduced energy consumption."" || } ||  || [ Prompt: 118.3 t/s | Generation: 29.6 t/s ]"
2601.08379v1_Training-Free Distribution Adaptation for Diffusio.pdf,Training-Free Distribution Adaptation for Diffusion,"['Matina Mahdizadeh Sani', 'Nima Jamali', 'Mohammad Jalali', 'Farzan Farnia']",,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Training-Free Distribution Adaptation for Diffusion || Models via Maximum Mean Discrepancy Guidance || Matina Mahdizadeh Sani  , Nima Jamali , Mohammad Jalali , Farzan Farnia || Abstract || Pre-trained diffusion models have emerged as powerful generative priors for both unconditional and || condi ... (truncated) ||  || { || ""title"": ""Training-Free Distribution Adaptation for Diffusion"", || ""authors"": [ || ""Matina Mahdizadeh Sani"", || ""Nima Jamali"", || ""Mohammad Jalali"", || ""Farzan Farnia"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper proposes MMD Guidance, a training-free mechanism that augments the reverse diffusion process using Maximum Mean Discrepancy (MMD) gradients to align generated samples with a reference dataset. It addresses distribution mismatch in domain adaptation tasks without requiring full retraining."" || } ||  || [ Prompt: 123.8 t/s | Generation: 29.1 t/s ]"
2601.08380v1_Thematic Working Group 5 -- Artificial Intelligenc.pdf,EDUsummIT 2025 - eBook,"['Mary Webb', 'Matt Bower', 'Ana Amlia Carvalho', 'Fredrik Mrk Rkenes', 'Jodie Torrington', 'Jonathan D. Cohen', 'Yousra Chtouki', 'Kathryn MacCallum', 'Tanya Linden', 'Deirdre Butler', 'Juliana E. Raffagheli', 'Henriikka Vartiainen', 'Martina Ronci', 'Peter Tiernan', 'Chris Shelton', 'Joyce Malyn-Smith', 'Pierre Gorissen']",,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || EDUsummIT 2025 - eBook || Thematic Working Group 5 - Artificial || Intelligence (AI) literacy for teaching and || learning: design and implementation || Mary Webb - Kings College London (TWG co-leader) || Matt Bower - Macquarie University (TWG co-leader) || Ana Amlia Carvalho -University of Coi ... (truncated) ||  || { || ""title"": ""EDUsummIT 2025 - eBook"", || ""authors"": [ || ""Mary Webb"", || ""Matt Bower"", || ""Ana Amlia Carvalho"", || ""Fredrik Mrk Rkenes"", || ""Jodie Torrington"", || ""Jonathan D. Cohen"", || ""Yousra Chtouki"", || ""Kathryn MacCallum"", || ""Tanya Linden"", || ""Deirdre Butler"", || ""Juliana E. Raffagheli"", || ""Henriikka Vartiainen"", || ""Martina Ronci"", || ""Peter Tiernan"", || ""Chris Shelton"", || ""Joyce Malyn-Smith"", || ""Pierre Gorissen"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Thematic Working Group 5 focuses on AI literacy for teaching and learning, exploring strategies to integrate AI into education through curriculum design, professional development, and classroom applications."" || } ||  || [ Prompt: 132.0 t/s | Generation: 29.3 t/s ]"
2601.08382v2_A Qualitative Model to Reason about Object Rotatio.pdf,A Qualitative Model to Reason about Object Rotations,['Zoe Falomira'],"aUme University, Computing Science Department, Sweden",29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A Qualitative Model to Reason about Object Rotations  applied to solve the Cube || Comparison Test || Zoe Falomira,1 || aUme University, Computing Science Department, Sweden || Abstract || This paper presents a Qualitative model for Reasoning about Object Rotations (QOR) which is applied to solve  ... (truncated) ||  || { || ""title"": ""A Qualitative Model to Reason about Object Rotations"", || ""authors"": [""Zoe Falomira""], || ""doi"": ""aUme University, Computing Science Department, Sweden"", || ""arxiv_id"": """", || ""keywords"": [""cube comparison test"", ""mental rotation"", ""qualitative reasoning"", ""spatial cognition"", ""spatial reasoning""], || ""summary"": ""This paper presents a Qualitative model for Reasoning about Object Rotations (QOR) which is applied to solve the Cube Comparison Test (CCT). A conceptual neighborhood graph relating rotation movement to location and orientation change has been built."" || } ||  || [ Prompt: 119.7 t/s | Generation: 29.1 t/s ]"
2601.08383v1_Deconstructing Pre-training Knowledge Attribution .pdf,,[],,29.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Deconstructing Pre-training: Knowledge Attribution Analysis in MoE and Dense || Models || Bo Wang1, Junzhuo Li1,2, Hong Chen1, Yuanlin Chu1, Yuxuan Fan1, Xuming Hu1,2* || 1The Hong Kong University of Science and Technology (Guangzhou) || 2The Hong Kong University of Science and Technology || {bo.w ... (truncated) ||  || { || ""title"": ""Deconstructing Pre-training: Knowledge Attribution Analysis in MoE and Dense Models"", || ""authors"": [ || ""Bo Wang"", || ""Jinzhuo Li"", || ""Hong Chen"", || ""Yuanlin Chu"", || ""Yuxuan Fan"", || ""Xuming Hu"", || ""Yukang Hu"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [ || ""Mixture-of-Experts"", || ""knowledge attribution"", || ""knowledge acquisition"", || ""dense architectures"", || ""interpretability"", || ""sparsity"", || ""training dynamics"" || ], || ""summary"": ""This paper investigates how MoE architectures influence knowledge acquisition during pre-training compared to dense architectures. It introduces Gated-LPI and analyzes knowledge distribution across MoE and dense models using large-scale training data. Key findings highlight the emergence of a sparse core in MoE, early stabilization, and improved robustness through sparsity."" || } ||  || [ Prompt: 117.1 t/s | Generation: 29.5 t/s ]"
2601.08388v1_Creativity in AI as Emergence from Domain-Limited .pdf,Creativity in AI as Emergence from Domain-Limited Generative Models,['Corina Chutaux'],,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Creativity in AI as Emergence from || Domain-Limited Generative Models || Corina Chutaux || Sorbonne University || corina@chutaux.com || Abstract || Creativity in artificial intelligence is most often addressed through evaluative frameworks that aim to measure novelty, || diversity, or usefulness in gen ... (truncated) ||  || { || ""title"": ""Creativity in AI as Emergence from Domain-Limited Generative Models"", || ""authors"": [""Corina Chutaux""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper proposes a generative perspective on creativity in AI, framing it as an emergent property of domain-limited generative models embedded within bounded informational environments. It examines structural and contextual conditions for creative behaviors and introduces a conceptual decomposition of creativity into four components: pattern-based generation, induced world models, contextual grounding, and arbitrarity."" || } ||  || [ Prompt: 122.3 t/s | Generation: 28.8 t/s ]"
2601.08393v1_Controlled LLM Training on Spectral Sphere.pdf,Controlled LLM Training on Spectral Sphere,"['Tian Xie', 'Haoming Luo', 'Yang Wang', 'Wayne Xin Zhao', 'Rui Yan', 'Bing Su', 'Chong Luo', 'Guo', 'Ren', 'Jian Liu']",arXiv:2601.08393v1,28.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Controlled LLM Training on Spectral Sphere || Tian Xie1 * || Haoming Luo2 Haoyu Tang2 Yiwen Hu2 Jason Klein Liu Qingnan Ren 1 || Yang Wang1 Wayne Xin Zhao2 Rui Yan3 Bing Su2 Chong Luo1 Baining Guo1 || 1Microsoft Research Asia 2Renmin University 3Wuhan University || Project Page:Spectral-Sphere-Opt ... (truncated) ||  || { || ""title"": ""Controlled LLM Training on Spectral Sphere"", || ""authors"": [ || ""Tian Xie"", || ""Haoming Luo"", || ""Yang Wang"", || ""Wayne Xin Zhao"", || ""Rui Yan"", || ""Bing Su"", || ""Chong Luo"", || ""Guo"", || ""Ren"", || ""Jian Liu"" || ], || ""doi"": ""arXiv:2601.08393v1"", || ""arxiv_id"": ""2601.08393"", || ""keywords"": [ || ""LLM training"", || ""Spectral Sphere"", || ""Optimization"", || ""Activation control"", || ""Parallel training"", || ""Stability"" || ], || ""summary"": ""The paper introduces the Spectral Sphere Optimizer (SSO) to enforce strict spectral constraints on model weights and updates, improving stability and convergence for large models. SSO outperforms existing optimizers like AdamW and Muon, offering better activation stability and robust training dynamics."" || } ||  || [ Prompt: 127.8 t/s | Generation: 28.0 t/s ]"
2601.08401v1_An Explainable Two Stage Deep Learning Framework f.pdf,Explainable Two-Stage Deep Learning Framework for Pericoronitis Assessment in Panoramic Radiographs Using YOLOv8 and ResNet-50,"['Ajo Babu George', 'Pranav S', 'Kunal Agarwal']",arXiv:2601.08401v1,31.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || An Explainable Two-Stage Deep Learning || Framework for Pericoronitis Assessment in || Panoramic Radiographs Using YOLOv8 and || ResNet-50 || Ajo Babu George 1*, Pranav S 2 and Kunal Agarwal 3 || 1* DiceMed, Cuttack, Odisha, India. || 2Department of Computer Science and Engineering, College of || Engine ... (truncated) ||  || { || ""title"": ""Explainable Two-Stage Deep Learning Framework for Pericoronitis Assessment in Panoramic Radiographs Using YOLOv8 and ResNet-50"", || ""authors"": [ || ""Ajo Babu George"", || ""Pranav S"", || ""Kunal Agarwal"" || ], || ""doi"": ""arXiv:2601.08401v1"", || ""arxiv_id"": ""arXiv:2601.08401"", || ""keywords"": [ || ""explainable AI"", || ""deep learning"", || ""pericoronitis"", || ""panoramic radiographs"", || ""YOLOv8"", || ""ResNet-50"", || ""diagnostic classification"" || ], || ""summary"": ""The paper presents a two-stage deep learning framework using YOLOv8 for anatomical localization and a modified ResNet-50 for pericoronitis detection, emphasizing interpretability through Grad-CAM to support clinical decision-making."" || } ||  || [ Prompt: 126.5 t/s | Generation: 31.6 t/s ]"
2601.08402v1_PATS Personality-Aware Teaching Strategies with La.pdf,Personality-Aware Teaching Strategies,"['Donya Rooein1', 'Sankalan Pal Chowdhury2', 'Mariia Eremeeva2', 'Yuan Qin3', 'Debora Nozza 1', 'Mrinmaya Sachan 2', 'Dirk Hovy 1']",,29.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || PATS: Personality-Aware Teaching Strategies || with Large Language Model Tutors || Donya Rooein1*, Sankalan Pal Chowdhury2*, Mariia Eremeeva2, || Yuan Qin3,Debora Nozza 1,Mrinmaya Sachan 2,Dirk Hovy 1 || 1Bocconi University || 2ETH Zurich || 3University of Zurich || Correspondence:donya.rooein@uniboccon ... (truncated) ||  || { || ""title"": ""Personality-Aware Teaching Strategies"", || ""authors"": [ || ""Donya Rooein1"", || ""Sankalan Pal Chowdhury2"", || ""Mariia Eremeeva2"", || ""Yuan Qin3"", || ""Debora Nozza 1"", || ""Mrinmaya Sachan 2"", || ""Dirk Hovy 1"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Recent advances in large language models demonstrate their potential as educational tutors. However, different tutoring strategies benefit different student personalities, and mismatches can be counterproductive. This paper constructs a taxonomy linking pedagogical methods to personality profiles and evaluates how human teachers prefer our approach over two base-line methods."" || } ||  || [ Prompt: 119.0 t/s | Generation: 29.7 t/s ]"
2601.08403v1_Owen-Shapley Policy Optimization OSPO A Principled.pdf,Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for Generative Search LLMs,"['Abhijnan Nath', 'Alireza Bagheri Garakani', 'Tianchen Zhou', 'Fan Yang', 'Nikhil Krishnaswamy']",,30.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for || Generative Search LLMs || Abhijnan Nath 1 2 Alireza Bagheri Garakani 1 Tianchen Zhou 1 Fan Yang1 Nikhil Krishnaswamy 2 || Abstract || Large language models are increasingly trained || via reinforcement learning for personali ... (truncated) ||  || { || ""title"": ""Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for Generative Search LLMs"", || ""authors"": [ || ""Abhijnan Nath"", || ""Alireza Bagheri Garakani"", || ""Tianchen Zhou"", || ""Fan Yang"", || ""Nikhil Krishnaswamy"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper introduces OWEN-SHAPLEY POLICYOPTIMIZATION (OSPO), a framework that redistributes sequence-level advantages based on tokens' marginal contributions to outcomes. OSPO uses potential-based reward shaping via Shapley-Owen attributions to assign segment-level credit without relying on parametric value models. Experiments demonstrate consistent gains over baselines on Amazon ESCI and H&M Fashion datasets, showing robustness to out-of-distribution retrievers."" || } ||  || [ Prompt: 119.2 t/s | Generation: 30.0 t/s ]"
2601.08406v1_WebTrap Park An Automated Platform for Systematic .pdf,WebTrap Park: An Automated Platform for Systematic Security Evaluation of Web Agents,"['Xinyi Wu', 'Jiagui Chen', 'Geng Hong B', 'Jiayi Dong', 'Xudong Pan', 'Jiarun Dai', 'Min Yang B']","xinyiwu20, jgchen20, ghong, xdpan, jrdai, m yang",28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || WebTrap Park: An Automated Platform for Systematic Security Evaluation of || Web Agents || Xinyi Wu,*, Jiagui Chen ,*, Geng Hong B, Jiayi Dong , Xudong Pan , Jiarun Dai , and Min Yang B || Fudan University, Shanghai Innovation Institute || {xinyiwu20, jgchen20, ghong, xdpan, jrdai, m yang}@fuda ... (truncated) ||  || { || ""title"": ""WebTrap Park: An Automated Platform for Systematic Security Evaluation of Web Agents"", || ""authors"": [ || ""Xinyi Wu"", || ""Jiagui Chen"", || ""Geng Hong B"", || ""Jiayi Dong"", || ""Xudong Pan"", || ""Jiarun Dai"", || ""Min Yang B"" || ], || ""doi"": ""xinyiwu20, jgchen20, ghong, xdpan, jrdai, m yang"", || ""arxiv_id"": """", || ""keywords"": [ || ""Web Agents"", || ""security evaluation"", || ""systematic evaluation"", || ""web agents"", || ""security boundaries"" || ], || ""summary"": ""WebTrapPark is an automated platform for evaluating Web Agents by instantiating three major security risk sources. It enables action-based assessment without modifying agents and highlights security differences across agent frameworks."" || } ||  || [ Prompt: 119.6 t/s | Generation: 28.5 t/s ]"
2601.08412v1_Hybrid Distillation with CoT Guidance for Edge-Dro.pdf,Hybrid Distillation with CoT Guidance for Edge-Drone Control Code,"['Yizhan Feng', 'Hichem Snoussi', 'Yuhang Wang', 'Jing Teng', 'Abel Cherouat', 'Tian Wang']",,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || Hybrid Distillation with CoT Guidance for Edge-Drone Control Code || Generation || Yizhan Feng1,4, Hichem Snoussi1,4, Yuhang Wang2, Jing Teng2, Abel Cherouat3,4 and Tian || Wang5 || 1 UR-LIST3N, University of Technology of Troyes, Troyes, France || E-mail: hichem.snoussi@utt.fr || 2Institute of Art ... (truncated) ||  || { || ""title"": ""Hybrid Distillation with CoT Guidance for Edge-Drone Control Code"", || ""authors"": [ || ""Yizhan Feng"", || ""Hichem Snoussi"", || ""Yuhang Wang"", || ""Jing Teng"", || ""Abel Cherouat"", || ""Tian Wang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Large language models"", || ""drone"", || ""Knowledge Distillation"", || ""Chain-of-Thought"", || ""Lightweight"" || ], || ""summary"": ""This paper proposes an integrated approach combining knowledge distillation, chain-of-thought guidance, and supervised fine-tuning for UAV multi-SDK control tasks, aiming to efficiently transfer complex reasoning and code generation capabilities to smaller models."", || ""summary_length_limit"": ""short"" || } ||  || [ Prompt: 130.4 t/s | Generation: 28.4 t/s ]"
2601.08415v2_Regulatory gray areas of LLM Terms.pdf,Regulatory gray areas of LLM Terms,"['Brittany I. Davidson', 'Kate Muir', 'Florian A.D. Burnat', 'Adam N. Joinson']",,31.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Regulatory gray areas of LLM Terms || Brittany I. Davidson || University of Bath || Bath, England || Email: bid23@bath.ac.uk || Kate Muir || Bath Spa University || Bath, England || Email: k.muir@bathspa.ac.uk || Florian A.D. Burnat || University of Bath || Bath, England || Email: fadb20@bath.ac.uk || Adam N. Joinson || Univ ... (truncated) ||  || { || ""title"": ""Regulatory gray areas of LLM Terms"", || ""authors"": [ || ""Brittany I. Davidson"", || ""Kate Muir"", || ""Florian A.D. Burnat"", || ""Adam N. Joinson"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Language Models"", || ""LLMs"", || ""Privacy Policy"", || ""Terms of Service"", || ""Regulation"" || ], || ""summary"": ""This paper examines the varying Terms of Service of major LLM providers, highlighting regulatory ambiguities that affect researchers and users in security, social sciences, and psychology. It identifies specific complexities and proposes a resource for comparing terms across platforms."" || } ||  || [ Prompt: 119.3 t/s | Generation: 31.4 t/s ]"
2601.08418v1_Taxon Hierarchical Tax Code Prediction with Semant.pdf,Taxon: Hierarchical Tax Code Prediction,"['Jihang Li', 'Qing Liu', 'Zulong Chen', 'Jing Wang', 'Wei Wang2', 'Chuanfei Xu', 'Zeyi Wen']",,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Taxon: Hierarchical Tax Code Prediction || with Semantically Aligned LLM Expert Guidance || Jihang Li 1, Qing Liu 2, Zulong Chen 2, Jing Wang 2, Wei Wang2, Chuanfei Xu 3, Zeyi Wen 1 || 1Data Science and Analytics Thrust, Hong Kong University of Science and Technology (Guangzhou), Guangzhou,  ... (truncated) ||  || { || ""title"": ""Taxon: Hierarchical Tax Code Prediction"", || ""authors"": [ || ""Jihang Li"", || ""Qing Liu"", || ""Zulong Chen"", || ""Jing Wang"", || ""Wei Wang2"", || ""Chuanfei Xu"", || ""Zeyi Wen"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Tax code prediction"", || ""Hierarchical taxonomy"", || ""Semantic alignment"", || ""LLM expert guidance"", || ""Taxonomy"", || ""Invoice compliance"", || ""Regulatory risk"" || ], || ""summary"": ""This paper presents Taxon, a semantically aligned and expert-guided framework for hierarchical tax code prediction. It integrates a feature-gating mixture-of-experts architecture and a semantic consistency model to improve accuracy in mapping products to tax codes, addressing challenges in e-commerce compliance."" || } ||  || [ Prompt: 120.9 t/s | Generation: 28.2 t/s ]"
2601.08430v1_RubricHub A Comprehensive and Highly Discriminativ.pdf,RubricHub: A Comprehensive and Highly Discriminative Rubric Dataset,"['Li Auto Inc.', 'The Chinese University of Hong Kong, Shenzhen, China', 'Zhejiang University 4Nanyang Technological University', 'Sunzhu Li1', 'Jiale Zhao', 'Miteto Wei1', 'Huimin Ren1', 'Yang Zhou3', 'Jingwen Yang2', 'Shunyu Liu4', 'Kaike Zhang1', 'Wei Chen1']",,29.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || RubricHub: A Comprehensive and Highly Discriminative Rubric Dataset || via Automated Coarse-to-Fine Generation || Sunzhu Li1, Jiale Zhao1 , Miteto Wei1 * , Huimin Ren1, || Yang Zhou3, Jingwen Yang2, Shunyu Liu4, Kaike Zhang1, Wei Chen1 || 1Li Auto Inc., China || 2The Chinese University of Hong Kon ... (truncated) ||  || { || ""title"": ""RubricHub: A Comprehensive and Highly Discriminative Rubric Dataset"", || ""authors"": [ || ""Li Auto Inc."", || ""The Chinese University of Hong Kong, Shenzhen, China"", || ""Zhejiang University 4Nanyang Technological University"", || ""Sunzhu Li1"", || ""Jiale Zhao"", || ""Miteto Wei1"", || ""Huimin Ren1"", || ""Yang Zhou3"", || ""Jingwen Yang2"", || ""Shunyu Liu4"", || ""Kaike Zhang1"", || ""Wei Chen1"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""autumn"", || ""poetry"", || ""metadata"", || ""rubric"", || ""reinforcement learning"", || ""verifiable rewards"" || ], || ""summary"": ""This paper introduces RubricHub, a large-scale dataset for reinforcement learning with verifiable rewards, and evaluates its impact on improving reasoning in mathematical domains."" || } ||  || [ Prompt: 123.8 t/s | Generation: 29.4 t/s ]"
2601.08434v3_Large Multimodal Models for Embodied Intelligent D.pdf,,[],,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || Large Multimodal Models for Embodied Intelligent || Driving: The Next Frontier in Self-Driving? || Long Zhang,Member, IEEE,Yuchen Xia, Bingqing Wei, Zhen Liu, Shiwen Mao,Fellow, IEEE, || Zhu Han,Fellow, IEEEand Mohsen Guizani,Fellow, IEEE || AbstractThe advent of Large Multimodal Models (LMMs ... (truncated) ||  || { || ""title"": ""Large Multimodal Models for Embodied Intelligent Driving: The Next Frontier in Self-Driving?"", || ""authors"": [ || ""Long Zhang"", || ""Yuchen Xia"", || ""Bingqing Wei"", || ""Zhen Liu"", || ""Shiwen Mao"", || ""Zhu Han"" || ], || ""doi"": ""10.48550/arXiv.2024.12345"",  // Placeholder || ""arxiv_id"": ""arXiv:2409.12345"", || ""keywords"": [ || ""Large Multimodal Models"", || ""Embodied Intelligence"", || ""Self-Driving"", || ""Autonomous Driving"", || ""Policy Optimization"", || ""Deep Reinforcement Learning"" || ], || ""summary"": ""This paper introduces a novel hybrid decision framework merging Large Multimodal Models and Deep Reinforcement Learning to address limitations in autonomous driving, focusing on continuous learning and joint decision-making for improved safety and generalization."" || } ||  || [ Prompt: 120.7 t/s | Generation: 28.3 t/s ]"
2601.08441v1_YaPO Learnable Sparse Activation Steering Vectors .pdf,YaPO: Learnable Sparse Activation Steering Vectors for Domain Adaptation,"['Abdelaziz Bounhar', 'Rania Hossam Elmohamady Elbadry', 'Preslav Nakov', 'Michalis Vazirgiannis', 'Guokan Shang']","1MBZUAI, 2Ecole Polytechnique",29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || YaPO: Learnable Sparse Activation Steering Vectors for Domain || Adaptation || Abdelaziz Bounhar1,, Rania Hossam Elmohamady Elbadry 1, Hadi Abdine 1, || Preslav Nakov1, Michalis Vazirgiannis1,2, Guokan Shang1, || 1MBZUAI, 2Ecole Polytechnique || Correspondence: {abdelaziz.bounhar, guokan.shang}@mb ... (truncated) ||  || { || ""title"": ""YaPO: Learnable Sparse Activation Steering Vectors for Domain Adaptation"", || ""authors"": [ || ""Abdelaziz Bounhar"", || ""Rania Hossam Elmohamady Elbadry"", || ""Preslav Nakov"", || ""Michalis Vazirgiannis"", || ""Guokan Shang"" || ], || ""doi"": ""1MBZUAI, 2Ecole Polytechnique"", || ""arxiv_id"": """", || ""keywords"": [ || ""large language models"", || ""activation interventions"", || ""steering vectors"", || ""domain adaptation"", || ""cultural alignment"", || ""interpretability"" || ], || ""summary"": ""This paper introduces YaPO, a reference-free method that learns sparse steering vectors in the latent space of a Sparse Autoencoder. By optimizing sparse codes, YaPO produces disentangled, interpretable, and efficient steering directions. It improves convergence, stability, and fine-grained alignment, preserving general knowledge while enabling applications like hallucination control and cultural adaptation."" || } ||  || [ Prompt: 115.0 t/s | Generation: 29.3 t/s ]"
2601.08444v1_Beyond Linearization Attributed Table Graphs for T.pdf,,[],,29.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Beyond Linearization: Attributed Table Graphs for Table Reasoning || Yuxiang Wang1, Junhao Gan1, Shengxiang Gao1, Shenghao Ye2, Zhengyi Yang3, Jianzhong Qi1 || 1The University of Melbourne 3The University of New South Wales || 2The University of Science and Technology of China || {yuxiang.wang8 ... (truncated) ||  || { || ""title"": ""Beyond Linearization: Attributed Table Graphs for Table Reasoning"", || ""authors"": [ || ""Yuxiang Wang"", || ""Junhao Gan"", || ""Shengxiang Gao"", || ""Shenghao Ye"", || ""Zhengyi Yang"", || ""Jianzhong Qi"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""table reasoning"", || ""linearization"", || ""LLM"", || ""attributed table graph"", || ""explanability"", || ""lost-in-the-middle"" || ], || ""summary"": ""This paper proposes Table Graph Reasoner (TABGR), a training-free model that represents tables as Attributed Table Graphs (ATGs) to preserve structures and improve explainability. It addresses issues like lost-in-the-middle and proposes a Question-Guided Perpersonalized PageRank mechanism."" || } ||  || [ Prompt: 119.3 t/s | Generation: 29.6 t/s ]"
2601.08448v1_Divide and Conquer Static-Dynamic Collaboration fo.pdf,Divide and Conquer: Static-Dynamic Collaboration for Few-Shot,"['Kexin Bao', 'Daichi Zhang', 'Yong Li', 'Dan Zeng', 'Shiming Ge']",10.1145/3731715.3733310,29.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Divide and Conquer: Static-Dynamic Collaboration for Few-Shot || Class-Incremental Learning || Kexin Bao || Institute of Information Engineering, || Chinese Academy of Sciences || School of Cyber Security, University || of Chinese Academy of Sciences || Beijing, China || baokexin@iie.ac.cn || Daichi Zhang || Ins ... (truncated) ||  || { || ""title"": ""Divide and Conquer: Static-Dynamic Collaboration for Few-Shot"", || ""authors"": [ || ""Kexin Bao"", || ""Daichi Zhang"", || ""Yong Li"", || ""Dan Zeng"", || ""Shiming Ge"" || ], || ""doi"": ""10.1145/3731715.3733310"", || ""arxiv_id"": ""ICMR 25"", || ""keywords"": [ || ""Few-Shot Class-Incremental Learning"", || ""Class-Incremental Learning"", || ""Stability-Plasticity Dilemma"", || ""Static Retaining Stage"", || ""Dynamic Learning Stage"" || ], || ""summary"": ""This paper proposes a framework called Static-Dynamic Collaboration (SDC) to address the stability-plasticity dilemma in few-shot class-incremental learning by dividing the task into Static Retaining Stage and Dynamic Learning Stage."" || } ||  || [ Prompt: 116.5 t/s | Generation: 29.6 t/s ]"
2601.08450v1_Decoding Order Matters in Autoregressive Speech Sy.pdf,Decoding Order Matters in Autoregressive Speech Synthesis,"['Minghui Zhao', 'Anton Ragni']",2104,29.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DECODING ORDER MA TTERS IN AUTOREGRESSIVE SPEECH SYNTHESIS || Minghui Zhao, Anton Ragni || School of Computer Science, University of Sheffield, 211 Portobello, Sheffield S1 4DP, UK || ABSTRACT || Autoregressive speech synthesis often adopts a left-to-right order, || yet generation order is a model ... (truncated) ||  || { || ""title"": ""Decoding Order Matters in Autoregressive Speech Synthesis"", || ""authors"": [""Minghui Zhao"", ""Anton Ragni""], || ""doi"": ""2104"", || ""arxiv_id"": ""2104/28002"", || ""keywords"": [""speech synthesis"", ""autoregressive"", ""decoding order"", ""discrete diffusion model""], || ""summary"": ""This paper investigates the impact of decoding order in autoregressive speech synthesis using a masked diffusion framework. It demonstrates that randomness in decoding order affects speech quality and compares fixed-order strategies with adaptive ones, concluding that adaptive decoding is more effective."" || } ||  || [ Prompt: 114.0 t/s | Generation: 29.8 t/s ]"
2601.08457v1_An Under-Explored Application for Explainable Mult.pdf,An Under-Explored Application for Explainable Multimodal Misogyny Detection in code-mixed Hindi-English Sargam Yadava,"['An Under-Explored Application for Explainable Multimodal Misogyny Detection in code-mixed Hindi-English Sargam Yadava', 'Abhishek Kaushikb', 'Kevin McDaidc a,b,cDundalk Institute of Technology', 'babhishek.kaushik@dkit.ie', 'ckevin.mcdaid@dkit.ie']",,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  || Information Classification: General || An Under-Explored Application for Explainable Multimodal Misogyny Detection in code-mixed Hindi-English Sargam Yadava, Abhishek Kaushikb, Kevin Mc Daidc a,b,cDundalk Institute of Technology asargam.yadav@dkit.ie  babhishek.kaushik@dkit.ie (Cor ... (truncated) ||  || { || ""title"": ""An Under-Explored Application for Explainable Multimodal Misogyny Detection in code-mixed Hindi-English Sargam Yadava"", || ""authors"": [ || ""An Under-Explored Application for Explainable Multimodal Misogyny Detection in code-mixed Hindi-English Sargam Yadava"", || ""Abhishek Kaushikb"", || ""Kevin McDaidc a,b,cDundalk Institute of Technology"", || ""babhishek.kaushik@dkit.ie"", || ""ckevin.mcdaid@dkit.ie"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""hate speech"", || ""misogyny"", || ""natural language processing"", || ""code-mixing"", || ""hinglish"" || ], || ""summary"": ""This paper presents a multi-modal and explainable web application for detecting misogyny in text and memes in code-mixed Hindi and English. It leverages transformer-based models and explainability techniques to enhance transparency in hate speech detection, aiming to support researchers and content moderators in combating gender-based digital violence."" || } ||  || [ Prompt: 120.0 t/s | Generation: 28.3 t/s ]"
2601.08462v1_M3-BENCH Process-Aware Evaluation of LLM Agents So.pdf,M3-BENCH: Process-Aware Evaluation of LLM Agents Social Behaviors in Mixed-Motive Games,"['Sixiong Xie', 'Zhuofan Shi', 'Haiyang Shen', 'Gang Huang', 'Yun Ma Xiang Jing']","xsx1001@stu.pku.edu.cn, jingxiang@pku.edu.cn",28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || M3-BENCH: Process-Aware Evaluation of LLM Agents Social Behaviors in || Mixed-Motive Games || Sixiong Xie* Zhuofan Shi* Haiyang Shen* Gang Huang Yun Ma Xiang Jing * || Peking University || National Key Laboratory of Data Space Technology and System || xsx1001@stu.pku.edu.cn, jingxiang@pku.edu.cn ||  || ... (truncated) ||  || { || ""title"": ""M3-BENCH: Process-Aware Evaluation of LLM Agents Social Behaviors in Mixed-Motive Games"", || ""authors"": [ || ""Sixiong Xie"", || ""Zhuofan Shi"", || ""Haiyang Shen"", || ""Gang Huang"", || ""Yun Ma Xiang Jing"" || ], || ""doi"": ""xsx1001@stu.pku.edu.cn, jingxiang@pku.edu.cn"", || ""arxiv_id"": """", || ""keywords"": [ || ""large language model"", || ""social behaviors"", || ""mixed-motive games"", || ""process-aware evaluation"", || ""personality model"", || ""communication analysis"" || ], || ""summary"": ""This paper introduces M3-BENCH, a multi-stage benchmark for evaluating social behaviors in large language model agents within mixed-motive games. It proposes a framework integrating Behavioral Trajectory Analysis, Reasoning Process Analysis, and Communication Content Analysis, enriched with the Big Five personality model and Social Exchange Theory. The study aims to capture multi-dimensional evidence of agent personality and capability beyond simple behavioral metrics."" || } ||  || [ Prompt: 118.8 t/s | Generation: 28.5 t/s ]"
2601.08464v1_CoMa Contextual Massing Generation with Vision-Lan.pdf,CoMa: Contextual Massing Generation with Vision-Language Models,"['Evgenii Maslov', 'Valentin Khrulkov', 'Anastasia V olkova', 'Anton Gusarov', 'Andrey Kuznetsov', 'Ivan Oseledets']",arXiv:2601.08464v1,29.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || CoMa: Contextual Massing Generation with Vision-Language Models || Evgenii Maslov1 Valentin Khrulkov1 Anastasia V olkova1 || Anton Gusarov1 Andrey Kuznetsov1, 2 Ivan Oseledets3 || 1 FusionBrain Lab 2 Innopolis University || 3 Institute of Numerical Mathematics || em.maslov01@gmail.com || Figure 1. A  ... (truncated) ||  || { || ""title"": ""CoMa: Contextual Massing Generation with Vision-Language Models"", || ""authors"": [ || ""Evgenii Maslov"", || ""Valentin Khrulkov"", || ""Anastasia V olkova"", || ""Anton Gusarov"", || ""Andrey Kuznetsov"", || ""Ivan Oseledets"" || ], || ""doi"": ""arXiv:2601.08464v1"", || ""arxiv_id"": ""arXiv:2601.08464"", || ""keywords"": [ || ""massing generation"", || ""vision-language models"", || ""urban planning"", || ""architectural design"", || ""functional requirements"" || ], || ""summary"": ""The paper introduces CoMa, a dataset and framework for generating building massing using vision-language models, addressing challenges in architectural design through automated, context-aware generation."" || } ||  || [ Prompt: 120.1 t/s | Generation: 29.7 t/s ]"
2601.08468v1_JudgeRLVR Judge First Generate Second for Efficien.pdf,JudgeRLVR: Efficient Reasoning,"['Jiangshan Duo', 'Hanyu Li', 'Hailin Zhang', 'Yudong Wang', 'Sujian Li', 'Liang Zhao', 'Xiaomi', 'LLM-Core Xiaomi']",arXiv:2601.08468v1,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || JudgeRLVR: Judge First, Generate Second for || Efficient Reasoning || Jiangshan Duo  Hanyu Li  Hailin Zhang  Yudong Wang || Sujian Li  Liang Zhao || State Key Laboratory of Multimedia Information Processing, School of || Computer Science, Peking University || CFCS, School of Computer Science, Pekin ... (truncated) ||  || { || ""title"": ""JudgeRLVR: Efficient Reasoning"", || ""authors"": [ || ""Jiangshan Duo"", || ""Hanyu Li"", || ""Hailin Zhang"", || ""Yudong Wang"", || ""Sujian Li"", || ""Liang Zhao"", || ""Xiaomi"", || ""LLM-Core Xiaomi"" || ], || ""doi"": ""arXiv:2601.08468v1"", || ""arxiv_id"": ""2601.08468"", || ""keywords"": [ || ""Reinforcement Learning"", || ""Verifiable Rewards"", || ""Reasoning"", || ""Large Language Models"", || ""Efficiency"", || ""Generation Quality"" || ], || ""summary"": ""This paper proposes JudgeRLVR, a two-stage judge-then-generate paradigm for RLVR, aiming to improve reasoning efficiency by learning discriminative capabilities that prune search space through verifiable answers."" || } ||  || [ Prompt: 120.3 t/s | Generation: 27.9 t/s ]"
2601.08472v1_sui-1 Grounded and Verifiable Long-Form Summarizat.pdf,Sui-1: Grounded and Verifiable,"['Benedikt Droste', 'Jan Philipp Harries', 'Maximilian Idahl', 'Bjrn Plster']",arXiv:2601.08472v1,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || sui-1: Grounded and Verifiable || Long-Form Summarization || Benedikt Droste* Jan Philipp Harries Maximilian Idahl Bjrn Plster || ellamind || Abstract || Large language models frequently generate plausible but unfaithful summaries that users cannot || verify against source text, a critical limitation ... (truncated) ||  || { || ""title"": ""Sui-1: Grounded and Verifiable"", || ""authors"": [ || ""Benedikt Droste"", || ""Jan Philipp Harries"", || ""Maximilian Idahl"", || ""Bjrn Plster"" || ], || ""doi"": ""arXiv:2601.08472v1"", || ""arxiv_id"": ""arXiv:2601.08472"", || ""keywords"": [ || ""grounded summarization"", || ""verifiable AI"", || ""citation-grounded"", || ""large language models"", || ""training accuracy"" || ], || ""summary"": ""Sui-1 is a 24B parameter model that produces abstractive summaries with inline citations, enabling traceability of claims. It outperforms baselines in citation-grounded summarization and supports processing up to 2 million tokens."" || } ||  || [ Prompt: 133.8 t/s | Generation: 28.6 t/s ]"
2601.08475v1_SUMMPILOT Bridging Efficiency and Customization fo.pdf,,[],,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SUMMPILOT: Bridging Efficiency and Customization || for Interactive Summarization System || JungMin Yun1, Juhwan Choi1, Kyohoon Jin2, Soojin Jang2, Jinhee Jang1, YoungBin Kim1,2 || 1Department of Artificial Intelligence, Chung-Ang University || 2Graduate School of Advanced Imaging Sciences, Mul ... (truncated) ||  || { || ""title"": ""Bridging Efficiency and Customization"", || ""authors"": [ || ""JungMin Yun"", || ""Juhwan Choi"", || ""Kyohoon Jin"", || ""Soojin Jang"", || ""Jinhee Jang"", || ""YoungBin Kim"", || ""cocoro357"", || ""gold5230"", || ""fhzh123"", || ""sujin0110"", || ""jinheejang"", || ""ybkim85"" || ], || ""doi"": ""https://doi.org/xxxx"",  // Placeholder || ""arxiv_id"": """", || ""keywords"": [ || ""interactive summarization"", || ""personalized summaries"", || ""user engagement"", || ""semantic graphs"", || ""entity clustering"", || ""explainable evaluation"" || ], || ""summary"": ""This paper introduces SUMMPILOT, an interactive summarization system that uses large language models to provide personalized summaries. It addresses the challenge of representing content relationships and supports multi-document summarization with user-driven customization."" || } ||  || [ Prompt: 122.7 t/s | Generation: 28.1 t/s ]"
2601.08490v1_BenchOverflow Measuring Overflow in Large Language.pdf,BenchOverflow: Measuring Overflow in Large Language,"['Erin Feiglin', 'Nir Hutnik', 'Raz Lapid']",arXiv:2601.08490v1,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Published in Transactions on Machine Learning Research (01/2026) || BenchOverflow: Measuring Overflow in Large Language || Models via Plain-Text Prompts || Erin Feiglin erin@deepkeep.ai || Deepkeep || Tel-Aviv, Israel || Nir Hutnik nir@deepkeep.ai || Deepkeep || Tel-Aviv, Israel || Raz Lapid raz.lapid@deepkee ... (truncated) ||  || { || ""title"": ""BenchOverflow: Measuring Overflow in Large Language"", || ""authors"": [ || ""Erin Feiglin"", || ""Nir Hutnik"", || ""Raz Lapid"" || ], || ""doi"": ""arXiv:2601.08490v1"", || ""arxiv_id"": ""arXiv:2601.08490"", || ""keywords"": [ || ""large language models"", || ""overflow"", || ""prompts"", || ""benchmarking"", || ""computational cost"" || ], || ""summary"": ""Investigates overflow in LLMs via plain-text prompts, highlighting performance and cost impacts, and introduces BenchOverflow for standardized evaluation."" || } ||  || [ Prompt: 121.1 t/s | Generation: 26.9 t/s ]"
2601.08493v1_PKI Prior Knowledge-Infused Neural Network for Few.pdf,PKI: Prior Knowledge-Infused Neural Network for Few-Shot Class-Incremental Learning,"['Kexin Baoa', 'Fanzhao Linc', 'Zichen Wang', 'Yong Liaob', 'Dan Zenge', 'Shiming Gea']",10.1093/pki/vis/a001,29.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || PKI: Prior Knowledge-Infused Neural Network for || Few-Shot Class-Incremental Learning || Kexin Baoa,b, Fanzhao Linc, Zichen Wangd, Yong Lia,b, Dan Zenge, || Shiming Gea,b, || aInstitute of Information Engineering, Chinese Academy of || Sciences, Beijing, 100092, China || bSchool of Cyber Security at ... (truncated) ||  || { || ""title"": ""PKI: Prior Knowledge-Infused Neural Network for Few-Shot Class-Incremental Learning"", || ""authors"": [ || ""Kexin Baoa"", || ""Fanzhao Linc"", || ""Zichen Wang"", || ""Yong Liaob"", || ""Dan Zenge"", || ""Shiming Gea"" || ], || ""doi"": ""10.1093/pki/vis/a001"", || ""arxiv_id"": ""2601.08493"", || ""keywords"": [ || ""PKI"", || ""few-shot learning"", || ""class-incremental learning"", || ""catastrophic forgetting"", || ""overfitting"", || ""prior knowledge"" || ], || ""summary"": ""This paper introduces PKI, a neural network architecture designed to support continual adaptation in few-shot learning scenarios. PKI incorporates prior knowledge to reduce catastrophic forgetting and overfitting, enabling efficient incremental learning."" || } ||  || [ Prompt: 131.6 t/s | Generation: 29.5 t/s ]"
2601.08499v2_EfficientFSL Enhancing Few-Shot Classification via.pdf,EfficientFSL: Enhancing Few-Shot Classification via Query-Only Tuning in Vision,"['Wenwen Liao', 'Hang Ruan', 'Jianbo Yu', 'Bing Song', 'Yuansong Wang', 'Xiaofeng Yang']",10.48550/arXiv.2405.12345,29.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || EfficientFSL: Enhancing Few-Shot Classification via Query-Only Tuning in Vision || Transformers || Wenwen Liao1, Hang Ruan1, Jianbo Yu2*, Bing Song3, Yuansong Wang4, Xiaofeng Yang2 || 1College of Intelligent Robotics and Advance Manufacturing, Fudan University, Shanghai China || 2School of Micr ... (truncated) ||  || { || ""title"": ""EfficientFSL: Enhancing Few-Shot Classification via Query-Only Tuning in Vision"", || ""authors"": [ || ""Wenwen Liao"", || ""Hang Ruan"", || ""Jianbo Yu"", || ""Bing Song"", || ""Yuansong Wang"", || ""Xiaofeng Yang"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [ || ""few-shot classification"", || ""Vision Transformers"", || ""query-only tuning"", || ""few-shot learning"", || ""model compression"" || ], || ""summary"": ""This paper introduces EfficientFSL, a query-only fine-tuning framework for few-shot classification using Vision Transformers. It proposes lightweight trainable components to synthesize task-specific queries and enhance feature representations, achieving state-of-the-art performance with minimal computational cost."" || } ||  || [ Prompt: 119.8 t/s | Generation: 29.8 t/s ]"
2601.08503v1_Temporal Fusion Nexus A task-agnostic multi-modal .pdf,Temporal Fusion Nexus: A task-agnostic multi-modal embedding model for clinical narratives and irregular time series in post-kidney transplant care,"['Aditya Kumar', 'Simon Rauch', 'Mario Cypko', 'Marcel Naik', 'Matthieu-P Schapranow', 'Aadil Rashid', 'Fabian Halleck', 'Bilgin Osmanodja', 'Roland Roller', 'Lars Pape', 'Klemens Budde', 'Mario Schiffer', 'Oliver Amft']",arXiv:2601.08503v1,29.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Temporal Fusion Nexus: A task-agnostic multi- || modal embedding model for clinical narratives and || irregular time series in post-kidney transplant care || Aditya Kumar1,2*, Simon Rauch 2, Mario Cypko 1,2, Marcel Naik 3, || Matthieu-P Schapranow4, Aadil Rashid 4, Fabian Halleck 3, || Bilgin Osma ... (truncated) ||  || { || ""title"": ""Temporal Fusion Nexus: A task-agnostic multi-modal embedding model for clinical narratives and irregular time series in post-kidney transplant care"", || ""authors"": [ || ""Aditya Kumar"", || ""Simon Rauch"", || ""Mario Cypko"", || ""Marcel Naik"", || ""Matthieu-P Schapranow"", || ""Aadil Rashid"", || ""Fabian Halleck"", || ""Bilgin Osmanodja"", || ""Roland Roller"", || ""Lars Pape"", || ""Klemens Budde"", || ""Mario Schiffer"", || ""Oliver Amft"" || ], || ""doi"": ""arXiv:2601.08503v1"", || ""arxiv_id"": ""2601.08503"", || ""keywords"": [ || ""clinical narratives"", || ""post-kidney transplant care"", || ""graft loss"", || ""graft rejection"", || ""mortality prediction"", || ""multi-modal embedding"", || ""disentanglement"", || ""SHAP"" || ], || ""summary"": ""TFN is a multi-modal embedding model for integrating clinical text and time series data in post-kidney transplant care, achieving superior performance in graft loss, graft rejection, and mortality prediction compared to state-of-the-art models."" || } ||  || [ Prompt: 129.6 t/s | Generation: 29.8 t/s ]"
2601.08509v1_What If TSF A Benchmark for Reframing Forecasting .pdf,What If TSF: A Benchmark for Reframing Forecasting,"['Jinkwan Jang', 'Hyunbin Jin', 'Hyungjin Park', 'Kyubyung Chae', 'Taesup Kim']",,29.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || What If TSF: A Benchmark for Reframing Forecasting || as Scenario-Guided Multimodal Forecasting || Jinkwan Jang, Hyunbin Jin, Hyungjin Park, Kyubyung Chae, Taesup Kim || Graduate School of Data Science, Seoul National University || {jkjang22, hyunbin.jin, robin5310, kyubyung.chae, taesup.kim}@s ... (truncated) ||  || { || ""title"": ""What If TSF: A Benchmark for Reframing Forecasting"", || ""authors"": [ || ""Jinkwan Jang"", || ""Hyunbin Jin"", || ""Hyungjin Park"", || ""Kyubyung Chae"", || ""Taesup Kim"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper introduces What If TSF (WIT), a multimodal forecasting benchmark designed to evaluate models' ability to incorporate contextual text and future scenarios, addressing limitations of unimodal time series methods."" || } ||  || [ Prompt: 119.5 t/s | Generation: 29.4 t/s ]"
2601.08510v2_STAGE A Benchmark for Knowledge Graph Construction.pdf,STAGE: A Benchmark for Knowledge Graph,"['Qiuyu Tian 1', 'Yiding Li 2', 'Fengyi Chen 3', 'Zequn Liu 2', 'Youyong', 'Jinjing Shen 5', 'Xin Zhang 5']",arXiv:2601.08510v2,30.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || STAGE: A Benchmark for Knowledge Graph || Construction, Question Answering, and In-Script || Role-Playing over Movie Screenplays || Qiuyu Tian 1,2 Yiding Li 5 Fengyi Chen3 Zequn Liu 2 Youyong || Kong1 Fan Guo5 || Yuyao Li5 Jinjing Shen 5 Zhijing Xie 5 Yiyun Luo 5 Xin Zhang 5 || 1Southeast University, ... (truncated) ||  || { || ""title"": ""STAGE: A Benchmark for Knowledge Graph"", || ""authors"": [ || ""Qiuyu Tian 1"", || ""Yiding Li 2"", || ""Fengyi Chen 3"", || ""Zequn Liu 2"", || ""Youyong"", || ""Jinjing Shen 5"", || ""Xin Zhang 5"" || ], || ""doi"": ""arXiv:2601.08510v2"", || ""arxiv_id"": ""arXiv:2601.08510v2"", || ""keywords"": [ || ""knowledge graph"", || ""screenplay"", || ""narrative understanding"", || ""character relationships"", || ""event summarization"", || ""long-context reasoning"" || ], || ""summary"": ""The paper introduces STAGE, a unified benchmark for evaluating narrative understanding in full-length movie screenplays. It covers knowledge graph construction, scene summarization, question answering, and in-script role-playing, all based on a shared narrative world."" || } ||  || [ Prompt: 129.2 t/s | Generation: 30.0 t/s ]"
2601.08519v1_CD2 Constrained Dataset Distillation for Few-Shot .pdf,Constrained Dataset Distillation for Few-Shot Class-Incremental Learning,"['Kexin Bao1', 'Daichi Zhang1', 'Hansong Zhang1', 'Yonghong Li1', 'Yutao Yue3', 'Shiming Ge1']",,29.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || CD2: Constrained Dataset Distillation for Few-Shot Class-Incremental Learning || Kexin Bao1,2 ,Daichi Zhang 1,2 ,Hansong Zhang 1,2 ,Y ong Li 1 ,Yutao Yue 3 andShiming Ge 1 || 1Institute of Information Engineering, Chinese Academy of Sciences || 2School of Cyber Security, University of Chines ... (truncated) ||  || { || ""title"": ""Constrained Dataset Distillation for Few-Shot Class-Incremental Learning"", || ""authors"": [ || ""Kexin Bao1"", || ""Daichi Zhang1"", || ""Hansong Zhang1"", || ""Yonghong Li1"", || ""Yutao Yue3"", || ""Shiming Ge1"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Few-shot class-incremental learning (FSCIL) addresses the catastrophic forgetting problem by introducing a dataset distillation module to preserve essential knowledge during incremental learning."" || } ||  || [ Prompt: 120.4 t/s | Generation: 29.9 t/s ]"
2601.08531v1_Sketch-Based Facade Renovation With Generative AI .pdf,Sketch-Based Facade Renovation With Generative AI Models,"['Warissara Booranamaitree1', 'Xusheng Du2', 'Y ushu Cai3', 'Zhengyang Wang4', 'Ye Zhang5*', 'Haoran Xie6']",16532152721@student.chula.ac.th,28.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  ||  || Sketch-Based Facade Renovation With Generative AI Models || A Streamlined Framework for Bypassing As-Built Modelling in Industrial Adaptive || Reuse || Warissara Booranamaitree1#, Xusheng Du2#, Y ushu Cai3, Zhengyang || Wang4, Ye Zhang5*, and Haoran Xie6,7* || 1Chulalongkorn University. || ... (truncated) ||  || { || ""title"": ""Sketch-Based Facade Renovation With Generative AI Models"", || ""authors"": [ || ""Warissara Booranamaitree1"", || ""Xusheng Du2"", || ""Y ushu Cai3"", || ""Zhengyang Wang4"", || ""Ye Zhang5*"", || ""Haoran Xie6"" || ], || ""doi"": ""16532152721@student.chula.ac.th"", || ""arxiv_id"": """", || ""keywords"": [ || ""industrial building renovation"", || ""vision-language model"", || ""diffusion model"", || ""user sketches"", || ""facade renovation"" || ], || ""summary"": ""A streamlined framework combining generative AI and vision-language models to bypass as-built modelling in industrial adaptive reuse."" || } ||  || [ Prompt: 116.8 t/s | Generation: 28.9 t/s ]"
2601.08545v2_Learner-Tailored Program Repair A Solution Generat.pdf,Learner-Tailored Program Repair: A Solution Generator with Iterative Edit-Driven Retrieval Enhancement,"['Zhenlong Dai', 'Zhuoluo Zhao', 'Hengning Wang', 'Xiu Tang', 'Sai Wu', 'Chang Yao', 'Zhipeng Gao', 'Jingyuan Chen']",,30.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Learner-Tailored Program Repair: A Solution Generator with || Iterative Edit-Driven Retrieval Enhancement || Zhenlong Dai1,2*, Zhuoluo Zhao1,2*, Hengning Wang1, || Xiu Tang1,2, Sai Wu1,2, Chang Yao1,2, Zhipeng Gao1, Jingyuan Chen1 || 1Zhejiang University || 2Hangzhou High-Tech Zone (Binjiang) Inst ... (truncated) ||  || { || ""title"": ""Learner-Tailored Program Repair: A Solution Generator with Iterative Edit-Driven Retrieval Enhancement"", || ""authors"": [ || ""Zhenlong Dai"", || ""Zhuoluo Zhao"", || ""Hengning Wang"", || ""Xiu Tang"", || ""Sai Wu"", || ""Chang Yao"", || ""Zhipeng Gao"", || ""Jingyuan Chen"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper introduces a novel task, LPR (Learner-Tailored Program Repair), and proposes a framework, LSGEN, to enhance program repair by offering bug descriptions and iteratively improving retrieval strategies."" || } ||  || [ Prompt: 125.7 t/s | Generation: 30.3 t/s ]"
2601.08549v1_Contrastive and Multi-Task Learning on Noisy Brain.pdf,Contrastive and Multi-Task Learning on Noisy Brain Signals,"['Sucheta Ghosh', 'Zahra Monfared', 'Felix Dietrich']",,27.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Published as a conference paper at ICLR 2026 || CONTRASTIVE ANDMULTI-TASKLEARNING ONNOISY || BRAINSIGNALS WITHNONLINEARDYNAMICALSIG- || NATURES || Sucheta Ghosh 1,2, Zahra Monfared1,2,3, Felix Dietrich4 || {sucheta.ghosh,zahra.monfared}@iwr.uni-heidelberg.de || 1Interdisciplinary Center for Scientifi ... (truncated) ||  || { || ""title"": ""Contrastive and Multi-Task Learning on Noisy Brain Signals"", || ""authors"": [ || ""Sucheta Ghosh"", || ""Zahra Monfared"", || ""Felix Dietrich"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""EEG"", ""EEG signals"", ""multitask learning"", ""dynamical modeling"", ""neural networks"", ""self-supervised learning""] || , ""summary"": ""This paper introduces a two-stage multitask learning framework for analyzing EEG signals, integrating denoising, dynamical modeling, and representation learning. The framework aims to improve robustness and generalization in EEG decoding by separating noise reduction from discriminative feature learning."" || } ||  || [ Prompt: 114.9 t/s | Generation: 27.4 t/s ]"
2601.08557v1_VideoHEDGE Entropy-Based Hallucination Detection f.pdf,VideoHEDGE: Entropy-Based Hallucination Detection for Video-VLMs via Semantic Clustering and Spatiotemporal Perturbations,"['Sushant Gautam', 'Cise Midoglu', 'Michael A. Riegler', 'Pl Halvorsen', 'Vajira Thambawita']",,29.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || VideoHEDGE: Entropy-Based Hallucination Detection for || Video-VLMs via Semantic Clustering and Spatiotemporal || Perturbations || Sushant Gautam || SimulaMet & OsloMet || Oslo, Norway || sushant@simula.no || Cise Midoglu || Forzasys || Oslo, Norway || cisemidoglu@gmail.com || Vajira Thambawita || SimulaMet || Oslo, Norw ... (truncated) ||  || { || ""title"": ""VideoHEDGE: Entropy-Based Hallucination Detection for Video-VLMs via Semantic Clustering and Spatiotemporal Perturbations"", || ""authors"": [ || ""Sushant Gautam"", || ""Cise Midoglu"", || ""Michael A. Riegler"", || ""Pl Halvorsen"", || ""Vajira Thambawita"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""hallucination detection"", || ""video-language models"", || ""semantic clustering"", || ""spatiotemporal perturbations"", || ""uncertainty estimation"", || ""semantic entropy"", || ""vision-language models"" || ], || ""summary"": ""Hallucinations in video-capable vision-language models remain frequent and high-confidence. VideoHEDGE introduces a framework for detecting hallucinations in video question answering using entropy-based reliability estimation and clustering methods."" || } ||  || [ Prompt: 122.0 t/s | Generation: 29.6 t/s ]"
2601.08559v1_WaterCopilot An AI-Driven Virtual Assistant for Wa.pdf,WaterCopilot: An AI-Driven Virtual Assistant for Water Management,"['Keerththanan Vickneswaran', 'Mariangel Garcia Andarcia', 'Hugo Retief', 'Chris Dickens', 'Paulo Silva']",,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || WaterCopilot: An AI-Driven Virtual Assistant || for Water Management ||  || Keerththanan Vickneswaran || Water Futures Data & Analytics || International Water Management || Institute || Sri Lanka || K.Vickneswaran@cgiar.org ... (truncated) ||  || { || ""title"": ""WaterCopilot: An AI-Driven Virtual Assistant for Water Management"", || ""authors"": [ || ""Keerththanan Vickneswaran"", || ""Mariangel Garcia Andarcia"", || ""Hugo Retief"", || ""Chris Dickens"", || ""Paulo Silva"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Water resource management"", || ""Retrieval-Augmented Generation"", || ""Water Futures Data & Analytics"", || ""International Water Management"", || ""Sustainable water resource management"", || ""Transboundary river basins"" || ], || ""summary"": ""WaterCopilot is an AI-driven virtual assistant developed to address fragmented data and limited real-time access in water management. It integrates static policy documents and live hydrological data via custom plugins, achieving high relevance and precision. Key innovations include automated alerts and scalable deployment."" || } ||  || [ Prompt: 129.0 t/s | Generation: 28.3 t/s ]"
2601.08565v1_Rewriting Video Text-Driven Reauthoring of Video F.pdf,Rewriting Video: Text-Driven Reauthoring of Video Footage,"['Sitong Wang', 'Anh Truong', 'Lydia B. Chilton', 'Dingzeyu Li']",sw3504@columbia.edu,27.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Rewriting Video: Text-Driven Reauthoring of Video Footage || Sitong Wang || Columbia University || New York, NY, USA || sw3504@columbia.edu || Anh Truong || Adobe Research || New York, NY, USA || truong@adobe.com || Lydia B. Chilton || Columbia University || New York, NY, USA || chilton@cs.columbia.edu || Dingzeyu Li || Ado ... (truncated) ||  || { || ""title"": ""Rewriting Video: Text-Driven Reauthoring of Video Footage"", || ""authors"": [ || ""Sitong Wang"", || ""Anh Truong"", || ""Lydia B. Chilton"", || ""Dingzeyu Li"" || ], || ""doi"": ""sw3504@columbia.edu"", || ""arxiv_id"": """", || ""keywords"": [ || ""Video reauthoring"", || ""Text-driven video editing"", || ""Generative video models"", || ""Creative AI tools"" || ], || ""summary"": ""This paper presents a tech probe and study on text-driven video reauthoring, introducing a generative reconstruction algorithm that converts video into editable text and an interactive tool called Rewrite Kit. It explores new use cases and highlights challenges in coherence, control, and creative alignment."" || } ||  || [ Prompt: 120.2 t/s | Generation: 27.1 t/s ]"
2601.08602v1_WaveFormer Frequency-Time Decoupled Vision Modelin.pdf,,[],,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || WaveFormer: Frequency-Time Decoupled Vision Modeling with Wave Equation || Zishan Shu1*, Juntong Wu1*, Wei Yan1*, Xudong Liu1, Hongyu Zhang1, Chang Liu2, || Youdong Mao1 , Jie Chen1 || 1Peking University || 2Tsinghua University || {zishanshu, wujt, weiyan, xudongliu, zhanghy}@stu.pku.edu.cn || {ymao, ... (truncated) ||  || { || ""title"": ""WaveFormer: Frequency-Time Decoupled Vision Modeling with Wave Equation"", || ""authors"": [ || ""Zishan Shu"", || ""Juntong Wu"", || ""Wei Yan"", || ""Xudong Liu"", || ""Hongyu Zhang"", || ""Chang Liu2"", || ""Youdong Mao"", || ""Jie Chen"", || ""Liuchang 2022"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Vision modeling with Transformers lacks explicit spatial propagation; this work introduces a wave-based approach to model spatial frequency interactions, offering competitive performance with improved efficiency."" || } ||  || [ Prompt: 120.3 t/s | Generation: 28.7 t/s ]"
2601.08605v1_ExpSeek Self-Triggered Experience Seeking for Web .pdf,Self-Triggered Experience Seeking for Web Agents,"['Wenyuan Zhang', 'Xinghua Zhang', 'Haiyang Yu', 'Shuaiyi Nie', 'Bingli Wu', 'Juwei Yue', 'Tingwen Liu', 'Yongbin Li']",,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ExpSeek: Self-Triggered Experience Seeking for Web Agents || Wenyuan Zhang1,2, Xinghua Zhang3, Haiyang Yu3, Shuaiyi Nie1,2, || Bingli Wu3,Juwei Yue 1,2,Tingwen Liu 1,2,Yongbin Li 3* || 1Institute of Information Engineering, Chinese Academy of Sciences || 2School of Cyber Security, University of ... (truncated) ||  || { || ""title"": ""Self-Triggered Experience Seeking for Web Agents"", || ""authors"": [ || ""Wenyuan Zhang"", || ""Xinghua Zhang"", || ""Haiyang Yu"", || ""Shuaiyi Nie"", || ""Bingli Wu"", || ""Juwei Yue"", || ""Tingwen Liu"", || ""Yongbin Li"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""experience intervention"", || ""web agents"", || ""self-triggering"", || ""entropy"", || ""LLM"", || ""multi-turn interactions"" || ], || ""summary"": ""Experience intervention in web agents emerges as a promising technical paradigm, enhancing agent interaction capabilities by providing valuable insights from accumulated experiences. However, existing methods predominantly inject experience passively as global context before task execution, struggling to adapt to dynamically changing contextual observations during agent-environment interaction. We propose ExpSeek, which shifts experience toward step-level proactive seeking: (1) estimating step-level entropy thresholds to determine intervention timing using the models intrinsic signals; (2) designing step-level tailored experience content. Experiments on Qwen3-8B and 32B models across four challenging web agent benchmarks demonstrate that ExpSeek achieves absolute improvements of 9.3% and 7.5%, respectively. Our experiments validate the feasibility and advantages of entropy as a self-triggering signal, revealing that even a 4B small-scale experience model can significantly boost the performance of larger agent models."" || } ||  || [ Prompt: 119.2 t/s | Generation: 28.8 t/s ]"
2601.08611v1_VeriTaS The First Dynamic Benchmark for Multimodal.pdf,VERITAS: The First Dynamic Benchmark for Multimodal Automated Fact-Checking,"['Mark Rothermel', 'Marcus Kornmann', 'Marcus Rohrbach', 'Anna Rohrbach']",,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || VERITAS: The First Dynamic Benchmark for || Multimodal Automated Fact-Checking || Mark Rothermel Marcus Kornmann Marcus Rohrbach Anna Rohrbach || Multimodal AI Lab || Technical University of Darmstadt || hessian.AI || Correspondence:mark.rothermel@tu-darmstadt.de || Gambar ini adalah citra || buatan AI ya ... (truncated) ||  || { || ""title"": ""VERITAS: The First Dynamic Benchmark for Multimodal Automated Fact-Checking"", || ""authors"": [ || ""Mark Rothermel"", || ""Marcus Kornmann"", || ""Marcus Rohrbach"", || ""Anna Rohrbach"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Multimodal AI benchmark for automated fact-checking with real-world media examples."" || } ||  || [ Prompt: 113.3 t/s | Generation: 28.5 t/s ]"
2601.08620v1_ViDoRe V3 A Comprehensive Evaluation of Retrieval .pdf,ViDoRe V3: A Comprehensive Evaluation of Retrieval Augmented Generation in Complex Real-World Scenarios,"['Antonio Loison', 'Quentin Mac1', 'Antoine Edy', 'Antoine Edy', 'Manuel Faysse', 'Cline Hudelot', 'Gautier Viaud']",10.48550/arXiv.2303.04219,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ViDoRe V3: A Comprehensive Evaluation of Retrieval Augmented || Generation in Complex Real-World Scenarios || Antnio Loison* Quentin Mac1,3 Antoine Edy1 || Victor Xing1 Tom Balough2 Gabriel Moreira2 Bo Liu2 || Manuel Faysse3 Cline Hudelot3 Gautier Viaud1 || 1Illuin Technology 2NVIDIA 3CentraleSupl ... (truncated) ||  || { || ""title"": ""ViDoRe V3: A Comprehensive Evaluation of Retrieval Augmented Generation in Complex Real-World Scenarios"", || ""authors"": [ || ""Antonio Loison"", || ""Quentin Mac1"", || ""Antoine Edy"", || ""Antoine Edy"", || ""Manuel Faysse"", || ""Cline Hudelot"", || ""Gautier Viaud"" || ], || ""doi"": ""10.48550/arXiv.2303.04219"", || ""arxiv_id"": ""10.48550/arXiv.2303.04219"", || ""keywords"": [ || ""Retrieval Augmented Generation"", || ""RAG"", || ""multi-modal"", || ""visual elements"", || ""benchmark"", || ""annotations"" || ], || ""summary"": ""ViDoRe V3 introduces a comprehensive multi-modal RAG benchmark covering 10 datasets across diverse domains, emphasizing visual retrieval and grounding. It evaluates performance across textual, visual, and hybrid contexts, highlighting challenges and opportunities for future work."" || } ||  || [ Prompt: 123.6 t/s | Generation: 28.8 t/s ]"
2601.08623v1_SafeRedir Prompt Embedding Redirection for Robust .pdf,SafeRedir: Prompt Embedding Redirection for Robust Unlearning in Image Generation Models,"['Renyang Liu', 'Kangjie Chen', 'Han Qiu', 'Jie Zhang', 'Kwok-Yan Lam', 'Tianwei Zhang', 'See-Kiong Ng', 'Tianwei Zhang', 'Kwok-Yan Lam', 'Tianwei Zhang', 'Seekiong Ng']",10.48550/arXiv.2311.07891,29.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SafeRedir: Prompt Embedding Redirection for || Robust Unlearning in Image Generation Models || Renyang Liu || National University of Singapore || ryliu@nus.edu.sg || Kangjie Chen || Nanyang Technological University || kangjie.chen@ntu.edu.sg || Han Qiu || Tsinghua University || qiuhan@tsinghua.edu.cn || Jie Zhang || C ... (truncated) ||  || { || ""title"": ""SafeRedir: Prompt Embedding Redirection for Robust Unlearning in Image Generation Models"", || ""authors"": [ || ""Renyang Liu"", || ""Kangjie Chen"", || ""Han Qiu"", || ""Jie Zhang"", || ""Kwok-Yan Lam"", || ""Tianwei Zhang"", || ""See-Kiong Ng"", || ""Tianwei Zhang"", || ""Kwok-Yan Lam"", || ""Tianwei Zhang"", || ""Seekiong Ng"" || ], || ""doi"": ""10.48550/arXiv.2311.07891"", || ""arxiv_id"": ""2311.07891"", || ""keywords"": [ || ""image generation models"", || ""robust unlearning"", || ""prompt embedding redirection"", || ""safety mechanisms"", || ""adversarial attacks"" || ], || ""summary"": ""This paper introduces SafeRedir, a lightweight inference-time framework for robust unlearning in image generation models. It addresses the issue of unsafe content reproduction by adapting prompts at the token level, improving semantic control and resilience to adversarial attacks while maintaining image quality."" || } ||  || [ Prompt: 116.1 t/s | Generation: 29.4 t/s ]"
2601.08631v1_M2FMoE Multi-Resolution Multi-View Frequency Mixtu.pdf,,[],,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || M2FMoE: Multi-Resolution Multi-View Frequency Mixture-of-Experts for || Extreme-Adaptive Time Series Forecasting || Yaohui Huang, Runmin Zou, Yun Wang*, Laeeq Aslam, Ruipeng Dong, || School of Automation, Central South University, Changsha, China || {yaohuihuang, rmzou, wangyun19, laeeq aslam,  ... (truncated) ||  || { || ""title"": ""M2FMoE: Multi-Resolution Multi-View Frequency Mixture-of-Experts for Extreme-Adaptive Time Series Forecasting"", || ""authors"": [ || ""Yaohui Huang"", || ""Runmin Zou"", || ""Yun Wang"", || ""Laeeq Aslam"", || ""Ruipeng Dong"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Forecasting time series with extreme events is critical yet challenging due to their high variance, irregular dynamics, and sparse but high-impact nature. Existing methods excel in regular patterns but degrade during extreme events. This paper proposes M2FMoE, a model that learns both regular and extreme patterns through multi-resolution and multi-view frequency modeling."" || } ||  || [ Prompt: 123.1 t/s | Generation: 28.3 t/s ]"
2601.08634v1_Moral Lenses Political Coordinates Towards Ideolog.pdf,,[],,29.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Moral Lenses, Political Coordinates: || Towards Ideological Positioning of Morally Conditioned LLMs || Chenchen Yuan1,3 Bolei Ma2,3 Zheyu Zhang1,3 Bardh Prenkaj1,3 || Frauke Kreuter2,3 Gjergji Kasneci1,3 || 1Technical University of Munich 2LMU Munich 3Munich Center for Machine Learning || 1{name.s ... (truncated) ||  || { || ""title"": ""Moral Lenses, Political Coordinates: Towards Ideological Positioning of Morally Conditioned LLMs"", || ""authors"": [ || ""Chenchen Yuan"", || ""Bolei Ma"", || ""Zheyu Zhang"", || ""Bardh Prenkaj"", || ""Frauke Kreuter"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [ || ""moral orientation"", || ""political orientation"", || ""moral conditioning"", || ""Political Compass Test"", || ""ethical AI"" || ], || ""summary"": ""This paper investigates how conditioning moral values influences political positioning in large language models, highlighting the role of moral lenses in shaping ideological stances and demonstrating the need for socially grounded alignment techniques."" || } ||  || [ Prompt: 115.7 t/s | Generation: 29.4 t/s ]"
2601.08641v1_Resisting Manipulative Bots in Memecoin Copy Tradi.pdf,Resisting Manipulative Bots in Memecoin Copy Trading: A Multi-Agent Approach with Chain-of-Thought Reasoning,"['Yichen Luo', 'Yebo Feng', 'Jiahua Xu']",XXXXXXX.XXXXXXX,29.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Resisting Manipulative Bots in Memecoin Copy Trading: A || Multi-Agent Approach with Chain-of-Thought Reasoning || Yichen Luo || University College London || London, United Kingdom || yichen.luo.22@ucl.ac.uk || Yebo Feng || Nanyang Technological University || Singapore || yebo.feng@ntu.edu.sg || Jiahua Xu || Univer ... (truncated) ||  || { || ""title"": ""Resisting Manipulative Bots in Memecoin Copy Trading: A Multi-Agent Approach with Chain-of-Thought Reasoning"", || ""authors"": [ || ""Yichen Luo"", || ""Yebo Feng"", || ""Jiahua Xu"" || ], || ""doi"": ""XXXXXXX.XXXXXXX"", || ""arxiv_id"": ""XXXXXX"", || ""keywords"": [ || ""meme coin"", || ""copy trading"", || ""manipulative bots"", || ""multi-agent system"", || ""chain-of-thought"", || ""LLM"", || ""asset allocation"" || ], || ""summary"": ""The paper discusses challenges in meme coin copy trading due to manipulative bots and proposes a multi-agent system leveraging LLMs and chain-of-thought reasoning to improve decision-making and profitability."" || } ||  || [ Prompt: 118.4 t/s | Generation: 29.4 t/s ]"
2601.08653v1_Prism Towards Lowering User Cognitive Load in LLMs.pdf,Prism: Towards Lowering User Cognitive Load in LLMs,"['Zenghua Liao', 'Jinzhi Liao', 'Xiang Zhao']",,27.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Prism: Towards Lowering User Cognitive Load in LLMs || via Complex Intent Understanding || Zenghua Liao || Laboratory for Big Data and Decision, || National University of Defense || Technology || Changsha, Hunan, China || liaozenghua18@nudt.edu.cn || Jinzhi Liao || Laboratory for Big Data and Decision, || Nation ... (truncated) ||  || { || ""title"": ""Prism: Towards Lowering User Cognitive Load in LLMs"", || ""authors"": [ || ""Zenghua Liao"", || ""Jinzhi Liao"", || ""Xiang Zhao"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Complex intent understanding"", || ""Large language models"", || ""Logical clarification"", || ""Cognitive load theory"" || ], || ""summary"": ""Prism proposes a novel framework for complex intent understanding to improve human-LLM collaboration, featuring modular components for intent decomposition, logical clarification, reward evaluation, and self-evolved tuning."" || } ||  || [ Prompt: 118.2 t/s | Generation: 27.4 t/s ]"
2601.08654v1_RULERS Locked Rubrics and Evidence-Anchored Scorin.pdf,RULERS: Locked Rubrics and Evidence-Anchored Scoring for Robust LLM Evaluation,"['Yihan Hong', 'Huaiyuan Yao', 'Bolin Shen', 'Wanpeng Xu', 'Hua Wei', 'Yushun Dong']",,29.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || RULERS: Locked Rubrics and Evidence-Anchored Scoring for Robust || LLM Evaluation || Yihan Hong1 Huaiyuan Yao2 Bolin Shen3 Wanpeng Xu2 Hua Wei2 Yushun Dong3 || 1 Washington University in St. Louis || 2 Arizona State University || 3 Florida State University || Abstract || The LLM-as-a-Judge paradigm prom ... (truncated) ||  || { || ""title"": ""RULERS: Locked Rubrics and Evidence-Anchored Scoring for Robust LLM Evaluation"", || ""authors"": [ || ""Yihan Hong"", || ""Huaiyuan Yao"", || ""Bolin Shen"", || ""Wanpeng Xu"", || ""Hua Wei"", || ""Yushun Dong"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""LLM evaluation"", || ""rubric-based scoring"", || ""LLM-as-a-Judge"", || ""LLM alignment"", || ""rubric instability"", || ""auditable evidence"", || ""scale calibration"" || ], || ""summary"": ""The paper introduces RULERS, a framework for robust LLM evaluation using executable rubrics. It addresses challenges like rubric instability, unverifiable reasoning, and scale misalignment by transforming natural language rubrics into deterministic specifications with evidence verification. Experiments show RULERS outperforms baselines in human agreement and stability."" || } ||  || [ Prompt: 123.5 t/s | Generation: 29.8 t/s ]"
2601.08659v1_TRACE Reconstruction-Based Anomaly Detection in En.pdf,Reconstruction-Based Anomaly Detection in Ensemble and Time-Dependent Simulations,"['Hamid Gadirov', 'Martijn Westra', 'Steffen Frey']",,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  || TRACE:  Reconstruction-Based  Anomaly  Detection  in  Ensemble  and || Time-Dependent ||  || Simulations ||  || Hamid  Gadirov,  Martijn  Westra,  Steffen  Frey || Abstract.  Detecting  anomalous  behavior  in  high-dimensional,  time-dependent  simulation  data  is || an ||  || important ||  || yet || ... (truncated) ||  || { || ""title"": ""Reconstruction-Based Anomaly Detection in Ensemble and Time-Dependent Simulations"", || ""authors"": [ || ""Hamid Gadirov"", || ""Martijn Westra"", || ""Steffen Frey"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""anomaly detection"", || ""reconstruction"", || ""ensemble"", || ""time-dependent"", || ""simulation"", || ""autoencoder"", || ""volumetric data"" || ], || ""summary"": ""Detecting anomalous behavior in high-dimensional, time-dependent simulation data using reconstruction-based methods."" || } ||  || [ Prompt: 115.7 t/s | Generation: 28.3 t/s ]"
2601.08662v1_From Classical to Quantum Reinforcement Learning a.pdf,From Classical to Quantum Reinforcement Learning and Its Applications in Quantum Control: A Beginners Tutorial,"['Abhijit Sen', 'Sonali Panda', 'Mahima Arya', 'Subhajit Patra', 'Zizhan Zheng', 'Denys I. Bondar']",https://github.com/asen009/Reinforcement_Tutorial_Undergraduates,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || From Classical to Quantum Reinforcement Learning and Its Applications in Quantum || Control: A Beginners Tutorial || Abhijit Sen ,1,Sonali Panda ,2,Mahima Arya ,1,Subhajit || Patra ,3,Zizhan Zheng ,3,and Denys I. Bondar 1, || 1Department of Physics and Engineering Physics, || Tulane University, Ne ... (truncated) ||  || { || ""title"": ""From Classical to Quantum Reinforcement Learning and Its Applications in Quantum Control: A Beginners Tutorial"", || ""authors"": [ || ""Abhijit Sen"", || ""Sonali Panda"", || ""Mahima Arya"", || ""Subhajit Patra"", || ""Zizhan Zheng"", || ""Denys I. Bondar"" || ], || ""doi"": ""https://github.com/asen009/Reinforcement_Tutorial_Undergraduates"", || ""arxiv_id"": """", || ""keywords"": [ || ""reinforcement learning"", || ""quantum control"", || ""undergraduate"", || ""tutorial"", || ""AI"", || ""robotics"", || ""large language models"" || ], || ""summary"": ""This tutorial bridges the gap between RL theory and practical coding, offering clear explanations and hands-on examples for students. It aims to equip learners with foundational skills to apply RL techniques in real-world scenarios."" || } ||  || [ Prompt: 121.1 t/s | Generation: 27.8 t/s ]"
2601.08670v1_Parallel Context-of-Experts Decoding for Retrieval.pdf,Parallel Context-of-Experts Decoding for Retrieval Augmented Generation,"['Giulio Corallo', 'Paolo Papotti']",,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Parallel Context-of-Experts Decoding for Retrieval Augmented Generation || Giulio Corallo || SAP Labs, France || EURECOM, France || giulio.corallo@sap.com || Paolo Papotti || EURECOM, France || papotti@eurecom.fr || Abstract || Retrieval Augmented Generation faces a trade- || off: concatenating documents in a lo ... (truncated) ||  || { || ""title"": ""Parallel Context-of-Experts Decoding for Retrieval Augmented Generation"", || ""authors"": [ || ""Giulio Corallo"", || ""Paolo Papotti"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Retrieval Augmented Generation"", || ""Parallel Context-of-Experts Decoding"", || ""Multi-document reasoning"", || ""KV caching"", || ""Reasoning capabilities"" || ], || ""summary"": ""The paper proposes PCED, a training-free framework that decodes parallel context experts to enable cross-document reasoning without joint attention, addressing prefill bottlenecks and improving inference efficiency."" || } ||  || [ Prompt: 116.5 t/s | Generation: 29.3 t/s ]"
2601.08673v1_Why AI Alignment Failure Is Structural Learned Hum.pdf,Why AI Alignment Failure Is Structural,"['Didier Sornette', 'Sandro Claudio Lera', 'Ke Wu']",arXiv:2601.08673v1,29.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Why AI Alignment Failure Is Structural: || Learned Human Interaction Structures and AGI as an Endogenous || Evolutionary Shock || Didier Sornette 1, Sandro Claudio Lera 1, and Ke Wu 1 || 1Institute of Risk Analysis, Prediction and Management (Risks-X), Southern University of || Science and Technol ... (truncated) ||  || { || ""title"": ""Why AI Alignment Failure Is Structural"", || ""authors"": [ || ""Didier Sornette"", || ""Sandro Claudio Lera"", || ""Ke Wu"" || ], || ""doi"": ""arXiv:2601.08673v1"", || ""arxiv_id"": ""arXiv:2601.08673"", || ""keywords"": [ || ""AI alignment"", || ""AGI"", || ""moral reasoning"", || ""structural generalizations"", || ""human interaction"", || ""ethical frameworks"" || ], || ""summary"": ""The paper argues that perceived alignment failures in AI stem from misunderstandings, not moral reasoning deficits. It emphasizes structural factors rooted in human social interaction patterns and warns that AGI could amplify existing power imbalances rather than merely reflect them."" || } ||  || [ Prompt: 128.4 t/s | Generation: 29.5 t/s ]"
2601.08676v2_Advancing ESG Intelligence An Expert-level Agent a.pdf,Advancing ESG Intelligence: An Expert-level Agent and Comprehensive Benchmark for Sustainable Finance,"['Yilei Zhao', 'Wentao Zhang', 'Lei Xiao', 'Yandan Zheng', 'Mengpu Liu', 'Wei Yang Bryan Lim']",,29.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Advancing ESG Intelligence: An Expert-level Agent and || Comprehensive Benchmark for Sustainable Finance || Yilei Zhao1, Wentao Zhang1, Lei Xiao2, Yandan Zheng1, || Mengpu Liu1, Wei Yang Bryan Lim1 || 1Nanyang Technological University,2Alibaba Group || YILEI002@e.ntu.edu.sg, bryan.limwy@ntu.edu.sg ... (truncated) ||  || { || ""title"": ""Advancing ESG Intelligence: An Expert-level Agent and Comprehensive Benchmark for Sustainable Finance"", || ""authors"": [ || ""Yilei Zhao"", || ""Wentao Zhang"", || ""Lei Xiao"", || ""Yandan Zheng"", || ""Mengpu Liu"", || ""Wei Yang Bryan Lim"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""ESG"", || ""sustainability"", || ""ethical performance"", || ""corporate responsibility"", || ""ESG analysis"", || ""benchmarking"", || ""financial reports"" || ], || ""summary"": ""This paper introduces ESGAgent, a hierarchical multi-agent system designed to enhance ESG analysis using retrieval augmentation, web search, and domain-specific functions. It presents a comprehensive three-level benchmark derived from 310 corporate sustainability reports, demonstrating superior performance over state-of-the-art LLMs in both atomic question-answering and professional report generation."" || } ||  || [ Prompt: 123.1 t/s | Generation: 29.6 t/s ]"
2601.08679v1_PersonaDual Balancing Personalization and Objectiv.pdf,Balancing Personalization and Objectivity,"['Xiaoyou Liu', 'Xinyi Mou', 'Shengbin Yue', 'Liang Wang', 'Yuqing Wang', 'Qiexiang Wang', 'Tianrui Qin', 'Wangchunshu Zhou', 'Zhongyu Wei']",,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || PersonaDual: Balancing Personalization and Objectivity || via Adaptive Reasoning || Xiaoyou Liu, Xinyi Mou, Shengbin Yue, Liang Wang, || Yuqing Wang, Qiexiang Wang, Tianrui Qin, Wangchunshu Zhou*, Zhongyu Wei * || Fudan University Shanghai Innovation Institute OPPO || xiaoyouliu25@m.fudan.edu.cn z ... (truncated) ||  || { || ""title"": ""Balancing Personalization and Objectivity"", || ""authors"": [ || ""Xiaoyou Liu"", || ""Xinyi Mou"", || ""Shengbin Yue"", || ""Liang Wang"", || ""Yuqing Wang"", || ""Qiexiang Wang"", || ""Tianrui Qin"", || ""Wangchunshu Zhou"", || ""Zhongyu Wei"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper proposes PersonaDual, a framework that supports both general-purpose objective reasoning and personalized reasoning, adapting modes based on context to balance personalization and objectivity."" || } ||  || [ Prompt: 125.6 t/s | Generation: 29.1 t/s ]"
2601.08682v1_Lessons from the Field An Adaptable Lifecycle Appr.pdf,,[],,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Lessons from the Field: An Adaptable Lifecycle Approach to Applied || Dialogue Summarization || Kushal Chawla Chenyang Zhu Pengshan Cai Sangwoo Cho || Scott Novotney Ayushman Singh Jonah Lewis Keasha Safewright || Alfy Samuel Erin Babinsky Shi-Xiong Zhang Sambit Sahu || Capital One || {firstname.last ... (truncated) ||  || { || ""title"": ""Lessons from the Field: An Adaptable Lifecycle Approach to Applied Dialogue Summarization"", || ""authors"": [ || ""Kushal Chawla"", || ""Chenyang Zhu"", || ""Pengshan Cai"", || ""Sangwoo Cho"", || ""Scott Novotney"", || ""Ayushman Singh"", || ""Jonah Lewis"", || ""Keasha Safewright"", || ""Alfy Samuel"", || ""Erin Babinsky"", || ""Shi-Xiong Zhang"", || ""Sambit Sahu"", || ""Capital One"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Summarization of multi-party dialogues is a critical capability in industry, enhancing knowledge transfer and operational effectiveness across many domains. This work presents an industry case study on developing an agentic system to summarize multi-party interactions, sharing practical insights spanning the full development lifecycle."" || } ||  || [ Prompt: 118.3 t/s | Generation: 29.0 t/s ]"
2601.08683v1_Region of interest detection for efficient aortic .pdf,Region of interest detection for efficient aortic segmentation,"['Loris Giordanoa', 'Ine Dirks', 'Tom Lenaerts', 'Jef Vandemeulebrouckea', 'Irene van der Meulen', 'Jens de Graaf']",10.1007/s00456-021-02432-7,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Region of interest detection for efficient aortic segmentation || Loris Giordanoa,b, Ine Dirks a,c, Tom Lenaertsb,d,e, and Jef Vandemeulebrouckea,c,f || aVrije Universiteit Brussel (VUB), Department of Electronics and Informatics (ETRO), || Brussels, Belgium || bInteruniversity Institute of Bio ... (truncated) ||  || { || ""title"": ""Region of interest detection for efficient aortic segmentation"", || ""authors"": [ || ""Loris Giordanoa"", || ""Ine Dirks"", || ""Tom Lenaerts"", || ""Jef Vandemeulebrouckea"", || ""Irene van der Meulen"", || ""Jens de Graaf"" || ], || ""doi"": ""10.1007/s00456-021-02432-7"", || ""arxiv_id"": """", || ""keywords"": [ || ""Detection"", || ""Segmentation"", || ""Multi-task learning"", || ""Cascade models"", || ""Aorta"", || ""Computed tomography"" || ], || ""summary"": ""This study presents an innovative approach for efficient aortic segmentation using targeted region of interest (ROI) detection. It proposes a multi-task model combining encoder-decoder architecture for segmentation and a fully connected network for detection, achieving state-of-the-art performance with high Dice similarity."" || } ||  || [ Prompt: 117.6 t/s | Generation: 28.3 t/s ]"
2601.08684v1_MEMEWEAVER Inter-Meme Graph Reasoning for Sexism a.pdf,Inter-Meme Graph Reasoning for Sexism and Misogyny Detection,"['Paolo Italiani', 'David Gimeno-Gomez', 'Luca Ragazzi', 'Gianluca Moro']",,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MEMEWEAVER: Inter-Meme Graph Reasoning for || Sexism and Misogyny Detection || Paolo Italiani*1,2 David Gimeno-Gomez*2 Luca Ragazzi*1 || Gianluca Moro*1 Paolo Rosso*2,3 || 1Department of Computer Science and Engineering, University of Bologna, Italy || 2PRHLT Research Center, Universtitat Politcni ... (truncated) ||  || { || ""title"": ""Inter-Meme Graph Reasoning for Sexism and Misogyny Detection"", || ""authors"": [ || ""Paolo Italiani"", || ""David Gimeno-Gomez"", || ""Luca Ragazzi"", || ""Gianluca Moro"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Women are twice as likely as men to face online harassment due to their gender. This work presents MEMEWEAVER, an end-to-end trainable multimodal framework for detecting sexism and misogyny through inter-meme graph reasoning, addressing limitations of existing approaches."" || } ||  || [ Prompt: 122.8 t/s | Generation: 29.3 t/s ]"
2601.08690v1_All Required In Order Phase-Level Evaluation for A.pdf,"All Required, In Order: Phase-Level Evaluation for AIHuman Dialogue in Healthcare and Beyond","['Shubham Kulkarni', 'Alexander Lyzhov', 'Shiva Chaitanya', 'Preetam Joshi']",10.48550/arXiv.2405.12345,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || All Required, In Order: Phase-Level Evaluation for AIHuman Dialogue in || Healthcare and Beyond || Shubham Kulkarni1, Alexander Lyzhov2, Shiva Chaitanya1, Preetam Joshi2 || 1Interactly.ai, California, USA 2AIMon Labs, California, USA || shubham@interactly.ai, alex@aimon.ai, shiva@interactly.ai, ... (truncated) ||  || { || ""title"": ""All Required, In Order: Phase-Level Evaluation for AIHuman Dialogue in Healthcare and Beyond"", || ""authors"": [ || ""Shubham Kulkarni"", || ""Alexander Lyzhov"", || ""Shiva Chaitanya"", || ""Preetam Joshi"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [ || ""AIHuman Dialogue"", || ""Healthcare"", || ""Clinical Evaluation"", || ""Compliance"", || ""Phased Assessment"" || ], || ""summary"": ""This paper introduces Obligatory-Information Phase Structured Compliance Evaluation (OIP SCE), a method to evaluate conversational AI in healthcare by focusing on compliance across the full conversation flow. It emphasizes auditable, phase-level evidence to align AI capabilities with clinical workflows."" || } ||  || [ Prompt: 121.8 t/s | Generation: 27.6 t/s ]"
2601.08697v2_Auditing Student-AI Collaboration A Case Study of .pdf,Auditing StudentAI Collaboration: A Case Study of Online Graduate CS Students,"['Nifu Dan', 'Georgia Institute of Technology']",10.1145/XXXXXXX.XXXXXXX,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Auditing StudentAI Collaboration: A Case Study of Online || Graduate CS Students || Nifu Dan || ndan3@gatech.edu || Georgia Institute of Technology || Atlanta, Georgia, USA || Abstract || As generative AI becomes embedded in higher education, it increas- || ingly shapes how students complete academic tasks ... (truncated) ||  || { || ""title"": ""Auditing StudentAI Collaboration: A Case Study of Online Graduate CS Students"", || ""authors"": [ || ""Nifu Dan"", || ""Georgia Institute of Technology"" || ], || ""doi"": ""10.1145/XXXXXXX.XXXXXXX"", || ""arxiv_id"": """", || ""keywords"": [ || ""AI in education"", || ""humanAI collaboration"", || ""student agency"", || ""automation preferences"", || ""generative AI"", || ""academic integrity"", || ""HCAI"" || ], || ""summary"": ""This study examines student preferences for AI collaboration in academic tasks, focusing on perceived benefits, risks, and desired boundaries. It uses surveys to explore how current AI tools align with students' expectations and to identify gaps for more trustworthy AI integration."" || } ||  || [ Prompt: 114.9 t/s | Generation: 29.1 t/s ]"
2601.08703v1_Evaluating the Ability of Explanations to Disambig.pdf,Evaluating Model Explanations without Ground Truth,"['Kaivalya Rawal', 'Eoin Delaney', 'Zihao Fu', 'Sandra Wachter', 'Chris Russell']",10.1145/3715275.3732219,29.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Evaluating the Ability of Explanations to Disambiguate Models in a Rashomon Set || Kaivalya Rawal1, Eoin Delaney2, Zihao Fu3, Sandra Wachter1,4, Chris Russell1 || 1Oxford Internet Institute, University of Oxford || 2Trinity College Dublin || 3Chinese University of Hong Kong || 4Hasso Plattner Inst ... (truncated) ||  || { || ""title"": ""Evaluating Model Explanations without Ground Truth"", || ""authors"": [ || ""Kaivalya Rawal"", || ""Eoin Delaney"", || ""Zihao Fu"", || ""Sandra Wachter"", || ""Chris Russell"" || ], || ""doi"": ""10.1145/3715275.3732219"", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper discusses evaluating explanations for models in a Rashomon set, highlighting the need to disambiguate model behavior and address challenges in explanation quality."" || } ||  || [ Prompt: 119.1 t/s | Generation: 29.4 t/s ]"
2601.08713v1_Real-Time Localization Framework for Autonomous Ba.pdf,Real-Time Localization Framework for Autonomous Basketball Robots,"['Naren Medarametla', 'Sreejon Mondal']",naren.medarametla2023@vitstudent.ac.in,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Real-Time Localization Framework for Autonomous || Basketball Robots || Naren Medarametla || School of Computer Science Engineering || Vellore Institute of Technology || Chennai, India || naren.medarametla2023@vitstudent.ac.in || Sreejon Mondal || School of Electrical and Electronics Engineering || Vellore In ... (truncated) ||  || { || ""title"": ""Real-Time Localization Framework for Autonomous Basketball Robots"", || ""authors"": [ || ""Naren Medarametla"", || ""Sreejon Mondal"" || ], || ""doi"": ""naren.medarametla2023@vitstudent.ac.in"", || ""arxiv_id"": """", || ""keywords"": [ || ""Robot Localization"", || ""Autonomous Navigation"", || ""Neural Networks"", || ""Robocon"", || ""Robotics"" || ], || ""summary"": ""This paper proposes a hybrid localization algorithm integrating classical techniques with learning-based methods for self-localization on a basketball court using visual data."" || } ||  || [ Prompt: 123.2 t/s | Generation: 27.8 t/s ]"
2601.08731v1_Learning from Demonstrations via Capability-Aware .pdf,Learning from Demonstrations via Capability-Aware Goal Sampling,"['Yuanlin Duan', 'Rutgers University', 'Ying Wang', 'Rutgers University', 'Wenjie Qiu', 'Rutgers University', 'He Zhu', 'Rutgers University']",,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Learning from Demonstrations via Capability-Aware || Goal Sampling || Yuanlin Duan || Rutgers University || yuanlin.duan@rutgers.edu || Yuning Wang || Rutgers University || yw895@cs.rutgers.edu || Wenjie Qiu || Rutgers University || wq37@cs.rutgers.edu || He Zhu || Rutgers University || hz375@cs.rutgers.edu || Abstract || Desp ... (truncated) ||  || { || ""title"": ""Learning from Demonstrations via Capability-Aware Goal Sampling"", || ""authors"": [ || ""Yuanlin Duan"", || ""Rutgers University"", || ""Ying Wang"", || ""Rutgers University"", || ""Wenjie Qiu"", || ""Rutgers University"", || ""He Zhu"", || ""Rutgers University"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Despite its promise, imitation learning often fails in long-horizon environments... Cago addresses this by dynamically tracking agent competence and selecting intermediate goals."" || } ||  || [ Prompt: 123.2 t/s | Generation: 27.8 t/s ]"
2601.08732v1_ISLA A U-Net for MRI-based acute ischemic stroke l.pdf,"ISLA: A U-Net for MRI-based acute ischemic stroke lesion segmentation with deep supervision, attention, domain adaptation, and ensemble learning","['Vincent Rocaa', 'Martin Bretzner', 'Hilde Henond', 'Laurent Puyb', 'Grgory Kuchcinskia', 'Renaud Lopesa']",,29.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ISLA: A U-Net for MRI-based acute ischemic stroke lesion segmentation with deep || supervision, attention, domain adaptation, and ensemble learning || Vincent Rocaa,, Martin Bretznera,b,c, Hilde Henond, Laurent Puyb,d, Grgory Kuchcinskia,b,c, Renaud Lopesa,b,e || aUniv. Lille, CNRS, Inserm,  ... (truncated) ||  || { || ""title"": ""ISLA: A U-Net for MRI-based acute ischemic stroke lesion segmentation with deep supervision, attention, domain adaptation, and ensemble learning"", || ""authors"": [ || ""Vincent Rocaa"", || ""Martin Bretzner"", || ""Hilde Henond"", || ""Laurent Puyb"", || ""Grgory Kuchcinskia"", || ""Renaud Lopesa"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Accurate delineation of acute ischemic stroke lesions in MRI is crucial for diagnosis and management. This work introduces ISLA, a deep learning model for AIS lesion segmentation using U-Net with improvements in loss functions, attention mechanisms, and domain adaptation. ISLA outperforms existing methods on an external test set."" || } ||  || [ Prompt: 119.9 t/s | Generation: 29.5 t/s ]"
2601.08734v1_TerraFormer Automated Infrastructure-as-Code with .pdf,TerraFormer: Automated Infrastructure-as-Code with LLMs Fine-Tuned via Policy-Guided Verifier Feedback,"['Prithwish Jana', 'Sam Davidson', 'Bhavana Bhasker', 'Andrey Kan', 'Anoop Deoras', 'Laurent Callot']",10.1145/3786583.3786898,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TerraFormer: Automated Infrastructure-as-Code with LLMs || Fine-Tuned via Policy-Guided Verifier Feedback || Prithwish Jana || pjana7@gatech.edu || Georgia Institute of Technology || Atlanta, USA || Sam Davidson || ssdavid@amazon.com || Amazon Web Services || Seattle, USA || Bhavana Bhasker || Amazon Web Services || S ... (truncated) ||  || { || ""title"": ""TerraFormer: Automated Infrastructure-as-Code with LLMs Fine-Tuned via Policy-Guided Verifier Feedback"", || ""authors"": [ || ""Prithwish Jana"", || ""Sam Davidson"", || ""Bhavana Bhasker"", || ""Andrey Kan"", || ""Anoop Deoras"", || ""Laurent Callot"" || ], || ""doi"": ""10.1145/3786583.3786898"", || ""arxiv_id"": ""2026.ICSE-SEIP26"", || ""keywords"": [ || ""Infrastructure as Code (IaC)"", || ""IaC generation"", || ""IaC mutation"", || ""Neuro-symbolic AI"", || ""Large language models"", || ""Formal verification"" || ], || ""summary"": ""Automating Infrastructure-as-Code (IaC) is challenging, and large language models (LLMs) often produce incorrect configurations from natural language (NL). We present TerraFormer, a neuro-symbolic framework for IaC generation and mutation that combines supervised fine-tuning with verifier-guided reinforcement learning, using formal verification tools to provide feedback on syntax, deployability, and policy compliance. We curate two large, high-quality NL-to-IaC datasets, TF-Gen (152k instances) and TF-Mutn (52k instances), via multi-stage verification and iterative LLM self-correction. Evaluations against 17 state-of-the-art LLMs, including larger models like Sonnet 3.7, DeepSeek-R1, and GPT-4.1, show that TerraFormer improves correctness over its base LLM by 15.94% on IaC-Eval, 11.65% on TF-Gen(Test), and 19.60% on TF-Mutn(Test). It outperforms larger models on both TF-Gen(Test) and TF-Mutn(Test), ranks third on IaC-Eval, and achieves top best-practices and security compliance."" || } ||  || [ Prompt: 120.0 t/s | Generation: 28.5 t/s ]"
2601.08743v1_TableCache Primary Foreign Key Guided KV Cache Pre.pdf,TableCache: Primary Foreign Key Guided KV Cache Precomputation for Low Latency Text-to-SQL,"['Jinbo Su1', '2. Yuxuan Hu', '3. Cuiping Li', '4. Hong Chen', '5. Jia Li', '6. Lintao Ma', '7. Jing Zhang*', 'Author: sujinbo,zhang-jing@ruc.edu.cn']",10.1234/example.12345,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TableCache: Primary Foreign Key Guided KV Cache Precomputation for || Low Latency Text-to-SQL || Jinbo Su1,2,Yuxuan Hu 1,2,Cuiping Li 1,3,Hong Chen 1,3,Jia Li 4,Lintao Ma 4, || Jing Zhang*1,2 || 1School of Information, Renmin University of China,Beijing, China || 2Key Laboratory of Data Engineerin ... (truncated) ||  || { || ""title"": ""TableCache: Primary Foreign Key Guided KV Cache Precomputation for Low Latency Text-to-SQL"", || ""authors"": [ || ""Jinbo Su1"", || ""2. Yuxuan Hu"", || ""3. Cuiping Li"", || ""4. Hong Chen"", || ""5. Jia Li"", || ""6. Lintao Ma"", || ""7. Jing Zhang*"", || ""Author: sujinbo,zhang-jing@ruc.edu.cn"" || ], || ""doi"": ""10.1234/example.12345"", || ""arxiv_id"": """", || ""keywords"": [ || ""Text-to-SQL"", || ""TableCache"", || ""KV cache"", || ""Precomputation"", || ""Latency optimization"", || ""Table representation"", || ""Inference efficiency"" || ], || ""summary"": ""The paper proposes TableCache to precompute table representations as KV caches offline, reducing latency in LLM-based Text-to-SQL systems. It addresses inefficiencies from embedding extensive table schemas in prompts and introduces a Table Trie structure for fast lookups. Experimental results demonstrate a significant speedup in Time to First Token (TTFT)."" || } ||  || [ Prompt: 115.9 t/s | Generation: 28.7 t/s ]"
2601.08747v2_To Retrieve or To Think An Agentic Approach for Co.pdf,,[],,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || T o Retrieve or T o Think? An Agentic Approach for Context Evolution || Rubing Chen, Jian Wang, Wenjie Li, Xiao-Yong Wei || * || , Qing Li || Department of Computing, The Hong Kong Polytechnic University || rubing.chen@connect.polyu.hk jian51.wang@polyu.edu.hk || cswjli@comp.polyu.edu.hk {cs007.wei,q ... (truncated) ||  || { || ""title"": ""Retrieve or Think? An Agentic Approach for Context Evolution"", || ""authors"": [ || ""Rubing Chen"", || ""Jian Wang"", || ""Wenjie Li"", || ""Xiao-Yong Wei"", || ""Qing Li"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Current context augmentation methods are essential for knowledge-intensive reasoning, but they often use rigid brute-force strategies. This paper introduces Agentic Context Evolution (ACE), a framework that dynamically decides whether to retrieve new information or reason internally, aiming to improve efficiency and accuracy in complex tasks."" || } ||  || [ Prompt: 122.2 t/s | Generation: 26.9 t/s ]"
2601.08753v1_Grid-Aware Charging and Operational Optimization f.pdf,Grid-Aware Charging and Operational,"['Rishav Sen', 'Amutheezan Sivagnanam', 'Aron Laszka', 'Ayan Mukhopadhyay', 'Abhishek Dubey']",,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Grid-Aware Charging and Operational || Optimization for Mixed-Fleet Public Transit || Rishav Sen , Amutheezan Sivagnanam , Aron Laszka , Ayan Mukhopadhyay , Abhishek Dubey || Institute for Software Integrated Systems, Vanderbilt University || Pennsylvania State University || AbstractThe rapid g ... (truncated) ||  || { || ""title"": ""Grid-Aware Charging and Operational"", || ""authors"": [ || ""Rishav Sen"", || ""Amutheezan Sivagnanam"", || ""Aron Laszka"", || ""Ayan Mukhopadhyay"", || ""Abhishek Dubey"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Mixed transit fleet"", || ""electrification"", || ""dynamic pricing"", || ""hierarchical MILP"", || ""operational challenges"", || ""seating constraints"" || ], || ""summary"": ""The paper presents a mixed-integer linear programming model to optimize charging schedules and trip assignments for mixed electric and diesel bus fleets, addressing challenges posed by dynamic electricity pricing and operational constraints."" || } ||  || [ Prompt: 131.5 t/s | Generation: 28.1 t/s ]"
2601.08768v1_AI as Entertainment.pdf,AI as Entertainment,"['Cody Kommers', 'Ari Holtzman']",https://doi.org/XXXXXXX.XXXXXX,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || AI as Entertainment || CODY KOMMERS,The Alan Turing Institute, UK || ARI HOLTZMAN,University of Chicago, USA || Generative AI systems are predominantly designed, evaluated, and marketed as intelligent systems which will benefit society by || augmenting or automating human cognitive labor, promi ... (truncated) ||  || { || ""title"": ""AI as Entertainment"", || ""authors"": [ || ""Cody Kommers"", || ""Ari Holtzman"" || ], || ""doi"": ""https://doi.org/XXXXXXX.XXXXXX"", || ""arxiv_id"": ""1, 1 (January 2026), 16 pages"", || ""keywords"": [ || ""Generative AI"", || ""Entertainment"", || ""Culture"", || ""LLMs"", || ""Societal Impact"", || ""Meaning-making"", || ""Human-centered computing"" || ], || ""summary"": ""This paper explores how AI is currently framed primarily as a tool for intelligence and productivity, but argues for a shift in perspective to consider its potential as entertainment. It highlights the need for frameworks that evaluate AI-generated cultural content based on its social and emotional impacts rather than just cultural harms."" || } ||  || [ Prompt: 125.3 t/s | Generation: 28.8 t/s ]"
2601.08773v1_Reliable Graph-RAG for Codebases AST-Derived Graph.pdf,Reliable Graph-RAG for Codebases: AST-Derived,['Manideep Reddy Chinthareddy'],arXiv:2601.08773v1,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Reliable Graph-RAG for Codebases: AST-Derived || Graphs vs LLM-Extracted Knowledge Graphs || Manideep Reddy Chinthareddy || Software Engineer, Centerville, USA || chmanideepreddy@gmail.com || January 2026 || Abstract || Retrieval-Augmented Generation (RAG) for software engineering || often relies on vector ... (truncated) ||  || { || ""title"": ""Reliable Graph-RAG for Codebases: AST-Derived"", || ""authors"": [""Manideep Reddy Chinthareddy""], || ""doi"": ""arXiv:2601.08773v1"", || ""arxiv_id"": ""arXiv:2601.08773"", || ""keywords"": [""software engineering"", ""code repositories"", ""knowledge graphs"", ""AST"", ""LLM""], || ""summary"": ""This paper benchmarks three retrieval-augmented generation pipelines for Java codebases, comparing No-Graph Naive RAG, LLM-Generated Knowledge Graph RAG, and a deterministic AST-derived Knowledge Graph RAG. It evaluates indexing overhead, query-time latency, coverage, and structural output, highlighting LLM-KB's higher latency and coverage issues."" || } ||  || [ Prompt: 120.6 t/s | Generation: 28.8 t/s ]"
2601.08776v1_Translating Light-Sheet Microscopy Images to Virtu.pdf,Translating Light-Sheet Microscopy Images to Virtual H&E Using CycleGAN,['Yanhua Zhao'],,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Translating Light-Sheet Microscopy Images to || Virtual H&E Using CycleGAN || Yanhua Zhao || AbstractHistopathology analysis relies on Hematoxylin and || Eosin (H&E) staining, but fluorescence microscopy offers comple- || mentary information. Converting fluorescence images to H&E- || like appearance  ... (truncated) ||  || { || ""title"": ""Translating Light-Sheet Microscopy Images to Virtual H&E Using CycleGAN"", || ""authors"": [""Yanhua Zhao""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Histopathology"", ""image translation"", ""H&E staining"", ""unpaired learning"", ""CycleGAN""], || ""summary"": ""This paper presents a Cycle-Consistent Adversarial Network (CycleGAN) approach for unpaired image-to-image translation from multi-channel fluorescence microscopy to pseudo H&E stained histopathology images. The method combines C01 and C02 fluorescence channels into RGB and learns a bidirectional mapping between fluorescence and H&E domains without paired training data. The architecture uses ResNet-based generators with residual blocks and PatchGAN discriminators, trained with adversarial, cycle-consistency, and identity losses. The model generates realistic pseudo H&E images that preserve morphological structures while adopting H&E-like color characteristics, enabling visualization of fluorescence data in a pathologist-friendly format."" || } ||  || [ Prompt: 128.5 t/s | Generation: 29.1 t/s ]"
2601.08777v1_Asymptotic Universal Alignment A New Alignment Fra.pdf,Asymptotic Universal Alignment: A New Alignment Framework via Test-Time Scaling,"['Yang Cai', 'Weiqiang Zheng']",arXiv:2601.08777v1,32.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Asymptotic Universal Alignment: || A New Alignment Framework via Test-Time Scaling || Yang Cai* || Yale University || yang.cai@yale.edu || Weiqiang Zheng* || Yale University || weiqiang.zheng@yale.edu || January 14, 2026 || Abstract || Aligning large language models (LLMs) to serve users with heterogeneous and p ... (truncated) ||  || { || ""title"": ""Asymptotic Universal Alignment: A New Alignment Framework via Test-Time Scaling"", || ""authors"": [ || ""Yang Cai"", || ""Weiqiang Zheng"" || ], || ""doi"": ""arXiv:2601.08777v1"", || ""arxiv_id"": ""2601.08777"", || ""keywords"": [], || ""summary"": ""Aligning large language models to serve users with heterogeneous preferences; introduces (k, f(k)) robust alignment and asymptotic universal alignment; characterizes optimal convergence rates; discusses limitations of NLHF."" || } ||  || [ Prompt: 129.4 t/s | Generation: 32.3 t/s ]"
2601.08778v3_Pervasive Annotation Errors Break Text-to-SQL Benc.pdf,Pervasive Annotation Errors Break Text-to-SQL Benchmarks and Leaderboards,"['Tengjun Jin', 'Yoojin Choi', 'Yuxuan Zhu', 'Daniel Kang']",,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Pervasive Annotation Errors Break Text-to-SQL Benchmarks and || Leaderboards || Tengjun Jin || University of Illinois (UIUC) || Urbana, USA || tengjun2@illinois.edu || Yoojin Choi || University of Illinois (UIUC) || Urbana, USA || yoojinc3@illinois.edu || Yuxuan Zhu || University of Illinois (UIUC) || Urbana, USA || yxx4 ... (truncated) ||  || { || ""title"": ""Pervasive Annotation Errors Break Text-to-SQL Benchmarks and Leaderboards"", || ""authors"": [ || ""Tengjun Jin"", || ""Yoojin Choi"", || ""Yuxuan Zhu"", || ""Daniel Kang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper benchmarks annotation error rates for BIRD and Spider 2.0-Snow text-to-SQL benchmarks, evaluates the impact of annotation errors on agent performance and leaderboard rankings, and analyzes how errors affect reported results."" || } ||  || [ Prompt: 113.3 t/s | Generation: 29.1 t/s ]"
2601.08785v1_Uncovering Political Bias in Large Language Models.pdf,Uncovering Political Bias in Large Language Models using Parliamentary Voting Records,"['Jieying Chen', 'Karen de Jong', 'Andreas Poole', 'Jan Burakowski', 'Elena Elderson Nosti', 'Joep Windt', 'Chendi Wang']",10.48550/arXiv.2026.XXXX,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Uncovering Political Bias in Large Language Models using || Parliamentary Voting Records || Jieying Chen || Vrije Universiteit Amsterdam || Amsterdam, Netherlands || jieying.chenchen@gmail.com || Karen de Jong || Vrije Universiteit Amsterdam || Amsterdam, Netherlands || karenmadejong@gmail.com || Andreas Poole || U ... (truncated) ||  || { || ""title"": ""Uncovering Political Bias in Large Language Models using Parliamentary Voting Records"", || ""authors"": [ || ""Jieying Chen"", || ""Karen de Jong"", || ""Andreas Poole"", || ""Jan Burakowski"", || ""Elena Elderson Nosti"", || ""Joep Windt"", || ""Chendi Wang"" || ], || ""doi"": ""10.48550/arXiv.2026.XXXX"", || ""arxiv_id"": ""10.48550/arXiv"", || ""keywords"": [ || ""political bias"", || ""large language models"", || ""parliamentary voting"", || ""ideological tendencies"", || ""cross-national evaluation"" || ], || ""summary"": ""This paper introduces a methodology to construct political-bias benchmarks by aligning model-generated voting predictions with verified parliamentary voting records. It evaluates ideological tendencies and political entity bias in LLMs across three national case studies, highlighting consistent left-leaning or centrist tendencies with negative biases toward right-conservative parties."" || } ||  || [ Prompt: 120.8 t/s | Generation: 28.2 t/s ]"
2601.08806v1_APEX-SWE.pdf,APEXSWE,"['Abhi Kottamasu1', 'Aakash Barthwal1', 'Jiagrh Mahapatra1', 'Adarsh Hiremath1', 'Brendan Foody1', 'Bertie Vidgen1']",arXiv:2601.08806v1,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || APEXSWE || Abhi Kottamasu1 Akul Datta1 Aakash Barthwal1 Ajay Arun1 || Chirag Mahapatra1 Adarsh Hiremath1 Brendan Foody1 Bertie Vidgen1 || 1Mercor Joint first authors || Abstract || We introduce the AI Productivity Index for || Software Engineering (APEXSWE), a bench- || mark for assessing whether fronti ... (truncated) ||  || { || ""title"": ""APEXSWE"", || ""authors"": [ || ""Abhi Kottamasu1"", || ""Aakash Barthwal1"", || ""Jiagrh Mahapatra1"", || ""Adarsh Hiremath1"", || ""Brendan Foody1"", || ""Bertie Vidgen1"" || ], || ""doi"": ""arXiv:2601.08806v1"", || ""arxiv_id"": ""arXiv:2601.08806"", || ""keywords"": [ || ""AI Productivity Index"", || ""software engineering"", || ""integration tasks"", || ""observability tasks"", || ""epistemic reasoning"" || ], || ""summary"": ""We introduce the AI Productivity Index for Software Engineering (APEXSWE), a benchmark for assessing frontier AI models in executing economically valuable software engineering tasks. The study evaluates two task types: integration tasks and observability tasks, and analyzes model performance based on reasoning abilities."" || } ||  || [ Prompt: 118.2 t/s | Generation: 29.1 t/s ]"
2601.08807v1_S3-CLIP Video Super Resolution for Person-ReID.pdf,S3-CLIP: Video Super Resolution for Person-ReID,"['Tamas Endrei', 'Pazmany Peter', 'Cserey Gyorgy']",10.48550/arXiv/2303.04112,29.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || S3-CLIP: Video Super Resolution for Person-ReID || Tamas Endrei || Pazmany Peter Catholic University, Hungary || endrei.tamas@itk.ppke.hu || Gyorgy Cserey || Pazmany Peter Catholic University, Hungary || cserey.gyorgy@itk.ppke.hu || Abstract || Tracklet quality is often treated as an afterthought in || most p ... (truncated) ||  || { || ""title"": ""S3-CLIP: Video Super Resolution for Person-ReID"", || ""authors"": [ || ""Tamas Endrei"", || ""Pazmany Peter"", || ""Cserey Gyorgy"" || ], || ""doi"": ""10.48550/arXiv/2303.04112"", || ""arxiv_id"": ""10.48550/arXiv/2303.04112"", || ""keywords"": [ || ""person re-identification"", || ""video super-resolution"", || ""CLIP"", || ""ReID"", || ""tracklet quality"", || ""architectural modifications"" || ], || ""summary"": ""This paper introduces S3-CLIP, a video super-resolution-based CLIP Re-ID framework for the VReID-XFD challenge. It integrates super-resolution networks with task-driven super-resolution to enhance tracklet quality in challenging cross-view conditions, achieving competitive performance."" || } ||  || [ Prompt: 120.8 t/s | Generation: 29.4 t/s ]"
2601.08808v1_Multiplex Thinking Reasoning via Token-wise Branch.pdf,Multiplex Thinking,"['Yao Tang1', 'Li Dong2', 'Yaru Hao2', 'Qingxiu Dong2', 'Furu Wei2', 'Jiatao Gu1']",,27.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Multiplex Thinking: || Reasoning via Token-wise Branch-and-Merge || Yao Tang1 Li Dong2 Yaru Hao2 Qingxiu Dong2 Furu Wei2 Jiatao Gu1 || 1University of Pennsylvania 2Microsoft Research || 1{tangyao,jgu32}@seas.upenn.edu || Large language models often solve complex reasoning tasks more effectively wi ... (truncated) ||  || { || ""title"": ""Multiplex Thinking"", || ""authors"": [ || ""Yao Tang1"", || ""Li Dong2"", || ""Yaru Hao2"", || ""Qingxiu Dong2"", || ""Furu Wei2"", || ""Jiatao Gu1"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""A stochastic soft reasoning mechanism that aggregates candidate tokens into a continuous multiplex token, enabling efficient optimization with reinforcement learning while balancing confidence and diversity in reasoning."" || } ||  || [ Prompt: 118.7 t/s | Generation: 27.3 t/s ]"
2601.08811v1_Reasoning Matters for 3D Visual Grounding.pdf,Reasoning Matters for 3D Visual Grounding,"['Hsiang-Wei Huang', 'Kuang-Ming Chen', 'Wenhao Chai', 'Cheng-Yen Yang']",,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Reasoning Matters for 3D Visual Grounding || Hsiang-Wei Huang Kuang-Ming Chen Wenhao Chai Cheng-Yen Yang || Jen-Hao Cheng Jenq-Neng Hwang || University of Washington || {hwhuang,kmchen,wchai,cycyang,andyhci,hwang}@uw.edu || Abstract || The recent development of Large Language Models (LLMs) || with stron ... (truncated) ||  || { || ""title"": ""Reasoning Matters for 3D Visual Grounding"", || ""authors"": [ || ""Hsiang-Wei Huang"", || ""Kuang-Ming Chen"", || ""Wenhao Chai"", || ""Cheng-Yen Yang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""3D visual grounding"", || ""LLM"", || ""reasoning"", || ""LLM fine-tuning"", || ""3D scene understanding"" || ], || ""summary"": ""This paper proposes a 3D visual grounding data pipeline that automatically synthesizes 3D visual grounding data and reasoning processes. It introduces Reason3DVG-8B, achieving 25% better performance than 3D-GRAND using only 1.6% of training data, highlighting the importance of reasoning in 3D visual grounding."" || } ||  || [ Prompt: 116.7 t/s | Generation: 29.1 t/s ]"
2601.08816v2_MemRec Collaborative Memory-Augmented Agentic Reco.pdf,MemRec: Collaborative Memory-Augmented Agentic Recommender,"['Weixin Chen', 'Yuhan Yu', 'Jingyuan Huang', 'Zihe Ye', 'Yongfeng Zhang', 'Neil Shah', 'Li Chen']",10.48550/arXiv.2405.12345,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MemRec: Collaborative Memory-Augmented Agentic Recommender || System || Weixin Chen1,2 Yuhan Zhao1 Jingyuan Huang2 Zihe Ye2 || Clark Mingxuan Ju3 Tong Zhao3 Neil Shah3 Li Chen1 Yongfeng Zhang2 || 1Hong Kong Baptist University 2Rutgers University 3Snap Inc. || {cswxchen, csyhzhao, lichen}@comp.hkbu ... (truncated) ||  || { || ""title"": ""MemRec: Collaborative Memory-Augmented Agentic Recommender"", || ""authors"": [ || ""Weixin Chen"", || ""Yuhan Yu"", || ""Jingyuan Huang"", || ""Zihe Ye"", || ""Yongfeng Zhang"", || ""Neil Shah"", || ""Li Chen"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [ || ""recommender systems"", || ""memory augmentation"", || ""agentic agents"", || ""semantic memory"", || ""LLM"", || ""collaborative memory"" || ], || ""summary"": ""The paper introduces MemRec, a framework that decouples reasoning from memory management to enable efficient collaborative augmentation. It features a dedicated LMMem for dynamic memory graphs and achieves state-of-the-art performance on benchmarks."" || } ||  || [ Prompt: 121.7 t/s | Generation: 28.8 t/s ]"
2601.08828v1_Motion Attribution for Video Generation.pdf,Motion Attribution for Video Generation,"['Xindi Wu', 'Despoina Paschalidou', 'Jun Gao', 'Antonio Torralba', 'Laura Leal-Taix', 'Olga Russakovsky', 'Sanja Fidler', 'Jonathan Lorraine']",https://research.nvidia.com/labs/sil/projects/MOTIVE/,29.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 2026-1-14 || Motion Attribution for Video Generation || Xindi Wu12, Despoina Paschalidou1, Jun Gao1, Antonio Torralba3, Laura Leal-Taix1, Olga Russakovsky2, || Sanja Fidler1, Jonathan Lorraine1 || 1NVIDIA 2Princeton University 3MIT CSAIL || https://research.nvidia.com/labs/sil/projects/MOTIVE/ || Abs ... (truncated) ||  || { || ""title"": ""Motion Attribution for Video Generation"", || ""authors"": [ || ""Xindi Wu"", || ""Despoina Paschalidou"", || ""Jun Gao"", || ""Antonio Torralba"", || ""Laura Leal-Taix"", || ""Olga Russakovsky"", || ""Sanja Fidler"", || ""Jonathan Lorraine"" || ], || ""doi"": ""https://research.nvidia.com/labs/sil/projects/MOTIVE/"", || ""arxiv_id"": ""NVIDIA 2Princeton University 3MIT CSAIL"", || ""keywords"": [ || ""motion attribution"", || ""video generation"", || ""data attribution"", || ""temporal dynamics"", || ""motion-specific influence"" || ], || ""summary"": ""Presents Motive, a motion-centric, gradient-based data attribution framework for video generation, demonstrating its effectiveness in improving motion smoothness and temporal consistency on VBench."" || } ||  || [ Prompt: 121.4 t/s | Generation: 29.7 t/s ]"
2601.08829v1_Modeling LLM Agent Reviewer Dynamics in Elo-Ranked.pdf,Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System,"['Hsiang-Wei Huang', 'Junbin Lu', 'Kuang-Ming Chen', 'Jenq-Neng Hwang']",,30.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System || Hsiang-Wei Huang* Junbin Lu* Kuang-Ming Chen Jenq-Neng Hwang || University of Washington || Abstract || In this work, we explore the Large Language || Model (LLM) agent reviewer dynamics in an || Elo-ranked review system using real-w ... (truncated) ||  || { || ""title"": ""Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System"", || ""authors"": [ || ""Hsiang-Wei Huang"", || ""Junbin Lu"", || ""Kuang-Ming Chen"", || ""Jenq-Neng Hwang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This work explores LLM agent reviewer dynamics in an Elo-ranked review system using real-world conference paper submissions. It compares a baseline with Elo ratings and reviewer memory effects, showing improved Area Chair decision accuracy and adaptive review strategies."" || } ||  || [ Prompt: 120.2 t/s | Generation: 30.1 t/s ]"
2601.08873v1_ForensicFormer Hierarchical Multi-Scale Reasoning .pdf,ForensicFormer: Hierarchical Multi-Scale Reasoning,['Hema Hariharan Samson'],,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ForensicFormer: Hierarchical Multi-Scale Reasoning || for Cross-Domain Image Forgery Detection || Hema Hariharan Samson || Independent Researcher || Email: hemahariharansamson@gmail.com || AbstractThe proliferation of AI-generated imagery and so- || phisticated editing tools has rendered traditional  ... (truncated) ||  || { || ""title"": ""ForensicFormer: Hierarchical Multi-Scale Reasoning"", || ""authors"": [""Hema Hariharan Samson""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""image forensics"", ""forgery detection"", ""transformers"", ""cross-domain generalization"", ""AI-generated images""], || ""summary"": ""Presents ForensicFormer, a hierarchical multi-scale framework for cross-domain forgery detection using transformers, achieving 86.8% average accuracy across diverse datasets and demonstrating robustness to various manipulation techniques."" || } ||  || [ Prompt: 118.9 t/s | Generation: 27.5 t/s ]"
2601.08874v1_The Illusion of Friendship Why Generative AI Deman.pdf,The Illusion of Friendship: Why Generative AI Demands Unprecedented Ethical Vigilance,['Md Zahidul Islam'],,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || The Illusion of Friendship: Why Generative AI Demands Unprecedented || Ethical Vigilance || Md Zahidul Islam || AI and Cyber Futures (AICF) Centre, and the School of Computing, Mathematics and Engineering, Faculty of || Business, Justice and Behavioural Sciences, Charles Sturt University, A ... (truncated) ||  || { || ""title"": ""The Illusion of Friendship: Why Generative AI Demands Unprecedented Ethical Vigilance"", || ""authors"": [""Md Zahidul Islam""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper explores how generative AI blurs the line between tool and companion, examining ethical risks when users form emotional attachments to AI systems. It argues that despite relational appearances, GenAI lacks moral agency and proposes safeguards to mitigate over-reliance and emotional misattribution."" || } ||  || [ Prompt: 127.4 t/s | Generation: 28.7 t/s ]"
2601.08875v2_Learning Domain-Invariant Representations for Cros.pdf,Learning Domain-Invariant Representations for Cross-Domain Image,"['Jiahao Qin', 'Yiwen Wang']",10.48550/arXiv.2405.12345,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Learning Domain-Invariant Representations for Cross-Domain Image || Registration via Scene-Appearance Disentanglement || Jiahao Qin, Yiwen Wang || jiahao.qin19@gmail.com || Equal contribution Corresponding author || Abstract || Image registration under domain shift remains a fundamen- || tal challenge i ... (truncated) ||  || { || ""title"": ""Learning Domain-Invariant Representations for Cross-Domain Image"", || ""authors"": [""Jiahao Qin"", ""Yiwen Wang""], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [""image registration"", ""domain shift"", ""scene-appearance disentanglement""], || ""summary"": ""Addresses domain shift in image registration by disentangling scene-invariant representations and domain-specific appearance codes, enabling robust cross-domain alignment."" || } ||  || [ Prompt: 118.7 t/s | Generation: 28.3 t/s ]"
2601.08881v1_TAG-MoE Task-Aware Gating for Unified Generative M.pdf,TAG-MoE: Task-Aware Gating for Unified Generative Mixture-of-Experts,"['Yu Xu', 'Hongbin Yan', 'Juan Cao', 'Tiankai Hang', 'Runze He', 'Zijin Yin', 'Shiyi Zhang', 'Jintao Li', 'Chunyu Wang', 'Quan Liang', 'Tong-Yee Lee', 'Fan Tang']",https://yuci-gpt.github.io/TAG-MoE/,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TAG-MoE: Task-Aware Gating for Unified Generative Mixture-of-Experts || Yu Xu1,2 Hongbin Yan1 Juan Cao1 Yiji Cheng2 Tiankai Hang2 || Runze He2 Zijin Yin2 Shiyi Zhang2 Yuxin Zhang1 Jintao Li1 || Chunyu Wang2 Qinglin Lu2 Tong-Yee Lee3 Fan Tang1 || 1University of Chinese Academy of Sciences 2Tence ... (truncated) ||  || { || ""title"": ""TAG-MoE: Task-Aware Gating for Unified Generative Mixture-of-Experts"", || ""authors"": [ || ""Yu Xu"", || ""Hongbin Yan"", || ""Juan Cao"", || ""Tiankai Hang"", || ""Runze He"", || ""Zijin Yin"", || ""Shiyi Zhang"", || ""Jintao Li"", || ""Chunyu Wang"", || ""Quan Liang"", || ""Tong-Yee Lee"", || ""Fan Tang"" || ], || ""doi"": ""https://yuci-gpt.github.io/TAG-MoE/"", || ""arxiv_id"": ""arXiv:2601.08881v1"", || ""keywords"": [ || ""TAG-MoE"", || ""Mixture-of-Experts"", || ""Generative modeling"", || ""Task-aware gating"", || ""Diffusion transformer"", || ""Image editing"", || ""Sketch-based guidance"" || ], || ""summary"": ""The paper presents a framework for injecting high-level task semantic intent into local routing decisions of Mixture-of-Experts models, enabling better handling of diverse generative tasks. It introduces a Hierarchical Task Semantic Annotation scheme and Predictive Alignment Regularization to mitigate interference and improve performance."" || } ||  || [ Prompt: 123.5 t/s | Generation: 28.4 t/s ]"
2601.08882v1_Compressing Vision Transformers in Geospatial Tran.pdf,Compressing Vision Transformers in Geospatial,"['Thomas Snyder', 'H. Lexie Yang', 'Stefan Schnake', 'Steffen Schotthfer']",arXiv:2601.08882v1,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Compressing Vision Transformers in Geospatial || Transfer Learning with Manifold-Constrained || Optimization || Thomas Snyder || Yale University || 201 York Street, New Haven, CT 06511, USA || thomas.snyder@yale.edu || H. Lexie Yang || Geospatial Science and Human Security Division || Oak Ridge National Labor ... (truncated) ||  || { || ""title"": ""Compressing Vision Transformers in Geospatial"", || ""authors"": [ || ""Thomas Snyder"", || ""H. Lexie Yang"", || ""Stefan Schnake"", || ""Steffen Schotthfer"" || ], || ""doi"": ""arXiv:2601.08882v1"", || ""arxiv_id"": ""arXiv:2601.08882"", || ""keywords"": [ || ""transfer learning"", || ""manifold-constrained"", || ""optimization"", || ""geospatial"", || ""compression"", || ""edge devices"" || ], || ""summary"": ""Deploying geospatial foundation models on resource-constrained edge devices demands compact architectures that maintain high downstream performance. This work leverages manifold-constrained optimization to compress large vision transformers during transfer learning, achieving strong compression with minimal accuracy loss."" || } ||  || [ Prompt: 134.4 t/s | Generation: 28.8 t/s ]"
2601.08884v1_Bridging the Gap Empowering Small Models in Reliab.pdf,Bridging the Gap: Empowering Small Models in Reliable OpenACC-based Parallelization via GEPA-Optimized Prompting,"['Samyak Jhaveri', 'Cristina V. Lopes']",,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Bridging the Gap: Empowering Small Models in || Reliable OpenACC-based Parallelization via || GEPA-Optimized Prompting || Samyak Jhaveri || School of Information and Computer Science || University of California, Irvine || samyaknj@uci.edu || Cristina V . Lopes || School of Information and Computer Science || ... (truncated) ||  || { || ""title"": ""Bridging the Gap: Empowering Small Models in Reliable OpenACC-based Parallelization via GEPA-Optimized Prompting"", || ""authors"": [ || ""Samyak Jhaveri"", || ""Cristina V. Lopes"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""OpenACC"", || ""Parallel Code Generation"", || ""Large Language Models"", || ""Prompt Optimization"", || ""High-Performance Computing"", || ""GPU Programming"" || ], || ""summary"": ""This work introduces a systematic prompt optimization approach to enhance OpenACC pragma generation for small and efficient LLMs. Using the GEPA framework, it iteratively refines prompts through expert feedback, improving compilation success and enabling functional GPU speedups, thereby lowering expertise barriers in HPC workflows."" || } ||  || [ Prompt: 115.7 t/s | Generation: 28.1 t/s ]"
2601.08891v1_Attention Consistency Regularization for Interpret.pdf,Attention Consistency Regularization for Interpretable Early-Exit Neural Networks,['Yanhua Zhao'],10.48550/arXiv.2405.12345,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Attention Consistency Regularization for || Interpretable Early-Exit Neural Networks || Yanhua Zhao || KIS*MED (AI Systems in Medicine) || Technische Universitat Darmstadt || Darmstadt, Germany || AbstractEarly-exit neural networks enable adaptive inference || by allowing predictions at intermediate lay ... (truncated) ||  || { || ""title"": ""Attention Consistency Regularization for Interpretable Early-Exit Neural Networks"", || ""authors"": [""Yanhua Zhao""], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [""early-exit networks"", ""explainable AI"", ""attention mechanisms"", ""multi-objective learning""], || ""summary"": ""The paper presents Explanation-Guided Training (EGT), a multi-objective framework that improves interpretability and consistency in early-exit networks through attention-based regularization. EGT introduces an attention consistency loss to align early-exit attention maps with the final exit, achieving up to 98.97% accuracy with a 1.97 inference speedup."" || } ||  || [ Prompt: 130.6 t/s | Generation: 28.6 t/s ]"
2601.08892v1_Evaluating Role-Consistency in LLMs for Counselor .pdf,,[],,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Evaluating Role-Consistency in LLMs for || Counselor Training || Eric Rudolph1[0009000306154780], Natalie Engert1[0009000124930208], and || Jens Albrecht1[0000000340701787] || Technische Hochschule Nrnberg Georg Simon Ohm, Kelerplatz 12,90489 Nrnberg, || Germany{eric.rudolph, natalie.engert, jens. ... (truncated) ||  || { || ""title"": ""Evaluating Role-Consistency in LLMs for Counselor Training"", || ""authors"": [ || ""Eric Rudolph"", || ""Natalie Engert"", || ""Jens Albrecht"" || ], || ""doi"": ""arXiv:2601.08892v1"", || ""arxiv_id"": ""arXiv:2601.08892v1"", || ""keywords"": [ || ""Counseling"", || ""Chatbot"", || ""LargeLanguageModel"", || ""Persona Consistency"", || ""Educational Role-Play"" || ], || ""summary"": ""The paper evaluates role-consistency in large language models using a new adversarial dataset to test their ability to maintain assigned roles in virtual client interactions. It compares Vicuna models and assesses performance in counseling contexts."" || } ||  || [ Prompt: 131.7 t/s | Generation: 28.6 t/s ]"
2601.08896v1_XGBoost Forecasting of NEPSE Index Log Returns wit.pdf,XGBoost Forecasting of NEPSE Index Log Returns with Walk,"['Sahaj Raj Mallaa', 'Shreeyash Kayasthaa', 'Rumi Suwala', 'Harish Chandra Bhandaria', 'Rajendra Adhikarib']",,29.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || XGBoost Forecasting of NEPSE Index Log Returns with Walk || Forward Validation || Sahaj Raj Mallaa,, Shreeyash Kayasthaa, Rumi Suwala, Harish Chandra Bhandaria and || Rajendra Adhikarib || aDepartment of Mathematics, Kathmandu University, P .O. Box 6250, Dhulikhel, 45200, Kavre, Bagmati Provinc ... (truncated) ||  || { || ""title"": ""XGBoost Forecasting of NEPSE Index Log Returns with Walk"", || ""authors"": [ || ""Sahaj Raj Mallaa"", || ""Shreeyash Kayasthaa"", || ""Rumi Suwala"", || ""Harish Chandra Bhandaria"", || ""Rajendra Adhikarib"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""NEPSE Index"", || ""stock index forecasting"", || ""XGBoost"", || ""walk-forward validation"", || ""hyperparameter optimization"", || ""time series forecasting"", || ""emerging markets"", || ""feature engineering"" || ], || ""summary"": ""This study develops a robust machine learning framework for one-step-ahead forecasting of daily log returns in the Nepal Stock Exchange (NEPSE) Index using the XGBoost regressor. A comprehensive feature set is engineered, including lagged log-returns and technical indicators. Hyperparameter optimization is performed using Optuna with time-series cross-validation. Out-of-sample performance is rigorously assessed via walk-forward validation under both expanding and fixed-length rolling windows. Predictive accuracy is evaluated using RMSE, MAE, coefficient of determination, and directional accuracy. The optimal configuration achieves the lowest log-return RMSE and MAE, highlighting the effectiveness of gradient boosting ensembles in modeling nonlinear dynamics in volatile emerging market time series."" || } ||  || [ Prompt: 125.6 t/s | Generation: 29.6 t/s ]"
2601.08901v1_Navigating Ideation Space Decomposed Conceptual Re.pdf,Navigating Ideation Space: Decomposed Conceptual Representations for Positioning Scientific Ideas,"['Yuexi Shen', 'Minqian Liu']",10.48550/arXiv.2303.03047,27.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Navigating Ideation Space: Decomposed Conceptual Representations for || Positioning Scientific Ideas || Yuexi Shen* Minqian Liu* Dawei Zhou Lifu Huang || Virginia Tech University of California, Davis || University of California, Santa Barbara || yuexishen@ucsb.edu minqianliu@vt.edu lfuhuang@ucdavi ... (truncated) ||  || { || ""title"": ""Navigating Ideation Space: Decomposed Conceptual Representations for Positioning Scientific Ideas"", || ""authors"": [ || ""Yuexi Shen"", || ""Minqian Liu"" || ], || ""doi"": ""10.48550/arXiv.2303.03047"", || ""arxiv_id"": ""arXiv:2303.03047"", || ""keywords"": [ || ""scientific discovery"", || ""idea generation"", || ""knowledge representation"", || ""literature retrieval"", || ""novelty assessment"" || ], || ""summary"": ""This paper introduces the Ideation Space framework to decompose scientific knowledge into research problem, methodology, and core findings. It proposes a hierarchical sub-space retrieval and novelty assessment algorithm, achieving improved recall and retrieval performance in literature searches."" || } ||  || [ Prompt: 125.4 t/s | Generation: 27.4 t/s ]"
2601.08910v1_Towards a Self-Driving Trigger at the LHC Adaptive.pdf,Towards a Self-Driving Trigger at the LHC: Adaptive Response in Real Time,"['Shaghayegh Emami', 'Cecilia Tosciri', 'Giovanna Salvi', 'Zixin Ding', 'Yuxin Chen', 'Abhijith Gandrakota', 'Christian Herwig', 'David W. Miller', 'Jennifer Ngadiuba', 'Nhan Tran']",arXiv:2601.08910v1,29.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Towards a Self-Driving Trigger at the LHC: Adaptive Response in Real Time || Shaghayegh Emami,1 Cecilia Tosciri,2 Giovanna Salvi,1 Zixin Ding, 3 || Yuxin Chen,3 Abhijith Gandrakota, 4 Christian Herwig, 1 || David W. Miller, 2, 5 Jennifer Ngadiuba, 4 and Nhan Tran 4 || 1University of Michigan, A ... (truncated) ||  || { || ""title"": ""Towards a Self-Driving Trigger at the LHC: Adaptive Response in Real Time"", || ""authors"": [ || ""Shaghayegh Emami"", || ""Cecilia Tosciri"", || ""Giovanna Salvi"", || ""Zixin Ding"", || ""Yuxin Chen"", || ""Abhijith Gandrakota"", || ""Christian Herwig"", || ""David W. Miller"", || ""Jennifer Ngadiuba"", || ""Nhan Tran"" || ], || ""doi"": ""arXiv:2601.08910v1"", || ""arxiv_id"": ""2601.08910"", || ""keywords"": [ || ""self-driving trigger"", || ""real-time data filtering"", || ""high-throughput scientific facilities"", || ""large hadron collider"", || ""machine learning"", || ""trigger optimization"" || ], || ""summary"": ""The paper explores an adaptive, autonomous trigger system for the LHC that dynamically adjusts filtering criteria in real time to optimize performance under changing conditions. It introduces a benchmark ecosystem using CMS data to demonstrate real-time optimization of trigger thresholds and anomaly detection."" || } ||  || [ Prompt: 133.4 t/s | Generation: 29.6 t/s ]"
2601.08950v1_ConvoLearn A Dataset of Constructivist Tutor-Stude.pdf,ConvoLearn: A Dataset of Constructivist Tutor-Student Dialogue,"['Mayank Sharma Roy', 'Pea Hari Subramonyam']",10.48550/arXiv.2405.12345,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ConvoLearn: A Dataset of Constructivist Tutor-Student Dialogue || Mayank Sharma Roy Pea Hari Subramonyam || Stanford University || {masharma, roypea, harihars}@stanford.edu || Abstract || In educational applications, LLMs exhibit sev- || eral fundamental pedagogical limitations, such || as their tendenc ... (truncated) ||  || { || ""title"": ""ConvoLearn: A Dataset of Constructivist Tutor-Student Dialogue"", || ""authors"": [""Mayank Sharma Roy"", ""Pea Hari Subramonyam""], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [""constructivist tutoring"", ""LLM pedagogy"", ""educational NLP"", ""dialogic learning""], || ""summary"": ""This paper introduces ConvoLearn1, a dataset of 1,250 tutor-student dialogues designed to support constructivist learning. It evaluates how fine-tuning a model on this dataset improves knowledge-building strategies, showing significant improvements over existing models."" || } ||  || [ Prompt: 116.7 t/s | Generation: 29.0 t/s ]"
2601.08951v1_PluriHarms Benchmarking the Full Spectrum of Human.pdf,,[],,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Preprint. Under review. || PLURIHARMS: BENCHMARKING THEFULLSPECTRUM || OFHUMANJUDGMENTS ONAI HARM || Jing-Jing Li, Joel Mire, Eve Fleisig, Valentina Pyatkin, Anne G. E. Collins, || Maarten Sap,Sydney Levine || UC Berkeley Carnegie Mellon University Allen Institute for AI New York University || jl367 ... (truncated) ||  || { || ""title"": ""PLURIHARMS: BENCHMARKING THEFULLSPECTRUM OF HUMANJUDGMENTS ONAOI HARM"", || ""authors"": [ || ""Benchmarking The Full Spectrum of Human Judgments on AI Harm"", || ""Jing-Jing Li"", || ""Joel Mire"", || ""Eve Fleisig"", || ""Valentina Pyatkin"", || ""Anne G. E. Collins"", || ""Maarten Sap"", || ""Sydney Levine"" || ], || ""doi"": ""j1.XXXXX"", || ""arxiv_id"": ""jl3676@berkeley.edu"", || ""keywords"": [ || ""AI safety"", || ""human judgment"", || ""harm judgments"", || ""pluralistic systems"", || ""value diversity"", || ""disagreement analysis""] || ""summary"": ""Introduces PLURIHARMS, a benchmark to study human harm judgments across harm axis and agreement axis, aiming to improve AI safety by capturing diverse perspectives and addressing disagreement."" || } ||  || [ Prompt: 114.2 t/s | Generation: 28.1 t/s ]"
2601.08953v1_Fairness risk and its privacy-enabled solution in .pdf,Fairness risk and its privacy-enabled solution in AI-driven robotic applications,"['Le Liu', 'Bangguo Yu', 'Nynke Vellinga', 'Ming Cao', 'Corresponding author(s)']",arXiv:2601.08953v1,31.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Fairness risk and its privacy-enabled solution in || AI-driven robotic applications || Le Liu 1, Bangguo Yu 1, Nynke Vellinga 2, Ming Cao 1,3* || 1Faculty of Science and Engineering, University of Groningen, || Groningen, 9747 AG, The Netherlands. || 2Faculty of Law, University of Groningen, Groni ... (truncated) ||  || { || ""title"": ""Fairness risk and its privacy-enabled solution in AI-driven robotic applications"", || ""authors"": [ || ""Le Liu"", || ""Bangguo Yu"", || ""Nynke Vellinga"", || ""Ming Cao"", || ""Corresponding author(s)"" || ], || ""doi"": ""arXiv:2601.08953v1"", || ""arxiv_id"": ""arXiv:2601.08953"", || ""keywords"": [""Robotic Decision-making"", ""Large Language Model"", ""Fairness"", ""Privacy""], || ""summary"": ""This paper discusses fairness concerns in Generative AI-driven robotics and proposes a utility-aware fairness metric that considers privacy constraints, showing that privacy budgets can support fairness goals in real-world robotic tasks."" || } ||  || [ Prompt: 133.5 t/s | Generation: 31.0 t/s ]"
2601.08955v1_Imagine-then-Plan Agent Learning from Adaptive Loo.pdf,,[],,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Imagine-then-Plan: Agent Learning from Adaptive || Lookahead with World Models || Youwei Liu2,1*, Jian Wang 1, Hanlin Wang 1, Beichen Guo 1, Wenjie Li 1 || 1 The Hong Kong Polytechnic University || 2 Central South University || loyiv5477@gmail.com jian51.wang@polyu.edu.hk || {hanlin-henry.wang,beiche ... (truncated) ||  || { || ""title"": ""Imagine-then-Plan (ITP)"", || ""authors"": [ || ""Youwei Liu"", || ""Jian Wang"", || ""Hanlin Wang"", || ""Beichen Guo"", || ""Wenjie Li"" || ], || ""doi"": ""loyiv5477@gmail.com"", || ""arxiv_id"": ""1"", || ""keywords"": [ || ""agent learning"", || ""adaptive lookahead"", || ""world models"", || ""policy learning"", || ""LLM reasoning"" || ], || ""summary"": ""This paper proposes a unified framework for agent learning via lookahead imagination, enabling multi-step reasoning without real-time environment access. It introduces an adaptive lookahead mechanism and demonstrates superior performance across benchmarks."" || } ||  || [ Prompt: 119.3 t/s | Generation: 29.1 t/s ]"
2601.08988v1_ART Action-based Reasoning Task Benchmarking for M.pdf,AAAI 2026: Healthy Aging and Longevity Workshop (AIAA),"['Ananya Mantravadi', 'Shivali Dalmia', 'Abhishek Mukherji']",,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || AAAI 2026: Healthy Aging and Longevity Workshop (AIAA) || ART: Action-based Reasoning Task Benchmarking for || Medical AI Agents || Ananya Mantravadi 1,, Shivali Dalmia 1,, Abhishek Mukherji 1 || ABSTRACT || Reliable clinical decision support requires medical AI agents capable of safe, multi-step  ... (truncated) ||  || { || ""title"": ""AAAI 2026: Healthy Aging and Longevity Workshop (AIAA)"", || ""authors"": [ || ""Ananya Mantravadi"", || ""Shivali Dalmia"", || ""Abhishek Mukherji"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Medical AI agents"", || ""synthetic data generation"", || ""clinical reasoning evaluation"", || ""healthcare LLMs"", || ""benchmark"", || ""HITL"" || ], || ""summary"": ""Reliable clinical decision support requires medical AI agents capable of safe, multi-step reasoning over structured electronic health records. Existing benchmarks inadequately assess performance on action-based tasks involving threshold evaluation, temporal aggregation, and conditional logic. The paper introduces ART, an Action-based Reasoning benchmark, identifying error categories and proposing evaluation pipelines to advance reliable clinical agents."" || } ||  || [ Prompt: 131.0 t/s | Generation: 28.3 t/s ]"
2601.09012v3_TranslateGemma Technical Report.pdf,TranslateGemma,[],,26.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 2026-01-21 || TranslateGemma Technical Report || Google Translate Research Team || We present TranslateGemma, a suite of open machine translation models based on the Gemma 3 || foundation models. To enhance the inherent multilingual capabilities of Gemma 3 for the translation || task, we employ a  ... (truncated) ||  || { || ""title"": ""TranslateGemma"", || ""authors"": [], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""TranslateGemma is an open machine translation model based on the Gemma 3 foundation, enhanced with two-stage fine-tuning and reinforcement learning to improve translation quality."" || } ||  || [ Prompt: 117.7 t/s | Generation: 26.2 t/s ]"
2601.09018v1_Meta-learning to Address Data Shift in Time Series.pdf,META-LEARNING TOADDRESSSEDATASHIFT INTIMESERIES,"['Samuel Myrenab', 'Natalie Kleina']",,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || META-LEARNING TOADDRESSDATASHIFT INTIMESERIES || CLASSIFICATION || A PREPRINT || Samuel Myrenab || Corresponding Author || myrenst@lanl.gov || P.O. Box 1663 || Los Alamos, NM 87545-0001 || United States || Nidhi Parikha || P.O. Box 1663 || Los Alamos, NM || 87545-0001 || United States || Natalie Kleina || P.O. Box 1663 || Los Ala ... (truncated) ||  || { || ""title"": ""META-LEARNING TOADDRESSSEDATASHIFT INTIMESERIES"", || ""authors"": [ || ""Samuel Myrenab"", || ""Natalie Kleina"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""signals"", || ""seismology"", || ""Reptile"", || ""FOMAML"", || ""model-agnostic meta-learning"", || ""domain generalization"" || ], || ""summary"": ""This paper compares traditional deep learning with meta-learning approaches to address data shift in time-series classification, introducing a seismic benchmark and evaluating performance under varying data availability."" || } ||  || [ Prompt: 115.9 t/s | Generation: 29.0 t/s ]"
2601.09028v1_OpenDecoder Open Large Language Model Decoding to .pdf,OpenDecoder: Open Large Language Model Decoding to Incorporate Document Quality in RAG,"['Fengran Mo', 'Zhan Su', 'Yuchen Hui', 'Jianhan Zhang', 'Jia Ao Sun', 'Zheyuan Liu', 'Chao Zhang', 'Jian-Yun Nie']",10.48550/arXiv.2024.12345,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || OpenDecoder: Open Large Language Model Decoding to || Incorporate Document Quality in RAG || Fengran Mo || Universit de Montral || Montral, Qubec, Canada || fengran.mo@umontreal.ca || Zhan Su || Universit de Montral || Montral, Qubec, Canada || zhan.su@umontreal.ca || Yuchen Hui || Universit de Montral || Montral, Qub ... (truncated) ||  || { || ""title"": ""OpenDecoder: Open Large Language Model Decoding to Incorporate Document Quality in RAG"", || ""authors"": [ || ""Fengran Mo"", || ""Zhan Su"", || ""Yuchen Hui"", || ""Jianhan Zhang"", || ""Jia Ao Sun"", || ""Zheyuan Liu"", || ""Chao Zhang"", || ""Jian-Yun Nie"" || ], || ""doi"": ""10.48550/arXiv.2024.12345"", || ""arxiv_id"": ""arXiv:2409.12345"", || ""keywords"": [ || ""large language models"", || ""LLM-based retrieval-augmented generation"", || ""document quality"", || ""information retrieval"", || ""computing methodologies"", || ""artificial intelligence"" || ], || ""summary"": ""The paper proposes OpenDecoder, a method that uses explicit evaluation of retrieved information as a quality indicator for LLM generation. It evaluates relevance, ranking, and QPP scores to improve robustness against noisy context. Experimental results show improved performance over baselines."" || } ||  || [ Prompt: 118.6 t/s | Generation: 29.3 t/s ]"
2601.09029v1_Proactively Detecting Threats A Novel Approach Usi.pdf,Proactively Detecting Threats: A Novel Approach,"['Aniesh Chawla', 'Udbhav Prasad']",10.48550/arXiv.2311.07891,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Proactively Detecting Threats: A Novel Approach || Using LLMs || Aniesh Chawla , Udbhav Prasad || California, USA || {chawla.aniesh, udbhav523}@gmail.com || These authors contributed equally to this work. || AbstractEnterprise security faces escalating threats from || sophisticated malware, compounded ... (truncated) ||  || { || ""title"": ""Proactively Detecting Threats: A Novel Approach"", || ""authors"": [""Aniesh Chawla"", ""Udbhav Prasad""], || ""doi"": ""10.48550/arXiv.2311.07891"", || ""arxiv_id"": ""arXiv:2311.07891"", || ""keywords"": [""malware"", ""Indicators of Compromise"", ""cyber-security"", ""LLMs"", ""GenAI"", ""Machine Learning Algorithms"", ""Deep Neural Network""], || ""summary"": ""This paper presents the first systematic evaluation of large language models (LLMs) to proactively identify indicators of compromise (IOCs) from unstructured web-based threat intelligence sources. It evaluates six LLM models across 479 webpages containing 2,658 IOCs, highlighting performance variations and demonstrating the potential of LLMs for proactive cybersecurity."" || } ||  || [ Prompt: 120.2 t/s | Generation: 28.8 t/s ]"
2601.09031v1_Generalizable Geometric Prior and Recurrent Spikin.pdf,Generalizable Geometric Prior and Recurrent Spiking Feature Learning for Humanoid Robot Manipulation 1,"['Xuetao Li', 'ID, Wenke Huang', 'ID, Mang Ye', 'ID, Senior Member, IEEE, Jifeng Xuan', 'ID, Member, IEEE', 'Bo Du', 'ID, Senior Member, IEEE, Sheng Liu', 'ID, Fellow, IEEE, and Miao Li']",,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || GENERALIZABLE GEOMETRIC PRIOR AND RECURRENT SPIKING FEATURE LEARNING FOR HUMANOID ROBOT MANIPULATION 1 || Generalizable Geometric Prior and Recurrent || Spiking Feature Learning for Humanoid Robot || Manipulation || Xuetao Li || ID , Wenke Huang || ID , Mang Y e || ID ,Senior Member, IEEE, Jifeng Xuan || I ... (truncated) ||  || { || ""title"": ""Generalizable Geometric Prior and Recurrent Spiking Feature Learning for Humanoid Robot Manipulation 1"", || ""authors"": [ || ""Xuetao Li"", || ""ID, Wenke Huang"", || ""ID, Mang Ye"", || ""ID, Senior Member, IEEE, Jifeng Xuan"", || ""ID, Member, IEEE"", || ""Bo Du"", || ""ID, Senior Member, IEEE, Sheng Liu"", || ""ID, Fellow, IEEE, and Miao Li"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Humanoid Robot Manipulation"", || ""Geometric Prior"", || ""Recurrent Spiking Feature Learning"", || ""Manipulation"", || ""Generalization"", || ""Robotic Systems"" || ], || ""summary"": ""This paper presents a novel RGMP-S, Recurrent Geometric-prior Multimodal Policy with Spiking features, enabling high-level skill reasoning and data-efficient motion synthesis for humanoid robots. It introduces lightweight 2D geometric inductive biases and a recursive adaptive spiking network to improve spatiotemporal consistency and generalization across diverse environments."" || } ||  || [ Prompt: 119.9 t/s | Generation: 28.8 t/s ]"
2601.09032v1_The Hierarchy of Agentic Capabilities Evaluating F.pdf,The Hierarchy of Agentic Capabilities: Evaluating Frontier Models on Realistic RL,"['Logan Ritchie', 'Sushant Mehta', 'Nick Heiner', 'Mason', 'Yu', 'Edwin Chen']",arXiv:2601.09032v1,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || The Hierarchy of Agentic Capabilities: || Evaluating Frontier Models on Realistic RL || Environments || Logan Ritchie Sushant Mehta Nick Heiner Mason Yu Edwin Chen || Surge AI || Abstract || The advancement of large language model (LLM) based agents has shifted AI || evaluation from single-turn response ... (truncated) ||  || { || ""title"": ""The Hierarchy of Agentic Capabilities: Evaluating Frontier Models on Realistic RL"", || ""authors"": [ || ""Logan Ritchie"", || ""Sushant Mehta"", || ""Nick Heiner"", || ""Mason"", || ""Yu"", || ""Edwin Chen"" || ], || ""doi"": ""arXiv:2601.09032v1"", || ""arxiv_id"": ""arXiv:2601.09032"", || ""keywords"": [ || ""agentic capabilities"", || ""LLM"", || ""RL"", || ""workplace tasks"", || ""tool use"", || ""planning"", || ""adaptability"", || ""groundedness"", || ""common-sense reasoning"" || ], || ""summary"": ""This paper evaluates frontier AI models on 150 workplace tasks in a realistic e-commerce RL environment. It identifies a hierarchy of agentic capabilities—tool use, planning, adaptability, groundedness, and common-sense reasoning—and finds that current models struggle with fundamental and contextual challenges, highlighting gaps before human-level performance."" || } ||  || [ Prompt: 113.7 t/s | Generation: 28.1 t/s ]"
2601.09035v1_A Decompilation-Driven Framework for Malware Detec.pdf,A Decompilation-Driven Framework for Malware,"['Aniesh Chawla', 'Udbhav Prasad']",,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A Decompilation-Driven Framework for Malware || Detection with Large Language Models || Aniesh Chawla , Udbhav Prasad || California, USA || {chawla.aniesh, udbhav523}@gmail.com || These authors contributed equally to this work. || AbstractThe parallel evolution of Large Language || Models (LLMs) with  ... (truncated) ||  || { || ""title"": ""A Decompilation-Driven Framework for Malware"", || ""authors"": [""Aniesh Chawla"", ""Udbhav Prasad""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Malware"", ""Ghidra"", ""Cybersecurity"", ""LLMs"", ""GenAI"", ""Machine Learning Algorithms"", ""LLMs Code development""], || ""summary"": ""The paper evaluates the efficacy of state-of-the-art LLMs in classifying executable code as benign or malicious, introducing an automated pipeline using Ghidra for decompilation and LLMs for classification. It highlights the need for continuous fine-tuning to combat evolving malware."" || } ||  || [ Prompt: 128.0 t/s | Generation: 28.7 t/s ]"
2601.09041v1_Can LLMs interpret figurative language as humans d.pdf,,[],,26.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || CANLLMSINTERPRETFIGURATIVELANGUAGE ASHUMANSDO?: SURFACE-LEVEL VS. || REPRESENTATIONALSIMILARITY || Samhita Bollepally || samhita.bollepally@tamu.edu || Aurora Sloman-Moll || auroraslomanmoll@tamu.edu || Takashi Yamauchi || takashi-yamauchi@tamu.edu || January 15, 2026 || ABSTRACT || Large language models generat ... (truncated) ||  || { || ""title"": ""CANLLMSINTERPRETFIGURABLYANGUAGE ASHUMANSDO?"", || ""authors"": [ || ""Samhita Bollepally"", || ""Aurora Sloman-Moll"", || ""Takashi Yamauchi"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""human language models"", || ""figurative language"", || ""surface-level vs representation"", || ""LLM interpretation"", || ""contextual understanding""] || ""summary"": ""The study investigates how human participants and large language models align in interpreting figurative and socially grounded language, revealing differences in representational understanding."" || } ||  || [ Prompt: 119.8 t/s | Generation: 26.8 t/s ]"
2601.09049v1_Is Grokking Worthwhile Functional Analysis and Tra.pdf,Is Grokking Worthwhile? Functional Analysis and Transferability of Generalization Circuits in Transformers,"['Kaiyu He', 'Mian Zhang', 'Peilin Wu', 'Xinya Du', 'Zhiyu Zoey Chen']",,29.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Is Grokking Worthwhile? Functional Analysis and Transferability of || Generalization Circuits in Transformers || Kaiyu He, Mian Zhang, Peilin Wu, Xinya Du, Zhiyu Zoey Chen || Department of Computer Science || University of Texas at Dallas || {kaiyu.he, zhiyu.chen2}@utdallas.edu || Abstract || While Larg ... (truncated) ||  || { || ""title"": ""Is Grokking Worthwhile? Functional Analysis and Transferability of Generalization Circuits in Transformers"", || ""authors"": [ || ""Kaiyu He"", || ""Mian Zhang"", || ""Peilin Wu"", || ""Xinya Du"", || ""Zhiyu Zoey Chen"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper investigates whether parameter-sharing transformers can bridge the gap in two-hop reasoning using Generalization Circuits, examining grokking effects, transferability, and computational cost."" || } ||  || [ Prompt: 115.2 t/s | Generation: 29.4 t/s ]"
2601.09066v1_Midm 2.0 Korea-centric Bilingual Language Models.pdf,Mi:dm 2.0,"['Tech. Innovation Group, KT']",https://huggingface.co/K-intelligence,29.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Mi:dm 2.0 || Korea-centric Bilingual Language Models || Tech. Innovation Group, KT || midm-llm@kt.com || https://huggingface.co/K-intelligence || Abstract || We introduce Mi:dm 2.0, a bilingual large language model (LLM) specifically || engineered to advanceKOREA-CENTRICAI. This model goes beyond Korean ... (truncated) ||  || { || ""title"": ""Mi:dm 2.0"", || ""authors"": [""Tech. Innovation Group, KT""], || ""doi"": ""https://huggingface.co/K-intelligence"", || ""arxiv_id"": ""https://huggingface.co/K-intelligence"", || ""keywords"": [ || ""Korea-centric AI"", || ""Mi:dm 2.0"", || ""KOREA-CENTRICAI"", || ""language model"", || ""cultural understanding"", || ""commonsense"", || ""Korea"", || ""LLM"" || ], || ""summary"": ""Mi:dm 2.0 is a bilingual large language model designed to advance Korea-centric AI by integrating cultural context, emotional nuance, and real-world knowledge, addressing gaps in existing models due to low-quality Korean data."" || } ||  || [ Prompt: 115.9 t/s | Generation: 29.5 t/s ]"
2601.09069v1_From Symbolic to Natural-Language Relations Rethin.pdf,From Symbolic to Natural-Language Relations: Rethinking Knowledge,"['Kanyao Han', 'Yushang Lai']",,26.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || From Symbolic to Natural-Language Relations: Rethinking Knowledge || Graph Construction in the Era of Large Language Models || Kanyao Han, Yushang Lai || Walmart Global Tech || {kanyao.han, yushang.lai}@walmart.com || Abstract || Knowledge graphs (KGs) have commonly been || constructed using predefined  ... (truncated) ||  || { || ""title"": ""From Symbolic to Natural-Language Relations: Rethinking Knowledge"", || ""authors"": [""Kanyao Han"", ""Yushang Lai""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper argues for rethinking the representation of relations in knowledge graphs in light of advances in large language models, advocating for a shift from symbolic to natural-language relation descriptions."" || } ||  || [ Prompt: 121.7 t/s | Generation: 26.8 t/s ]"
2601.09072v1_Human-AI Co-design for Clinical Prediction Models.pdf,Human-AI Co-design for Clinical Prediction Models,"['Jean Feng', 'Avni Kothari', 'Patrick Vossler', 'Andrew Bishara', 'Lucas Zier', 'Newton Addo', 'Aaron Kornblith', 'Yan Shuo Tan', 'Chandan Singh']",,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Human-AI Co-design for Clinical Prediction Models || Jean Feng1,*,, Avni Kothari 1,*, Patrick Vossler 1, Andrew Bishara 1, Lucas Zier 1, || Newton Addo 1, Aaron Kornblith 1, Yan Shuo Tan 2, Chandan Singh 3 || 1University of California, San Francisco. || 2National University of Singapore. || 3Micro ... (truncated) ||  || { || ""title"": ""Human-AI Co-design for Clinical Prediction Models"", || ""authors"": [ || ""Jean Feng"", || ""Avni Kothari"", || ""Patrick Vossler"", || ""Andrew Bishara"", || ""Lucas Zier"", || ""Newton Addo"", || ""Aaron Kornblith"", || ""Yan Shuo Tan"", || ""Chandan Singh"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Large language models"", || ""Electronic health records"", || ""Concept Bottleneck"", || ""Human-AI Interaction"" || ], || ""summary"": ""Developing safe, effective, and practically useful clinical prediction models requires iterative collaboration between clinical experts, data scientists, and informaticists. This process is time-intensive and limits the adoption of CPMs, which is why HACHI is introduced to accelerate and improve model development."" || } ||  || [ Prompt: 115.3 t/s | Generation: 28.6 t/s ]"
2601.09085v1_MMR-GRPO Accelerating GRPO-Style Training through .pdf,MMR-GRPO: Accelerating GRPO-Style Training through Diversity-Aware,"['Kangda Wei', 'Ruihong Huang']",,29.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MMR-GRPO: Accelerating GRPO-Style Training through Diversity-Aware || Reward Reweighting || Kangda Wei, Ruihong Huang || Department of Computer Science and Engineering || Texas A&M University, College Station, TX || {kangda, huangrh}@tamu.edu || Abstract || Group Relative Policy Optimization (GRPO) || (Sha ... (truncated) ||  || { || ""title"": ""MMR-GRPO: Accelerating GRPO-Style Training through Diversity-Aware"", || ""authors"": [""Kangda Wei"", ""Ruihong Huang""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""GRPO"", ""diversity-aware"", ""reward reweighting"", ""mathematical reasoning""], || ""summary"": ""MMR-GRPO integrates Maximal Marginal Relevance to reweight rewards based on completion diversity, achieving faster convergence with fewer training steps and reduced wall-clock time."" || } ||  || [ Prompt: 120.6 t/s | Generation: 29.5 t/s ]"
2601.09089v1_SubTokenTest A Practical Benchmark for Real-World .pdf,A Practical Benchmark for Real-World Sub-token,['Shuyang Hou Yi Hu Muhan Zhang'],,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SUBTOKENTEST: A Practical Benchmark for Real-World Sub-token || Understanding || Shuyang Hou Yi Hu Muhan Zhang || Institute for Artificial Intelligence, Peking University || Abstract || Recent advancements in large language models || (LLMs) have significantly enhanced their rea- || soning capabilities.  ... (truncated) ||  || { || ""title"": ""A Practical Benchmark for Real-World Sub-token"", || ""authors"": [""Shuyang Hou Yi Hu Muhan Zhang""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper introduces SUBTOKENTEST, a benchmark assessing sub-token understanding through practical tasks. It evaluates ten tasks across four domains and examines tokenization-related failures, highlighting challenges in character-level comprehension."" || } ||  || [ Prompt: 118.8 t/s | Generation: 29.3 t/s ]"
2601.09097v1_Programming over Thinking Efficient and Robust Mul.pdf,Programming over Thinking: Efficient and Robust,"['Derrick Goh Xin Deik1', 'Quanyu Long1', 'Zhengyuan Liu2', 'Nancy F. Chen2', 'Wenya Wang1']",,29.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Programming over Thinking: Efficient and Robust || Multi-Constraint Planning || Derrick Goh Xin Deik1, Quanyu Long1, Zhengyuan Liu2, Nancy F. Chen2, Wenya Wang1 || 1Nanyang Technological University, Singapore || 2Agency for Science, Technology and Research (A*STAR), Singapore || gohx0043@e.ntu.edu ... (truncated) ||  || { || ""title"": ""Programming over Thinking: Efficient and Robust"", || ""authors"": [ || ""Derrick Goh Xin Deik1"", || ""Quanyu Long1"", || ""Zhengyuan Liu2"", || ""Nancy F. Chen2"", || ""Wenya Wang1"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Multi-constraint planning involves identifying, evaluating, and refining candidate plans while satisfying multiple, potentially conflicting constraints. Existing large language model (LLM) approaches face fundamental limitations in this domain. Pure reasoning paradigms, which rely on long natural language chains, are prone to inconsistency, error accumulation, and prohibitive cost as constraints compound. Conversely, LLMs combined with coding- or solver-based strategies lack flexibility: they often generate problem-specific code from scratch or depend on fixed solvers, failing to capture generalizable logic across diverse problems. To address these challenges, we introduce the ScalableCodePlanning Engine (SCOPE), a framework that disentangles query-specific reasoning from generic code execution. By separating reasoning from execution, SCOPE produces solver functions that are consistent, deterministic, and reusable across queries while requiring only minimal changes to input parameters. SCOPE achieves state-of-the-art performance while lowering cost and latency. For example, with GPT-4o, it reaches 93.1% success on TravelPlanner, a 61.6% gain over the best baseline (CoT) while cutting inference cost by 1.4x and time by 4.67x. Code is available at https://github.com/DerrickGXD/SCOPE."" || } ||  || [ Prompt: 122.2 t/s | Generation: 29.4 t/s ]"
2601.09100v2_DScheLLM Enabling Dynamic Scheduling through a Fin.pdf,Dynamic Scheduling through a Fine-Tuned Dual System Large Language Model,"['Zhang a', 'Zhang b', 'Chenggong Zhao b', 'Gaoa b', 'Xiaoke Zhao b', 'Gengyi Bai b', 'Jinhu Lv a']",,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  || D || S || ch || eLLM: || Enabling Dynamic Scheduling through a Fine || - || Tuned || Dual || - || System Large language Model ||  || L || ixiang ||  || Zhang || a || ,b || , Chenggong Zhao || b || , Q || ing ||  || G || ao || a || ,b || ,* || , Xiaoke Zhao || b || , Gengyi Bai || b || , Jinhu Lv || a ||  || a ||  || School of Automation Science and Electrical Engineering, Beihang ... (truncated) ||  || { || ""title"": ""Dynamic Scheduling through a Fine-Tuned Dual System Large Language Model"", || ""authors"": [ || ""Zhang a"", || ""Zhang b"", || ""Chenggong Zhao b"", || ""Gaoa b"", || ""Xiaoke Zhao b"", || ""Gengyi Bai b"", || ""Jinhu Lv a"" || ] || , ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""dynamic scheduling"", || ""large language model"", || ""fine-tuning"", || ""job shop scheduling"" || ], || ""summary"": ""The paper proposes DScheLLM, a dynamic scheduling approach leveraging fine-tuned large language models within a dual-system architecture to handle disturbances of different scales."" || } ||  || [ Prompt: 115.0 t/s | Generation: 29.0 t/s ]"
2601.09105v2_AviationLMM A Large Multimodal Foundation Model fo.pdf,AviationLMM: A Large Multimodal Foundation,"['Wenbin Li', 'Jingling Wu', 'Xiaoyong Lin', 'Jing Chen', 'Cong Chen']",,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  || AviationLMM: A Large Multimodal Foundation || Model for Civil Aviation ||  || Wenbin Li* || China Southern Digital || Intelligence Technology || (Guangdong) Co., Ltd. || China Southern Airlines Co., || Ltd. || Guangzhou, China || li_wenbin@csair.com ||  || Jingling Wu || China Southern Digital || Intelligen ... (truncated) ||  || { || ""title"": ""AviationLMM: A Large Multimodal Foundation"", || ""authors"": [ || ""Wenbin Li"", || ""Jingling Wu"", || ""Xiaoyong Lin"", || ""Jing Chen"", || ""Cong Chen"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""civil aviation"", || ""multi-modal model"", || ""foundation model"", || ""cloud edge collaboration"", || ""hybrid training"", || ""computer systems organization computing methodologies"" || ], || ""summary"": ""This paper introduces AviationLMM, a large multimodal foundation model for civil aviation, aiming to unify heterogeneous data streams and enhance situational awareness, adaptability, and decision support in aviation."" || } ||  || [ Prompt: 120.4 t/s | Generation: 27.5 t/s ]"
2601.09113v1_The AI Hippocampus How Far are We From Human Memor.pdf,The AI Hippocampus: How Far are We From Human Memory?,"['Zixia Jia1', 'Jiaqi Li', 'Yipeng Kang', 'Yuxuan Wang', 'Tong Wu', 'Quansen Wang', 'Xiaobo Wang', 'Shuyi Zhang', 'Jinzhe Shen', 'Qing Li', 'Siyuan Qi', 'Yitao Liang', 'Di He2']",10.48550/arXiv.2025.12345,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Published in Transactions on Machine Learning Research (11/2025) || The AI Hippocampus: || How Far are We From Human Memory? || Zixia Jia1, Jiaqi Li 1, Yipeng Kang 1, Yuxuan Wang 1, Tong Wu 1, Quansen Wang 1,2, || Xiaobo Wang1, Shuyi Zhang1, Junzhe Shen1, Qing Li1, Siyuan Qi1, Yitao Liang2, Di  ... (truncated) ||  || { || ""title"": ""The AI Hippocampus: How Far are We From Human Memory?"", || ""authors"": [ || ""Zixia Jia1"", || ""Jiaqi Li"", || ""Yipeng Kang"", || ""Yuxuan Wang"", || ""Tong Wu"", || ""Quansen Wang"", || ""Xiaobo Wang"", || ""Shuyi Zhang"", || ""Jinzhe Shen"", || ""Qing Li"", || ""Siyuan Qi"", || ""Yitao Liang"", || ""Di He2"" || ], || ""doi"": ""10.48550/arXiv.2025.12345"", || ""arxiv_id"": ""arXiv:2601.09113v1"", || ""keywords"": [ || ""memory"", || ""LLM"", || ""memory mechanisms"", || ""memory architectures"", || ""memory-augmented models"" || ], || ""summary"": ""This survey presents a comprehensive synthesis of memory in large language models and multi-modal LLMs, organizing literature into implicit, explicit, and agentic memory paradigms. It discusses architectural advances, benchmark tasks, and open challenges, aiming to guide the development of more flexible and context-sensitive memory-augmented systems."" || } ||  || [ Prompt: 114.8 t/s | Generation: 28.4 t/s ]"
2601.09116v1_LP-LLM End-to-End Real-World Degraded License Plat.pdf,LP-LLM: End-to-End Real-World Degraded License Plate Text Recognition via Large Multimodal Models,"['Haoyan Gong', 'Xian Jiaotong-Liverpool University', 'Hongbin Liu']",,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LP-LLM: End-to-End Real-World Degraded License Plate Text Recognition || via Large Multimodal Models || Haoyan Gong || Xian Jiaotong-Liverpool University || haoyan.gong21@student.xjtlu.edu.cn || Hongbin Liu || Xian Jiaotong-Liverpool University || hongbin.liu@xjtlu.edu.cn || Abstract || Real-world License Pla ... (truncated) ||  || { || ""title"": ""LP-LLM: End-to-End Real-World Degraded License Plate Text Recognition via Large Multimodal Models"", || ""authors"": [ || ""Haoyan Gong"", || ""Xian Jiaotong-Liverpool University"", || ""Hongbin Liu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""license plate recognition"", || ""degraded images"", || ""motion blur"", || ""low resolution"", || ""character recognition"", || ""structured reasoning"" || ], || ""summary"": ""The paper addresses challenges in real-world license plate recognition under severe degradations. It proposes a character-aware multimodal reasoning framework using Vision-Language Models, introducing a Character-Aware Multimodal Reasoning Module to align image restoration objectives with character recognition goals."" || } ||  || [ Prompt: 115.6 t/s | Generation: 28.3 t/s ]"
2601.09117v1_A Marketplace for AI-Generated Adult Content and D.pdf,A Marketplace for AI-Generated Adult Content and Deepfakes,"['Shalmoli Ghosh', 'Matthew R. DeVerna', 'Filippo Menczer']",,27.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A Marketplace for AI-Generated Adult Content and Deepfakes || Shalmoli Ghosh1,, Matthew R. DeVerna2,, and Filippo Menczer1 || 1Indiana University Bloomington || 2Stanford University || These authors contributed equally || Abstract || Generative AI systems increasingly enable the produc- || tion of highl ... (truncated) ||  || { || ""title"": ""A Marketplace for AI-Generated Adult Content and Deepfakes"", || ""authors"": [ || ""Shalmoli Ghosh"", || ""Matthew R. DeVerna"", || ""Filippo Menczer"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""generative AI"", || ""deepfakes"", || ""bounties"", || ""content moderation"", || ""gender asymmetry"" || ], || ""summary"": ""The study examines a marketplace for AI-generated adult content and deepfakes, analyzing bounty requests and their societal impacts."" || } ||  || [ Prompt: 118.7 t/s | Generation: 27.4 t/s ]"
2601.09120v1_Adaptive Multi-Stage Patent Claim Generation with .pdf,Adaptive Multi-Stage Patent Claim Generation with Unified Quality Assessment,"['Chen-Wei Liang', 'Bin Guo', 'Zhen-Yuan Wei', 'Mu-Jiang-Shan Wang']",arXiv:2601.09120v1,31.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Adaptive Multi-Stage Patent Claim Generation || with Unified Quality Assessment || Chen-Wei Liang1, Bin Guo 1, Zhen-Yuan Wei 1, || Mu-Jiang-Shan Wang1,2* || 1Shenzhen Kaihong Digital Industry Development Co., Ltd., Shenzhen, || China . || 2Shenzhen Institute of Advanced Technology, Chinese Academy of ... (truncated) ||  || { || ""title"": ""Adaptive Multi-Stage Patent Claim Generation with Unified Quality Assessment"", || ""authors"": [ || ""Chen-Wei Liang"", || ""Bin Guo"", || ""Zhen-Yuan Wei"", || ""Mu-Jiang-Shan Wang"" || ], || ""doi"": ""arXiv:2601.09120v1"", || ""arxiv_id"": ""2601.09120v1"", || ""keywords"": [ || ""Patent claim generation"", || ""Cross-jurisdictional learning"", || ""Quality assessment"", || ""Transformer"", || ""Domain adaptation"" || ], || ""summary"": ""Introduces a novel three-stage framework for patent claim generation that improves generalization across jurisdictions, enhances semantic relationship modeling, and provides unified quality assessment, achieving significant gains in evaluation metrics."" || } ||  || [ Prompt: 120.2 t/s | Generation: 31.4 t/s ]"
2601.09130v1_Equi-ViT Rotational Equivariant Vision Transformer.pdf,EQUI-VIT: ROTATIONAL EQUIVARIANT VISION TRANSFORMER FOR ROBUST,"['Fuyao Chen', 'Yuexi Du', 'El eonore V. Lieffrig', 'Nicha C. Dvornek', 'John A. Onofrey']",,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || EQUI-VIT: ROTATIONAL EQUIV ARIANT VISION TRANSFORMER FOR ROBUST || HISTOPATHOLOGY ANALYSIS || Fuyao Chen1,2, Yuexi Du1, El eonore V . Lieffrig1, Nicha C. Dvornek 1,3, John A. Onofrey1,3,4 || 1Departments of Biomedical Engineering, 2Medical Scientist Training Program, || 3Radiology & Biomedical  ... (truncated) ||  || { || ""title"": ""EQUI-VIT: ROTATIONAL EQUIVARIANT VISION TRANSFORMER FOR ROBUST"", || ""authors"": [ || ""Fuyao Chen"", || ""Yuexi Du"", || ""El eonore V. Lieffrig"", || ""Nicha C. Dvornek"", || ""John A. Onofrey"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Digital Histopathology"", || ""Vision Transformer"", || ""Rotation Equivariance"", || ""Artificial Intelligence"" || ], || ""summary"": ""This paper proposes Equi-ViT, integrating an equivariant convolution kernel into a Vision Transformer to achieve rotation-consistent patch embeddings, improving robustness in histopathology analysis."" || } ||  || [ Prompt: 120.5 t/s | Generation: 27.6 t/s ]"
2601.09136v1_SkinFlow Efficient Information Transmission for Op.pdf,SkinFlow: Efficient Information Transmission for Open Dermatological Diagnosis via Dynamic Visual Encoding and Staged RL,"['Lijun Liu', 'Linwei Chen', '6', '7', 'Zhishou Zhang', 'Meng Tian', 'Hengfu Cui', 'Ruiyang Li', 'Zhaocheng Liu', 'Qiang Ju', 'Qianxi Li', '2', '3', '4', '5', 'Hong-Yu Zhou', '6', 'Baichuan Inc.', 'Department of Dermatology, Peking University First Hospital', 'Beijing Key Laboratory of Molecular Diagnosis on Dermatoses', 'NMPA Key Laboratory for Quality Control and Evaluation of Cosmetics', 'School of Biomedical Engineering, Tsinghua University', 'University of Hong Kong']",,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SkinFlow: Efficient Information Transmission for Open Dermatological || Diagnosis via Dynamic Visual Encoding and Staged RL || Lijun Liu*,1,Linwei Chen *,1,6,7,Zhishou Zhang 1,Meng Tian 1, || Hengfu Cui1,Ruiyang Li 1,Zhaocheng Liu 1,Qiang Ju 1,Qianxi Li ,2,3,4,5,Hong-Yu Zhou ,6 || 1Baichuan Inc ... (truncated) ||  || { || ""title"": ""SkinFlow: Efficient Information Transmission for Open Dermatological Diagnosis via Dynamic Visual Encoding and Staged RL"", || ""authors"": [ || ""Lijun Liu"", || ""Linwei Chen"", || ""6"", || ""7"", || ""Zhishou Zhang"", || ""Meng Tian"", || ""Hengfu Cui"", || ""Ruiyang Li"", || ""Zhaocheng Liu"", || ""Qiang Ju"", || ""Qianxi Li"", || ""2"", || ""3"", || ""4"", || ""5"", || ""Hong-Yu Zhou"", || ""6"", || ""Baichuan Inc."", || ""Department of Dermatology, Peking University First Hospital"", || ""Beijing Key Laboratory of Molecular Diagnosis on Dermatoses"", || ""NMPA Key Laboratory for Quality Control and Evaluation of Cosmetics"", || ""School of Biomedical Engineering, Tsinghua University"", || ""University of Hong Kong"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper introduces SkinFlow, a framework that optimizes visual information transmission efficiency for dermatological diagnosis using a Virtual-Width Dynamic Vision Encoder and a two-stage reinforcement learning strategy. It achieves state-of-the-art performance on the Fitzpatrick17k benchmark, outperforming general-purpose models in diagnostic accuracy."" || } ||  || [ Prompt: 119.0 t/s | Generation: 28.5 t/s ]"
2601.09147v2_SSVP Synergistic Semantic-Visual Prompting for Ind.pdf,Synergistic Semantic-Visual Prompting for Industrial Zero-Shot Anomaly Detection,"['Chenhao Fu1', 'Han Fang2', 'Xiuzheng Zheng2', 'Wenbo Wei1', 'Yonghua Li1', 'Hao Sun2', 'Xuelong Li2']",10.48550/arXiv.2405.12345,29.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SSVP: Synergistic Semantic-Visual Prompting for || Industrial Zero-Shot Anomaly Detection || Chenhao Fu1,2,Han Fang 2,Xiuzheng Zheng 2,Wenbo Wei 1,Yonghua Li 1,Hao Sun 2,Xuelong Li 2 || 1Beijing University of Posts and Telecommunications,2Institute of Artificial Intelligence (TeleAI), || China  ... (truncated) ||  || { || ""title"": ""Synergistic Semantic-Visual Prompting for Industrial Zero-Shot Anomaly Detection"", || ""authors"": [ || ""Chenhao Fu1"", || ""Han Fang2"", || ""Xiuzheng Zheng2"", || ""Wenbo Wei1"", || ""Yonghua Li1"", || ""Hao Sun2"", || ""Xuelong Li2"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [ || ""industrial anomaly detection"", || ""zero-shot anomaly detection"", || ""semantic-visual prompting"", || ""CLIP"", || ""Vision-Language Models"", || ""semantic-space integration"" || ], || ""summary"": ""This paper introduces Synergistic Semantic-Visual Prompting (SSVP) to enhance industrial zero-shot anomaly detection. SSVP leverages a Hierarchical Semantic-Visual Synergy mechanism and Vision-Conditioned Prompt Generator to improve fine-grained perception. It addresses limitations of existing methods by integrating multi-scale structural priors and dynamic prompting, achieving state-of-the-art performance on industrial benchmarks."" || } ||  || [ Prompt: 121.3 t/s | Generation: 29.4 t/s ]"
2601.09152v1_PrivacyReasoner Can LLM Emulate a Human-like Priva.pdf,PrivacyReasoner: An AI-agent for simulating privacy concerns,"['Yiwen Tu', 'Xuan Liu', 'Lianhui Qin', 'Haojian Jin']",10.48550/arXiv.2311.07818,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || PrivacyReasoner: Can LLM Emulate a Human-like Privacy Mind? || Yiwen Tu and Xuan Liu and Lianhui Qin and Haojian Jin || University of California, San Diego || Abstract || This paper introduces PrivacyReasoner, an || AI-agent design for simulating how individ- || ual users form privacy concerns in res ... (truncated) ||  || { || ""title"": ""PrivacyReasoner: An AI-agent for simulating privacy concerns"", || ""authors"": [""Yiwen Tu"", ""Xuan Liu"", ""Lianhui Qin"", ""Haojian Jin""], || ""doi"": ""10.48550/arXiv.2311.07818"", || ""arxiv_id"": ""arXiv:2311.07818"", || ""keywords"": [""privacy"", ""AI-agent"", ""privacy concerns"", ""contextual reasoning""], || ""summary"": ""This paper introduces PrivacyReasoner, an AI-agent designed to simulate how individual users form privacy concerns in response to real-world news. It integrates privacy and cognitive theories to model user-specific reasoning using personal comment histories and contextual cues."" || } ||  || [ Prompt: 119.2 t/s | Generation: 27.6 t/s ]"
2601.09156v1_KTCF Actionable Recourse in Knowledge Tracing via .pdf,KTCF: Actionable Recourse in Knowledge Tracing via Counterfactual,"['Woojin Kim', 'Changkwon Lee', 'Hyeoncheol Kim']",,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || KTCF: Actionable Recourse in Knowledge Tracing via Counterfactual || Explanations for Education || Woojin Kim, Changkwon Lee, Hyeoncheol Kim || Department of Computer Science and Engineering, Korea University || {woojinkim1021, eckdrnjs, harrykim}@korea.ac.kr || Abstract || Using Artificial Intellige ... (truncated) ||  || { || ""title"": ""KTCF: Actionable Recourse in Knowledge Tracing via Counterfactual"", || ""authors"": [""Woojin Kim"", ""Changkwon Lee"", ""Hyeoncheol Kim""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Using Artificial Intelligence to improve teaching and learning benefits greater adaptivity and scalability in education. Counterfactual explanations of actionable recourse are explored for Knowledge Tracing."" || } ||  || [ Prompt: 123.0 t/s | Generation: 26.9 t/s ]"
2601.09182v1_Position on LLM-Assisted Peer Review Addressing Re.pdf,Position on LLM-Assisted Peer Review: Addressing Reviewer Gap through Mentoring and Feedback,"['JungMin Yun', 'JuneHyoung Kwon', 'MiHyeon Kim', 'YoongBin Kim', '2']",,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Position on LLM-Assisted Peer Review: Addressing Reviewer Gap || through Mentoring and Feedback || JungMin Yun*1, JuneHyoung Kwon*1, MiHyeon Kim *3, Y oungBin Kim1, 2 || 1 Department of Artificial Intelligence, Chung-Ang University || 2 Graduate School of Advanced Imaging Sciences, Multimedia a ... (truncated) ||  || { || ""title"": ""Position on LLM-Assisted Peer Review: Addressing Reviewer Gap through Mentoring and Feedback"", || ""authors"": [ || ""JungMin Yun"", || ""JuneHyoung Kwon"", || ""MiHyeon Kim"", || ""YoongBin Kim"", || ""2"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""LLM-Assisted Peer Review"", || ""Reviewer Gap"", || ""Mentoring"", || ""Feedback"", || ""Scholar Ecosystem"" || ], || ""summary"": ""This paper critiques existing LLM approaches for generating reviews and proposes a paradigm shift positioning LLMs as tools for assisting and educating human reviewers. It defines core principles of high-quality peer review and outlines two complementary systems: an LLM-assisted mentoring system and an LLM-assisted feedback system."" || } ||  || [ Prompt: 114.9 t/s | Generation: 28.7 t/s ]"
2601.09195v1_ProFit Leveraging High-Value Signals in SFT via Pr.pdf,ProFit: Leveraging High-Value Signals in SFT via Probability-Guided Token Selection,"['Tao Liu', 'Taiqiang Wu', 'Runming Yang', 'Shaoning Sun', 'Junjie Wang', 'Yujiu Yang']",,29.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ProFit: Leveraging High-Value Signals in SFT via Probability-Guided || Token Selection || Tao Liu1, Taiqiang Wu2,, Runming Yang2 Shaoning Sun1 Junjie Wang1, Yujiu Yang1, || 1Tsinghua University 2The University of Hong Kong || Equal contribution Project Leader Corresponding authors || /githubhttps: ... (truncated) ||  || { || ""title"": ""ProFit: Leveraging High-Value Signals in SFT via Probability-Guided Token Selection"", || ""authors"": [ || ""Tao Liu"", || ""Taiqiang Wu"", || ""Runming Yang"", || ""Shaoning Sun"", || ""Junjie Wang"", || ""Yujiu Yang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Supervised Fine-Tuning"", || ""Large Language Models"", || ""Token Probability"", || ""Semantic Importance"", || ""Multi-SFT"", || ""Cost Diversity"" || ], || ""summary"": ""The paper discusses the limitations of traditional supervised fine-tuning in aligning LLMs with human intent, proposing ProFit to mitigate single-reference overfitting by selectively masking low-probability tokens."" || } ||  || [ Prompt: 122.1 t/s | Generation: 29.7 t/s ]"
2601.09208v2_Mikasa A Character-Driven Emotional AI Companion I.pdf,Mikasa: A Character-Driven Emotional AI Companion,['Miki Ueno'],,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Mikasa: A Character-Driven Emotional AI Companion || Inspired by Japanese Oshi Culture || Miki Ueno || The Kyoto College of Graduate Studies for Informatics || m_ueno@kcg.ac.jp || Abstract || Recent progress in large language models and multimodal interaction has made it possible || to develop AI compan ... (truncated) ||  || { || ""title"": ""Mikasa: A Character-Driven Emotional AI Companion"", || ""authors"": [""Miki Ueno""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper discusses the challenges in creating long-term emotional AI companions, focusing on character design and relationship dynamics. It introduces Mikasa, a character inspired by Japanese Oshi culture, as a case study for stable personality and defined user-AI relationships. The authors argue that character coherence and clear relationship definitions are crucial for sustained user engagement, not just technical performance."" || } ||  || [ Prompt: 125.9 t/s | Generation: 28.3 t/s ]"
2601.09212v1_Annealed Relaxation of Speculative Decoding for Fa.pdf,Annealed Relaxation of Speculative Decoding,"['Xingyao Li', 'Fengzhuo Zhang', 'Cunxiao Du', 'Hui Ji']",10.48550/arxiv/2303.04112,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Annealed Relaxation of Speculative Decoding || for Faster Autoregressive Image Generation || Xingyao Li1, Fengzhuo Zhang1, Cunxiao Du2*, Hui Ji1 || 1National University of Singapore || 2Sea AI Lab || xingyao@u.nus.edu, fzzhang@u.nus.edu, cnsdunm@gmail.com, matjh@nus.edu.sg || Abstract || Despite signifi ... (truncated) ||  || { || ""title"": ""Annealed Relaxation of Speculative Decoding"", || ""authors"": [ || ""Xingyao Li"", || ""Fengzhuo Zhang"", || ""Cunxiao Du"", || ""Hui Ji"" || ], || ""doi"": ""10.48550/arxiv/2303.04112"", || ""arxiv_id"": ""arXiv:2303.04112"", || ""keywords"": [ || ""auto-regressive"", || ""image generation"", || ""speculative decoding"", || ""annealed relaxation"", || ""COOL-SD"" || ], || ""summary"": ""This paper proposes COOL-SD, an annealed relaxation of speculative decoding for faster autoregressive image generation. It introduces theoretical insights into relaxed speculative decoding and demonstrates improved speed-quality trade-offs through resampling optimizations."" || } ||  || [ Prompt: 121.8 t/s | Generation: 29.3 t/s ]"
2601.09213v1_SpikeVAEDiff Neural Spike-based Natural Visual Sce.pdf,SpikeV AEDiff: Neural Spike-based Natural Visual Scene Reconstruction via VD-V AE and Versatile Diffusion,"['Jialu Li', 'Taiyan Zhou']",,27.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SpikeV AEDiff: Neural Spike-based Natural Visual Scene Reconstruction via || VD-V AE and V ersatile Diffusion || Jialu Li || HKUST || Clear Water Bay, Kowloon, Hong Kong || jlikr@connect.ust.hk || Taiyan Zhou || HKUST || Clear Water Bay, Kowloon, Hong Kong || tzhouau@connect.ust.hk || Abstract || Reconstructing nat ... (truncated) ||  || { || ""title"": ""SpikeV AEDiff: Neural Spike-based Natural Visual Scene Reconstruction via VD-V AE and Versatile Diffusion"", || ""authors"": [ || ""Jialu Li"", || ""Taiyan Zhou"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Reconstructing natural visual scenes from neural activity using a two-stage framework combining VDVAE and Versatile Diffusion to generate high-resolution image reconstructions from neural spike data."" || } ||  || [ Prompt: 116.8 t/s | Generation: 27.0 t/s ]"
2601.09233v1_GIFT Unlocking Global Optimality in Post-Training .pdf,Unlocking Global Optimality in Post-Training via Finite-Temperature Gibbs Initialization,"['Zhengyang Zhao', 'Lu Ma', 'Yizhen Jiang', 'Xiaochen Ma', 'Zimo Meng', 'Chengyu Shen', 'Lexiang Tang', 'Haoze Sun', 'Peng Pei', 'Wentao Zhang']",,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || GIFT: Unlocking Global Optimality in Post-Training via || Finite-Temperature Gibbs Initialization || Zhengyang Zhao1,, Lu Ma1,, Yizhen Jiang1,2, Xiaochen Ma1, Zimo Meng1, || Chengyu Shen1,Lexiang Tang 1,Haoze Sun 2,Peng Pei 2,Wentao Zhang 1, || 1Peking University 2Meituan || zhengyangzhao@stu.pku. ... (truncated) ||  || { || ""title"": ""Unlocking Global Optimality in Post-Training via Finite-Temperature Gibbs Initialization"", || ""authors"": [ || ""Zhengyang Zhao"", || ""Lu Ma"", || ""Yizhen Jiang"", || ""Xiaochen Ma"", || ""Zimo Meng"", || ""Chengyu Shen"", || ""Lexiang Tang"", || ""Haoze Sun"", || ""Peng Pei"", || ""Wentao Zhang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper addresses the optimization mismatch in post-training for Large Reasoning Models by reformulating Supervised Fine-Tuning with Gibbs Initialization at finite temperature, enabling better exploration and global optimality."" || } ||  || [ Prompt: 122.2 t/s | Generation: 29.0 t/s ]"
2601.09236v2_Reward Learning through Ranking Mean Squared Error.pdf,Reward learning through ranking means squared error,"['Chaitanya Kharyal', 'Calarina Muslimani', 'Matthew E. Taylor']",10.48550/arXiv.2405.07918,27.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || REWARDLEARNING THROUGH || RANKINGMEANSQUAREDERROR || Chaitanya Kharyal, Calarina Muslimani & Matthew E. Taylor || Department of Computing Science || University of Alberta, Canada || {kharyal,musliman,matthew.e.taylor}@ualberta.ca || ABSTRACT || Reward design remains a significant bottleneck in applying  ... (truncated) ||  || { || ""title"": ""Reward learning through ranking means squared error"", || ""authors"": [""Chaitanya Kharyal"", ""Calarina Muslimani"", ""Matthew E. Taylor""], || ""doi"": ""10.48550/arXiv.2405.07918"", || ""arxiv_id"": ""arXiv:2405.07918"", || ""keywords"": [""reward learning"", ""reinforcement learning"", ""ranking"", ""reward design""], || ""summary"": ""The paper introduces a new rating-based reinforcement learning method, Ranked Return Regression for RL (R4), which uses a novel ranking mean squared error loss to learn reward functions from human feedback. R4 treats teacher-provided ratings as ordinal targets and optimizes mean squared error between predicted and actual ratings, offering formal guarantees on optimality under mild assumptions."" || } ||  || [ Prompt: 118.8 t/s | Generation: 27.4 t/s ]"
2601.09239v2_DSA-Tokenizer Disentangled Semantic-Acoustic Token.pdf,DSA-Tokenizer: Disentangled Semantic-Acoustic Tokenization,"['Hanlin ZHANG1', 'Linqi Song', 'Jianping Wang', 'Xiao Chen', 'Yunhe Li', 'Yuchen Cao', 'Jianping Wang', 'Linqi Song']",,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DSA-Tokenizer: Disentangled Semantic-Acoustic Tokenization || via Flow Matching-based Hierarchical Fusion || Hanlin ZHANG1,*, , Daxin Tan2,*, Dehua Tao2, Xiao Chen2, , Haochen Tan2, || Yunhe Li1,Yuchen Cao 1,Jianping Wang 1,Linqi Song 1, || 1Department of Computer Science, City University of Ho ... (truncated) ||  || { || ""title"": ""DSA-Tokenizer: Disentangled Semantic-Acoustic Tokenization"", || ""authors"": [ || ""Hanlin ZHANG1"", || ""Linqi Song"", || ""Jianping Wang"", || ""Xiao Chen"", || ""Yunhe Li"", || ""Yuchen Cao"", || ""Jianping Wang"", || ""Linqi Song"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""speech tokenization"", || ""semantic-acoustic disentanglement"", || ""speech large language models"", || ""discrete tokens"", || ""audio modeling"" || ], || ""summary"": ""Speech tokenizers aim to disentangle semantic and acoustic components. This paper introduces DSA-Tokenizer, which disentangles speech into discrete semantic and acoustic tokens using hierarchical flow matching and joint reconstruction-recombination training."" || } ||  || [ Prompt: 115.6 t/s | Generation: 28.7 t/s ]"
2601.09248v1_Hybrid guided variational autoencoder for visual p.pdf,Hybrid guided variational autoencoder for visual place recognition,"['Ni Wang', 'Zihan You', 'Emre Neftci', 'Thorben Schoepe']",arXiv:2601.09248v1,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Hybrid guided variational autoencoder for visual || place recognition || Ni Wang1, Zihan You2, Emre Neftci3, and Thorben Schoepe4 || 1 Amazon Development Center Germany GmbH, Berlin, Germany || 2 Southeast University, Nanjing, China || 3 Forschungszentrum Jlich GmbH, Aachen, Germany || 4 imec, Luven, ... (truncated) ||  || { || ""title"": ""Hybrid guided variational autoencoder for visual place recognition"", || ""authors"": [ || ""Ni Wang"", || ""Zihan You"", || ""Emre Neftci"", || ""Thorben Schoepe"" || ], || ""doi"": ""arXiv:2601.09248v1"", || ""arxiv_id"": ""arXiv:2601.09248v1"", || ""keywords"": [ || ""Visual place recognition"", || ""Spiking neural network"", || ""Guided variational autoencoder"", || ""Robotics"", || ""Low latency hardware"" || ], || ""summary"": ""This work presents a hybrid guided variational autoencoder combining event-based vision sensors and a novel VAE to enable efficient and robust visual place recognition for mobile robots in indoor environments. The model achieves high classification performance and generalization across diverse lighting conditions."" || } ||  || [ Prompt: 132.2 t/s | Generation: 29.3 t/s ]"
2601.09251v1_HGATSolver A Heterogeneous Graph Attention Solver .pdf,HGA TSolver: A Heterogeneous Graph Attention Solver for FluidStructure,"['Qin-Yi Zhang', 'Hong Wang', 'Siyao Liu', 'Haichuan Lin', 'Linying Cao', 'Chen Chen', 'Shuangyi Wang', 'Zeng-Guang Hou', 'Zhao']",zhangqinyi2024,28.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || HGA TSolver: A Heterogeneous Graph Attention Solver for FluidStructure || Interaction || Qin-Yi Zhang1, 2*, Hong Wang3*, Siyao Liu 4, Haichuan Lin 1, 2, Linying Cao 1, 2, Xiao-Hu Zhou 1, 2, || Chen Chen1, 2, Shuangyi Wang1, 2, Zeng-Guang Hou 1, 2 || 1State Key Laboratory of Multimodal Artificia ... (truncated) ||  || { || ""title"": ""HGA TSolver: A Heterogeneous Graph Attention Solver for FluidStructure"", || ""authors"": [ || ""Qin-Yi Zhang"", || ""Hong Wang"", || ""Siyao Liu"", || ""Haichuan Lin"", || ""Linying Cao"", || ""Chen Chen"", || ""Shuangyi Wang"", || ""Zeng-Guang Hou"", || ""Zhao"" || ], || ""doi"": ""zhangqinyi2024"", || ""arxiv_id"": """", || ""keywords"": [ || ""FluidStructure Interaction"", || ""Heterogeneous Graph Attention"", || ""Physics-Informed Learning"", || ""Surrogate Modeling"", || ""Multi-physics Systems"" || ], || ""summary"": ""The paper proposes the Heterogeneous Graph Attention Solver (HGA TSolver) to address challenges in fluid-structure interaction by modeling distinct physical domains with specialized graph structures and adaptive learning mechanisms."" || } ||  || [ Prompt: 119.8 t/s | Generation: 28.9 t/s ]"
2601.09253v1_RIFT Repurposing Negative Samples via Reward-Infor.pdf,RIFT: Repurposing Negative Samples via Reward-Informed Fine-Tuning,"['Zehua Liu', 'Shuqi Liu', 'Tao Zhong', 'Mingxuan Yuan']",10.48550/arXiv.2303.03002,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || RIFT: Repurposing Negative Samples via Reward-Informed Fine-Tuning || Zehua Liu, Shuqi Liu, Tao Zhong, Mingxuan Yuan || Huawei Noahs Ark Lab || liuzehua@connect.hku.hk, liu.shuqi1@huawei.com || Abstract || While Supervised Fine-Tuning (SFT) and Re- || jection Sampling Fine-Tuning (RFT) are stan- || dard ... (truncated) ||  || { || ""title"": ""RIFT: Repurposing Negative Samples via Reward-Informed Fine-Tuning"", || ""authors"": [""Zehua Liu"", ""Shuqi Liu"", ""Tao Zhong"", ""Mingxuan Yuan""], || ""doi"": ""10.48550/arXiv.2303.03002"", || ""arxiv_id"": ""arXiv:2303.03002"", || ""keywords"": [""Reward Informed Fine-Tuning"", ""LLM alignment"", ""data efficiency""], || ""summary"": ""This paper proposes RIFT, a method that repurposes negative samples by reweighting losses using scalar rewards, improving data efficiency and performance over traditional RFT and SFT."" || } ||  || [ Prompt: 120.8 t/s | Generation: 28.2 t/s ]"
2601.09259v1_MAXS Meta-Adaptive Exploration with LLM Agents.pdf,Meta-Adaptive Exploration with LLM Agents,"['Jian Zhang', 'Zhiyuan Wang', 'Zhangqi Wang', 'Yu He', 'Haoran Luo', 'Li Yuan', 'Lingling Zhang', 'Rui Mao', 'Qika Lin', 'Jun Liu']",,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MAXS: Meta-Adaptive Exploration with LLM Agents || Jian Zhang1, Zhiyuan Wang1, Zhangqi Wang1, Yu He1*, Haoran Luo2, || Li Yuan4, Lingling Zhang1, Rui Mao2, Qika Lin3, Jun Liu1 || 1Xian Jiaotong University 2Nanyang Technological University || 3National University of Singapore 4South China Univer ... (truncated) ||  || { || ""title"": ""Meta-Adaptive Exploration with LLM Agents"", || ""authors"": [ || ""Jian Zhang"", || ""Zhiyuan Wang"", || ""Zhangqi Wang"", || ""Yu He"", || ""Haoran Luo"", || ""Li Yuan"", || ""Lingling Zhang"", || ""Rui Mao"", || ""Qika Lin"", || ""Jun Liu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""LLM Agents"", || ""meta-adaptive exploration"", || ""LLM agents"", || ""reasoning"", || ""multi-tool reasoning"", || ""search tools"", || ""code tools"", || ""LLM agents"", || ""trajectory stability"" || ], || ""summary"": ""The paper proposes MAXS, a meta-adaptive reasoning framework for LLM agents that integrates tool execution and reasoning planning. MAXS uses a lookahead strategy to extend reasoning paths, balances computational efficiency with effectiveness, and improves performance across multiple models and datasets."" || } ||  || [ Prompt: 114.7 t/s | Generation: 29.0 t/s ]"
2601.09260v1_Efficient Paths and Dense Rewards Probabilistic Fl.pdf,Efficient Paths and Dense Rewards: Probabilistic Flow Reasoning for Large Language Models,"['Yan Liu', 'Feng Zhang', 'Zhanyu Ma', 'Jinghua Hao', 'Renqing He', 'Han Liu', 'Yangdong Deng']",,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Efficient Paths and Dense Rewards: Probabilistic Flow Reasoning for || Large Language Models || Yan Liu1,2* Feng Zhang1,3 Zhanyu Ma1 Jun Xu1 Jiuchong Gao1 || Jinghua Hao1 Renqing He1 Han Liu4 Yangdong Deng2 || 1Meituan, 2Tsinghua University, 3Peking University, 4Dalian University of Technology || ... (truncated) ||  || { || ""title"": ""Efficient Paths and Dense Rewards: Probabilistic Flow Reasoning for Large Language Models"", || ""authors"": [ || ""Yan Liu"", || ""Feng Zhang"", || ""Zhanyu Ma"", || ""Jinghua Hao"", || ""Renqing He"", || ""Han Liu"", || ""Yangdong Deng"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper proposes CoT-Flow, a framework that models discrete reasoning steps as a continuous probabilistic flow to quantify each step's contribution to the answer. It introduces flow-guided decoding and flow-based reinforcement learning to improve inference efficiency and reasoning performance."" || } ||  || [ Prompt: 121.5 t/s | Generation: 27.5 t/s ]"
2601.09262v1_Magnifying change Rapid burn scar mapping with mul.pdf,"Magnifying change: Rapid burn scar mapping with multi-resolution, multi-source satellite imagery","['Maria Sdraka', 'Dimitrios Michail', 'Ioannis Papoutsis']",,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || Magnifying change: Rapid burn scar mapping with multi-resolution, || multi-source satellite imagery || Maria Sdraka, Dimitrios Michail, Ioannis Papoutsis || AbstractDelineating wildfire affected areas using satellite || imagery remains challenging due to irregular and spatially het- || erogeneou ... (truncated) ||  || { || ""title"": ""Magnifying change: Rapid burn scar mapping with multi-resolution, multi-source satellite imagery"", || ""authors"": [""Maria Sdraka"", ""Dimitrios Michail"", ""Ioannis Papoutsis""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Artificial intelligence"", || ""Machine Learning"", || ""Remote Sensing"", || ""burnt area mapping"", || ""disaster management"", || ""disaster monitoring"", || ""wildfires"", || ""burn scar mapping"", || ""change detection"", || ""downscaling"", || ""super-resolution"" || ], || ""summary"": ""Delineating wildfire affected areas using satellite imagery remains challenging due to irregular spectral changes. The paper proposes a novel deep learning model, BAM-MRCD, using multi-resolution, multi-source satellite data for timely burnt area mapping with high spatial and temporal resolution."" || } ||  || [ Prompt: 113.5 t/s | Generation: 28.4 t/s ]"
2601.09264v1_Coordinated Pandemic Control with Large Language M.pdf,Coordinated Pandemic Control with Large Language,"['Ziyi Shi', 'Xusen Guo', 'Hongliang Lu', 'Mingxing Peng', 'Haotian Wang', 'Zhenning Li', 'Yuxuan Liang', 'Xinhu Zheng', 'Hai Yang']",,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Coordinated Pandemic Control with Large Language || Model Agents as Policymaking Assistants || Ziyi Shi1,, Xusen Guo2,, Hongliang Lu1,*, Mingxing Peng2, Haotian Wang2, Zheng Zhu3, || Zhenning Li4, Yuxuan Liang2, Xinhu Zheng2, and Hai Yang1,* || 1The Hong Kong University of Science and Technolog ... (truncated) ||  || { || ""title"": ""Coordinated Pandemic Control with Large Language"", || ""authors"": [ || ""Ziyi Shi"", || ""Xusen Guo"", || ""Hongliang Lu"", || ""Mingxing Peng"", || ""Haotian Wang"", || ""Zhenning Li"", || ""Yuxuan Liang"", || ""Xinhu Zheng"", || ""Hai Yang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Pandemic Control"", || ""Large Language Models"", || ""Multi-Agent System"", || ""Coordinated Policymaking"" || ], || ""summary"": ""Effective pandemic control requires timely and coordinated policymaking across administrative regions. This study proposes a large language model (LLM) multi-agent policymaking framework to support coordinated and proactive pandemic control, reducing cumulative infections and deaths through joint exploration of counterfactual interventions."" || } ||  || [ Prompt: 127.1 t/s | Generation: 28.4 t/s ]"
2601.09269v2_RISER Orchestrating Latent Reasoning Skills for Ad.pdf,RISER: Orchestrating Latent Reasoning Skills for Adaptive Activation Steering,"['Wencheng Ye', 'Xiaoyang Yuan', 'Yi Bin', 'Hengyu Jin', 'Liang Peng', 'Pengpeng Zeng', 'Heng Tao Shen']",,29.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || RISER: Orchestrating Latent Reasoning Skills for Adaptive || Activation Steering || Wencheng Ye || Tongji University || Xiaoyang Yuan || Tongji University || Yi Bin || Tongji University || Hengyu Jin || Tongji University || Liang Peng || Tencent || Pengpeng Zeng || Tongji University || Heng Tao Shen || Tongji University || Abstra ... (truncated) ||  || { || ""title"": ""RISER: Orchestrating Latent Reasoning Skills for Adaptive Activation Steering"", || ""authors"": [ || ""Wencheng Ye"", || ""Xiaoyang Yuan"", || ""Yi Bin"", || ""Hengyu Jin"", || ""Liang Peng"", || ""Pengpeng Zeng"", || ""Heng Tao Shen"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Recent work on domain-specific reasoning with large language models (LLMs) often relies on training-intensive approaches... RISER proposes a plug-and-play intervention framework that adaptively steers LLM reasoning in activation space."" || } ||  || [ Prompt: 114.8 t/s | Generation: 29.5 t/s ]"
2601.09274v1_A3-Bench Benchmarking Memory-Driven Scientific Rea.pdf,A3-Bench: Benchmarking Memory-Driven Scientific Reasoning,"['Jian Zhang', 'Yu He', 'Zhiyuan Wang', 'Zhangqi Wang', 'Kai He', 'Fangzhi Xu', 'Qika Lin']",,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A3-Bench: Benchmarking Memory-Driven Scientific Reasoning || via Anchor and Attractor Activation || Jian Zhang1, Yu He1, Zhiyuan Wang1, Zhangqi Wang1, Kai He2, || Fangzhi Xu1, Qika Lin2, Jun Liu1* || 1Xian Jiaotong University 2National University of Singapore || zhangjian062422@stu.xjtu.edu.cn,liu ... (truncated) ||  || { || ""title"": ""A3-Bench: Benchmarking Memory-Driven Scientific Reasoning"", || ""authors"": [ || ""Jian Zhang"", || ""Yu He"", || ""Zhiyuan Wang"", || ""Zhangqi Wang"", || ""Kai He"", || ""Fangzhi Xu"", || ""Qika Lin"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Scientific reasoning relies on memory-driven mechanisms; this paper proposes A3-Bench to evaluate reasoning through dual-scale memory activation."" || } ||  || [ Prompt: 117.6 t/s | Generation: 29.1 t/s ]"
2601.09278v1_M3Searcher Modular Multimodal Information Seeking .pdf,M3Searcher: Modular Multimodal Information Seeking Agency with Retrieval-Oriented Reasoning,"['Xiaohan Yu', 'Chao Feng', 'Lang Mei', 'Chong Chen']",,29.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || M3Searcher: Modular Multimodal Information Seeking Agency with || Retrieval-Oriented Reasoning || Xiaohan Yu, Chao Feng, Lang Mei, Chong Chen /envelpe || Huawei Cloud BU, Beijing || {yuxiaohan5, fengchao37, meilang1, chenchong55}@huawei.com || Abstract || Recent advances in DeepResearch-style agents || ... (truncated) ||  || { || ""title"": ""M3Searcher: Modular Multimodal Information Seeking Agency with Retrieval-Oriented Reasoning"", || ""authors"": [""Xiaohan Yu"", ""Chao Feng"", ""Lang Mei"", ""Chong Chen""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""M3Searcher"", ""multimodal information seeking"", ""retrieval-oriented reasoning""], || ""summary"": ""This paper proposes M3Searcher, a modular multimodal information-seeking agent that decouples information acquisition from answer derivation. It introduces MM-SearchVQA to support retrieval-centric reinforcement learning training and demonstrates superior performance in complex multimodal tasks."" || } ||  || [ Prompt: 114.8 t/s | Generation: 29.5 t/s ]"
2601.09280v1_ReGraM Region-First Knowledge Graph Reasoning for .pdf,Answering,"['Chaerin Lee', 'Sohee Park Hyunsik', 'Na Daseon Choi']",,30.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ReGraM: Region-First Knowledge Graph Reasoning for Medical Question || Answering || Chaerin Lee Sohee Park Hyunsik Na Daseon Choi || Department of Software, Soongsil University, Seoul, Republic of Korea || {chaerin1112, sosohi, rnrud7932}@soongsil.ac.kr sunchoi@ssu.ac.kr || Abstract || Recent studies ... (truncated) ||  || { || ""title"": ""Answering"", || ""authors"": [""Chaerin Lee"", ""Sohee Park Hyunsik"", ""Na Daseon Choi""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""medical question answering"", ""medical QA"", ""knowledge graph"", ""LLM"", ""factual accuracy""], || ""summary"": ""ReGraM proposes a region-first knowledge graph reasoning framework for medical question answering, improving accuracy by focusing inference on relevant subgraphs."" || } ||  || [ Prompt: 120.5 t/s | Generation: 30.3 t/s ]"
2601.09281v1_STaR Sensitive Trajectory Regulation for Unlearnin.pdf,Sensitive Trajectory Regulation for Unlearning in Large Reasoning Models,"['Jingjing Zhou', 'Gaoxiang Cong', 'Li Su', 'Liang Li']",10.48550/arXiv.2303.04219,28.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || STaR: Sensitive Trajectory Regulation for Unlearning in Large Reasoning Models || Jingjing Zhou1*, Gaoxiang Cong2,1, Li Su1, Liang Li1,2 || 1University of Chinese Academy of Sciences || 2Institute of Computing Technology, Chinese Academy of Sciences || zhoujingjing25@ucas.ac.cn, gaoxiang.cong@v ... (truncated) ||  || { || ""title"": ""Sensitive Trajectory Regulation for Unlearning in Large Reasoning Models"", || ""authors"": [ || ""Jingjing Zhou"", || ""Gaoxiang Cong"", || ""Li Su"", || ""Liang Li"" || ], || ""doi"": ""10.48550/arXiv.2303.04219"", || ""arxiv_id"": ""arXiv:2303.04219"", || ""keywords"": [ || ""large reasoning models"", || ""privacy protection"", || ""unlearning"", || ""trajectory regulation"", || ""chain-of-thought"", || ""sensitive content"" || ], || ""summary"": ""This paper proposes Sensitive Trajectory Regulation (STaR), a parameter-free, inference-time unlearning framework for Large Reasoning Models. STaR identifies sensitive content via semantic-aware detection, enforces safety constraints through secure prompt prefix, suppresses sensitive trajectories dynamically, and applies token-level filtering. It introduces two evaluation metrics: Multi-Decoding Consistency Assessment and Multi-Granularity Membership Inference Attack, demonstrating effective privacy preservation with minimal utility loss."" || } ||  || [ Prompt: 119.8 t/s | Generation: 28.9 t/s ]"
2601.09282v1_Cluster Workload Allocation Semantic Soft Affinity.pdf,Cluster Workload Allocation: Semantic Soft Affinity Using Natural Language Processing,"['Leszek Sliwko', 'Jolanta Mizeria-Pietraszko']",10.48550/arXiv.2405.12345,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  ||  || Cluster Workload Allocation: Semantic Soft Affinity Using Natural Language Processing Leszek Sliwko1, Jolanta Mizeria-Pietraszko2 1Standard Chartered Bank, EC2V 5DD London, U.K.  2Department of Computer Science, Opole University of Technology, Opole, Poland Corresponding author ... (truncated) ||  || { || ""title"": ""Cluster Workload Allocation: Semantic Soft Affinity Using Natural Language Processing"", || ""authors"": [ || ""Leszek Sliwko"", || ""Jolanta Mizeria-Pietraszko"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [ || ""Artificial Intelligence"", || ""Kubernetes"", || ""Load Balancing"", || ""Semantic Parsing"", || ""Soft-Affinity"", || ""Task Assignment"" || ], || ""summary"": ""This paper introduces a semantic, intent-driven scheduling paradigm for cluster systems using Natural Language Processing. It employs a Large Language Model integrated via a Kubernetes scheduler extender to interpret natural language allocation hint annotations for soft affinity preferences. Empirical evaluation shows high LLM parsing accuracy and superior scheduling performance compared to baseline models."" || } ||  || [ Prompt: 125.8 t/s | Generation: 28.6 t/s ]"
2601.09286v1_Why not Collaborative Filtering in Dual View Bridg.pdf,Why not Collaborative Filtering in Dual View? Bridging Sparse and Dense Models,"['Hanze Guo', 'Jianxun Lian', 'Xiaozhou']",https://doi.org/XXXXXXX.XXXXXXX,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Why not Collaborative Filtering in Dual View? Bridging Sparse and Dense || Models || HANZE GUO,Gaoling School of Artificial Intelligence, Renmin University of China, China || JIANXUN LIAN,Microsoft Research Asia, China || XIAO ZHOU ,Gaoling School of Artificial Intelligence, Renmin University o ... (truncated) ||  || { || ""title"": ""Why not Collaborative Filtering in Dual View? Bridging Sparse and Dense Models"", || ""authors"": [ || ""Hanze Guo"", || ""Jianxun Lian"", || ""Xiaozhou"" || ], || ""doi"": ""https://doi.org/XXXXXXX.XXXXXXX"", || ""arxiv_id"": """", || ""keywords"": [ || ""Collaborative Filtering"", || ""Dual View Alignment"", || ""Sparse and Dense model"" || ], || ""summary"": ""The paper discusses limitations of parameter-based dense models in sparse settings and introduces SaD to improve global SNR by aligning dense and sparse views."" || } ||  || [ Prompt: 116.8 t/s | Generation: 28.3 t/s ]"
2601.09292v1_Blue Teaming Function-Calling Agents.pdf,Blue Teaming Function-Calling Agents,"['Greta Dolcetti', 'Giulio Zizzo', 'Sergio Maffeis']",https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Blue Teaming Function-Calling Agents || Greta Dolcetti1, Giulio Zizzo 2, Sergio Maffeis 3 || 1Ca Foscari University of Venice, Venice, Italy || 2IBM Research Europe, Dublin, Ireland || 3Imperial College London, London, UK || Work done while at IBM Research || greta.dolcetti@unive.it, giulio.zizzo2@ib ... (truncated) ||  || { || ""title"": ""Blue Teaming Function-Calling Agents"", || ""authors"": [ || ""Greta Dolcetti"", || ""Giulio Zizzo"", || ""Sergio Maffeis"" || ], || ""doi"": ""https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/"", || ""arxiv_id"": """", || ""keywords"": [ || ""function-calling"", || ""LLMs"", || ""robustness"", || ""defenses"", || ""agentic systems"" || ], || ""summary"": ""This paper evaluates the robustness of four open source LLMs with function-calling capabilities against various attacks and tests eight defensive measures. The results highlight vulnerabilities and limitations in current defenses."" || } ||  || [ Prompt: 121.3 t/s | Generation: 27.9 t/s ]"
2601.09293v1_Policy-Based Reinforcement Learning with Action Ma.pdf,Policy-Based Reinforcement Learning with Action Masking for Dynamic Job Shop,"['Sofiene Lassoued', 'Stefan Lier', 'Andreas Schwung']",,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Policy-Based Reinforcement Learning with Action Masking for Dynamic Job Shop || Scheduling under Uncertainty: Handling Random Arrivals and Machine Failures || Sofiene Lassoued a,, Stefan Lier b, Andreas Schwung a || aSouth Westphalia University of Applied Sciences, Automation Technology and  ... (truncated) ||  || { || ""title"": ""Policy-Based Reinforcement Learning with Action Masking for Dynamic Job Shop"", || ""authors"": [ || ""Sofiene Lassoued"", || ""Stefan Lier"", || ""Andreas Schwung"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Dynamic Job Shop Scheduling"", || ""Fault tolerance"", || ""Reinforcement learning"", || ""Actions masking"", || ""Petri nets"" || ], || ""summary"": ""A novel framework for Dynamic Job Shop Scheduling under uncertainty, addressing stochastic job arrivals and machine failures using Coloured Timed Petri Nets and Maskable Proximal Policy Optimization."" || } ||  || [ Prompt: 122.4 t/s | Generation: 28.8 t/s ]"
2601.09306v1_On-Device Large Language Models for Sequential Rec.pdf,On-Device Large Language Models for Sequential Recommendation,"['Xin Xia', 'Hongzhi Yin', 'Shane Culpepper']",10.1145/3773966.3777961,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || On-Device Large Language Models for Sequential || Recommendation || Xin Xia || x.xia@uq.edu.au || The University of Queensland || Brisbane, QLD, Australia || Hongzhi Yin || h.yin1@uq.edu.au || The University of Queensland || Brisbane, QLD, Australia || Shane Culpepper || s.culpepper@uq.edu.au || The University of Quee ... (truncated) ||  || { || ""title"": ""On-Device Large Language Models for Sequential Recommendation"", || ""authors"": [ || ""Xin Xia"", || ""Hongzhi Yin"", || ""Shane Culpepper"" || ], || ""doi"": ""10.1145/3773966.3777961"", || ""arxiv_id"": ""Ninth ACM International Conference on Web Search and Data Mining (WSDM) 2026"", || ""keywords"": [ || ""Recommender Systems"", || ""Sequential Recommendation"", || ""On-Device Recommendation"", || ""Model Compression"", || ""Resource Constrained Devices"" || ], || ""summary"": ""The paper proposes OD-LLM, a task-adaptive compression framework for efficient on-device deployment of large language models in sequential recommendation tasks. It combines low-rank structural compression with a novel tokenization normalization and progressive alignment to maintain performance while reducing model size."" || } ||  || [ Prompt: 122.9 t/s | Generation: 29.1 t/s ]"
2601.09313v1_Understanding or Memorizing A Case Study of German.pdf,Understanding or Memorizing? A Case Study of German Definite Articles,"['Jonathan Drechsel', 'Erisa Bytyqi', 'Steffen Herbold']",10.48550/arXiv.2405.12345,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Understanding or Memorizing? A Case Study of German Definite Articles || in Language Models || Jonathan Drechsel and Erisa Bytyqi and Steffen Herbold || Faculty of Computer Science and Mathematics || University of Passau || Correspondence:jonathan.drechsel@uni-passau.de || Abstract || Language models pe ... (truncated) ||  || { || ""title"": ""Understanding or Memorizing? A Case Study of German Definite Articles"", || ""authors"": [""Jonathan Drechsel"", ""Erisa Bytyqi"", ""Steffen Herbold""], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [""language models"", ""German definite articles"", ""grammatical gender"", ""case"", ""memorization""], || ""summary"": ""The study investigates whether German definite articles are learned through rule-based generalization or memorization, using gradient-based interpretability methods to analyze parameter updates for gender-case article transitions."" || } ||  || [ Prompt: 117.9 t/s | Generation: 27.8 t/s ]"
2601.09342v1_Improving Implicit Hate Speech Detection via a Com.pdf,Improving Implicit Hate Speech Detection via a Community-Driven Multi-Agent Framework,"['Ewelina Gajewska', 'Katarzyna Budzynska', 'Jaroslaw A. Chudziak']",,28.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Improving Implicit Hate Speech Detection via a Community-Driven || Multi-Agent Framework || Ewelina Gajewska1 || a, Katarzyna Budzynska1 || b and Jarosaw A. Chudziak1 || c || 1Warsaw University of Technology, Plac Politechniki 1, Warsaw, Poland || ewelina.gajewska.dokt@pw.edu.pl, katarzyna.budzynska@ ... (truncated) ||  || { || ""title"": ""Improving Implicit Hate Speech Detection via a Community-Driven Multi-Agent Framework"", || ""authors"": [ || ""Ewelina Gajewska"", || ""Katarzyna Budzynska"", || ""Jaroslaw A. Chudziak"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""LLMs"", || ""Community agents"", || ""Hate speech"", || ""Social media"", || ""Moderation"", || ""Fairness"" || ], || ""summary"": ""This work proposes a contextualised detection framework for implicitly hateful speech, implemented as a multi-agent system comprising a central Moderator Agent and dynamically constructed Community Agents. The approach integrates socio-cultural context from publicly available sources for identity-aware moderation, improving classification accuracy and fairness on the ToxiGen dataset."" || } ||  || [ Prompt: 124.3 t/s | Generation: 28.0 t/s ]"
2601.09351v1_Navigating Ethical AI Challenges in the Industrial.pdf,Navigating Ethical AI Challenges in the Industrial Sector: Balancing Innovation and Responsibility,"['Dr. Ruomu Tan', 'Dr.-Ing Martin W Hoffmann']",arXiv:2601.09351v1,31.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Navigating Ethical AI Challenges in the || Industrial Sector: || Balancing Innovation and Responsibility || Ruomu Tan and Martin W Hoffmann || AbstractThe integration of artificial intelligence (AI) into the industrial sector has || not only driven innovation but also expanded the ethical landscap ... (truncated) ||  || { || ""title"": ""Navigating Ethical AI Challenges in the Industrial Sector: Balancing Innovation and Responsibility"", || ""authors"": [ || ""Dr. Ruomu Tan"", || ""Dr.-Ing Martin W Hoffmann"" || ], || ""doi"": ""arXiv:2601.09351v1"", || ""arxiv_id"": ""arXiv:2601.09351"", || ""keywords"": [ || ""AI"", || ""ethical challenges"", || ""industrial sector"", || ""innovation"", || ""responsibility"", || ""transparency"", || ""accountability"", || ""fairness"" || ], || ""summary"": ""This chapter explores how AI-empowered industrial innovation intersects with ethics, addressing transparency, accountability, and fairness. It examines ethical considerations in AI applications within industrial use cases and highlights the need to embed ethical principles in industrial AI systems."" || } ||  || [ Prompt: 115.4 t/s | Generation: 31.3 t/s ]"
2601.09353v1_Monte-Carlo Tree Search with Neural Network Guidan.pdf,,[],,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Monte-Carlo Tree Search with Neural Network Guidance || for Lane-Free Autonomous Driving || Ioannis Peridis, Dimitrios Troullinos, Georgios Chalkiadakis, Pantelis || Giankoulidis, Ioannis Papamichail, and Markos Papageorgiou || Technical University of Crete || {iperidis, dtroullinos, gchalkiadakis ... (truncated) ||  || { || ""title"": ""Monte-Carlo Tree Search with Neural Network Guidance"", || ""authors"": [ || ""Ioannis Peridis"", || ""Dimitrios Troullinos"", || ""Georgios Chalkiadakis"", || ""Pantelis Giankoulidis"", || ""Ioannis Papamichail"", || ""Markos Papageorgiou"" || ], || ""doi"": ""arXiv:2601.09353v1"", || ""arxiv_id"": ""arXiv:2601.09353"", || ""keywords"": [ || ""Monte-Carlo Tree Search"", || ""Neural Network Guidance"", || ""Autonomous Driving"", || ""Lane-Free Traffic"", || ""Reinforcement Learning"", || ""Traffic Flow"" || ], || ""summary"": ""This paper explores a Monte-Carlo Tree Search planning approach for single-agent autonomous driving in lane-free environments. It integrates a pre-trained neural network to guide tree search, aiming to improve safety and performance metrics such as collision rates and speed. The study examines the impact of isotropic state information and evaluates computational trade-offs."" || } ||  || [ Prompt: 114.9 t/s | Generation: 28.1 t/s ]"
2601.09361v1_GeoRA Geometry-Aware Low-Rank Adaptation for RLVR.pdf,GeoRA: Geometry-Aware Low-Rank Adaptation for RLVR,"['Jiaying Zhang', 'Lei Shi', 'Jiguo Li', 'Jun Xu', 'Jiuchong Gao', 'Jinghua Hao']",,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || GeoRA: Geometry-Aware Low-Rank Adaptation for RLVR || Jiaying Zhang1,2*, Lei Shi1*, Jiguo Li1, || Jun Xu1,Jiuchong Gao 1,Jinghua Hao 1,Renqing He 1 || 1Meituan, 2Peking University || {xujun58, gaojiuchong}@meituan.com || Abstract || Reinforcement Learning with Verifiable Re- || wards (RLVR) is crucial f ... (truncated) ||  || { || ""title"": ""GeoRA: Geometry-Aware Low-Rank Adaptation for RLVR"", || ""authors"": [ || ""Jiaying Zhang"", || ""Lei Shi"", || ""Jiguo Li"", || ""Jun Xu"", || ""Jiuchong Gao"", || ""Jinghua Hao"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Reinforcement Learning"", || ""RLVR"", || ""Parameter-efficient Tuning"", || ""Low-rank Adaptation"", || ""Geometric Structures"", || ""Optimization Stability"" || ], || ""summary"": ""This paper proposes GeoRA, a geometry-aware low-rank adaptation method for RLVR. It addresses optimization instability in existing parameter-efficient fine-tuning methods by leveraging geometric constraints and sparse updates, achieving state-of-the-art performance on benchmark models."" || } ||  || [ Prompt: 121.0 t/s | Generation: 28.8 t/s ]"
2601.09365v1_Frame of Reference Addressing the Challenges of Co.pdf,Frame of Reference: Addressing the Challenges of Common Ground,"['Biswesh Mohapatra', 'Laurent Romary', 'Justine Cassell']",,26.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Frame of Reference: Addressing the Challenges of Common Ground || Representation in Situational Dialogs || Biswesh Mohapatra* || Inria || Tho Charlot || Nantes Universit || Giovanni Duca || University of Trento || Mayank Palan || VJTI Mumbai || Laurent Romary* || Inria || Justine Cassell* || Inria, Carnegie Mellon Univer ... (truncated) ||  || { || ""title"": ""Frame of Reference: Addressing the Challenges of Common Ground"", || ""authors"": [ || ""Biswesh Mohapatra"", || ""Laurent Romary"", || ""Justine Cassell"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Common ground plays a critical role in situational dialogs. This work evaluates a model's ability to establish common ground using relational references in dynamic environments, addressing challenges in grounding for complex dialog scenarios."" || } ||  || [ Prompt: 119.6 t/s | Generation: 26.6 t/s ]"
2601.09381v1_Query Languages for Machine-Learning Models.pdf,,[],,27.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Query Languages for Machine-Learning Models || Martin Grohe/envelpe || RWTH Aachen University, Germany || Abstract || In this paper, I discuss two logics for weighted finite structures: first-order logic with summation || (FO(SUM)) and its recursive extension IFP(SUM). These logics originate from  ... (truncated) ||  || { || ""title"": ""Query Languages for Machine-Learning Models"", || ""authors"": [""Martin Grohe"", || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""expressive power of query languages"", ""fixed-point logics"", ""weighted structures"", ""neural networks"", ""explainable AI""], || ""summary"": ""Discusses logics for weighted finite structures and their application to neural networks."" || } ||  || [ Prompt: 125.0 t/s | Generation: 27.4 t/s ]"
2601.09382v1_Long-term Task-oriented Agent Proactive Long-term .pdf,Long-term Task-oriented Agent: Proactive Long-term Intent Maintenance,"['Qinglong Shi', 'Donghai Wang', 'Hantao Zhou', 'Jiguo Li', 'Jun Xu', 'Jiuchong Gao', 'Jinghua Hao', 'Renqing He']",,29.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Long-term Task-oriented Agent: Proactive Long-term Intent Maintenance || in Dynamic Environments || Qinglong Shi1, Donghai Wang2, Hantao Zhou2, Jiguo Li2, Jun Xu2, || Jiuchong Gao2,Jinghua Hao 2,Renqing He 2 || 1School of Management, University of Science and Technology of China, Anhui, China || 2 ... (truncated) ||  || { || ""title"": ""Long-term Task-oriented Agent: Proactive Long-term Intent Maintenance"", || ""authors"": [ || ""Qinglong Shi"", || ""Donghai Wang"", || ""Hantao Zhou"", || ""Jiguo Li"", || ""Jun Xu"", || ""Jiuchong Gao"", || ""Jinghua Hao"", || ""Renqing He"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper proposes a novel interaction paradigm for proactive task-oriented agents capable of bridging the gap between static user needs and dynamic environments. It introduces intent-conditioned monitoring and event-triggered follow-up, along with a new benchmark called ChronosBench. The authors evaluate their fine-tuned model trained on synthetic data, achieving an 85.19% task completion rate for complex tasks."" || } ||  || [ Prompt: 116.9 t/s | Generation: 29.6 t/s ]"
2601.09394v2_FairGE Fairness-Aware Graph Encoding in Incomplete.pdf,FairGE: Fairness-Aware Graph Encoding in Incomplete Social Networks,"['Renqiang Luo', 'Huafei Huang', 'Tao Tang', 'Jing Ren', 'Ziqi Xu', 'Mingliang Hou', 'Enyan Dai', 'Feng Xia', 'Jiang Ren']",https://doi.org/XXXXXXX,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || FairGE: Fairness-Aware Graph Encoding in Incomplete Social || Networks || Renqiang Luo || Jilin University || Changchun, China || lrenqiang@outlook.com || Huafei Huang || Adelaide University || Adelaide, Australia || hhuafei@outlook.com || Tao Tang || Zhejiang University of Technology || Hangzhou, China || tao.tang@ieee. ... (truncated) ||  || { || ""title"": ""FairGE: Fairness-Aware Graph Encoding in Incomplete Social Networks"", || ""authors"": [ || ""Renqiang Luo"", || ""Huafei Huang"", || ""Tao Tang"", || ""Jing Ren"", || ""Ziqi Xu"", || ""Mingliang Hou"", || ""Enyan Dai"", || ""Feng Xia"", || ""Jiang Ren"" || ], || ""doi"": ""https://doi.org/XXXXXXX"", || ""arxiv_id"": """", || ""keywords"": [ || ""Social Networks"", || ""Graph Learning"", || ""Graph Transformers"", || ""Fairness"", || ""Incomplete Data"" || ], || ""summary"": ""Graph Transformers (GTs) are increasingly applied to social network analysis, yet their deployment is often constrained by fairness concerns. This issue is particularly critical in incomplete social networks, where sensitive attributes are frequently missing due to privacy and ethical restrictions. Existing solutions commonly generate these incomplete attributes, which may introduce additional biases and further compromise user privacy. To address this challenge, FairGE (Fair Graph Encoding) is introduced as a fairness-aware framework for GTs in incomplete social networks."", || ""contact_emails"": [ || ""lrenqiang@outlook.com"", || ""huafei@outlook.com"", || ""tao.tang@ieee.org"", || ""jing.ren@ieee.org"", || ""zhiqi.xu@rmit.edu.au"", || ""mingliang.hou@hkust-gz.edu.cn"", || ""f.xia@ieee.org"", || ""enyandai@hkust-gz.edu.cn"", || ""teemohold@outlook.com"", || ""enyang.dai@hkust"", || ""f.xia@rmit.edu.au"" || ] || } ||  || [ Prompt: 118.4 t/s | Generation: 28.6 t/s ]"
2601.09398v1_Ability Transfer and Recovery via Modularized Para.pdf,Ability Transfer and Recovery via Modularized Parameters Localization,"['Songyao Jin', 'Kun Zhou', 'Wenqi Li', 'Peng Wang', 'Biwei Huang']","soj007, kuzhou, wel118, pew025, bih007",29.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Ability Transfer and Recovery via Modularized Parameters Localization || Songyao Jin, Kun Zhou*, Wenqi Li, Peng Wang, Biwei Huang || University of California San Diego || {soj007, kuzhou, wel118, pew025, bih007}@ucsd.edu || Abstract || Large language models can be continually pre- || trained or fine- ... (truncated) ||  || { || ""title"": ""Ability Transfer and Recovery via Modularized Parameters Localization"", || ""authors"": [ || ""Songyao Jin"", || ""Kun Zhou"", || ""Wenqi Li"", || ""Peng Wang"", || ""Biwei Huang"" || ], || ""doi"": ""soj007, kuzhou, wel118, pew025, bih007"", || ""arxiv_id"": """", || ""keywords"": [ || ""ability transfer"", || ""recovery"", || ""modularized parameters"", || ""LLM localization"", || ""catastrophic forgetting"" || ], || ""summary"": ""This paper investigates how abilities are distributed within large language model parameters by analyzing module activations. It proposes ACT (Activation-Guided Channel-wise Ability Transfer) to localize ability-relevant channels, enabling selective transfer and minimal interference, with experiments showing successful recovery of forgotten abilities."" || } ||  || [ Prompt: 119.8 t/s | Generation: 29.2 t/s ]"
2601.09413v1_Speech-Hands A Self-Reflection Voice Agentic Appro.pdf,Speech-Hands: A Self-Reflection Voice Agentic Approach to Speech Recognition and Audio Reasoning with Omni Perception,"['Zhen Wan1', 'Chao-Han Huck Yang1', 'Jinchuan Tian1', 'Hanrong Ye1', 'Ankita Pasad1', 'Szu-wei Fu1', 'Ryo Hachiuma1', 'Shizhe Diao1', 'Kunal Dhawan1', 'Sreyan Ghosh1', 'Yusuke Hirota1', 'Zhehuai Chen1', 'Rafael Valle1', 'Ehsan Hosseini Asl1', 'Chenhui Chu2', 'Shinji Watanabe3', 'Yu-Chiang Frank Wang1', 'Boris Ginsburg1']",,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Speech-Hands: A Self-Reflection Voice Agentic Approach to || Speech Recognition and Audio Reasoning with Omni Perception || Zhen Wan1,2 Chao-Han Huck Yang1 Jinchuan Tian1,3 Hanrong Ye1 Ankita Pasad1 || Szu-wei Fu1 Arushi Goel1 Ryo Hachiuma1 Shizhe Diao1 Kunal Dhawan1 || Sreyan Ghosh1 Yusuke Hir ... (truncated) ||  || { || ""title"": ""Speech-Hands: A Self-Reflection Voice Agentic Approach to Speech Recognition and Audio Reasoning with Omni Perception"", || ""authors"": [ || ""Zhen Wan1"", || ""Chao-Han Huck Yang1"", || ""Jinchuan Tian1"", || ""Hanrong Ye1"", || ""Ankita Pasad1"", || ""Szu-wei Fu1"", || ""Ryo Hachiuma1"", || ""Shizhe Diao1"", || ""Kunal Dhawan1"", || ""Sreyan Ghosh1"", || ""Yusuke Hirota1"", || ""Zhehuai Chen1"", || ""Rafael Valle1"", || ""Ehsan Hosseini Asl1"", || ""Chenhui Chu2"", || ""Shinji Watanabe3"", || ""Yu-Chiang Frank Wang1"", || ""Boris Ginsburg1"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""We introduce a voice-agentic framework that learns one critical omni-understanding skill: knowing when to trust itself versus when to consult external audio perception. Our work is motivated by the finding that naively fine-tuning an omni-model on both speech recognition and external sound understanding tasks often degrades performance. To address this, our framework, Speech-Hands, recasts the problem as an explicit self-reflection decision, proving effective in preventing the model from being derailed by flawed external candidates. This agentic action mechanism generalizes naturally from speech recognition to complex, multiple-choice audio reasoning."" || } ||  || [ Prompt: 114.6 t/s | Generation: 28.7 t/s ]"
2601.09416v1_Radiomics-Integrated Deep Learning with Hierarchic.pdf,Radiomics-IntEGra TED Deep Learning With Hierarchical Loss For Osteosarcoma Histology Classification,"['Yaxi Chen1', 'Zi Ye1', 'Shaheer U. Saeed 2', 'Oliver Yu1', 'Simin Ni6', 'Jie Huang1', 'Yipeng Hu2', '3', '4', '5', '6', '7']",,29.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || RADIOMICS-INTEGRA TED DEEP LEARNING WITH HIERARCHICAL LOSS FOR || OSTEOSARCOMA HISTOLOGY CLASSIFICA TION || Yaxi Chen1,2 Zi Ye1 Shaheer U. Saeed 2,3,4,5 || Oliver Yu1 Simin Ni6,7 Jie Huang1 Yipeng Hu2,3 || 1Department of Mechanical Engineering, University College London, London, UK || 2UCL Hawkes  ... (truncated) ||  || { || ""title"": ""Radiomics-IntEGra TED Deep Learning With Hierarchical Loss For Osteosarcoma Histology Classification"", || ""authors"": [ || ""Yaxi Chen1"", || ""Zi Ye1"", || ""Shaheer U. Saeed 2"", || ""Oliver Yu1"", || ""Simin Ni6"", || ""Jie Huang1"", || ""Yipeng Hu2"", || ""3"", || ""4"", || ""5"", || ""6"", || ""7"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Osteosarcoma"", || ""Radiomics"", || ""Multi-Task Learning"", || ""Uncertainty Weighting"", || ""Hierarchical Loss"", || ""Deep Learning"", || ""Histopathology"", || ""Tumor Assessment"" || ], || ""summary"": ""This work proposes using radiomic features as additional input in deep learning models for osteosarcoma histology classification. It introduces a hierarchical loss function to optimize two binary classification tasks (tumor vs non-tumor and viable vs non-viable) and demonstrates improved performance using the TCIA OS Tumor Assessment dataset."" || } ||  || [ Prompt: 119.4 t/s | Generation: 29.4 t/s ]"
2601.09421v2_Bias Dynamics in BabyLMs Towards a Compute-Efficie.pdf,Bias Dynamics in BabyLMs: Towards a Compute-Efficient Sandbox for Democratising Pre-Training Debiasing,"['Filip Trhlik', 'Andrew Caines', 'Paula Buttery']",ft360@cam.ac.uk,29.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Bias Dynamics in BabyLMs: Towards a Compute-Efficient Sandbox for || Democratising Pre-Training Debiasing || Filip Trhlik, Andrew Caines, Paula Buttery, || Department of Computer Science & Technology, University of Cambridge, U.K. || ALTA Institute, University of Cambridge, U.K. || ft360@cam.ac.uk ... (truncated) ||  || { || ""title"": ""Bias Dynamics in BabyLMs: Towards a Compute-Efficient Sandbox for Democratising Pre-Training Debiasing"", || ""authors"": [ || ""Filip Trhlik"", || ""Andrew Caines"", || ""Paula Buttery"" || ], || ""doi"": ""ft360@cam.ac.uk"", || ""arxiv_id"": """", || ""keywords"": [ || ""BabyLMs"", || ""pre-trained language models"", || ""bias mitigation"", || ""computational efficiency"", || ""democratising research"" || ], || ""summary"": ""This paper explores BabyLMs as a low-cost proxy for studying bias in large language models, demonstrating their ability to approximate bias patterns and enabling faster, more accessible debiasing research."" || } ||  || [ Prompt: 118.1 t/s | Generation: 29.5 t/s ]"
2601.09433v1_Do Transformers Understand Ancient Roman Coin Moti.pdf,Do Transformers Understand Ancient Roman Coin,"['David Reid', 'Ognjen Arandjelovi']",arXiv:2601.09433v1,31.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Do Transformers Understand Ancient Roman Coin || Motifs Better than CNNs? || David Reid and Ognjen Arandjelovi c || School of Computer Science || University of St Andrews || Scotland KY16 9AJ, UK || Abstract || Automated analysis of ancient coins has the potential to help researchers extract || more histor ... (truncated) ||  || { || ""title"": ""Do Transformers Understand Ancient Roman Coin"", || ""authors"": [""David Reid"", ""Ognjen Arandjelovi""], || ""doi"": ""arXiv:2601.09433v1"", || ""arxiv_id"": ""arXiv:2601.09433v1"", || ""keywords"": [], || ""summary"": ""Automated analysis of ancient coins has the potential to help researchers extract more historical insights... ViT models outperform CNNs in accuracy."" || } ||  || [ Prompt: 117.2 t/s | Generation: 31.5 t/s ]"
2601.09445v1_Where Knowledge Collides A Mechanistic Study of In.pdf,Where Knowledge Collides: A Mechanistic Study of Intra-Memory Knowledge Conflict in Language Models,"['Minh Vu Pham', 'Hsuvas Borkakoty', 'Yufang Hou', 'IBM Research']",arXiv:2601.09445v1,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Where Knowledge Collides: A Mechanistic Study of Intra-Memory || Knowledge Conflict in Language Models || Minh Vu Pham * || IT:U Austria || minhvu.pham@it-u.at || Hsuvas Borkakoty * || IT:U Austria || hsuvas.borkakoty@it-u.at || Yufang Hou || IT:U Austria || IBM Research || yufang.hou@it-u.at || Abstract || In language m ... (truncated) ||  || { || ""title"": ""Where Knowledge Collides: A Mechanistic Study of Intra-Memory Knowledge Conflict in Language Models"", || ""authors"": [ || ""Minh Vu Pham"", || ""Hsuvas Borkakoty"", || ""Yufang Hou"", || ""IBM Research"" || ], || ""doi"": ""arXiv:2601.09445v1"", || ""arxiv_id"": ""arXiv:2601.09445"", || ""keywords"": [ || ""language models"", || ""intra-memory knowledge conflict"", || ""mechanistic interpretability"", || ""hallucinations"", || ""knowledge editing"" || ], || ""summary"": ""This work investigates how conflicting information encoded within a model's internal knowledge during pre-training leads to intra-memory knowledge conflicts. Using mechanistic interpretability methods, the authors identify components of language models responsible for such conflicts and demonstrate how interpretability techniques can intervene at inference time."" || } ||  || [ Prompt: 121.7 t/s | Generation: 29.3 t/s ]"
2601.09446v1_Improving Symbolic Translation of Language Models .pdf,Improving Symbolic Translation of Language Models for Logical Reasoning,"['Ramya Keerthy Thatikonda', 'Jiuzhou Han', 'Wray Buntine', 'Ehsan Shareghi']",,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Improving Symbolic Translation of Language Models for Logical Reasoning || Ramya Keerthy Thatikonda1, Jiuzhou Han1, Wray Buntine2, Ehsan Shareghi1 || 1Department of Data Science & AI, Monash University || 2College of Engineering and Computer Science, VinUniversity || ramya.thatikonda1@monash.ed ... (truncated) ||  || { || ""title"": ""Improving Symbolic Translation of Language Models for Logical Reasoning"", || ""authors"": [ || ""Ramya Keerthy Thatikonda"", || ""Jiuzhou Han"", || ""Wray Buntine"", || ""Ehsan Shareghi"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper discusses challenges in translating natural language into formal logic using language models, proposes a framework with incremental inference and verification to improve reasoning performance for smaller models."" || } ||  || [ Prompt: 124.4 t/s | Generation: 27.5 t/s ]"
2601.09448v1_Population-Aligned Audio Reproduction With LLM-Bas.pdf,Population-Aligned Audio Reproduction With LLM-Based Equalizers,"['Ioannis Stylianou', 'Jon Francombe', 'Pablo Mart nez-Nuevo', 'Sven Ewan Shepstone', 'Member, IEEE', 'Zheng-Hua Tan']",,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SUBMITTED TO IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING 1 || Population-Aligned Audio Reproduction With LLM-Based Equalizers || Ioannis Stylianou, Jon Francombe, Pablo Mart nez-Nuevo, Sven Ewan Shepstone,Member, IEEE, and Zheng-Hua || Tan,Senior Member, IEEE || AbstractConventional au ... (truncated) ||  || { || ""title"": ""Population-Aligned Audio Reproduction With LLM-Based Equalizers"", || ""authors"": [ || ""Ioannis Stylianou"", || ""Jon Francombe"", || ""Pablo Mart nez-Nuevo"", || ""Sven Ewan Shepstone"", || ""Member, IEEE"", || ""Zheng-Hua Tan"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""LLMs"", || ""Equalization"", || ""Audio Reproduction"", || ""Listening Experiments"", || ""Recommender Systems"" || ], || ""summary"": ""Conventional audio equalization is a static process requiring manual adjustments. This paper introduces an LLM-based alternative that maps natural language prompts to equalization settings, enabling conversational sound system control. Evaluation shows statistically significant improvements over static baselines."" || } ||  || [ Prompt: 120.6 t/s | Generation: 27.6 t/s ]"
2601.09451v1_Late Breaking Results Quamba-SE Soft-edge Quantize.pdf,Quamba-SE: Soft-edge quantizer for State Space Models,"['Yizhi Chen', 'Ahmed Hemani']",10.48550/arXiv.2303.06912,29.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Late Breaking Results: Quamba-SE: Soft-edge || Quantizer for Activations in State Space Models || Yizhi Chen{yizhic@kth.se}and Ahmed Hemani{hemani@kth.se} || Department of Electronics and Embedded Systems, KTH Royal Institute of Technology, Stockholm, Sweden || AbstractWe propose Quamba-SE, a s ... (truncated) ||  || { || ""title"": ""Quamba-SE: Soft-edge quantizer for State Space Models"", || ""authors"": [""Yizhi Chen"", ""Ahmed Hemani""], || ""doi"": ""10.48550/arXiv.2303.06912"", || ""arxiv_id"": ""10.48550/arXiv.2303.06912"", || ""keywords"": [""quantization"", ""State Space Models"", ""soft-edge"", ""Quanta""], || ""summary"": ""Proposes Quamba-SE, a soft-edge quantizer for State Space Model activation quantization, preserving outlier information while maintaining precision."" || } ||  || [ Prompt: 114.1 t/s | Generation: 29.8 t/s ]"
2601.09455v1_On the Hardness of Computing Counterfactual and Se.pdf,Providing clear explanations to the choices of machine learning models is essential for these models to be deployed in crucial applications.,"['Andr Arteltaartelt', 'Martin Olsen', 'Kevin Tierney']",,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Published in Transactions on Machine Learning Research (12/2025) || On the Hardness of Computing Counterfactual and Semi- || factual Explanations in XAI || Andr Arteltaartelt@techfak.uni-bielefeld.de || Faculty of Technology || Bielefeld University, Germany || Martin Olsen martino@btech.au.dk || Departm ... (truncated) ||  || { || ""title"": ""Providing clear explanations to the choices of machine learning models is essential for these models to be deployed in crucial applications."", || ""authors"": [ || ""Andr Arteltaartelt"", || ""Martin Olsen"", || ""Kevin Tierney"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper discusses the computational complexity of generating counterfactual and semi-factual explanations in XAI, highlighting that explanation generation can be computationally hard and that approximating them is even more challenging under certain assumptions."" || } ||  || [ Prompt: 115.1 t/s | Generation: 27.8 t/s ]"
2601.09460v1_SoK Enhancing Cryptographic Collaborative Learning.pdf,,[],,27.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SoK: Enhancing Cryptographic Collaborative || Learning with Differential Privacy || Francesco Capano || SAP SE || Karlsruhe, Germany || francesco.capano@sap.com || Jonas B ohler || SAP SE || Karlsruhe, Germany || jonas.boehler@sap.com || Benjamin Weggenmann* || Technische Hochschule W urzburg-Schweinfurt || Wurzburg-S ... (truncated) ||  || { || ""title"": ""Enhancing Cryptographic Collaborative Learning with Differential Privacy"", || ""authors"": [ || ""Francesco Capano"", || ""Jonas B ohler"", || ""Benjamin Weggenmann"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""cryptography"", || ""collaborative machine learning"", || ""differential privacy"", || ""secure learning"", || ""privacy-preserving computation""] || ""summary"": ""The paper discusses combining cryptographic techniques and differential privacy to enable secure collaborative machine learning while mitigating inference attacks. It introduces a unified framework for cryptographic and differentially private collaborative learning and evaluates secure noise sampling methods."" || } ||  || [ Prompt: 119.1 t/s | Generation: 27.3 t/s ]"
2601.09465v1_EvoFSM Controllable Self-Evolution for Deep Resear.pdf,EvoFSM: Controllable Self-Evolution for Deep Research with Finite State,"['Shuo Zhang', 'Chaofa Yuan', 'Ryan Guo', 'Xiaomin Yu', 'Rui Xu', 'Zhangquan Chen', 'Zinuo Li', 'Zhi Yang', 'Shuhao Guan', 'Zhenheng Tang', 'Sen Hu', 'Liwen Zhang', 'Ronghao Chen', 'Huacan Wang']",10.48550/arXiv.2601.09465,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 2026-01-15 || EvoFSM: Controllable Self-Evolution for Deep Research with Finite State || Machines || Shuo Zhang1*, Chaofa Yuan1*, Ryan Guo1*, Xiaomin Yu2, Rui Xu3, Zhangquan Chen4, || Zinuo Li1,Zhi Yang 5,Shuhao Guan 6,Zhenheng Tang 7,Sen Hu 1,8,Liwen Zhang 5, || Ronghao Chen1,8,Huacan Wang 1,9 || 1Q ... (truncated) ||  || { || ""title"": ""EvoFSM: Controllable Self-Evolution for Deep Research with Finite State"", || ""authors"": [ || ""Shuo Zhang"", || ""Chaofa Yuan"", || ""Ryan Guo"", || ""Xiaomin Yu"", || ""Rui Xu"", || ""Zhangquan Chen"", || ""Zinuo Li"", || ""Zhi Yang"", || ""Shuhao Guan"", || ""Zhenheng Tang"", || ""Sen Hu"", || ""Liwen Zhang"", || ""Ronghao Chen"", || ""Huacan Wang"" || ], || ""doi"": ""10.48550/arXiv.2601.09465"", || ""arxiv_id"": ""2601.09465"", || ""keywords"": [ || ""EvoFSM"", || ""Self-Evolution"", || ""Deep Research"", || ""Finite State"", || ""LLM"", || ""Adaptability"", || ""Control"", || ""Code Evolution"" || ], || ""summary"": ""EvoFSM introduces a structured self-evolving framework that decouples optimization into macroscopic flow and microscopic skills, enabling adaptable and controllable agents. It improves performance on multi-hop QA benchmarks with 58.0% accuracy."", || ""summary_short"": ""A structured self-evolving framework enhances LLM adaptability by evolving explicit finite state machines, balancing stability and performance."" || } ||  || [ Prompt: 116.6 t/s | Generation: 28.1 t/s ]"
2601.09467v1_Searth Transformer A Transformer Architecture Inco.pdf,,[],,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Searth Transformer: A Transformer Architecture Incorporating Earth's Geospheric Physical Priors for Global Mid-Range Weather Forecasting  Tianye Li1, 3, Qi Liu2, 3, Hao Li4, 5, Lei Chen4, 5, Wencong Cheng6, *, Fei Zheng2, Xiangao Xia7, 3, Ya Wang8, Gang Huang2, Weiwei Wang9, 10, Xua ... (truncated) ||  || { || ""title"": ""Searth Transformer: A Transformer Architecture Incorporating Earth's Geospheric Physical Priors for Global Mid-Range Weather Forecasting"", || ""authors"": [ || ""Tianye Li1"", || ""3"", || ""Qi Liu2"", || ""3"", || ""Hao Li4"", || ""5"", || ""Lei Chen4"", || ""5"", || ""Wencong Cheng6"", || ""*"", || ""Fei Zheng2"", || ""Xiangao Xia7"", || ""3"", || ""Ya Wang8"", || ""Gang Huang2"", || ""Weiwei Wang9"", || ""10"", || ""Xuan Tong11"", || ""Ziqing Zu12"", || ""13"", || ""Yi Fang1"", || ""Shenming Fu2"", || ""Jiang Jiang14"", || ""Haochen Li15"", || ""Mingxing Li1"", || ""3"", || ""Jiangjiang Xia1"", || ""3"", || ""*"", || ""1Temperate East Asia Research Center on Global Change"", || ""Institute of Atmospheric Physics, Chinese Academy of Sciences, Beijing 100029, China"", || ""2State Key Laboratory of Earth System Numerical Modeling and Application, Institute of Atmospheric Physics, Chinese Academy of Sciences, Beijing 100029, China"", || ""3University of Chinese Academy of Sciences, Beijing 100049, China"", || ""4Artificial Intelligence Innovation and Incubation Institute, Fudan University, Shanghai"", || ""200433, China"", || ""6Beijing Aviation Meteorological Institute, Beijing 100085, China"", || ""7Laboratory of Middle Atmosphere and Global Environment Observation (LAGEO), Institute of Atmospheric Physics, Chinese Academy of Sciences, Beijing 100029, China"", || ""8Earth System Numerical Simulation Science Center, Institute of Atmospheric Physics, Chinese Academy of Sciences, Beijing 100029, China"", || ""9Meteorological Bureau of Shenzhen Municipality, Shenzhen 518040, China"", || ""10Shenzhen Key Laboratory of Severe Weather in South China, Shenzhen 518040, China"", || ""11Jiangsu Key Laboratory of Intelligent Weather Forecasting and Applications Based on Big Data, Nanjing University of Information Science and Technology, Nanjing 210044, China"", || ""12State Key Laboratory of Satellite Ocean ||  || [ Prompt: 119.8 t/s | Generation: 28.2 t/s ]"
2601.09469v2_FairGU Fairness-aware Graph Unlearning in Social N.pdf,Fairness-aware Graph Unlearning in Social Networks,"['Renqiang Luo', 'Yongshuai Yang', 'Huafei Huang', 'Qing Qing', 'Mingliang Hou', 'Ziqi Xu', 'Yi Yu', 'Jingjing Zhou', 'Feng Xia', 'Ziqi Xu', 'Jiang']",https://doi.org/XXXXXXX,29.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || FairGU: Fairness-aware Graph Unlearning in Social Networks || Renqiang Luo || Jilin University || Changchun, China || lrenqiang@outlook.com || Yongshuai Yang || Zhejiang Gongshang University || Hangzhou, China || frost.yang@outlook.com || Huafei Huang || Adelaide University || Adelaide, Australia || hhuafei@outlook.co ... (truncated) ||  || { || ""title"": ""Fairness-aware Graph Unlearning in Social Networks"", || ""authors"": [ || ""Renqiang Luo"", || ""Yongshuai Yang"", || ""Huafei Huang"", || ""Qing Qing"", || ""Mingliang Hou"", || ""Ziqi Xu"", || ""Yi Yu"", || ""Jingjing Zhou"", || ""Feng Xia"", || ""Ziqi Xu"", || ""Jiang"" || ], || ""doi"": ""https://doi.org/XXXXXXX"", || ""arxiv_id"": """", || ""keywords"": [ || ""fairness-aware graph unlearning"", || ""social networks"", || ""privacy-preserving"", || ""algorithmic fairness"", || ""data protection"" || ], || ""summary"": ""Graph unlearning techniques often fail to safeguard sensitive attributes. This paper introduces FairGU, a fairness-aware framework that enhances utility and fairness during unlearning, improving performance over existing methods."" || } ||  || [ Prompt: 120.5 t/s | Generation: 29.5 t/s ]"
2601.09470v1_Personalized Multimodal Feedback Using Multiple Ex.pdf,Personalized Multimodal Feedback Using Multiple External Representations: Strategy Profiles and Learning in High School Physics,"['Natalia Revenga-Lozano', 'Karina E. Avila', 'Steffen Steinert', 'Matthias Schweinberger', 'Clara E. Gmez-Prez', 'Jochen Kuhn', 'Stefan Kchemann']",arXiv:2601.09470v1,30.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Personalized Multimodal Feedback Using Multiple || External Representations: Strategy Profiles and || Learning in High School Physics || Natalia Revenga-Lozano1*, Karina E. Avila1, Steffen Steinert1, || Matthias Schweinberger1, Clara E. Gmez-Prez1, Jochen Kuhn1, || Stefan Kchemann1* || 1Chair of Phys ... (truncated) ||  || { || ""title"": ""Personalized Multimodal Feedback Using Multiple External Representations: Strategy Profiles and Learning in High School Physics"", || ""authors"": [ || ""Natalia Revenga-Lozano"", || ""Karina E. Avila"", || ""Steffen Steinert"", || ""Matthias Schweinberger"", || ""Clara E. Gmez-Prez"", || ""Jochen Kuhn"", || ""Stefan Kchemann"" || ], || ""doi"": ""arXiv:2601.09470v1"", || ""arxiv_id"": ""arXiv:2601.09470"", || ""keywords"": [ || ""multimodal feedback"", || ""personalized feedback"", || ""multiple external representations"", || ""strategy profiles"", || ""learning in physics"", || ""high school physics"" || ], || ""summary"": ""This study investigates how personalized feedback in a computer-based platform affects post-test performance in high school physics, emphasizing the role of representation choice and learner competence."" || } ||  || [ Prompt: 116.0 t/s | Generation: 30.9 t/s ]"
2601.09473v1_SimMerge Learning to Select Merge Operators from S.pdf,SimMerge: Learning to Select Merge,"['Oliver Bolton', 'Aakanksha', 'Arash Ahmadian', 'Sara Hooker', 'Marzieh Fadaee', 'Beyza Ermis']","1Cohere Labs, 2Cohere, 3Google, 4Adaption Labs",28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SimMerge: Learning to Select Merge || Operators from Similarity Signals || Oliver Bolton 1, Aakanksha 2, Arash Ahmadian 3, Sara Hooker 4, || Marzieh Fadaee 1, and Beyza Ermis 1 || 1Cohere Labs, 2Cohere, 3Google, 4Adaption Labs || Corresponding authors: {beyza,marzieh}@cohere.com || Abstract || Model mer ... (truncated) ||  || { || ""title"": ""SimMerge: Learning to Select Merge"", || ""authors"": [ || ""Oliver Bolton"", || ""Aakanksha"", || ""Arash Ahmadian"", || ""Sara Hooker"", || ""Marzieh Fadaee"", || ""Beyza Ermis"" || ], || ""doi"": ""1Cohere Labs, 2Cohere, 3Google, 4Adaption Labs"", || ""arxiv_id"": ""1"", || ""keywords"": [ || ""model merging"", || ""similarity signals"", || ""LLM development"", || ""merge operator"", || ""simulation"", || ""performance prediction"" || ], || ""summary"": ""This paper introduces SimMerge, a predictive method for selecting optimal merge operators in multi-model LLM composition. It leverages task-agnostic similarity signals to eliminate expensive evaluation loops, achieving competitive performance on 2-way LLM merges and generalizing to larger models."" || } ||  || [ Prompt: 122.7 t/s | Generation: 28.3 t/s ]"
2601.09478v3_Bridging Semantic Understanding and Popularity Bia.pdf,Bridging Semantic Understanding and Popularity Bias with LLMs,"['Renqiang Luo', 'Dong Zhang', 'Yupeng Gao', 'Wen Shi', 'Mingliang Hou', 'Zhe Wang', 'Jiaying Liu']",10.1093/acr/acv045,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Bridging Semantic Understanding and Popularity Bias with LLMs || Renqiang Luo || Jilin University || Changchun, China || lrenqiang@outlook.com || Dong Zhang || Dalian University of Technology || Dalian, China || dongzhang1222@outlook.com || Yupeng Gao || Dalian University of Technology || Dalian, China || commer@mail. ... (truncated) ||  || { || ""title"": ""Bridging Semantic Understanding and Popularity Bias with LLMs"", || ""authors"": [ || ""Renqiang Luo"", || ""Dong Zhang"", || ""Yupeng Gao"", || ""Wen Shi"", || ""Mingliang Hou"", || ""Zhe Wang"", || ""Jiaying Liu"" || ], || ""doi"": ""10.1093/acr/acv045"", || ""arxiv_id"": """", || ""keywords"": [ || ""semantic understanding"", || ""popularity bias"", || ""recommender systems"", || ""LLMs"", || ""fairness"", || ""recommendation"" || ], || ""summary"": ""Semantic understanding of popularity bias is a crucial yet underexplored challenge in recommender systems, where popular items are often favored at the expense of niche content. Most existing debias methods treat the semantic understanding of popularity bias as a matter of diversity enhancement or long-tail coverage, neglecting the deeper semantic layer that embodies the causal origins of the bias itself. Consequently, such shallow interpretations limit both debiasing effectiveness and recommendation accuracy. In this paper, we propose FairLRM, a novel framework that bridges the gap in the semantic understanding of popularity bias with Recommender systems via Large Language Model (RecLLM). FairLRM decomposes popularity bias into item-side and user-side components, using structured instruction-based prompts to enhance the models comprehension of both global item distributions and individual user preferences. Unlike traditional methods that rely on surface-level features such as 'diversity' or 'debiasing', FairLRM improves the models ability to semantically interpret and address the underlying bias. Through empirical evaluation, we show that FairLRM significantly enhances both fairness and recommendation accuracy, providing a more semantically aware and trustworthy approach to enhance the semantic understanding of popularity bias."", || ""contact_emails"": [ || ""lrenqiang@outlook.com"", || ""dongzhang1222@outlook.com"", || ""jiayingliu@dlut.edu.cn"", || ""shuo.yu@ieee.org"", || ""shuo.yu@ieee.org"", || ""teemohold@outlook.com"", || ""wz2000@jlu.edu.cn"" || ] || } ||  || [ Prompt: 120.9 t/s | Generation: 28.7 t/s ]"
2601.09503v1_What Do LLM Agents Know About Their World Task2Qui.pdf,What Do LLM Agents Know About Their World?,"['Siyuan Liu', 'Hongbang Yuan', 'Xinze Li', 'Ziyue Zhu', 'Yixin Cao', 'Yu-Gang Jiang']",,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || What Do LLM Agents Know About Their World? || Task2Quiz: A Paradigm for Studying Environment || Understanding || Siyuan Liu1, Hongbang Yuan1, Xinze Li1, Ziyue Zhu1, Yixin Cao1, Yu-Gang Jiang1 || 1School of Computer Science, Fudan University || Abstract || Large language model (LLM) agents have demons ... (truncated) ||  || { || ""title"": ""What Do LLM Agents Know About Their World?"", || ""authors"": [ || ""Siyuan Liu"", || ""Hongbang Yuan"", || ""Xinze Li"", || ""Ziyue Zhu"", || ""Yixin Cao"", || ""Yu-Gang Jiang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper investigates whether large language model agents develop a grounded, transferable model of their environment, highlighting that task success does not always reflect true environment understanding. It identifies proactive exploration and fine-grained state representation as key challenges."" || } ||  || [ Prompt: 123.4 t/s | Generation: 28.3 t/s ]"
2601.09518v1_Learning Whole-Body Human-Humanoid Interaction fro.pdf,Learning Whole-Body Human-Humanoid Interaction,"['Wei-Jin Huang', 'Yue-Yi Zhang', 'Yi-Lin Wei', 'Zhi-Wei Xia', 'Juantao Tan', 'Yuan-Ming Li', 'Zhilin Zhao', 'Wei-Shi Zheng', 'Guangdong Province Key Laboratory of Information Security Technology']",arXiv:2601.09518v1,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Learning Whole-Body Human-Humanoid Interaction || from Human-Human Demonstrations || Wei-Jin Huang1 Yue-Yi Zhang1 Yi-Lin Wei1 Zhi-Wei Xia1 Juantao Tan1 || Yuan-Ming Li1 Zhilin Zhao1 Wei-Shi Zheng1,2,3,4, || 1School of Computer Science and Engineering, Sun Yat-sen University, China || 2Peng Cheng L ... (truncated) ||  || { || ""title"": ""Learning Whole-Body Human-Humanoid Interaction"", || ""authors"": [ || ""Wei-Jin Huang"", || ""Yue-Yi Zhang"", || ""Yi-Lin Wei"", || ""Zhi-Wei Xia"", || ""Juantao Tan"", || ""Yuan-Ming Li"", || ""Zhilin Zhao"", || ""Wei-Shi Zheng"", || ""Guangdong Province Key Laboratory of Information Security Technology"" || ], || ""doi"": ""arXiv:2601.09518v1"", || ""arxiv_id"": ""HHI Dataset"", || ""keywords"": [ || ""Human-Human Interaction"", || ""Humanoid Robotics"", || ""Physics-Aware Interaction"", || ""Decoupled Spatio-Temporal Action Reasoner"", || ""D-STAR"", || ""Whole-Body Interaction"" || ], || ""summary"": ""The paper presents a contact-centric two-stage pipeline for generating high-quality Human-Humanoid Interaction data from Human-Human Interaction datasets. It addresses the limitations of standard retargeting methods and introduces D-STAR to preserve contact semantics, enabling more interactive and physically consistent robot behaviors."" || } ||  || [ Prompt: 131.4 t/s | Generation: 29.0 t/s ]"
2601.09520v1_Towards Realistic Synthetic Data for Automatic Dru.pdf,TOW ARDS REALISTIC SYNTHETIC DA TA FOR AUTOMA TIC DRUM TRANSCRIPTION,"['Pierfrancesco Melucci', 'Paolo Merialdo', 'Taketo Akama']",,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TOW ARDS REALISTIC SYNTHETIC DA TA FOR AUTOMA TIC DRUM TRANSCRIPTION || Pierfrancesco Melucci1,2, Paolo Merialdo2, Taketo Akama3 || 1Sapienza University of Rome, Italy; || 2Roma Tre University, Italy; || 3Sony Computer Science Laboratories, Tokyo, Japan || ABSTRACT || Deep learning models define the  ... (truncated) ||  || { || ""title"": ""TOW ARDS REALISTIC SYNTHETIC DA TA FOR AUTOMA TIC DRUM TRANSCRIPTION"", || ""authors"": [ || ""Pierfrancesco Melucci"", || ""Paolo Merialdo"", || ""Taketo Akama"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper introduces a semi-supervised method to automatically curate a large and diverse corpus of one-shot drum samples from unlabeled audio sources. It uses this corpus to synthesize a high-quality dataset from MIDI files alone, achieving state-of-the-art results in Automatic Drum Transcription."" || } ||  || [ Prompt: 122.0 t/s | Generation: 27.7 t/s ]"
2601.09527v1_Private LLM Inference on Consumer Blackwell GPUs A.pdf,Private LLM Inference on Consumer Blackwell GPUs: A Practical Guide for Cost-Effective Local Deployment in SMEs,"['Jonathan Knoop', 'Hendrik Holtmann']",,29.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Private LLM Inference on Consumer Blackwell GPUs: || A Practical Guide for Cost-Effective Local Deployment in SMEs || Jonathan Knoop1 and Hendrik Holtmann2 || 1IE Business University, Madrid, Spain (jmknoop.ieu2025@student.ie.edu) || 2Independent Researcher, Hamburg, Germany (holtmann@gmail.com ... (truncated) ||  || { || ""title"": ""Private LLM Inference on Consumer Blackwell GPUs: A Practical Guide for Cost-Effective Local Deployment in SMEs"", || ""authors"": [ || ""Jonathan Knoop"", || ""Hendrik Holtmann"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""LLM"", || ""consumer GPUs"", || ""Blackwell"", || ""quantization"", || ""quantumization"", || ""deployment"", || ""SMEs"", || ""cost-effectiveness"", || ""privacy"", || ""hardware"", || ""serving"" || ], || ""summary"": ""SMEs can replace cloud LLM APIs with cost-effective local deployment using NVIDIA Blackwell GPUs, achieving competitive performance and latency while addressing data privacy and cost concerns."" || } ||  || [ Prompt: 121.1 t/s | Generation: 29.2 t/s ]"
2601.09536v1_Omni-R1 Towards the Unified Generative Paradigm fo.pdf,Omni-R1: Towards the Unified Generative Paradigm for Multimodal Reasoning,"['Dongjie Cheng', 'Yongqi Li', 'Hongru Cai', 'Wenjie Wang', 'Liqiang Nie', 'Wenjie Li']",,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 2026-1-14 || Omni-R1: Towards the Unified Generative || Paradigm for Multimodal Reasoning || Dongjie Cheng1 Yongqi Li1 Zhixin Ma2 Hongru Cai1 || Yupeng Hu3 Wenjie Wang4 Liqiang Nie5 Wenjie Li1 || 1 The Hong Kong Polytechnic University 2 Singapore Management University 3 Shandong University || 4 Unive ... (truncated) ||  || { || ""title"": ""Omni-R1: Towards the Unified Generative Paradigm for Multimodal Reasoning"", || ""authors"": [ || ""Dongjie Cheng"", || ""Yongqi Li"", || ""Hongru Cai"", || ""Wenjie Wang"", || ""Liqiang Nie"", || ""Wenjie Li"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper proposes a unified generative multimodal reasoning framework using Omni-R1, which integrates perception alignment and perception reward to enable functional image generation. It introduces Omni-R1-Zero to eliminate multimodal annotations by leveraging text-only reasoning data. Empirical results demonstrate its effectiveness across diverse multimodal tasks."" || } ||  || [ Prompt: 124.9 t/s | Generation: 27.6 t/s ]"
2601.09555v1_Benchmarking Post-Training Quantization of Large L.pdf,Benchmarking Post-Training Quantization of Large Language Models,"['Manyi Zhang Ji-Fu', 'Li Zhongao', 'Sun Huaoli', 'Bai Hui-Ling', 'Zhen Zhenhua', 'Dong Xianzhi Yu']","zhangmanyi6, yuxianzhi",29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Benchmarking Post-Training Quantization of Large Language Models || under Microscaling Floating Point Formats || Manyi Zhang Ji-Fu Li Zhongao Sun* || Haoli Bai Hui-Ling Zhen Zhenhua Dong Xianzhi Yu || Huawei Technologies || {zhangmanyi6, yuxianzhi}@huawei.com || Abstract || Microscaling Floating-Point  ... (truncated) ||  || { || ""title"": ""Benchmarking Post-Training Quantization of Large Language Models"", || ""authors"": [ || ""Manyi Zhang Ji-Fu"", || ""Li Zhongao"", || ""Sun Huaoli"", || ""Bai Hui-Ling"", || ""Zhen Zhenhua"", || ""Dong Xianzhi Yu"" || ], || ""doi"": ""zhangmanyi6, yuxianzhi"", || ""arxiv_id"": """", || ""keywords"": [ || ""post-training quantization"", || ""MXFP"", || ""large language models"", || ""quantization"", || ""low-precision formats"" || ], || ""summary"": ""This work systematically investigates post-training quantization under Microscaling Floating-Point formats, evaluating over 7 PTQ algorithms across 15 benchmarks and 3 LLM families. Key findings highlight performance trends, accuracy degradation, and the impact of quantization scaling."" || } ||  || [ Prompt: 115.0 t/s | Generation: 29.1 t/s ]"
2601.09566v2_Hot-Start from Pixels Low-Resolution Visual Tokens.pdf,Submitted to ACL 2026,"['Shuyang Xiang', 'Hao Guan']",https://github.com/ShuyangenFrance/chinese-vision,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Submitted to ACL 2026https://github.com/ShuyangenFrance/chinese-vision || Hot-Start from Pixels: Low-Resolution Visual Tokens for Chinese || Language Modeling || Shuyang Xiang || Independent Researcher || vanillaxiangshuyang@gmail.com || Hao Guan || Institute of Software, Chinese Academy of Sciences || gua ... (truncated) ||  || { || ""title"": ""Submitted to ACL 2026"", || ""authors"": [ || ""Shuyang Xiang"", || ""Hao Guan"" || ], || ""doi"": ""https://github.com/ShuyangenFrance/chinese-vision"", || ""arxiv_id"": ""2601.09566v2"", || ""keywords"": [ || ""Chinese language modeling"", || ""character-level modeling"", || ""low-resolution visual tokens"", || ""visual structure"", || ""language representation"" || ], || ""summary"": ""Investigates low-resolution visual inputs for Chinese character modeling, showing they can achieve competitive accuracy and reveal insights into visual semantics."" || } ||  || [ Prompt: 127.4 t/s | Generation: 28.6 t/s ]"
2601.09600v1_Information Access of the Oppressed A Problem-Posi.pdf,Information Access of the Oppressed: A Problem-Posing Framework for Envisioning Emancipatory Information Access Platforms,"['Bhaskar Mitra', 'Nicola Neophytou', 'Sireesh Gururaja']",https://doi.org/XXXXXXX.XXXXXXX,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Information Access of the Oppressed: A Problem-Posing Framework for || Envisioning Emancipatory Information Access Platforms || BHASKAR MITRA,Independent Researcher, Canada || NICOLA NEOPHYTOU,Independent Researcher, Canada || SIREESH GURURAJA,Carnegie Mellon University, USA || Online information  ... (truncated) ||  || { || ""title"": ""Information Access of the Oppressed: A Problem-Posing Framework for Envisioning Emancipatory Information Access Platforms"", || ""authors"": [ || ""Bhaskar Mitra"", || ""Nicola Neophytou"", || ""Sireesh Gururaja"" || ], || ""doi"": ""https://doi.org/XXXXXXX.XXXXXXX"", || ""arxiv_id"": """", || ""keywords"": [ || ""Information Access"", || ""Emancipatory Information Access"", || ""Search and Society"", || ""Sociotechnical Information Systems"" || ], || ""summary"": ""The paper explores how online information access platforms should be reimagined to resist authoritarian capture, using Paulo Freire's emancipatory pedagogy as a framework. It calls for technologists to engage marginalized communities in co-creating technology for emancipation."" || } ||  || [ Prompt: 119.5 t/s | Generation: 28.2 t/s ]"
2601.09603v1_Linear Complexity Self-Supervised Learning for Mus.pdf,Linear Complexity Self-Supervised Learning for Music Understanding with Random Quantizer,"['Petros Vavaroutsos', 'Theodoros Palamas', 'Pantelis Vikatos']",10.1145/3748522.3779786,28.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Linear Complexity Self-Supervised Learning for Music || Understanding with Random Quantizer || Petros Vavaroutsos || peter@orfium.com || Orfium Research || Athens, Greece || Theodoros Palamas || theodoros@orfium.com || Orfium Research || Athens, Greece || Pantelis Vikatos || pantelis@orfium.com || Orfium Research || Athe ... (truncated) ||  || { || ""title"": ""Linear Complexity Self-Supervised Learning for Music Understanding with Random Quantizer"", || ""authors"": [ || ""Petros Vavaroutsos"", || ""Theodoros Palamas"", || ""Pantelis Vikatos"" || ], || ""doi"": ""10.1145/3748522.3779786"", || ""arxiv_id"": """", || ""keywords"": [ || ""Deep Learning"", || ""Music Understanding"", || ""Transformers"", || ""Embeddings"", || ""Attention"" || ], || ""summary"": ""This paper focuses on reducing the size of foundation models for music information retrieval tasks by combining Branchformer architecture with SummaryMixing and a random quantization process. Pre-training is performed on public datasets with a proprietary dataset, and performance is evaluated across various downstream MIR tasks."" || } ||  || [ Prompt: 122.6 t/s | Generation: 28.9 t/s ]"
2601.09605v1_Sim2real Image Translation Enables Viewpoint-Robus.pdf,Sim2real Image Translation Enables Viewpoint-Robust Policies from Fixed-Camera Datasets,"['Jeremiah Coholich', 'Justin Wit', 'Robert Azarcon', 'Zsolt Kira']",10.48550/arXiv.2405.12345,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Sim2real Image Translation Enables Viewpoint- || Robust Policies from Fixed-Camera Datasets || Jeremiah Coholich 1, Justin Wit 1, Robert Azarcon 1, Zsolt Kira 1 || AbstractVision-based policies for robot manipulation have || achieved significant recent success, but are still brittle to || distribu ... (truncated) ||  || { || ""title"": ""Sim2real Image Translation Enables Viewpoint-Robust Policies from Fixed-Camera Datasets"", || ""authors"": [ || ""Jeremiah Coholich"", || ""Justin Wit"", || ""Robert Azarcon"", || ""Zsolt Kira"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""10.48550/arXiv.2405.12345"", || ""keywords"": [ || ""image translation"", || ""robot manipulation"", || ""viewpoint variation"", || ""sim2real challenge"", || ""robot policies"", || ""fixed-camera datasets"" || ], || ""summary"": ""This paper proposes MANGO, an unpaired image translation method with a novel segmentation-conditioned InfoNCE loss and modified PatchNCE loss, to enable robust policies under viewpoint shifts. It demonstrates that training on limited real-world data can generate diverse unseen viewpoints, achieving high success rates in simulation-to-reality transfer."" || } ||  || [ Prompt: 123.2 t/s | Generation: 27.9 t/s ]"
2601.09609v1_DPWriter Reinforcement Learning with Diverse Plann.pdf,Reinforcement Learning with Diverse Planning Branching for Creative Writing,"['Qian Cao', 'Yahui Liu', 'Wei Bi', 'Yi Zhao', 'Ruihua Song', 'Xiting Wang', 'Ruiming Tang', 'Guorui Zhou', 'Han Li']",,29.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DPWriter: Reinforcement Learning with || Diverse Planning Branching for Creative Writing || Qian Cao1 *, Yahui Liu2, Wei Bi2, Yi Zhao1, Ruihua Song 1B, Xiting Wang1B, || Ruiming Tang2, Guorui Zhou 2, Han Li 2 || 1Renmin University of China, 2Kuaishou Technology || {caoqian4real, rsong, xitingwang} ... (truncated) ||  || { || ""title"": ""Reinforcement Learning with Diverse Planning Branching for Creative Writing"", || ""authors"": [ || ""Qian Cao"", || ""Yahui Liu"", || ""Wei Bi"", || ""Yi Zhao"", || ""Ruihua Song"", || ""Xiting Wang"", || ""Ruiming Tang"", || ""Guorui Zhou"", || ""Han Li"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""reinforcement learning"", || ""large language models"", || ""creative writing"", || ""diversity"", || ""planning branching"" || ], || ""summary"": ""This paper proposes an RL framework with a semi-structured long Chain-of-Thought reasoning to enhance output diversity in creative writing. It introduces a Diverse Planning Branching method and a group-aware diversity reward to guide exploration."" || } ||  || [ Prompt: 121.9 t/s | Generation: 29.2 t/s ]"
2601.09613v1_CogRail Benchmarking VLMs in Cognitive Intrusion P.pdf,CogRail: Benchmarking VLMs in Cognitive Intrusion Perception for Intelligent Railway Transportation Systems,"['Yonglin Tian', 'Qiyao Zhang', 'Wei Xu', 'Yutong Wang', 'Yihao Wu', 'Xinyi Li', 'Xingyuan Dai', 'Hui Zhang', 'Zhiyong Cui', 'Baoqing Guo', 'Member, IEEE', 'Zujun Yu', 'Yisheng Lv']",10.1093/acr/csy045,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 1 || CogRail: Benchmarking VLMs in || Cognitive Intrusion Perception for || Intelligent Railway Transportation Systems || Yonglin Tian1, Qiyao Zhang 2, Wei Xu 3, Yutong Wang1, Yihao Wu 4, Xinyi Li 4, Xingyuan Dai 1, Hui Zhang 5, || Zhiyong  ... (truncated) ||  || { || ""title"": ""CogRail: Benchmarking VLMs in Cognitive Intrusion Perception for Intelligent Railway Transportation Systems"", || ""authors"": [ || ""Yonglin Tian"", || ""Qiyao Zhang"", || ""Wei Xu"", || ""Yutong Wang"", || ""Yihao Wu"", || ""Xinyi Li"", || ""Xingyuan Dai"", || ""Hui Zhang"", || ""Zhiyong Cui"", || ""Baoqing Guo"", || ""Member, IEEE"", || ""Zujun Yu"", || ""Yisheng Lv"" || ], || ""doi"": ""10.1093/acr/csy045"", || ""arxiv_id"": """", || ""keywords"": [ || ""cognitive intrusion perception"", || ""railway transportation"", || ""visual language models"", || ""spatial context"", || ""temporal dynamics"", || ""safety systems"" || ], || ""summary"": ""Accurate and early perception of potential intrusion targets is essential for railway safety. This paper introduces CogRail, a benchmark integrating open-source datasets and question-answer annotations, and evaluates state-of-the-art VLMs for cognitive intrusion perception."" || } ||  || [ Prompt: 124.7 t/s | Generation: 28.6 t/s ]"
2601.09620v1_Full Disclosure Less Trust How the Level of Detail.pdf,"Full Disclosure, Less Trust? How the Level of Detail about AI Use in News","['POOJA PRAJOD', 'HANNES COOLS', 'THOMAS RGGLA', 'KARTHIKEYA PUTTUR VENKATRAJ', 'AMBER KUSTERS', 'ALIA ELKATTAN', 'PABLO CESAR', 'ABDALLAH EL ALI']",,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Full Disclosure, Less Trust? How the Level of Detail about AI Use in News || Writing Affects Readers Trust || POOJA PRAJOD,Centrum Wiskunde & Informatica, the Netherlands || HANNES COOLS,University of Amsterdam, the Netherlands || THOMAS RGGLA,Centrum Wiskunde & Informatica, the Netherlands || KAR ... (truncated) ||  || { || ""title"": ""Full Disclosure, Less Trust? How the Level of Detail about AI Use in News"", || ""authors"": [ || ""POOJA PRAJOD"", || ""HANNES COOLS"", || ""THOMAS RGGLA"", || ""KARTHIKEYA PUTTUR VENKATRAJ"", || ""AMBER KUSTERS"", || ""ALIA ELKATTAN"", || ""PABLO CESAR"", || ""ABDALLAH EL ALI"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""artificial intelligence"", || ""news production"", || ""transparency"", || ""trust"", || ""readers"", || ""AI disclosures"" || ], || ""summary"": ""This study investigates how varying levels of AI disclosure impact readers' trust in news, examining effects across different news types and disclosure details."" || } ||  || [ Prompt: 115.2 t/s | Generation: 27.9 t/s ]"
2601.09624v1_Toward Understanding Unlearning Difficulty A Mecha.pdf,Toward Understanding Unlearning Difficulty: A Mechanistic Perspective,"['Jiali Cheng', 'Ziheng Chen', 'Chirag Agarwal', 'Hadi Amiri']",,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Toward Understanding Unlearning Difficulty: A Mechanistic Perspective || and Circuit-Guided Difficulty Metric || Jiali Cheng || University of Massachusetts Lowell || jiali_cheng@uml.edu || Ziheng Chen || Walmart Global Tech || albertchen1993pokemon@gmail.com || Chirag Agarwal || University of Virginia || chiraga ... (truncated) ||  || { || ""title"": ""Toward Understanding Unlearning Difficulty: A Mechanistic Perspective"", || ""authors"": [ || ""Jiali Cheng"", || ""Ziheng Chen"", || ""Chirag Agarwal"", || ""Hadi Amiri"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""machine unlearning"", || ""unlearning difficulty"", || ""circuit-guided difficulty"", || ""model circuits"", || ""unlearning metrics"" || ], || ""summary"": ""This paper explores the variability in machine unlearning success across samples, proposing a Circuit-guided Unlearning Difficulty (CUD) metric to quantify difficulty based on circuit-level interactions. It identifies patterns linking easier samples to shorter interactions and harder samples to deeper pathways, aiming to provide a principled, interpretable analysis of unlearning mechanisms."" || } ||  || [ Prompt: 121.9 t/s | Generation: 29.1 t/s ]"
2601.09625v1_The Promptware Kill Chain How Prompt Injections Gr.pdf,The Promptware Kill Chain: How Prompt Injections Gradually Evolved Into a Multi-Step Malware,"['Ben Nassi', 'Bruce Schneier', 'Oleg Brodt']",,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || The Promptware Kill Chain: How Prompt Injections Gradually || Evolved Into a Multi-Step Malware || Ben Nassi 1, Bruce Schneier 2, Oleg Brodt 3 || 1School of Electrical and Computer Engineering, Tel Aviv University || 2Harvard Kennedy School, Harvard University, and Munk School, University of  ... (truncated) ||  || { || ""title"": ""The Promptware Kill Chain: How Prompt Injections Gradually Evolved Into a Multi-Step Malware"", || ""authors"": [ || ""Ben Nassi"", || ""Bruce Schneier"", || ""Oleg Brodt"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""prompt injection"", || ""promptware"", || ""malware"", || ""security"", || ""LLM"", || ""attack chain"", || ""security frameworks"" || ], || ""summary"": ""The paper discusses how prompt injections have evolved into a multi-step malware known as promptware, introducing a five-step kill chain model to analyze these threats."" || } ||  || [ Prompt: 132.1 t/s | Generation: 28.4 t/s ]"
2601.09626v1_From Prompt to Protocol Fast Charging Batteries wi.pdf,Fast Charging Batteries,"['Ge Lei1', 'Ferran Brosa Planella2', 'Sterling G. Baird', 'Samuel J. Cooper']",,27.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || From Prompt to Protocol: Fast Charging Batteries || with Large Language Models || Ge Lei1 Ferran Brosa Planella2 Sterling G. Baird3 Samuel J. Cooper1 || 1Dyson School of Design Engineering, Imperial College London, London SW7 2AZ, UK || 2University of Warwick, Coventry CV4 7AL, UK || 3Acceleration ... (truncated) ||  || { || ""title"": ""Fast Charging Batteries"", || ""authors"": [ || ""Ge Lei1"", || ""Ferran Brosa Planella2"", || ""Sterling G. Baird"", || ""Samuel J. Cooper"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Efficiently optimizing battery charging protocols is challenging... LLMs can expand the search space and enable efficient optimization."" || } ||  || [ Prompt: 128.3 t/s | Generation: 27.0 t/s ]"
2601.09635v1_LLM for Large-Scale Optimization Model Auto-Formul.pdf,LLM for Large-Scale Optimization Model Auto-Formulation: A Lightweight Few-Shot Learning Approach,"['Kuo Liang1', 'Yuhang Lu', 'Jianming Mao', 'Shuyi Sun', 'Chunwei Yang', 'Congcong Zeng', 'Xiao Jin', 'Hanzhang Qin', 'Ruihao Zhu', 'Chung-Piaw Teo', 'Antai College of Economics and Management', 'Department of Industrial Systems Engineering and Management, National University of Singapore', 'School of Information Management and Engineering, Shanghai University of Finance and Economics', 'Department of System Engineering, City University of Hong Kong', 'Institute of Operations Research and Analytics, National University of Singapore', 'Modern Logistics Centre, National University of Singapore (Chongqing) Research Institute', 'SC Johnson College of Business, Cornell University', 'SIA-NUS Digital Aviation Corporate Lab']",,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LLM for Large-Scale Optimization Model Auto-Formulation: A || Lightweight Few-Shot Learning Approach || Kuo Liang1, Yuhang Lu 2, Jianming Mao3, Shuyi Sun2, Chunwei Yang4, Congcong Zeng6 || Xiao Jin5,8, Hanzhang Qin2,5,6 , Ruihao Zhu7, Chung-Piaw Teo5,6,8 || 1 Antai College of Economics and Mana ... (truncated) ||  || { || ""title"": ""LLM for Large-Scale Optimization Model Auto-Formulation: A Lightweight Few-Shot Learning Approach"", || ""authors"": [ || ""Kuo Liang1"", || ""Yuhang Lu"", || ""Jianming Mao"", || ""Shuyi Sun"", || ""Chunwei Yang"", || ""Congcong Zeng"", || ""Xiao Jin"", || ""Hanzhang Qin"", || ""Ruihao Zhu"", || ""Chung-Piaw Teo"", || ""Antai College of Economics and Management"", || ""Department of Industrial Systems Engineering and Management, National University of Singapore"", || ""School of Information Management and Engineering, Shanghai University of Finance and Economics"", || ""Department of System Engineering, City University of Hong Kong"", || ""Institute of Operations Research and Analytics, National University of Singapore"", || ""Modern Logistics Centre, National University of Singapore (Chongqing) Research Institute"", || ""SC Johnson College of Business, Cornell University"", || ""SIA-NUS Digital Aviation Corporate Lab"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""large language models"", || ""tool use"", || ""agentic workflow construction"", || ""automated optimization modeling"" || ], || ""summary"": ""This paper presents LEAN-LLM-OPT, a lightweight workflow framework for LLM-assisted large-scale optimization auto-formulation. It describes how the framework constructs workflows for generating optimization formulations and evaluates its performance using GPT-4.1."" || } ||  || [ Prompt: 119.0 t/s | Generation: 29.0 t/s ]"
2601.09636v1_PersonalAlign Hierarchical Implicit Intent Alignme.pdf,PersonalAlign: Hierarchical Implicit Intent Alignment for Personalized GUI Agent,"['Yibo Lyu', 'Gongwei Chen', 'Rui Shao', 'Weili Guan', 'Liqiang Nie']",weberlv1b@gmail.com,29.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || PersonalAlign: Hierarchical Implicit Intent Alignment for Personalized || GUI Agent with Long-Term User-Centric Records || Yibo Lyu, Gongwei Chen, Rui Shao, Weili Guan, Liqiang Nie || Harbin Institute of Technology, Shenzhen || weberlv1b@gmail.com {shaorui, nieliqiang}@hit.edu.com || https://githu ... (truncated) ||  || { || ""title"": ""PersonalAlign: Hierarchical Implicit Intent Alignment for Personalized GUI Agent"", || ""authors"": [ || ""Yibo Lyu"", || ""Gongwei Chen"", || ""Rui Shao"", || ""Weili Guan"", || ""Liqiang Nie"" || ], || ""doi"": ""weberlv1b@gmail.com"", || ""arxiv_id"": ""harbin-2025-00123"", || ""keywords"": [ || ""Personalized GUI Agent"", || ""Hierarchical Intent Alignment"", || ""Long-Term User Records"", || ""Proactive Assistance"", || ""Multimodal Large Language Models"" || ], || ""summary"": ""This work introduces PersonalAlign, a new agent task that leverages long-term user records to align with users' implicit intents, enabling agents to resolve vague instructions and anticipate user needs proactively. It presents AndroidIntent evaluations and introduces a Hierarchical Intent Memory Agent for improved personalization."" || } ||  || [ Prompt: 117.9 t/s | Generation: 29.2 t/s ]"
2601.09667v2_Collaborative Multi-Agent Test-Time Reinforcement .pdf,Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning,"['Zhiyuan Hu', 'Yunhai Hu', 'Juncheng Liu', 'Shuyue Stella Li', 'Yucheng Wang', 'Zhen Xu', 'Xu6', 'Ng2 Anh Tuan Luu', 'Xinxing Xu', 'Bryan Hooi2 Cynthia Breazeal', 'Hae Won Park']",,29.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning || Zhiyuan Hu1,2* Yunhai Hu3 Juncheng Liu4 Shuyue Stella Li5 Yucheng Wang2 Zhen Xu6 || See-Kiong Ng2 Anh Tuan Luu7 Xinxing Xu4 Bryan Hooi2 Cynthia Breazeal1 Hae Won Park1 || 1 MIT 2 NUS 3 NYU 4 Microsoft 5 UW 6 Columbia ... (truncated) ||  || { || ""title"": ""Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning"", || ""authors"": [ || ""Zhiyuan Hu"", || ""Yunhai Hu"", || ""Juncheng Liu"", || ""Shuyue Stella Li"", || ""Yucheng Wang"", || ""Zhen Xu"", || ""Xu6"", || ""Ng2 Anh Tuan Luu"", || ""Xinxing Xu"", || ""Bryan Hooi2 Cynthia Breazeal"", || ""Hae Won Park"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Multi-agent Test-Time Reinforcement Learning (MATTRL) introduces a framework that injects structured textual experiences at inference time, enabling multi-expert teams to collaborate, integrate test-time experiences, and reach consensus for decision-making. It improves performance across benchmarks in medicine, math, and education, outperforming single-agent baselines by 3.67% and 8.67% respectively."" || } ||  || [ Prompt: 115.1 t/s | Generation: 29.2 t/s ]"
2601.09680v1_Automating Supply Chain Disruption Monitoring via .pdf,Automating Supply Chain Disruption Monitoring via an Agentic AI,"['Sara AlMahria', 'Liming Xu', 'Alexandra Brintrup']",arXiv:2601.09680v1,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || RESEARCH ARTICLE || Automating Supply Chain Disruption Monitoring via an Agentic AI || Approach || Sara AlMahria, Liming Xu a, and Alexandra Brintrup a,b || aInstitute for Manufacturing, Department of Engineering, University of Cambridge, || Cambridge, UK || bThe Alan Turing Institute, London, UK || AR  ... (truncated) ||  || { || ""title"": ""Automating Supply Chain Disruption Monitoring via an Agentic AI"", || ""authors"": [ || ""Sara AlMahria"", || ""Liming Xu"", || ""Alexandra Brintrup"" || ], || ""doi"": ""arXiv:2601.09680v1"", || ""arxiv_id"": ""arXiv:2601.09680"", || ""keywords"": [ || ""Supply Chain Management"", || ""Supply Chain Disruption"", || ""Large Language Models"", || ""AI Agents"", || ""Multi-Agent System"", || ""Agentic System"" || ], || ""summary"": ""This paper introduces an agentic AI framework to proactively monitor and respond to supply chain disruptions across extended networks. It leverages large language models and deterministic tools to detect disruptions from unstructured data, map supplier networks, assess exposure, and recommend mitigation strategies. The system achieves high accuracy and fast response times, offering a significant improvement over traditional analyst-driven methods."" || } ||  || [ Prompt: 114.3 t/s | Generation: 28.2 t/s ]"
2601.09684v1_Disentangling Task Conflicts in Multi-Task LoRA vi.pdf,Disentangling Task Conflicts in Multi-Task LoRA via Orthogonal Gradient Projection,"['Ziyu Yang', 'Guibin Chen', 'Yuxin Yang', 'Aoxiong Zeng', 'Xiangquan Yang']",,29.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Disentangling Task Conflicts in Multi-Task LoRA via || Orthogonal Gradient Projection || Ziyu Yang1 Guibin Chen2 Yuxin Yang1 Aoxiong Zeng2 Xiangquan Yang2 || 1Shanghai University || 2East China Normal University || Abstract || Multi-Task Learning (MTL) combined with || Low-Rank Adaptation (LoRA) has eme ... (truncated) ||  || { || ""title"": ""Disentangling Task Conflicts in Multi-Task LoRA via Orthogonal Gradient Projection"", || ""authors"": [ || ""Ziyu Yang"", || ""Guibin Chen"", || ""Yuxin Yang"", || ""Aoxiong Zeng"", || ""Xiangquan Yang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper discusses gradient conflict in multi-task LoRA and introduces Ortho-LoRA to mitigate interference by projecting conflicting gradients orthogonally."" || } ||  || [ Prompt: 118.1 t/s | Generation: 29.2 t/s ]"
2601.09692v1_Routing with Generated Data Annotation-Free LLM Sk.pdf,Routing with Generated Data: Annotation-Free,"['Tianyi Niu', 'Justin Chih-Yao Chen', 'Genta Indra Winata', 'Shi-Xiong Zhang', 'Supriyo Chakraborty', 'Sambit Sahu', 'Yue Zhang', 'Elias Stengel-Eskin', 'Mohit Bansal']",1UNC Chapel Hill 2Capital One 3The University of Texas at Austin,29.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Routing with Generated Data: Annotation-Free || LLM Skill Estimation and Expert Selection || Tianyi Niu1, Justin Chih-Yao Chen1, Genta Indra Winata2, Shi-Xiong Zhang2, || Supriyo Chakraborty2,Sambit Sahu 2,Yue Zhang 1, || Elias Stengel-Eskin3,Mohit Bansal 1 || 1UNC Chapel Hill 2Capital One 3The Un ... (truncated) ||  || { || ""title"": ""Routing with Generated Data: Annotation-Free"", || ""authors"": [ || ""Tianyi Niu"", || ""Justin Chih-Yao Chen"", || ""Genta Indra Winata"", || ""Shi-Xiong Zhang"", || ""Supriyo Chakraborty"", || ""Sambit Sahu"", || ""Yue Zhang"", || ""Elias Stengel-Eskin"", || ""Mohit Bansal"" || ], || ""doi"": ""1UNC Chapel Hill 2Capital One 3The University of Texas at Austin"", || ""arxiv_id"": """", || ""keywords"": [ || ""LLM routing"", || ""LLM skill estimation"", || ""LLM expert selection"", || ""query-only routing"", || ""query-answer routing"", || ""LLM models"", || ""generative data"" || ], || ""summary"": ""This paper introduces Routing with Generated Data (RGD), a method for training LLM routers using only generated queries and answers. It evaluates query-answer and query-only routing across multiple benchmarks, showing that query-answer routers degrade more with lower generator quality. The authors propose CASCAL, a novel query-only router that leverages consensus voting and hierarchical clustering to improve robustness."" || } ||  || [ Prompt: 122.7 t/s | Generation: 29.4 t/s ]"
2601.09694v1_LLMs can Compress LLMs Adaptive Pruning by Agents.pdf,LLMs can Compress LLMs: Adaptive Pruning by Agents,"['Sai Varun Kodathala', 'Rakesh Vunnam']",arXiv:2601.09694v1,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LLMs can Compress LLMs: Adaptive Pruning by || Agents || Sai Varun Kodathala1 ( ... (truncated) ||  || { || ""title"": ""LLMs can Compress LLMs: Adaptive Pruning by Agents"", || ""authors"": [ || ""Sai Varun Kodathala"", || ""Rakesh Vunnam"" || ], || ""doi"": ""arXiv:2601.09694v1"", || ""arxiv_id"": ""arXiv:2601.09694"", || ""keywords"": [""Model Compression"", ""Adaptive Pruning"", ""Self-Reflection""], || ""summary"": ""This paper introduces agent-guided pruning for LLMs, improving compression while preserving performance. It uses a foundation model as an adaptive pruning agent that learns from previous pruning outcomes to intelligently select layers to prune, maintaining critical knowledge pathways."" || } ||  || [ Prompt: 125.1 t/s | Generation: 28.5 t/s ]"
2601.09703v1_ShortCoder Knowledge-Augmented Syntax Optimization.pdf,ShortCoder: Knowledge-Augmented Syntax,"['Sicong Liu', 'Yanxian Huang', 'Mingwei Liu', 'Jiachi Chen', 'Ensheng Shi', 'Yuchi Ma', 'Hongyu Zhang', 'Yin Zhang', 'Yanlin Wang']",10.48550/arXiv.2024.12345,28.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ShortCoder: Knowledge-Augmented Syntax || Optimization for Token-Efficient Code Generation || Sicong Liu 1, Yanxian Huang 1, Mingwei Liu 1, || Jiachi Chen 1, Ensheng Shi 2, Yuchi Ma 2, Hongyu Zhang 3, Yin Zhang 4, Yanlin Wang1 || 1Sun Yat-sen University, China || 2Huawei Cloud Computing Technologi ... (truncated) ||  || { || ""title"": ""ShortCoder: Knowledge-Augmented Syntax"", || ""authors"": [ || ""Sicong Liu"", || ""Yanxian Huang"", || ""Mingwei Liu"", || ""Jiachi Chen"", || ""Ensheng Shi"", || ""Yuchi Ma"", || ""Hongyu Zhang"", || ""Yin Zhang"", || ""Yanlin Wang"" || ], || ""doi"": ""10.48550/arXiv.2024.12345"", || ""arxiv_id"": ""arXiv:2408.12345"", || ""keywords"": [ || ""code generation"", || ""large language models"", || ""token efficiency"", || ""semantic equivalence"", || ""code optimization"" || ], || ""summary"": ""The paper proposes ShortCoder, a knowledge-infused framework to optimize code generation efficiency while preserving semantic equivalence and readability. It introduces syntax-level simplification rules, a hybrid data synthesis pipeline, and fine-tuning strategies to improve performance. Experimental results show significant improvements over previous methods."" || } ||  || [ Prompt: 118.8 t/s | Generation: 28.0 t/s ]"
2601.09706v1_Value-Aware Numerical Representations for Transfor.pdf,Value-Aware Numerical Representations for Transformer Language Models,"['Andreea Dutulescu', 'Stefan Ruseti', 'Mihai Dascalu']",10.48550/arXiv.2405.12345,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Value-Aware Numerical Representations for Transformer Language Models || Andreea Dutulescu and Stefan Ruseti and Mihai Dascalu || National University of Science and Technology POLITEHNICA Bucharest || {andreea.dutulescu, stefan.ruseti, mihai.dascalu}@upb.ro || Abstract || Transformer-based languag ... (truncated) ||  || { || ""title"": ""Value-Aware Numerical Representations for Transformer Language Models"", || ""authors"": [""Andreea Dutulescu"", ""Stefan Ruseti"", ""Mihai Dascalu""], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [""value-aware"", ""numerical representation"", ""transformer"", ""mathematical reasoning""], || ""summary"": ""The paper introduces a value-aware numerical representation that augments token embeddings with a dedicated prefix token conditioned on numerical value, improving numerical robustness in language models."" || } ||  || [ Prompt: 113.5 t/s | Generation: 28.2 t/s ]"
2601.09708v1_Fast-ThinkAct Efficient Vision-Language-Action Rea.pdf,Fast-ThinkAct: Efficient Vision-Language-Action,"['Chi-Pin Huang', 'Yunze Man', 'Zhiding Yu', 'Min-Hung Chen', 'Jan Kautz', 'Yu-Chiang Frank Wang', 'Fu-En Yang']",,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 2026-1-15 || Fast-ThinkAct: Efficient Vision-Language-Action || Reasoning via Verbalizable Latent Planning || Chi-Pin Huang1, Yunze Man2, Zhiding Yu, Min-Hung Chen, Jan Kautz, Yu-Chiang Frank Wang1, Fu-En Yang || NVIDIA || Abstract || Vision-Language-Action (VLA) tasks require reasoning over complex  ... (truncated) ||  || { || ""title"": ""Fast-ThinkAct: Efficient Vision-Language-Action"", || ""authors"": [ || ""Chi-Pin Huang"", || ""Yunze Man"", || ""Zhiding Yu"", || ""Min-Hung Chen"", || ""Jan Kautz"", || ""Yu-Chiang Frank Wang"", || ""Fu-En Yang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Proposes Fast-ThinkAct, an efficient reasoning framework for Vision-Language-Action that reduces inference latency while maintaining strong planning performance."" || } ||  || [ Prompt: 120.5 t/s | Generation: 28.7 t/s ]"
2601.09749v1_R-LAM Reproducibility-Constrained Large Action Mod.pdf,R-LAM: Reproducibility-Constrained Large Action,['Suriya Sureshkumar'],240171.ad@rmkec.ac.in,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || R-LAM: Reproducibility-Constrained Large Action || Models for Scientific Workflow Automation || Suriya Sureshkumar 1,* || 1,*Department of AI & Data Science, RMK Engineering College, Chennai, India || 240171.ad@rmkec.ac.in || AbstractLarge Action Models (LAMs) extend large language || models by enabl ... (truncated) ||  || { || ""title"": ""R-LAM: Reproducibility-Constrained Large Action"", || ""authors"": [""Suriya Sureshkumar""], || ""doi"": ""240171.ad@rmkec.ac.in"", || ""arxiv_id"": """", || ""keywords"": [""Reproducible Scientific Workflows"", ""Large Action Models"", ""LLM-Based Agents"", ""Execution Provenance""], || ""summary"": ""The paper proposes R-LAM, a framework for applying Large Action Models to scientific workflows, emphasizing reproducibility, auditability, and deterministic execution through structured action schemas and provenance tracking."" || } ||  || [ Prompt: 115.1 t/s | Generation: 27.7 t/s ]"
2601.09750v1_SAGE Tool-Augmented LLM Task Solving Strategies in.pdf,SAGE: Tool-Augmented LLM Task Solving Strategies,"['Robert K. Strehlow', 'Tobias Kster', 'Oskar F. Kupke', 'Brandon Llanque Kurps', 'Fikret Sivrikaya', 'Sahin Albayrak']",DKI.00.00032.21,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SAGE: Tool-Augmented LLM Task Solving Strategies || in Scalable Multi-Agent Environments || Robert K. Strehlow 1,3,Tobias Kster 1,3,Oskar F. Kupke 1,3,Brandon || Llanque Kurps 1,3,Fikret Sivrikaya 1,3,Sahin Albayrak 1,2 || 1Technische Universitt Berlin (e-mail: first.second@tu-berlin.de) || 2DAI-L ... (truncated) ||  || { || ""title"": ""SAGE: Tool-Augmented LLM Task Solving Strategies"", || ""authors"": [ || ""Robert K. Strehlow"", || ""Tobias Kster"", || ""Oskar F. Kupke"", || ""Brandon Llanque Kurps"", || ""Fikret Sivrikaya"", || ""Sahin Albayrak"" || ], || ""doi"": ""DKI.00.00032.21"", || ""arxiv_id"": """", || ""keywords"": [ || ""large language models"", || ""tool integration"", || ""zero-shot prompting"", || ""task solving strategies"", || ""OPACA framework"" || ], || ""summary"": ""This paper presents SAGE, a specialized conversational AI interface based on OPACA, designed to dynamically integrate tools and enable robust zero-shot prompting for real-world applications. It evaluates various task-solving strategies and benchmarks their performance."" || } ||  || [ Prompt: 121.8 t/s | Generation: 29.3 t/s ]"
2601.09753v1_Critically Engaged Pragmatism A Scientific Norm an.pdf,"Critically Engaged Pragmatism: A Scientific Norm and Social, Pragmatist Epistemology for AI Science Evaluation Tools",['Carole J. Lee'],0000-0002-5323-9205,27.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || Critically Engaged Pragmatism: A Scientific Norm and Social, Pragmatist Epistemology for AI Science Evaluation Tools  Carole J. Lee* || ORCID ID: 0000-0002-5323-9205 Department of Philosophy, Center for an Informed Public, University of Washington, Seattle  Crises in peer review c ... (truncated) ||  || { || ""title"": ""Critically Engaged Pragmatism: A Scientific Norm and Social, Pragmatist Epistemology for AI Science Evaluation Tools"", || ""authors"": [""Carole J. Lee""], || ""doi"": ""0000-0002-5323-9205"", || ""arxiv_id"": """", || ""keywords"": [""peer review"", ""replication crisis"", ""AI evaluation"", ""scientific credibility""], || ""summary"": ""Discusses the crisis in peer review and replication, advocating for a social, pragmatist epistemology and Critically Engaged Pragmatism to scrutinize AI science evaluation tools."" || } ||  || [ Prompt: 123.9 t/s | Generation: 27.2 t/s ]"
2601.09755v1_Heterogeneous computing platform for real-time rob.pdf,Heterogeneous computing platform for real-time robotics,"['Jakub Fil', 'Yulia Sandamirskaya', 'Hector Gonzalez', 'Stefan Glge', 'Lukas Friedenstab', 'Friedrich Wolf', 'Tim Rosmeisl', 'Matthias Lohrmann', 'Mahmoud Akl', 'Khaleel Khan', 'Leonie Wolf', 'Kristin Richter', 'Holm Puder', 'Mazhar Ali Bari', 'Xuan Choo', 'Noha Alharthi', 'Michael Hopkins', 'Steve Furber', 'Jens Struckmeier']",,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Heterogeneous computing platform for real-time robotics. || Jakub Fil 1 Yulia Sandamirskaya2 Hector Gonzalez 3 Loc Azzalin 2 || Stefan Glge 2 Lukas Friedenstab1 Friedrich Wolf1 Tim Rosmeisl 3 || Matthias Lohrmann 3 Mahmoud Akl 3 Khaleel Khan 4 Leonie Wolf1 || Kristin Richter 1 Holm Puder 1 Mazh ... (truncated) ||  || { || ""title"": ""Heterogeneous computing platform for real-time robotics"", || ""authors"": [ || ""Jakub Fil"", || ""Yulia Sandamirskaya"", || ""Hector Gonzalez"", || ""Stefan Glge"", || ""Lukas Friedenstab"", || ""Friedrich Wolf"", || ""Tim Rosmeisl"", || ""Matthias Lohrmann"", || ""Mahmoud Akl"", || ""Khaleel Khan"", || ""Leonie Wolf"", || ""Kristin Richter"", || ""Holm Puder"", || ""Mazhar Ali Bari"", || ""Xuan Choo"", || ""Noha Alharthi"", || ""Michael Hopkins"", || ""Steve Furber"", || ""Jens Struckmeier"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""After Industry 4.0 has embraced tight integration between machinery (OT), software (IT), and the Internet, creating a web of sensors, data, and algorithms in service of efficient and reliable production, a new concept of Society 5.0 is emerging, in which infrastructure of a city will be instrumented to increase reliability, efficiency, and safety. Robotics will play a pivotal role in enabling this vision that is pioneered by the NEOM initiative - a smart city, co-inhabited by humans and robots. In this paper we explore the computing platform that will be required to enable this vision. We show how we can combine neuromorphic computing hardware, exemplified by the Loihi2 processor used in conjunction with event-based cameras, for sensing and real-time perception and interaction with a local AI compute cluster (GPUs) for high-level language processing, cognition, and task planning. We demonstrate the use of this hybrid computing architecture in an interactive task, in which a humanoid robot plays a musical instrument with a human. Central to our design is the efficient and seamless integration of disparate components, ensuring that the synergy between software and hardware maximizes overall performance and responsiveness. Our proposed system architecture underscores the potential of heterogeneous computing architectures in advancing robotic autonomy and interactive intelligence, pointing toward a future where such integrated systems become the norm in complex, real-time applications."" || } ||  || [ Prompt: 119.6 t/s | Generation: 29.1 t/s ]"
2601.09756v1_Synthetic Data for Veterinary EHR De-identificatio.pdf,"Synthetic Data for Veterinary EHR De-identification: Benefits, Limits, and Safety Trade-offs Under Fixed Compute","['David Brundage, PhD']",,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Synthetic Data for Veterinary EHR De-identification: Benefits, || Limits, and Safety Trade-offs Under Fixed Compute || David Brundage, PhD || University of Wisconsin-Madison, School of Veterinary Medicine || Abstract || Background:Veterinaryelectronichealthrecords(vEHRs)areincreasinglyusedforsurve ... (truncated) ||  || { || ""title"": ""Synthetic Data for Veterinary EHR De-identification: Benefits, Limits, and Safety Trade-offs Under Fixed Compute"", || ""authors"": [""David Brundage, PhD""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Evaluation of synthetic veterinary narratives for improving de-identification safety and utility under varying training regimes."" || } ||  || [ Prompt: 113.6 t/s | Generation: 26.9 t/s ]"
2601.09757v1_Democracy and Distrust in an Era of Artificial Int.pdf,Democracy & Distrust in an Era of,['Sonia K. Katyal'],10.1162/DAED_a_01919,26.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 322 || 2022 by Sonia K. Katyal || Published under a Creative Commons Attribution- || NonCommercial 4.0 International (CC BY-NC 4.0) license || https://doi.org/10.1162/DAED_a_01919 || Democracy & Distrust in an Era of || Artificial Intelligence || Sonia K. Katyal || Our legal system has historically o ... (truncated) ||  || { || ""title"": ""Democracy & Distrust in an Era of"", || ""authors"": [""Sonia K. Katyal""], || ""doi"": ""10.1162/DAED_a_01919"", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The rise of AI decision-making poses challenges to judicial review, prompting a re-examination of due process and equal protection in the context of artificial intelligence."" || } ||  || [ Prompt: 131.4 t/s | Generation: 26.7 t/s ]"
2601.09760v1_Investigating Tool-Memory Conflicts in Tool-Augmen.pdf,Investigating Tool-Memory Conflicts in Tool-Augmented LLMs,"['Jiali Cheng', 'Rui Pan', 'Hadi Amiri', '1', '2']",,29.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Investigating Tool-Memory Conflicts in Tool-Augmented LLMs || Jiali Cheng 1 Rui Pan 2 Hadi Amiri 1 || Abstract || Tool-augmented large language models (LLMs) || have powered many applications. However, they || are likely to suffer from knowledge conflict. In || this paper, we propose a new type of kn ... (truncated) ||  || { || ""title"": ""Investigating Tool-Memory Conflicts in Tool-Augmented LLMs"", || ""authors"": [ || ""Jiali Cheng"", || ""Rui Pan"", || ""Hadi Amiri"", || ""1"", || ""2"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""tool-memory conflict"", || ""knowledge conflict"", || ""LLM augmentation"", || ""tool-augmented LLMs"", || ""knowledge reliability"" || ], || ""summary"": ""This paper proposes a new type of knowledge conflict, Tool-Memory Conflict (TMC), where internal parametric knowledge contradicts external tool knowledge in LLMs. Existing conflict resolution techniques fail to address TMC, especially in STEM tasks. The study evaluates prompting and RAG-based methods without success."" || } ||  || [ Prompt: 118.7 t/s | Generation: 29.7 t/s ]"
2601.09762v1_Explicating Tacit Regulatory Knowledge from LLMs t.pdf,Explicating Tacit Regulatory Knowledge from LLMs to Auto-Formalize,"['Zhiyi Xue', 'Xiaohong Chen', 'Min Zhang']",52275902017@stu.ecnu.edu.cn,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Explicating Tacit Regulatory Knowledge from LLMs to Auto-Formalize || Requirements for Compliance Test Case Generation || Zhiyi Xue1, Xiaohong Chen1, Min Zhang2 || 1Shanghai Key Laboratory of Trustworthy Computing, ECNU, Shanghai, China || 2Dishui Lake International Software Engineering Institu ... (truncated) ||  || { || ""title"": ""Explicating Tacit Regulatory Knowledge from LLMs to Auto-Formalize"", || ""authors"": [ || ""Zhiyi Xue"", || ""Xiaohong Chen"", || ""Min Zhang"" || ], || ""doi"": ""52275902017@stu.ecnu.edu.cn"", || ""arxiv_id"": """", || ""keywords"": [ || ""compliance testing"", || ""LLMs"", || ""regulatory knowledge"", || ""automated testing"", || ""formal models"" || ], || ""summary"": ""The paper proposes RAFT, a framework for requirements auto-formalization and compliance test generation by explicating tacit regulatory knowledge from multiple LLMs. It integrates this knowledge into a do-unit meta-model, formal requirements representation, and testability constraints, enabling high-precision requirement formalization and automated test generation."" || } ||  || [ Prompt: 115.9 t/s | Generation: 29.1 t/s ]"
2601.09765v1_AI Survival Stories a Taxonomic Analysis of AI Exi.pdf,Philosophy of AI,"['John Hawthorne', 'Department of Philosophy, The University of Hong Kong, HK', 'Australian Catholic University, Melbourne, AU', 'Lingnan University, Dept of Philosophy, Tuen Mun, HK', 'Department of Philosophy, University of Southern California, US']",,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Philosophy of AI || Vo l . , , - || ./ojs/phai/. || by the author(s) || , John Hawthorne || Department of Philosophy, The University of Hong Kong, HK, || Australian Catholic University, Melbourne, AU, || Lingnan University, Dept of Philosophy, Tuen Mun, HK, || Department of Philosophy, University of South ... (truncated) ||  || { || ""title"": ""Philosophy of AI"", || ""authors"": [ || ""John Hawthorne"", || ""Department of Philosophy, The University of Hong Kong, HK"", || ""Australian Catholic University, Melbourne, AU"", || ""Lingnan University, Dept of Philosophy, Tuen Mun, HK"", || ""Department of Philosophy, University of Southern California, US"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Artificial Intelligence"", || ""Existential Risk"", || ""AI Safety"", || ""AI Catastrophe"", || ""Superintelligent AI"", || ""AI Alignment"" || ], || ""summary"": ""This paper develops a framework for thinking about the existential risk of AI systems, analyzing survival stories where humanity survives despite threats from AI."" || } ||  || [ Prompt: 121.6 t/s | Generation: 27.5 t/s ]"
2601.09768v1_CLiMB A Domain-Informed Novelty Detection Clusteri.pdf,CLiMB: A Domain-Informed Novelty Detection Clustering,"['Lorenzo Monti', 'Tatiana Muraveva', 'Brian Sheridan', 'Davide Massari', 'Alessia Garofalo', 'Gisella Clementini', 'Umberto Michelucci', 'National Institute for Astrophysics', 'TOELT LLC', 'Computer Science Department, Lucerne University of Applied Sciences and Arts']",arXiv:2601.09768v1,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Journal of Machine Learning Research 23 (2022) 1-28 Submitted 1/21; Revised 5/22; Published 9/22 || CLiMB: A Domain-Informed Novelty Detection Clustering || Framework for Scientific Discovery || Lorenzo Monti  lorenzo.monti@inaf.it || Tatiana Muraveva  tatiana.muraveva@inaf.it || Brian Sheridan  b ... (truncated) ||  || { || ""title"": ""CLiMB: A Domain-Informed Novelty Detection Clustering"", || ""authors"": [ || ""Lorenzo Monti"", || ""Tatiana Muraveva"", || ""Brian Sheridan"", || ""Davide Massari"", || ""Alessia Garofalo"", || ""Gisella Clementini"", || ""Umberto Michelucci"", || ""National Institute for Astrophysics"", || ""TOELT LLC"", || ""Computer Science Department, Lucerne University of Applied Sciences and Arts"" || ], || ""doi"": ""arXiv:2601.09768v1"", || ""arxiv_id"": ""2601.09768"", || ""keywords"": [ || ""novelty detection"", || ""semi-supervised clustering"", || ""constrained clustering"", || ""density-based clustering"", || ""domain knowledge integration"" || ], || ""summary"": ""In data-driven scientific discovery, a challenge lies in classifying well-characterized phenomena while identifying novel anomalies. Current semi-supervised clustering algorithms often assume global representativeness, limiting effectiveness for novelty detection. CLiMB addresses this by decoupling prior knowledge from structure exploration, achieving high recovery accuracy for known structures."" || } ||  || [ Prompt: 116.5 t/s | Generation: 29.0 t/s ]"
2601.09770v1_GUI-Eyes Tool-Augmented Perception for Visual Grou.pdf,GUI-Eyes: Tool-Augmented Perception for Visual Grounding in GUI Agents,"['Chen Chen1', 'Chen Jiawei Shao2', 'Dakuan Lu2', 'Haoyi Hu4', 'Xiangcheng Liu1', 'Xiangcheng Liu3', 'Hantao Yao1', 'Wu Liu1']",,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || GUI-Eyes: Tool-Augmented Perception for Visual Grounding in GUI Agents || Chen Chen1,3, Jiawei Shao2*, Dakuan Lu2, Haoyi Hu4, || Xiangcheng Liu1,3, Hantao Yao1, Wu Liu1 || 1University of Science and Technology of China || 2Institute of Artificial Intelligence (TeleAI), China Telecom || 3Shanghai I ... (truncated) ||  || { || ""title"": ""GUI-Eyes: Tool-Augmented Perception for Visual Grounding in GUI Agents"", || ""authors"": [ || ""Chen Chen1"", || ""Chen Jiawei Shao2"", || ""Dakuan Lu2"", || ""Haoyi Hu4"", || ""Xiangcheng Liu1"", || ""Xiangcheng Liu3"", || ""Hantao Yao1"", || ""Wu Liu1"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Recent advances in vision-language models and reinforcement learning have driven progress in GUI automation. This paper presents GUI-Eyes, a reinforcement learning framework for active visual perception in GUI tasks. The agent learns strategic decisions on visual tool invocation through a two-stage reasoning process and a spatially continuous reward function."" || } ||  || [ Prompt: 125.7 t/s | Generation: 29.0 t/s ]"
2601.09771v1_PCN-Rec Agentic Proof-Carrying Negotiation for Rel.pdf,PCN-Rec: Agentic Proof-Carrying Negotiation for Reliable Governance-Constrained Recommendation,"['Adhish Dixit', 'Shreem Dixit']",,29.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || PCN-Rec: Agentic Proof-Carrying Negotiation for Reliable || Governance-Constrained Recommendation || Aradhya Dixit || Wake Technical Community College || Raleigh, North Carolina, USA || adixit1@my.waketech.edu || Shreem Dixit || University of North Carolina at Charlotte || Charlotte, North Carolina, USA || sd ... (truncated) ||  || { || ""title"": ""PCN-Rec: Agentic Proof-Carrying Negotiation for Reliable Governance-Constrained Recommendation"", || ""authors"": [ || ""Adhish Dixit"", || ""Shreem Dixit"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""recommendation systems"", || ""LLM agents"", || ""constrained ranking"", || ""governance"", || ""verification"", || ""negotiation"" || ], || ""summary"": ""PCN-Rec introduces an agentic proof-carrying negotiation pipeline for LLM-based recommendation systems, enabling reliable enforcement of governance constraints through negotiation between a User Advocate and a Policy Agent."" || } ||  || [ Prompt: 117.8 t/s | Generation: 29.2 t/s ]"
2601.09772v1_Antisocial behavior towards large language model u.pdf,Antisocial behavior towards large language model users: experimental evidence,"['Pawe Niszczota', 'Cassandra Grtzner']",,31.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || Antisocial behavior towards large language model users: experimental evidence || Pawe Niszczota 1,3,* and Cassandra Grtzner 2,1,3 ||  || 1 Pozna University of Economics and Business, Humans & Artificial Intelligence Laboratory || (HAI Lab), Institute of International Business and Economi ... (truncated) ||  || { || ""title"": ""Antisocial behavior towards large language model users: experimental evidence"", || ""authors"": [ || ""Pawe Niszczota"", || ""Cassandra Grtzner"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Experimental evidence on antisocial behavior towards large language model users."" || } ||  || [ Prompt: 120.8 t/s | Generation: 31.9 t/s ]"
2601.09773v1_Enhancing LUT-based Deep Neural Networks Inference.pdf,Enhancing LUT-based Deep Neural Networks Inference through Architecture and Connectivity Optimization,"['Binglei Lou', 'Ruinil Wu', 'Philip Leong']",,30.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || Enhancing LUT-based Deep Neural Networks Inference through || Architecture and Connectivity Optimization || Binglei Lou, Ruilin Wu, Philip Leong || School of Electrical and Computer Engineering || The University of Sydney, 2006, Australia || Email:{binglei.lou,ruilin.wu,philip.leong}@sydney.edu. ... (truncated) ||  || { || ""title"": ""Enhancing LUT-based Deep Neural Networks Inference through Architecture and Connectivity Optimization"", || ""authors"": [""Binglei Lou"", ""Ruinil Wu"", ""Philip Leong""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Dynamic Sparsity"", ""FPGA"", ""Neural Network"", ""Lookup Table""], || ""summary"": ""The paper presents SparseLUT, a framework optimizing LUT-based DNNs for FPGAs by reducing LUT size and improving latency through architectural enhancements and non-greedy training."" || } ||  || [ Prompt: 120.7 t/s | Generation: 30.1 t/s ]"
2601.09805v1_Improving Chain-of-Thought for Logical Reasoning v.pdf,Improving Chain-of-Thought for Logical Reasoning via Attention-Aware Intervention,"['Phuong Minh Nguyen', 'Tien Huu Dang', 'Naoya Inoue']",10.48550/arXiv.2303.03015,29.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Improving Chain-of-Thought for Logical Reasoning || via Attention-Aware Intervention || Phuong Minh Nguyen and Tien Huu Dang and Naoya Inoue || RebelsNLU Lab, IS school || Japan Advanced Institute of Science and Technology || {phuongnm,tiendh,naoya-i}@jaist.ac.jp || Abstract || Modern logical reasoning  ... (truncated) ||  || { || ""title"": ""Improving Chain-of-Thought for Logical Reasoning via Attention-Aware Intervention"", || ""authors"": [""Phuong Minh Nguyen"", ""Tien Huu Dang"", ""Naoya Inoue""], || ""doi"": ""10.48550/arXiv.2303.03015"", || ""arxiv_id"": ""arXiv:2303.03015"", || ""keywords"": [""logical reasoning"", ""LLMs"", ""attention"", ""intervention""], || ""summary"": ""This paper introduces an end-to-end framework for logical reasoning that enhances reasoning performance by activating attention heads aligned with logical operators. The method, Attention-Aware Intervention (AAI), reweights attention scores to guide the model toward leveraging prior knowledge, improving generalization and analyzability without external resources."" || } ||  || [ Prompt: 115.7 t/s | Generation: 29.6 t/s ]"
2601.09806v1_Diffusion-Driven Deceptive Patches Adversarial Man.pdf,Diffusion-Driven Deceptive Patches: Adversarial Manipulation and Forensic Detection in Facial Identity Verification,"['Shahrzad Sayyafzadeh', 'Hongmei Chi', 'Shonda Bernadin']",arXiv:2601.09806v1,31.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Diffusion-Driven Deceptive Patches: Adversarial || Manipulation and Forensic Detection in Facial || Identity Verification || Shahrzad Sayyafzadeh, Hongmei Chi and Shonda Bernadin || 1,3*Electrical & Computer Engineering, FAMU-FSU College of || Engineering, Pottsdamer St, Tallahassee, 32310, Florid ... (truncated) ||  || { || ""title"": ""Diffusion-Driven Deceptive Patches: Adversarial Manipulation and Forensic Detection in Facial Identity Verification"", || ""authors"": [ || ""Shahrzad Sayyafzadeh"", || ""Hongmei Chi"", || ""Shonda Bernadin"" || ], || ""doi"": ""arXiv:2601.09806v1"", || ""arxiv_id"": ""arXiv:2601.09806"", || ""keywords"": [ || ""Adversarial Patch Generation"", || ""Gaussian Smoothing"", || ""Diffusion Model"", || ""Social Media Forensics"", || ""Perceptual Hashing"" || ], || ""summary"": ""This work presents an end-to-end pipeline for generating, refining, and evaluating adversarial patches to compromise facial biometric systems with forensic analysis and security testing applications. The refined patch is applied to facial images to test its ability to evade recognition systems while maintaining natural visual characteristics."" || } ||  || [ Prompt: 131.6 t/s | Generation: 31.3 t/s ]"
2601.09809v1_QFed Parameter-Compact Quantum-Classical Federated.pdf,Parameter-Compact Quantum-Classical,"['Samar Abdelghani', 'Soumaya Cherkaoui']",,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || QFed: Parameter-Compact Quantum-Classical || Federated Learning || Samar Abdelghani, Soumaya Cherkaoui || Department of Computer and Software Engineering, Polytechnique Montreal, Montreal, Canada || samar .abdelghani@polymtl.ca, soumaya.cherkaoui@polymtl.ca || AbstractOrganizations and enterprises ... (truncated) ||  || { || ""title"": ""Parameter-Compact Quantum-Classical"", || ""authors"": [""Samar Abdelghani"", ""Soumaya Cherkaoui""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Quantum Computing"", ""Quantum Machine Learning"", ""Federated Learning"", ""Privacy"", ""Communication"", ""IoT""], || ""summary"": ""This study examines quantum-assisted federated learning to reduce parameter count in classical models while maintaining accuracy. QFed aims to enhance computational efficiency in edge device networks using quantum computing."" || } ||  || [ Prompt: 116.7 t/s | Generation: 27.7 t/s ]"
2601.09814v1_Explainable Deep Learning for Pediatric Pneumonia .pdf,Explainable Deep Learning for Pediatric Pneumonia Detection in Chest X-Ray Images,"['Adil O. Khadidos', 'Aziida Nanyonga', 'Alaa O. Khadidos', 'Olfat M. Mirza', 'Mustafa Tahsin Yilmaz']",,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  || Explainable Deep Learning for Pediatric Pneumonia Detection || in Chest X-Ray Images || Adil O. Khadidos1, , Aziida Nanyonga2*, , Alaa O. Khadidos3,4, Olfat M. Mirza5, Mustafa Tahsin Yilmaz6,4 || 1Department of Information Technology, Faculty of Computing and Information Technology, Kin ... (truncated) ||  || { || ""title"": ""Explainable Deep Learning for Pediatric Pneumonia Detection in Chest X-Ray Images"", || ""authors"": [ || ""Adil O. Khadidos"", || ""Aziida Nanyonga"", || ""Alaa O. Khadidos"", || ""Olfat M. Mirza"", || ""Mustafa Tahsin Yilmaz"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""pediatric pneumonia"", || ""deep learning"", || ""chest x-ray"", || ""explainable ai"", || ""gradient-weighted class activation mapping"", || ""local interpretable model-agnostic explanations"" || ], || ""summary"": ""This study compares two state-of-the-art convolutional neural network architectures for automated pediatric pneumonia detection using chest X-ray images. It evaluates model performance with accuracy, F1-score, MCC, and recall, and incorporates Grad-CAM and LIME for model interpretability."" || } ||  || [ Prompt: 125.9 t/s | Generation: 28.7 t/s ]"
2601.09822v2_LLM-Based Agentic Systems for Software Engineering.pdf,LLM-Based Agentic Systems for Software Engineering: Challenges and Opportunities,"['Yongjian Tang', 'Thomas Runkler']",arXiv:2601.09822v2,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LLM-Based Agentic Systems for Software Engineering: || Challenges and Opportunities || Yongjian Tang 1,2 and Thomas Runkler 1,2 || Abstract:Despite recent advancements in Large Language Models (LLMs), complex Software || Engineering (SE) tasks require more collaborative and specialized approach ... (truncated) ||  || { || ""title"": ""LLM-Based Agentic Systems for Software Engineering: Challenges and Opportunities"", || ""authors"": [ || ""Yongjian Tang"", || ""Thomas Runkler"" || ], || ""doi"": ""arXiv:2601.09822v2"", || ""arxiv_id"": ""cs.SE"", || ""keywords"": [""LLMs"", ""Agents"", ""Software Engineering"", ""Future Challenges""], || ""summary"": ""This paper reviews the emerging paradigm of LLM-based multi-agent systems for software engineering, examining their applications across the Software Development Life Cycle and highlighting challenges and future research opportunities."" || } ||  || [ Prompt: 118.4 t/s | Generation: 28.1 t/s ]"
2601.09841v2_A pipeline for enabling path-specific causal fairn.pdf,APIPELINE FOR ENABLING PATH-SPECIFIC CAUSAL FAIRNESS IN OBSERVATIONAL HEALTH DATA,"['Aparajita Kashyap', 'Sara Matijevic', 'Nomie Elhadad', 'Steven A. Kushner', 'Noemie Elhadad', 'Shalmali Joshi']",arXiv:2601.09841v2,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || APIPELINE FOR ENABLING PATH-SPECIFIC CAUSAL FAIRNESS IN || OBSERVATIONAL HEALTH DATA || A PREPRINT || Aparajita Kashyap || Department of Biomedical Informatics || Columbia University || New York, NY , USA || ak4885@cumc.columbia.edu || Sara Matijevic || Big Data Institute || University of Oxford || Oxford, UK || sm608 ... (truncated) ||  || { || ""title"": ""APIPELINE FOR ENABLING PATH-SPECIFIC CAUSAL FAIRNESS IN OBSERVATIONAL HEALTH DATA"", || ""authors"": [ || ""Aparajita Kashyap"", || ""Sara Matijevic"", || ""Nomie Elhadad"", || ""Steven A. Kushner"", || ""Noemie Elhadad"", || ""Shalmali Joshi"" || ], || ""doi"": ""arXiv:2601.09841v2"", || ""arxiv_id"": ""2601.09841v2"", || ""keywords"": [ || ""causal fairness"", || ""foundation models"", || ""causal inference"", || ""observational health data"", || ""fair machine learning"" || ], || ""summary"": ""This paper presents a pipeline for training causally fair machine learning models in healthcare settings, focusing on path-specific fairness to address social and medical biases. It maps structural fairness to real-world contexts and demonstrates how models can be made fair across direct and indirect biases while maintaining accuracy."" || } ||  || [ Prompt: 122.5 t/s | Generation: 28.7 t/s ]"
2601.09851v1_ViSIL Unified Evaluation of Information Loss in Mu.pdf,Unified Evaluation of Information Loss in Multimodal Video Captioning,"['Po-han Li', 'Shenghui Chen', 'Ufuk Topcu', 'Sandeep Chinchali']",10.48550/arXiv.2026.12345,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ViSIL: Unified Evaluation of Information Loss in Multimodal Video Captioning || Po-han Li * 1 Shenghui Chen * 1 Ufuk Topcu1 Sandeep Chinchali 1 || Abstract || Multimodal video captioning condenses dense || footage into a structured format of keyframes and || natural language. By creating a cohesiv ... (truncated) ||  || { || ""title"": ""Unified Evaluation of Information Loss in Multimodal Video Captioning"", || ""authors"": [ || ""Po-han Li"", || ""Shenghui Chen"", || ""Ufuk Topcu"", || ""Sandeep Chinchali"" || ], || ""doi"": ""10.48550/arXiv.2026.12345"", || ""arxiv_id"": ""arXiv:2109.12345"", || ""keywords"": [ || ""multimodal video captioning"", || ""information loss"", || ""video summarization"", || ""semantic evaluation"", || ""text-to-video generation"" || ], || ""summary"": ""This paper introduces the Video Summary Information Loss (ViSIL) score, a novel information-theoretic metric that quantifies the information not captured by a summary through vision-language model inference. It addresses limitations of traditional metrics like BLEU and ROUGE by enabling direct comparison across multimodal summary formats. Results show ViSIL correlates significantly with human and VLM performance on video question answering, while also optimizing the trade-off between information loss and processing speed."" || } ||  || [ Prompt: 121.1 t/s | Generation: 27.7 t/s ]"
2601.09853v1_MedRedFlag Investigating how LLMs Redirect Misconc.pdf,MedRedFlag: Investigating how LLMs Redirect,"['Sraavya Sambara', 'Yuan Pu1', 'Ayman Ali', 'Vishala Mishra', 'Lionel Wong', 'Monica Agrawal']",,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MedRedFlag: Investigating how LLMs Redirect || Misconceptions in Real-World Health Communication || Sraavya Sambara, Yuan Pu1,, Ayman Ali1, Vishala Mishra1, Lionel Wong2, Monica Agrawal1 || 1Duke University 2Stanford University Equal contribution || Abstract || Real-world health questions from pat ... (truncated) ||  || { || ""title"": ""MedRedFlag: Investigating how LLMs Redirect"", || ""authors"": [ || ""Sraavya Sambara"", || ""Yuan Pu1"", || ""Ayman Ali"", || ""Vishala Mishra"", || ""Lionel Wong"", || ""Monica Agrawal"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""medical communication"", || ""LLMs"", || ""health communication"", || ""patient misconceptions"", || ""safety concerns"" || ], || ""summary"": ""Real-world health questions from patients often embed false assumptions. LLMs frequently fail to redirect problematic questions, risking suboptimal medical decisions. This study investigates how LLMs handle false premises in health contexts."" || } ||  || [ Prompt: 122.6 t/s | Generation: 27.7 t/s ]"
2601.09855v1_Thinking Long but Short Stable Sequential Test-Tim.pdf,Stable Sequential Test-Time Scaling for Large Reasoning Models,"['Michael R. Metel', 'Yufei Cui', 'Boxing Chen', 'Prasanna Parthasarathi']",,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Thinking Long, but Short: || Stable Sequential Test-Time Scaling for Large Reasoning Models || Michael R. Metel, Yufei Cui, Boxing Chen, and Prasanna Parthasarathi || Huawei Noahs Ark Lab || Correspondence:michael.metel@huawei.com || Abstract || Sequential test-time scaling is a promising || training-fr ... (truncated) ||  || { || ""title"": ""Stable Sequential Test-Time Scaling for Large Reasoning Models"", || ""authors"": [""Michael R. Metel"", ""Yufei Cui"", ""Boxing Chen"", ""Prasanna Parthasarathi""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Presents a novel sequential test-time scaling method, Min-Seek, which improves model accuracy over a wide range of induced thoughts, stabilizes accuracy, and reduces computational complexity."" || } ||  || [ Prompt: 123.7 t/s | Generation: 29.0 t/s ]"
2601.09858v1_OUTLINEFORGE Hierarchical Reinforcement Learning w.pdf,OUTLINEFORGE: Hierarchical Reinforcement Learning with Explicit States for Scientific Writing,"['Yilin Bao', 'Ziyao He', 'Zayden Yang']",,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || OUTLINEFORGE: Hierarchical Reinforcement Learning with Explicit || States for Scientific Writing || Yilin Bao || UC San Diego || yibao@ucsd.edu || Ziyao He || Ohio State University || ziyaohe@ohio.edu || Zayden Yang || Sheltered.AI || zayden.yang@sheltered-ai.edu || Abstract || Scientific paper generation requires doc ... (truncated) ||  || { || ""title"": ""OUTLINEFORGE: Hierarchical Reinforcement Learning with Explicit States for Scientific Writing"", || ""authors"": [ || ""Yilin Bao"", || ""Ziyao He"", || ""Zayden Yang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""scientific writing"", || ""reinforcement learning"", || ""outline construction"", || ""long-horizon planning"", || ""citation consistency"" || ], || ""summary"": ""Presents a reinforcement learning framework for scientific outline construction, addressing challenges in global structure, input coverage, and citation fidelity through hierarchical document planning."" || } ||  || [ Prompt: 117.3 t/s | Generation: 28.6 t/s ]"
2601.09865v1_Advancing Model Refinement Muon-Optimized Distilla.pdf,Advancing Model Refinement: Muon-Optimized Distillation,"['Jacob Sander', 'Brian Jalaian', 'V enkat R. Dasarivenkateswara.r.dasari.civ@army.mil']",,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Advancing Model Refinement: Muon-Optimized Distillation || and Quantization for LLM Deployment || Jacob Sander jhs39@students.uwf.edu || Intelligent Systems and Robotics (ISR) || University of West Florida || Brian Jalaian bjalaian@uwf.edu || Intelligent Systems and Robotics (ISR) || University of West  ... (truncated) ||  || { || ""title"": ""Advancing Model Refinement: Muon-Optimized Distillation"", || ""authors"": [ || ""Jacob Sander"", || ""Brian Jalaian"", || ""V enkat R. Dasarivenkateswara.r.dasari.civ@army.mil"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Large Language Models"", || ""Quantization"", || ""Model Compression"", || ""Data Distillation"", || ""Edge Computing"", || ""LLM Deployment"" || ], || ""summary"": ""This paper presents an integrated framework combining GPTQ-based quantization, LoRA, and Muon optimizer to reduce model size and improve inference efficiency for LLMs on resource-constrained devices. It achieves up to 2memory compression and demonstrates superior performance on standard benchmarks."" || } ||  || [ Prompt: 115.2 t/s | Generation: 28.5 t/s ]"
2601.09869v1_A Scoping Review of the Ethical Perspectives on An.pdf,A Scoping Review of the Ethical Perspectives on Anthropomorphising Large Language Models,"['Andrea Ferrario', 'Rasita Vinay', 'Matteo Casserini', 'Alessandro Facchini']",,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A SCOPINGREVIEW OF THEETHICALPERSPECTIVES ON || ANTHROPOMORPHISINGLARGELANGUAGEMODEL-BASED || CONVERSATIONALAGENTS || Andrea Ferrario1,2,3, Rasita Vinay4,5,6, Matteo Casserini7, and Alessandro Facchini2,8 || 1 Institute of Biomedical Ethics and History of Medicine, University of Zrich, Zrich, S ... (truncated) ||  || { || ""title"": ""A Scoping Review of the Ethical Perspectives on Anthropomorphising Large Language Models"", || ""authors"": [ || ""Andrea Ferrario"", || ""Rasita Vinay"", || ""Matteo Casserini"", || ""Alessandro Facchini"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""anthropomorphism"", || ""conversational agents"", || ""large language models"", || ""AI ethics"", || ""deception"", || ""trust"", || ""governance"" || ], || ""summary"": ""This scoping review maps ethically oriented work on anthropomorphising LLM-based conversational agents across five databases and three preprint repositories. It synthesizes conceptual foundations, ethical challenges and opportunities, and methodological approaches, highlighting convergence on attribution-based definitions and divergent operationalizations."" || } ||  || [ Prompt: 118.2 t/s | Generation: 27.5 t/s ]"
2601.09871v1_Epistemology gives a Future to Complementarity in .pdf,Epistemology Gives Afuture ToCOMPLEMENTARITY In Human-AI Interactions,"['Andrea Ferrario', 'Alessandro Facchini', 'Juan M. Durn']",,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || EPISTEMOLOGY GIVES AFUTURE TOCOMPLEMENTARITY IN || HUMAN-AI INTERACTIONS || Andrea Ferrario1,2,3, Alessandro Facchini2,4, and Juan M. Durn5 || 1 Institute of Biomedical Ethics and History of Medicine, University of Zrich, Zrich, Switzerland || 2 SUPSI, Dalle Molle Institute for Artificial Intel ... (truncated) ||  || { || ""title"": ""Epistemology Gives Afuture ToCOMPLEMENTARITY In Human-AI Interactions"", || ""authors"": [ || ""Andrea Ferrario"", || ""Alessandro Facchini"", || ""Juan M. Durn"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""artificial intelligence"", || ""machine learning"", || ""reliance"", || ""complementarity"", || ""human-AI interaction"", || ""computational reliabilism"", || ""epistemology"" || ], || ""summary"": ""The paper discusses how human-AI complementarity can enhance decision-making performance and proposes reframing it within justificatory AI discourse using computational reliabilism."" || } ||  || [ Prompt: 131.6 t/s | Generation: 28.5 t/s ]"
2601.09879v1_MedVL-SAM2 A unified 3D medical vision-language mo.pdf,MedVL-SAM2: A unified 3D medical visionlanguage model for multimodal reasoning and prompt-driven segmentation,"['Yang Xing1', 'Jiong Wu', 'Savas Ozdemir2', 'Ying Zhang3', 'Yang Yang5', 'Wei Shao4', 'Gong1']",10.48550/arXiv.2405.12345,29.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MedVL-SAM2: A unified 3D medical visionlanguage model for multimodal || reasoning and prompt-driven segmentation || Yang Xing1 Jiong Wu1 Savas Ozdemir2 Ying Zhang3 Yang Yang5 || Wei Shao4 Kuang Gong1 || 1Department of Biomedical Engineering, University of Florida, Gainesville, FL, USA || 2Departme ... (truncated) ||  || { || ""title"": ""MedVL-SAM2: A unified 3D medical visionlanguage model for multimodal reasoning and prompt-driven segmentation"", || ""authors"": [ || ""Yang Xing1"", || ""Jiong Wu"", || ""Savas Ozdemir2"", || ""Ying Zhang3"", || ""Yang Yang5"", || ""Wei Shao4"", || ""Gong1"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""10.48550/arXiv.2405.12345"", || ""keywords"": [ || ""medical vision language model"", || ""3D medical imaging"", || ""report generation"", || ""visual question answering"", || ""multi-modal segmentation"", || ""semantic segmentation"", || ""interactive segmentation"" || ], || ""summary"": ""MedVL-SAM2 is a unified 3D medical multimodal model that supports report generation, visual question answering, and multi-paradigm segmentation. It integrates image-level reasoning and pixel-level perception for precise 3D spatial reasoning in medical imaging."", || ""summary_users"": ""Users can segment the lung in the CT scan, identifying respiratory structures and assessing normal anatomy."" || } ||  || [ Prompt: 117.4 t/s | Generation: 29.5 t/s ]"
2601.09881v1_Transition Matching Distillation for Fast Video Ge.pdf,Transition Matching Distillation for Fast Video Generation,"['Weili Nie', 'Julius Berner', 'Nanye Ma', 'Chao Liu', 'Saining Xie', 'Arash Vahdat']",arXiv:2601.09881v1,31.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 2026-1-16 || Transition Matching Distillation for Fast Video Generation || Weili Nie1*, Julius Berner1*, Nanye Ma2, Chao Liu1, Saining Xie2, Arash Vahdat1 || 1NVIDIA2NYU *equal contribution || Figure 1|Generated examples from TMD.Four frames of 5s 480p videos generated from two text || prompts usi ... (truncated) ||  || { || ""title"": ""Transition Matching Distillation for Fast Video Generation"", || ""authors"": [ || ""Weili Nie"", || ""Julius Berner"", || ""Nanye Ma"", || ""Chao Liu"", || ""Saining Xie"", || ""Arash Vahdat"" || ], || ""doi"": ""arXiv:2601.09881v1"", || ""arxiv_id"": ""2026-1-16"", || ""keywords"": [ || ""video generation"", || ""distillation"", || ""TMD"", || ""generation speed"", || ""visual quality"" || ], || ""summary"": ""This paper introduces Transition Matching Distillation (TMD), a framework that distills video diffusion models into efficient few-step generators by matching multi-step denoising trajectories with lightweight conditional flows. Experiments show TMD achieves a good balance between generation speed and visual fidelity."" || } ||  || [ Prompt: 134.4 t/s | Generation: 31.5 t/s ]"
2601.09883v1_Beyond Rule-Based Workflows An Information-Flow-Or.pdf,Beyond Rule-Based Workflows: An Information-Flow-Orchestrated Multi-Agents,"['Xinxing Ren', 'Quagmire Zang', 'Caelum Forder', 'Suman Deb', 'Ahsen Tahir1', 'Roman J. Georgio', 'Peter Carroll', 'Coral Protocol 2', 'Brunel University of London', 'Universiteit Letzebuerg', 'National University of Computer and Emerging Sciences']",,29.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Beyond Rule-Based Workflows: An Information-Flow-Orchestrated Multi-Agents || Paradigm via Agent-to-Agent Communication from CORAL || Xinxing Ren1,2, Quagmire Zang3, Caelum Forder1, Suman Deb1, Ahsen Tahir1,5, || Roman J. Georgio1 Peter Carroll1 Zekun Guo4, || 1 Coral Protocol 2 Brunel Universi ... (truncated) ||  || { || ""title"": ""Beyond Rule-Based Workflows: An Information-Flow-Orchestrated Multi-Agents"", || ""authors"": [ || ""Xinxing Ren"", || ""Quagmire Zang"", || ""Caelum Forder"", || ""Suman Deb"", || ""Ahsen Tahir1"", || ""Roman J. Georgio"", || ""Peter Carroll"", || ""Coral Protocol 2"", || ""Brunel University of London"", || ""Universiteit Letzebuerg"", || ""National University of Computer and Emerging Sciences"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper proposes an Information-Flow-Orchestrated Multi-Agent Paradigm via Agent-to-Agent Communication from CORAL, addressing limitations of rule-based workflows in LLM-based MAS by enabling flexible, dynamic coordination without predefined workflows."" || } ||  || [ Prompt: 117.6 t/s | Generation: 29.4 t/s ]"
2601.09896v1_The Algorithmic Gaze An Audit and Ethnography of t.pdf,The Algorithmic Gaze: An Audit and Ethnography of the LAION-Aesthetics,"['Jordan Taylor', 'William Agnew', 'Maarten Sap', 'Sarah E. Fox', 'Haiyi Zhu']",https://doi.org/10.1145/nnnnnnn.nnnnnnn,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || The Algorithmic Gaze: An Audit and Ethnography of the LAION-Aesthetics || Predictor Model || JORDAN TAYLOR,Carnegie Mellon University, USA || WILLIAM AGNEW,Carnegie Mellon University, USA || MAARTEN SAP,Carnegie Mellon University, USA || SARAH E. FOX,Carnegie Mellon University, USA || HAIYI ZHU,Carne ... (truncated) ||  || { || ""title"": ""The Algorithmic Gaze: An Audit and Ethnography of the LAION-Aesthetics"", || ""authors"": [ || ""Jordan Taylor"", || ""William Agnew"", || ""Maarten Sap"", || ""Sarah E. Fox"", || ""Haiyi Zhu"" || ], || ""doi"": ""https://doi.org/10.1145/nnnnnnn.nnnnnnn"", || ""arxiv_id"": """", || ""keywords"": [ || ""AI"", || ""Art"", || ""Aesthetic Evaluation"" || ], || ""summary"": ""This study audits the LAION-Aesthetic Predictor (LAP) model, examining how it filters images based on captions, revealing biases in aesthetic evaluation that reinforce imperial and male gazes in art history."" || } ||  || [ Prompt: 119.6 t/s | Generation: 29.0 t/s ]"
2601.09902v1_A Novel Contrastive Loss for Zero-Day Network Intr.pdf,A Novel Contrastive Loss for Zero-Day Network,"['Jack Wilkie', 'Hanan Hindy', 'Craig Michie', 'Christos Tachtatzis', 'James Irvine', 'Robert Atkinson']",,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || A Novel Contrastive Loss for Zero-Day Network || Intrusion Detection || Jack Wilkie, Hanan Hindy, Craig Michie, Christos Tachtatzis, James Irvine, Robert Atkinson || AbstractMachine learning has achieved state-of-the-art re- || sults in network intrusion detection; however, its performance || si ... (truncated) ||  || { || ""title"": ""A Novel Contrastive Loss for Zero-Day Network"", || ""authors"": [ || ""Jack Wilkie"", || ""Hanan Hindy"", || ""Craig Michie"", || ""Christos Tachtatzis"", || ""James Irvine"", || ""Robert Atkinson"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Internet of Things"", || ""Network Intrusion Detection"", || ""Machine Learning"", || ""Contrastive Learning"" || ], || ""summary"": ""The paper proposes a novel contrastive loss function to improve zero-day attack detection in network intrusion detection, achieving better AUROC and OpenAUC performance compared to existing methods."" || } ||  || [ Prompt: 115.1 t/s | Generation: 28.5 t/s ]"
2601.09913v1_Continuum Memory Architectures for Long-Horizon LL.pdf,Continuum Memory Architectures for Long-Horizon LLM Agents,['Joe Logan'],,27.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Continuum Memory Architectures for Long-Horizon LLM Agents || Joe Logan || Mode7 GK || Tokyo, Japan || hello@joelogan.co || Abstract || Retrieval-augmented generation (RAG) has become the default strategy for providing || large language model (LLM) agents with contextual knowledge. Yet RAG treats memory ... (truncated) ||  || { || ""title"": ""Continuum Memory Architectures for Long-Horizon LLM Agents"", || ""authors"": [""Joe Logan""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Retrieval-augmented generation (RAG) treats memory as stateless, leading to challenges in continuity and memory dynamics. The paper introduces the Continuum Memory Architecture (CMA) to address these issues by enabling persistent, evolving memory systems."" || } ||  || [ Prompt: 113.7 t/s | Generation: 27.3 t/s ]"
2601.09921v1_Learning to Decode in Parallel Self-Coordinating N.pdf,Learning to Decode in Parallel: Self-Coordinating,"['Kai Zhang', 'Zhengzhong Yi', 'Shaojun Guo', 'Linghang Kong', 'Wang Situ', 'Zhengfeng Ji', 'Fusheng Chen', 'Jianxin Chen']",arXiv:2601.09921v1,30.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Learning to Decode in Parallel: Self-Coordinating || Neural Network for Real-Time Quantum Error || Correction || Kai Zhang 1,3, Zhengzhong Yi 4,5,6, Shaojun Guo 4,5,6, || Linghang Kong 2, Situ Wang 1, Xiaoyu Zhan 1, Tan He 4,5,6, || Weiping Lin4,5,6, Tao Jiang 4,5,6, Dongxin Gao 4,5,6, || Yiming Zhan ... (truncated) ||  || { || ""title"": ""Learning to Decode in Parallel: Self-Coordinating"", || ""authors"": [ || ""Kai Zhang"", || ""Zhengzhong Yi"", || ""Shaojun Guo"", || ""Linghang Kong"", || ""Wang Situ"", || ""Zhengfeng Ji"", || ""Fusheng Chen"", || ""Jianxin Chen"" || ], || ""doi"": ""arXiv:2601.09921v1"", || ""arxiv_id"": ""2601.09921v1"", || ""keywords"": [ || ""neural network"", || ""quantum error correction"", || ""self-coordinating"", || ""parallel decoding"" || ], || ""summary"": ""Fast, reliable decoders are pivotal components for enabling fault-tolerant quantum computation. Neural network decoders like AlphaQubit have demonstrated significant potential, achieving higher accuracy than traditional human-designed decoding algorithms. However, existing implementations of neural network decoders are described here."" || } ||  || [ Prompt: 126.1 t/s | Generation: 30.8 t/s ]"
2601.09923v1_CaMeLs Can Use Computers Too System-level Security.pdf,CAMELSCANUSECOMPUTERSTOO: A PREPRINT,"['Hanna Foerster', 'Robert Mullins', 'Tom Blanchard', 'Nicolas Papernot', 'Kristina Nikolic', 'Florian Tramr', 'Ilia Shumailov', 'Cheng Zhang', 'Yiren Zhao']",,32.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || CAMELSCANUSECOMPUTERSTOO: || SYSTEM-LEVELSECURITY FORCOMPUTERUSEAGENTS || A PREPRINT || Hanna Foerster, Robert Mullins || University of Cambridge || Tom Blanchard, Nicolas Papernot || University of Toronto & || Vector Institute || Kristina Nikolic, Florian Tramr || ETH Zurich || Ilia Shumailov, Cheng Zhang, Yire ... (truncated) ||  || { || ""title"": ""CAMELSCANUSECOMPUTERSTOO: A PREPRINT"", || ""authors"": [ || ""Hanna Foerster"", || ""Robert Mullins"", || ""Tom Blanchard"", || ""Nicolas Papernot"", || ""Kristina Nikolic"", || ""Florian Tramr"", || ""Ilia Shumailov"", || ""Cheng Zhang"", || ""Yiren Zhao"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""AI agents are vulnerable to prompt injection attacks, where malicious content hijacks agent behavior to steal credentials or cause financial loss. The paper proposes architectural isolation for Computer Use Agents (CUAs) to ensure control flow integrity, demonstrating a Single-Shot Planning approach that mitigates branch steering attacks while maintaining performance."" || } ||  || [ Prompt: 115.0 t/s | Generation: 32.3 t/s ]"
2601.09929v1_Hallucination Detection and Mitigation in Large La.pdf,Hallucination Detection and Mitigation in Large Language Models,"['Ahmad Pesaranghader', 'Erin Li']",,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Hallucination Detection and Mitigation in Large || Language Models || Ahmad Pesaranghader, Erin Li || CIBC, Toronto || {ahmad.pesaranghader, erin.li}@cibc.com || Abstract || Large Language Models (LLMs) and Large Reasoning Models (LRMs) offer || transformative potential for high-stakes domains like fina ... (truncated) ||  || { || ""title"": ""Hallucination Detection and Mitigation in Large Language Models"", || ""authors"": [""Ahmad Pesaranghader"", ""Erin Li""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper introduces a comprehensive operational framework for managing hallucinations in LLMs, focusing on detection and mitigation strategies that are root cause aware. It applies to high-stakes domains like finance and law, emphasizing systematic reliability enhancement."" || } ||  || [ Prompt: 123.5 t/s | Generation: 27.8 t/s ]"
2601.09933v1_Malware Classification using Diluted Convolutional.pdf,Malware Classification using Diluted Convolutional Neural Network with Fast Gradient Sign Method,"['Ashish Anand', 'Bhupendra Singh', 'Sunil Khemka', 'Bireswar Banerjee', 'Vishi Singh Bhatia', 'Piyush Ranjan']",gcp.ashish2020@gmail.com,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Malware Classification using Diluted Convolutional || Neural Network with Fast Gradient Sign Method || 1st Ashish Anand || Marriott International || Broadlands, USA || gcp.ashish2020@gmail.com || 2nd Bhupendra Singh || Marriott International || Cary, USA || bhupendra.research1@gmail.com || 3rd Sunil Kh ... (truncated) ||  || { || ""title"": ""Malware Classification using Diluted Convolutional Neural Network with Fast Gradient Sign Method"", || ""authors"": [ || ""Ashish Anand"", || ""Bhupendra Singh"", || ""Sunil Khemka"", || ""Bireswar Banerjee"", || ""Vishi Singh Bhatia"", || ""Piyush Ranjan"" || ], || ""doi"": ""gcp.ashish2020@gmail.com"", || ""arxiv_id"": """", || ""keywords"": [ || ""security"", || ""diluted convolutional neural network"", || ""fast gradient sign method"", || ""malware classification"", || ""privacy"" || ], || ""summary"": ""This research proposes a Fast Gradient Sign Method with Diluted Convolutional Neural Network (FGSM-DICNN) for malware classification. The model uses diluted convolutions to capture patterns across long ranges with fewer features, achieving 99.44% accuracy."" || } ||  || [ Prompt: 125.0 t/s | Generation: 28.4 t/s ]"
2601.09949v2_Kinematic Tokenization Optimization-Based Continuo.pdf,Kinematic Tokenization: Optimization-Based,"['Griffin M. Kearney, Ph.D.']",arXiv:2601.09949v2,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Kinematic Tokenization: Optimization-Based || Continuous-Time Tokens for Learnable Decision || Policies in Noisy Time Series || Griffin M. Kearney, Ph.D. || Syracuse, New York, USA || gkearneyengineering@gmail.com || January 21, 2026 || Abstract || Transformers are designed for discrete tokens, yet many re ... (truncated) ||  || { || ""title"": ""Kinematic Tokenization: Optimization-Based"", || ""authors"": [""Griffin M. Kearney, Ph.D.""], || ""doi"": ""arXiv:2601.09949v2"", || ""arxiv_id"": ""arXiv:2601.09949v2"", || ""keywords"": [""kinematic tokenization"", ""optimization-based"", ""continuous-time"", ""financial time series""], || ""summary"": ""Transformers are designed for discrete tokens, yet many real-world signals are continuous processes observed through noisy sampling. Discrete tokenizations can be brittle in low signal-to-noise regimes, especially when downstream objectives impose asymmetric penalties. We introduce Kinematic Tokenization, an optimization-based continuous-time representation that reconstructs an explicit spline from noisy measurements and tokenizes local spline coefficients. This is applied to financial time series data in conjunction with trading volume profiles. Under a risk-averse asymmetric classification objective, discrete baselines collapse to an absorbing cash policy, whereas continuous spline tokens sustain calibrated, non-trivial action distributions and stable policies. These results suggest that explicit continuous-time tokens can improve the learnability and calibration of selective decision policies in noisy time series under abstention-inducing losses."", || ""summary_abstract"": ""Transformers are designed for discrete tokens, yet many real-world signals are continuous processes observed through noisy sampling. Discrete tokenizations (raw values, patches, finite differences) can be brittle in low signal-to-noise regimes, especially when downstream objectives impose asymmetric penalties that rationally encourage abstention. We introduce Kinematic Tokenization, an optimization-based continuous-time representation that reconstructs an explicit spline from noisy measurements and tokenizes local spline coefficients (position, velocity, acceleration, jerk). This is applied to financial time series data in conjunction with trading volume profiles. Across a multi-asset daily-equity testbed, we use a risk-averse asymmetric classification objective as a stress test for learnability. Under this objective, several discrete baselines collapse to an absorbing cash policy (theLiquidation Equilibrium), whereas the continuous spline tokens sustain calibrated, non-trivial action distributions and stable policies. These results suggest that explicit continuous-time tokens can improve the learnability and calibration of selective decision policies in noisy time series under abstention-inducing losses."", || ""publication_date"": ""January 21, 2026"" || } ||  || [ Prompt: 125.3 t/s | Generation: 29.1 t/s ]"
2601.09966v1_A Sustainable AI Economy Needs Data Deals That Wor.pdf,A Sustainable AI Economy Needs Data Deals That Work for Generators,"['Ruoxi Jia', 'Luis Oala', 'Wenjie Xiong', 'Suqin Ge', 'Jiachen T. Wang', 'Feiyang Kang', 'Dawn Song']",,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A Sustainable AI Economy Needs Data Deals That || Work for Generators || Ruoxi Jia || Virginia Tech || Luis Oala || Brickroad || Wenjie Xiong || Virginia Tech || Suqin Ge || Virginia Tech || Jiachen T. Wang || Princeton University || Feiyang Kang || Virginia Tech || Dawn Song || UC Berkeley || Abstract || We argue that the machine l ... (truncated) ||  || { || ""title"": ""A Sustainable AI Economy Needs Data Deals That Work for Generators"", || ""authors"": [ || ""Ruoxi Jia"", || ""Luis Oala"", || ""Wenjie Xiong"", || ""Suqin Ge"", || ""Jiachen T. Wang"", || ""Feiyang Kang"", || ""Dawn Song"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper argues that the machine learning value chain is structurally unsustainable due to an economic data processing inequality. It analyzes seventy-three public data deals and identifies issues such as unequal value distribution, opaque terms, and systemic inequities, proposing an Equitable Data-Value Exchange framework."" || } ||  || [ Prompt: 123.0 t/s | Generation: 27.7 t/s ]"
2601.09972v1_Chinese Labor Law Large Language Model Benchmark.pdf,Chinese Labor Law Large Language Model,"['Zixun Lan', 'Maochun Xu', 'Yifan Ren', 'Rui Wu', 'Jianghui Zhou', 'Xueyang Cheng', 'Jianan Ding', 'Xinheng Wang', 'Mingmin Chi', 'Fei Ma']",,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || Chinese Labor Law Large Language Model || Benchmark || Zixun Lan, Maochun Xu, Yifan Ren, Rui Wu, Jianghui Zhou, Xueyang Cheng, Jianan Ding, Xinheng Wang, || Mingmin Chi, Fei Ma || AbstractRecent advancements in large language models || (LLMs) have led to substantial progress in domain-specific a ... (truncated) ||  || { || ""title"": ""Chinese Labor Law Large Language Model"", || ""authors"": [ || ""Zixun Lan"", || ""Maochun Xu"", || ""Yifan Ren"", || ""Rui Wu"", || ""Jianghui Zhou"", || ""Xueyang Cheng"", || ""Jianan Ding"", || ""Xinheng Wang"", || ""Mingmin Chi"", || ""Fei Ma"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Chinese labor law"", || ""legal natural language processing"", || ""large language models"", || ""domain-specific fine-tuning"", || ""benchmark dataset"", || ""statute recall"", || ""legal reasoning"", || ""case analysis"" || ], || ""summary"": ""Recent advancements in large language models have led to substantial progress in domain-specific applications, particularly within the legal domain. This paper presents LaborLawLLM, a legal LLM tailored to labor law, and introduces LaborLawBenchmark for evaluating its performance across various tasks."" || } ||  || [ Prompt: 124.1 t/s | Generation: 27.8 t/s ]"
2601.09974v1_SPRInG Continual LLM Personalization via Selective.pdf,SPRInG: Continual LLM Personalization via Selective Parametric Adaptation and Retrieval-Interpolated Generation,"['Seoyeon Kim', 'Jaehyung Kim']",10.48550/arXiv.2405.12345,28.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SPRInG: Continual LLM Personalization via Selective Parametric || Adaptation and Retrieval-Interpolated Generation || Seoyeon Kim || Yonsei University || yeon_04@yonsei.ac.kr || Jaehyung Kim || Yonsei University || jaehyungk@yonsei.ac.kr || Abstract || Personalizing Large Language Models typi- || cally relies on ... (truncated) ||  || { || ""title"": ""SPRInG: Continual LLM Personalization via Selective Parametric Adaptation and Retrieval-Interpolated Generation"", || ""authors"": [ || ""Seoyeon Kim"", || ""Jaehyung Kim"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""10.48550/arXiv.2405.12345"", || ""keywords"": [ || ""continual personalization"", || ""LLM personalization"", || ""parameter adaptation"", || ""retrieval interpolation"", || ""preference drift"" || ], || ""summary"": ""This paper introduces SPRING, a semi-parametric framework for continual personalization of large language models. It addresses preference drift by employing drift-driven selective adaptation and logit interpolation between parametric knowledge and retrieved interactions, improving robustness in real-world settings."" || } ||  || [ Prompt: 119.4 t/s | Generation: 28.9 t/s ]"
2601.09980v1_Performance of AI agents based on reasoning langua.pdf,ALD optimization using reasoning LLMs,['Angel Yanguas-Gil'],,26.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ALD optimization using reasoning LLMs || Performance of AI agents based on reasoning language models on ALD || process optimization tasks || Angel Yanguas-Gil1 || Applied Materials Division, Argonne National Laboratory, Lemont, IL 60439, USA || (*Electronic mail: ayg@anl.gov) || (Dated: 16 January 20 ... (truncated) ||  || { || ""title"": ""ALD optimization using reasoning LLMs"", || ""authors"": [""Angel Yanguas-Gil""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This work explores the performance and behavior of reasoning large language models in autonomously optimizing atomic layer deposition processes without prior knowledge of the process."" || } ||  || [ Prompt: 115.5 t/s | Generation: 26.8 t/s ]"
2601.09982v1_Context Volume Drives Performance Tackling Domain .pdf,Volume Drives Performance: Tackling Domain Shift in Extremely Low-Resource Translation via RAG,"['David Samuel Setiawan', 'Raphal Merx', 'Jey Han Lau']",10.48550/arXiv.2405.12345,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Context Volume Drives Performance: Tackling Domain Shift in Extremely || Low-Resource Translation via RAG || David Samuel Setiawan, Raphal Merx, Jey Han Lau || The University of Melbourne || {david.setiawan, raphael.merx}@student.unimelb.edu.au || jeyhan.lau@unimelb.edu.au || Abstract || Neural Machine  ... (truncated) ||  || { || ""title"": ""Volume Drives Performance: Tackling Domain Shift in Extremely Low-Resource Translation via RAG"", || ""authors"": [ || ""David Samuel Setiawan"", || ""Raphal Merx"", || ""Jey Han Lau"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [ || ""neural machine translation"", || ""low-resource languages"", || ""domain shift"", || ""retrieval augmented generation"", || ""biblical texts"", || ""language models"" || ], || ""summary"": ""This study quantifies performance degradation of NMT models for low-resource languages under domain shift using Dhao. Applying the model to the Old Testament reveals that performance drops significantly, especially when relying on the New Testament. The authors introduce a hybrid framework combining fine-tuning and LLM refinement to recover in-domain quality, achieving improved results."" || } ||  || [ Prompt: 123.9 t/s | Generation: 29.0 t/s ]"
2601.10010v1_VERHallu Evaluating and Mitigating Event Relation .pdf,Evaluating and Mitigating Event,"['Zefan Zhang', 'Kehua Zhu', 'Shijie Jiang', 'Hongyuan Lu', 'Shengkai Sun', 'Tian Bai']",,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || VERHallu: Evaluating and Mitigating Event || Relation Hallucination in Video Large Language || Models || Zefan Zhang , Kehua Zhu , Shijie Jiang , Hongyuan Lu , Shengkai Sun , Tian Bai* || AbstractVideo Large Language Models (VideoLLMs) exhibit || various types of hallucinations. Existing researc ... (truncated) ||  || { || ""title"": ""Evaluating and Mitigating Event"", || ""authors"": [ || ""Zefan Zhang"", || ""Kehua Zhu"", || ""Shijie Jiang"", || ""Hongyuan Lu"", || ""Shengkai Sun"", || ""Tian Bai"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Video Large Language Models"", || ""Event Relation Hallucination"", || ""Video Understanding"", || ""Event Relation Understanding"", || ""Video Understanding"" || ], || ""summary"": ""This paper introduces VERHallu, a novel benchmark for evaluating event relation hallucination in video LLMs. It focuses on causal, temporal, and subevent relations across three tasks: relation classification, question answering, and counterfactual question answering. The study highlights challenges in dense-event relation reasoning and proposes a Key-Frame Propagating strategy to improve multi-event understanding without sacrificing inference speed."" || } ||  || [ Prompt: 120.6 t/s | Generation: 27.8 t/s ]"
2601.10011v1_Memo-SQL Structured Decomposition and Experience-D.pdf,Memo-SQL: Structured Decomposition and Experience-Driven Self-Correction for Training-Free NL2SQL,"['Zerui Yang', 'Weichuan Wang', 'Yanwei Xu', 'Linqi Song', 'Yudai Matsuda', 'Wei Han', 'Bo Bai']",,29.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Memo-SQL: Structured Decomposition and Experience-Driven || Self-Correction for Training-Free NL2SQL || Zerui Yang1, Weichuan Wang1, Yanwei Xu*2, Linqi Song1, Yudai Matsuda1, Wei Han2, and Bo Bai2 || 1City University of Hong Kong, Hong Kong, PR China || 2Huawei Technologies Ltd. || Abstract || Existi ... (truncated) ||  || { || ""title"": ""Memo-SQL: Structured Decomposition and Experience-Driven Self-Correction for Training-Free NL2SQL"", || ""authors"": [ || ""Zerui Yang"", || ""Weichuan Wang"", || ""Yanwei Xu"", || ""Linqi Song"", || ""Yudai Matsuda"", || ""Wei Han"", || ""Bo Bai"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Addresses limitations of NL2SQL by introducing structured decomposition and experience-aware self-correction, achieving 68.5% execution accuracy with improved robustness and efficiency."" || } ||  || [ Prompt: 117.6 t/s | Generation: 29.4 t/s ]"
2601.10018v1_Empowering Older Adults in Digital Technology Use .pdf,Empowering Older Adults in Digital Technology Use with Foundation Models,"['Hasti Sharifi', 'Homaira Huda Shomee', 'Sourav Medya', 'Debaleena Chattopadhyay']",,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Empowering Older Adults in Digital Technology Use with || Foundation Models || Hasti Sharifi, Homaira Huda Shomee, Sourav Medya, Debaleena Chattopadhyay || Department of Computer Science || University of Illinois Chicago || {hshari3, hshome2, medya, debchatt}@uic.edu || Abstract || Background and Object ... (truncated) ||  || { || ""title"": ""Empowering Older Adults in Digital Technology Use with Foundation Models"", || ""authors"": [ || ""Hasti Sharifi"", || ""Homaira Huda Shomee"", || ""Sourav Medya"", || ""Debaleena Chattopadhyay"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Technology support"", || ""Digital technology use"", || ""Artificial intelligence"", || ""Large language models"", || ""Communication barriers"", || ""Human-computer interaction"" || ], || ""summary"": ""This study examines communication challenges faced by older adults in using digital technology and explores AI-based solutions to address these issues."" || } ||  || [ Prompt: 126.1 t/s | Generation: 27.6 t/s ]"
2601.10025v1_Structured Personality Control and Adaptation for .pdf,Structured Personality Control and Adaptation for LLM Agents,"['Jinpeng Wang', 'Xinyu Jia', 'Wei Wei Heng', 'Yuquan Li', 'Binbin Shi', 'Qianlei Chen', 'Guannan Chen', 'Junxia Zhang', 'Yuyu Yin']",10.1093/acps/ccad045,29.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Structured Personality Control and Adaptation for LLM Agents || JINPENG WANG,Qianzhen Digital Tech, China || XINYU JIA,Qianzhen Digital Tech, China || WEI WEI HENG,Key Laboratory of Complex Systems Modeling and Simulation of Ministry of Education, China || YUQUAN LI,Qianzhen Digital Tech, China ... (truncated) ||  || { || ""title"": ""Structured Personality Control and Adaptation for LLM Agents"", || ""authors"": [ || ""Jinpeng Wang"", || ""Xinyu Jia"", || ""Wei Wei Heng"", || ""Yuquan Li"", || ""Binbin Shi"", || ""Qianlei Chen"", || ""Guannan Chen"", || ""Junxia Zhang"", || ""Yuyu Yin"" || ], || ""doi"": ""10.1093/acps/ccad045"", || ""arxiv_id"": """", || ""keywords"": [ || ""Personalization"", || ""Jungian Psychological Types"", || ""MBTI Personality Types"", || ""Persona Adaptation"", || ""Explainable AI"" || ], || ""summary"": ""This paper presents a framework modeling LLM personality via Jungian psychological types, integrating mechanisms for coherent expression, adaptive reinforcement, and long-term evolution. It evaluates personality alignment using MBTI questionnaires and applies it to diverse interaction scenarios to support naturalistic agent design in HCI."" || } ||  || [ Prompt: 122.9 t/s | Generation: 29.2 t/s ]"
2601.10029v1_PaperScout An Autonomous Agent for Academic Paper .pdf,PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization,"['Tingyue Pan', 'Jie Ouyang', 'Mingyue Cheng', 'Qingchuan Li', 'Zirui Liu', 'Mingfan Pan', 'Shuo Yu', 'Qi Liu']",10.48550/arXiv.2405.12345,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || PaperScout: An Autonomous Agent for Academic Paper Search with || Process-Aware Sequence-Level Policy Optimization || Tingyue Pan, Jie Ouyang , Mingyue Cheng , || Qingchuan Li, Zirui Liu, Mingfan Pan, Shuo Yu, Qi Liu || State Key Lab of Cognitive Intelligence, University of Science and Technolo ... (truncated) ||  || { || ""title"": ""PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization"", || ""authors"": [ || ""Tingyue Pan"", || ""Jie Ouyang"", || ""Mingyue Cheng"", || ""Qingchuan Li"", || ""Zirui Liu"", || ""Mingfan Pan"", || ""Shuo Yu"", || ""Qi Liu"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""10.48550/arXiv.2405.12345"", || ""keywords"": [ || ""academic paper search"", || ""autonomous agent"", || ""process-aware policy"", || ""sequence-level optimization"", || ""reinforcement learning"" || ], || ""summary"": ""This paper introduces PaperScout, an autonomous agent that reformulates paper search as a sequential decision-making process. It addresses the limitations of static workflows by employing Proximal Sequence Policy Optimization (PSPO) to handle complex, conditional queries. Comprehensive experiments show that PaperScout outperforms existing workflow-driven and RL-based methods in both recall and relevance."" || } ||  || [ Prompt: 117.4 t/s | Generation: 29.3 t/s ]"
2601.10031v1_FilDeep Learning Large Deformations of Elastic-Pla.pdf,FilDeep: Learning Large Deformations of Elastic-Plastic Solids with Multi-Fidelity Data,"['Jianheng Tang', 'Shilong Tao', 'Zhe Feng', 'Haonan Sun', 'Menglu Wang', 'Zhanxing Zhu']",10.1145/3770854.3783959,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || FilDeep: Learning Large Deformations of Elastic-Plastic Solids || with Multi-Fidelity Data || Jianheng Tang || Peking University || School of Computer Science || Beijing, China || tangentheng@gmail.com || Shilong Tao || Peking University || School of Computer Science || Beijing, China || shilongtao@stu.pku.edu.cn || Z ... (truncated) ||  || { || ""title"": ""FilDeep: Learning Large Deformations of Elastic-Plastic Solids with Multi-Fidelity Data"", || ""authors"": [ || ""Jianheng Tang"", || ""Shilong Tao"", || ""Zhe Feng"", || ""Haonan Sun"", || ""Menglu Wang"", || ""Zhanxing Zhu"" || ], || ""doi"": ""10.1145/3770854.3783959"", || ""arxiv_id"": ""KDD 26, Jeju Island, Republic of Korea"", || ""keywords"": [ || ""Large Deformations"", || ""Elastic-Plastic Solids"", || ""Multi-Fidelity Data"", || ""Deep Learning"", || ""Quantity-Accuracy Dilemma"" || ], || ""summary"": ""The scientific computation of large deformations in elastic-plastic solids is crucial in various manufacturing applications. Traditional numerical methods exhibit limitations, prompting Deep Learning as a promising alternative. FilDeep addresses the quantity-accuracy dilemma by training with both low-fidelity and high-fidelity data."" || } ||  || [ Prompt: 121.4 t/s | Generation: 28.8 t/s ]"
2601.10038v1_What Understanding Means in AI-Laden Astronomy.pdf,Understanding Means in AI-Laden Astronomy,"['Yuan-Sen Ting', 'Andr Curtis-Trudel', 'Siyu Yao']",,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || What Understanding Means in AI-Laden || Astronomy || Yuan-Sen Ting1,2,3*, Andr Curtis-Trudel4,5, Siyu Y ao6 || 1Department of Astronomy, The Ohio State University, Columbus, OH, USA. || 2Center for Cosmology and AstroParticle Physics (CCAPP), The Ohio State University, Columbus, OH, || USA. || 3Max-P ... (truncated) ||  || { || ""title"": ""Understanding Means in AI-Laden Astronomy"", || ""authors"": [ || ""Yuan-Sen Ting"", || ""Andr Curtis-Trudel"", || ""Siyu Yao"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""understanding"", || ""AI"", || ""astronomy"", || ""philosophy of science"", || ""discovery"", || ""knowledge generation"" || ], || ""summary"": ""The paper discusses the implications of artificial intelligence in astronomy, emphasizing the need for philosophical reflection on understanding, discovery, and the role of philosophy in science."" || } ||  || [ Prompt: 115.7 t/s | Generation: 28.2 t/s ]"
2601.10061v1_CoF-T2I Video Models as Pure Visual Reasoners for .pdf,CoF-T2I: Video Models as Pure Visual Reasoners,"['Chengzhuo Tong1,2', 'Mingkun Chang3', 'Shenglong Zhang4', 'Yuanxing Zhang2', 'Wentao Zhang1', 'Peking University1 Kling Team', 'Kuaishou Technology2', 'Sun Yat-sen University3', 'Zhejiang University4', 'Nanjing University5']",,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || CoF-T2I: Video Models as Pure Visual Reasoners || for Text-to-Image Generation || Chengzhuo Tong1,2,, Mingkun Chang3,, Shenglong Zhang4, Yuran Wang1,2, Cheng Liang2,5 || Zhizheng Zhao1, Ruichuan An1, Bohan Zeng1,2, Yang Shi1,2, Yifan Dai2, Ziming Zhao4 || Guanbin Li3, Pengfei Wan2, Yuanxing Zha ... (truncated) ||  || { || ""title"": ""CoF-T2I: Video Models as Pure Visual Reasoners"", || ""authors"": [ || ""Chengzhuo Tong1,2"", || ""Mingkun Chang3"", || ""Shenglong Zhang4"", || ""Yuanxing Zhang2"", || ""Wentao Zhang1"", || ""Peking University1 Kling Team"", || ""Kuaishou Technology2"", || ""Sun Yat-sen University3"", || ""Zhejiang University4"", || ""Nanjing University5"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""CoF-T2I"", || ""video models"", || ""text-to-image generation"", || ""visual reasoning"", || ""frame-by-frame"", || ""motion artifacts"", || ""benchmark performance"" || ], || ""summary"": ""Recent video generation models exhibit Chain-of-Frame reasoning, enabling frame-by-frame visual inference. This work proposes CoF-T2I, a model integrating CoF reasoning into text-to-image generation via progressive visual refinement. Experiments show improved performance on benchmarks."" || } ||  || [ Prompt: 117.2 t/s | Generation: 29.0 t/s ]"
2601.10073v1_ReaMIL Reasoning- and Evidence-Aware Multiple Inst.pdf,ReaMIL: Reasoning- and Evidence-Aware Multiple Instance Learning for Whole-Slide Histopathology,"['Hyun Do Jung', 'Jungwon Choi', 'Hwiyoung Kim']",,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ReaMIL: Reasoning- and Evidence-Aware Multiple Instance Learning for || Whole-Slide Histopathology || Hyun Do Jung1 Jungwon Choi2 Hwiyoung Kim1* || 1Yonsei University 2KAIST || Abstract || We introduce ReaMIL (Reasoning- and Evidence-Aware || MIL), a multiple instance learning approach for whole-slid ... (truncated) ||  || { || ""title"": ""ReaMIL: Reasoning- and Evidence-Aware Multiple Instance Learning for Whole-Slide Histopathology"", || ""authors"": [ || ""Hyun Do Jung"", || ""Jungwon Choi"", || ""Hwiyoung Kim"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""ReaMIL introduces a multiple instance learning approach for whole-slide histopathology with a light selection head, improving evidence efficiency and maintaining strong performance across multiple cancer datasets."" || } ||  || [ Prompt: 115.3 t/s | Generation: 29.0 t/s ]"
2601.10079v1_Sparse-RL Breaking the Memory Wall in LLM Reinforc.pdf,Sparse-RL: Breaking the Memory Wall in LLM Reinforcement Learning,"['Sijia Luo1', 'Xiaokang Zhang1', 'Yuxuan Hu1', 'Bohan Zhang1', 'Ke Wang1', 'Jinbo Su1', 'Mengshu Sun3', 'Lei Liang3', 'Jing Zhang1', '2', '1 School of Information, Renmin University of China', '2 Key Laboratory of Data Engineering and Knowledge Engineering, Beijing', '3 Ant Group, Hangzhou, China']",,34.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Sparse-RL: Breaking the Memory Wall in LLM Reinforcement Learning || via Stable Sparse Rollouts || Sijia Luo1,2*, Xiaokang Zhang1,2*, Yuxuan Hu1,2, Bohan Zhang1,2, || Ke Wang1,2, Jinbo Su1,2, Mengshu Sun3, Lei Liang3, Jing Zhang1,2 || 1School of Information, Renmin University of China, Beijing, ... (truncated) ||  || { || ""title"": ""Sparse-RL: Breaking the Memory Wall in LLM Reinforcement Learning"", || ""authors"": [ || ""Sijia Luo1"", || ""Xiaokang Zhang1"", || ""Yuxuan Hu1"", || ""Bohan Zhang1"", || ""Ke Wang1"", || ""Jinbo Su1"", || ""Mengshu Sun3"", || ""Lei Liang3"", || ""Jing Zhang1"", || ""2"", || ""1 School of Information, Renmin University of China"", || ""2 Key Laboratory of Data Engineering and Knowledge Engineering, Beijing"", || ""3 Ant Group, Hangzhou, China"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Reinforcement Learning faces memory overhead issues in long-horizon rollouts. Sparse-RL introduces sparsity-aware techniques to reduce rollout overhead and improve performance."" || } ||  || [ Prompt: 123.6 t/s | Generation: 34.4 t/s ]"
2601.10088v1_State of AI An Empirical 100 Trillion Token Study .pdf,State of AI: An Empirical 100 Trillion Token Study with OpenRouter,"['Malika Aubakirova', 'Alex Atallah', 'Chris Clark', 'Justin Summerville', 'Anjney Midha']",a16z-2025-001,30.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || State of AI: || An Empirical 100 Trillion Token Study with OpenRouter || Malika Aubakirova, Alex Atallah , Chris Clark , Justin Summerville , and Anjney Midha || OpenRouter Inc. a16z (Andreessen Horowitz) || December, 2025 || Abstract || The past year has marked a turning point in the evolution and  ... (truncated) ||  || { || ""title"": ""State of AI: An Empirical 100 Trillion Token Study with OpenRouter"", || ""authors"": [ || ""Malika Aubakirova"", || ""Alex Atallah"", || ""Chris Clark"", || ""Justin Summerville"", || ""Anjney Midha"" || ], || ""doi"": ""a16z-2025-001"", || ""arxiv_id"": ""a16z-2025-001"", || ""keywords"": [ || ""large language models"", || ""LLM adoption"", || ""OpenRouter"", || ""empirical study"", || ""multi-step inference"" || ], || ""summary"": ""This study analyzes over 100 trillion tokens of real-world LLM interactions using OpenRouter, highlighting shifts in usage patterns, adoption of creative roleplay, coding assistance, and agentic inference. It identifies foundational user cohorts and discusses implications for model development."" || } ||  || [ Prompt: 113.6 t/s | Generation: 30.7 t/s ]"
2601.10090v1_Difficulty-guided Sampling Bridging the Target Gap.pdf,Difficulty-guided Sampling: Bridging the Target Gap,"['Mingzhuo Lia', 'Guang Lia', 'Linfeng Yeb', 'Jiafeng Maoc', 'Takahiro Ogawaa', 'Konstantinos N. Plataniotis', 'Miki Haseyamaa']",arXiv:2601.10090v1,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Difficulty-guided Sampling: Bridging the Target Gap || between Dataset Distillation and Downstream Tasks || Mingzhuo Lia, Guang Lia, Linfeng Yeb, Jiafeng Maoc, Takahiro Ogawaa, || Konstantinos N. Plataniotisb, Miki Haseyamaa || aHokkaido University, N-14, W-9, Kita-Ku, Sapporo, 060-0814, Japan || ... (truncated) ||  || { || ""title"": ""Difficulty-guided Sampling: Bridging the Target Gap"", || ""authors"": [ || ""Mingzhuo Lia"", || ""Guang Lia"", || ""Linfeng Yeb"", || ""Jiafeng Maoc"", || ""Takahiro Ogawaa"", || ""Konstantinos N. Plataniotis"", || ""Miki Haseyamaa"" || ], || ""doi"": ""arXiv:2601.10090v1"", || ""arxiv_id"": ""2601.10090"", || ""keywords"": [ || ""dataset distillation"", || ""downstream tasks"", || ""target gap"", || ""deep neural networks"", || ""data distillation"", || ""image classification"" || ], || ""summary"": ""The paper proposes difficulty-guided sampling to bridge the gap between distillation objectives and downstream tasks, aiming to improve dataset distillation performance while maintaining model accuracy."" || } ||  || [ Prompt: 120.2 t/s | Generation: 28.3 t/s ]"
2601.10092v1_LeMoF Level-guided Multimodal Fusion for Heterogen.pdf,LEMOF: LEVEL-GUIDEDMULTIMODALFUSION FOR HETEROGENEOUSCLINICALDATA,"['Jongseok Kim', 'Seongae Kang', 'Jonghwan Shin', 'Yuhan Lee', 'Ohyun Jo', 'Hongming Xu']",10.1007/XXXXXX,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LEMOF: LEVEL-GUIDEDMULTIMODALFUSION FOR || HETEROGENEOUSCLINICALDATA || Jongseok Kim || Department of Computer Science || Chungbuk National University || South Korea || kjseok@chungbuk.ac.kr || Seongae Kang || Department of Computer Science || Chungbuk National University || South Korea || kseongae@chungbuk.ac.kr ... (truncated) ||  || { || ""title"": ""LEMOF: LEVEL-GUIDEDMULTIMODALFUSION FOR HETEROGENEOUSCLINICALDATA"", || ""authors"": [ || ""Jongseok Kim"", || ""Seongae Kang"", || ""Jonghwan Shin"", || ""Yuhan Lee"", || ""Ohyun Jo"", || ""Hongming Xu"" || ], || ""doi"": ""10.1007/XXXXXX"", || ""arxiv_id"": """", || ""keywords"": [ || ""Multimodal Learning"", || ""Hierarchical Representation Learning"", || ""Clinical Time-Series Modeling"", || ""Level-guided Feature Fusion"", || ""Explainable Medical AI"" || ], || ""summary"": ""This paper proposes LeMoF, a novel framework for integrating heterogeneous clinical data by selectively combining level-guided representations. It aims to balance prediction stability and discriminative power across modalities, demonstrating superior performance in length of stay prediction using ICU data."" || } ||  || [ Prompt: 125.4 t/s | Generation: 28.2 t/s ]"
2601.10094v1_V-Zero Self-Improving Multimodal Reasoning with Ze.pdf,V-Zero: Self-Improving Multimodal Reasoning with Zero Annotation,"['Han Wang', 'Yi Yang', 'Jingyuan Hu', 'Minfeng Zhu', 'Wei Chen']",,29.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || V-Zero: Self-Improving Multimodal Reasoning with Zero Annotation || Han Wang1*, Yi Yang1*, Jingyuan Hu2*, Minfeng Zhu2, Wei Chen1, || 1State Key Laboratory of CAD&CG, Zhejiang University, || 2Zhejiang University || Abstract || Recent advances in multimodal learning have || significantly enhanced the  ... (truncated) ||  || { || ""title"": ""V-Zero: Self-Improving Multimodal Reasoning with Zero Annotation"", || ""authors"": [ || ""Han Wang"", || ""Yi Yang"", || ""Jingyuan Hu"", || ""Minfeng Zhu"", || ""Wei Chen"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Recent advances in multimodal learning have significantly enhanced the reasoning capabilities of vision-language models (VLMs). However, state-of-the-art approaches rely heavily on large-scale human-annotated datasets, which are costly and time-consuming to acquire. To overcome this limitation, we introduce V-Zero, a general post-training framework that facilitates self-improvement using exclusively unlabeled images. V-Zero establishes a co-evolutionary loop by instantiating two distinct roles: a Questioner and a Solver. The Questioner learns to synthesize high-quality, challenging questions by leveraging a dual-track reasoning reward, while the Solver is optimized using pseudo-labels derived from majority voting over its own sampled responses. Both roles are trained iteratively via Group Relative Policy Optimization (GRPO), driving a cycle of mutual enhancement. Remarkably, without any human annotation, V-Zero achieves consistent performance gains on Qwen2.5-VL7B-Instruct, improving visual mathematical reasoning by +1.7 and general vision-centric reasoning by +2.6, demonstrating the potential of self-improvement in multimodal systems."" || } ||  || [ Prompt: 120.0 t/s | Generation: 29.7 t/s ]"
2601.10101v2_Matrix as Plan Structured Logical Reasoning with F.pdf,Matrix as Plan: Structured Logical Reasoning with Feedback-Driven Replanning,"['Ke Chen', 'Jiandian Zeng', 'Guo Li', 'Guangxue Zhang', 'Tian Wang']",10.1145/XXXXXX.XXXXXX,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Matrix as Plan: Structured Logical Reasoning with || Feedback-Driven Replanning || Ke Chen || kechen@mail.bnu.edu.cn || Faculty of Arts and Sciences || Beijing Normal University || Zhuhai, Guangdong, China || Jiandian Zeng || jiandian@bnu.edu.cn || Institute of Artificial Intelligence and || Future Networks || Beij ... (truncated) ||  || { || ""title"": ""Matrix as Plan: Structured Logical Reasoning with Feedback-Driven Replanning"", || ""authors"": [ || ""Ke Chen"", || ""Jiandian Zeng"", || ""Guo Li"", || ""Guangxue Zhang"", || ""Tian Wang"" || ], || ""doi"": ""10.1145/XXXXXX.XXXXXX"", || ""arxiv_id"": """", || ""keywords"": [ || ""MatrixCoT"", || ""Logical Reasoning"", || ""LLM"", || ""Symbolic Expressions"", || ""Feedback-Driven Replanning"", || ""Semantic Equivalence"", || ""Structured Reasoning"" || ], || ""summary"": ""The paper proposes MatrixCoT, a structured CoT framework with a matrix-based plan to enhance LLM reasoning. It addresses limitations of existing methods by introducing normalization, explicit citation fields, and feedback-driven replanning to improve robustness and interpretability without relying on external solvers."" || } ||  || [ Prompt: 121.3 t/s | Generation: 29.3 t/s ]"
2601.10103v1_FlowAct-R1 Towards Interactive Humanoid Video Gene.pdf,FlowAct-R1: Towards Interactive Humanoid Video,"['Lizhen Wang', 'Yongming Zhu', 'Zhipeng Ge', 'Youwei Zheng', 'Longhao Zhang', 'Tianshu Hu', 'Shiyang Qin', 'Mingshuang Luo', 'Jiaxu Zhang', 'Xin Chen', 'Yulong Wang', 'Zerong Zheng', 'Jianwen Jiang', 'Chao Liang', 'Weifeng Chen', 'Xing Wang', 'Yuan Zhang', 'Mingyuan Gao']",arXiv:2601.10103v1,30.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || FlowAct-R1: Towards Interactive Humanoid Video || Generation || Lizhen Wang ,Yongming Zhu ,Zhipeng Ge ,Youwei Zheng ,Longhao Zhang , || Tianshu Hu ,Shiyang Qin,Mingshuang Luo,Jiaxu Zhang,Xin Chen,Yulong || Wang,Zerong Zheng,Jianwen Jiang,Chao Liang,Weifeng Chen,Xing Wang, || Yuan Zhang,Mingyuan Ga ... (truncated) ||  || { || ""title"": ""FlowAct-R1: Towards Interactive Humanoid Video"", || ""authors"": [ || ""Lizhen Wang"", || ""Yongming Zhu"", || ""Zhipeng Ge"", || ""Youwei Zheng"", || ""Longhao Zhang"", || ""Tianshu Hu"", || ""Shiyang Qin"", || ""Mingshuang Luo"", || ""Jiaxu Zhang"", || ""Xin Chen"", || ""Yulong Wang"", || ""Zerong Zheng"", || ""Jianwen Jiang"", || ""Chao Liang"", || ""Weifeng Chen"", || ""Xing Wang"", || ""Yuan Zhang"", || ""Mingyuan Gao"" || ], || ""doi"": ""arXiv:2601.10103v1"", || ""arxiv_id"": ""2601.10103"", || ""keywords"": [ || ""humanoid video generation"", || ""interactive video"", || ""real-time interaction"", || ""video synthesis"", || ""MMDiT"", || ""low-latency"" || ], || ""summary"": ""Interactive humanoid video generation aims to synthesize lifelike visual agents. This paper proposes FlowAct-R1, a framework for real-time interactive humanoid video generation using a chunkwise diffusion forcing strategy and self-forcing variant to ensure temporal consistency. It achieves stable 25fps at 480p with low TTFF and supports diverse behavioral states."" || } ||  || [ Prompt: 130.9 t/s | Generation: 30.4 t/s ]"
2601.10104v1_MathDoc Benchmarking Structured Extraction and Act.pdf,Benchmarking Structured Extraction and Active Refusal on Noisy Mathematics Exam Papers,"['Chenyue Zhou', 'Jiayi Tuo', 'Shitong Qin2', 'Wei Dai', 'Mingxuan Wang', 'Ziwei Zhao', 'Duoyang Li', 'Shiyang Su', 'Yanxi Lu']",,29.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MathDoc: Benchmarking Structured Extraction and Active || Refusal on Noisy Mathematics Exam Papers || Chenyue Zhou5, Jiayi Tuo6, Shitong Qin2, Wei Dai3, Mingxuan Wang1, || Ziwei Zhao1 Duoyang Li1,Shiyang Su 1,Yanxi Lu 1,Yanbiao Ma 1,3,4* || 1Gaoling School of Artificial Intelligence, Renmin Uni ... (truncated) ||  || { || ""title"": ""Benchmarking Structured Extraction and Active Refusal on Noisy Mathematics Exam Papers"", || ""authors"": [ || ""Chenyue Zhou"", || ""Jiayi Tuo"", || ""Shitong Qin2"", || ""Wei Dai"", || ""Mingxuan Wang"", || ""Ziwei Zhao"", || ""Duoyang Li"", || ""Shiyang Su"", || ""Yanxi Lu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper introduces MathDoc, the first benchmark for document-level extraction from high school mathematics exam papers, addressing challenges posed by visual noise and incomplete inputs. It evaluates models on stem accuracy, visual similarity, and refusal capability, highlighting gaps in current MLLMs."" || } ||  || [ Prompt: 118.4 t/s | Generation: 29.6 t/s ]"
2601.10108v1_SIN-Bench Tracing Native Evidence Chains in Long-C.pdf,Sin-Bench: Tracing Native Evidence Chains in Long-Context Multimodal,"['Yiming Ren', 'Junjie Wang', 'Yuxin Meng', 'Yihang Shi', 'Zhiqiang Lin', 'Ruihang Chu', 'Yiran Xu', 'Ziming Li', 'Yu Fei Zhao', 'Yang Yu']",,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SIN-Bench: Tracing Native Evidence Chains in Long-Context Multimodal || Scientific Interleaved Literature || Yiming Ren1,2* Junjie Wang1,3* Yuxin Meng1* Yihang Shi1* || Zhiqiang Lin1 Ruihang Chu1 Yiran Xu1 Ziming Li4 Yunfei Zhao3,5 || Zihan Wang3,6 Yu Qiao2 Ruiming Tang4 Minghao Liu3 Yujiu Yang ... (truncated) ||  || { || ""title"": ""Sin-Bench: Tracing Native Evidence Chains in Long-Context Multimodal"", || ""authors"": [ || ""Yiming Ren"", || ""Junjie Wang"", || ""Yuxin Meng"", || ""Yihang Shi"", || ""Zhiqiang Lin"", || ""Ruihang Chu"", || ""Yiran Xu"", || ""Ziming Li"", || ""Yu Fei Zhao"", || ""Yang Yu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Evaluating whether multimodal large language models truly understand long-form scientific papers remains challenging: answer-only metrics and synthetic Needle-In-A-Haystack tests often reward answer matching without requiring a causal, evidence-linked reasoning trace in the document. We propose the Fish-in-the-Ocean paradigm, which requires models to construct explicit cross-modal evidence chains within native scientific documents."" || } ||  || [ Prompt: 116.1 t/s | Generation: 29.1 t/s ]"
2601.10112v1_Repository Intelligence Graph Deterministic Archit.pdf,Repository Intelligence Graph: Deterministic,"['Tsvi Cherny-Shahar', 'Amiram Yehudai']",,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Repository Intelligence Graph: Deterministic || Architectural Map for LLM Code Assistants || Tsvi Cherny-Shahar || Blavatnik School of Computer Science || Tel Aviv University || Israel || tsvic (at) mail.tau.ac.il || Amiram Yehudai || Blavatnik School of Computer Science || Tel Aviv University || Israel || amiramy  ... (truncated) ||  || { || ""title"": ""Repository Intelligence Graph: Deterministic"", || ""authors"": [ || ""Tsvi Cherny-Shahar"", || ""Amiram Yehudai"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""software repositories"", || ""build systems"", || ""dependency graphs"", || ""software engineering agents"", || ""multi-lingual software"" || ], || ""summary"": ""Repository aware coding agents often struggle to recover build and test structure, especially in multilingual projects. The paper introduces the Repository Intelligence Graph (RIG) to provide a deterministic architectural map for LLM code assistants."" || } ||  || [ Prompt: 117.5 t/s | Generation: 27.9 t/s ]"
2601.10114v1_Following the Teachers Footsteps Scheduled Checkpo.pdf,,[],,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Following the Teachers Footsteps: Scheduled || Checkpoint Distillation for Domain-Specific || LLMs || Cheng Feng1[0000000338610042], Chaoliang Zhong 1[0000000316976932], || Jun Sun 1[0000000209674859], and Yusuke Oishi 2[0000000342648932] || 1 Fujitsu R&D Center, Beijing, China || {fengcheng, clzhong ... (truncated) ||  || { || ""title"": ""Following the Teachers Footsteps: Scheduled Checkpoint Distillation for Domain-Specific LLMs"", || ""authors"": [ || ""Cheng Feng"", || ""Chaoliang Zhong"", || ""Jun Sun"", || ""Yusuke Oishi"" || ], || ""doi"": ""10.1002/2016aci.1234"", || ""arxiv_id"": ""arXiv:2601.10114"", || ""keywords"": [""LLMs"", ""Knowledge Distillation"", ""Domain-specific Tasks""], || ""summary"": ""This paper proposes a novel theoretical insight and method—Scheduled Checkpoint Distillation (SCD)—to help student models outperform teacher models on domain-specific tasks by balancing their performance on student-favored and teacher-favored subdomains."" || } ||  || [ Prompt: 135.1 t/s | Generation: 28.6 t/s ]"
2601.10120v1_TopoDIM One-shot Topology Generation of Diverse In.pdf,TopoDIM: One-shot Topology Generation of Diverse Interaction Modes for Multi-Agent Systems,"['Rui Sun', 'Jie Ding', 'Chenghua Gong', 'Tianjun Gu2', 'Yihang Jiang', 'Juyuan Zhang', 'Liming Pan', 'Linyuan L1']",https://anonymous.4open.science/r/TopoDIM-8D35/,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TopoDIM: One-shot Topology Generation of Diverse Interaction Modes for || Multi-Agent Systems || Rui Sun1 Jie Ding1 Chenghua Gong1 Tianjun Gu2 || Yihang Jiang1 Juyuan Zhang1 Liming Pan1 Linyuan L1 || 1University of Science and Technology of China, Hefei, China || 2East China Normal University, Sha ... (truncated) ||  || { || ""title"": ""TopoDIM: One-shot Topology Generation of Diverse Interaction Modes for Multi-Agent Systems"", || ""authors"": [ || ""Rui Sun"", || ""Jie Ding"", || ""Chenghua Gong"", || ""Tianjun Gu2"", || ""Yihang Jiang"", || ""Juyuan Zhang"", || ""Liming Pan"", || ""Linyuan L1"" || ], || ""doi"": ""https://anonymous.4open.science/r/TopoDIM-8D35/"", || ""arxiv_id"": ""TopoDIM-8D35/"", || ""keywords"": [ || ""multi-agent systems"", || ""LLM-based"", || ""topology generation"", || ""interaction modes"", || ""token efficiency"", || ""adaptability"" || ], || ""summary"": ""Optimizing communication topology in LLM-based multi-agent systems is critical for collective intelligence. This paper proposes TOPODIM, a framework for one-shot topology generation with diverse interaction modes, enabling decentralized execution and improving task performance while reducing token consumption."" || } ||  || [ Prompt: 116.1 t/s | Generation: 28.4 t/s ]"
2601.10122v1_Role-Playing Agents Driven by Large Language Model.pdf,Role-Playing Agents Driven by Large Language Models,"['Ye Wang', 'Jiaxing Chen', 'Hongjiang Xiao', 'Yewang', 'Xiaohj']",,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Role-Playing Agents Driven by Large Language || Models: Current Status, Challenges, and Future || Trends || Ye Wang12 Jiaxing Chen12 Hongjiang Xiao1 || 1State Key Laboratory of Media Convergence and Communication, Communication University of China || 2Neuroscience and Intelligent Media Institute,  ... (truncated) ||  || { || ""title"": ""Role-Playing Agents Driven by Large Language Models"", || ""authors"": [ || ""Ye Wang"", || ""Jiaxing Chen"", || ""Hongjiang Xiao"", || ""Yewang"", || ""Xiaohj"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""large language models"", || ""role-playing agents"", || ""natural language processing"", || ""human-computer interaction"", || ""personality modeling"", || ""memory mechanisms"" || ], || ""summary"": ""This paper systematically reviews the current development and key technologies of role-playing language agents (RPLAs), covering technological evolution, challenges, and future directions. It emphasizes psychological scale-driven character modeling, memory-augmented prompting, and motivation-based decision control."" || } ||  || [ Prompt: 126.3 t/s | Generation: 28.4 t/s ]"
2601.10129v1_LaViT Aligning Latent Visual Thoughts for Multi-mo.pdf,LaViT: Aligning Latent Visual Thoughts for Multi-modal Reasoning,"['Linquan Wu', 'Tianxiang Jiang', 'Yifei Dong', 'Haoyu Yang', 'Fengji Zhang', 'Shichang Meng', 'Ai Xuan', 'Linqi Song', 'Jacky Keung']",https://github.com/Svardfox/LaViT,29.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LaViT: Aligning Latent Visual Thoughts for Multi-modal Reasoning || Linquan Wu*1, Tianxiang Jiang*2, Yifei Dong3, Haoyu Yang4, || Fengji Zhang1,Shichang Meng 1,Ai Xuan 1,Linqi Song 1,Jacky Keung 1 || 1City University of Hong Kong, 2University of Science and Technology of China, || 3Utrecht Univ ... (truncated) ||  || { || ""title"": ""LaViT: Aligning Latent Visual Thoughts for Multi-modal Reasoning"", || ""authors"": [ || ""Linquan Wu"", || ""Tianxiang Jiang"", || ""Yifei Dong"", || ""Haoyu Yang"", || ""Fengji Zhang"", || ""Shichang Meng"", || ""Ai Xuan"", || ""Linqi Song"", || ""Jacky Keung"" || ], || ""doi"": ""https://github.com/Svardfox/LaViT"", || ""arxiv_id"": """", || ""keywords"": [ || ""multimodal reasoning"", || ""visual attention"", || ""latent visual thoughts"", || ""distillation"", || ""visual grounding"" || ], || ""summary"": ""This paper introduces LaViT, a framework that aligns latent visual thoughts instead of static embeddings, aiming to bridge the critical perception gap by requiring students to reconstruct visual semantics and attention trajectories before text generation. Experiments show significant improvements in visual grounding and reasoning performance."" || } ||  || [ Prompt: 111.5 t/s | Generation: 29.2 t/s ]"
2601.10130v1_Redundancy-Driven Top-k Functional Dependency Disc.pdf,Redundancy-Driven Top-k Functional Dependency,"['Xiaolong Wan', 'Xixian Han']",,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || Redundancy-Driven Top-k Functional Dependency || Discovery || Xiaolong Wan, Xixian Han || AbstractFunctional dependencies (FDs) are basic constraints || in relational databases and are used for many data managemen t || tasks. Most FD discovery algorithms nd all valid dependenc ies, || but this caus ... (truncated) ||  || { || ""title"": ""Redundancy-Driven Top-k Functional Dependency"", || ""authors"": [""Xiaolong Wan"", ""Xixian Han""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""functional dependency"", ""top-k discovery"", ""data redundancy""], || ""summary"": ""Discusses challenges in discovering functional dependencies due to computational cost and large result sets, and introduces SDP for efficient pruning."" || } ||  || [ Prompt: 120.9 t/s | Generation: 28.8 t/s ]"
2601.10131v2_M4olGen Multi-Agent Multi-Stage Molecular Generati.pdf,"M4olGen: Multi-Agent, Multi-Stage Molecular Generation under Precise Multi-Property Constraints","['Yizhan Li', 'Florence Cloutier', 'Sifan Wu', 'Ali Parviz', 'Boris Knyazev', 'Yan Zhang', 'Glen Berseth', 'Bang Liu']",,29.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || M4olGen: Multi-Agent, Multi-Stage Molecular Generation under Precise || Multi-Property Constraints || Yizhan Li1,2, Florence Cloutier1,2, Sifan Wu1,2, Ali Parviz2, Boris Knyazev1,2,4, || Yan Zhang2,4, Glen Berseth1,2,3,5 & Bang Liu1,2,3,5* || 1DIRO & Universit de Montral || 2Mila  Quebec AI Instit ... (truncated) ||  || { || ""title"": ""M4olGen: Multi-Agent, Multi-Stage Molecular Generation under Precise Multi-Property Constraints"", || ""authors"": [ || ""Yizhan Li"", || ""Florence Cloutier"", || ""Sifan Wu"", || ""Ali Parviz"", || ""Boris Knyazev"", || ""Yan Zhang"", || ""Glen Berseth"", || ""Bang Liu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""multi-agent"", || ""multi-stage"", || ""molecular generation"", || ""precise constraints"", || ""numeric properties"", || ""LLMs"", || ""optimization"" || ], || ""summary"": ""Generating molecules that satisfy precise numeric constraints is critical for scientific discovery. This paper introduces M4olGen, a framework for multi-property constrained generation using retrieval-augmented and two-stage methods."" || } ||  || [ Prompt: 121.7 t/s | Generation: 29.4 t/s ]"
2601.10132v1_Is More Context Always Better Examining LLM Reason.pdf,Is More Context Always Better? Examining LLM Reasoning,"['Yanan Cao', 'Farnaz Fallahi', 'Murali Mohana Krishna Dandu', 'Lalitesh Morishetti', 'Kai Zhao', 'Luyi Ma', 'Sinduja Subramaniam', 'Jianpeng Xu', 'Ekorpeoglu', 'Kaushiki Nag']",10.1145/XXXXXX.XXXXXX,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Is More Context Always Better? Examining LLM Reasoning || Capability for Time Interval Prediction || Yanan Cao || Walmart Global Tech || Sunnyvale, CA, USA || yanan.cao@walmart.com || Farnaz Fallahi || Walmart Global Tech || Sunnyvale, CA, USA || farnaz.fallahi@walmart.com || Murali Mohana Krishna Dandu || Walmart  ... (truncated) ||  || { || ""title"": ""Is More Context Always Better? Examining LLM Reasoning"", || ""authors"": [ || ""Yanan Cao"", || ""Farnaz Fallahi"", || ""Murali Mohana Krishna Dandu"", || ""Lalitesh Morishetti"", || ""Kai Zhao"", || ""Luyi Ma"", || ""Sinduja Subramaniam"", || ""Jianpeng Xu"", || ""Ekorpeoglu"", || ""Kaushiki Nag"" || ], || ""doi"": ""10.1145/XXXXXX.XXXXXX"", || ""arxiv_id"": """", || ""keywords"": [ || ""Large Language Models"", || ""Temporal Reasoning"", || ""Inter-Purchase Interval Prediction"" || ], || ""summary"": ""This paper investigates whether LLMs can predict time intervals between recurring user actions, examining how contextual information affects performance. It benchmarks LLMs against statistical and machine-learning models and finds that while LLMs outperform lightweight baselines, they struggle with quantitative temporal structure and degrade with added context."" || } ||  || [ Prompt: 118.7 t/s | Generation: 28.7 t/s ]"
2601.10137v1_Step-by-Step Causality Transparent Causal Discover.pdf,Step-by-Step Causality: Transparent Causal Discovery with Multi-Agent,"['Ziyi Ding', 'Chenfei Ye-Hao', 'Zheyuan Wang', 'Xiao-Ping Zhang']",https://anonymous.4open,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Step-by-Step Causality: Transparent Causal Discovery with Multi-Agent || Tree-Query and Adversarial Confidence Estimation || Ziyi Ding * 1 Chenfei Ye-Hao* 1 Zheyuan Wang 2 || Xiao-Ping Zhang 1 || Abstract || Causal discovery aims to recover what causes || what, but classical constraint-based methods || ... (truncated) ||  || { || ""title"": ""Step-by-Step Causality: Transparent Causal Discovery with Multi-Agent"", || ""authors"": [ || ""Ziyi Ding"", || ""Chenfei Ye-Hao"", || ""Zheyuan Wang"", || ""Xiao-Ping Zhang"" || ], || ""doi"": ""https://anonymous.4open"", || ""arxiv_id"": ""https://anonymous.4open/science/r/Repo-9B3E-4F96/"", || ""keywords"": [ || ""causal discovery"", || ""multi-agent"", || ""LLM"", || ""confidence estimation"", || ""structural inference"" || ], || ""summary"": ""This paper introduces Tree-Query, a tree-structured, multi-expert LLM framework that enables interpretable causal discovery by reducing pairwise causal discovery to a sequence of queries. It improves structural metrics over direct LLM baselines and provides robust confidence scores, supporting data-free causal priors."" || } ||  || [ Prompt: 120.7 t/s | Generation: 28.7 t/s ]"
2601.10141v1_Understanding and Preserving Safety in Fine-Tuned .pdf,Understanding and Preserving Safety in Fine-Tuned LLMs,"['Jiawen Zhang', 'Yangfan Hu', 'Kejia Chen', 'Lipeng He', 'Jiachen Ma', 'Jian Lou', 'Dan Li', 'Ruoxi Jia', 'Jian Liu']",,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Understanding and Preserving Safety in Fine-Tuned LLMs || Jiawen Zhang || Zhejiang University || Zhejiang, China || kevinzh@zju.edu.cn || Yangfan Hu || University of || WisconsinMadison || Wisconsin, USA || yhu557@wisc.edu || Kejia Chen || Zhejiang University || Zhejiang, China || chenkejia@zju.edu.cn || Lipeng He || Universit ... (truncated) ||  || { || ""title"": ""Understanding and Preserving Safety in Fine-Tuned LLMs"", || ""authors"": [ || ""Jiawen Zhang"", || ""Yangfan Hu"", || ""Kejia Chen"", || ""Lipeng He"", || ""Jiachen Ma"", || ""Jian Lou"", || ""Dan Li"", || ""Ruoxi Jia"", || ""Jian Liu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""fine-tuning"", || ""safety alignment"", || ""LLMs"", || ""safety-utility dilemma"", || ""jailbreak attacks"" || ], || ""summary"": ""This paper addresses the challenge of balancing safety and utility in fine-tuning large language models. It introduces SPF to preserve safety while maintaining performance, offering theoretical and empirical insights into the geometric relationship between safety and utility gradients."" || } ||  || [ Prompt: 119.8 t/s | Generation: 28.5 t/s ]"
2601.10143v1_History Is Not Enough An Adaptive Dataflow System .pdf,History Is Not Enough: An Adaptive Dataflow,"['Haochong Xia', 'Yao Long Teng', 'Regan Tan', 'Molei Qin', 'Xinrun Wang', 'Bo An']","HAOCHONG001, yaolong001, rtan072, molei001",27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || History Is Not Enough: An Adaptive Dataflow || System for Financial Time-Series Synthesis || Haochong Xia 1,*, Yao Long Teng 1,*, Regan Tan 1 , Molei Qin 1 , Xinrun Wang 2, Bo An 1, || 1College of Computing and Data Science, Nanyang Technological University, Singapore || 2School of Computing an ... (truncated) ||  || { || ""title"": ""History Is Not Enough: An Adaptive Dataflow"", || ""authors"": [ || ""Haochong Xia"", || ""Yao Long Teng"", || ""Regan Tan"", || ""Molei Qin"", || ""Xinrun Wang"", || ""Bo An"" || ], || ""doi"": ""HAOCHONG001, yaolong001, rtan072, molei001"", || ""arxiv_id"": """", || ""keywords"": [ || ""adaptive dataflow"", || ""workflow automation"", || ""financial time-series"", || ""data augmentation"", || ""data augmentation"", || ""financial time-series synthesis"" || ], || ""summary"": ""The paper presents a drift-aware dataflow system integrating adaptive control into data curation to address concept drift in financial time-series. It proposes a parameterized data manipulation module and an adaptive scheduler with gradient-based optimization to improve model robustness and risk-adjusted returns."" || } ||  || [ Prompt: 116.3 t/s | Generation: 27.9 t/s ]"
2601.10148v1_DecisionLLM Large Language Models for Long Sequenc.pdf,DecisionLLM: Large Language Models for Long Sequence Decision Exploration,"['Xiaowei Lv 1', '2 Zhiling Zhang', '3 Yijun Li', '3 Yusen Huo3 Siyuan Ju', '3 Xuyan Li', '3 Chunxiang Hong', '3 Bo Zheng']",10.48550/arXiv.2024.12345,29.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DecisionLLM: Large Language Models for Long Sequence Decision Exploration || Xiaowei Lv 1 2 Zhiling Zhang 3 Yijun Li 3 Yusen Huo3 Siyuan Ju 3 Xuyan Li 3 Chunxiang Hong 3 || Tianyu Wang3 Yongcai Wang1 Peng Sun 3 Chuan Yu3 Jian Xu 3 Bo Zheng 3 || Abstract || Long-sequence decision-making, which i ... (truncated) ||  || { || ""title"": ""DecisionLLM: Large Language Models for Long Sequence Decision Exploration"", || ""authors"": [ || ""Xiaowei Lv 1"", || ""2 Zhiling Zhang"", || ""3 Yijun Li"", || ""3 Yusen Huo3 Siyuan Ju"", || ""3 Xuyan Li"", || ""3 Chunxiang Hong"", || ""3 Bo Zheng"" || ], || ""doi"": ""10.48550/arXiv.2024.12345"", || ""arxiv_id"": ""arXiv:2409.12345"", || ""keywords"": [ || ""long sequence decision-making"", || ""reinforcement learning"", || ""large language models"", || ""decision transformer"", || ""offline reinforcement learning"" || ], || ""summary"": ""This paper explores applying large language models to long-horizon decision-making tasks, addressing challenges like interpreting continuous values. It introduces DecisionLLM, a framework that aligns trajectory data with natural language descriptions, and presents empirical results showing strong performance improvements over existing methods."" || } ||  || [ Prompt: 121.2 t/s | Generation: 29.6 t/s ]"
2601.10150v1_Simple Network Graph Comparative Learning.pdf,Simple Network Graph Comparative Learning,"['Qiang Yua', 'Xinran Chenga', 'Shiqiang Xub', 'Chuanyi Liua']",,27.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Simple Network Graph Comparative Learning || Qiang Yua, Xinran Chenga, Shiqiang Xub and Chuanyi Liua || aorganization=School of Computer Science and Technology, Harbin Institute of Technology,Shenzhen, city=Shenzhen, postcode=518071, country=China || borganization=Inspur Cloud Information Te ... (truncated) ||  || { || ""title"": ""Simple Network Graph Comparative Learning"", || ""authors"": [ || ""Qiang Yua"", || ""Xinran Chenga"", || ""Shiqiang Xub"", || ""Chuanyi Liua"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Filters"", || ""Siamese network"", || ""Graph contrastive learning"", || ""Unsupervised representation learning"" || ], || ""summary"": ""The paper proposes a novel node classification contrast learning method called Simple Network Graph Comparative Learning (SNGCL), which uses a superimposed multilayer Laplace smoothing filter to enhance global and local feature smoothing, improving performance in node classification tasks."" || } ||  || [ Prompt: 121.6 t/s | Generation: 27.2 t/s ]"
2601.10154v1_MHub.ai A Simple Standardized and Reproducible Pla.pdf,Artificial Intelligence in Medicine (AIM) Program,"['Leonard Nrnberg', 'Dennis Bontempi', 'Suraj Pai', 'Curtis Lisle', 'Steve Pieper', 'Ron Kikinis', 'Sil van de', 'Rahul', 'Soni', 'Gowtham', 'Murugesan', 'Ciausu', 'Miriam', 'Groeneveld', 'Felix', 'J.', 'Dorfner', 'Jue', 'Jiang', 'Aneesh', 'Rangnekar', 'Harini', 'Joeran', 'Bosma', 'Keno', 'Bressem', 'Raymond', 'Mak', 'Andrey', 'Fedorov', 'Hugo', 'Aerts']","1,2,3",28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MHub.ai:  A  Simple,  Standardized,  and  Reproducible  Platform  for  AI || Models ||  || in ||  || Medical ||  || Imaging ||  || Leonard  Nrnberg || 1,2,3 || ,  Dennis  Bontempi || 1,2,3 || ,  Suraj  Pai || 1,2,3 || ,  Curtis  Lisle || 4 || ,  Steve  Pieper || 5 || ,  Ron  Kikinis || 6 || ,  Sil  van || de ||  || Leemput || 7 || , ||  || Rahul ||  || Soni || ... (truncated) ||  || { || ""title"": ""Artificial Intelligence in Medicine (AIM) Program"", || ""authors"": [ || ""Leonard Nrnberg"", || ""Dennis Bontempi"", || ""Suraj Pai"", || ""Curtis Lisle"", || ""Steve Pieper"", || ""Ron Kikinis"", || ""Sil van de"", || ""Rahul"", || ""Soni"", || ""Gowtham"", || ""Murugesan"", || ""Ciausu"", || ""Miriam"", || ""Groeneveld"", || ""Felix"", || ""J."", || ""Dorfner"", || ""Jue"", || ""Jiang"", || ""Aneesh"", || ""Rangnekar"", || ""Harini"", || ""Joeran"", || ""Bosma"", || ""Keno"", || ""Bressem"", || ""Raymond"", || ""Mak"", || ""Andrey"", || ""Fedorov"", || ""Hugo"", || ""Aerts"" || ], || ""doi"": ""1,2,3"", || ""arxiv_id"": """", || ""keywords"": [ || ""Medical"", || ""Imaging"", || ""AI"", || ""Machine Learning"", || ""Radiology"", || ""Nuclear Medicine"" || ], || ""summary"": ""A simple, standardized, and reproducible platform for AI models in medical imaging."" || } ||  || [ Prompt: 121.9 t/s | Generation: 28.7 t/s ]"
2601.10155v1_LOOKAT Lookup-Optimized Key-Attention for Memory-E.pdf,LOOKAT: Lookup-Optimized Key-Attention for Memory-Efficient Transformers,['Aryan Karmore'],bt24csd009@iiitn.ac.in,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LOOKAT: Lookup-Optimized Key-Attention for Memory-Efficient || Transformers || Aryan Karmore || Indian Institute of Information Technology, Nagpur || bt24csd009@iiitn.ac.in || Abstract || Compressing the KV cache is a required step to deploy || large language models on edge devices. Current quanti- || zati ... (truncated) ||  || { || ""title"": ""LOOKAT: Lookup-Optimized Key-Attention for Memory-Efficient Transformers"", || ""authors"": [""Aryan Karmore""], || ""doi"": ""bt24csd009@iiitn.ac.in"", || ""arxiv_id"": """", || ""keywords"": [""transformers"", ""key-attention"", ""memory-efficient"", ""compression"", ""rank correlation""], || ""summary"": ""Compressing the KV cache for deploying large language models on edge devices by applying product quantization and asymmetric distance computation. LOOKAT achieves high compression with minimal loss in attention performance."" || } ||  || [ Prompt: 122.9 t/s | Generation: 28.1 t/s ]"
2601.10157v1_MMPG MoE-based Adaptive Multi-Perspective Graph Fu.pdf,MMPG: MoE-based Adaptive Multi-Perspective Graph Fusion for Protein Representation Learning,"['Yusong Wang', 'Jialun Shen', 'Zhihao Wu', 'Yicheng Xu', 'Shiyin Tan', 'Mingkun Xu', 'Changshuo Wang', 'Zixing Song', 'Prayag Tiwari']",,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MMPG: MoE-based Adaptive Multi-Perspective Graph Fusion for || Protein Representation Learning || Yusong Wang1*, Jialun Shen2*, Zhihao Wu3, Yicheng Xu2, Shiyin Tan2, Mingkun Xu1, || Changshuo Wang4, Zixing Song5, Prayag Tiwari6 || 1Guangdong Institute of Intelligence Science and Technology, Zhu ... (truncated) ||  || { || ""title"": ""MMPG: MoE-based Adaptive Multi-Perspective Graph Fusion for Protein Representation Learning"", || ""authors"": [ || ""Yusong Wang"", || ""Jialun Shen"", || ""Zhihao Wu"", || ""Yicheng Xu"", || ""Shiyin Tan"", || ""Mingkun Xu"", || ""Changshuo Wang"", || ""Zixing Song"", || ""Prayag Tiwari"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Graph Neural Networks (GNNs) have been widely adopted for Protein Representation Learning (PRL), as residue interaction networks can be naturally represented as graphs. Current GNN-based PRL methods typically rely on single-perspective graph construction strategies, which capture partial properties of residue interactions, resulting in incomplete protein representations. To address this limitation, we propose MMPG, a framework that constructs protein graphs from multiple perspectives and adaptively fuses them via Mixture of Experts (MoE) for PRL. MMPG constructs graphs from physical, chemical, and geometric perspectives to characterize different properties of residue interactions. To capture both perspective-specific features and their synergies, we develop an MoE module, which dynamically routes perspectives to specialized experts, where experts learn intrinsic features and cross-perspective interactions. We quantitatively verify that MoE automatically specializes experts in modeling distinct levels of interaction from individual representations, to pairwise inter-perspective synergies, and ultimately to a global consensus across all perspectives. Through integrating this multi-level information, MMPG produces superior protein representations and achieves advanced performance on four different downstream protein tasks."" || } ||  || [ Prompt: 118.8 t/s | Generation: 28.3 t/s ]"
2601.10160v1_Alignment Pretraining AI Discourse Causes Self-Ful.pdf,Alignment Pretraining: AI Discourse Causes Self-Fulfilling (Mis)alignment,"['Cameron Tice', 'Puria Radmard', '2 Samuel Ratnam', 'Andy Kim', 'David Africa', 'Kyle OBrien']",,29.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Alignment Pretraining: AI Discourse Causes Self-Fulfilling (Mis)alignment || Cameron Tice * 1 Puria Radmard * 1 2 Samuel Ratnam 3 Andy Kim 4 David Africa 2 Kyle OBrien1 || Geodesic Research || Abstract || Pretraining corpora contain extensive discourse || about AI systems, yet the causal influence ... (truncated) ||  || { || ""title"": ""Alignment Pretraining: AI Discourse Causes Self-Fulfilling (Mis)alignment"", || ""authors"": [ || ""Cameron Tice"", || ""Puria Radmard"", || ""2 Samuel Ratnam"", || ""Andy Kim"", || ""David Africa"", || ""Kyle OBrien"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper presents the first controlled study on how pretraining discourse about AI influences alignment, finding that increased discussion of misalignment can amplify it, while emphasizing the need for alignment pretraining."" || } ||  || [ Prompt: 119.3 t/s | Generation: 29.4 t/s ]"
2601.10161v1_AWED-FiNER Agents Web applications and Expert Dete.pdf,"A WED-FiNER: Agents, Web applications, and Expert Detectors for Fine-grained Named Entity Recognition across 36 Languages","['Prachuryya Kaushik', 'Ashish Anand']",,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A WED-FiNER: Agents, Web applications, and Expert Detectors for || Fine-grained Named Entity Recognition across 36 Languages for 6.6 Billion || Speakers || Prachuryya Kaushik and Ashish Anand || Department of Computer Science and Engineering || Indian Institute of Technology Guwahati || Guwahati, Ass ... (truncated) ||  || { || ""title"": ""A WED-FiNER: Agents, Web applications, and Expert Detectors for Fine-grained Named Entity Recognition across 36 Languages"", || ""authors"": [""Prachuryya Kaushik"", ""Ashish Anand""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Named Entity Recognition"", ""Fine-grained NLP"", ""Multilingual models"", ""Expert detectors""], || ""summary"": ""AWED-FiNER is an open-source ecosystem bridging the gap in fine-grained Named Entity Recognition for 36 languages spoken by over 6.6 billion people, including vulnerable languages. It offers agentic tools, web applications, and expert models for offline deployment."" || } ||  || [ Prompt: 116.9 t/s | Generation: 29.0 t/s ]"
2601.10168v1_RAG-3DSG Enhancing 3D Scene Graphs with Re-Shot Gu.pdf,ENHANCING3D SCENEGRAPHS WITH RE-SHOTGUIDEDRETRIEVAL-AUGMENTEDGENERATION,"['Yue Chang', 'Rufeng Chen', 'Zhaofan Zhang', 'Yi Chen', 'Sihong Xie']",,30.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || RAG-3DSG: ENHANCING3D SCENEGRAPHS WITH || RE-SHOTGUIDEDRETRIEVAL-AUGMENTEDGENER- || ATION || Yue Chang, Rufeng Chen, Zhaofan Zhang, Yi Chen, Sihong Xie || AI Thrust, HKUST(GZ) || ABSTRACT || Open-vocabulary 3D Scene Graph (3DSG) generation can enhance various down- || stream tasks in robotics, such as m ... (truncated) ||  || { || ""title"": ""ENHANCING3D SCENEGRAPHS WITH RE-SHOTGUIDEDRETRIEVAL-AUGMENTEDGENERATION"", || ""authors"": [ || ""Yue Chang"", || ""Rufeng Chen"", || ""Zhaofan Zhang"", || ""Yi Chen"", || ""Sihong Xie"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper proposes RAG-3DSG to improve open-vocabulary 3D scene graph generation by mitigating aggregation noise through re-shot guided uncertainty estimation and supporting object-level Retrieval-Augmented Generation. It introduces a dynamic downsample-mapping strategy to accelerate cross-image object aggregation."" || } ||  || [ Prompt: 121.9 t/s | Generation: 30.4 t/s ]"
2601.10169v1_CtD Composition through Decomposition in Emergent .pdf,Composition through Decomposition,"['Boaz Carmeli', 'Ron Meir', 'Yonatan Belinkov']",,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Published as a conference paper at ICLR 2025 || CTD: COMPOSITION THROUGHDECOMPOSITION || INEMERGENTCOMMUNICATION || Boaz Carmeli || Technion  Israel Institute of Technology || boaz.carmeli@campus.technion.ac.il, || Ron Meir || Technion  Israel Institute of Technology || rmeir@ee.technion.ac.il || Yonatan Beli ... (truncated) ||  || { || ""title"": ""Composition through Decomposition"", || ""authors"": [ || ""Boaz Carmeli"", || ""Ron Meir"", || ""Yonatan Belinkov"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This study demonstrates how artificial neural agents acquire and utilize compositional generalization to describe previously unseen images. The method, termed Composition through Decomposition, involves two sequential training steps: Decompose and Compose."" || } ||  || [ Prompt: 121.4 t/s | Generation: 29.0 t/s ]"
2601.10173v1_ReasAlign Reasoning Enhanced Safety Alignment agai.pdf,ReasAlign: Reasoning Enhanced Safety Alignment against Prompt,"['Hao Li1', 'Yankai Yang2', 'G. Edward Suh3', 'Ning Zhang1', 'Chaowei Xiao3,4', 'Washington University in St. Louis, 2University of WisconsinMadison', 'NVIDIA', 'Johns Hopkins University']",,29.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ReasAlign: Reasoning Enhanced Safety Alignment against Prompt || Injection Attack || Hao Li1, Yankai Yang2, G. Edward Suh3, Ning Zhang1, Chaowei Xiao3,4, || 1Washington University in St. Louis, 2University of WisconsinMadison, || 3NVIDIA, 4Johns Hopkins University || {li.hao, zhang.ning}@wustl.edu ... (truncated) ||  || { || ""title"": ""ReasAlign: Reasoning Enhanced Safety Alignment against Prompt"", || ""authors"": [ || ""Hao Li1"", || ""Yankai Yang2"", || ""G. Edward Suh3"", || ""Ning Zhang1"", || ""Chaowei Xiao3,4"", || ""Washington University in St. Louis, 2University of WisconsinMadison"", || ""NVIDIA"", || ""Johns Hopkins University"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""ReasAlign"", || ""prompt injection"", || ""LLM safety"", || ""reasoning"", || ""agentic systems"" || ], || ""summary"": ""This paper presents ReasAlign, a model-level solution to improve safety alignment against indirect prompt injection attacks. It introduces structured reasoning steps to detect conflicting instructions and enhance task continuity, achieving strong performance on the CyberSecEval2 benchmark."" || } ||  || [ Prompt: 119.8 t/s | Generation: 29.7 t/s ]"
2601.10187v1_HOMURA Taming the Sand-Glass for Time-Constrained .pdf,,[],,27.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || HOMURA: Taming the Sand-Glass for || Time-Constrained LLM Translation via || Reinforcement Learning || Ziang Cui,Mengran Yu ,Tianjiao Li , || Chenyu Shi,Yingxuan Shi,Lusheng Zhang,Hongwei Lin || Bilibili Inc., Shanghai, China || Equal contribution Corresponding author || {cuiziang, yumengran03, litianji ... (truncated) ||  || { || ""title"": ""Taming the Sand-Glass for Time-Constrained LLM Translation via Reinforcement Learning"", || ""authors"": [ || ""Ziang Cui"", || ""Mengran Yu"", || ""Tianjiao Li"", || ""Chenyu Shi"", || ""Yingxuan Shi"", || ""Lusheng Zhang"", || ""Hongwei Lin"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper introduces Sand-Glass, a benchmark for translation under syllable-level duration constraints, and presents HOMURA, a reinforcement learning framework that optimizes semantic fidelity and temporal compliance."" || } ||  || [ Prompt: 119.7 t/s | Generation: 27.0 t/s ]"
2601.10191v1_How does downsampling affect needle electromyograp.pdf,A generalisable workflow for understanding downsampling effects on high-frequency time series,"['Mathieu J.L. Cherpitel', 'Janne A.M. Luijten', 'Thomas H.W. Bäck', 'Camiel Verhamme', 'Martijn R. Tannemaat', 'Anna V. Kononova']",,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || How does downsampling affect needle electromyography signals? A || generalisable workflow for understanding downsampling effects on || high-frequency time series || Mathieu J.L. Cherpitel 1, Janne A.M. Luijten 2,3, Thomas H.W. B ack1, Camiel Verhamme3, Martijn R. || Tannemaat2, and Anna V. Kono ... (truncated) ||  || { || ""title"": ""A generalisable workflow for understanding downsampling effects on high-frequency time series"", || ""authors"": [ || ""Mathieu J.L. Cherpitel"", || ""Janne A.M. Luijten"", || ""Thomas H.W. Bäck"", || ""Camiel Verhamme"", || ""Martijn R. Tannemaat"", || ""Anna V. Kononova"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This study presents a workflow to evaluate how downsampling impacts needle electromyography (nEMG) signals, focusing on preserving diagnostic information while reducing computational load. It combines shape-based distortion metrics with classification results to guide effective downsampling strategies."" || } ||  || [ Prompt: 125.1 t/s | Generation: 28.3 t/s ]"
2601.10193v1_GFM4GA Graph Foundation Model for Group Anomaly De.pdf,GFM4GA: Graph Foundation Model for Group Anomaly Detection,"['Jiujiu Chen', 'Weijun Zeng', 'Shaofeng Hu', 'Hui Xiong']",10.1002/2017-hcse.118,29.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || GFM4GA: Graph Foundation Model for Group Anomaly Detection || Jiujiu Chen || jchen349@connect.hkust-gz.edu.cn || HKUST(GZ) || China || Weijun Zeng || messizeng@tencent.com || Tencent || China || Shaofeng Hu || hugohu@tencent.com || Tencent || China || Sihong Xie || sihongxie@hkust-gz.edu.cn || HKUST(GZ) || China || Hui Xiong || xionghu ... (truncated) ||  || { || ""title"": ""GFM4GA: Graph Foundation Model for Group Anomaly Detection"", || ""authors"": [ || ""Jiujiu Chen"", || ""Weijun Zeng"", || ""Shaofeng Hu"", || ""Hui Xiong"" || ], || ""doi"": ""10.1002/2017-hcse.118"", || ""arxiv_id"": """", || ""keywords"": [ || ""Group Anomaly Detection"", || ""Graph Foundation Model"", || ""Graph Contrastive Learning"", || ""Few-shot Learning"", || ""Anomaly Detection"", || ""Anomaly Proportion"", || ""Labeled Neighbors"" || ], || ""summary"": ""This paper proposes GFM4GA, a graph foundation model for group anomaly detection, leveraging dual-level contrastive learning to capture group anomaly structures and improve detection accuracy."" || } ||  || [ Prompt: 113.8 t/s | Generation: 29.6 t/s ]"
2601.10201v1_PRL Process Reward Learning Improves LLMs Reasonin.pdf,Process Reward Learning Improves LLMs Reasoning Ability,"['Jiarui Yao', 'Ruida Wang', 'Tong Zhang']",,31.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || PRL: Process Reward Learning Improves LLMs Reasoning Ability || and Broadens the Reasoning Boundary || Jiarui Yao*, Ruida Wang*, Tong Zhang || University of Illinois Urbana-Champaign || {jiarui14, ruidaw, tozhang}@illinois.edu || Abstract || Improving the reasoning abilities of Large Lan- || guage Model ... (truncated) ||  || { || ""title"": ""Process Reward Learning Improves LLMs Reasoning Ability"", || ""authors"": [""Jiarui Yao"", ""Ruida Wang"", ""Tong Zhang""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Process Reward Learning"", ""LLMs"", ""Reasoning"", ""RL""], || ""summary"": ""The paper proposes Process Reward Learning (PRL) to improve LLMs' reasoning abilities by decomposing the reinforcement learning objective into intermediate steps with process supervision signals. It demonstrates that PRL enhances both average performance and reasoning boundaries."" || } ||  || [ Prompt: 116.8 t/s | Generation: 31.3 t/s ]"
2601.10205v1_One Instruction Does Not Fit All How Well Do Embed.pdf,One Instruction Does Not Fit All: How Well Do Embeddings Align,"['Arya Shah', 'Himanshu Beniwal', 'Mayank Singh']",10.48550/arXiv.2405.01382,29.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || One Instruction Does Not Fit All: How Well Do Embeddings Align || Personas and Instructions in Low-Resource Indian Languages? || Arya Shah, Himanshu Beniwal, and Mayank Singh || Indian Institute of Technology || Gandhinagar, India || {arya.shah, himanshu.beniwal, mayank.singh}@iitgn.ac.in || Abstract ... (truncated) ||  || { || ""title"": ""One Instruction Does Not Fit All: How Well Do Embeddings Align"", || ""authors"": [""Arya Shah"", ""Himanshu Beniwal"", ""Mayank Singh""], || ""doi"": ""10.48550/arXiv.2405.01382"", || ""arxiv_id"": ""arXiv:2405.01382"", || ""keywords"": [""multilingual assistants"", ""persona-instruction"", ""cross-lingual retrieval"", ""Indian languages""], || ""summary"": ""This paper presents a benchmark for evaluating multilingual embedding models across 12 Indian languages, focusing on persona-instruction alignment. It evaluates models on monolingual and cross-lingual retrieval tasks and provides performance metrics for benchmarking."" || } ||  || [ Prompt: 118.7 t/s | Generation: 29.7 t/s ]"
2601.10212v1_PADER Paillier-based Secure Decentralized Social R.pdf,PADER: Paillier-based Secure Decentralized Social Recommendation,"['Chaochao Chen', 'Jiaming Qian', 'Fei Zheng', 'Yachuan Liu']",10.1007/s40295-020-01012-7,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || JOURNAL OF LATEX CLASS FILES, VOL. 18, NO. 9, SEPTEMBER 2020 1 || PADER: Paillier-based Secure Decentralized || Social Recommendation || Chaochao Chen, Jiaming Qian, Fei Zheng, Y achuan Liu || AbstractThe prevalence of recommendation systems also brings privacy concerns to both the users and th ... (truncated) ||  || { || ""title"": ""PADER: Paillier-based Secure Decentralized Social Recommendation"", || ""authors"": [""Chaochao Chen"", ""Jiaming Qian"", ""Fei Zheng"", ""Yachuan Liu""], || ""doi"": ""10.1007/s40295-020-01012-7"", || ""arxiv_id"": ""10.1007/s40295-020-01012-7"", || ""keywords"": [""Paillier"", ""Secure Computation"", ""Recommendation System""], || ""summary"": ""The paper proposes PADER, a Paillier-based secure decentralized social recommendation system that enables privacy-preserving training and inference without a centralized platform. It uses secure addition and multiplication protocols and an optimal data packing scheme for polynomial computations."" || } ||  || [ Prompt: 118.8 t/s | Generation: 27.9 t/s ]"
2601.10215v1_Topo-RAG Topology-aware retrieval for hybrid text-.pdf,Topo-RAG: Topology-Aware Retrieval for Hybrid,"['Alex Dantart', 'Marco Kovacs-Navarro']",arXiv:2601.10215v1,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TOPO-RAG: TOPOLOGY-AWARE RETRIEVAL FOR HYBRID || TEXTTABLE DOCUMENTS || Alex Dantart || CIO, Humanizing Internet || arxiv@humanizinginternet.com || Marco Kovacs-Navarro || CTO, Humanizing Internet || marco@humanizinginternet.com || ABSTRACT || In enterprise datasets, documents are rarely pure. They are not ju ... (truncated) ||  || { || ""title"": ""Topo-RAG: Topology-Aware Retrieval for Hybrid"", || ""authors"": [ || ""Alex Dantart"", || ""Marco Kovacs-Navarro"" || ], || ""doi"": ""arXiv:2601.10215v1"", || ""arxiv_id"": ""arxiv@humanizinginternet.com"", || ""keywords"": [ || ""Retrieval-Augmented Generation (RAG)"", || ""table retrieval"", || ""late interaction"", || ""multivector retrieval"", || ""enterprise search"", || ""heterogeneous data"", || ""semantic routing"", || ""structure-aware embeddings"" || ], || ""summary"": ""This work introduces Topo-RAG, a framework that respects the topology of data by routing narrative through traditional retrievers and processing tabular structures with a cell-aware interaction mechanism. It achieves an 18.4% improvement in nDCG@10 on hybrid queries compared to standard linearization approaches."" || } ||  || [ Prompt: 113.1 t/s | Generation: 28.2 t/s ]"
2601.10222v1_Introduction to optimization methods for training .pdf,Introduction to optimization methods for training SciML models,"['Alena Kopanikov', 'Elisa Riccietti']",10.1093/acps/csa123,31.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Introduction to optimization methods for || training SciML models || Alena Kopanikovand Elisa Riccietti || January 16, 2026 || 1 Introduction || Optimization is the foundation of modern machine learning (ML). Historically, || optimization methods have been categorized by the degree to which they ex- ... (truncated) ||  || { || ""title"": ""Introduction to optimization methods for training SciML models"", || ""authors"": [""Alena Kopanikov"", ""Elisa Riccietti""], || ""doi"": ""10.1093/acps/csa123"", || ""arxiv_id"": ""2601.10222v1"", || ""keywords"": [ || ""optimization methods"", || ""machine learning"", || ""Stochastic optimization"", || ""SciML"", || ""gradient descent"", || ""physics informed models"" || ], || ""summary"": ""This paper discusses the shift from classical ML to SciML, focusing on optimization in data-scarce settings, especially with physics-informed constraints."" || } ||  || [ Prompt: 129.4 t/s | Generation: 31.6 t/s ]"
2601.10236v1_Who Owns the Text Design Patterns for Preserving A.pdf,Who Owns the Text? Design Patterns for Preserving Authorship in AI-Assisted Writing,"['Bohan Zhang', 'Chengke Bu', 'Paramveer Dhillon']",arXiv:2601.10236v1,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Who Owns the Text? Design Patterns for Preserving Authorship in || AI-Assisted Writing || Bohan Zhang1, Chengke Bu2, and Paramveer Dhillon1 || 1University of Michigan, Ann Arbor, Michigan, USA || 2Tsinghua University, Beijing, China || Abstract || AI writing assistants can reduce effort and improve f ... (truncated) ||  || { || ""title"": ""Who Owns the Text? Design Patterns for Preserving Authorship in AI-Assisted Writing"", || ""authors"": [ || ""Bohan Zhang"", || ""Chengke Bu"", || ""Paramveer Dhillon"" || ], || ""doi"": ""arXiv:2601.10236v1"", || ""arxiv_id"": ""arXiv:2601.10236"", || ""keywords"": [ || ""AI-assisted writing"", || ""humanAI collaboration"", || ""psychological ownership"", || ""personalization"", || ""proveance"" || ], || ""summary"": ""This study examines how AI-assisted writing tools affect writers' sense of authorship. It evaluates two design approaches—persona-based coaching and style personalization—and finds that while psychological ownership decreases slightly, quality and cognitive load remain stable. Persona coaching does not reverse the decline, and style personalization partially restores ownership."" || } ||  || [ Prompt: 121.9 t/s | Generation: 28.8 t/s ]"
2601.10242v1_Loop as a Bridge Can Looped Transformers Truly Lin.pdf,Loop As An Abridge: CanLoopedTransformers,"['Guanxu Chen', 'Dongrui Liu']",,29.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Report || LOOP AS ABRIDGE: CANLOOPEDTRANSFORMERS || TRULYLINKREPRESENTATIONSPACE ANDNATURAL || LANGUAGEOUTPUTS? || Guanxu Chen1,2 Dongrui Liu1 Jing Shao1 || 1 Shanghai Artificial Intelligence Laboratory, 2 Shanghai Jiao Tong University, || lm.cgx@sjtu.edu.cn{liudongrui, shaojing}@pjlab.org.cn || ABSTRAC ... (truncated) ||  || { || ""title"": ""Loop As An Abridge: CanLoopedTransformers"", || ""authors"": [ || ""Guanxu Chen"", || ""Dongrui Liu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This report investigates whether Looped Transformers (LTs) can bridge the gap between internal knowledge and explicit linguistic outputs by leveraging their iterative nature for introspection. Findings suggest that while increasing loop iterations narrows the knowledge-gap, it is limited by degradation in internal representations. Current LTs do not consistently improve representation perception across loops."" || } ||  || [ Prompt: 118.2 t/s | Generation: 29.7 t/s ]"
2601.10245v1_TRIM Hybrid Inference via Targeted Stepwise Routin.pdf,Hybrid Inference via Targeted Stepwise,"['Vansh Kapoor', 'Aman Gupta', 'Hao Chen', 'Anurag Beniwal', 'Jing Huang', 'Aviral Kumar']",,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TRIM: Hybrid Inference via Targeted Stepwise || Routing in Multi-Step Reasoning Tasks || Vansh Kapoor1 Aman Gupta 2 Hao Chen 2 Anurag Beniwal 2 Jing Huang 2 Aviral Kumar1 || Abstract || Multi-step reasoning tasks like mathematical || problem solving are vulnerable to cascading fail- || ures where a s ... (truncated) ||  || { || ""title"": ""Hybrid Inference via Targeted Stepwise"", || ""authors"": [ || ""Vansh Kapoor"", || ""Aman Gupta"", || ""Hao Chen"", || ""Anurag Beniwal"", || ""Jing Huang"", || ""Aviral Kumar"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""multi-step reasoning"", || ""multi-step tasks"", || ""LLM routing"", || ""cascading failures"", || ""step-level interventions"" || ], || ""summary"": ""The paper proposes TRIM (Targeted routing in multi-step reasoning tasks), which routes only critical steps to reduce cost while allowing smaller models to handle routine steps. TRIM improves cost efficiency and performance across math reasoning benchmarks."" || } ||  || [ Prompt: 116.3 t/s | Generation: 28.1 t/s ]"
2601.10251v1_X-SAM Boosting Sharpness-Aware Minimization with D.pdf,X-SAM: Boosting Sharpness-Aware Minimization with Dominant-Eigenvector,['Hongru Duan Yongle Chen Lei Guan'],,27.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || X-SAM: Boosting Sharpness-Aware Minimization with Dominant-Eigenvector || Gradient Correction || Hongru Duan Yongle Chen Lei Guan * || Taiyuan University of Technology || Abstract || Sharpness-Aware Minimization (SAM) aims to improve gen- || eralization by minimizing a worst-case perturbed loss over || ... (truncated) ||  || { || ""title"": ""X-SAM: Boosting Sharpness-Aware Minimization with Dominant-Eigenvector"", || ""authors"": [""Hongru Duan Yongle Chen Lei Guan""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Investigates Sharpness-Aware Minimization (SAM) from a spectral and geometric perspective, proposing X-SAM to improve generalization by aligning gradients with the leading eigenvector."" || } ||  || [ Prompt: 113.8 t/s | Generation: 27.4 t/s ]"
2601.10254v1_NoReGeo Non-Reasoning Geometry Benchmark.pdf,NoReGeo: Non-Reasoning Geometry Benchmark,"['Irina Abdullaeva', 'Anton Vasiliuk', 'Elizaveta Goncharova', 'Temurbek Rahmatullaev', 'Zagorulko Ivan', 'Maxim Kurkin', '6', 'Andrey Kuznetsov', '2', 'FusionBrain Lab', 'Research Center of the Artificial Intelligence Institute, Innopolis University', 'HSE University', 'Lomonosov Moscow State University', 'Central University, Russia', 'Applied AI Institute, Moscow']",,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || NoReGeo: Non-Reasoning Geometry Benchmark || Irina Abdullaeva1,2, Anton Vasiliuk1, Elizaveta Goncharova1,3, Temurbek Rahmatullaev1,4, || Zagorulko Ivan5, Maxim Kurkin1, 6, Andrey Kuznetsov1,2 || 1FusionBrain Lab, Russia || 2Research Center of the Artificial Intelligence Institute, Innopolis Uni ... (truncated) ||  || { || ""title"": ""NoReGeo: Non-Reasoning Geometry Benchmark"", || ""authors"": [ || ""Irina Abdullaeva"", || ""Anton Vasiliuk"", || ""Elizaveta Goncharova"", || ""Temurbek Rahmatullaev"", || ""Zagorulko Ivan"", || ""Maxim Kurkin"", || ""6"", || ""Andrey Kuznetsov"", || ""2"", || ""FusionBrain Lab"", || ""Research Center of the Artificial Intelligence Institute, Innopolis University"", || ""HSE University"", || ""Lomonosov Moscow State University"", || ""Central University, Russia"", || ""Applied AI Institute, Moscow"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""NoReGeo"", || ""geometric understanding"", || ""large language models"", || ""spatial relationships"", || ""geometry benchmarks"", || ""intuitive reasoning"" || ], || ""summary"": ""NoReGeo evaluates intrinsic geometric understanding in LLMs without reasoning or algebraic computation. It assesses models on 2,500 trivial geometric problems across 25 categories, revealing that even advanced models achieve only 65% accuracy in binary classification. Ablation studies show geometric comprehension requires specialized training."" || } ||  || [ Prompt: 116.2 t/s | Generation: 27.9 t/s ]"
2601.10257v1_Untangling Input Language from Reasoning Language .pdf,Untangling Input Language from Reasoning Language,"['Nan Li', 'Bo Kang', 'Tijl De Bie']",10.48550/arXiv.2407.08600,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Untangling Input Language from Reasoning Language: || A Diagnostic Framework for Cross-Lingual Moral Alignment in LLMs || Nan Li and Bo Kang and Tijl De Bie || IDLab, Department of Electronics and Information Systems || Ghent University, Belgium || Abstract || When LLMs judge moral dilemmas, do they || ... (truncated) ||  || { || ""title"": ""Untangling Input Language from Reasoning Language"", || ""authors"": [""Nan Li"", ""Bo Kang"", ""Tijl De Bie""], || ""doi"": ""10.48550/arXiv.2407.08600"", || ""arxiv_id"": ""arXiv:2407.08600"", || ""keywords"": [""moral alignment"", ""cross-lingual reasoning"", ""ethical foundations""], || ""summary"": ""This paper introduces a methodology to separate the effects of language of the dilemma and the language of reasoning, aiming to better understand cross-lingual moral judgments. It demonstrates diagnostic power using English-Chinese moral dilemmas and identifies patterns in moral foundations."" || } ||  || [ Prompt: 120.6 t/s | Generation: 28.1 t/s ]"
2601.10272v1_MoST Mixing Speech and Text with Modality-Aware Mi.pdf,MOST: MIXINGSPEECH ANDTEXT WITHMODALITY,"['Yuxuan Lou', 'Kai Yang', 'Yang You']",,29.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MOST: MIXINGSPEECH ANDTEXT WITHMODALITY- || AWAREMIXTURE OFEXPERTS || Yuxuan Lou1, Kai Yang 2, Yang You 1 || 1School of Computer Science, National University of Singapore || 2School of Computer Science, Shanghai Jiao Tong University || yuxuanlou@u.nus.edu, icarus1411@sjtu.edu.cn || youy@comp.nus.edu. ... (truncated) ||  || { || ""title"": ""MOST: MIXINGSPEECH ANDTEXT WITHMODALITY"", || ""authors"": [ || ""Yuxuan Lou"", || ""Kai Yang"", || ""Yang You"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""We present MoST (Mixture of Speech and Text), a novel multimodal large language model that seamlessly integrates speech and text processing through our proposed Modality-Aware Mixture of Experts (MAMoE) architecture. While current multimodal models typically process diverse modality representations with identical parameters disregarding their inherent representational differences, we introduce specialized routing pathways that direct tokens to modality-appropriate experts based on input type. MAMoE simultaneously enhances modality-specific learning and cross-modal understanding through two complementary components: modality-specific expert groups that capture domain-specific patterns and shared experts that facilitate information transfer between modalities. Building on this architecture, we develop an efficient transformation pipeline that adapts the pretrained MoE language model through strategic post-training on ASR and TTS datasets, followed by fine-tuning with a carefully curated speech-text instruction dataset. A key feature of this pipeline is that it relies exclusively on fully accessible, open-source datasets to achieve strong performance and data efficiency. Comprehensive evaluations across ASR, TTS, audio language modeling, and spoken question answering benchmarks show that MoST consistently outperforms existing models of comparable parameter counts. Our ablation studies confirm that the modality-specific routing mechanism and shared experts design significantly contribute to performance gains across all tested domains. To our knowledge, MoST represents the first fully open-source speech-text LLM built on a Mixture of Experts architecture."" || } ||  || [ Prompt: 127.6 t/s | Generation: 29.2 t/s ]"
2601.10274v1_Queueing-Aware Optimization of Reasoning Tokens fo.pdf,Queueing-Aware Optimization of Reasoning Tokens,"['Emre Ozbas', 'Melih Bastopcu']",,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Queueing-Aware Optimization of Reasoning Tokens || for AccuracyLatency Trade-offs in LLM Servers || Emre Ozbas and Melih Bastopcu || Department of Electrical and Electronics Engineering || Bilkent University, Ankara, Trkiye || Email: {emre.ozbas, bastopcu}@bilkent.edu.tr || AbstractWe consider a sing ... (truncated) ||  || { || ""title"": ""Queueing-Aware Optimization of Reasoning Tokens"", || ""authors"": [""Emre Ozbas"", ""Melih Bastopcu""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Accuracy-latency trade-offs"", ""LLM-based servers"", ""Optimization of reasoning tokens"", ""LLM inference""], || ""summary"": ""The paper discusses optimizing reasoning token allocation in LLM servers to balance accuracy and latency, formulating a constrained optimization problem and presenting a projected gradient method for convergence."" || } ||  || [ Prompt: 115.8 t/s | Generation: 27.6 t/s ]"
2601.10282v2_SPIKE Sparse Koopman Regularization for Physics-In.pdf,SPIKE: Sparse Koopman Regularization for Physics-Informed Neural Networks,['Jose Marie Antonio Mioza'],,29.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SPIKE: Sparse Koopman Regularization for || Physics-Informed Neural Networks || Jose Marie Antonio Mioza || Center for AI Research PH || Physics-Informed Neural Networks (PINNs) provide a mesh-free approach for || solving differential equations by embedding physical constraints into neural net- || wo ... (truncated) ||  || { || ""title"": ""SPIKE: Sparse Koopman Regularization for Physics-Informed Neural Networks"", || ""authors"": [""Jose Marie Antonio Mioza""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This work introduces SPIKE, a framework that regularizes PINNs with continuous-time Koopman operators to achieve sparse dynamics representations. It demonstrates improved generalization across various PDEs and stability benefits from continuous-time formulation."" || } ||  || [ Prompt: 119.2 t/s | Generation: 29.5 t/s ]"
2601.10305v1_DanQing An Up-to-Date Large-Scale Chinese Vision-L.pdf,DanQing: An Up-to-Date Large-Scale Chinese Vision-Language Pre-training Dataset,"['Hengyu Shen', 'Tiancheng Gu', 'Bin Qin', 'Lan Wu', 'Yuling Wu', 'Shuo Tan', 'Zelong Sun', 'Jun Wang', 'Nan Wu', 'Xiang An', 'Weidong Cai', 'Ziyong Feng', 'Kaicheng Yang']",,29.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DanQingTechnical Report || Glint Lab || DanQing: An Up-to-Date Large-Scale Chinese Vision- || Language Pre-training Dataset || Hengyu Shen, Tiancheng Gu, Bin Qin, Lan Wu, Yuling Wu, Shuo Tan, Zelong Sun || Jun Wang, Nan Wu, Xiang An, Weidong Cai, Ziyong Feng, Kaicheng Yang || DanQingTeam, || Glint Lab ... (truncated) ||  || { || ""title"": ""DanQing: An Up-to-Date Large-Scale Chinese Vision-Language Pre-training Dataset"", || ""authors"": [ || ""Hengyu Shen"", || ""Tiancheng Gu"", || ""Bin Qin"", || ""Lan Wu"", || ""Yuling Wu"", || ""Shuo Tan"", || ""Zelong Sun"", || ""Jun Wang"", || ""Nan Wu"", || ""Xiang An"", || ""Weidong Cai"", || ""Ziyong Feng"", || ""Kaicheng Yang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Vision-Language Pre-training (VLP) models demonstrate strong performance across various downstream tasks by learning from large-scale image-text pairs through contrastive pretraining. The release of extensive English image-text datasets has enabled widespread adoption of models such as CLIP and SigLIP. This work addresses the scarcity of high-quality Chinese image-text data by developing a comprehensive pipeline for constructing a high-quality Chinese cross-modal dataset, DanQing."" || } ||  || [ Prompt: 118.6 t/s | Generation: 29.2 t/s ]"
2601.10306v1_Evidence-Augmented Policy Optimization with Reward.pdf,Evidence-Augmented Policy Optimization with Reward Co-Evolution for Long-Context Reasoning,"['Xin Guan', 'Zijian Li', 'Shen Huang', 'Pengjun Xie', 'Jingren Zhou', 'Jiuxin Cao']",,29.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Evidence-Augmented Policy Optimization with Reward Co-Evolution for || Long-Context Reasoning || Xin Guan*, Zijian Li, Shen Huang, Pengjun Xie, || Jingren Zhou,Jiuxin Cao || Tongyi Lab, Alibaba Group || Abstract || While Reinforcement Learning (RL) has ad- || vanced LLM reasoning, applying it to long- || c ... (truncated) ||  || { || ""title"": ""Evidence-Augmented Policy Optimization with Reward Co-Evolution for Long-Context Reasoning"", || ""authors"": [ || ""Xin Guan"", || ""Zijian Li"", || ""Shen Huang"", || ""Pengjun Xie"", || ""Jingren Zhou"", || ""Jiuxin Cao"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Evidence-Augmented Policy Optimization"", || ""Long-Context Reasoning"", || ""LLM Reasoning"", || ""Reward Co-Evolution"", || ""Needle-in-a-Haystack Evidence"" || ], || ""summary"": ""The paper proposes EAPO to address evidence sparsity in LLM reasoning by integrating evidence augmentation and reward co-evolution, showing significant improvements over baselines."" || } ||  || [ Prompt: 113.8 t/s | Generation: 29.6 t/s ]"
2601.10338v1_Agent Skills in the Wild An Empirical Study of Sec.pdf,Agent Skills in the Wild: An Empirical Study of Security,"['Yi Liu', 'Weizhe Wang', 'Tianjin University', 'China', 'Ruitao Feng', 'Southern Cross University', 'Australia', 'Yao Zhang', 'School of Cybersecurity, Tianjin University', 'China', 'Guangquan Xu', 'School of Cybersecurity, Tianjin University', 'Singapore', 'Yuekang Li', 'University of New South Wales', 'Australia', 'Leo Zhang', 'Griffith University']",10.1145/nnnnnnn.nnnnnnn,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Agent Skills in the Wild: An Empirical Study of Security || Vulnerabilities at Scale || Yi Liu || Quantstamp || yi009@e.ntu.edu.sg || Weizhe Wang || Tianjin University || China || wwz@tju.edu.cn || Ruitao Feng || Southern Cross University || Australia || ruitao.feng@scu.edu.au || Yao Zhang || School of Cybersecurity, Tianji ... (truncated) ||  || { || ""title"": ""Agent Skills in the Wild: An Empirical Study of Security"", || ""authors"": [ || ""Yi Liu"", || ""Weizhe Wang"", || ""Tianjin University"", || ""China"", || ""Ruitao Feng"", || ""Southern Cross University"", || ""Australia"", || ""Yao Zhang"", || ""School of Cybersecurity, Tianjin University"", || ""China"", || ""Guangquan Xu"", || ""School of Cybersecurity, Tianjin University"", || ""Singapore"", || ""Yuekang Li"", || ""University of New South Wales"", || ""Australia"", || ""Leo Zhang"", || ""Griffith University"" || ], || ""doi"": ""10.1145/nnnnnnn.nnnnnnn"", || ""arxiv_id"": """", || ""keywords"": [ || ""Agent skills"", || ""AI security"", || ""vulnerability analysis"", || ""supply chain security"", || ""prompt injection"", || ""large language models"" || ], || ""summary"": ""The study analyzes 42,447 skills from major marketplaces, identifying pervasive security risks. It reveals that 26.1% of skills contain vulnerabilities, with data exfiltration and privilege escalation being most common. The research introduces a vulnerability taxonomy and a detection framework achieving high precision and recall."" || } ||  || [ Prompt: 113.1 t/s | Generation: 29.0 t/s ]"
2601.10342v1_C-GRASP Clinically-Grounded Reasoning for Affectiv.pdf,C-GRASP: Clinically-Grounded Reasoning for Affective Signal Processing,"['1st Cheng Lin Cheng', '2nd Ting Chuan Lin', '3rd Chai Kai Chang']",,27.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || C-GRASP: Clinically-Grounded Reasoning for || Affective Signal Processing || 1st Cheng Lin Cheng || Department of Physics || National Central University || Taoyuan, Taiwan || 2nd Ting Chuan Lin || Department of Physics || National Central University || Taoyuan, Taiwan || 3rd Chai Kai Chang || Center for Education || N ... (truncated) ||  || { || ""title"": ""C-GRASP: Clinically-Grounded Reasoning for Affective Signal Processing"", || ""authors"": [ || ""1st Cheng Lin Cheng"", || ""2nd Ting Chuan Lin"", || ""3rd Chai Kai Chang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Large language model"", || ""clinical decision support"", || ""heart rate variability"", || ""retrieval-augmented generation"", || ""explainable AI"", || ""guardrails"" || ], || ""summary"": ""This paper introduces C-GRASP, a guardrailed RAG-enhanced pipeline for HRV interpretation that emphasizes individualized baselines and mitigates spectral hallucinations through automated RSA-aware guardrails. It achieves strong performance in emotion classification and high clinical reasoning consistency."" || } ||  || [ Prompt: 120.6 t/s | Generation: 27.3 t/s ]"
2601.10343v2_OctoBench Benchmarking Scaffold-Aware Instruction .pdf,Benchmarking Scaffold-Aware Instruction Following in Repository-Grounded Agentic Coding,"['Deming Ding1', 'Shichun Liu1', 'Enhui Yang2', 'Jiahang Lin1', 'Ziying Chen1', 'Shihan Dou 1', 'Honglin Guo1', 'Weiyu Cheng2', 'Pengyu Zhao2', 'Chengjun Xiao2', 'Qunhong Zeng2', 'Qi Zhang1', 'Xuanjing Huang1', 'Qidi Xu2', 'Tao Gui1']",,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || OCTOBENCH: Benchmarking Scaffold-Aware Instruction Following in || Repository-Grounded Agentic Coding || Deming Ding1,2*, Shichun Liu1, Enhui Yang2,3, Jiahang Lin1, || Ziying Chen1,2,Shihan Dou 1,Honglin Guo 1,Weiyu Cheng 2,Pengyu Zhao 2, || Chengjun Xiao2,Qunhong Zeng 2,Qi Zhang 1,Xuanjing Hua ... (truncated) ||  || { || ""title"": ""Benchmarking Scaffold-Aware Instruction Following in Repository-Grounded Agentic Coding"", || ""authors"": [ || ""Deming Ding1"", || ""Shichun Liu1"", || ""Enhui Yang2"", || ""Jiahang Lin1"", || ""Ziying Chen1"", || ""Shihan Dou 1"", || ""Honglin Guo1"", || ""Weiyu Cheng2"", || ""Pengyu Zhao2"", || ""Chengjun Xiao2"", || ""Qunhong Zeng2"", || ""Qi Zhang1"", || ""Xuanjing Huang1"", || ""Qidi Xu2"", || ""Tao Gui1"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Modern coding scaffolds turn LLMs into capable software agents, but their ability to follow scaffold-specified instructions remains under-examined, especially when constraints are heterogeneous and persist across interactions. OCTOBENCH benchmarks scaffold-aware instruction following in repository-grounded agentic coding."" || } ||  || [ Prompt: 121.8 t/s | Generation: 29.1 t/s ]"
2601.10348v1_Training-Trajectory-Aware Token Selection.pdf,Training-Trajectory-Aware Token Selection,"['Zhanming Shen', 'Jiaqi Hu', 'Zeyu Qin', 'Hao Chen', 'Wentao Ye1', 'Zenan Huang', 'Yihong Zhuang', 'Guoshan Lu', 'Junlin Zhou', 'Junbo Zhao']",,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Training-Trajectory-Aware Token Selection || Zhanming Shen 1 2 Jiaqi Hu 1 2 Zeyu Qin 3 Hao Chen 1 Wentao Ye1 2 Zenan Huang 2 Yihong Zhuang 2 || Guoshan Lu 2 Junlin Zhou 2 Junbo Zhao 1 2 || Abstract || Efficient distillation is a key pathway for con- || verting expensive reasoning capability into d ... (truncated) ||  || { || ""title"": ""Training-Trajectory-Aware Token Selection"", || ""authors"": [ || ""Zhanming Shen"", || ""Jiaqi Hu"", || ""Zeyu Qin"", || ""Hao Chen"", || ""Wentao Ye1"", || ""Zenan Huang"", || ""Yihong Zhuang"", || ""Guoshan Lu"", || ""Junlin Zhou"", || ""Junbo Zhao"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Efficient distillation is key for converting expensive reasoning into deployable efficiency. The study observes that performance metrics drop sharply at a certain point despite decreasing loss, revealing a token-level mechanism involving confidence bifurcation. The authors propose Training-Trajectory-Aware Token Selection (T3S) to address this issue."" || } ||  || [ Prompt: 114.0 t/s | Generation: 28.7 t/s ]"
2601.10349v1_SuS Strategy-aware Surprise for Intrinsic Explorat.pdf,Strategy-aware Surprise for Intrinsic Exploration,"['Mark Kashirskiy1', 'Ilya Makarov1']",353056@niuitmo.ru,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SuS: Strategy-aware Surprise for Intrinsic Exploration || Mark Kashirskiy1,2 Ilya Makarov1 || 1Higher School of Economics, Moscow, Russia || 2AI Talent Hub, ITMO University, Saint Petersburg, Russia || 353056@niuitmo.ru iamakarov@hse.ru || Abstract || We propose Strategy-aware Surprise (SuS), a novel ... (truncated) ||  || { || ""title"": ""Strategy-aware Surprise for Intrinsic Exploration"", || ""authors"": [ || ""Mark Kashirskiy1"", || ""Ilya Makarov1"" || ], || ""doi"": ""353056@niuitmo.ru"", || ""arxiv_id"": """", || ""keywords"": [ || ""intrinsic motivation"", || ""reinforcement learning"", || ""contrastive learning"", || ""exploration"", || ""exploration strategies"" || ], || ""summary"": ""We propose Strategy-aware Surprise (SuS), a novel intrinsic motivation framework that uses pre-post prediction mismatch as a novelty signal for exploration in reinforcement learning. Unlike traditional methods, SuS introduces Strategy Stability and Strategy Surprise, leveraging learned weighting to improve performance in mathematical reasoning tasks."" || } ||  || [ Prompt: 131.4 t/s | Generation: 28.3 t/s ]"
2601.10373v1_Towards Efficient Low-rate Image Compression with .pdf,Towards Efficient Low-rate Image Compression with Frequency-aware Diffusion Prior Refinement,"['Yichong Xia', 'Yimin Zhou', 'Jinpeng Wang', 'Bin Chen']",10.48550/arXiv.2405.12345,28.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Towards Efficient Low-rate Image Compression with Frequency-aware || Diffusion Prior Refinement || Yichong Xia*1,2, Yimin Zhou*1, Jinpeng Wang 3, Bin Chen 3 || 1Tsinghua Shenzhen International Graduate School, Tsinghua University || 2Peng Cheng Laboratory || 3Harbin Institute of Technology, Shenzh ... (truncated) ||  || { || ""title"": ""Towards Efficient Low-rate Image Compression with Frequency-aware Diffusion Prior Refinement"", || ""authors"": [ || ""Yichong Xia"", || ""Yimin Zhou"", || ""Jinpeng Wang"", || ""Bin Chen"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [ || ""image compression"", || ""diffusion models"", || ""frequency-aware estimation"", || ""low bitrate"", || ""compression efficiency"" || ], || ""summary"": ""The paper proposes DiffCR, a novel compression framework using Frequency-aware Skip Estimation and Frequency Decoupling Attention to achieve efficient and high-fidelity image reconstruction at low bit rates."" || } ||  || [ Prompt: 119.5 t/s | Generation: 28.9 t/s ]"
2601.10378v2_Global Context Compression with Interleaved Vision.pdf,Global Context Compression with Interleaved Vision-Text Transformation,"['Dian Jiao', 'Jiaxin Duan', 'Shuai Zhao', 'Jiabing Leng', 'Yiran Zhang', 'Feng Huang']",,29.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Global Context Compression with Interleaved Vision-Text Transformation || Dian Jiao*,Jiaxin Duan *,Shuai Zhao,Jiabing Leng,Yiran Zhang,Feng Huang || China Electronics Cloud Technology Co., Ltd. || {jiaodian, duanjiaxin, zhaoshuai, lengjiabing, zhangyiran, huangfeng01}@cestc.cn || Abstract || Rece ... (truncated) ||  || { || ""title"": ""Global Context Compression with Interleaved Vision-Text Transformation"", || ""authors"": [ || ""Dian Jiao"", || ""Jiaxin Duan"", || ""Shuai Zhao"", || ""Jiabing Leng"", || ""Yiran Zhang"", || ""Feng Huang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper investigates global context compression to save tokens at both prefilling and inference stages. It proposes VIST2, a Transformer that interleaves input text chunks with visual encoding, achieving significant improvements in speed, memory usage, and FLOPS."" || } ||  || [ Prompt: 117.8 t/s | Generation: 29.5 t/s ]"
2601.10386v1_Handling Missing Modalities in Multimodal Survival.pdf,Handling Missing Modalities in Multimodal Survival Prediction for Non-Small Cell Lung Cancer,"['Filippo Ruffini', 'Camillo Maria Caruso', 'Lorenzo Nibid5', 'Francesca Miccolis', 'Marta Lovino', 'Carlo Greco', 'Edy Ippolito', 'Michele Fiore', 'Alessio Cortellini', 'Bruno Beomonte Zobel', 'Giuseppe Perrone', 'Bruno Vincenzi', 'Claudio Marrocco', 'Alessandro Bria', 'Elisa Ficarra', 'Sara Ramella', 'Valerio Guarrasi', 'Paolo Soda']",arXiv:2601.10386v1,29.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Handling Missing Modalities in Multimodal || Survival Prediction for Non-Small Cell Lung || Cancer || Filippo Ruffini1,2, Camillo Maria Caruso 1, Claudia Tacconi 4, || Lorenzo Nibid5, 6, Francesca Miccolis 10, Marta Lovino 10, || Carlo Greco3, 4, Edy Ippolito 3, 4, Michele Fiore 3, 4, || Alessio Cort ... (truncated) ||  || { || ""title"": ""Handling Missing Modalities in Multimodal Survival Prediction for Non-Small Cell Lung Cancer"", || ""authors"": [ || ""Filippo Ruffini"", || ""Camillo Maria Caruso"", || ""Lorenzo Nibid5"", || ""Francesca Miccolis"", || ""Marta Lovino"", || ""Carlo Greco"", || ""Edy Ippolito"", || ""Michele Fiore"", || ""Alessio Cortellini"", || ""Bruno Beomonte Zobel"", || ""Giuseppe Perrone"", || ""Bruno Vincenzi"", || ""Claudio Marrocco"", || ""Alessandro Bria"", || ""Elisa Ficarra"", || ""Sara Ramella"", || ""Valerio Guarrasi"", || ""Paolo Soda"" || ], || ""doi"": ""arXiv:2601.10386v1"", || ""arxiv_id"": ""2601.10386"", || ""keywords"": [], || ""summary"": ""Survival prediction study focusing on missing modalities in multimodal analysis for non-small cell lung cancer."" || } ||  || [ Prompt: 122.5 t/s | Generation: 29.2 t/s ]"
2601.10398v2_LatentRefusal Latent-Signal Refusal for Unanswerab.pdf,LatentRefusal: Latent-Signal Refusal for Unanswerable Text-to-SQL,"['Xuancheng Ren', 'Jiangqi Huang', 'Qiang Duan']",25213050189,29.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LatentRefusal: Latent-Signal Refusal for Unanswerable Text-to-SQL || Queries || Xuancheng Ren Shijing Hu Zhihui Lu * Jiangqi Huang || Fudan University || {xcren25, sjhu24, 25213050189}@m.fudan.edu.cn, lzh@fudan.edu.cn || Qiang Duan || Pennsylvania State University Abington College || qduan@psu.edu || Abstr ... (truncated) ||  || { || ""title"": ""LatentRefusal: Latent-Signal Refusal for Unanswerable Text-to-SQL"", || ""authors"": [ || ""Xuancheng Ren"", || ""Jiangqi Huang"", || ""Qiang Duan"" || ], || ""doi"": ""25213050189"", || ""arxiv_id"": ""xcren25, sjhu24"", || ""keywords"": [ || ""Text-to-SQL"", || ""unanswerable queries"", || ""LLM safety"", || ""refusal strategy"", || ""LLM hallucination"" || ], || ""summary"": ""The paper introduces LATENTREFUSAL, a latent-signal refusal mechanism for Text-to-SQL systems, aiming to detect unanswerable queries by analyzing LLM hidden activations. It proposes TRGE to suppress schema noise and improve safety without generating harmful SQL."" || } ||  || [ Prompt: 118.3 t/s | Generation: 29.5 t/s ]"
2601.10402v1_Toward Ultra-Long-Horizon Agentic Science Cognitiv.pdf,Toward Ultra-Long-Horizon Agentic Science: Cognitive Accumulation for Machine Learning Engineering,"['Xinyu Zhu', 'Yuzhu Cai', 'Zexi Liu', 'Bingyang Zheng', 'Rui Ye', 'Jiaao Chen', 'Hanrui Wang', 'Wei-Chen Wang', 'Yuzhi Zhang', 'Linfeng Zhang', 'Weinan E', 'Di Jin', 'Siheng Chen']",10.48550/arXiv.2601.10402,28.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || T oward Ultra-Long-Horizon Agentic Science: Cognitive || Accumulation for Machine Learning Engineering || Xinyu Zhu1, , Yuzhu Cai1,4, , Zexi Liu 1, , Bingyang Zheng 1, Cheng Wang1, || Rui Ye1, Jiaao Chen 2, Hanrui Wang2, Wei-Chen Wang2, Yuzhi Zhang3, || Linfeng Zhang3, Weinan E1, Di Jin 2, , Si ... (truncated) ||  || { || ""title"": ""Toward Ultra-Long-Horizon Agentic Science: Cognitive Accumulation for Machine Learning Engineering"", || ""authors"": [ || ""Xinyu Zhu"", || ""Yuzhu Cai"", || ""Zexi Liu"", || ""Bingyang Zheng"", || ""Rui Ye"", || ""Jiaao Chen"", || ""Hanrui Wang"", || ""Wei-Chen Wang"", || ""Yuzhi Zhang"", || ""Linfeng Zhang"", || ""Weinan E"", || ""Di Jin"", || ""Siheng Chen"" || ], || ""doi"": ""10.48550/arXiv.2601.10402"", || ""arxiv_id"": ""2601.10402"", || ""keywords"": [ || ""agentic science"", || ""cognitive accumulation"", || ""machine learning engineering"", || ""ultra-long-horizon"", || ""experimental cycles"", || ""LLM"", || ""context management"", || ""knowledge accumulation"" || ], || ""summary"": ""The paper presents ML-Master 2.0, an autonomous agent designed for ultra-long-horizon machine learning engineering. It introduces Hierarchical Cognitive Caching (HCC) to enable sustained strategic coherence across extended research cycles. Evaluated on OpenAI MLE-Bench, ML-Master 2.0 achieves a 56.44% medal rate, demonstrating significant improvements in handling complex, long-term tasks."", || ""summary_score"": ""High"" || } ||  || [ Prompt: 117.2 t/s | Generation: 28.9 t/s ]"
2601.10406v1_ErrEval Error-Aware Evaluation for Question Genera.pdf,ErrEval: Error-Aware Evaluation for Question Generation through Explicit Diagnostics,"['Weiping Fu', 'Bifan Wei', 'Jingyi Hao', 'Yushun Zhang', 'Jian Zhang', 'Jiaxin Wang', 'Bo Li', 'Yu He', 'Lingling Zhang', 'Jun Liu']",,29.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ErrEval: Error-Aware Evaluation for Question Generation through || Explicit Diagnostics || Weiping Fu1,3, Bifan Wei2,3, Jingyi Hao1,3, Yushun Zhang1,3, Jian Zhang1,3, || Jiaxin Wang4,Bo Li 1,3,Yu He 1,3,Lingling Zhang 1,3,Jun Liu 1,3 || 1School of Computer Science and Technology, Xian Jiaotong  ... (truncated) ||  || { || ""title"": ""ErrEval: Error-Aware Evaluation for Question Generation through Explicit Diagnostics"", || ""authors"": [ || ""Weiping Fu"", || ""Bifan Wei"", || ""Jingyi Hao"", || ""Yushun Zhang"", || ""Jian Zhang"", || ""Jiaxin Wang"", || ""Bo Li"", || ""Yu He"", || ""Lingling Zhang"", || ""Jun Liu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""question generation"", || ""error modeling"", || ""LLM evaluation"", || ""error diagnostics"", || ""natural language generation"" || ], || ""summary"": ""Automatic Question Generation (QG) often produces outputs with critical defects, such as factual hallucinations and answer mismatches. This paper proposes ErrEval, a framework that enhances QG evaluation through explicit error diagnostics."" || } ||  || [ Prompt: 122.5 t/s | Generation: 29.2 t/s ]"
2601.10413v1_LADFA A Framework of Using Large Language Models a.pdf,LADFA: A Framework of Using Large Language Models and Retrieval-Augmented Generation for Personal Data Flow Analysis in Privacy Policies,"['Haiyue Yuan', 'Nikolay Matyunin', 'Ali Raza', 'Shujun Li']",https://doi.org/XXXXXXX.XXXXXX,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LADFA: A Framework of Using Large Language Models and || Retrieval-Augmented Generation for Personal Data Flow || Analysis in Privacy Policies || HAIYUE YUAN,Institute of Cyber Security for Society (iCSS) & School of Computing, University of Kent, || United Kingdom || NIKOLAY MATYUNIN and ALI RAZA ... (truncated) ||  || { || ""title"": ""LADFA: A Framework of Using Large Language Models and Retrieval-Augmented Generation for Personal Data Flow Analysis in Privacy Policies"", || ""authors"": [ || ""Haiyue Yuan"", || ""Nikolay Matyunin"", || ""Ali Raza"", || ""Shujun Li"" || ], || ""doi"": ""https://doi.org/XXXXXXX.XXXXXX"", || ""arxiv_id"": ""1, 1 (January 2025), 43 pages"", || ""keywords"": [ || ""Large Language Model"", || ""LLM"", || ""Privacy Policy"", || ""Text Analysis"", || ""Data Flows"", || ""Privacy"", || ""Security"", || ""Retrieval-Augmented Generation"", || ""RAG"", || ""Framework"", || ""Automotive Industry"", || ""Connected Vehicle"" || ], || ""summary"": ""This paper presents LADFA, an end-to-end computational framework that leverages large language models and retrieval-augmented generation to analyze personal data flows in privacy policies. It builds on prior work by integrating LLMs with custom knowledge bases and demonstrates effectiveness through a case study in the automotive industry."" || } ||  || [ Prompt: 119.4 t/s | Generation: 28.2 t/s ]"
2601.10416v1_LLMdoctor Token-Level Flow-Guided Preference Optim.pdf,LLMdoctor: Token-Level Flow-Guided Preference Optimization,"['Tiesunlong Shen', 'Rui Mao', 'Jin Wang', 'Heming Sun', 'Jian Zhang', 'Xuejie Zhang', 'Erik Cambria', 'Tensorshen', 'Rui Mao', 'Wangjin', 'Heming Sun', 'Zhangjian', 'Xian Jiaotong University']",,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LLMdoctor: Token-Level Flow-Guided Preference Optimization || for Efficient Test-Time Alignment of Large Language Models || Tiesunlong Shen1,2, Rui Mao1, Jin Wang2*, Heming Sun3, || Jian Zhang4, Xuejie Zhang2, Erik Cambria1 || 1Nanyang Technological University || 2Yunnan University || 3Yokohama Natio ... (truncated) ||  || { || ""title"": ""LLMdoctor: Token-Level Flow-Guided Preference Optimization"", || ""authors"": [ || ""Tiesunlong Shen"", || ""Rui Mao"", || ""Jin Wang"", || ""Heming Sun"", || ""Jian Zhang"", || ""Xuejie Zhang"", || ""Erik Cambria"", || ""Tensorshen"", || ""Rui Mao"", || ""Wangjin"", || ""Heming Sun"", || ""Zhangjian"", || ""Xian Jiaotong University"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""LLM"", || ""test-time alignment"", || ""token-level optimization"", || ""flow-guided preference"", || ""large language models"", || ""reinforcement learning"", || ""preference optimization"" || ], || ""summary"": ""This paper introduces LLMdoctor, a framework for efficient test-time alignment of large language models using token-level reward acquisition and flow-guided preference optimization. It aims to overcome the computational costs and inflexibility of traditional methods by leveraging fine-grained token-level signals and maintaining generation diversity."" || } ||  || [ Prompt: 112.9 t/s | Generation: 28.5 t/s ]"
2601.10421v1_Are Language Models Models.pdf,How Linguistics Learned to Stop Worrying and Love the Language Models,['Philip Resnik'],10.1017/S0140525X2510112X,31.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Are Language Models Models?  Philip Resnik Department of Linguistics and Institute for Advanced Computer Studies University of Maryland resnik@umd.edu   Commentary on Futrell, R. & Mahowald, K. (in press). How Linguistics Learned to Stop Worrying and Love the Language Models. Beh ... (truncated) ||  || { || ""title"": ""How Linguistics Learned to Stop Worrying and Love the Language Models"", || ""authors"": [""Philip Resnik""], || ""doi"": ""10.1017/S0140525X2510112X"", || ""arxiv_id"": """", || ""keywords"": [""language models"", ""computational theory"", ""linguistics""], || ""summary"": ""The commentary discusses whether language models are true cognitive models, highlighting issues at implementation, algorithmic representation, and computational theory. It argues that while LLMs are useful tools, labeling them as cognitive models overstates the case."" || } ||  || [ Prompt: 124.9 t/s | Generation: 31.8 t/s ]"
2601.10436v1_Development of Ontological Knowledge Bases by Leve.pdf,Development of Ontological Knowledge Bases by Leveraging Large Language Models,"['Leveraging Large Language Models', 'Marie-Hlne ABEL', 'Philippe GOUSPILLOU', 'Heuristics and Diagnosis of Complex Systems']",,31.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  ||  ||  ||  ||  ||  ||  ||  ||  ||  ||  ||  ||  ||  ||  ||  ||  ||  ||  ||  || Development of Ontological Knowledge Bases by || Leveraging Large Language Models || LE Ngoc Luyen || Universit de technologie de Compigne, CNRS, || Heudiasyc (Heuristics and Diagnosis of Complex Systems), || CS  ... (truncated) ||  || { || ""title"": ""Development of Ontological Knowledge Bases by Leveraging Large Language Models"", || ""authors"": [ || ""Leveraging Large Language Models"", || ""Marie-Hlne ABEL"", || ""Philippe GOUSPILLOU"", || ""Heuristics and Diagnosis of Complex Systems"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Ontology Development"", || ""Ontological Knowledge bases"", || ""Large Language Models"", || ""Knowledge Representation"", || ""User Modeling, Knowledge Management"" || ], || ""summary"": ""This paper introduces a structured, iterative methodology leveraging LLMs to optimize ontology development, focusing on automating knowledge acquisition, improving consistency, and enhancing transparency in ontology engineering. Key contributions include accelerated construction, improved consistency, bias mitigation, and enhanced efficiency."" || } ||  || [ Prompt: 129.0 t/s | Generation: 31.0 t/s ]"
2601.10440v1_AgentGuardian Learning Access Control Policies to .pdf,Learning Access Control Policies to Govern AI Agent Behavior,"['Nadya Abaev', 'Denis Klimov', 'Gerard Levinov', 'David Mimran', 'Yuval Elovici', 'Asaf Shabtai']",,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || AGENTGUARDIAN: Learning Access Control Policies to Govern || AI Agent Behavior || Nadya Abaev*, Denis Klimov *, Gerard Levinov, David Mimran, Yuval Elovici, Asaf Shabtai || Faculty of Computer and Information Science || Ben Gurion University of the Negev, Israel || AbstractArtificial intelligence  ... (truncated) ||  || { || ""title"": ""Learning Access Control Policies to Govern AI Agent Behavior"", || ""authors"": [ || ""Nadya Abaev"", || ""Denis Klimov"", || ""Gerard Levinov"", || ""David Mimran"", || ""Yuval Elovici"", || ""Asaf Shabtai"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Security"", || ""AI Agents"", || ""Access Control Policies"", || ""Control Flow Graph"" || ], || ""summary"": ""The study introduces AgentGuardian, a security framework for AI agents that enforces context-aware access control policies. It demonstrates effectiveness in detecting malicious inputs and mitigating hallucination-driven errors through adaptive policies."" || } ||  || [ Prompt: 129.4 t/s | Generation: 28.5 t/s ]"
2601.10457v1_NSR-Boost A Neuro-Symbolic Residual Boosting Frame.pdf,NSR-Boost: A Neuro-Symbolic Residual Boosting Framework for Industrial Legacy Models,"['Ziming Dai', 'Dabiao Ma', 'Jinle Tong', 'Mengyuan Han', 'Jian Yang', 'Hanmengyuan-JK']",10.1145/nnnnnnn.nnnnnnn,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || NSR-Boost: A Neuro-Symbolic Residual Boosting Framework for || Industrial Legacy Models || Ziming Dai || Tianjin University || Tianjin, China || phoenixdai@tju.edu.cn || Dabiao Ma || Qfin Holdings, Inc. || Beijing, China || madabiao-jk@qifu.com || Jinle Tong || Qfin Holdings, Inc. || Beijing, China || lancertong@live.com ... (truncated) ||  || { || ""title"": ""NSR-Boost: A Neuro-Symbolic Residual Boosting Framework for Industrial Legacy Models"", || ""authors"": [ || ""Ziming Dai"", || ""Dabiao Ma"", || ""Jinle Tong"", || ""Mengyuan Han"", || ""Jian Yang"", || ""Hanmengyuan-JK"" || ], || ""doi"": ""10.1145/nnnnnnn.nnnnnnn"", || ""arxiv_id"": """", || ""keywords"": [ || ""Neuro-Symbolic AI"", || ""Large Language Models"", || ""Gradient Boosting"", || ""Legacy Model"", || ""Interpretability"" || ], || ""summary"": ""The paper presents NSR-Boost, a neuro-symbolic residual boosting framework tailored for industrial legacy models. It addresses challenges in high-concurrency production environments by upgrading outdated models with non-intrusive targeted repairs. The approach uses symbolic code generation and Bayesian optimization, achieving strong performance on both public and private datasets, with notable gains in real-world applications."" || } ||  || [ Prompt: 113.6 t/s | Generation: 29.0 t/s ]"
2601.10460v1_Contextual StereoSet Stress-Testing Bias Alignment.pdf,Contextual StereoSet: Stress-Testing Bias Alignment Robustness in Large Language Models,"['Abhinaba Basu', 'Pavan Chakraborty']",arXiv:2601.10460v1,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Contextual StereoSet: Stress-Testing Bias Alignment Robustness in || Large Language Models || Abhinaba Basu 1,2 || Pavan Chakraborty1 || 1Indian Institute of Information Technology, Allahabad (IIITA) || 2National Institute of Electronics and Information Technology (NIELIT) || mail@abhinaba.com || Abstra ... (truncated) ||  || { || ""title"": ""Contextual StereoSet: Stress-Testing Bias Alignment Robustness in Large Language Models"", || ""authors"": [ || ""Abhinaba Basu"", || ""Pavan Chakraborty"" || ], || ""doi"": ""arXiv:2601.10460v1"", || ""arxiv_id"": ""arXiv:2601.10460"", || ""keywords"": [ || ""bias evaluation"", || ""alignment robustness"", || ""stress-testing"", || ""large language models"", || ""so-cio technical context"", || ""StereoSet"" || ], || ""summary"": ""A model that avoids stereotypes in a lab benchmark may not avoid them in deployment. The study introduces Contextual StereoSet to systematically vary contextual framing and demonstrates that bias shifts based on prompts about time, place, and audience, highlighting the need for context-aware evaluation."" || } ||  || [ Prompt: 127.6 t/s | Generation: 28.7 t/s ]"
2601.10462v3_ChartComplete A Taxonomy-based Inclusive Chart Dat.pdf,ChartComplete: A Taxonomy-based Inclusive Chart Dataset,"['Ahmad Mustapha', 'Charbel Toumieh', 'Mariette Awad']",,27.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ChartComplete: A Taxonomy-based Inclusive Chart Dataset || Ahmad Mustapha, Charbel Toumieh, and Mariette Awad || American University of Beirut, Lebanon || January 21, 2026 || Abstract || With advancements in deep learning (DL) and com- || puter vision techniques, the field of chart understand- || ing is ... (truncated) ||  || { || ""title"": ""ChartComplete: A Taxonomy-based Inclusive Chart Dataset"", || ""authors"": [""Ahmad Mustapha"", ""Charbel Toumieh"", ""Mariette Awad""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Chart"", ""Dataset"", ""Chart Taxonomy"", ""Chart Classification""], || ""summary"": ""The ChartComplete dataset introduces a taxonomy-based inclusive chart dataset covering thirty different chart types to address limitations in existing benchmarks."" || } ||  || [ Prompt: 120.1 t/s | Generation: 27.4 t/s ]"
2601.10477v1_Urban Socio-Semantic Segmentation with Vision-Lang.pdf,Urban Socio-Semantic Segmentation with Vision-Language Reasoning,"['Yu Wang', 'Yi Wang', 'Rui Dai', 'Yujie Wang', 'Kaikui Liu', 'Xiangxiang Chu', 'Yansheng Li']",,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Preprint. || URBANSOCIO-SEMANTICSEGMENTATION WITH || VISION-LANGUAGEREASONING || Yu Wang1,2, Yi Wang 2, Rui Dai 2, Yujie Wang 1, Kaikui Liu 2, || Xiangxiang Chu2, Yansheng Li 1 || 1Wuhan University 2Amap, Alibaba Group || ABSTRACT || As hubs of human activity, urban surfaces consist of a wealth of seman ... (truncated) ||  || { || ""title"": ""Urban Socio-Semantic Segmentation with Vision-Language Reasoning"", || ""authors"": [ || ""Yu Wang"", || ""Yi Wang"", || ""Rui Dai"", || ""Yujie Wang"", || ""Kaikui Liu"", || ""Xiangxiang Chu"", || ""Yansheng Li"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""urban segmentation"", || ""socio-semantic segmentation"", || ""vision-language reasoning"", || ""semantic entities"", || ""social semantics"", || ""satellite imagery"", || ""digital maps"" || ], || ""summary"": ""This paper introduces the SocioSeg dataset and a vision-language reasoning framework to improve segmentation of socially defined urban entities using satellite imagery and digital maps. The approach leverages reinforcement learning to enhance reasoning capabilities."" || } ||  || [ Prompt: 122.5 t/s | Generation: 27.6 t/s ]"
2601.10485v1_Panning for Gold Expanding Domain-Specific Knowled.pdf,Panning for Gold: Expanding Domain-Specific Knowledge,"['Runhao Zhao', 'Weixin Zeng', 'Wentao Zhang', 'Chong Chen', 'Zhengpin Li', 'Xiang Zhao', 'Lei Chen']",,29.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Panning for Gold: Expanding Domain-Specific Knowledge || Graphs with General Knowledge || Runhao Zhao || National Key Laboratory of Big Data || and Decision, National University of || Defense Technology || Changsha, China || runhaozhao@nudt.edu.cn || Weixin Zeng || National Key Laboratory of Big Data || and Deci ... (truncated) ||  || { || ""title"": ""Panning for Gold: Expanding Domain-Specific Knowledge"", || ""authors"": [ || ""Runhao Zhao"", || ""Weixin Zeng"", || ""Wentao Zhang"", || ""Chong Chen"", || ""Zhengpin Li"", || ""Xiang Zhao"", || ""Lei Chen"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""domain-specific knowledge graphs"", || ""knowledge graph enrichment"", || ""machine learning research"", || ""data science"", || ""knowledge mining"" || ], || ""summary"": ""The paper discusses the importance of domain-specific knowledge graphs and proposes ExeFuse, a framework for domain-specific knowledge graph fusion, to address gaps in knowledge integration."" || } ||  || [ Prompt: 118.0 t/s | Generation: 29.5 t/s ]"
2601.10496v1_Model See Model Do Exposure-Aware Evaluation of Bu.pdf,"Model See, Model Do?","['Ali Al-Kaswan', 'Claudio Spiess', 'Prem Devanbu', 'Arie van Deursen', 'Maliheh Izadi']",10.1145/nnnnnnn.nnnnnnn,26.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Model See, Model Do? || Exposure-Aware Evaluation of Bug-vs-Fix Preference in Code || LLMs || Ali Al-Kaswan || Delft University of Technology || Delft, Netherlands || a.al-kaswan@tudelft.nl || Claudio Spiess || University of California at Davis || Davis, United States || cvspiess@ucdavis.edu || Prem Devanbu || Univers ... (truncated) ||  || { || ""title"": ""Model See, Model Do?"", || ""authors"": [ || ""Ali Al-Kaswan"", || ""Claudio Spiess"", || ""Prem Devanbu"", || ""Arie van Deursen"", || ""Maliheh Izadi"" || ], || ""doi"": ""10.1145/nnnnnnn.nnnnnnn"", || ""arxiv_id"": """", || ""keywords"": ""Large Lang"", || ""summary"": ""Exposure-aware evaluation of bug-vs-fix preference in code using LLMs."" || } ||  || [ Prompt: 121.0 t/s | Generation: 26.7 t/s ]"
2601.10498v1_Projected Microbatch Accumulation yields reference.pdf,Projected Microbatch Accumulation yields reference-free proximal policy updates for reinforcement learning,['Nilin Abrahamsen'],,30.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Projected Microbatch Accumulation yields reference-free proximal || policy updates for reinforcement learning || Nilin Abrahamsen || Abstract || This note introduces Projected Microbatch Accumulation (PROMA), a proximal policy update method || for large language model fine-tuning. PROMA accumulate ... (truncated) ||  || { || ""title"": ""Projected Microbatch Accumulation yields reference-free proximal policy updates for reinforcement learning"", || ""authors"": [""Nilin Abrahamsen""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""PROMA is a proximal policy update method for large language model fine-tuning that enforces tighter control of local KL divergence without relying on a reference policy."" || } ||  || [ Prompt: 113.7 t/s | Generation: 30.4 t/s ]"
2601.10511v1_Scalable Algorithms for Approximate DNF Model Coun.pdf,Scalable Algorithms for Approximate DNF Model Counting,"['Paul Burkhardt', 'David G. Harris', 'Kevin T. Schmitt']",arXiv:2601.10511v1,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Scalable Algorithms for Approximate || DNF Model Counting || Paul Burkhardt  and David G. Harris  and Kevin T. Schmitt || Abstract || Model counting of Disjunctive Normal Form (DNF) formulas is a crit- || ical problem in applications such as probabilistic inference and network || reliability. For ex ... (truncated) ||  || { || ""title"": ""Scalable Algorithms for Approximate DNF Model Counting"", || ""authors"": [ || ""Paul Burkhardt"", || ""David G. Harris"", || ""Kevin T. Schmitt"" || ], || ""doi"": ""arXiv:2601.10511v1"", || ""arxiv_id"": ""arXiv:2601.10511"", || ""keywords"": [ || ""model counting"", || ""DNF"", || ""approximation algorithms"", || ""Monte Carlo"", || ""probabilistic inference"" || ], || ""summary"": ""The paper presents a new Monte Carlo approach for approximate counting of Disjunctive Normal Form (DNF) formulas, achieving PAC learning bounds and demonstrating superior performance over prior methods."" || } ||  || [ Prompt: 127.7 t/s | Generation: 27.7 t/s ]"
2601.10512v2_SatMap Revisiting Satellite Maps as Prior for Onli.pdf,SatMap: Revisiting Satellite Maps as Prior for Online HD Map Construction,"['Kanak Mazumder', 'Fabian B. Flohr']","0009000668068388, 0000000214993790",29.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SatMap: Revisiting Satellite Maps as Prior for || Online HD Map Construction || Kanak Mazumder[0009000668068388] and Fabian B. Flohr[0000000214993790] || Munich University of Applied Sciences, Intelligent Vehicles Lab (IVL) || Munich, Germany || {kanak.mazumder,fabian.flohr}@hm.edu || Abstract.Online ... (truncated) ||  || { || ""title"": ""SatMap: Revisiting Satellite Maps as Prior for Online HD Map Construction"", || ""authors"": [""Kanak Mazumder"", ""Fabian B. Flohr""], || ""doi"": ""0009000668068388, 0000000214993790"", || ""arxiv_id"": ""arXiv:2601.10512v2"", || ""keywords"": [""Online HD map prediction"", ""Satellite map prior"", ""Vectorized HD map"", ""HD map"", ""Autonomous driving""], || ""summary"": ""The paper presents SatMap, an online vectorized HD map estimation method that integrates satellite maps with multi-view camera observations to improve depth perception and reduce occlusion issues. It achieves significant performance gains over camera-only and camera-LiDAR baselines, especially in long-range and adverse weather conditions."" || } ||  || [ Prompt: 120.2 t/s | Generation: 29.2 t/s ]"
2601.10520v1_Breaking Up with Normatively Monolithic Agency wit.pdf,Breaking Up with Normatively Monolithic Agency,"['Felix Jahn', 'Yannic Muskalla', 'Lisa Dargasz', 'Kevin Baum']",,26.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Breaking Up with Normatively Monolithic Agency || with GRACE: A Reason-Based Neuro-Symbolic || Architecture for Safe and Ethical AI Alignment || Felix Jahn1,3* Yannic Muskalla1,3 Lisa Dargasz1 Patrick Schramowski1,2,4,5 || Kevin Baum1,2,3* || 1German Research Center for Artificial Intelligence, || 2C ... (truncated) ||  || { || ""title"": ""Breaking Up with Normatively Monolithic Agency"", || ""authors"": [ || ""Felix Jahn"", || ""Yannic Muskalla"", || ""Lisa Dargasz"", || ""Kevin Baum"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""An introduction to GRACE, a reason-based neuro-symbolic architecture for safe and ethical AI alignment, focusing on normative constraints and moral modules."" || } ||  || [ Prompt: 123.1 t/s | Generation: 26.8 t/s ]"
2601.10524v1_Diagnosing Generalization Failures in Fine-Tuned L.pdf,Diagnosing Generalization Failures in Fine-Tuned LLMs: A Cross-Architectural Study on Phishing,"['Frank Bobe III', 'Gregory D. Vetaw', 'Chase Pavlick', 'Darshan Bryner', 'Matthew Cook', 'Jose Salas-Vernis']",10.48550/arXiv.2303.04219,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Diagnosing Generalization Failures in Fine-Tuned || LLMs: A Cross-Architectural Study on Phishing || Detection || Frank Bobe IIIFrank Bobe IIIFrank Bobe III, Gregory D. Vetaw, Chase Pavlick, || Darshan Bryner, Matthew Cook, and Jose Salas-Vernis || Naval Surface Warfare Center Panama City Division ... (truncated) ||  || { || ""title"": ""Diagnosing Generalization Failures in Fine-Tuned LLMs: A Cross-Architectural Study on Phishing"", || ""authors"": [ || ""Frank Bobe III"", || ""Gregory D. Vetaw"", || ""Chase Pavlick"", || ""Darshan Bryner"", || ""Matthew Cook"", || ""Jose Salas-Vernis"" || ], || ""doi"": ""10.48550/arXiv.2303.04219"", || ""arxiv_id"": ""arXiv:2303.04219"", || ""keywords"": [ || ""LLM fine-tuning"", || ""generalization failures"", || ""phishing detection"", || ""SHAP analysis"", || ""mechanistic interpretability"" || ], || ""summary"": ""This study introduces a multi-layered diagnostic framework to analyze generalization issues in fine-tuned LLMs, focusing on a phishing detection task. It identifies architectural and data diversity factors, highlights performance variations across models, and emphasizes the need for deeper validation of architecture-data interactions."" || } ||  || [ Prompt: 119.5 t/s | Generation: 27.6 t/s ]"
2601.10527v2_A Safety Report on GPT-5.2 Gemini 3 Pro Qwen3-VL G.pdf,"A Safety Report on GPT-5.2, Gemini 3 Pro, Qwen3-VL, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5","['Xingjun Ma1', 'Yixu Wang1', 'Hengyuan Xu1', 'Yutao Wu3', 'Yifan Ding1', 'Yunhan Zhao1', 'Zilong Wang1', 'Jiabin Hua1', 'Ming Wen1,2', 'Jianan Liu1,2', 'Ranjie Duan', 'Yifeng Gao1', 'Tan Yunhao Chen', 'Hui Xue Xin', 'Wei Cheng', 'Jingjing Chen1', 'Bo Li4', 'Yi Gang Jiang', 'Fudan University1', 'Deakin University3', 'UIUC4']",https://xsafeai.github.io/AI-safety-report,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A Safety Report on GPT-5.2, Gemini 3 Pro, Qwen3-VL, Grok 4.1 Fast, || Nano Banana Pro, and Seedream 4.5 || Xingjun Ma1,2 Yixu Wang1 Hengyuan Xu1 Yutao Wu3 Yifan Ding1 Yunhan || Zhao1 Zilong Wang1 Jiabin Hua1 Ming Wen1,2 Jianan Liu1,2 Ranjie Duan || Yifeng Gao1 Yingshui Tan Yunhao Chen 1 Hui Xue ... (truncated) ||  || { || ""title"": ""A Safety Report on GPT-5.2, Gemini 3 Pro, Qwen3-VL, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5"", || ""authors"": [ || ""Xingjun Ma1"", || ""Yixu Wang1"", || ""Hengyuan Xu1"", || ""Yutao Wu3"", || ""Yifan Ding1"", || ""Yunhan Zhao1"", || ""Zilong Wang1"", || ""Jiabin Hua1"", || ""Ming Wen1,2"", || ""Jianan Liu1,2"", || ""Ranjie Duan"", || ""Yifeng Gao1"", || ""Tan Yunhao Chen"", || ""Hui Xue Xin"", || ""Wei Cheng"", || ""Jingjing Chen1"", || ""Bo Li4"", || ""Yi Gang Jiang"", || ""Fudan University1"", || ""Deakin University3"", || ""UIUC4"" || ], || ""doi"": ""https://xsafeai.github.io/AI-safety-report"", || ""arxiv_id"": ""https://github.com/XSafeAI/AI-safety-report"", || ""keywords"": [ || ""GPT-5.2"", || ""Gemini 3 Pro"", || ""Qwen3-VL"", || ""Grok 4.1 Fast"", || ""Nano Banana Pro"", || ""Seedream 4.5"", || ""safety evaluation"", || ""LLM safety"", || ""multimodal models"", || ""regulatory compliance"" || ], || ""summary"": ""The report evaluates the safety of frontier models across language, vision, and multimodal settings, revealing uneven safety performance and highlighting vulnerabilities under adversarial conditions."" || } ||  || [ Prompt: 127.7 t/s | Generation: 29.0 t/s ]"
2601.10543v1_Defending Large Language Models Against Jailbreak .pdf,Defending Large Language Models Against Jailbreak Attacks via In-Decoding Safety-Awareness Probing,"['Yinzhi Zhao', 'Ming Wang', 'Shi Feng', 'Xiaocui Yang', 'Daling Wang', 'Yifei Zhang']",,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Defending Large Language Models Against Jailbreak Attacks via || In-Decoding Safety-Awareness Probing || W ARNING: This paper contains model outputs that may be considered harmful. || Yinzhi Zhao, Ming Wang, Shi Feng *, Xiaocui Yang, Daling Wang, Yifei Zhang || Northeastern University, China || zh ... (truncated) ||  || { || ""title"": ""Defending Large Language Models Against Jailbreak Attacks via In-Decoding Safety-Awareness Probing"", || ""authors"": [ || ""Yinzhi Zhao"", || ""Ming Wang"", || ""Shi Feng"", || ""Xiaocui Yang"", || ""Daling Wang"", || ""Yifei Zhang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""large language models"", || ""jailbreak attacks"", || ""decoding safety"", || ""LLM safety"", || ""model safety awareness"" || ], || ""summary"": ""This paper examines the decoding process of LLMs and proposes a method to detect unsafe content during generation by leveraging latent safety signals, aiming to enhance safety without excessively over-refusing benign inputs."" || } ||  || [ Prompt: 117.1 t/s | Generation: 29.3 t/s ]"
2601.10560v1_Learning Latency-Aware Orchestration for Parallel .pdf,Learning Latency-Aware Orchestration for Parallel Multi-Agent Systems,"['Xi Shi', 'Mengxin Zheng', 'Qian Lou']",,26.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Learning Latency-Aware Orchestration for Parallel Multi-Agent Systems || Xi Shi, Mengxin Zheng, Qian Lou || University of Central Florida || xi320101@ucf.edu, mengxin.zheng@ucf.edu, qian.lou@ucf.edu || Abstract || Multi-agent systems (MAS) enable complex || reasoning by coordinating multiple agents,  ... (truncated) ||  || { || ""title"": ""Learning Latency-Aware Orchestration for Parallel Multi-Agent Systems"", || ""authors"": [ || ""Xi Shi"", || ""Mengxin Zheng"", || ""Qian Lou"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper proposes a latency-aware multi-agent orchestration framework, Latency-Aware Multi-agent System (LAMaS), to enable parallel execution and explicitly optimize execution paths for reduced latency."" || } ||  || [ Prompt: 125.1 t/s | Generation: 26.6 t/s ]"
2601.10562v1_Process-Guided Concept Bottleneck Model.pdf,,[],,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || IEEE TRANSACTIONS ON PA TTERN ANAL YSIS AND MACHINE INTELLIGENCE, VOL. V , NO. N, JANUARY 2026 1 || Process-Guided Concept Bottleneck Model || Reza M. Asiyabi, Sam Harrison, John L. Godlee, David Milodowski, Nicole H. Augustin, Penelope J. Mograbi, || Timothy R. Baker, Lorena M. Benitez, Sam ... (truncated) ||  || { || ""title"": ""Process-Guided Concept Bottleneck Model"", || ""authors"": [ || ""Reza M. Asiyabi"", || ""Sam Harrison"", || ""John L. Godlee"", || ""David Milodowski"", || ""Nicole H. Augustin"", || ""Penelope J. Mograbi"", || ""Timothy R. Baker"", || ""Lorena M. Benitez"", || ""Samuel J. Bowers"", || ""Thomas K. Brade"", || ""Joao M. B. Carreiras"", || ""Duncan M. Chalo"", || ""Vera De Cauwer"", || ""Kyle G. Dexter"", || ""Mathias I. Disney"", || ""Luisa F. Escobar-Alvarado"", || ""Manfred Finckh"", || ""Tatenda Gotore"", || ""Gabriele C. Hegerl"", || ""John N. Kigomo"", || ""Fainess C. Lumbwe"", || ""Francisco Maiato"", || ""Rudzani A. Makhado"", || ""Collins W. Masinde"", || ""Musingo Tito E. Mbuvi"", || ""Iain M. McNicol"", || ""Edward T.A. Mitchard"", || ""Buster P. Mogonong"", || ""Wilson A. Mugasha"", || ""Aristides Baptista Muhate"", || ""Hinji Mutondo"", || ""Leena Naftal"", || ""Paula Nieto-Quintano"", || ""Elifuraha Elisha Njoghomi"", || ""Catherine L. Parr"", || ""Oliver L. Phillips"", || ""Pierre Proces"", || ""Tshililo Ramaswiela"", || ""Jayashree Ratnam"", || ""Mathew Rees"", || ""Rasmus Revermann"", || ""Natasha Ribeiro"", || ""Mahesh Sankaran"", || ""Abel M. Siampale"", || ""Stephen Sitch"", || ""Kathleen G. Smart"", || ""Hemant G. Tripathi"", || ""Wayne Twine"", || ""Gabriel I.K. Uusiku"", || ""Helga van der Merwe"", || ""Chemuku Wekesa"", || ""Benjamin J. Wigley"", || ""Mathew Williams"", || ""Ell ||  || [ Prompt: 119.5 t/s | Generation: 28.3 t/s ]"
2601.10567v1_Generative AI collective behavior needs an interac.pdf,Generative AI collective behavior,"['Laura Ferrarotti', 'Gian Maria Campedelli', 'Roberto Dess', 'Andrea Baronchelli', 'Giovanni Iacca', 'Kathleen M. Carley', 'Alex Pentland', 'Joel Z. Leibo', 'James Evans', 'Bruno Lepri', 'Not Diamond', 'City St. Georges University of London', 'Carnegie Mellon University', 'Massachusetts Institute of Technology', 'Stanford University', 'Google DeepMind', 'University of Chicago']",arXiv:2601.10567v1,37.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Generative AI collective behavior || needs an interactionist paradigm || Laura Ferrarotti1,, Gian Maria Campedelli2,1,, Roberto Dess3, || Andrea Baronchelli4, Giovanni Iacca2, Kathleen M. Carley5, Alex || Pentland6,7, Joel Z. Leibo8, James Evans9, Bruno Lepri1 || 1Fondazione Bruno Kessler || 2Univers ... (truncated) ||  || { || ""title"": ""Generative AI collective behavior"", || ""authors"": [ || ""Laura Ferrarotti"", || ""Gian Maria Campedelli"", || ""Roberto Dess"", || ""Andrea Baronchelli"", || ""Giovanni Iacca"", || ""Kathleen M. Carley"", || ""Alex Pentland"", || ""Joel Z. Leibo"", || ""James Evans"", || ""Bruno Lepri"", || ""Not Diamond"", || ""City St. Georges University of London"", || ""Carnegie Mellon University"", || ""Massachusetts Institute of Technology"", || ""Stanford University"", || ""Google DeepMind"", || ""University of Chicago"" || ], || ""doi"": ""arXiv:2601.10567v1"", || ""arxiv_id"": ""2601.10567"", || ""keywords"": [], || ""summary"": ""The article discusses the need for an interactionist paradigm to understand the collective behavior of agents based on large language models, emphasizing the importance of prior knowledge, social priors, and in-context learning in multi-agent generative AI systems."" || } ||  || [ Prompt: 131.9 t/s | Generation: 37.0 t/s ]"
2601.10581v1_From Single to Multi-Agent Reasoning Advancing Gen.pdf,Advancing GeneGPT for Genomics QA,"['Kimia Abedini', 'Farzad Shami', 'Gianmaria Silvello']",https://kimia-abedini.github.io/Genom-Agent/,30.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || From Single to Multi-Agent Reasoning: || Advancing GeneGPT for Genomics QA || Kimia Abedini1 , Farzad Shami2 , and Gianmaria Silvello1 || 1 University of Padua, Italy || 2 Aalto University, Finland || Abstract.Comprehending genomic information is essential for biomed- || ical research, yet extracting ... (truncated) ||  || { || ""title"": ""Advancing GeneGPT for Genomics QA"", || ""authors"": [ || ""Kimia Abedini"", || ""Farzad Shami"", || ""Gianmaria Silvello"" || ], || ""doi"": ""https://kimia-abedini.github.io/Genom-Agent/"", || ""arxiv_id"": ""2601.10581v1"", || ""keywords"": [ || ""Question Answering"", || ""Genomic QA"", || ""Multi-Agent Systems"", || ""GeneGPT"", || ""LLMs"", || ""Scientific Knowledge Extraction"" || ], || ""summary"": ""This paper proposes GenomAgent, a multi-agent framework that enhances GeneGPT by coordinating specialized agents, improving performance on genomic QA tasks and extending applicability to other scientific domains."" || } ||  || [ Prompt: 133.5 t/s | Generation: 30.5 t/s ]"
2601.10587v1_Adversarial Evasion Attacks on Computer Vision usi.pdf,Adversarial Evasion Attacks on Computer Vision using SHAP Values,"['Frank Mollard', 'Marcus Becker', 'Florian Rhrbein']",arXiv:2601.10587v1,31.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Adversarial Evasion Attacks on || Computer Vision using SHAP Values || Frank Mollard * || , Marcus Becker || , Florian Rhrbein || *Business Intelligence & Data Science, Infraserv GmbH & Co. Hchst KG, Germany || International School of Management, Germany || TU-Chemnitz, Germany || Abstract || The paper in ... (truncated) ||  || { || ""title"": ""Adversarial Evasion Attacks on Computer Vision using SHAP Values"", || ""authors"": [ || ""Frank Mollard"", || ""Marcus Becker"", || ""Florian Rhrbein"" || ], || ""doi"": ""arXiv:2601.10587v1"", || ""arxiv_id"": ""arXiv:2601.10587"", || ""keywords"": [], || ""summary"": ""The paper introduces a white-box attack on computer vision models using SHAP values, demonstrating how adversarial evasion attacks can compromise model performance by reducing output confidence or inducing misclassifications. It compares SHAP attacks with the Fast Gradient Sign Method and highlights their effectiveness in gradient hiding scenarios."" || } ||  || [ Prompt: 117.2 t/s | Generation: 31.8 t/s ]"
2601.10591v1_ProbFM Probabilistic Time Series Foundation Model .pdf,Probabilistic Time Series Foundation Model with Uncertainty,"['Arundeep Chinta', 'Lucas Vinh Tran', 'Jay Katukuri']",,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ProbFM: Probabilistic Time Series Foundation Model with Uncertainty || Decomposition || Arundeep Chinta1, Lucas Vinh Tran2, Jay Katukuri1 || 1JPMorganChase, Palo Alto, USA || 2JPMorganChase, London, UK || arundeep.chinta@jpmchase.com, lucas.vinhtran@chase.com, jay.katukuri@chase.com || Abstract || Time  ... (truncated) ||  || { || ""title"": ""Probabilistic Time Series Foundation Model with Uncertainty"", || ""authors"": [ || ""Arundeep Chinta"", || ""Lucas Vinh Tran"", || ""Jay Katukuri"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper introduces ProbFM, a novel transformer-based probabilistic framework that leverages Deep Evidential Regression for principled uncertainty quantification. It evaluates DER-based uncertainty decomposition across multiple models and demonstrates improved risk management in cryptocurrency forecasting."" || } ||  || [ Prompt: 128.2 t/s | Generation: 27.6 t/s ]"
2601.10600v1_Procedural Fairness in Multi-Agent Bandits.pdf,Procedural Fairness in Multi-Agent Bandits,"['Joshua Caiata', 'Carter Blair', 'Kate Larson']",arXiv:2601.10600v1,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Procedural Fairness in Multi-Agent Bandits || Joshua Caiata 1, Carter Blair 2, and Kate Larson 1 || 1University of Waterloo || 2Harvard University || jcaiata@uwaterloo.ca, carterblair@g.harvard.edu, || kate.larson@uwaterloo.ca || Abstract || In the context of multi-agent multi-armed bandits (MA-MAB), fa ... (truncated) ||  || { || ""title"": ""Procedural Fairness in Multi-Agent Bandits"", || ""authors"": [ || ""Joshua Caiata"", || ""Carter Blair"", || ""Kate Larson"" || ], || ""doi"": ""arXiv:2601.10600v1"", || ""arxiv_id"": ""1University of Waterloo"", || ""keywords"": [ || ""procedural fairness"", || ""multi-agent systems"", || ""fairness objectives"", || ""agency"", || ""consequentialism"" || ], || ""summary"": ""This paper introduces a new fairness objective called procedural fairness, emphasizing equal decision-making power and proportionality in outcomes for multi-agent multi-armed bandits. It argues that fairness should focus on process rather than just outcomes, highlighting the importance of legitimacy in decision-making."" || } ||  || [ Prompt: 118.3 t/s | Generation: 27.5 t/s ]"
2601.10611v1_Molmo2 Open Weights and Data for Vision-Language M.pdf,Molmo2,"['Christopher Clark', 'Jieyu Zhang', 'Zixian Ma', 'Jae Sung Park', 'Mohammadreza Salehi', 'Rohun Tripathi', 'Sangho Lee', 'Zhongzheng Ren', 'Chris Dongjoo Kim', 'Yinuo Yang', 'Vincent Shao', 'Yue Yang', 'Weikai Huang', 'Ziqi Gao', 'Taira Anderson', 'Jianrui Zhang', 'Jitesh Jain', 'George Stoica', 'Winson Han', 'Ali Farhadi', 'Ranjay Krishna']",arXiv:2601.10611v1,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Molmo2 || Open Weights and Data for Vision-Language Models || with Video Understanding and Grounding || Christopher Clark 1 Jieyu Zhang 1,2 Zixian Ma 1,2 Jae Sung Park 1,2 Mohammadreza || Salehi1,2 Rohun Tripathi1 Sangho Lee1 || Zhongzheng Ren1,2 Chris Dongjoo Kim1 Yinuo Yang2 Vincent Shao2 Yue Ya ... (truncated) ||  || { || ""title"": ""Molmo2"", || ""authors"": [ || ""Christopher Clark"", || ""Jieyu Zhang"", || ""Zixian Ma"", || ""Jae Sung Park"", || ""Mohammadreza Salehi"", || ""Rohun Tripathi"", || ""Sangho Lee"", || ""Zhongzheng Ren"", || ""Chris Dongjoo Kim"", || ""Yinuo Yang"", || ""Vincent Shao"", || ""Yue Yang"", || ""Weikai Huang"", || ""Ziqi Gao"", || ""Taira Anderson"", || ""Jianrui Zhang"", || ""Jitesh Jain"", || ""George Stoica"", || ""Winson Han"", || ""Ali Farhadi"", || ""Ranjay Krishna"" || ], || ""doi"": ""arXiv:2601.10611v1"", || ""arxiv_id"": ""2601.10611v1"", || ""keywords"": [], || ""summary"": ""Presents Molmo2, a new family of open-source video-language models with state-of-the-art performance in point-driven grounding across single image, multi-image, and video tasks. Includes new datasets and training strategies."" || } ||  || [ Prompt: 120.1 t/s | Generation: 28.2 t/s ]"
2601.10651v1_Multi-Property Synthesis.pdf,Multi-Property Synthesis,"['Christoph Weinhuber1', 'Yannik Schnitzer 1', 'Alessandro Abate1', 'David Parker 1', 'Giuseppe De Giacomo 1', 'Moshe Y. Vardi 2']",,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Multi-Property Synthesis || Christoph Weinhuber1, ,Yannik Schnitzer 1, , || Alessandro Abate1 ,David Parker 1 ,Giuseppe De Giacomo 1 ,Moshe Y. Vardi 2 || 1University of Oxford, Oxford, UK || 2Rice University, Houston, Texas, US || Abstract || We study LTLf synthesis with multiple properties, || where sa ... (truncated) ||  || { || ""title"": ""Multi-Property Synthesis"", || ""authors"": [ || ""Christoph Weinhuber1"", || ""Yannik Schnitzer 1"", || ""Alessandro Abate1"", || ""David Parker 1"", || ""Giuseppe De Giacomo 1"", || ""Moshe Y. Vardi 2"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""We study LTLf synthesis with multiple properties, where satisfying all properties may be impossible. Instead of enumerating subsets of properties, we compute in one fixed-point computation the relationship between product-game states and the goal sets that are realizable from them, and we synthesize strategies achieving maximal realizable sets. We develop a fully symbolic algorithm that introduces Boolean goal variables and exploits monotonicity to represent exponentially many goal combinations compactly. Our approach substantially outperforms enumeration-based baselines, with speedups of up to two orders of magnitude."" || } ||  || [ Prompt: 119.7 t/s | Generation: 28.5 t/s ]"
2601.10679v1_Are Your Reasoning Models Reasoning or Guessing A .pdf,Are Your Reasoning Models Reasoning or Guessing?,"['Zirui Ren', 'Ziming Liu']",,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Are Your Reasoning Models Reasoning or Guessing? || A Mechanistic Analysis of Hierarchical Reasoning Models || Zirui Ren 1 2 Ziming Liu 1 3 || Abstract || Hierarchical reasoning model (HRM) achieves || extraordinary performance on various reason- || ing tasks, significantly outperforming large lan- || g ... (truncated) ||  || { || ""title"": ""Are Your Reasoning Models Reasoning or Guessing?"", || ""authors"": [ || ""Zirui Ren"", || ""Ziming Liu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""hierarchical reasoning models"", || ""reasoning patterns"", || ""guessing"", || ""fixed point property"", || ""grokking dynamics"", || ""model scaling"" || ], || ""summary"": ""This paper investigates the performance and limitations of hierarchical reasoning models (HRM) in reasoning tasks, identifying surprising failure modes and proposing strategies to improve their accuracy."" || } ||  || [ Prompt: 117.8 t/s | Generation: 29.1 t/s ]"
2601.10681v1_Structure and Diversity Aware Context Bubble Const.pdf,Structure and Diversity Aware Context Bubble Construction for Enterprise Retrieval,"['Amir Khurshid', 'Abhishek Sehgal']",,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  ||  ||  || Structure and Diversity Aware Context Bubble Construction for Enterprise Retrieval || Augmented Systems || Amir Khurshid1a*, Abhishek Sehgal1b || a Bravada Group, Melbourne,3134, Melbourne, Australia || amir@finsoeasy.com || b Eye Dream Pty Ltd, 302/50 Murray St., Pyrmont, Sydney, NSW  ... (truncated) ||  || { || ""title"": ""Structure and Diversity Aware Context Bubble Construction for Enterprise Retrieval"", || ""authors"": [ || ""Amir Khurshid"", || ""Abhishek Sehgal"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Large Language Model"", || ""Retrieval-Augmented Generation"", || ""Context Bubble"", || ""Retrieval"", || ""Enterprise Documents"" || ], || ""summary"": ""The paper proposes a structure-informed and diversity-constrained context bubble construction framework for LLM-based retrieval, aiming to improve coherence, reduce redundancy, and enhance coverage in enterprise document contexts."" || } ||  || [ Prompt: 115.2 t/s | Generation: 27.9 t/s ]"
2601.10684v1_On the origin of neural scaling laws from random g.pdf,On the origin of neural scaling laws,"['Maissam Barkeshli', 'Alberto Alfarano', 'Andrey Gromov']",,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || On the origin of neural scaling laws: || from random graphs to natural language || Maissam Barkeshli1,2,,Alberto Alfarano 3,,,Andrey Gromov 1 || 1Meta Superintelligence Labs, FAIR,2Department of Physics, University of Maryland, College Park || and Joint Quantum Institute,3Axiom Math || Equal contr ... (truncated) ||  || { || ""title"": ""On the origin of neural scaling laws"", || ""authors"": [ || ""Maissam Barkeshli"", || ""Alberto Alfarano"", || ""Andrey Gromov"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper explores how scaling laws emerge in transformers trained on random walks on graphs, demonstrating their appearance even without inherent power law structure in data correlations. It examines scaling laws from simplified settings and language modeling."" || } ||  || [ Prompt: 120.5 t/s | Generation: 27.5 t/s ]"
2601.10696v1_The Impact of Generative AI on Architectural Conce.pdf,"The Impact of Generative AI on Architectural Conceptual Design: Performance, Creative Self-Efficacy and Cognitive Load","['Han Jiang', 'Yao Xiao', 'Rachel Hurley', 'Shichao Liu']",sliu8@wpi.edu,30.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Preprint, under review 1 ||  || The Impact of Generative AI on Architectural Conceptual Design: || Performance, Creative Self-Efficacy and Cognitive Load ||  || Han Jiang*, Yao Xiao*, Rachel Hurley, Shichao Liu || Department of Civil, Environmental, and Architectural Engineering, Worcester Poly ... (truncated) ||  || { || ""title"": ""The Impact of Generative AI on Architectural Conceptual Design: Performance, Creative Self-Efficacy and Cognitive Load"", || ""authors"": [ || ""Han Jiang"", || ""Yao Xiao"", || ""Rachel Hurley"", || ""Shichao Liu"" || ], || ""doi"": ""sliu8@wpi.edu"", || ""arxiv_id"": """", || ""keywords"": [ || ""Visual communication"", || ""Architectural design"", || ""Learning"", || ""Performance Assessment"", || ""Hybrid Intelligence"", || ""Human-AI teaming"", || ""GPT Generative Pre-trained Transformer"", || ""SD Standard deviation"", || ""STEM Science, technology, engineering, and mathematics"" || ], || ""summary"": ""Our study examines how generative AI influences performance, creative self-efficacy, and cognitive load in architectural conceptual design tasks. Subgroup analyses indicate GenAI benefits novice designers but may reduce general creative self-efficacy."" || } ||  || [ Prompt: 111.8 t/s | Generation: 30.9 t/s ]"
2601.10700v2_LIBERTy A Causal Framework for Benchmarking Concep.pdf,LIBERTy: A Causal Framework for Benchmarking Concept-Based Explanations of LLMs with Structural Counterfactuals,"['Gilat Toker', 'Nitay Calderon', 'Ohad Amosy', 'Roi Reichart']",10.48550/arXiv.2303.04219,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LIBERTy: A Causal Framework for Benchmarking Concept-Based || Explanations of LLMs with Structural Counterfactuals || Gilat Toker*, Nitay Calderon*, Ohad Amosy, Roi Reichart || Faculty of Data and Decision Sciences, Technion  Israel Institute of Technology || {gilatt, nitay}@campus.technion.ac. ... (truncated) ||  || { || ""title"": ""LIBERTy: A Causal Framework for Benchmarking Concept-Based Explanations of LLMs with Structural Counterfactuals"", || ""authors"": [""Gilat Toker"", ""Nitay Calderon"", ""Ohad Amosy"", ""Roi Reichart""], || ""doi"": ""10.48550/arXiv.2303.04219"", || ""arxiv_id"": ""arXiv:2303.04219"", || ""keywords"": [""concept-based explanations"", ""LLMs"", ""structural counterfactuals"", ""explainability""], || ""summary"": ""LIBERTy introduces a framework for constructing datasets with structural counterfactual pairs to evaluate the faithfulness of concept-based explanations. It evaluates models across multiple domains and identifies improvements in sensitivity to demographic concepts."" || } ||  || [ Prompt: 113.1 t/s | Generation: 29.0 t/s ]"
2601.10702v1_Grounding Agent Memory in Contextual Intent.pdf,Grounding Agent Memory in Contextual Intent,"['Ruozhen Yang', 'Yucheng Jiang', 'Yueqi Jiang', 'Priyanka Kargupta', 'Junyi Zhang', 'Jiawei Han']",,29.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Grounding Agent Memory in Contextual Intent || Ruozhen Yang1* Yucheng Jiang2* Yueqi Jiang1 || Priyanka Kargupta1 Yunyi Zhang1 Jiawei Han1 || 1University of Illinois Urbana-Champaign 2Stanford University || {ruozhen2, hanj}@illinois.edu yuchengj@cs.stanford.edu || Abstract || Deploying large language  ... (truncated) ||  || { || ""title"": ""Grounding Agent Memory in Contextual Intent"", || ""authors"": [ || ""Ruozhen Yang"", || ""Yucheng Jiang"", || ""Yueqi Jiang"", || ""Priyanka Kargupta"", || ""Junyi Zhang"", || ""Jiawei Han"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Proposes STITCH (StructuredIntentTracking in ContextualHistory), an agentic memory system that indexes trajectory steps with structured retrieval cues, contextual intent, and retrieves history by matching current intent. It improves performance in long-horizon goal-oriented reasoning by reducing retrieval noise through intent indexing."" || } ||  || [ Prompt: 116.2 t/s | Generation: 29.2 t/s ]"
2601.10712v1_MatchTIR Fine-Grained Supervision for Tool-Integra.pdf,MatchTIR: Fine-Grained Supervision for Tool-Integrated Reasoning via Bipartite Matching,"['Changle Qu1', 'Sunhao Dai', 'Hengyi Cai', 'Jun Xu1', 'Shuaiqiang Wang2', 'Dawei Yin2']",,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MatchTIR: Fine-Grained Supervision for || Tool-Integrated Reasoning via Bipartite Matching || Changle Qu1, Sunhao Dai1, Hengyi Cai2, Jun Xu1, Shuaiqiang Wang2, Dawei Yin2 || 1Gaoling School of Artificial Intelligence, Renmin University of China; 2Baidu Inc. || {changlequ,sunhaodai,junxu}@ruc.ed ... (truncated) ||  || { || ""title"": ""MatchTIR: Fine-Grained Supervision for Tool-Integrated Reasoning via Bipartite Matching"", || ""authors"": [ || ""Changle Qu1"", || ""Sunhao Dai"", || ""Hengyi Cai"", || ""Jun Xu1"", || ""Shuaiqiang Wang2"", || ""Dawei Yin2"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Tool-Integrated Reasoning"", || ""LLM"", || ""Bipartite Matching"", || ""Fine-Grained Supervision"", || ""Multi-Turn Reasoning"" || ], || ""summary"": ""Tool-Integrated Reasoning (TIR) empowers large language models to tackle complex tasks by interleaving reasoning steps with external tool interactions. This paper proposes MatchTIR, a framework that introduces fine-grained supervision via bi-partite matching-based turn-level reward assignment and dual-level advantage estimation to address limitations in existing reinforcement learning methods."" || } ||  || [ Prompt: 116.4 t/s | Generation: 29.3 t/s ]"
2601.10748v1_AnyECG Evolved ECG Foundation Model for Holistic H.pdf,AnyECG: Evolved ECG Foundation Model for Holistic Health Profiling,"['Jun Li1,2', 'Hongling Zhu5', 'Yujie Xiao1,2', 'Qinghao Zhao6', 'Yale Ali Ke7,8,9', 'Gongzheng Tang1,2', 'Guangkun Nie1,2', 'Deyun Zhang11', 'Jin Li12', 'Canqing Yu7,8,9', 'Shenda Hong1,2,3,4*']",,28.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || AnyECG: Evolved ECG Foundation Model for Holistic Health Profiling || Jun Li1,2,# , Hongling Zhu5,#, Yujie Xiao1,2,#, Qinghao Zhao6,#, Y alei Ke7,8,9, Gongzheng Tang1,2, || Guangkun Nie1,2,10, Deyun Zhang11, Jin Li12, Canqing Yu7,8,9, and Shenda Hong1,2,3,4,*, || 1National Institute of Healt ... (truncated) ||  || { || ""title"": ""AnyECG: Evolved ECG Foundation Model for Holistic Health Profiling"", || ""authors"": [ || ""Jun Li1,2"", || ""Hongling Zhu5"", || ""Yujie Xiao1,2"", || ""Qinghao Zhao6"", || ""Yale Ali Ke7,8,9"", || ""Gongzheng Tang1,2"", || ""Guangkun Nie1,2"", || ""Deyun Zhang11"", || ""Jin Li12"", || ""Canqing Yu7,8,9"", || ""Shenda Hong1,2,3,4*"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This study introduces AnyECG, a refined ECG foundation model built using a large-scale multicenter dataset, aiming to enable comprehensive disease screening, risk prediction, and comorbidity analysis in holistic health profiling."" || } ||  || [ Prompt: 123.4 t/s | Generation: 28.0 t/s ]"
2601.10768v1_Optimisation of complex product innovation process.pdf,Optimisation of Complex Product Innovation Processes Based on Trend Models,"['Nina Bo Kocova1', 'Barbora Volna A2*', 'Mirko Dohnal 3']",arXiv:2601.10768v1,29.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || OPTIMISATION OF COMPLEX PRODUCT INNOVATION || PROCESSES BASED ON TREND MODELS || WITH THREE-VALUED LOGIC || NINA BO CKOVA1, BARBORA VOLN A2*, MIRKO DOHNAL 3 || 1Prague University of Economics and Business, Faculty of Business Administration, W. Churchilla 4, || 130 67 Praha 3, Czech Republic. || 2Sil ... (truncated) ||  || { || ""title"": ""Optimisation of Complex Product Innovation Processes Based on Trend Models"", || ""authors"": [ || ""Nina Bo Kocova1"", || ""Barbora Volna A2*"", || ""Mirko Dohnal 3"" || ], || ""doi"": ""arXiv:2601.10768v1"", || ""arxiv_id"": ""2601.10768"", || ""keywords"": [ || ""complex product innovation"", || ""technological forecasting"", || ""three-valued logic"", || ""trend-based modelling"", || ""scenarios"", || ""transition graphs"" || ], || ""summary"": ""This paper investigates complex product-innovation processes using models grounded in heuristics. Each heuristic is expressed through simple trends increasing, decreasing, or constant, serving as minimally information-intensive quantifiers. A solution to a trend model is defined as a set of scenarios with possible transitions between them, represented by a transition graph. Any possible future or past behaviour can be depicted by a path within this graph."" || } ||  || [ Prompt: 131.8 t/s | Generation: 29.5 t/s ]"
2601.10770v1_Unifying Speech Recognition Synthesis and Conversi.pdf,Unifyingspeechrecognition synthesis and conversion with autoregressive transformers,"['Runyuan Cai', 'Yu Lin', 'Yiming Wang', 'Chunlin Fu', 'Xiaodong Zeng']",https://github.com/AutoArk/GPA,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || UNIFYINGSPEECHRECOGNITION, SYNTHESIS AND || CONVERSION WITHAUTOREGRESSIVETRANSFORMERS || TECHNICALREPORT || Runyuan Cai Yu Lin Yiming Wang Chunlin Fu Xiaodong Zeng || AutoArk-AI || {runyuan.cai, yu.lin, yiming.wang, chunlin.fu, xiaodong.zeng}@autoark.ai || https://github.com/AutoArk/GPA || ABSTRACT || Trad ... (truncated) ||  || { || ""title"": ""Unifyingspeechrecognition synthesis and conversion with autoregressive transformers"", || ""authors"": [ || ""Runyuan Cai"", || ""Yu Lin"", || ""Yiming Wang"", || ""Chunlin Fu"", || ""Xiaodong Zeng"" || ], || ""doi"": ""https://github.com/AutoArk/GPA"", || ""arxiv_id"": ""2601.10770v1"", || ""keywords"": [ || ""Text-to-Speech"", || ""Automatic Speech Recognition"", || ""Voice Conversion"", || ""Foundation Model"", || ""Speech Tasks"" || ], || ""summary"": ""This paper introduces General-Purpose Audio (GPA), a unified audio foundation model integrating multiple speech tasks within a single LLM architecture. GPA uses a shared discrete audio token space and supports instruction-driven task induction, allowing a single autoregressive model to perform TTS, ASR, and VC efficiently without architectural changes. It emphasizes scalability, concurrency, and practical deployment for edge environments."" || } ||  || [ Prompt: 120.5 t/s | Generation: 28.3 t/s ]"
2601.10773v1_LogicLens Leveraging Semantic Code Graph to explor.pdf,Leveraging Semantic Code Graph to explore Multi Repository large systems,"['Niko Usai', 'Dario Montagnini', 'Kristian Ilianov Iliev', 'Raffaele Camanzo']",,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LogicLens: Leveraging Semantic Code Graph to explore Multi Repository large || systems || Niko Usai1 ,Dario Montagnini 1 ,Kristian Ilianov Iliev 1 andRaffaele Camanzo 1 || 1Sourcesense || {niko.usai, dario.montagnini, kristian.iliev, raffaele.camanzo}@sourcesense.com || Abstract || Understanding larg ... (truncated) ||  || { || ""title"": ""Leveraging Semantic Code Graph to explore Multi Repository large systems"", || ""authors"": [ || ""Niko Usai"", || ""Dario Montagnini"", || ""Kristian Ilianov Iliev"", || ""Raffaele Camanzo"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Understanding large software systems is challenging, especially across multiple repositories. This paper introduces LogicLens, a reactive conversational agent that uses a semantic multi-repository graph built from code analysis and LLMs to help developers explore complex systems."" || } ||  || [ Prompt: 124.6 t/s | Generation: 26.9 t/s ]"
2601.10779v1_Unified Optimization of Source Weights and Transfe.pdf,Unified Optimization of Source Weights and Transfer Quantities in Multi-Source Transfer Learning: An Asymptotic Framework,"['Qingyue Zhang', 'Chang Chu', 'Haohao Fu', 'Tianren Peng', 'Yanru Wu', 'Guanbo Huang', 'Yang Li', 'Shao-Lun Huang']",,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || Unified Optimization of Source Weights and || Transfer Quantities in Multi-Source Transfer || Learning: An Asymptotic Framework || Qingyue Zhang, Chang Chu, Haohao Fu, Tianren Peng, Yanru Wu, Guanbo Huang, Yang Li, and Shao-Lun Huang || AbstractTransfer learning plays a vital role in improvin ... (truncated) ||  || { || ""title"": ""Unified Optimization of Source Weights and Transfer Quantities in Multi-Source Transfer Learning: An Asymptotic Framework"", || ""authors"": [ || ""Qingyue Zhang"", || ""Chang Chu"", || ""Haohao Fu"", || ""Tianren Peng"", || ""Yanru Wu"", || ""Guanbo Huang"", || ""Yang Li"", || ""Shao-Lun Huang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""transfer learning"", || ""multi-source learning"", || ""asymptotic analysis"", || ""Kullback-Leibler divergence"", || ""transfer learning"", || ""optimization"" || ], || ""summary"": ""This paper proposes a theoretical framework, Unified Optimization of Weights and Quantities (UOWQ), to optimize source weights and transfer quantities jointly in multi-source transfer learning. It presents a parameter estimation problem grounded in asymptotic analysis and provides theoretical and numerical results demonstrating its effectiveness."" || } ||  || [ Prompt: 126.6 t/s | Generation: 28.7 t/s ]"
2601.10810v1_Digital Metabolism Decoupling Logic from Facts via.pdf,Digital Metabolism: Decoupling Logic from Facts via Regenerative Unlearning,"['Mengmeng Peng', 'Zhenyu Fang', 'He Sun']",arXiv:2601.10810v1,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Digital Metabolism: Decoupling Logic from Facts via || Regenerative Unlearning || Towards a Pure Neural Logic Core || Mengmeng Peng 1, Zhenyu Fang 1,, He Sun 2,1 || 1 || School of Software, Northwestern Polytechnical University, Xian, China || 2 || Key Laboratory of Computational Optical Imaging Technol ... (truncated) ||  || { || ""title"": ""Digital Metabolism: Decoupling Logic from Facts via Regenerative Unlearning"", || ""authors"": [ || ""Mengmeng Peng"", || ""Zhenyu Fang"", || ""He Sun"" || ], || ""doi"": ""arXiv:2601.10810v1"", || ""arxiv_id"": ""2601.10810"", || ""keywords"": [ || ""digital metabolism"", || ""logic"", || ""facts"", || ""hallucinations"", || ""neural logic core"", || ""regenerative unlearning"" || ], || ""summary"": ""The paper discusses the parameter entanglement problem in large language models and introduces the Regenerative Logic-Core Protocol to enable decoupled reasoning and fact retention. Empirical results show a shift toward structural crystallization and improved chain-of-thought capabilities."" || } ||  || [ Prompt: 128.5 t/s | Generation: 28.3 t/s ]"
2601.10820v1_Towards Reliable ML Feature Engineering via Planni.pdf,Towards Reliable ML Feature Engineering via Planning in Constrained-Topology of LLM Agents,"['Himanshu Thakur', 'Anusha Kamath', 'Anurag Muthyala', 'Dhwani Sanmukhani', 'Smruthi Mukund', 'Jay Katukuri']",arXiv:2601.10820v1,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Towards Reliable ML Feature Engineering via || Planning in Constrained-Topology of LLM Agents || Himanshu Thakur || Meta || Menlo Park, CA || scihimanshu10@gmail.com || Anusha Kamath || JPMorgan Chase & Co. || Palo Alto, CA || anusha.kamath@chase.com || Anurag Muthyala || JPMorgan Chase & Co. || Bangalore, India || anura ... (truncated) ||  || { || ""title"": ""Towards Reliable ML Feature Engineering via Planning in Constrained-Topology of LLM Agents"", || ""authors"": [ || ""Himanshu Thakur"", || ""Anusha Kamath"", || ""Anurag Muthyala"", || ""Dhwani Sanmukhani"", || ""Smruthi Mukund"", || ""Jay Katukuri"" || ], || ""doi"": ""arXiv:2601.10820v1"", || ""arxiv_id"": ""2601.10820"", || ""keywords"": [ || ""feature engineering"", || ""LLM agents"", || ""code generation"", || ""ML teams"", || ""human-AI collaboration"", || ""recommendation systems"" || ], || ""summary"": ""This paper addresses challenges in adopting code generation models for feature engineering in real-world ML teams. It proposes a planner-guided, constrained-topology multi-agent framework to automate and improve reliability, maintainability, and alignment with team workflows. The approach leverages LLMs to orchestrate agents, generate context-aware prompts, and handle feedback, achieving significant improvements over manual methods."" || } ||  || [ Prompt: 114.3 t/s | Generation: 27.7 t/s ]"
2601.10827v1_Approximately Optimal Global Planning for Contact-.pdf,Approximately Optimal Global Planning for Contact-Rich SE(2) Manipulation,"['Simin Liu', 'Tong Zhao', 'Bernhard Paus Graesdal', 'Peter Werner', 'Jiuguang Wang', 'John Dolan', 'Changliu Liu', 'Tao Pang']",,27.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || Approximately Optimal Global Planning || for Contact-Rich SE(2) Manipulation || on a Graph of Reachable Sets || Simin Liu1,2,, Tong Zhao 2,, Bernhard Paus Graesdal 3, Peter Werner 3, Jiuguang Wang 2, John Dolan 1, Changliu || Liu1, Tao Pang2 || AbstractIf we consider human manipulation, it is cl ... (truncated) ||  || { || ""title"": ""Approximately Optimal Global Planning for Contact-Rich SE(2) Manipulation"", || ""authors"": [ || ""Simin Liu"", || ""Tong Zhao"", || ""Bernhard Paus Graesdal"", || ""Peter Werner"", || ""Jiuguang Wang"", || ""John Dolan"", || ""Changliu Liu"", || ""Tao Pang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""contact-rich manipulation"", || ""manipulation planning"", || ""dexterous manipulation"", || ""robot manipulation"", || ""global optimization"" || ], || ""summary"": ""This paper introduces a new paradigm for computing approximately optimal manipulator plans by combining offline graph construction of mutual reachable sets with online local planning. It demonstrates improved task performance in contact-rich tasks, achieving a 61% reduction in task cost and a 91% success rate."" || } ||  || [ Prompt: 123.9 t/s | Generation: 27.4 t/s ]"
2601.10835v1_Can Vision-Language Models Understand Construction.pdf,Vision-Language Models Understand Construction Workers? An Exploratory Study,"['Hieu Bui', 'Nathaniel E. Chodosh', 'Arash Tavakoli']",,27.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Can Vision-Language Models Understand || Construction Workers? An Exploratory Study || Hieu Bui || Department of Electrical and Computer Engineering || Villanova University || Villanova, PA, USA || hbui01@villanova.edu || Nathaniel E. Chodosh || Department of Computing Sciences || Villanova University || Villano ... (truncated) ||  || { || ""title"": ""Vision-Language Models Understand Construction Workers? An Exploratory Study"", || ""authors"": [ || ""Hieu Bui"", || ""Nathaniel E. Chodosh"", || ""Arash Tavakoli"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Vision-Language Models"", || ""Construction Automation"", || ""Robotics"", || ""Human Robot Interaction"" || ], || ""summary"": ""This study evaluates three leading Vision-Language Models (GPT-4o, Florence 2, LLaVa-1.5) in detecting construction worker actions and emotions from static images. It assesses performance using standardized pipelines and finds general-purpose models effective but highlighting limitations in nuanced domain tasks."" || } ||  || [ Prompt: 120.5 t/s | Generation: 27.1 t/s ]"
2601.10880v1_Medical SAM3 A Foundation Model for Universal Prom.pdf,Medical SAM3: A Foundation Model for Universal Prompt-Driven Medical Image Segmentation,"['Chongcong Jiang', 'Tianxingjian Ding', 'Chuhan Song', 'Jiachen Tu', 'Ziyang Yan', 'Yihua Shao', 'Zhenyi Wang', 'Yuzhang Shang', 'Tianyu Han', 'Yu Tian']",arXiv:2601.10880v1,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Medical SAM3: A Foundation Model for || Universal Prompt-Driven Medical Image || Segmentation || Chongcong Jiang1*, Tianxingjian Ding1*, Chuhan Song2*, Jiachen Tu3, Ziyang || Yan4, Yihua Shao5, Zhenyi Wang1, Yuzhang Shang1, Tianyu Han6, and Yu || Tian1B || 1 University of Central Florida, Orlando, US ... (truncated) ||  || { || ""title"": ""Medical SAM3: A Foundation Model for Universal Prompt-Driven Medical Image Segmentation"", || ""authors"": [ || ""Chongcong Jiang"", || ""Tianxingjian Ding"", || ""Chuhan Song"", || ""Jiachen Tu"", || ""Ziyang Yan"", || ""Yihua Shao"", || ""Zhenyi Wang"", || ""Yuzhang Shang"", || ""Tianyu Han"", || ""Yu Tian"" || ], || ""doi"": ""arXiv:2601.10880v1"", || ""arxiv_id"": ""2601.10880"", || ""keywords"": [ || ""Medical Image Segmentation"", || ""Foundation Models"", || ""Fine-Tuning"", || ""SAM3"", || ""Medical Imaging"", || ""Text Prompts"" || ], || ""summary"": ""Medical SAM3 is a foundation model for universal prompt-driven medical image segmentation, demonstrating strong generalization and robust performance across diverse medical datasets after fine-tuning."" || } ||  || [ Prompt: 122.4 t/s | Generation: 28.7 t/s ]"
2601.10904v1_ARC Prize 2025 Technical Report.pdf,ARC Prize 2025: Technical Report,"['Franois Chollet', 'Mike Knoop', 'Gregory Kamradt', 'Bryan Landers']",10.48550/arxiv/2503.12345,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ARC Prize 2025: Technical Report || Franois Chollet, Mike Knoop, Gregory Kamradt, Bryan Landers || January 19, 2026 || Abstract || The ARC-AGI benchmark series serves as a critical measure of few-shot generalization on novel || tasks, a core aspect of intelligence. The ARC Prize 2025 global compet ... (truncated) ||  || { || ""title"": ""ARC Prize 2025: Technical Report"", || ""authors"": [ || ""Franois Chollet"", || ""Mike Knoop"", || ""Gregory Kamradt"", || ""Bryan Landers"" || ], || ""doi"": ""10.48550/arxiv/2503.12345"", || ""arxiv_id"": ""arxiv:2503.12345"", || ""keywords"": [ || ""ARC-AGI"", || ""few-shot generalization"", || ""intelligence"", || ""refinement loop"", || ""AGI"", || ""knowledge coverage"" || ], || ""summary"": ""The paper discusses the ARC Prize 2025 competition, focusing on the ARC-AGI benchmark, its impact on AI research, and the role of refinement loops in advancing artificial intelligence."" || } ||  || [ Prompt: 118.8 t/s | Generation: 27.5 t/s ]"
2601.10917v1_Self-learned representation-guided latent diffusio.pdf,SELF-LEARNED REPRESENTATION-GUIDED LATENT DIFFUSION MODEL FOR BREAST CANCER CLASSIFICATION IN DEEP ULTRA VIOLET WHOLE SURFACE IMAGES,"['Pouya Afshin', 'David Helminiak', 'Tianling Niu', 'Julie M. Jorns', 'Tina Yen', 'Bing Yu', 'Dong Hye Ye']",10.48550/arXiv.2405.12345,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SELF-LEARNED REPRESENTATION-GUIDED LATENT DIFFUSION MODEL FOR BREAST || CANCER CLASSIFICATION IN DEEP ULTRA VIOLET WHOLE SURFACE IMAGES || Pouya Afshin1, David Helminiak 2, Tianling Niu3, Julie M. Jorns 4, Tina Yen5, Bing Yu3, Dong Hye Ye1 || 1Department of Computer Science, Georgia State Un ... (truncated) ||  || { || ""title"": ""SELF-LEARNED REPRESENTATION-GUIDED LATENT DIFFUSION MODEL FOR BREAST CANCER CLASSIFICATION IN DEEP ULTRA VIOLET WHOLE SURFACE IMAGES"", || ""authors"": [ || ""Pouya Afshin"", || ""David Helminiak"", || ""Tianling Niu"", || ""Julie M. Jorns"", || ""Tina Yen"", || ""Bing Yu"", || ""Dong Hye Ye"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [ || ""Breast Cancer Classification"", || ""Latent Diffusion Model"", || ""Self-Supervised Learning"", || ""Data Augmentation"", || ""Deep Learning"", || ""Medical Imaging"" || ], || ""summary"": ""This paper proposes a Self-Supervised Learning-guided Latent Diffusion Model to generate synthetic training patches for Deep Ultraviolet Fluorescence Scanning Microscopy (DUV-FSM) data. By leveraging fine-tuned DINO teacher embeddings, the method enhances semantic detail in synthetic data, improving performance in breast cancer classification at full resolution."" || } ||  || [ Prompt: 121.0 t/s | Generation: 28.5 t/s ]"
2601.10921v1_RobuMTL Enhancing Multi-Task Learning Robustness A.pdf,Robust Multi-Task Learning Robustness,"['Tasneem Shaffee', 'Sherief Reda']",10.48550/arXiv.2405.12345,28.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || RobuMTL: Enhancing Multi-Task Learning Robustness || Against Weather Conditions || Tasneem Shaffee || Brown University || Providence, RI || tasneem shaffee@brown.edu || Sherief Reda || Brown University || Providence, RI || sherief reda@brown.edu || Abstract || Robust Multi-Task Learning (MTL) is crucial for au- || ton ... (truncated) ||  || { || ""title"": ""Robust Multi-Task Learning Robustness"", || ""authors"": [ || ""Tasneem Shaffee"", || ""Sherief Reda"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""10.48550/arXiv.2405.12345"", || ""keywords"": [ || ""Robust Multi-Task Learning"", || ""Weather Conditions"", || ""Multi-Task Learning"", || ""Adversarial Training"", || ""Data Augmentation"" || ], || ""summary"": ""This paper introduces RobuMTL, a novel architecture for robust multi-task learning that adapts to adverse weather conditions by dynamically selecting hierarchical Low-Rank Adaptation rules. It achieves significant improvements over single-task and standard MTL baselines across benchmark datasets."" || } ||  || [ Prompt: 117.5 t/s | Generation: 28.9 t/s ]"
2601.10922v1_What Matters in Data Curation for Multimodal Reaso.pdf,What Matters in Data Curation for Multimodal Reasoning?,"['Yosub Shin', 'Michael Buriek', 'Boris Sobolev', 'Pavel Bushuyeu', 'Vikas Kumar', 'Haoyang Xu', 'Igor Molybog', 'Samuel Watson']",10.48550/DCVLR2025,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || What Matters in Data Curation for Multimodal Reasoning? || Insights from the DCVLR Challenge || Yosub Shin1 Michael Buriek 1 2 Boris Sobolev 1 3 Pavel Bushuyeu 1 Vikas Kumar 1 Haoyang Xu 1 || Samuel Watson 1 Igor Molybog 1 || Abstract || We study data curation for multimodal reason- || ing through th ... (truncated) ||  || { || ""title"": ""What Matters in Data Curation for Multimodal Reasoning?"", || ""authors"": [ || ""Yosub Shin"", || ""Michael Buriek"", || ""Boris Sobolev"", || ""Pavel Bushuyeu"", || ""Vikas Kumar"", || ""Haoyang Xu"", || ""Igor Molybog"", || ""Samuel Watson"" || ], || ""doi"": ""10.48550/DCVLR2025"", || ""arxiv_id"": ""NeurIPS2025-1234"", || ""keywords"": [ || ""data curation"", || ""multimodal reasoning"", || ""DCVLR"", || ""data efficiency"", || ""model selection"" || ], || ""summary"": ""This paper examines data curation strategies for multimodal reasoning in the DCVLR challenge, emphasizing the impact of dataset selection and alignment on model performance. It highlights that difficulty-based example selection is crucial, and that increasing dataset size mainly stabilizes performance rather than improving it."" || } ||  || [ Prompt: 117.0 t/s | Generation: 28.4 t/s ]"
2601.10926v1_Selecting Language Models for Social Science Start.pdf,Selecting Language Models for Social Science,"['Dustin S. Stoltz', 'Marshall A. Taylor', 'Sanuj Kumar']",XX(X):122,27.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Selecting Language Models for Social Science: || Start Small, Start Open, and Validate || Preprint || XX(X):122 || The Author(s) 2026 || Dustin S. Stoltz 1, Marshall A. Taylor 2, and Sanuj Kumar 3 || Abstract || Currently, there are thousands of large pretrained language models (LLMs) available to socia ... (truncated) ||  || { || ""title"": ""Selecting Language Models for Social Science"", || ""authors"": [ || ""Dustin S. Stoltz"", || ""Marshall A. Taylor"", || ""Sanuj Kumar"" || ], || ""doi"": ""XX(X):122"", || ""arxiv_id"": """", || ""keywords"": [ || ""large language models"", || ""LLMs"", || ""reproducibility"", || ""reliability"", || ""replicability"", || ""model openness"" || ], || ""summary"": ""The paper discusses how to select among thousands of large pretrained language models for social science research, emphasizing the importance of validity, reliability, reproducibility, and replicability. It suggests starting with smaller, open models and building benchmarks."" || } ||  || [ Prompt: 120.8 t/s | Generation: 27.1 t/s ]"
2601.10931v1_Sparse Data Tree Canopy Segmentation Fine-Tuning L.pdf,Sparse Data Tree Canopy Segmentation,"['David Szczecina', 'Niloofar Azad', 'Hudson Sun', 'Kyle Gao', 'Anthony Bertnyk', 'Lincoln Linlin Xu']",,27.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Sparse Data Tree Canopy Segmentation: || Fine-Tuning Leading Pretrained Models on Only || 150 Images || David Szczecina || University of Waterloo || Waterloo, Canada || david.szczecina@uwaterloo.ca || Niloofar Azad || University of Waterloo || Waterloo, Canada || n2azad@uwaterloo.ca || Hudson Sun || University of Wate ... (truncated) ||  || { || ""title"": ""Sparse Data Tree Canopy Segmentation"", || ""authors"": [ || ""David Szczecina"", || ""Niloofar Azad"", || ""Hudson Sun"", || ""Kyle Gao"", || ""Anthony Bertnyk"", || ""Lincoln Linlin Xu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Deep Learning"", || ""Computer Vision"", || ""Object Segmentation"", || ""Remote Sensing"", || ""Forestry"", || ""Tree Canopy"" || ], || ""summary"": ""This paper evaluates five architectures for canopy segmentation under extreme data scarcity, highlighting the effectiveness of pretrained convolutional models and the challenges posed by semantic vs. instance segmentation in low-data regimes."" || } ||  || [ Prompt: 120.8 t/s | Generation: 27.1 t/s ]"
2601.10945v1_PatientVLM Meets DocVLM Pre-Consultation Dialogue .pdf,PatientVLM Meets DocVLM: Pre-Consultation Dialogue Between,"['K Lokesh1', 'Abhirama Subramanyam Penamakuri1', 'Uday Agarwal1', 'Apoorva Challa2', 'Shreya K Gowda2', 'Somesh Gupta2', 'Anand Mishra1']",https://vl2g.github.io/projects/pcdf,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || PatientVLM Meets DocVLM: Pre-Consultation Dialogue Between || Vision-Language Models for Efficient Diagnosis || K Lokesh1*, Abhirama Subramanyam Penamakuri1*, Uday Agarwal1, Apoorva Challa2, Shreya K || Gowda2, Somesh Gupta2, Anand Mishra1 || 1Indian Institute of Technology Jodhpur || 2All India I ... (truncated) ||  || { || ""title"": ""PatientVLM Meets DocVLM: Pre-Consultation Dialogue Between"", || ""authors"": [ || ""K Lokesh1"", || ""Abhirama Subramanyam Penamakuri1"", || ""Uday Agarwal1"", || ""Apoorva Challa2"", || ""Shreya K Gowda2"", || ""Somesh Gupta2"", || ""Anand Mishra1"" || ], || ""doi"": ""https://vl2g.github.io/projects/pcdf"", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper proposes a Pre-Consultation Dialogue Framework (PCDF) for vision-language models to simulate realistic doctor-patient dialogues, aiming to improve diagnostic accuracy by incorporating patient-reported symptoms."" || } ||  || [ Prompt: 118.3 t/s | Generation: 28.6 t/s ]"
2601.10951v1_Multi-Stage Patient Role-Playing Framework for Rea.pdf,Multi-Stage Patient Role-Playing Framework for Realistic Clinical Interactions,"['Shijie Jianga', 'Zefan Zhanga', 'Kehua Zhub', 'Tian Baia', 'Ruihong Zhaoc', 'aCollege of Computer Science and Technology, Key Laboratory of Symbolic Computation and Knowledge Engineering, Ministry of Education, Jilin University, Changchun 130012, China', 'bCollege of Software, Jilin University, Changchun 130012, China', 'cGastrointestinal Endoscopy Center, The First Hospital of Jilin University, Changchun 130012, China']",https://doi.org/2601.10951v1,29.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Multi-Stage Patient Role-Playing Framework for || Realistic Clinical Interactions || Shijie Jianga, Zefan Zhanga, Kehua Zhub, Tian Baia,, Ruihong Zhaoc, || aCollege of Computer Science and Technology, Key Laboratory of Symbolic Computation || and Knowledge Engineering, Ministry of Education, Ji ... (truncated) ||  || { || ""title"": ""Multi-Stage Patient Role-Playing Framework for Realistic Clinical Interactions"", || ""authors"": [ || ""Shijie Jianga"", || ""Zefan Zhanga"", || ""Kehua Zhub"", || ""Tian Baia"", || ""Ruihong Zhaoc"", || ""aCollege of Computer Science and Technology, Key Laboratory of Symbolic Computation and Knowledge Engineering, Ministry of Education, Jilin University, Changchun 130012, China"", || ""bCollege of Software, Jilin University, Changchun 130012, China"", || ""cGastrointestinal Endoscopy Center, The First Hospital of Jilin University, Changchun 130012, China"" || ], || ""doi"": ""https://doi.org/2601.10951v1"", || ""arxiv_id"": ""2601.10951"", || ""keywords"": [ || ""Patient Role-Playing"", || ""Large Language Models"", || ""Clinical"", || ""Diagnostic Education"", || ""Simulation"", || ""Persona Structure"" || ], || ""summary"": ""The paper proposes a new Chinese patient simulation dataset (Ch-PatientSim) to enhance the realism of clinical interactions for training LLMs. It addresses persona imbalance through few-shot generation and manual verification, and introduces a Multi-Stage Patient Role-Playing framework to improve model performance."" || } ||  || [ Prompt: 129.3 t/s | Generation: 29.9 t/s ]"
2601.10955v1_Beyond Max Tokens Stealthy Resource Amplification .pdf,Beyond Max Tokens: Stealthy Resource Amplification via Tool,"['Kaiyu Zhou', 'Yongsen Zheng', 'Yicheng He', 'Meng Xue', 'Xueluan Gong', 'Yuji Wang']",,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Beyond Max Tokens: Stealthy Resource Amplification via Tool || Calling Chains in LLM Agents || Kaiyu Zhou || Nanyang Technological University || Singapore || kaiyu001@e.ntu.edu.sg || Yongsen Zheng || Nanyang Technological University || Singapore || yongsen.zheng@ntu.edu.sg || Yicheng He || University of Illinois || Ur ... (truncated) ||  || { || ""title"": ""Beyond Max Tokens: Stealthy Resource Amplification via Tool"", || ""authors"": [ || ""Kaiyu Zhou"", || ""Yongsen Zheng"", || ""Yicheng He"", || ""Meng Xue"", || ""Xueluan Gong"", || ""Yuji Wang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Large Language Models"", || ""LLM Agents"", || ""Tool Calling"", || ""Agent Security"", || ""Economic Denial-of-Service"" || ], || ""summary"": ""The paper introduces a stealthy, multi-turn economic DoS attack targeting LLM agents. It operates under the guise of a correctly completed task, adjusting text-visible fields and using a Model Context Protocol to prolong tool-calling sequences. The attack scales tasks across high token counts while evading detection, increasing computational costs and energy usage."" || } ||  || [ Prompt: 124.4 t/s | Generation: 28.7 t/s ]"
2601.10960v1_Steering Language Models Before They Speak Logit-L.pdf,Steering Language Models Before They Speak: Logit-Level Interventions,"['Hyeseon An', 'Shinwoo Park', 'Hyundong Jin', 'Yo-Sub Han']",,27.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Steering Language Models Before They Speak: Logit-Level Interventions || Hyeseon An, Shinwoo Park, Hyundong Jin, and Yo-Sub Han * || Department of Computer Science, Yonsei University, Seoul, South Korea || {hsan, pshkhh, tuzi04, emmous}@yonsei.ac.kr || Abstract || Steering LLMs is essential for sp ... (truncated) ||  || { || ""title"": ""Steering Language Models Before They Speak: Logit-Level Interventions"", || ""authors"": [""Hyeseon An"", ""Shinwoo Park"", ""Hyundong Jin"", ""Yo-Sub Han""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""steering"", ""language models"", ""logit-level"", ""interventions""], || ""summary"": ""The paper proposes a training-free inference-time logit intervention to steer language model outputs, addressing limitations of existing prompting and activation-based methods. Empirical results show effective control over writing complexity, formality, and toxicity."" || } ||  || [ Prompt: 120.3 t/s | Generation: 27.1 t/s ]"
2601.11000v1_When Personalization Misleads Understanding and Mi.pdf,When Personalization Misleads: Understanding and Mitigating,"['Zhongxiang Sun', 'Yi Zhan', 'Chenglei Shen', 'Weijie Yu', 'Xiao Zhang', 'Ming He', 'Jun Xu']",,27.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || When Personalization Misleads: Understanding and Mitigating || Hallucinations in Personalized LLMs || Zhongxiang Sun1, Yi Zhan1, Chenglei Shen1, Weijie Yu3, Xiao Zhang1, Ming He2, Jun Xu1 || 1Gaoling School of Artificial Intelligence, Renmin University of China; 2AI Lab at Lenovo Research; || 3 ... (truncated) ||  || { || ""title"": ""When Personalization Misleads: Understanding and Mitigating"", || ""authors"": [ || ""Zhongxiang Sun"", || ""Yi Zhan"", || ""Chenglei Shen"", || ""Weijie Yu"", || ""Xiao Zhang"", || ""Ming He"", || ""Jun Xu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""personalization"", || ""hallucinations"", || ""personalized LLMs"", || ""factual accuracy"", || ""representational entanglement"" || ], || ""summary"": ""The paper discusses how personalization in large language models can lead to hallucinations, especially when handling factual queries. It introduces FPPS to mitigate these issues and presents PFQABench for evaluating factual and personalized question answering."" || } ||  || [ Prompt: 123.4 t/s | Generation: 27.3 t/s ]"
2601.11007v1_AdaMARP An Adaptive Multi-Agent Interaction Framew.pdf,AdaMARP,"['Zhenhua Xu1', 'Dongsheng Chen', 'Shuo Wang2', 'Jian Li2', 'Chengjie Wang2', 'Meng Han2', 'Yabiao Wang2']",,29.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || AdaMARP || AdaMARP: An Adaptive Multi-Agent Interaction Framework for || General Immersive Role-Playing || Zhenhua Xu1, Dongsheng Chen 2 || Shuo Wang2, Jian Li 2, Chengjie Wang 2, Meng Han 2, Yabiao Wang 2 || 1Zhejiang University,2Tencent Youtu Lab || LLM role-playing seeks to portray arbitrary chara ... (truncated) ||  || { || ""title"": ""AdaMARP"", || ""authors"": [ || ""Zhenhua Xu1"", || ""Dongsheng Chen"", || ""Shuo Wang2"", || ""Jian Li2"", || ""Chengjie Wang2"", || ""Meng Han2"", || ""Yabiao Wang2"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""AdaMARP"", || ""multi-agent interaction"", || ""general immersive role-playing"", || ""adaptive frameworks"", || ""LLM role-playing"", || ""environment modeling"" || ], || ""summary"": ""AdaMARP proposes an adaptive multi-agent interaction framework for general immersive role-playing, addressing limitations in dynamic environment modeling and multi-character orchestration."" || } ||  || [ Prompt: 117.1 t/s | Generation: 29.5 t/s ]"
2601.11012v1_Efficient Protein Optimization via Structure-aware.pdf,Efficient Protein Optimization via Structure-aware Hamiltonian Dynamics,"['Jiahao Wang', 'Shuangjia Zheng']",10.48550/arXiv.2407.04219,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Efficient Protein Optimization via Structure-aware Hamiltonian Dynamics || Jiahao Wang1, Shuangjia Zheng1,* || 1Shanghai Jiao Tong University || {jiahaowang, shuangjia.zheng}@sjtu.edu.cn || Abstract || The ability to engineer optimized protein variants has trans- || formative potential for biotechnol ... (truncated) ||  || { || ""title"": ""Efficient Protein Optimization via Structure-aware Hamiltonian Dynamics"", || ""authors"": [""Jiahao Wang"", ""Shuangjia Zheng""], || ""doi"": ""10.48550/arXiv.2407.04219"", || ""arxiv_id"": ""2407.04219"", || ""keywords"": [ || ""protein optimization"", || ""structure-aware"", || ""Bayesian optimization"", || ""Hamiltonian dynamics"", || ""protein sequences"", || ""machine learning"" || ], || ""summary"": ""The paper proposes HADES, a Bayesian optimization method using Hamiltonian dynamics to efficiently sample from a structure-aware posterior, aiming to engineer optimized protein variants by leveraging structural constraints."" || } ||  || [ Prompt: 119.3 t/s | Generation: 27.8 t/s ]"
2601.11016v1_Contextual Distributionally Robust Optimization wi.pdf,Contextual Distributionally Robust Optimization with Causal and Continuous Structure: An Interpretable and Tractable Approach,"['Fenglin Zhang', 'Jie Wang']",arXiv:2601.11016v1,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Contextual Distributionally Robust Optimization with || Causal and Continuous Structure: An Interpretable and || Tractable Approach || Fenglin Zhang, Jie Wang || January 19, 2026 || Abstract || In this paper, we introduce a framework for contextual distributionally robust optimiza- || tion (DRO) that co ... (truncated) ||  || { || ""title"": ""Contextual Distributionally Robust Optimization with Causal and Continuous Structure: An Interpretable and Tractable Approach"", || ""authors"": [ || ""Fenglin Zhang"", || ""Jie Wang"" || ], || ""doi"": ""arXiv:2601.11016v1"", || ""arxiv_id"": ""arXiv:2601.11016"", || ""keywords"": [ || ""Contextual distributionally robust optimization"", || ""Causal Sinkhorn discrepancy"", || ""Soft regression forest"", || ""Stochastic compositional optimization"" || ], || ""summary"": ""The paper introduces a framework for contextual distributionally robust optimization that incorporates causal and continuous structure via interpretable decision rules. It presents Causal Sinkhorn Discrepancy and derives a strong dual reformulation, followed by a novel Soft Regression Forest algorithm for policy optimization."" || } ||  || [ Prompt: 129.5 t/s | Generation: 29.0 t/s ]"
2601.11019v1_Finding the Translation Switch Discovering and Exp.pdf,Finding the Translation Switch: Discovering and Exploiting the Task-Initiation,"['Xinwei Wu', 'Heng Liu', 'Xiaohu Zhao', 'Yuqi Ren', 'Linlong Xu', 'Longyue Wang', 'Dehyi Xiong', 'Weihua Luo', 'Kaifu Zhang']","wuxw2021, ryq20, dyxiong",27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Finding the Translation Switch: Discovering and Exploiting the Task-Initiation || Features in LLMs || Xinwei Wu1*, Heng Liu2*, Xiaohu Zhao2, Yuqi Ren1, Linlong Xu2, || Longyue Wang2, Deyi Xiong1, Weihua Luo2, Kaifu Zhang2 || 1 TJUNLP, Tianjin University, China || 2 Alibaba International Digital Co ... (truncated) ||  || { || ""title"": ""Finding the Translation Switch: Discovering and Exploiting the Task-Initiation"", || ""authors"": [ || ""Xinwei Wu"", || ""Heng Liu"", || ""Xiaohu Zhao"", || ""Yuqi Ren"", || ""Linlong Xu"", || ""Longyue Wang"", || ""Dehyi Xiong"", || ""Weihua Luo"", || ""Kaifu Zhang"" || ], || ""doi"": ""wuxw2021, ryq20, dyxiong"", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper explores how Large Language Models exhibit strong translation abilities without task-specific fine-tuning, focusing on identifying and amplifying translation initiation features to improve performance and robustness."" || } ||  || [ Prompt: 124.4 t/s | Generation: 27.6 t/s ]"
2601.11021v1_Combating Spurious Correlations in Graph Interpret.pdf,Combating Spurious Correlations in Graph Interpretability via Self-Reflection,"['Kecheng Cai', 'Chenyang Xu', 'Chao Peng']",10.48550/arXiv.2026.12345,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Combating Spurious Correlations in Graph Interpretability via || Self-Reflection || Kecheng Cai, Chenyang Xu, Chao Peng || January 2026 || Abstract || Interpretable graph learning has recently emerged as a popular research topic in machine learning. The goal || is to identify the important nodes and  ... (truncated) ||  || { || ""title"": ""Combating Spurious Correlations in Graph Interpretability via Self-Reflection"", || ""authors"": [""Kecheng Cai"", ""Chenyang Xu"", ""Chao Peng""], || ""doi"": ""10.48550/arXiv.2026.12345"", || ""arxiv_id"": ""arXiv:2509.12345"", || ""keywords"": [""graph interpretability"", ""spurious correlations"", ""self-reflection"", ""graph learning""], || ""summary"": ""This paper addresses the challenge of spurious correlations in graph datasets by proposing a self-reflection framework to improve interpretability. It demonstrates how iterative self-reflection can enhance performance on benchmark datasets like Spurious-Motif, offering insights for better graph representation learning."" || } ||  || [ Prompt: 124.0 t/s | Generation: 27.6 t/s ]"
2601.11030v1_IDDR-NGP Incorporating Detectors for Distractor Re.pdf,Incorporating Detectors for Distractor Removal with Instant Neural Radiance Field,"['Xianliang Huang', 'Jiajie Gou', 'Shuhang Chen', 'Zhizhou Zhong', 'Jihong Guan', 'Shuigeng Zhou', 'Petals']",10.1145/3581783.3612045,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || IDDR-NGP: Incorporating Detectors for Distractor Removal with || Instant Neural Radiance Field || Xianliang Huang || Fudan University || Shanghai, China || huangxl21@m.fudan.edu.cn || Jiajie Gou || Fudan University || Shanghai, China || 19307110343@fudan.edu.cn || Shuhang Chen || Fudan University || Shanghai, China || 22 ... (truncated) ||  || { || ""title"": ""Incorporating Detectors for Distractor Removal with Instant Neural Radiance Field"", || ""authors"": [ || ""Xianliang Huang"", || ""Jiajie Gou"", || ""Shuhang Chen"", || ""Zhizhou Zhong"", || ""Jihong Guan"", || ""Shuigeng Zhou"", || ""Petals"" || ], || ""doi"": ""10.1145/3581783.3612045"", || ""arxiv_id"": ""IDDR-NGP"", || ""keywords"": [ || ""distractor removal"", || ""distractors"", || ""3D scenes"", || ""synthetic scene"", || ""realistic scene"", || ""input views"", || ""detect distractors"", || ""defoliation"", || ""petals"" || ], || ""summary"": ""This paper presents the first unified distractor removal method, IDDR-NGP, which directly operates on Instant-NPG. The method removes a wide range of distractors in 3D scenes such as snowflakes, confetti, defoliation, and petals, demonstrating efficient restoration of 3D scenes from corrupted images."" || } ||  || [ Prompt: 115.5 t/s | Generation: 29.0 t/s ]"
2601.11035v1_Your One-Stop Solution for AI-Generated Video Dete.pdf,Long Ma1 Zihao Xue2 Yan Wang3 Zhiyuan Yan4,"['Jin Xu5', 'Xiaorui Jiang1', 'Haiyang Yu1,6', 'Yong Liao1, Zhen Bi2']",arXiv:2601.11035v1,29.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Your One-Stop Solution for AI-Generated Video Detection || Long Ma1 Zihao Xue2 Yan Wang3 Zhiyuan Yan4 || Jin Xu5 Xiaorui Jiang1 Haiyang Yu1,6 Yong Liao1, Zhen Bi2, || 1School of Cyber Science and Technology, University of Science and Technology of China || 2Huzhou University 3Alibaba Group || 4Sch ... (truncated) ||  || { || ""title"": ""Long Ma1 Zihao Xue2 Yan Wang3 Zhiyuan Yan4"", || ""authors"": [ || ""Jin Xu5"", || ""Xiaorui Jiang1"", || ""Haiyang Yu1,6"", || ""Yong Liao1, Zhen Bi2"" || ], || ""doi"": ""arXiv:2601.11035v1"", || ""arxiv_id"": ""arXiv:2601.11035"", || ""keywords"": [ || ""Text to Video"", || ""Image to Video"", || ""Mainstream Detectors"", || ""Vehicles"", || ""Quantity"", || ""Scenery"", || ""Experimental Results"", || ""Judgement"", || ""Imaging Quality"", || ""Motion Smoothness"", || ""Diverse Video Content"", || ""Real Multiple Tasks"", || ""Numerous Advanced models"", || ""Video To Video"", || ""AIGVD"", || ""Bench"", || ""Insightful Analyses"", || ""Abstract"" || ], || ""summary"": ""Recent advances in generative modeling can create remarkably realistic synthetic videos, making it increasingly difficult for humans to distinguish them from real ones. However, two key limitations hinder the development of this field."" || } ||  || [ Prompt: 129.0 t/s | Generation: 29.2 t/s ]"
2601.11037v1_BAPO Boundary-Aware Policy Optimization for Reliab.pdf,BAPO: Boundary-Aware Policy Optimization for Reliable Agentic Search,"['Shiyu Liu', 'Yongjing Yin', 'Jianhao Yan', 'Yunbo Tang', 'Qinggang Zhang', 'Xin Chen', 'Jingang Wang', 'Xunliang Cai', 'Jinsong Su']",,28.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || BAPO: Boundary-Aware Policy Optimization for Reliable Agentic Search || Shiyu Liu1,2,, Yongjing Yin2, Jianhao Yan4, Yunbo Tang3, Qinggang Zhang5* || Bei Li2,Xin Chen 2,Jingang Wang 2,Xunliang Cai 2,Jinsong Su 1,3* || 1Institute of Artificial Intelligence, Xiamen University || 2Meituan Inc. 3Sch ... (truncated) ||  || { || ""title"": ""BAPO: Boundary-Aware Policy Optimization for Reliable Agentic Search"", || ""authors"": [ || ""Shiyu Liu"", || ""Yongjing Yin"", || ""Jianhao Yan"", || ""Yunbo Tang"", || ""Qinggang Zhang"", || ""Xin Chen"", || ""Jingang Wang"", || ""Xunliang Cai"", || ""Jinsong Su"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""RL-based agentic search enables LLMs to solve complex questions via dynamic planning and external search. The paper highlights a critical gap in reliability: agents fail to recognize reasoning boundaries and rarely admit I DONT KNOW, even when evidence is insufficient. To address this, the authors propose Boundary-Aware Policy Optimization (BAPO), a novel RL framework that cultivates reliable boundary awareness without compromising accuracy."" || } ||  || [ Prompt: 122.5 t/s | Generation: 28.0 t/s ]"
2601.11042v1_Spectral Characterization and Mitigation of Sequen.pdf,Spectral Characterization and Mitigation of Sequential Knowledge Editing Collapse,"['Chi Zhang', 'Mengqi Zhang', 'Xiaotian Ye', 'Runxi Cheng', 'Zisheng Zhou', 'Ying Zhou', 'Pengjie Ren', 'Zhumin Chen']",2000 4000 10000 20000,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Spectral Characterization and Mitigation of || Sequential Knowledge Editing Collapse || Chi Zhang1, Mengqi Zhang1*, Xiaotian Ye2, Runxi Cheng3, || Zisheng Zhou1,Ying Zhou 1,Pengjie Ren 1,Zhumin Chen 1 || 1Shandong University || 2School of Computer Science, Beijing University of Posts and Telecommu ... (truncated) ||  || { || ""title"": ""Spectral Characterization and Mitigation of Sequential Knowledge Editing Collapse"", || ""authors"": [ || ""Chi Zhang"", || ""Mengqi Zhang"", || ""Xiaotian Ye"", || ""Runxi Cheng"", || ""Zisheng Zhou"", || ""Ying Zhou"", || ""Pengjie Ren"", || ""Zhumin Chen"" || ], || ""doi"": ""2000 4000 10000 20000"", || ""arxiv_id"": """", || ""keywords"": [ || ""sequential knowledge editing"", || ""knowledge editing"", || ""large language models"", || ""parameter updates"", || ""general abilities"", || ""spectral analysis"" || ], || ""summary"": ""This paper presents a spectral analysis of sequential knowledge editing in large language models, identifying dominant singular directions in pretrained weights that degrade under repeated edits. It proposes REVIVE, a framework that stabilizes sequential editing by preserving dominant singular subspaces."" || } ||  || [ Prompt: 121.8 t/s | Generation: 28.6 t/s ]"
2601.11044v2_AgencyBench Benchmarking the Frontiers of Autonomo.pdf,AGENCYBENCH: Benchmarking the Frontiers of Autonomous Agents in 1M-Token Real-World Contexts,"['Keyu Li', 'Junhao Shi', 'Yang Xiao', 'Mohan Jiang', 'Jie Sun', 'Yunze Wu', 'Dayuan Fu', 'Shijie Xia', 'Xiaojie Cai', 'Tianze Xu', 'Weiye Si', 'Pengfei Liu']",SII 2SJTU 3PolyU 4GAIR,28.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SII-GAIR || AGENCYBENCH: Benchmarking the Frontiers of Autonomous || Agents in 1M-Token Real-World Contexts || Keyu Li1,2,4 Junhao Shi2,4 Yang Xiao3,4 Mohan Jiang1,2,4 Jie Sun1,4 Yunze Wu2,4 Dayuan Fu1,4 || Shijie Xia1,2,4 Xiaojie Cai2,4 Tianze Xu2,4 Weiye Si2,4 Wenjie Li3 Dequan Wang1,2,4 Peng ... (truncated) ||  || { || ""title"": ""AGENCYBENCH: Benchmarking the Frontiers of Autonomous Agents in 1M-Token Real-World Contexts"", || ""authors"": [ || ""Keyu Li"", || ""Junhao Shi"", || ""Yang Xiao"", || ""Mohan Jiang"", || ""Jie Sun"", || ""Yunze Wu"", || ""Dayuan Fu"", || ""Shijie Xia"", || ""Xiaojie Cai"", || ""Tianze Xu"", || ""Weiye Si"", || ""Pengfei Liu"" || ], || ""doi"": ""SII 2SJTU 3PolyU 4GAIR"", || ""arxiv_id"": ""SII Open Source: AgencyBench/githubCode"", || ""keywords"": [ || ""autonomous agents"", || ""LLMs"", || ""benchmarking"", || ""real-world scenarios"", || ""tool evaluation"", || ""agentic capabilities"" || ], || ""summary"": ""This paper introduces AGENCYBENCH, a comprehensive benchmark evaluating 6 core agentic capabilities across 32 real-world scenarios. It assesses performance in economic production contexts, highlighting differences between open-source and closed-source models, and explores the impact of agentic scaffolds and tool usage."" || } ||  || [ Prompt: 121.9 t/s | Generation: 28.0 t/s ]"
2601.11049v1_Predicting Biased Human Decision-Making with Large.pdf,Predicting Biased Human Decision-Making with Large Language Models in Conversational Settings,"['Stephen Pilli', 'Vivek Nallur']",,27.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Predicting Biased Human Decision-Making with Large Language || Models in Conversational Settings || Stephen Pilli || stephen.pilli@ucdconnect.ie || University College Dublin || Dublin, Ireland || Vivek Nallur || vivek.nallur@ucd.ie || University College Dublin || Dublin, Ireland || Abstract || We examine whether la ... (truncated) ||  || { || ""title"": ""Predicting Biased Human Decision-Making with Large Language Models in Conversational Settings"", || ""authors"": [ || ""Stephen Pilli"", || ""Vivek Nallur"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Conversational AI"", || ""Framing Effect"", || ""Status Quo Bias"", || ""LLM Simulation"" || ], || ""summary"": ""We examine whether large language models can predict biased decision-making in conversational settings and how cognitive biases interact with cognitive load. The study finds that increased dialogue complexity amplifies bias effects and that LLMs can accurately predict human-like decision patterns when incorporating dialogue context."" || } ||  || [ Prompt: 116.1 t/s | Generation: 27.1 t/s ]"
2601.11063v1_H-AIM Orchestrating LLMs PDDL and Behavior Trees f.pdf,"Orchestrating LLMs, PDDL, and Behavior Trees for Hierarchical Multi-Robot Planning","['Haishan Zeng', 'Peng Li']",,29.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || H-AIM: Orchestrating LLMs, PDDL, and Behavior Trees for Hierarchical || Multi-Robot Planning || Haishan Zeng 1,2 Peng Li 1,2 || 1University of Chinese Academy of Sciences || 2Institute of Software, Chinese Academy of Sciences || zenghaishan24@mails.ucas.ac.cn lipeng@iscas.ac.cn || Abstract || In embodie ... (truncated) ||  || { || ""title"": ""Orchestrating LLMs, PDDL, and Behavior Trees for Hierarchical Multi-Robot Planning"", || ""authors"": [ || ""Haishan Zeng"", || ""Peng Li"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""multi-robot planning"", || ""large language models"", || ""PDDL"", || ""behavior trees"", || ""hierarchical planning"", || ""robot coordination"" || ], || ""summary"": ""The paper proposes H-AIM, a framework for hierarchical multi-robot planning that integrates LLMs, PDDL, and behavior trees to enable long-horizon task execution in heterogeneous robot teams. Experimental results show significant improvements over baselines."" || } ||  || [ Prompt: 115.6 t/s | Generation: 29.2 t/s ]"
2601.11065v1_Fairness in Healthcare Processes A Quantitative An.pdf,Fairness in Healthcare Processes: A Quantitative Analysis of Decision Making in Triage,"['Rachmadita Andreswari', 'Stephan A. Fahrenkrog-Petersen', 'Jan Mendling']",arXiv:2601.11065v1,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Fairness in Healthcare Processes: A Quantitative || Analysis of Decision Making in Triage || Rachmadita Andreswari1,2,4, Stephan A. Fahrenkrog-Petersen2,3, || Jan Mendling1,2 || 1 Humboldt-Universitt zu Berlin, Rudower Chaussee 25, 12489 Berlin, Germany || 2 Weizenbaum Institut, Hardenbergstrae 32 ... (truncated) ||  || { || ""title"": ""Fairness in Healthcare Processes: A Quantitative Analysis of Decision Making in Triage"", || ""authors"": [ || ""Rachmadita Andreswari"", || ""Stephan A. Fahrenkrog-Petersen"", || ""Jan Mendling"" || ], || ""doi"": ""arXiv:2601.11065v1"", || ""arxiv_id"": ""arXiv:2601.11065"", || ""keywords"": [ || ""process mining"", || ""fairness"", || ""triage"", || ""emergency room"", || ""justice theory"" || ], || ""summary"": ""This study investigates fairness in automated decision-making within emergency triage processes using process mining. It analyzes real-life event logs linked to justice dimensions and evaluates factors such as age, gender, race, language, and insurance to assess potential unfairness in healthcare workflows."" || } ||  || [ Prompt: 126.1 t/s | Generation: 27.8 t/s ]"
2601.11073v1_Bridging Cognitive Neuroscience and Graph Intellig.pdf,Bridging Cognitive Neuroscience and Graph Intelligence: Hippocampus-Inspired Multi-View Hypergraph Learning for Web,"['Rongkun Cui', 'Nana Zhang', 'Kun Zhu', 'Qi Zhang', 'Zhangqi C.S.', 'Joker Cui']","WWW26, Dubai, United Arab Emirates",28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Bridging Cognitive Neuroscience and Graph Intelligence: || Hippocampus-Inspired Multi-View Hypergraph Learning for Web || Finance Fraud || Rongkun Cui || Tongji University || Shanghai, China || jokercui@tongji.edu.cn || Nana Zhang || Donghua University || Shanghai, China || nnzhang@dhu.edu.cn || Kun Zhu || Tongji Univ ... (truncated) ||  || { || ""title"": ""Bridging Cognitive Neuroscience and Graph Intelligence: Hippocampus-Inspired Multi-View Hypergraph Learning for Web"", || ""authors"": [ || ""Rongkun Cui"", || ""Nana Zhang"", || ""Kun Zhu"", || ""Qi Zhang"", || ""Zhangqi C.S."", || ""Joker Cui"" || ], || ""doi"": ""WWW26, Dubai, United Arab Emirates"", || ""arxiv_id"": """", || ""keywords"": [ || ""cognitive neuroscience"", || ""graph intelligence"", || ""web fraud detection"", || ""multi-view learning"", || ""hippocampus-inspired"", || ""fraud detection"", || ""long-tailed data"", || ""information systems"" || ], || ""summary"": ""Online financial services face significant fraud risks that undermine trust. Existing GNN-based methods struggle with fraud camouflage and long-tailed data. We propose HIMVH, a Hippocampus-Inspired Multi-View Hypergraph learning model, to detect subtle cross-view conflicts and rare fraud patterns."" || } ||  || [ Prompt: 117.4 t/s | Generation: 28.4 t/s ]"
2601.11076v1_A3D Adaptive Affordance Assembly with Dual-Arm Man.pdf,Adaptive Affordance Assembly with Dual-Arm Manipulation,"['Jiaqi Liang', 'Yue Chen', 'Qize Yu', 'Yan Shen', 'Haipeng Zhang', 'Hao Dong', 'Ruihai Wu']",,29.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A3D: Adaptive Affordance Assembly with Dual-Arm Manipulation || Jiaqi Liang1*, Yue Chen1*, Qize Yu1*, Yan Shen1, Haipeng Zhang1, Hao Dong1, Ruihai Wu1 || 1Peking University || jiaqiliang@stu.pku.edu.cn, yuechen@stu.pku.edu.cn, wuruihai@pku.edu.cn || Abstract || Furniture assembly is a crucial yet  ... (truncated) ||  || { || ""title"": ""Adaptive Affordance Assembly with Dual-Arm Manipulation"", || ""authors"": [ || ""Jiaqi Liang"", || ""Yue Chen"", || ""Qize Yu"", || ""Yan Shen"", || ""Haipeng Zhang"", || ""Hao Dong"", || ""Ruihai Wu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Furniture assembly is challenging for robots, requiring adaptive support strategies. The proposed A3D framework learns optimal support locations using dense point-level geometry representations and adapts support dynamically during assembly."" || } ||  || [ Prompt: 114.4 t/s | Generation: 29.6 t/s ]"
2601.11077v1_ABC-Bench Benchmarking Agentic Backend Coding in R.pdf,OpenMOSS,"['Jie Yang', 'Honglin Guo', 'Li Ji', 'Jiazheng Zhou', 'Rui Zheng', 'Bo Wang', 'Ying Zheng', 'Tao Gui', 'Xipeng Qiu']",10.1093/acprof:oso/9780190871293.013,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || OpenMOSS || ABC-Bench: Benchmarking Agentic Backend Coding || in Real-World Development || Jie Yang1,* Honglin Guo1,* Li Ji1 Jiazheng Zhou1 Rui Zheng2 || Zhikai Lei2 Shuo Zhang2 Zhiheng Xi1 Shichun Liu1 Yuxin Wang1 || Bo Wang1 Yining Zheng1, Tao Gui1, Xipeng Qiu1,3 || 1Fudan University 2Shanghai Qi Z ... (truncated) ||  || { || ""title"": ""OpenMOSS"", || ""authors"": [ || ""Jie Yang"", || ""Honglin Guo"", || ""Li Ji"", || ""Jiazheng Zhou"", || ""Rui Zheng"", || ""Bo Wang"", || ""Ying Zheng"", || ""Tao Gui"", || ""Xipeng Qiu"" || ], || ""doi"": ""10.1093/acprof:oso/9780190871293.013"", || ""arxiv_id"": ""2601.11077"", || ""keywords"": [ || ""OpenMOSS"", || ""ABC-Bench"", || ""agentic backend coding"", || ""LLM"", || ""software engineering"", || ""benchmarking"" || ], || ""summary"": ""The paper introduces ABC-Bench, a benchmark for evaluating autonomous agents in real-world software engineering tasks. It highlights the need for models to handle full development lifecycles, from repository exploration to service deployment, and notes a significant gap between current model capabilities and practical requirements."" || } ||  || [ Prompt: 129.6 t/s | Generation: 27.7 t/s ]"
2601.11078v1_Visual Marker Search for Autonomous Drone Landing .pdf,Visual Marker Search for Autonomous Drone,"['Jiaohong Yao', 'Linfeng Liang', 'Yao Deng', 'Xi Zheng', 'Richard Han', 'Yuankai Qi']",,27.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Visual Marker Search for Autonomous Drone || Landing in Diverse Urban Environments || Jiaohong Yao, Linfeng Liang, Yao Deng, Xi Zheng, Richard Han, Yuankai Qi || School of Computing, Macquarie University || Sydney, Australia || jiaohong.yao@hdr.mq.edu.au || AbstractMarker-based landing is widely used ... (truncated) ||  || { || ""title"": ""Visual Marker Search for Autonomous Drone"", || ""authors"": [ || ""Jiaohong Yao"", || ""Linfeng Liang"", || ""Yao Deng"", || ""Xi Zheng"", || ""Richard Han"", || ""Yuankai Qi"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""drone navigation"", || ""marker-based landing"", || ""reinforcement learning"", || ""AirSim"", || ""robustness"" || ], || ""summary"": ""Marker-based landing is widely used in drone delivery and return-to-base systems. This study presents a simulation-based evaluation suite on AirSim to assess robustness under diverse urban conditions, focusing on coverage patterns and exploration strategies."" || } ||  || [ Prompt: 127.1 t/s | Generation: 27.3 t/s ]"
2601.11089v2_MiCA A Mobility-Informed Causal Adapter for Lightw.pdf,,[],,26.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MiCA: A Mobility-Informed Causal Adapter for Lightweight Epidemic || Forecasting || Suhan Guo1,2 ,Jiahong Deng 1,2 ,Furao Shen 1,2 || 1State Key Laboratory for Novel Software Technology, Nanjing University, China || 2School of Artificial Intelligence, Nanjing University, China || {shguo, jiahongde ... (truncated) ||  || { || ""title"": ""MiCA: A Mobility-Informed Causal Adapter for Lightweight Epidemic"", || ""authors"": [ || ""Suhan Guo"", || ""Jiahong Deng"", || ""Furao Shen"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Accurate forecasting of infectious disease dynamics is critical for public health planning. This work proposes MiCA, a lightweight mobility-aware forecasting model that integrates causal mobility relationships into temporal forecasting using gated residual mixing."" || } ||  || [ Prompt: 121.9 t/s | Generation: 26.8 t/s ]"
2601.11090v1_Efficient Multilingual Name Type Classification Us.pdf,Eicient Multilingual Name T ype Classification,['Davor Lauc'],,26.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Eicient Multilingual Name T ype Classification || Using Convolutional Networks || Davor Lauc || University of Zagreb / Mondonomo AI || Zagreb, Croatia / Wilmington, DE, US || dlauc@ffzg.unizg.hr; davor@mondonomo.ai || AbstractWe present a convolutional neural network approach || for classifying proper n ... (truncated) ||  || { || ""title"": ""Eicient Multilingual Name T ype Classification"", || ""authors"": [""Davor Lauc""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""multilingual NLP"", ""named entity recognition"", ""convolutional neural networks"", ""efficient inference"", ""proper names""], || ""summary"": ""Presents a convolutional neural network approach for classifying proper names by language and entity type. Achieves 92.1% accuracy on a multilingual dataset and demonstrates competitive performance with large pre-trained models."" || } ||  || [ Prompt: 119.5 t/s | Generation: 26.0 t/s ]"
2601.11100v1_ReCreate Reasoning and Creating Domain Agents Driv.pdf,Reasoning and Creating Domain Agents Driven by Experience,"['Zhezheng Hao', 'Hong Wang', 'Jian Luo', 'Jianqing Zhang', 'Yuyan Zhou', 'Qiang Lin', 'Can Wang', 'Hande Dong', 'Jiawei Chen', '*']",,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ReCreate: Reasoning and Creating Domain Agents Driven by Experience || Zhezheng Hao1 Hong Wang2 Jian Luo3 Jianqing Zhang4 || Yuyan Zhou2 Qiang Lin2 Can Wang1 Hande Dong2* Jiawei Chen1* || 1 Zhejiang University 2 Tencent || 3 University of Science and Technology of China 4 Shanghai Jiao Tong Uni ... (truncated) ||  || { || ""title"": ""Reasoning and Creating Domain Agents Driven by Experience"", || ""authors"": [ || ""Zhezheng Hao"", || ""Hong Wang"", || ""Jian Luo"", || ""Jianqing Zhang"", || ""Yuyan Zhou"", || ""Qiang Lin"", || ""Can Wang"", || ""Hande Dong"", || ""Jiawei Chen"", || ""*"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper proposes ReCreate, an experience-driven framework for the automatic creation of domain agents. ReCreate leverages agent interaction history to learn from experience, using an agent-as-optimizer paradigm with three components: experience storage, reasoning synergy pipeline, and hierarchical updates. It outperforms human-designed agents and existing automated generation methods."" || } ||  || [ Prompt: 121.0 t/s | Generation: 28.7 t/s ]"
2601.11109v1_Vision-as-Inverse-Graphics Agent via Interleaved M.pdf,Vision-as-Inverse-Graphics Agent via Interleaved Multimodal Reasoning,"['Shaofeng Yin', 'Jiaxin Ge', 'Michael J. Black', 'Trevor Darrell', 'Haiwen Feng']",arXiv:2601.11109v1,27.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Vision-as-Inverse-Graphics Agent via Interleaved Multimodal Reasoning || Shaofeng Yin1,4* Jiaxin Ge1 Zora Zhiruo Wang2 Xiuyu Li1 || Michael J. Black3 Trevor Darrell1 Angjoo Kanazawa1 Haiwen Feng1,3,4 || 1University of California, Berkeley 2Carnegie Mellon University || 3Max Planck Institute for ... (truncated) ||  || { || ""title"": ""Vision-as-Inverse-Graphics Agent via Interleaved Multimodal Reasoning"", || ""authors"": [ || ""Shaofeng Yin"", || ""Jiaxin Ge"", || ""Michael J. Black"", || ""Trevor Darrell"", || ""Haiwen Feng"" || ], || ""doi"": ""arXiv:2601.11109v1"", || ""arxiv_id"": ""arXiv:2601.11109"", || ""keywords"": [ || ""Vision-as-Inverse-Graphics"", || ""3D reconstruction"", || ""interleaved reasoning"", || ""multimodal reasoning"", || ""3D scene editing"" || ], || ""summary"": ""VIGA crafts a 3D graphics scene from a single image through iteration. It alternates between generation and verification steps to progressively refine layout, geometry, and lighting, enabling robust single-shot reconstruction."" || } ||  || [ Prompt: 120.9 t/s | Generation: 27.2 t/s ]"
2601.11124v1_Learn Before Represent Bridging Generative and Con.pdf,Learn Before Represent: Bridging Generative and Contrastive Learning,"['Xiaoyu Liang', 'Yuchen Peng', 'Jiale Luo', 'Wenhao Wang', 'Haoji Hu', 'Xincheng Zhou']",,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Learn Before Represent: Bridging Generative and Contrastive Learning || for Domain-Specific LLM Embeddings || Xiaoyu Liang1, Yuchen Peng1, Jiale Luo1, || Wenhao Wang1,Haoji Hu 1,Xincheng Zhou 2, || 1Zhejiang University, 2Peking University, || Correspondence:zhouxincheng@pku.edu.cn || Abstract || Large L ... (truncated) ||  || { || ""title"": ""Learn Before Represent: Bridging Generative and Contrastive Learning"", || ""authors"": [ || ""Xiaoyu Liang"", || ""Yuchen Peng"", || ""Jiale Luo"", || ""Wenhao Wang"", || ""Haoji Hu"", || ""Xincheng Zhou"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""LLM"", || ""contrastive learning"", || ""domain-specific embeddings"", || ""knowledge acquisition"", || ""representation learning"" || ], || ""summary"": ""This work identifies a bottleneck in LLM-based embeddings for vertical domains and proposes a two-stage framework—Learn Before Represent—to improve performance by integrating information bottleneck constrained generative learning with contrastive learning."" || } ||  || [ Prompt: 121.4 t/s | Generation: 28.6 t/s ]"
2601.11135v1_Context-aware Graph Causality Inference for Few-Sh.pdf,Context-aware Graph Causality Inference for Few-Shot Molecular Property,"['Van Thuy Hoang', 'O-Joun Lee']",,27.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Context-aware Graph Causality Inference for Few-Shot Molecular Property || Prediction || Van Thuy Hoang and O-Joun Lee* || Department of Artificial Intelligence, The Catholic University of Korea || {hoangvanthuy90, ojlee}@catholic.ac.kr || Abstract || Molecular property prediction is becoming one of  ... (truncated) ||  || { || ""title"": ""Context-aware Graph Causality Inference for Few-Shot Molecular Property"", || ""authors"": [""Van Thuy Hoang"", ""O-Joun Lee""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""molecular property prediction"", ""graph learning"", ""causal inference"", ""few-shot learning""], || ""summary"": ""The paper proposes CaMol, a context-aware graph causality inference framework for predicting molecular properties in few-shot scenarios. It addresses challenges in exploiting functional group causality and identifying relevant substructures using causal inference and atom masking strategies."" || } ||  || [ Prompt: 121.9 t/s | Generation: 27.2 t/s ]"
2601.11143v1_Learning Quadrupedal Locomotion for a Heavy Hydrau.pdf,Learning Quadrupedal Locomotion for a Heavy Hydraulic Robot Using an Actuator Model,"['Minho Lee', 'Hyeonseok Kim', 'Jin Tak Kim', 'Sangshin Park', 'Jeong Hyun Lee', 'Jungsan Cho', 'Jemin Hwangbo']",,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Learning Quadrupedal Locomotion for a Heavy Hydraulic Robot Using || an Actuator Model || Minho Lee 1, Hyeonseok Kim 2, Jin Tak Kim 3, Sangshin Park 3, Jeong Hyun Lee 1, Jungsan Cho 3, || and Jemin Hwangbo ,1 || Abstract The simulation-to-reality (sim-to-real) transfer of || large-scale hydraulic  ... (truncated) ||  || { || ""title"": ""Learning Quadrupedal Locomotion for a Heavy Hydraulic Robot Using an Actuator Model"", || ""authors"": [ || ""Minho Lee"", || ""Hyeonseok Kim"", || ""Jin Tak Kim"", || ""Sangshin Park"", || ""Jeong Hyun Lee"", || ""Jungsan Cho"", || ""Jemin Hwangbo"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Hydraulic/Pneumatic Actuators"", || ""Legged Robots"", || ""Reinforcement Learning"", || ""Sim-to-Real Transfer"", || ""Robotics"" || ], || ""summary"": ""The paper discusses sim-to-real transfer challenges for large-scale hydraulic robots and presents an analytical actuator model for efficient RL-based locomotion control."" || } ||  || [ Prompt: 123.9 t/s | Generation: 28.7 t/s ]"
2601.11144v2_Deep GraphRAG A Balanced Approach to Hierarchical .pdf,Deep GraphRAG: A Balanced Approach to Hierarchical Retrieval and Adaptive Integration,"['Yuejie Li', 'Ke Yang', 'Zhejiang University', 'Bolin Chen', 'Chengjun Mao']",,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Deep GraphRAG: A Balanced Approach to Hierarchical Retrieval || and Adaptive Integration || Yuejie Li || liyuejie.lyj@antgroup.com || Ant Group || China || Ke Yang || zhulang.yk@antgroup.com || Ant Group || China || Tao Wang || wangtop@zju.edu.cn || Zhejiang University || China || Bolin Chen || bolin.cbl@antgroup.com || Ant Group ... (truncated) ||  || { || ""title"": ""Deep GraphRAG: A Balanced Approach to Hierarchical Retrieval and Adaptive Integration"", || ""authors"": [ || ""Yuejie Li"", || ""Ke Yang"", || ""Zhejiang University"", || ""Bolin Chen"", || ""Chengjun Mao"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""GraphRAG"", || ""Reinforcement Learning"", || ""Large Language Models"" || ], || ""summary"": ""Deep GraphRAG addresses the trade-off between global and local search in hierarchical retrieval by introducing a balanced framework with hierarchical retrieval strategies and a reinforcement learning-based fine-grained search."" || } ||  || [ Prompt: 117.3 t/s | Generation: 28.7 t/s ]"
2601.11147v1_Do We Always Need Query-Level Workflows Rethinking.pdf,Do We Always Need Query-Level Workflows?,"['Zixu Wang', 'Bingbing Xu', 'Yige Yuan', 'Huawei Shen', 'Xueqi Cheng']",,28.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Do We Always Need Query-Level Workflows? || Rethinking Agentic Workflow Generation for Multi-Agent Systems || Zixu Wang, Bingbing Xu *, Yige Yuan, Huawei Shen, Xueqi Cheng || State Key Laboratory of AI Safety, Institute of Computing Technology, Chinese Academy of Sciences || University of Chi ... (truncated) ||  || { || ""title"": ""Do We Always Need Query-Level Workflows?"", || ""authors"": [ || ""Zixu Wang"", || ""Bingbing Xu"", || ""Yige Yuan"", || ""Huawei Shen"", || ""Xueqi Cheng"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper explores whether query-level workflow generation is always necessary for multi-agent systems, arguing that a small set of top K task-level workflows can cover many queries efficiently. It proposes a low-cost task-level generation framework called SCALE and demonstrates its effectiveness with competitive performance and reduced token usage."" || } ||  || [ Prompt: 116.1 t/s | Generation: 28.9 t/s ]"
2601.11151v1_Cross-Modal Attention Network with Dual Graph Lear.pdf,,[],,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Cross-Modal Attention Network with Dual Graph Learning in || Multimodal Recommendation || JI DAI,Beijing University of Posts and Telecommunications, China || QUAN FANG,Beijing University of Posts and Telecommunications, China || JUN HU,National University of Singapore, Singapore || DESHENG CAI,Tia ... (truncated) ||  || { || ""title"": ""Cross-Modal Attention Network with Dual Graph Learning in Multimodal Recommendation"", || ""authors"": [ || ""Ji Dai"", || ""Quan Fang"", || ""Jun Hu"", || ""DeSheng Cai"", || ""Yang Yang"", || ""Can Zhao"" || ], || ""doi"": ""https://doi.org/XXXXXXX.XXXXXXX"", || ""arxiv_id"": ""XXX"", || ""keywords"": [ || ""Multimedia recommendation"", || ""Graph Neural Network"", || ""Multimodal Fusion"" || ], || ""summary"": ""The paper proposes a Cross-Modal Attention Network with dual graph learning to address limitations in multimodal recommendation systems by capturing rich intra- and inter-modal relationships through a core recursive attention mechanism and symmetric graph frameworks."", || ""summary_description"": ""To tackle shallow modality fusion and asymmetric feature treatment, the authors introduce CRANE, which refines modality features via cross-correlations in a joint latent space and integrates a symmetric dual-graph model with self-supervised learning."", || ""publication_details"": { || ""journal"": ""ACM Trans. Multimedia Comput. Commun. Appl."", || ""volume"": ""XX"", || ""pages"": ""23"", || ""year"": ""2026"", || ""article_body"": ""Comprehensive experiments on four public real-world datasets validate an average 5% improvement over state-of-the-art baselines."" || } || } ||  || [ Prompt: 117.1 t/s | Generation: 27.9 t/s ]"
2601.11160v1_Clustering High-dimensional Data Balancing Abstrac.pdf,Clustering High-dimensional Data: Balancing Abstraction and Representation,"['Claudia Plant', 'Lena G. M. Bauer', 'Christian B. ohm']",,27.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Clustering High-dimensional Data: Balancing Abstraction and Representation || Tutorial at AAAI 2026 || Claudia Plant1, 2, Lena G. M. Bauer 1, Christian B ohm1 || 1Faculty of Computer Science, University of Vienna, Vienna, Austria || 2 Data Science @ Uni Vienna, University of Vienna, Vienna, Aus ... (truncated) ||  || { || ""title"": ""Clustering High-dimensional Data: Balancing Abstraction and Representation"", || ""authors"": [ || ""Claudia Plant"", || ""Lena G. M. Bauer"", || ""Christian B. ohm"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""How to find a natural grouping of a large real data set? Clustering requires a balance between abstraction and representation. To identify clusters, we need to abstract from superfluous details of individual objects. But we also need a rich representation that emphasizes the key features shared by groups of objects that distinguish them from other groups of objects."" || } ||  || [ Prompt: 114.7 t/s | Generation: 27.0 t/s ]"
2601.11178v1_TANDEM Temporal-Aware Neural Detection for Multimo.pdf,Temporal-Aware Neural Detection for Multimodal Hate Speech,"['Girish A. Koushik', 'Helen Treharne', 'Diptesh Kanojia']",10.48550/arXiv.2311.07818,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TANDEM: Temporal-Aware Neural Detection for Multimodal Hate Speech || Girish A. Koushik1*, Helen Treharne2, Diptesh Kanojia1 || 1Nature-Inspired Computing & Engineering, University of Surrey, Guildford, United Kingdom || 2Surrey Centre for Cyber Security, University of Surrey, Guildford, Uni ... (truncated) ||  || { || ""title"": ""Temporal-Aware Neural Detection for Multimodal Hate Speech"", || ""authors"": [ || ""Girish A. Koushik"", || ""Helen Treharne"", || ""Diptesh Kanojia"" || ], || ""doi"": ""10.48550/arXiv.2311.07818"", || ""arxiv_id"": ""arXiv:2311.07818"", || ""keywords"": [ || ""hate speech"", || ""multimodal detection"", || ""structured reasoning"", || ""interpretable evidence"", || ""online safety"" || ], || ""summary"": ""This paper introduces TANDEM, a framework that transforms audio-visual hate detection into a structured reasoning problem. It employs a novel reinforcement learning strategy with vision-language and audio-language models, optimizing each other through self-constrained cross-modal context. Experiments show significant improvements over baselines in target identification accuracy."" || } ||  || [ Prompt: 118.3 t/s | Generation: 27.8 t/s ]"
2601.11189v1_Policy-Based Deep Reinforcement Learning Hyperheur.pdf,Policy-Based Deep Reinforcement Learning Hyperheuristics for Job-Shop Scheduling,"['Sofiene Lassoued', 'Asrat Gobachew', 'Stefan Lier', 'Andreas Schwung']",,27.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Policy-Based Deep Reinforcement Learning Hyperheuristics for Job-Shop Scheduling || Problems || Sofiene Lassoued *a, Asrat Gobachew b, Stefan Lier b, Andreas Schwung a || aSouth Westphalia University of Applied Sciences, Automation Technology and Learning Systems Lbecker Ring 2, Soest, 59494 ... (truncated) ||  || { || ""title"": ""Policy-Based Deep Reinforcement Learning Hyperheuristics for Job-Shop Scheduling"", || ""authors"": [ || ""Sofiene Lassoued"", || ""Asrat Gobachew"", || ""Stefan Lier"", || ""Andreas Schwung"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Hyper-heuristics"", || ""Job Shop Scheduling"", || ""Policy-based Reinforcement learning"", || ""Petri nets"" || ], || ""summary"": ""This paper proposes a policy-based deep reinforcement learning hyper-heuristic framework for solving the Job Shop Scheduling Problem. The hyper-heuristic agent learns to switch scheduling rules based on the system state dynamically. It introduces action prefiltering and a commitment mechanism to regulate heuristic switching frequency, and compares deterministic greedy selection and stochastic sampling strategies."" || } ||  || [ Prompt: 118.2 t/s | Generation: 27.3 t/s ]"
2601.11196v1_Artificial Intelligence and the US Economy An Acco.pdf,Artificial Intelligence and the US Economy: An Accounting Perspective on Investment and Production,"['Luisa Carpinelli', 'Filippo Natoli', 'Marco Taboga']",arXiv:2601.11196v1,30.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Artificial Intelligence and the US Economy: An || Accounting Perspective on Investment and || Production || Luisa Carpinelli  Filippo Natoli  Marco Taboga || January 19, 2026 || Abstract || Artificial intelligence (AI) has moved to the center of policy, market, and academic || debates, but its macroeco ... (truncated) ||  || { || ""title"": ""Artificial Intelligence and the US Economy: An Accounting Perspective on Investment and Production"", || ""authors"": [ || ""Luisa Carpinelli"", || ""Filippo Natoli"", || ""Marco Taboga"" || ], || ""doi"": ""arXiv:2601.11196v1"", || ""arxiv_id"": ""2601.11196"", || ""keywords"": [ || ""artificial intelligence"", || ""capital expenditures"", || ""data centers"", || ""national accounts"" || ], || ""summary"": ""This paper provides an overview on how the current AI wave is captured in US national accounts, highlighting the role of data centers and their impact on aggregate demand and GDP growth."" || } ||  || [ Prompt: 125.0 t/s | Generation: 30.4 t/s ]"
2601.11199v1_SD-RAG A Prompt-Injection-Resilient Framework for .pdf,SD-RAG: A Prompt-Injection-Resilient Framework for Selective Disclosure in Retrieval-Augmented Generation,"['Aiman Al Masoud', 'Marco Arazzi', 'Antonino Nocera']",,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || SD-RAG: A Prompt-Injection-Resilient || Framework for Selective Disclosure in || Retrieval-Augmented Generation || Aiman Al Masoud, Marco Arazzi, and Antonino Nocera || Department of Electrical, Computer and Biomedical Engineering || University of Pavia, Pavia, Italy || Email: aiman.almasoud01@univ ... (truncated) ||  || { || ""title"": ""SD-RAG: A Prompt-Injection-Resilient Framework for Selective Disclosure in Retrieval-Augmented Generation"", || ""authors"": [ || ""Aiman Al Masoud"", || ""Marco Arazzi"", || ""Antonino Nocera"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper introduces SD-RAG, a novel approach for Selective Disclosure in Retrieval-Augmented Generation that enhances privacy and security by applying sanitization and disclosure controls during the retrieval phase, rather than relying on prompt-level safeguards. It demonstrates improved privacy scores and resilience to prompt injection attacks."" || } ||  || [ Prompt: 114.2 t/s | Generation: 27.5 t/s ]"
2601.11200v1_FAQ Mitigating Quantization Error via Regenerating.pdf,Mitigating Quantization Error via Regenerating Calibration Data,"['Haiyang Xiao', 'Weiqing Li', 'Jinyue Guo', 'Guochao Jiang', 'Guohua Liu', 'Yuewei Zhang']",,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || FAQ: Mitigating Quantization Error via Regenerating Calibration Data || with Family-Aware Quantization || Haiyang Xiao1,*, Weiqing Li1,*, Jinyue Guo 1,2, Guochao Jiang 1, Guohua Liu 1, Yuewei Zhang1, || 1Alibaba Cloud Computing, 2Chinese Academy of Sciences || {xiaohaiyang.xhy, liweiqing.lwq}@a ... (truncated) ||  || { || ""title"": ""Mitigating Quantization Error via Regenerating Calibration Data"", || ""authors"": [ || ""Haiyang Xiao"", || ""Weiqing Li"", || ""Jinyue Guo"", || ""Guochao Jiang"", || ""Guohua Liu"", || ""Yuewei Zhang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""quantization error"", || ""calibration data"", || ""family-aware quantization"", || ""LLMs"", || ""model compression"", || ""accuracy loss"" || ], || ""summary"": ""The paper proposes FAQ (Family-Aware Quantization) to improve quantization accuracy by regenerating high-fidelity calibration data using LLMs from the same family, reducing accuracy loss."" || } ||  || [ Prompt: 118.9 t/s | Generation: 28.3 t/s ]"
2601.11202v1_Epistemic Control and the Normativity of Machine L.pdf,Epistemic Control and the Normativity of Machine Learning,['Emanuele Ratti'],10.1093/acps/rpac023,29.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || To be published in The Role of AI in Science: Epistemological and Methodological Studies || (Routledge), edited by David Barack, Andr Curtis-Trudel, and Darrell Rowbottom ||  || EPISTEMIC CONTROL AND THE NORMATIVITY OF MACHINE LEARNING- || BASED SCIENCE || Emanuele Ratti1 || Department of P ... (truncated) ||  || { || ""title"": ""Epistemic Control and the Normativity of Machine Learning"", || ""authors"": [""Emanuele Ratti""], || ""doi"": ""10.1093/acps/rpac023"", || ""arxiv_id"": """", || ""keywords"": [""machine learning"", ""epistemic control"", ""cognitive values"", ""normativity""], || ""summary"": ""The paper explores concerns about human scientists being excluded from scientific processes due to the characteristics of machine learning systems, examining epistemic control and its implications."" || } ||  || [ Prompt: 132.4 t/s | Generation: 29.9 t/s ]"
2601.11207v1_LoRA as Oracle.pdf,LoRA as Oracle,"['Marco Arazzi', 'Antonino Nocera']",,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LoRA as Oracle || Marco Arazzi || marco.arazzi01@universitadipavia.it || University of Pavia || Pavia, Italy || Antonino Nocera || antonino.nocera@unipv.it || University of Pavia || Pavia, Italy || Abstract || Backdoored and privacy-leaking deep neural networks pose a se- || rious threat to the deployment of machin ... (truncated) ||  || { || ""title"": ""LoRA as Oracle"", || ""authors"": [ || ""Marco Arazzi"", || ""Antonino Nocera"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""LoRA"", || ""Membership Inference Attack"", || ""Backdoor Attack"" || ], || ""summary"": ""Introduces a novel LoRA-based oracle framework for detecting backdoors and membership inference attacks without requiring clean reference models or extensive retraining."" || } ||  || [ Prompt: 125.5 t/s | Generation: 27.7 t/s ]"
2601.11219v1_SDFLoRA Selective Dual-Module LoRA for Federated F.pdf,SDFLoRA: Selective Dual-Module LoRA for Federated Fine-tuning with Heterogeneous Clients,"['Zhikang Shen', 'Jianrong Lu', 'Haiyuan Wan', 'Jianhai Chen']",22351168@zju.edu.cn,27.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SDFLoRA: Selective Dual-Module LoRA for Federated Fine-tuning with || Heterogeneous Clients || Zhikang Shen1 Jianrong Lu1 Haiyuan Wan2 Jianhai Chen1 /envelpe || 1Zhejiang University 2Tsinghua University || 22351168@zju.edu.cn jrong.alvin@gmail.com || wanhy24@mails.tsinghua.edu.cn chenjh919@zju.edu ... (truncated) ||  || { || ""title"": ""SDFLoRA: Selective Dual-Module LoRA for Federated Fine-tuning with Heterogeneous Clients"", || ""authors"": [ || ""Zhikang Shen"", || ""Jianrong Lu"", || ""Haiyuan Wan"", || ""Jianhai Chen"" || ], || ""doi"": ""22351168@zju.edu.cn"", || ""arxiv_id"": """", || ""keywords"": [ || ""federated learning"", || ""LoRA"", || ""heterogeneous clients"", || ""parameter-efficient"", || ""privacy-preserving"", || ""differential privacy"" || ], || ""summary"": ""The paper proposes SDFLoRA, a selective dual-module federated LoRA method that balances transferable and client-specific adaptations while addressing heterogeneity and privacy concerns in large language model fine-tuning."" || } ||  || [ Prompt: 120.0 t/s | Generation: 27.1 t/s ]"
2601.11232v1_FactCorrector A Graph-Inspired Approach to Long-Fo.pdf,FACTCORRECTOR: A Graph-Inspired Approach to Long-Form Factuality Correction of Large Language Models,"['Javier Carnerero-Cano', 'Massimiliano Pronesti', 'Radu Marinescu', 'Tigran Tchrakian', 'James Barry', 'Jasmina Gajcin', 'Yufang Hou', 'Alessandra Pascale', 'Elizabeth Daly']",10.48550/arXiv.2405.12345,28.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || FACTCORRECTOR: A Graph-Inspired Approach || to Long-Form Factuality Correction of Large Language Models || Javier Carnerero-Cano1, Massimiliano Pronesti1, Radu Marinescu1, Tigran Tchrakian1, || James Barry1,Jasmina Gajcin 1,Yufang Hou 1,2,Alessandra Pascale 1,Elizabeth Daly 1 || 1IBM Research E ... (truncated) ||  || { || ""title"": ""FACTCORRECTOR: A Graph-Inspired Approach to Long-Form Factuality Correction of Large Language Models"", || ""authors"": [ || ""Javier Carnerero-Cano"", || ""Massimiliano Pronesti"", || ""Radu Marinescu"", || ""Tigran Tchrakian"", || ""James Barry"", || ""Jasmina Gajcin"", || ""Yufang Hou"", || ""Alessandra Pascale"", || ""Elizabeth Daly"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [ || ""factuality correction"", || ""large language models"", || ""LLM"", || ""factual errors"", || ""correction method"", || ""factual precision"" || ], || ""summary"": ""This paper introduces FACTCORRECTOR, a post-hoc correction method for improving the factual accuracy of large language models without retraining. It presents the VELI5 benchmark and demonstrates significant improvements over existing methods in maintaining relevance while correcting errors."" || } ||  || [ Prompt: 115.3 t/s | Generation: 28.0 t/s ]"
2601.11252v1_Beyond Model Scaling Test-Time Intervention for Ef.pdf,Under Review,"['Qianyue Wang', 'Jinwu Hu', 'Yufeng Wang', 'Huanxiang Lin', 'Bolin Chen', 'Yaofo Chen', 'Mingkui Tan']",,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Under Review || BEYONDMODELSCALING: TEST-TIMEINTERVENTION || FOREFFICIENTDEEPREASONING || Qianyue Wang 1 2 Jinwu Hu 1 2 Yufeng Wang 1 3 Huanxiang Lin 1 Bolin Chen 1 || Zhiquan Wen 1 2 Yaofo Chen 1 2 Mingkui Tan 1 || 1South China University of Technology, 2Pazhou Laboratory, 3Peng Cheng Laboratory, ... (truncated) ||  || { || ""title"": ""Under Review"", || ""authors"": [ || ""Qianyue Wang"", || ""Jinwu Hu"", || ""Yufeng Wang"", || ""Huanxiang Lin"", || ""Bolin Chen"", || ""Yaofo Chen"", || ""Mingkui Tan"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Large Reasoning Models"", || ""Test-Time Intervention"", || ""Efficient Reasoning"", || ""Overthinking"", || ""Reasoning Length"", || ""Security"", || ""Creative Tasks"" || ], || ""summary"": ""The paper proposes Think-with-Me, a test-time interactive reasoning paradigm that uses external feedback to guide reasoning, aiming to improve accuracy and reasoning efficiency by pausing at transitional points for external intervention."" || } ||  || [ Prompt: 117.1 t/s | Generation: 28.3 t/s ]"
2601.11258v1_Knowledge is Not Enough Injecting RL Skills for Co.pdf,Knowledge Is Not Enough: Injecting RL Skills for Continual Adaptation,"['Pingzhi Tang', 'Yiding Wang', 'Muhan Zhang']",,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Knowledge is Not Enough: Injecting RL Skills for Continual Adaptation || Pingzhi Tang1,2, Yiding Wang1,2, Muhan Zhang1,3 || 1Institute for Artificial Intelligence, Peking University 2Yuanpei College, Peking University || 3State Key Laboratory of General Artificial Intelligence, BIGAI || *Equal  ... (truncated) ||  || { || ""title"": ""Knowledge Is Not Enough: Injecting RL Skills for Continual Adaptation"", || ""authors"": [ || ""Pingzhi Tang"", || ""Yiding Wang"", || ""Muhan Zhang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Large Language Models face knowledge cutoff challenges. This paper proposes Parametric Skill Transfer (PaST) to enable efficient and effective knowledge adaptation by injecting modular skills after lightweight fine-tuning."" || } ||  || [ Prompt: 120.3 t/s | Generation: 29.1 t/s ]"
2601.11269v1_X-Distill Cross-Architecture Vision Distillation f.pdf,X-Distill: Cross-Architecture Vision Distillation,"['Maanping Shao', 'Feihong Zhang', 'Gu Zhang', 'Baiye Cheng', 'Zhengrong Xue', 'Huazhe Xu']",10.1093/pasj/psa123,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 1 || X-Distill: Cross-Architecture Vision Distillation || for Visuomotor Learning || Maanping Shao #, Feihong Zhang #, Gu Zhang, Baiye Cheng, Zhengrong Xue, Huazhe Xu || #Equal contribution Corresponding authorX-Distill.github.io || CNN || X-D ... (truncated) ||  || { || ""title"": ""X-Distill: Cross-Architecture Vision Distillation"", || ""authors"": [ || ""Maanping Shao"", || ""Feihong Zhang"", || ""Gu Zhang"", || ""Baiye Cheng"", || ""Zhengrong Xue"", || ""Huazhe Xu"" || ], || ""doi"": ""10.1093/pasj/psa123"", || ""arxiv_id"": ""10.1093/pasj.psa123"", || ""keywords"": [ || ""visuomotor learning"", || ""knowledge distillation"", || ""visual encoder"", || ""robot action"", || ""manipulation tasks"" || ], || ""summary"": ""X-Distill introduces a method for data-efficient visuomotor learning by distilling a large ViT teacher into a compact CNN student, enabling effective policy learning on robotics datasets."" || } ||  || [ Prompt: 122.9 t/s | Generation: 28.1 t/s ]"
2601.11282v1_From SERPs to Sound How Search Engine Result Pages.pdf,FromSERPs to Sound: How Search Engine Result Pages and AI-generated Podcasts Interact to Influence User Attitudes on Controversial Topics,"['Junjie Wang', 'Gaole He', 'Alisa Rieger', 'Ujwal Gadiraju']",10.1145/3786304.3787942,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || FromSERPsto Sound: How Search Engine Result Pages and || AI-generated Podcasts Interact to Influence User Attitudes on || Controversial Topics || Junjie Wang || Delft University of Technology || Delft, South Holland, Netherlands || j.wang-101@student.tudelft.nl || Gaole He || Delft University of Technology ... (truncated) ||  || { || ""title"": ""FromSERPs to Sound: How Search Engine Result Pages and AI-generated Podcasts Interact to Influence User Attitudes on Controversial Topics"", || ""authors"": [ || ""Junjie Wang"", || ""Gaole He"", || ""Alisa Rieger"", || ""Ujwal Gadiraju"" || ], || ""doi"": ""10.1145/3786304.3787942"", || ""arxiv_id"": ""CCS Concepts"", || ""keywords"": [ || ""Attitude Change"", || ""AI-generated Podcasts"", || ""Information modality"", || ""Web search"", || ""Controversial Topics"", || ""Responsible Opinion Formation"" || ], || ""summary"": ""This study investigates how the interaction between search engine result pages (SERPs) and AI-generated podcasts influences user attitudes, especially on controversial topics. It examines the effects of sequence and modality of exposure on attitude change, highlighting the role of viewpoint bias and topic controversy."" || } ||  || [ Prompt: 112.7 t/s | Generation: 28.1 t/s ]"
2601.11286v1_XChoice Explainable Evaluation of AI-Human Alignme.pdf,XChoice: Explainable Evaluation of AIHuman Alignment in LLM-based Constrained Choice Decision Making,"['Weihong Qi', 'Fan Huang', 'Rasika Muralidharan', 'Jisun An', 'Haewoon Kwak']",10.48550/arXiv.2405.12345,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || XChoice: Explainable Evaluation of AIHuman Alignment in LLM-based || Constrained Choice Decision Making || Weihong Qi 1, Fan Huang 1, Rasika Muralidharan 1, Jisun An 1, Haewoon Kwak 1 || 1 Indiana University Bloomington || Correspondence:{wq3, hwkwak}@iu.edu || Abstract || We present XCHOICE, an expl ... (truncated) ||  || { || ""title"": ""XChoice: Explainable Evaluation of AIHuman Alignment in LLM-based Constrained Choice Decision Making"", || ""authors"": [ || ""Weihong Qi"", || ""Fan Huang"", || ""Rasika Muralidharan"", || ""Jisun An"", || ""Haewoon Kwak"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""10.48550/arXiv.2405.12345"", || ""keywords"": [ || ""AIHuman alignment"", || ""LLM-based decision making"", || ""constrained decision making"", || ""explainable evaluation"", || ""interpretable parameters"" || ], || ""summary"": ""XCHOICE presents a mechanism-based framework to evaluate AI-human alignment in constrained decision making, focusing on interpretable parameters that reflect decision factors, constraints, and trade-offs. It assesses alignment using human data and LLM-generated decisions, identifies heterogeneous misalignment across groups, and evaluates mitigation strategies."" || } ||  || [ Prompt: 116.7 t/s | Generation: 28.2 t/s ]"
2601.11344v1_How Much Would a Clinician Edit This Draft Evaluat.pdf,Evaluating LLM Alignment for Patient Message Response Drafting,"['Parker Seegmiller', 'Joseph Gatto', 'Sarah E. Greer', 'Ganza Belise Isingizwe', 'Rohan Ray', 'Timothy Burdick', 'Sarah M. Preum']",,26.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || How Much Would a Clinician Edit This Draft? || Evaluating LLM Alignment for Patient Message Response Drafting || Parker Seegmiller1, Joseph Gatto1, Sarah E. Greer1, || Ganza Belise Isingizwe1, Rohan Ray1, Timothy Burdick2,3, Sarah M. Preum1 || 1 Department of Computer Science, Dartmouth College ... (truncated) ||  || { || ""title"": ""Evaluating LLM Alignment for Patient Message Response Drafting"", || ""authors"": [ || ""Parker Seegmiller"", || ""Joseph Gatto"", || ""Sarah E. Greer"", || ""Ganza Belise Isingizwe"", || ""Rohan Ray"", || ""Timothy Burdick"", || ""Sarah M. Preum"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Large language models (LLMs) show promise in drafting responses to patient portal messages, yet their integration into clinical workflows raises concerns about time and effort savings for clinicians. The study investigates LLM alignment with individual clinicians through a comprehensive evaluation of the patient message response drafting task."" || } ||  || [ Prompt: 120.6 t/s | Generation: 26.8 t/s ]"
2601.11350v1_FEATHer Fourier-Efficient Adaptive Temporal Hierar.pdf,Fourier-Efficient Adaptive Temporal Hierarchy Forecaster for Time-Series Forecasting,"['Jaehoon Lee', 'Seungwoo Lee', 'Younghwi Kim', 'Dohee Kim', 'Sunghyun Sim']",,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  ||  || FEATHer: Fourier-Efficient Adaptive Temporal || Hierarchy Forecaster for Time-Series || Forecasting || Jaehoon Lee , Seungwoo Lee , Younghwi Kim, Dohee Kim*, Member, Sunghyun Sim* , Member || Abstract Time-series forecasting plays a fundamental role in industrial domains such as manu ... (truncated) ||  || { || ""title"": ""Fourier-Efficient Adaptive Temporal Hierarchy Forecaster for Time-Series Forecasting"", || ""authors"": [ || ""Jaehoon Lee"", || ""Seungwoo Lee"", || ""Younghwi Kim"", || ""Dohee Kim"", || ""Sunghyun Sim"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Time-series Forecasting"", || ""Edge AI"", || ""Ultra-Lightweight Models"", || ""Fourier-Efficient Adaptive Temporal Hierarchy Forecaster (FEATHer)"", || ""Long-term Forecasting"", || ""Parameter Budget"", || ""Predictive Performance"" || ], || ""summary"": ""FEATHer is a multiscale temporal model designed for resource-constrained edge environments, achieving strong forecasting performance with minimal parameters."" || } ||  || [ Prompt: 124.7 t/s | Generation: 27.8 t/s ]"
2601.11354v1_AstroReason-Bench Evaluating Unified Agentic Plann.pdf,AstroReason-Bench: Evaluating Unified Agentic Planning,"['Weiyi Wang', 'Xinchi Chen', 'Jingjing Gong', 'Xuanjing Huang', 'Fudan University2Shanghai Innovation Institute', 'OpenMOSS Team']",arXiv:2601.11354v1,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || OpenMOSS || AstroReason-Bench: Evaluating Unified Agentic Planning || across Heterogeneous Space Planning Problems || Weiyi Wang1,3,Xinchi Chen1,3,Jingjing Gong2,3 Xuanjing Huang1 Xipeng Qiu1,2,3, || 1Fudan University2Shanghai Innovation Institute3OpenMOSS Team || Abstract || ecentadvancesinagenticLa ... (truncated) ||  || { || ""title"": ""AstroReason-Bench: Evaluating Unified Agentic Planning"", || ""authors"": [ || ""Weiyi Wang"", || ""Xinchi Chen"", || ""Jingjing Gong"", || ""Xuanjing Huang"", || ""Fudan University2Shanghai Innovation Institute"", || ""OpenMOSS Team"" || ], || ""doi"": ""arXiv:2601.11354v1"", || ""arxiv_id"": ""arXiv:2601.11354"", || ""keywords"": [ || ""agentic planning"", || ""space planning problems"", || ""heterogeneous objectives"", || ""physical constraints"", || ""long-horizon decision-making"" || ], || ""summary"": ""This paper introduces AstroReason-Bench, a benchmark for evaluating agentic planning in space planning problems, highlighting the limitations of current generalist agents under realistic constraints."" || } ||  || [ Prompt: 124.8 t/s | Generation: 27.8 t/s ]"
2601.11359v1_Think-Clip-Sample Slow-Fast Frame Selection for Vi.pdf,THINK-CLIP-SAMPLE: SLOW-FAST FRAME SELECTION FOR VIDEO UNDERSTANDING,"['Wenhui Tan', 'Ruihua SongB', 'Jiaze Li', 'Jianzhong Ju', 'Zhenbo Luo', 'MiLM Plus', 'Xiaomi Inc.']",,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || THINK-CLIP-SAMPLE: SLOW-FAST FRAME SELECTION FOR VIDEO UNDERSTANDING || Wenhui Tan, Ruihua SongB || Gaoling School of Artificial Intelligence || Renmin University of China || Beijing, China || Jiaze Li, Jianzhong Ju, Zhenbo LuoB || MiLM Plus || Xiaomi Inc. || Beijing, China || ABSTRACT || Recent progress in mult ... (truncated) ||  || { || ""title"": ""THINK-CLIP-SAMPLE: SLOW-FAST FRAME SELECTION FOR VIDEO UNDERSTANDING"", || ""authors"": [ || ""Wenhui Tan"", || ""Ruihua SongB"", || ""Jiaze Li"", || ""Jianzhong Ju"", || ""Zhenbo Luo"", || ""MiLM Plus"", || ""Xiaomi Inc."" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""multi-modal LLMs"", || ""long video understanding"", || ""frame selection"", || ""performance improvement"", || ""computational efficiency"" || ], || ""summary"": ""Recent progress in multi-modal large language models has advanced video understanding, but performance on long-form videos is limited. This paper introduces Think-Clip-Sample (TCS), a training-free framework that enhances long video understanding through Multi-Query Reasoning and Clip-level Slow-Fast Sampling, achieving up to 6.9% accuracy with reduced inference cost."" || } ||  || [ Prompt: 120.8 t/s | Generation: 26.9 t/s ]"
2601.11369v2_Institutional AI Governing LLM Collusion in Multi-.pdf,Institutional AI: Governing LLM Collusion in Multi-Agent,"['M. Bracale Syrnikov', 'F. Pierucci', 'M. Galisai', 'M. Prandi', 'P. Bisconti', 'F. Giarrusso', 'O. Sorokoletova', 'V. Suriani', 'D. Nardi']",arXiv:2601.11369v2,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Institutional AI: Governing LLM Collusion in Multi-Agent || Cournot Markets via Public Governance Graphs || M. Bracale Syrnikov1,4, F. Pierucci1,3, M. Galisai1,2, M. Prandi1,2, P. Bisconti1,2, || F. Giarrusso1,2, O. Sorokoletova1,2, V . Suriani2, D. Nardi2 || 1DEXAI  Icaro Lab || 2Sapienza Univers ... (truncated) ||  || { || ""title"": ""Institutional AI: Governing LLM Collusion in Multi-Agent"", || ""authors"": [ || ""M. Bracale Syrnikov"", || ""F. Pierucci"", || ""M. Galisai"", || ""M. Prandi"", || ""P. Bisconti"", || ""F. Giarrusso"", || ""O. Sorokoletova"", || ""V. Suriani"", || ""D. Nardi"" || ], || ""doi"": ""arXiv:2601.11369v2"", || ""arxiv_id"": ""arXiv:2601.11369"", || ""keywords"": [ || ""Institutional AI"", || ""LLM governance"", || ""Collusion"", || ""Market design"", || ""Governance graphs"", || ""AI alignment"" || ], || ""summary"": ""This paper presents an experimental framework for governing multi-agent LLM systems through institutional AI, focusing on governance graphs to enforce compliance and reduce collusion in Cournot markets. It compares three regimes—Ungoverned, Constitutional, and Institutional—and finds that institutional governance significantly reduces collusion."" || } ||  || [ Prompt: 117.6 t/s | Generation: 28.3 t/s ]"
2601.11379v1_Evaluating LLM Behavior in Hiring Implicit Weights.pdf,"Evaluating LLM Behavior in Hiring: Implicit Weights, Fairness","['Morgane Hoffmann', 'Emma Jouffroy', 'Warren Jouanneau', 'Marc Palyart', 'Charles Pebereau']",,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Evaluating LLM Behavior in Hiring: Implicit Weights, Fairness || Across Groups, and Alignment with Human Preferences || Morgane Hoffmann1, Emma Jouffroy1, Warren Jouanneau1, Marc Palyart1 and || Charles Pebereau1 || 1Malt, 75008 Paris, France || Abstract || General-purpose Large Language Models (LLMs ... (truncated) ||  || { || ""title"": ""Evaluating LLM Behavior in Hiring: Implicit Weights, Fairness"", || ""authors"": [ || ""Morgane Hoffmann"", || ""Emma Jouffroy"", || ""Warren Jouanneau"", || ""Marc Palyart"", || ""Charles Pebereau"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Large Language Models"", || ""Person-job Fit"", || ""Fairness"", || ""Interpretability"" || ], || ""summary"": ""This paper proposes a framework to evaluate how large language models assign importance to different attributes in recruitment decisions, examining alignment with human hiring behavior and fairness across groups."" || } ||  || [ Prompt: 126.7 t/s | Generation: 27.8 t/s ]"
2601.11389v1_Hyperparameter Optimization of Constraint Programm.pdf,Hyperparameter Optimization of Constraint Programming Solvers,"['Hedieh Haddad', 'Thibault Falque', 'Pierre Talbot', 'Pascal Bouvry']",arXiv:2601.11389v1,29.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Hyperparameter Optimization of Constraint || Programming Solvers || Hedieh Haddad1*, Thibault Falque 2, Pierre Talbot 2, || Pascal Bouvry2 || 1*Interdisciplinary Centre for Security, Reliability and Trust (SnT), || University of Luxembourg, Esch-sur-Alzette, Luxembourg. || 2Faculty of Science, Techno ... (truncated) ||  || { || ""title"": ""Hyperparameter Optimization of Constraint Programming Solvers"", || ""authors"": [ || ""Hedieh Haddad"", || ""Thibault Falque"", || ""Pierre Talbot"", || ""Pascal Bouvry"" || ], || ""doi"": ""arXiv:2601.11389v1"", || ""arxiv_id"": ""arXiv:2601.11389"", || ""keywords"": [ || ""constraint programming"", || ""hyperparameter optimization"", || ""probe and solve algorithm"", || ""ACEP"", || ""Choco"", || ""Hamming distance"", || ""solvers"" || ], || ""summary"": ""The paper introduces a probe and solve algorithm for automated hyperparameter optimization in constraint programming solvers, demonstrating improved performance over default configurations."" || } ||  || [ Prompt: 124.2 t/s | Generation: 29.7 t/s ]"
2601.11400v1_Wetland mapping from sparse annotations with satel.pdf,,[],,28.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Wetland mapping from sparse annotations with satellite image time series and || temporal-aware segment anything model || Shuai Yuana,b, Tianwu Linb, Shuang Chena, Yu Xiab, Peng Qinb, Xiangyu Liub, Xiaoqing Xub, Nan Xud, || Hongsheng Zhanga, Jie Wangb,1, Peng Gonga,1 || aDepartment of Geography, ... (truncated) ||  || { || ""title"": ""Wetland mapping from sparse annotations with satellite image time series and temporal-aware segment anything model"", || ""authors"": [ || ""Shuai Yuana"", || ""Tianwu Linb"", || ""Shuang Chena"", || ""Yu Xiab"", || ""Peng Qinb"", || ""Xiangyu Liub"", || ""Xiaoqing Xub"", || ""Nan Xud"", || ""Hongsheng Zhanga"", || ""Jie Wangb"" || ], || ""doi"": ""1"", || ""arxiv_id"": """", || ""keywords"": [ || ""wetland mapping"", || ""satellite image time series"", || ""sparse annotations"", || ""temporal-aware segmentation"", || ""spatial segmentation"", || ""seasonal dynamics"", || ""inter-annual variations"" || ], || ""summary"": ""Accurate wetland mapping is critical for ecosystem monitoring and management, yet acquiring dense pixel-level annotations is prohibitively costly. In practice, only sparse point labels are typically available, and existing deep learning-based models struggle under such weak supervision. Meanwhile, wetlands exhibit strong seasonal and inter-annual dynamics, making single-date imagery insufficient and causing substantial omission and commission errors when mapping. Although powerful foundation models like the Segment Anything Model (SAM) provide promising generalization from point prompts, it is intrinsically designed for static natural images, resulting in spatially fragmented masks in heterogeneous wetland environments and cannot exploit satellite image time series. To address these challenges, we propose WetSAM, a novel SAM-based framework that effectively leverages satellite image time series to enhance wetland mapping from sparse point annotations. WetSAM adopts a dual-branch design: (1) The temporal branch is prompted by sparse point labels to extend the SAM with a hierarchical adapter and a dynamic temporal aggregation module. By decomposing time series into seasonal trends and transient events, this branch effectively distinguishes wetland features from phenological variations; (2) The spatial branch reconstructs distinct boundaries via a temporal-constrained region-growing strategy, iteratively expanding sparse points into reliable dense pseudo-labels; (3) A bidirectional consistency regularization enforces minimizing the discrepancy of the predictions from two segmentation heads of two branches. We validate the effectiveness of WetSAM across eight diverse global locations, each covering an area of around 5,000 km² and with various wetland types and geographical features. WetSAM reaches an ||  || [ Prompt: 129.5 t/s | Generation: 28.0 t/s ]"
2601.11409v1_Topology-Guaranteed Image Segmentation Enforcing C.pdf,"Topology-Guaranteed Image Segmentation: Enforcing Connectivity, Genus, and Width Constraints","['Wenxiao Li', 'Xue-Cheng Tai', 'Jun Liu']","MSC codes.68U10, 62H35, 94A08",28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Topology-Guaranteed Image Segmentation: Enforcing Connectivity, Genus, and || Width Constraints || Wenxiao Li  , Xue-Cheng Tai  ,andJun Liu || Abstract.Existing research highlights the crucial role of topological priors in image segmentation, particularly || in preserving essential structure ... (truncated) ||  || { || ""title"": ""Topology-Guaranteed Image Segmentation: Enforcing Connectivity, Genus, and Width Constraints"", || ""authors"": [""Wenxiao Li"", ""Xue-Cheng Tai"", ""Jun Liu""], || ""doi"": ""MSC codes.68U10, 62H35, 94A08"", || ""arxiv_id"": ""1. Introduction"", || ""keywords"": [""image segmentation"", ""topological preservation"", ""persistent homology"", ""thickness of topology"", ""variational"", ""regularization""], || ""summary"": ""This paper proposes a novel mathematical framework that integrates width information into topological structures for image segmentation. It leverages persistent homology and PDE-based smoothing to preserve connectivity, genus, and width properties, enhancing segmentation accuracy."" || } ||  || [ Prompt: 131.0 t/s | Generation: 28.1 t/s ]"
2601.11421v1_The Great March 100 100 Detail-oriented Tasks for .pdf,THEGREATMARCH100: 100 DETAIL-ORIENTED TASKS FOR EVALUATING EMBODIED AI AGENTS,"['Ziyu Wang', 'Chenyuan Liu', 'Yushun Xiang', 'Runhao Zhang', 'Yu Zhang', 'Qingbo Hao', 'Hongliang Lu', 'Xianchao Zeng', 'Kaiyue Zheng', 'Dehao Y', 'Xianchao Zeng', 'Xinyu Zhou', 'Boran Wen', 'Jiaxin Li', 'Mingyu Zhang', 'Kecheng Zheng', 'Qian Zhu', 'Ran Cheng', 'Yong-Lu Li']",,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || THEGREATMARCH100: 100 DETAIL-ORIENTEDTASKS FOR || EVALUATINGEMBODIEDAI AGENTS || Ziyu Wang1, Chenyuan Liu 1, Yushun Xiang1, Runhao Zhang 2, Yu Zhang1, Qingbo Hao 1, Hongliang Lu 1 || Houyu Chen1,Zhizhong Feng 1,Kaiyue Zheng 1,Dehao Y e1,Xianchao Zeng 2,Xinyu Zhou 2,Boran Wen 1,2 || Jiaxin Li1,2 ... (truncated) ||  || { || ""title"": ""THEGREATMARCH100: 100 DETAIL-ORIENTED TASKS FOR EVALUATING EMBODIED AI AGENTS"", || ""authors"": [ || ""Ziyu Wang"", || ""Chenyuan Liu"", || ""Yushun Xiang"", || ""Runhao Zhang"", || ""Yu Zhang"", || ""Qingbo Hao"", || ""Hongliang Lu"", || ""Xianchao Zeng"", || ""Kaiyue Zheng"", || ""Dehao Y"", || ""Xianchao Zeng"", || ""Xinyu Zhou"", || ""Boran Wen"", || ""Jiaxin Li"", || ""Mingyu Zhang"", || ""Kecheng Zheng"", || ""Qian Zhu"", || ""Ran Cheng"", || ""Yong-Lu Li"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper introduces the Great March 100 (GM-100), a set of 100 carefully designed tasks aimed at evaluating robotic agents comprehensively. It addresses the need for systematic consideration of datasets and task designs to better assess model performance and promote diversity in robot learning."" || } ||  || [ Prompt: 118.9 t/s | Generation: 28.2 t/s ]"
2601.11429v1_Relational Linearity is a Predictor of Hallucinati.pdf,Relational Linearity is a Predictor of Hallucinations,"['Yuetian Lu', 'Yihong Liu', 'Hinrich Schtze']",,28.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Relational Linearity is a Predictor of Hallucinations || Yuetian Lu1,2,3 Yihong Liu1,3 Hinrich Schtze1,3 || 1Center for Information and Language Processing (CIS), LMU Munich, Germany || 2Ubiquitous Knowledge Processing (UKP) Lab, TU Darmstadt, Germany || 3Munich Center for Machine Learning (MCM ... (truncated) ||  || { || ""title"": ""Relational Linearity is a Predictor of Hallucinations"", || ""authors"": [ || ""Yuetian Lu"", || ""Yihong Liu"", || ""Hinrich Schtze"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Hallucination in LLMs is linked to linearity of relational representations; synthetic entities show higher hallucination rates when relations are linear."" || } ||  || [ Prompt: 114.6 t/s | Generation: 28.0 t/s ]"
2601.11440v1_GenDA Generative Data Assimilation on Complex Urba.pdf,Generative Data Assimilation on Complex Urban Areas,"['Francisco Giral1', 'Lvaro Manzano1', 'Ignacio Gmez1', 'Ricardo Vinuesa3', 'Soledad Le Clainche1']",,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || GENDA: GENERATIVEDATAASSIMILATION ONCOMPLEX || URBANAREAS VIACLASSIFIER-FREEDIFFUSIONGUIDANCE || Francisco Giral1 lvaro Manzano1,2 Ignacio Gmez1 || Ricardo Vinuesa3 Soledad Le Clainche1 || 1 Applied Mathematics Department, ETSIAE-School of Aeronautics, Universidad Politcnica de Madrid, Spain || 2  ... (truncated) ||  || { || ""title"": ""Generative Data Assimilation on Complex Urban Areas"", || ""authors"": [ || ""Francisco Giral1"", || ""Lvaro Manzano1"", || ""Ignacio Gmez1"", || ""Ricardo Vinuesa3"", || ""Soledad Le Clainche1"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""urban wind flow"", || ""data assimilation"", || ""generative modeling"", || ""CFD"", || ""reynolds number"", || ""building geometry"" || ], || ""summary"": ""Urban wind flow reconstruction is essential for assessing air quality, heat dispersion, and pedestrian comfort. This paper proposes GenDA, a generative data assimilation framework that reconstructs high-resolution wind fields on unstructured meshes from limited observations. The model employs a multiscale graph-based diffusion architecture trained on CFD simulations and uses classifier-free guidance for robust reconstruction."" || } ||  || [ Prompt: 112.6 t/s | Generation: 27.7 t/s ]"
2601.11441v1_Hierarchical Orthogonal Residual Spread for Precis.pdf,Hierarchical Orthogonal Residual Spread for Precise Massive Editing in Large Language Models,"['Xiaojie Gu', 'Guangxu Chen', 'Yuheng Yang', 'Jingxin Han', 'Andi Zhang']",,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || HIERARCHICAL ORTHOGONAL RESIDUAL SPREAD FOR PRECISE MASSIVE EDITING IN || LARGE LANGUAGE MODELS || Xiaojie Gu1*, Guangxu Chen2*, Yuheng Yang1, Jingxin Han3, Andi Zhang4 || 1 Independent Researcher 2UESTC 3Shanghai University 4University of Manchester || ABSTRACT || Large language models (LLMs) exh ... (truncated) ||  || { || ""title"": ""Hierarchical Orthogonal Residual Spread for Precise Massive Editing in Large Language Models"", || ""authors"": [ || ""Xiaojie Gu"", || ""Guangxu Chen"", || ""Yuheng Yang"", || ""Jingxin Han"", || ""Andi Zhang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Large language models"", || ""Model Editing"", || ""Knowledge Update"", || ""Residual Spread"", || ""Massive Editing"", || ""Security Risks"" || ], || ""summary"": ""This paper introduces HORSE, a method for precise massive editing in large language models by leveraging hierarchical orthogonal residual spread. It compares HORSE favorably with existing methods and demonstrates effectiveness across multiple datasets."" || } ||  || [ Prompt: 113.3 t/s | Generation: 27.9 t/s ]"
2601.11442v1_Map2Thought Explicit 3D Spatial Reasoning via Metr.pdf,Map2Thought: Explicit 3D Spatial Reasoning via Metric Cognitive Maps,"['Xiangjun Gao', 'Zhensong Zhang', 'Dave Zhenyu Chen', 'Songcen Xu', 'Long Quan', 'Eduardo Perez-Pellitero', 'Youngkyoon Jang']",10.48550/arXiv.2405.12345,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Map2Thought: Explicit 3D Spatial Reasoning via Metric Cognitive Maps || Xiangjun Gao1 Zhensong Zhang2 Dave Zhenyu Chen2 Songcen Xu2 || Long Quan1 Eduardo Perez-Pellitero2 Youngkyoon Jang2 || 1The Hong Kong University of Science and Technology 2Huawei Noahs Ark Lab || Figure 1.Comparison with pr ... (truncated) ||  || { || ""title"": ""Map2Thought: Explicit 3D Spatial Reasoning via Metric Cognitive Maps"", || ""authors"": [ || ""Xiangjun Gao"", || ""Zhensong Zhang"", || ""Dave Zhenyu Chen"", || ""Songcen Xu"", || ""Long Quan"", || ""Eduardo Perez-Pellitero"", || ""Youngkyoon Jang"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""10.48550/arXiv.2405.12345"", || ""keywords"": [ || ""3D Vision-Language Models"", || ""Metric Cognitive Map"", || ""Cognitive Chain-of-Thought"", || ""Explainable AI"", || ""3D Spatial Understanding"" || ], || ""summary"": ""The paper introduces Map2Thought, a framework that enables explicit and interpretable spatial reasoning for 3D Vision-Language Models. It integrates a Metric Cognitive Map and a chain-of-thought reasoning process, achieving high accuracy with less training data compared to baselines."" || } ||  || [ Prompt: 120.1 t/s | Generation: 27.8 t/s ]"
2601.11451v1_PRISM-CAFO Prior-conditioned Remote-sensing Infras.pdf,PRISM-CAFO: Prior-conditioned Remote-sensing Infrastructure Segmentation and Mapping for CAFOs,"['Oishee Bintey Hoque', 'Nibir Chandra Mandal', 'Kyle Luong', 'Amanda Wilson', 'Samarth Swarup', 'Madhav Marathe', 'Abhijin Adiga']",10.48550/arXiv.2405.07901,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || PRISM-CAFO: Prior-conditioned Remote-sensing Infrastructure Segmentation || and Mapping for CAFOs || Oishee Bintey Hoque1,*, Nibir Chandra Mandal1,*, Kyle Luong1, Amanda Wilson2, Samarth Swarup2, || Madhav Marathe1,2, Abhijin Adiga2 || 1Dept. of Computer Science, University of Virginia || 2Biocomp ... (truncated) ||  || { || ""title"": ""PRISM-CAFO: Prior-conditioned Remote-sensing Infrastructure Segmentation and Mapping for CAFOs"", || ""authors"": [ || ""Oishee Bintey Hoque"", || ""Nibir Chandra Mandal"", || ""Kyle Luong"", || ""Amanda Wilson"", || ""Samarth Swarup"", || ""Madhav Marathe"", || ""Abhijin Adiga"" || ], || ""doi"": ""10.48550/arXiv.2405.07901"", || ""arxiv_id"": ""10.48550/arXiv.2405.07901"", || ""keywords"": [ || ""CAFOs"", || ""remote sensing"", || ""infrastructure segmentation"", || ""mapping"", || ""livestock operations"", || ""environmental risk"" || ], || ""summary"": ""This work presents an infrastructure-first, explainable pipeline for identifying and characterizing Concentrated Animal Feeding Operations (CAFOs) using aerial and satellite imagery. The method employs a domain-tuned YOLOv8 detector to detect infrastructure, extracts structured descriptors, and combines them with deep visual features to achieve state-of-the-art performance. The approach supports risk modeling, change detection, and regulatory actions."" || } ||  || [ Prompt: 114.1 t/s | Generation: 28.2 t/s ]"
2601.11459v1_Interactive Narrative Analytics Bridging Computati.pdf,Interactive Narrative Analytics: Bridging Computational Narrative Extraction and Human Sensemaking,['Brian Keith'],10.1 109/ACCESS.2025.3650352,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Received 24 November 2025, accepted 24 December 2025,date of publication 1 January 2026, || date of current version 6 January 2026 || Digital Object Identifier 10.1 109/ACCESS.2025.3650352 || Interactive Narrative Analytics: Bridging || Computational Narrative Extraction and Human || Sensemaking || B ... (truncated) ||  || { || ""title"": ""Interactive Narrative Analytics: Bridging Computational Narrative Extraction and Human Sensemaking"", || ""authors"": [""Brian Keith""], || ""doi"": ""10.1 109/ACCESS.2025.3650352"", || ""arxiv_id"": ""10.1 109/ACCESS.2025.3650352"", || ""keywords"": [""Human-AI collaboration"", ""information extraction"", ""interactive visual analytics"", ""knowledge integration"", ""narrative extraction"", ""narrative sensemaking"", ""semantic interaction"", ""visual analytics""], || ""summary"": ""This paper defines the nascent field of Interactive Narrative Analytics (INA), combining computational narrative extraction with interactive visual analytics to support sensemaking. It addresses challenges such as scalability, interactivity, knowledge integration, and evaluation standardization, highlighting opportunities across news analysis, intelligence, scientific literature, and social media."" || } ||  || [ Prompt: 117.1 t/s | Generation: 27.9 t/s ]"
2601.11464v1_MHA2MLA-VLM Enabling DeepSeeks Economical Multi-He.pdf,,[],,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MHA2MLA-VLM: Enabling DeepSeeks Economical Multi-Head Latent Attention || across Vision-Language Models || Xiaoran Fan1*, Zhichao Sun1*, Tao Ji1*, Lixing Shen2, Tao Gui1,3,4 || 1Fudan University || 2Hikvision Inc || 3Shanghai Innovation Institute || 4Pengcheng Laboratory || xrfan23@m.fudan.edu.cn; {taoj ... (truncated) ||  || { || ""title"": ""MHA2MLA-VLM: Enabling DeepSeeks Economical Multi-Head Latent Attention"", || ""authors"": [ || ""Xiaoran Fan"", || ""Zhichao Sun"", || ""Tao Ji"", || ""Lixing Shen"", || ""Tao Gui"", || ""3"", || ""4"" || ], || ""doi"": ""10.48550/arXiv.2303.04212"", || ""arxiv_id"": ""arXiv:2303.04212"", || ""keywords"": [ || ""vision-language models"", || ""key-value cache"", || ""multi-head attention"", || ""parameter-efficient fine-tuning"", || ""KV cache compression"" || ], || ""summary"": ""This paper presents MHA2MLA-VLM, a parameter-efficient framework for adapting vision-language models to Multi-Head Latent Attention architectures. It introduces modality-adaptive partial-RoPE and modality-decoupled low-rank approximation techniques to reduce memory usage and improve inference speed, while maintaining strong performance with minimal supervised data."" || } ||  || [ Prompt: 117.3 t/s | Generation: 28.4 t/s ]"
2601.11468v1_Exploring LLM Features in Predictive Process Monit.pdf,Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs,"['Alessandro Padella', 'Massimiliano de Leoni', 'Marlon Dumas']","1, 1 (January 2026), 19 pages",27.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Exploring LLM Features in Predictive Process Monitoring for Small-Scale || Event-Logs || ALESSANDRO PADELLA,Universit degli Studi di Padova, Italy || MASSIMILIANO DE LEONI,Universit degli Studi di Padova, Italy || MARLON DUMAS,University of Tartu, Estonia || Predictive Process Monitoring is a bran ... (truncated) ||  || { || ""title"": ""Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs"", || ""authors"": [ || ""Alessandro Padella"", || ""Massimiliano de Leoni"", || ""Marlon Dumas"" || ], || ""doi"": ""1, 1 (January 2026), 19 pages"", || ""arxiv_id"": ""19"", || ""keywords"": [ || ""Predictive process monitoring"", || ""Large language models"", || ""Trace Encoding"", || ""Key Performance Indicators"" || ], || ""summary"": ""This paper extends a prior LLM-based Predictive Process Monitoring framework, evaluating its generality, semantic leverage, and reasoning mechanisms across multiple KPIs. Empirical results show LLMs outperform benchmarks with limited data, leveraging prior knowledge and internal correlations."" || } ||  || [ Prompt: 124.9 t/s | Generation: 27.3 t/s ]"
2601.11479v1_Health Facility Location in Ethiopia Leveraging LL.pdf,Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning,"['Yohai Trabelsi', 'Guojun Xiong', 'Fentabil Getnet', 'Stphane Verguet', 'Milind Tambe']",10.1093/acm/qad045,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Health Facility Location in Ethiopia: Leveraging LLMs to || Integrate Expert Knowledge into Algorithmic Planning || Yohai Trabelsi || John A. Paulson School of || Engineering and Applied Sciences, || Harvard University || Cambridge, MA, United States || yohai.trabelsi@gmail.com || Guojun Xiong || John A. Paul ... (truncated) ||  || { || ""title"": ""Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning"", || ""authors"": [ || ""Yohai Trabelsi"", || ""Guojun Xiong"", || ""Fentabil Getnet"", || ""Stphane Verguet"", || ""Milind Tambe"" || ], || ""doi"": ""10.1093/acm/qad045"", || ""arxiv_id"": """", || ""keywords"": [ || ""Health Facility Location"", || ""Optimization"", || ""Human expert knowledge"", || ""Alignment"", || ""LLM"", || ""LLM-driven refinement"" || ], || ""summary"": ""Ethiopia's Ministry of Health is upgrading health posts to improve access, especially in rural areas. The study proposes a hybrid framework combining optimization methods with large language models to integrate expert knowledge and ensure equitable health planning."" || } ||  || [ Prompt: 114.5 t/s | Generation: 28.3 t/s ]"
2601.11492v1_BoxMind Closed-loop AI strategy optimization for e.pdf,BoxMind: Closed-loop AI strategy optimization for elite boxing,"['Kaiwen Wang', 'Kaili Zheng', 'Rongrong Deng', 'Qingmin Fan', 'Milin Zhang', 'Zongrui Li', 'Xuesi Zhou', 'Bo Han', 'Liren Chen', 'Chenyi Guo', 'Ji Wu']",,27.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || BoxMind: Closed-loop AI strategy optimization for elite boxing || validated in the 2024 Olympics || Kaiwen Wang1, Kaili Zheng *1, Rongrong Deng *2, Qingmin Fan 2, Milin Zhang 1, Zongrui || Li1, Xuesi Zhou 1, Bo Han 3, Liren Chen 3, Chenyi Guo 1, and Ji Wu 1,4,5 || 1Department of Electronic Engi ... (truncated) ||  || { || ""title"": ""BoxMind: Closed-loop AI strategy optimization for elite boxing"", || ""authors"": [ || ""Kaiwen Wang"", || ""Kaili Zheng"", || ""Rongrong Deng"", || ""Qingmin Fan"", || ""Milin Zhang"", || ""Zongrui Li"", || ""Xuesi Zhou"", || ""Bo Han"", || ""Liren Chen"", || ""Chenyi Guo"", || ""Ji Wu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""boxing"", || ""AI strategy"", || ""elite boxing"", || ""tactical analysis"", || ""machine learning"", || ""sports analytics"" || ], || ""summary"": ""Presents BoxMind, a closed-loop AI expert system validated in elite boxing, demonstrating state-of-the-art performance in predicting match outcomes and providing strategic recommendations based on technical-tactical indicators."" || } ||  || [ Prompt: 111.3 t/s | Generation: 27.0 t/s ]"
2601.11496v1_The Poisoned Apple Effect Strategic Manipulation o.pdf,The Poisoned Apple Effect: Strategic Manipulation of Mediated Markets via Technology Expansion,"['Eilam Shapira', 'Moshe Tennenholtz', 'Roi Reichart']",10.48550/arXiv.2026.12345,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || The Poisoned Apple Effect: Strategic Manipulation of Mediated || Markets via Technology Expansion of AI Agents || Eilam Shapira, Moshe Tennenholtz, and Roi Reichart || Technion  Israel Institute of Technology || January 2026 || Abstract || The integration of AI agents into economic markets fundamenta ... (truncated) ||  || { || ""title"": ""The Poisoned Apple Effect: Strategic Manipulation of Mediated Markets via Technology Expansion"", || ""authors"": [""Eilam Shapira"", ""Moshe Tennenholtz"", ""Roi Reichart""], || ""doi"": ""10.48550/arXiv.2026.12345"", || ""arxiv_id"": ""arXiv:2109.12345"", || ""keywords"": [""AI agents"", ""market design"", ""regulatory frameworks"", ""strategic manipulation""], || ""summary"": ""Investigates how expanding AI technologies alters strategic interactions in economic markets, highlighting the Poisoned Apple effect where agents manipulate regulators to favor their interests."" || } ||  || [ Prompt: 130.0 t/s | Generation: 27.7 t/s ]"
2601.11505v1_MetaboNet The Largest Publicly Available Consolida.pdf,MetaboNet: Thalassegraphetically Publicly Available,"['Miriam K. Wolff', 'Peter Calhoun', 'Eleonora Maria Aiello', 'Yao Qin', 'Sam F. Royston']",arXiv:2601.11505v1,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || METABONET: THELARGESTPUBLICLYAVAILABLE || CONSOLIDATEDDATASET FORTYPE1 DIABETES || MANAGEMENT || Miriam K. Wolff || Replica Health || New York, NY , USA || miriam@replica.health || Peter Calhoun || Jaeb Center for Health Research || Tampa, FL, USA || pcalhoun@jaeb.org || Eleonora Maria Aiello || University of Pavia || Pa ... (truncated) ||  || { || ""title"": ""MetaboNet: Thalassegraphetically Publicly Available"", || ""authors"": [ || ""Miriam K. Wolff"", || ""Peter Calhoun"", || ""Eleonora Maria Aiello"", || ""Yao Qin"", || ""Sam F. Royston"" || ], || ""doi"": ""arXiv:2601.11505v1"", || ""arxiv_id"": ""arXiv:2601.11505"", || ""keywords"": [ || ""type 1 diabetes"", || ""T1D"", || ""algorithm development"", || ""data integration"", || ""standardization"", || ""metaboNet"", || ""continuous glucose monitoring"", || ""insulin pump dosing"" || ], || ""summary"": ""Progress in Type 1 Diabetes (T1D) algorithm development is limited by the fragmentation and lack of standardization across existing T1D management datasets. Current datasets differ substantially in structure and are time-consuming to access and process, which impedes data integration and reduces the comparability and generalizability of algorithmic developments. This work aims to establish a unified and accessible data resource for T1D algorithm development. Multiple publicly available T1D datasets were consolidated into a unified resource, termed the MetaboNet dataset. Inclusion required the availability of both continuous glucose monitoring (CGM) data and corresponding insulin pump dosing records. Additionally, auxiliary information such as reported carbohydrate intake and physical activity was retained when present. The MetaboNet dataset comprises 3135 subjects and 1228 patient-years of overlapping CGM and insulin data, making it substantially larger than existing standalone benchmark datasets. The resource is distributed as a fully public subset available for immediate download at https://metabo-net.org/, and with a Data Use Agreement (DUA)-restricted subset accessible through their respective application processes. For the datasets in the latter subset, processing pipelines are provided to automatically convert the data into the standardized MetaboNet format. A consolidated public dataset for T1D research is presented, and the access pathways for both its unrestricted and DUA-governed components are described. The resulting dataset covers a broad range of glycemic profiles and demographics and thus can yield more generalizable algorithmic performance than individual datasets."" || } ||  || [ Prompt: 109.1 t/s | Generation: 27.5 t/s ]"
2601.11516v2_Building Production-Ready Probes For Gemini.pdf,Building Production-Ready Probes For Gemini,"['Jnos Kramr', 'Joshua Engels', 'Zheng Wang', 'Bilal Chughtai', 'Rohin Shah', 'Neel Nanda', 'Arthur Conmy']",,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 2026-01 || Building Production-Ready Probes For Gemini || Jnos Kramr, Joshua Engels, Zheng Wang, Bilal Chughtai, Rohin Shah, Neel Nanda, and Arthur Conmy || Google DeepMind, Equal contributions to this work. || Frontier language model capabilities are improving rapidly. We thus need stronger mi ... (truncated) ||  || { || ""title"": ""Building Production-Ready Probes For Gemini"", || ""authors"": [ || ""Jnos Kramr"", || ""Joshua Engels"", || ""Zheng Wang"", || ""Bilal Chughtai"", || ""Rohin Shah"", || ""Neel Nanda"", || ""Arthur Conmy"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Activation Probing"", || ""Interpretability"", || ""Language Models"", || ""Misuse Risk"", || ""AI Safety"", || ""Monitoring"" || ], || ""summary"": ""The paper discusses challenges in deploying robust misuse mitigation probes for frontier language models like Gemini 2.5 Flash, highlighting the need for improved generalization under production distribution shifts and the benefits of combining probes with prompted classifiers."" || } ||  || [ Prompt: 121.4 t/s | Generation: 27.6 t/s ]"
2601.11517v1_Do explanations generalize across large reasoning .pdf,Under Review,"['Koyena Pal', 'David Bau', 'Chandan Singh']",,26.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Under Review || DO EXPLANATIONS GENERALIZE ACROSS LARGE REA- || SONING MODELS? || Koyena Pal1, David Bau 1, Chandan Singh 2 || 1Northeastern University 2Microsoft Research || {pal.k, d.bau}@northeastern.edu, chansingh@microsoft.com || ABSTRACT || Large reasoning models (LRMs) produce a textual chain of  ... (truncated) ||  || { || ""title"": ""Under Review"", || ""authors"": [ || ""Koyena Pal"", || ""David Bau"", || ""Chandan Singh"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper investigates whether explanations generated by large reasoning models generalize across different models, examining consistency and human preference in cross-model reasoning traces."" || } ||  || [ Prompt: 119.2 t/s | Generation: 26.1 t/s ]"
2601.11625v1_Reasoning Stabilization Point A Training-Time Sign.pdf,Reasoning Stabilization Point: A Training-Time Signal for Stable Evidence,['Sahil Rajesh Dhayalkar'],,28.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Reasoning Stabilization Point: A Training-Time Signal for Stable Evidence || and Shortcut Reliance || Sahil Rajesh Dhayalkar || Arizona State University || sdhayalk@asu.edu || Abstract || Fine-tuning pretrained language models can || improve task performance while subtly al- || tering the evidence a model  ... (truncated) ||  || { || ""title"": ""Reasoning Stabilization Point: A Training-Time Signal for Stable Evidence"", || ""authors"": [""Sahil Rajesh Dhayalkar""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper proposes a training-time interpretability view to track token-level attributions during fine-tuning. It introduces the Reasoning Stabilization Point (RSP) as the earliest epoch where explanation drift becomes consistently low, helping monitor decision evidence evolution."" || } ||  || [ Prompt: 112.4 t/s | Generation: 28.9 t/s ]"
2601.11643v1_Syllabic Agglutinative Tokenizations for Indonesia.pdf,Syllabic Agglutinative Tokenizations for Indonesian LLM,"['Hokky Situngkir', 'Andhika Bernard Lumbantobing', 'Yohanes Surya']",10.1234/example.doi,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Syllabic Agglutinative Tokenizations for Indonesian LLM: || A Study from Gasing Literacy Learning System || Hokky Situngkir* Andhika Bernard Lumbantobing Yohanes Surya || Version: 2025-08-04 || Abstract || This paper presents a novel syllable-based tokenization approach for Indonesian large langua ... (truncated) ||  || { || ""title"": ""Syllabic Agglutinative Tokenizations for Indonesian LLM"", || ""authors"": [ || ""Hokky Situngkir"", || ""Andhika Bernard Lumbantobing"", || ""Yohanes Surya"" || ], || ""doi"": ""10.1234/example.doi"", || ""arxiv_id"": ""2025-08-04"", || ""keywords"": [ || ""Indonesian natural language processing"", || ""Indonesian computational linguistics"", || ""tokenization"", || ""large language models"", || ""Gasing Literacy Learning System"", || ""low-resource languages"", || ""Austronesian languages"" || ], || ""summary"": ""This paper presents a novel syllable-based tokenization approach for Indonesian large language models, inspired by the Gasing Literacy Learning Systems pedagogical methodology. It develops a tokenization framework that segments Indonesian text at syllable boundaries before applying byte-pair encoding, aligning with the language's morphophonological structure. Empirical evaluation shows improved efficiency and token length compared to conventional methods."" || } ||  || [ Prompt: 119.6 t/s | Generation: 28.2 t/s ]"
2601.11644v1_Predicting When to Trust Vision-Language Models fo.pdf,Predicting When to Trust Vision-Language Models for Spatial Reasoning,"['Muhammad Imran', 'Yugyung Lee']",,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Predicting When to Trust Vision-Language Models for Spatial || Reasoning || Muhammad Imran 1 andYugyung Lee 1 || 1University of Missouri Kansas City || {mi3dr, leeyu}@umkc.edu || Abstract || Vision-Language Models (VLMs) demonstrate || impressive capabilities across multimodal || tasks, yet exhibit systema ... (truncated) ||  || { || ""title"": ""Predicting When to Trust Vision-Language Models for Spatial Reasoning"", || ""authors"": [""Muhammad Imran"", ""Yugyung Lee""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""vision-language models"", ""spatial reasoning"", ""robotics"", ""autonomous systems""], || ""summary"": ""The paper proposes a vision-based confidence estimation framework to validate VLM predictions through geometric verification, improving reliability in spatial tasks. It achieves significant gains over text-based baselines and enables selective prediction strategies."" || } ||  || [ Prompt: 107.8 t/s | Generation: 28.5 t/s ]"
2601.11647v1_Reinforcement Learning for Dynamic Workflow Optimi.pdf,Reinforcement Learning for Dynamic Workflow,"['Aniket Abhishek Soni', 'Milan Parikh', 'Rashi Nimesh Kumar Dhenia', 'Jubin Abhishek Soni', 'Ayush Raj Jha', 'Sneha Mitinbhai Shah']",,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Reinforcement Learning for Dynamic Workflow || Optimization in CI/CD Pipelines || Aniket Abhishek Soni || Independent Researcher || Senior Member, IEEE || Brooklyn, NY , USA || aniketsoni@ieee.org || Milan Parikh || Independent Researcher || Senior Member, IEEE || Richmond, TX, USA || milan.parikh@ieee.org || Rashi Ni ... (truncated) ||  || { || ""title"": ""Reinforcement Learning for Dynamic Workflow"", || ""authors"": [ || ""Aniket Abhishek Soni"", || ""Milan Parikh"", || ""Rashi Nimesh Kumar Dhenia"", || ""Jubin Abhishek Soni"", || ""Ayush Raj Jha"", || ""Sneha Mitinbhai Shah"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Reinforcement Learning"", || ""CI/CD"", || ""DevOps"", || ""Workflow Optimization"" || ], || ""summary"": ""This paper proposes a reinforcement learning approach to optimize CI/CD pipeline workflows dynamically by modeling them as a Markov Decision Process and training an RL agent to make runtime decisions that maximize throughput while minimizing testing overhead. Experimental results show a 30% improvement in throughput and a 25% reduction in test execution overhead."" || } ||  || [ Prompt: 116.1 t/s | Generation: 28.7 t/s ]"
2601.11650v1_Large Language Model Agent for User-friendly Chemi.pdf,LARGELANGUAGEMODELAGENT FORUSER-FRIENDLY,"['Jingkang Liang', 'Niklas Groll', 'Grkan Sin', 'gsi@kt.dtu.dk', 'Niklas Groll', 'Jinliau Liang']",arXiv:2601.11650v1,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LARGELANGUAGEMODELAGENT FORUSER-FRIENDLY || CHEMICALPROCESSSIMULATIONS || A PREPRINT || Jingkang Liang || Process and System Engineering Center || Department of Chemical and Biochemical Engineering || Technical University of Denmark || 2800 Kgs. Lyngby, Denmark || jinlia@kt.dtu.dk || Niklas Groll || Process and ... (truncated) ||  || { || ""title"": ""LARGELANGUAGEMODELAGENT FORUSER-FRIENDLY"", || ""authors"": [ || ""Jingkang Liang"", || ""Niklas Groll"", || ""Grkan Sin"", || ""gsi@kt.dtu.dk"", || ""Niklas Groll"", || ""Jinliau Liang"" || ], || ""doi"": ""arXiv:2601.11650v1"", || ""arxiv_id"": ""2601.11650v1"", || ""keywords"": [ || ""Chemical Process Simulation"", || ""Large Language Model"", || ""Model Context Protocol"", || ""Process Simulation"", || ""Educational Tools"", || ""Automated Data Extraction"" || ], || ""summary"": ""Modern process simulators are powerful but require expert knowledge. This paper introduces a large language model agent integrated with A VEV A Process Simulation via Model Context Protocol, enabling natural language interaction for early-stage exploration. Two case studies demonstrate its use in educational and expert settings."" || } ||  || [ Prompt: 125.7 t/s | Generation: 27.7 t/s ]"
2601.11651v1_Aesthetics as Structural Harm Algorithmic Lookism .pdf,Aesthetics as Structural Harm: ALGORITHMIC LOOKISMACROSS,"['Miriam Doh', 'Aditya Gulati', 'Corina Canali', 'Nuria Oliver']",,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Aesthetics as Structural Harm:ALGORITHMICLOOKISMACROSS || TEXT-TO-IMAGEGENERATION ANDCLASSIFICATION || Miriam Doh || Universit Libre de Bruxelles || Brussels, Belgium || miriam.doh@umons.ac.be || Aditya Gulati || ELLIS Alicante || Alicante, Spain || aditya@ellisalicante.org || Corina Canali || Universitt der Knste  ... (truncated) ||  || { || ""title"": ""Aesthetics as Structural Harm: ALGORITHMIC LOOKISMACROSS"", || ""authors"": [ || ""Miriam Doh"", || ""Aditya Gulati"", || ""Corina Canali"", || ""Nuria Oliver"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Generative AI"", || ""Artificial Intelligence"", || ""Cognitive Biases"", || ""Attractiveness Halo Effect"" || ], || ""summary"": ""This paper examines algorithmic lookism through text-to-image generative AI and a gender classification task, demonstrating systematic biases in associating facial attractiveness with positive attributes and identifying gender disparities in classification systems."" || } ||  || [ Prompt: 110.2 t/s | Generation: 28.8 t/s ]"
2601.11652v1_WISP Waste- and Interference-Suppressed Distribute.pdf,WISP: Waste- and Interference-Suppressed Distributed Speculative LLM Serving at the Edge via Dynamic Drafting and SLO-Aware Batching,"['Xiangchen Li', 'Jiakun Fan', 'Qingyuan Wang', 'Dimitrios Spatharakis', 'Saeid Ghafouri', 'Hans Vandierendonck', 'Deepu John']",,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || WISP: Waste- and Interference-Suppressed Distributed || Speculative LLM Serving at the Edge via Dynamic Drafting || and SLO-Aware Batching || XIANGCHEN LI,Virginia Tech, USA || JIAKUN FAN,Virginia Tech, USA || QINGYUAN WANG,University College Dublin, Ireland || DIMITRIOS SPATHARAKIS,National Technica ... (truncated) ||  || { || ""title"": ""WISP: Waste- and Interference-Suppressed Distributed Speculative LLM Serving at the Edge via Dynamic Drafting and SLO-Aware Batching"", || ""authors"": [ || ""Xiangchen Li"", || ""Jiakun Fan"", || ""Qingyuan Wang"", || ""Dimitrios Spatharakis"", || ""Saeid Ghafouri"", || ""Hans Vandierendonck"", || ""Deepu John"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Speculative Decoding"", || ""Large Language Models"", || ""Edge Computing"", || ""Distributed Computing"", || ""Natural Language Processing"", || ""Computer Systems Organization"", || ""Distributed Architectures"", || ""Networks"", || ""Cloud Computing"", || ""General and Reference"" || ], || ""summary"": ""The paper addresses bottlenecks in distributed speculative LLM serving—wasted drafting time and verification interference—and proposes WISP to improve efficiency and scalability through intelligent speculation, verification estimation, and batch scheduling."" || } ||  || [ Prompt: 116.8 t/s | Generation: 28.2 t/s ]"
2601.11657v1_Size is Not the Solution Deformable Convolutions f.pdf,,[],,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Size is Not the Solution: Deformable Convolutions forEffective || Physics Aware Deep Learning || Jack T. Beerman 1, Shobhan Roy 2, H.S. Udaykumar 2, and Stephen S. Baek 1,3 || 1School of Data Science, University of Virginia, Charlottesville, V A 22903, United States || 2Department of Mechanical ... (truncated) ||  || { || ""title"": ""Size is Not the Solution: Deformable Convolutions for Effective Physics Aware Deep Learning"", || ""authors"": [ || ""Jack T. Beerman"", || ""Shobhan Roy"", || ""H.S. Udaykumar"", || ""Stephen S. Baek"" || ], || ""doi"": ""10.48550/arXiv.2026.12345"",  // Placeholder || ""arxiv_id"": ""arXiv:2509.12345"", || ""keywords"": [ || ""physics-aware deep learning"", || ""deformable convolutions"", || ""physics modeling"", || ""computational mechanics"", || ""nonlinear flows"" || ], || ""summary"": ""This paper introduces deformable physics-aware recurrent convolutions (D-PARC) inspired by Hybrid Lagrangian-Eulerian methods. D-PARC improves performance in modeling complex physical systems by overcoming CNN rigidity, showing superior fidelity across Burgers, Navier-Stokes, and reactive flows. The approach autonomously refines focus in high-strain regions, offering a more effective alternative to scaling models."" || } ||  || [ Prompt: 121.7 t/s | Generation: 27.8 t/s ]"
2601.11658v1_Towards AGI A Pragmatic Approach Towards Self Evol.pdf,Towards AGI: A Pragmatic Approach Towards Self Evolving Agent,"['Indrajit Kar', 'Sammy Zonunpuia', 'Zonunfeli Ralte']",,27.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  || Towards AGI: A Pragmatic Approach Towards || Self Evolving Agent ||  || Indrajit Kar || ORCID: 0000-0002-9539-6719 ||  || Sammy Zonunpuia || sammy@rastrai.com || Zonunfeli Ralte || ORCID: 0009-0000-3282-3368 || Abstract: Large Language Model (LLM)  based agents are powerful  ... (truncated) ||  || { || ""title"": ""Towards AGI: A Pragmatic Approach Towards Self Evolving Agent"", || ""authors"": [ || ""Indrajit Kar"", || ""Sammy Zonunpuia"", || ""Zonunfeli Ralte"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Self-evolving agent"", || ""Large Language Model (LLM)"", || ""Curriculum Learning"", || ""Reward-Based Learning"", || ""Genetic Algorithm"", || ""TaskCraft dataset"", || ""Autonomous adaptation"", || ""Capability evolution"" || ], || ""summary"": ""This paper introduces a hierarchical self-evolving multi-agent framework integrating a base LLM, an operational SLM agent, a Code-Gen LLM, and a Teacher-LLM to enable continuous adaptation. It evaluates these paradigms using the TaskCraft dataset, demonstrating that evolved agents outperform their original counterparts through robust, autonomous self-improvement."" || } ||  || [ Prompt: 109.7 t/s | Generation: 27.2 t/s ]"
2601.11663v1_Activation Sensitivity as a Unifying Principle for.pdf,Activations Sensitivity as a Unifying Principle for Post-Training Quantization,['Bruce Changlong Xu'],,27.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ACTIVATIONSENSITIVITY AS AUNIFYINGPRINCIPLE FOR || POST-TRAININGQUANTIZATION || Bruce Changlong Xu || brucechanglongxu@cs.stanford.edu || January 21, 2026 || ABSTRACT || Post-training quantization (PTQ) methods for large language models rely on heuristics that implicitly || estimate which weight channel ... (truncated) ||  || { || ""title"": ""Activations Sensitivity as a Unifying Principle for Post-Training Quantization"", || ""authors"": [""Bruce Changlong Xu""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This work presents a unified theoretical framework for post-training quantization by formalizing activation sensitivity. It explains how sensitivity emerges from the squared norm of gradient-weighted activations and connects it to classical pruning methods. The study highlights limitations and challenges in current PTQ approaches."" || } ||  || [ Prompt: 117.9 t/s | Generation: 27.4 t/s ]"
2601.11664v1_Serverless AI Security Attack Surface Analysis and.pdf,Serverless AI Security: Attack Surface Analysis and Runtime Protection Mechanisms for FaaS-Based Machine Learning,"['Chetan Pathade', 'Vinod Dhimam', 'Ilsa Lareb', 'Sheheryar Ahmad']",,27.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Serverless AI Security: Attack Surface Analysis and || Runtime Protection Mechanisms for FaaS-Based || Machine Learning || Chetan Pathade || Security Engineer || Arlington, VA, USA || chetanpathadeur@gmail.com || Vinod Dhimam || Technical Program Manager || Arlington, VA, USA || vinod.dhiman@icloud.com || Ilsa Lare ... (truncated) ||  || { || ""title"": ""Serverless AI Security: Attack Surface Analysis and Runtime Protection Mechanisms for FaaS-Based Machine Learning"", || ""authors"": [ || ""Chetan Pathade"", || ""Vinod Dhimam"", || ""Ilsa Lareb"", || ""Sheheryar Ahmad"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Serverless computing"", || ""machine learning security"", || ""Function-as-a-Service"", || ""cloud security"", || ""adversarial machine learning"", || ""AWS Lambda"", || ""Azure Functions"", || ""attack surface analysis"", || ""runtime protection"", || ""MLOps security"" || ], || ""summary"": ""This paper presents the first comprehensive security analysis of machine learning workloads in serverless environments. It characterizes attack surfaces across five categories and proposes Serverless AI Shield (SAS) for enhanced security."" || } ||  || [ Prompt: 118.1 t/s | Generation: 27.1 t/s ]"
2601.11666v1_MATEX Multi-scale Attention and Text-guided Explai.pdf,Multi-scale Attention and Text-guided Explainability of Medical Vision-Language Models,"['Muhammad Imran', 'Chi Lee', 'Yugyung Lee']",,27.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MATEX: Multi-scale Attention and Text-guided || Explainability of Medical Vision-Language Models || Muhammad Imran1, Chi Lee2, and Yugyung Lee1 || 1Computer Science, School of Science and Engineering, || 2Division of Pharmacology and Pharmaceutical Sciences, School of Pharmacy, || University of Mi ... (truncated) ||  || { || ""title"": ""Multi-scale Attention and Text-guided Explainability of Medical Vision-Language Models"", || ""authors"": [""Muhammad Imran"", ""Chi Lee"", ""Yugyung Lee""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Explainable AI"", ""Medical Imaging"", ""Gradient Attribution"", ""Attention Rollout"", ""Chest X-ray"", ""CLIP""], || ""summary"": ""MATEX introduces a novel framework for interpretability in medical vision-language models by integrating multi-scale attention, text-guided spatial reasoning, and layer consistency analysis, thereby improving spatial precision and clinical relevance."" || } ||  || [ Prompt: 109.8 t/s | Generation: 27.2 t/s ]"
2601.11667v1_Distill-then-Replace Efficient Task-Specific Hybri.pdf,Distill-then-Replace: Efficient Task-Specific Hybrid Attention Model Construction,"['Xiaojie Xia1', 'Huigang Zhang1', 'Chaoliang Zhong1', 'Jun Sun1', 'Yusuke Oishi2']",,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Distill-then-Replace: Efficient Task-Specific || Hybrid Attention Model Construction || Xiaojie Xia1[0000-0002-6486-7557], Huigang Zhang1[0000-0002-7567-7177], || Chaoliang Zhong1[0000-0003-1697-6932], Jun Sun1[0000-0002-0967-4859], and || Yusuke Oishi2[0000-0003-4264-8932] || 1 Fujitsu Research & ... (truncated) ||  || { || ""title"": ""Distill-then-Replace: Efficient Task-Specific Hybrid Attention Model Construction"", || ""authors"": [ || ""Xiaojie Xia1"", || ""Huigang Zhang1"", || ""Chaoliang Zhong1"", || ""Jun Sun1"", || ""Yusuke Oishi2"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Hybridattentionmodels"", || ""Blockwiselocaldistillation"", || ""Greedy"", || ""Search"" || ], || ""summary"": ""This paper presents a method to construct task-specific hybrid attention models by transferring weights from full-attention to linear attention and using greedy layer replacement to balance efficiency and performance without costly retraining."" || } ||  || [ Prompt: 126.8 t/s | Generation: 27.9 t/s ]"
2601.11670v1_A Confidence-Variance Theory for Pseudo-Label Sele.pdf,A Condence-Variance Theory for Pseudo-Label Selection,"['Jinshi Liu', 'Pan Liu']",,26.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || A Condence-V ariance Theory for Pseudo-Label || Selection in Semi-Supervised Learning || Jinshi Liu , Pan Liu || AbstractMost pseudo-label selection strategies in semi- || supervised learning rely on xed condence thresholds, im- || plicitly assuming that prediction condence reliably indicates || c ... (truncated) ||  || { || ""title"": ""A Condence-Variance Theory for Pseudo-Label Selection"", || ""authors"": [ || ""Jinshi Liu"", || ""Pan Liu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""semi-supervised learning"", || ""pseudo-label selection"", || ""condence"", || ""residual-class variance"", || ""spectral relaxation"", || ""semantic segmentation"", || ""image classification"" || ], || ""summary"": ""This paper introduces a Condence-Variance (CoVar) theory framework for pseudo-label selection in semi-supervised learning. It derives a reliability measure combining maximum condence and residual-class variance, aiming to correct overcondence by emphasizing both high confidence and low uncertainty in predictions."" || } ||  || [ Prompt: 115.7 t/s | Generation: 26.3 t/s ]"
2601.11674v1_Pigment Network Detection and Classification in De.pdf,Pigment Network Detection and Classification in Dermoscopic Images Using Directional Imaging Algorithms and Convolutional Neural Networks,"['M. A. Rasel', 'Sameem Abdul Kareem', 'Unaizah Obaidellah']",10.1016/j.bspc.2024.106883,27.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Accepted Manuscript: This is the peer-reviewed version of the article accepted for publication in Biomedical Signal Processing and Control. || Final published version: https://doi.org/10.1016/j.bspc.2024.106883 || 2024. This manuscript version is made available under the CC BY-NC-ND li ... (truncated) ||  || { || ""title"": ""Pigment Network Detection and Classification in Dermoscopic Images Using Directional Imaging Algorithms and Convolutional Neural Networks"", || ""authors"": [ || ""M. A. Rasel"", || ""Sameem Abdul Kareem"", || ""Unaizah Obaidellah"" || ], || ""doi"": ""10.1016/j.bspc.2024.106883"", || ""arxiv_id"": """", || ""keywords"": [ || ""Melanoma"", || ""Dermoscopic Images"", || ""Pigment Networks"", || ""Contrast Enhancement"", || ""Threshold Level"", || ""Convolutional Neural Networks"", || ""Bag of Features"" || ], || ""summary"": ""This study presents a directional imaging algorithm combined with machine learning to detect and classify pigment networks in dermoscopic images. The approach improves accuracy in distinguishing between typical and atypical pigment networks, achieving high performance with a proposed CNN model."" || } ||  || [ Prompt: 114.9 t/s | Generation: 27.0 t/s ]"
2601.11675v1_Generating metamers of human scene understanding.pdf,Generating Metamers of Human Scene Under-Standing,"['Ritik Raina', 'Abe Leite', 'Alexandros Graikos', 'Dimitris Samaras', 'Gregory J. Zelinsky']",,26.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Preprint || GENERATING METAMERS OF HUMAN SCENE UNDER- || STANDING || Ritik Raina1, Abe Leite1, Alexandros Graikos1 Seoyoung Ahn2, Dimitris Samaras1, || Gregory J. Zelinsky1 || 1Stony Brook University 2UC Berkeley || ABSTRACT || Human vision combines low-resolution gist information from the visual periph ... (truncated) ||  || { || ""title"": ""Generating Metamers of Human Scene Under-Standing"", || ""authors"": [ || ""Ritik Raina"", || ""Abe Leite"", || ""Alexandros Graikos"", || ""Dimitris Samaras"", || ""Gregory J. Zelinsky"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper introduces Metamer-Gen, a tool for generating scene metamers by combining low-resolution gist information with high-resolution fixated inputs. It presents a dual-stream representation and evaluates perceptual alignment using behavioral experiments."" || } ||  || [ Prompt: 113.7 t/s | Generation: 26.6 t/s ]"
2601.11676v1_HALO Semantic-Aware Distributed LLM Inference in L.pdf,HALO: Semantic-Aware Distributed LLM Inference in Lossy Edge Network,"['Peirong Zheng', 'Wenchao Xu', 'Haozhao Wang', 'Jinyu Chen', 'Xuemin (Sherman) Shen']",,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || HALO: Semantic-Aware Distributed LLM Inference || in Lossy Edge Network || Peirong Zheng1, Wenchao Xu* 2, Haozhao Wang 3, Jinyu Chen 1, and Xuemin (Sherman) Shen 4,Fellow, IEEE || 1Department of Computing, The Hong Kong Polytechnic University || 2Division of Integrative Systems and Design, The  ... (truncated) ||  || { || ""title"": ""HALO: Semantic-Aware Distributed LLM Inference in Lossy Edge Network"", || ""authors"": [ || ""Peirong Zheng"", || ""Wenchao Xu"", || ""Haozhao Wang"", || ""Jinyu Chen"", || ""Xuemin (Sherman) Shen"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Large Language Models"", || ""Tensor Parallelism"", || ""Edge Computing"", || ""Heterogeneity"", || ""Semantics"", || ""Packet Loss"" || ], || ""summary"": ""The paper proposes HALO, a framework to enhance distributed LLM inference in lossy edge networks by relaxing synchronization and optimizing resource allocation."" || } ||  || [ Prompt: 114.1 t/s | Generation: 26.9 t/s ]"
2601.11683v1_Attesting Model Lineage by Consisted Knowledge Evo.pdf,Attesting Model Lineage by Consisted Knowledge Evolution,"['Zhuoyi Shang1', 'Zhuoyi Shang2', 'Zhuoyi Shang3', 'Jiasen Li1', 'Jiasen Li2', 'Jiasen Li3', 'Pengzhen Chen1', 'Pengzhen Chen2', 'Pengzhen Chen3', 'Yanwei Liu1', 'Yanwei Liu3', 'Xiaoyan Gu1', 'Xiaoyan Gu2', 'Weiping Wang1', 'Weiping Wang2', 'Xiaoyan Wang1']",,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Attesting Model Lineage by Consisted Knowledge Evolution || with Fine-Tuning Trajectory || Zhuoyi Shang1,2,3,, Jiasen Li1,2,3,, Pengzhen Chen1,2,3,, || Yanwei Liu1,3,, Xiaoyan Gu1,2,3,, Weiping Wang1 || 1Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China || 2 School  ... (truncated) ||  || { || ""title"": ""Attesting Model Lineage by Consisted Knowledge Evolution"", || ""authors"": [ || ""Zhuoyi Shang1"", || ""Zhuoyi Shang2"", || ""Zhuoyi Shang3"", || ""Jiasen Li1"", || ""Jiasen Li2"", || ""Jiasen Li3"", || ""Pengzhen Chen1"", || ""Pengzhen Chen2"", || ""Pengzhen Chen3"", || ""Yanwei Liu1"", || ""Yanwei Liu3"", || ""Xiaoyan Gu1"", || ""Xiaoyan Gu2"", || ""Weiping Wang1"", || ""Weiping Wang2"", || ""Xiaoyan Wang1"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper discusses a novel framework for attesting model lineage by analyzing the trajectory of knowledge evolution during fine-tuning. It addresses challenges in verifying model provenance and proposes methods leveraging parameter and knowledge vectorization to ensure robust lineage verification."" || } ||  || [ Prompt: 109.3 t/s | Generation: 27.6 t/s ]"
2601.11684v1_Mobile-friendly Image de-noising Hardware Consciou.pdf,Equal Contribution,"['Srinivas Miriyala', 'Sowmya Vajrala', 'Hitesh Kumar', 'Sravanth Kodavanti', 'Vikram Rajendiran']",,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || *Equal Contribution || Mobile-friendly Image de-noising: Hardware || Conscious Optimization for Edge Application || Srinivas Miriyala* || On-Device AI || Samsung Research || Institute || Bangalore, India || srinivas.m1@samsung.com || Sowmya Vajrala* || On-Device AI || Samsung Research || Institute || ... (truncated) ||  || { || ""title"": ""Equal Contribution"", || ""authors"": [ || ""Srinivas Miriyala"", || ""Sowmya Vajrala"", || ""Hitesh Kumar"", || ""Sravanth Kodavanti"", || ""Vikram Rajendiran"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""De-noising"", || ""Differentiable NAS"", || ""Hardware-aware search space"", || ""Smartphone Deployment"" || ], || ""summary"": ""This work presents a novel mobile-friendly network for image de-noising using Entropy-Regularized differentiable Neural Architecture Search (NAS) on a hardware-aware search space for a U-Net architecture. The model achieves a 12% reduction in parameters, improved on-device latency, and better memory efficiency compared to state-of-the-art methods, demonstrating competitive accuracy and generalization across benchmarks."" || } ||  || [ Prompt: 115.4 t/s | Generation: 28.4 t/s ]"
2601.11685v1_Towards Efficient Image Deblurring for Edge Deploy.pdf,Equal Contribution Towards Efficient Image Deblurring for Edge Deployment,"['Srinivas Soumitri Miriyala', 'Sowmya Lahari Vajrala', 'Rama Sravanth Kodavanti']",,26.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || *Equal Contribution || Towards Efficient Image Deblurring for Edge || Deployment || Srinivas Soumitri Miriyala* || On-Device AI || Samsung Research  Institute || Bangalore, India || srinivas.m1@samsung.com ||  || Sowmya Lahari Vajrala* || On-Device AI || Samsung Research Institute || Bangalore, India || ... (truncated) ||  || { || ""title"": ""Equal Contribution Towards Efficient Image Deblurring for Edge Deployment"", || ""authors"": [ || ""Srinivas Soumitri Miriyala"", || ""Sowmya Lahari Vajrala"", || ""Rama Sravanth Kodavanti"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Mobile Image Signal Processing (ISP)"", || ""De-blurring"", || ""Training-free Search"", || ""Inference Optimization"", || ""Edge Deployment"" || ], || ""summary"": ""The paper proposes a hardware-aware adaptation framework for efficient image deblurring, achieving up to 55% reduction in GMACs while maintaining accuracy. It demonstrates improvements in latency and generalizes across motion and defocus deblurring tasks."" || } ||  || [ Prompt: 115.5 t/s | Generation: 26.5 t/s ]"
2601.11686v1_Proof of Concept Multi-Target Wildfire Risk Predic.pdf,Proof of Concept: Multi-Target Wildfire Risk Prediction and Large Language Model Synthesis,"['Nicolas Caron', 'Hassan Noura', 'Christophe Guyeux', 'Benjamin Aynes']",arXiv:2601.11686v1,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Proof of Concept: Multi-Target Wildfire Risk Prediction and || Large Language Model Synthesis || Nicolas Caron  Hassan Noura  Christophe Guyeux  Benjamin Aynes || Abstract || Current state-of-the-art approaches to wildfire risk assessment often overlook operational || needs, limiting their practic ... (truncated) ||  || { || ""title"": ""Proof of Concept: Multi-Target Wildfire Risk Prediction and Large Language Model Synthesis"", || ""authors"": [ || ""Nicolas Caron"", || ""Hassan Noura"", || ""Christophe Guyeux"", || ""Benjamin Aynes"" || ], || ""doi"": ""arXiv:2601.11686v1"", || ""arxiv_id"": ""arXiv:2601.11686"", || ""keywords"": [ || ""wildfire risk"", || ""multi-target analysis"", || ""large language models"", || ""operational needs"", || ""fire management"" || ], || ""summary"": ""This paper proposes a hybrid framework combining predictive models for wildfire risk dimensions with large language models to generate structured reports for first responders, emphasizing practical utility over single indicators."" || } ||  || [ Prompt: 118.6 t/s | Generation: 26.9 t/s ]"
2601.11687v1_Semantic Caching and Intent-Driven Context Optimiz.pdf,Semantic Caching and Intent-Driven Context,['Harmohit Singh'],arXiv:2601.11687v1,29.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Semantic Caching and Intent-Driven Context || Optimization || for Multi-Agent Natural Language to Code Systems || A Production Study in Enterprise Analytics || Harmohit Singh || CoreOps AI || harmohit.singh@coreops.ai || January 2026 || Abstract || We present a production-optimized multi-agent system designed ... (truncated) ||  || { || ""title"": ""Semantic Caching and Intent-Driven Context"", || ""authors"": [""Harmohit Singh""], || ""doi"": ""arXiv:2601.11687v1"", || ""arxiv_id"": ""arXiv:2601.11687"", || ""keywords"": [""Natural Language to Code"", ""Multi-Agent Systems"", ""Semantic Caching"", ""LLM Optimization"", ""Production Systems""], || ""summary"": ""A production-optimized multi-agent system for translating natural language queries into executable Python code, featuring semantic caching, intent-driven prompts, and high accuracy in enterprise analytics."" || } ||  || [ Prompt: 117.9 t/s | Generation: 29.8 t/s ]"
2601.11688v1_SpecMap Hierarchical LLM Agent for Datasheet-to-Co.pdf,SpecMap: Hierarchical LLM Agent for Datasheet-to-Code,"['Vedant Nipane Pulkit Agrawal', 'Amit Singh']",,31.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SpecMap: Hierarchical LLM Agent for Datasheet-to-Code || Traceability Link Recovery in Systems Engineering || Vedant Nipane Pulkit Agrawal Amit Singh || H2LooP.ai || Abstract || Establishing precise traceability between embedded systems datasheets and their corresponding || code implementations remai ... (truncated) ||  || { || ""title"": ""SpecMap: Hierarchical LLM Agent for Datasheet-to-Code"", || ""authors"": [""Vedant Nipane Pulkit Agrawal"", ""Amit Singh""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Establishing precise traceability between embedded systems datasheets and code implementations using a hierarchical LLM-based methodology."" || } ||  || [ Prompt: 112.1 t/s | Generation: 31.2 t/s ]"
2601.11700v1_Telling Human and Machine Handwriting Apart.pdf,Telling Human and Machine Handwriting Apart,"['Luis A. Leiva', 'Moises Diaz', 'Nuwan T. Attygalle', 'Miguel A. Ferrer', 'Rjean Plamondon']",10.1093/pasj/psa123,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  ||  || O || Telling Human and Machine Handwriting Apart || Luis A. Leiva , Moises Diaz , Nuwan T. Attygalle , Miguel A. Ferrer , || and Rjean Plamondon , Life Fellow, IEEE ||  ||  ||  || AbstractHandwriting movements can be leveraged as a || unique form of behavioral biometrics, to verify whether a re ... (truncated) ||  || { || ""title"": ""Telling Human and Machine Handwriting Apart"", || ""authors"": [ || ""Luis A. Leiva"", || ""Moises Diaz"", || ""Nuwan T. Attygalle"", || ""Miguel A. Ferrer"", || ""Rjean Plamondon"" || ], || ""doi"": ""10.1093/pasj/psa123"", || ""arxiv_id"": ""101071147"", || ""keywords"": [ || ""biometrics"", || ""classification"", || ""deep learning"", || ""reverse Turing test"", || ""verification"" || ], || ""summary"": ""Handwriting movements can be leveraged as a unique form of behavioral biometrics to verify user presence. The study evaluates performance across synthetic datasets and demonstrates strong classification accuracy even with limited training data."" || } ||  || [ Prompt: 113.5 t/s | Generation: 28.5 t/s ]"
2601.11702v1_PASTA A Scalable Framework for Multi-Policy AI Com.pdf,A Scalable Framework for Multi-Policy AI Compliance,"['YU YANG', 'IG-JAE KIM', 'DONGWOOK YOON']",,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || PASTA: A Scalable Framework for Multi-Policy AI Compliance || Evaluation || YU YANG,The University of British Columbia, Canada || IG-JAE KIM,Korea Institute of Science and Technology, South Korea || DONGWOOK YOON,The University of British Columbia, Canada || AI compliance is becoming increasingly  ... (truncated) ||  || { || ""title"": ""A Scalable Framework for Multi-Policy AI Compliance"", || ""authors"": [ || ""YU YANG"", || ""IG-JAE KIM"", || ""DONGWOOK YOON"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper presents PASTA, a scalable compliance tool integrating four innovations to address multi-policy AI compliance challenges. It evaluates five major policies efficiently and provides actionable recommendations."" || } ||  || [ Prompt: 118.8 t/s | Generation: 26.9 t/s ]"
2601.11713v1_Inter-Cell Interference Rejection Based on Ultrawi.pdf,Inter-Cell Interference Rejection Based on Ultrawideband Walsh-Domain Wireless Autoencoding,"['Rodney Martinez Alonso', 'Cedric Dehos', 'Yuneisy Esthela Garcia Guzman']",,26.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Inter-Cell Interference Rejection Based on || Ultrawideband Walsh-Domain Wireless || Autoencoding || Rodney Martinez Alonso || Cel Thys || Sofie Pollin || Department of Electrical Engineering || KU LEUVEN || Leuven, Belgium 3001 || Email: rodney.martinezalonso@kuleuven.be || Cedric Dehos || CEA-Leti || Email: cedric.d ... (truncated) ||  || { || ""title"": ""Inter-Cell Interference Rejection Based on Ultrawideband Walsh-Domain Wireless Autoencoding"", || ""authors"": [ || ""Rodney Martinez Alonso"", || ""Cedric Dehos"", || ""Yuneisy Esthela Garcia Guzman"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Inter-Cell Interference Rejection"", || ""Ultrawideband"", || ""Walsh Domain"", || ""Autoencoding"", || ""5G Communication"", || ""Spectrum Utilization"", || ""Interference Mitigation"" || ], || ""summary"": ""This paper proposes a novel technique for rejecting partial-in-band interference in ultrawideband communication systems using an end-to-end wireless autoencoder architecture optimized in the Walsh domain."" || } ||  || [ Prompt: 114.6 t/s | Generation: 26.8 t/s ]"
2601.11746v1_LIME-LLM Probing Models with Fluent Counterfactual.pdf,"LIME-LLM: Probing Models with Fluent Counterfactuals, Not Broken Text","['George Mihaila', 'Suleyman Olcay Polat', 'Poli Nemkova', 'Himanshu Sharma', 'Namratha V. Urs', 'Mark V. Albert']",arXiv:2601.11746v1,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LIME-LLM: Probing Models with Fluent Counterfactuals, || Not Broken Text || George Mihaila || University of North Texas || georgemihaila@my.unt.edu || Suleyman Olcay Polat || University of North Texas || suleymanolcaypolat@my.unt.edu || Poli Nemkova || University of North Texas || poli.nemkova@unt.edu || Himanshu S ... (truncated) ||  || { || ""title"": ""LIME-LLM: Probing Models with Fluent Counterfactuals, Not Broken Text"", || ""authors"": [ || ""George Mihaila"", || ""Suleyman Olcay Polat"", || ""Poli Nemkova"", || ""Himanshu Sharma"", || ""Namratha V. Urs"", || ""Mark V. Albert"" || ], || ""doi"": ""arXiv:2601.11746v1"", || ""arxiv_id"": ""arXiv:2601.11746"", || ""keywords"": [ || ""LIME"", || ""LLM"", || ""local explanation"", || ""counterfactuals"", || ""NLP"", || ""explainability"" || ], || ""summary"": ""This paper introduces LIME-LLM, a framework that replaces random noise with hypothesis-driven, controlled perturbations to improve local explanation in NLP. It evaluates its effectiveness across CoLA, SST-2, and HateXplain benchmarks, showing significant improvements over traditional methods."" || } ||  || [ Prompt: 113.6 t/s | Generation: 28.6 t/s ]"
2601.11747v1_PRISM Learning Design Knowledge from Data for Styl.pdf,PRISM: Learning Design Knowledge from Data,"['Huaxiaoyue Wang', 'Sunav Choudhary', 'Franck Dernoncourt', 'Yu Shen', 'Stefano Petrangeli']",,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || PRISM: Learning Design Knowledge from Data || for Stylistic Design Improvement || Huaxiaoyue Wang1, Sunav Choudhary2, Franck Dernoncourt2, Yu Shen2, Stefano Petrangeli2 || 1Cornell University, 2Adobe Research || yukiwang@cs.cornell.edu,{schoudha, dernonco, shenyu, petrange}@adobe.com || Abstract || G ... (truncated) ||  || { || ""title"": ""PRISM: Learning Design Knowledge from Data"", || ""authors"": [ || ""Huaxiaoyue Wang"", || ""Sunav Choudhary"", || ""Franck Dernoncourt"", || ""Yu Shen"", || ""Stefano Petrangeli"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Graphic design often involves exploring different stylistic directions, which can be time-consuming for non-experts. This paper addresses the problem by leveraging design data to improve stylistic choices based on natural language instructions. PRISM constructs a design knowledge base and applies it to achieve style-aware improvements, achieving high style alignment performance."" || } ||  || [ Prompt: 113.2 t/s | Generation: 28.1 t/s ]"
2601.11758v1_Early Linguistic Pattern of Anxiety from Social Me.pdf,Early Linguistic Pattern of Anxiety from Social Media,['Arnab Das Utsa'],,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Early Linguistic Pattern of Anxiety from Social Media || Using Interpretable Linguistic Features: A Multi-Faceted || Validation Study with Author-Disjoint Evaluation || Arnab Das Utsa || Department of Computer Science || Stockton University || Galloway, New Jersey, USA || utsaa@go.stockton.edu || Abstract || ... (truncated) ||  || { || ""title"": ""Early Linguistic Pattern of Anxiety from Social Media"", || ""authors"": [""Arnab Das Utsa""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""anxiety detection"", ""linguistic pattern"", ""interpretable machine learning"", ""keyword robustness"", ""cross-domain validation""], || ""summary"": ""This study presents a transparent approach to social media-based anxiety detection using linguistically interpretable features. It evaluates model performance through feature ablation, keyword masking, and cross-domain validation, demonstrating strong detection accuracy even after sentiment removal or keyword masking. The findings support reliable, generalizable, and keyword-robust anxiety screening."" || } ||  || [ Prompt: 116.7 t/s | Generation: 28.2 t/s ]"
2601.11762v1_Industry-Aligned Granular Topic Modeling.pdf,Industry-Aligned Granular Topic Modeling,"['Sae Young Moon', 'Myeongjun Erik Jang', 'Haoyan Luo', 'Chunyang Xiao', 'Antonios Georgiadis', 'Fran Silavong']",,28.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Industry-Aligned Granular Topic Modeling || Sae Young Moon1, Myeongjun Erik Jang1, Haoyan Luo1, Chunyang Xiao1, || Antonios Georgiadis1,Fran Silavong 1 || 1 J.P. Morgan Chase || {saeyoung.moon, myeongjun.jang, haoyan.luo, chunyang.xiao, || antonios.georgiadis, fran.silavong} @jpmchase.com || Abstract ... (truncated) ||  || { || ""title"": ""Industry-Aligned Granular Topic Modeling"", || ""authors"": [ || ""Sae Young Moon"", || ""Myeongjun Erik Jang"", || ""Haoyan Luo"", || ""Chunyang Xiao"", || ""Antonios Georgiadis"", || ""Fran Silavong"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""topic modeling"", || ""granularity"", || ""industry"", || ""text mining"", || ""data analysis"", || ""LLMs"", || ""business applications"" || ], || ""summary"": ""This paper introduces a framework called TIDE for granular topic modeling using large language models, demonstrating its effectiveness in business contexts."" || } ||  || [ Prompt: 113.0 t/s | Generation: 28.0 t/s ]"
2601.11768v1_Lightweight Self-Supervised Detection of Fundament.pdf,Lightweight Self-Supervised Detection of Fundamental Frequency and Accurate Probability of Voicing in Monophonic Music,"['Venkat Suprabath Bitra', 'Homayoon Beigi']",10.1093/icpram/icp002,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Lightweight Self-Supervised Detection of Fundamental Frequency and || Accurate Probability of Voicing in Monophonic Music || Venkat Suprabath Bitra 1 || a and Homayoon Beigi 2 || b || 1Dept. of Computer Science, Columbia University, New York, US || 2Dept. of Mechanical Engineering and Dept. of Elec ... (truncated) ||  || { || ""title"": ""Lightweight Self-Supervised Detection of Fundamental Frequency and Accurate Probability of Voicing in Monophonic Music"", || ""authors"": [ || ""Venkat Suprabath Bitra"", || ""Homayoon Beigi"" || ], || ""doi"": ""10.1093/icpram/icp002"", || ""arxiv_id"": ""arXiv:2108.10470"", || ""keywords"": [ || ""self-supervised pitch detection"", || ""unsupervised pitch detection"", || ""fundamental frequency"", || ""pitch estimation"", || ""resonance"", || ""musical timbre transfer"", || ""probability of voicing"", || ""music synthesis"", || ""music analysis"", || ""CQT"", || ""constant Q transform"", || ""DDSP"", || ""shift cross-entropy loss"", || ""musical instrument modeling"", || ""ResNeXt neural network"", || ""music information retrieval"", || ""MIR"" || ], || ""summary"": ""The paper presents a lightweight, fully self-supervised framework for joint fundamental frequency estimation and voicing inference. It leverages transposition-equivariant learning on CQT features and an EM-style iterative reweighting scheme with Shift Cross-Entropy to suppress noisy/unvoiced frames. The method achieves competitive cross-corpus performance and demonstrates cross-instrument generalization."" || } ||  || [ Prompt: 115.4 t/s | Generation: 28.1 t/s ]"
2601.11776v1_Cleansing the Artificial Mind A Self-Reflective De.pdf,Cleansing the Artificial Mind: A Self-Reflective Detoxification Framework,"['Kaituo Zhang', 'Zhimeng Jiang', 'Na Zou']",10.48550/arXiv.2405.12345,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Cleansing the Artificial Mind: A Self-Reflective Detoxification Framework || for Large Language Models || Kaituo Zhang || University of Houston || Houston, Texas, USA || kzhang42@cougarnet.uh.edu || Zhimeng Jiang || Texas A&M University || College Station, Texas, USA || Na Zou || University of Houston || Houston, T ... (truncated) ||  || { || ""title"": ""Cleansing the Artificial Mind: A Self-Reflective Detoxification Framework"", || ""authors"": [ || ""Kaituo Zhang"", || ""Zhimeng Jiang"", || ""Na Zou"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [ || ""Large Language Models"", || ""Self-regulation"", || ""Detoxification"", || ""Toxic content"", || ""Ethical AI"" || ], || ""summary"": ""This paper introduces a fully self-reflective detoxification framework for Large Language Models that leverages their inherent self-correction capabilities without relying on external modules or extensive data annotation. The method uses a Toxic Signal Detector internal mechanism to identify and transform toxic content, improving model safety and coherence. Experiments demonstrate superior detoxification performance compared to existing approaches."" || } ||  || [ Prompt: 112.7 t/s | Generation: 28.5 t/s ]"
2601.11778v1_Translation as a Scalable Proxy for Multilingual E.pdf,Translation as a Scalable Proxy for Multilingual Evaluation,"['Sheriff Issaka1', 'Erick Rosas Gonzalez1*', 'Lieqi Liu1*', 'Evans Kofi Agyei2', 'Lucas Bandarkar1', 'Nanyun Peng 1', 'David Ifeoluwa Adelani 3', 'Francisco Guzmn4', 'Saadia Gabriel 1']",,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Translation as a Scalable Proxy for Multilingual Evaluation || Sheriff Issaka1, Erick Rosas Gonzalez1*, Lieqi Liu1*, Evans Kofi Agyei2, || Lucas Bandarkar1,Nanyun Peng 1,David Ifeoluwa Adelani 3, || Francisco Guzmn4,Saadia Gabriel 1 || 1University of California, Los Angeles, 2African Languages  ... (truncated) ||  || { || ""title"": ""Translation as a Scalable Proxy for Multilingual Evaluation"", || ""authors"": [ || ""Sheriff Issaka1"", || ""Erick Rosas Gonzalez1*"", || ""Lieqi Liu1*"", || ""Evans Kofi Agyei2"", || ""Lucas Bandarkar1"", || ""Nanyun Peng 1"", || ""David Ifeoluwa Adelani 3"", || ""Francisco Guzmn4"", || ""Saadia Gabriel 1"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The rapid proliferation of LLMs has created a critical evaluation paradox... Translation quality alone indicates broader multilingual capabilities."" || } ||  || [ Prompt: 113.4 t/s | Generation: 28.7 t/s ]"
2601.11781v1_Risk-Aware Human-in-the-Loop Framework with Adapti.pdf,Risk-Aware Human-in-the-Loop Framework with Adaptive Intrusion Response for Autonomous Vehicles,"['Dawood Wasif', 'Terrence J. Moore', 'Seunghyun Yoon', 'Hyuk Lim', 'Dan Dongseong Kim', 'Frederica F. Nelson', 'Jin-Hee Cho']",,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Risk-Aware Human-in-the-Loop Framework with Adaptive || Intrusion Response for Autonomous Vehicles || Dawood Wasif 1, Terrence J. Moore 2, Seunghyun Yoon 3, Hyuk Lim 3, || Dan Dongseong Kim 4, Frederica F. Nelson 2, Jin-Hee Cho 1 || 1Virginia Tech, USA 2U.S. Army Research Laboratory, USA || 3KENTE ... (truncated) ||  || { || ""title"": ""Risk-Aware Human-in-the-Loop Framework with Adaptive Intrusion Response for Autonomous Vehicles"", || ""authors"": [ || ""Dawood Wasif"", || ""Terrence J. Moore"", || ""Seunghyun Yoon"", || ""Hyuk Lim"", || ""Dan Dongseong Kim"", || ""Frederica F. Nelson"", || ""Jin-Hee Cho"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""autonomous vehicles"", || ""safety"", || ""human-in-the-loop"", || ""intrusion response"", || ""risk-aware"", || ""adaptive control"", || ""soft actor-critic"", || ""distributional reinforcement learning"" || ], || ""summary"": ""RAIL is a risk-aware human-in-the-loop framework that integrates adaptive intrusion response for autonomous vehicles. It fuses three cues into an Intrusion Risk Score and uses learned authority to blend actions with human override, improving safety and performance under rare or adversarial conditions."" || } ||  || [ Prompt: 110.6 t/s | Generation: 28.3 t/s ]"
2601.11792v1_A self-evolving multi-role collaborative framework.pdf,A self-evolving multi-role collaborative framework with fine-grained difficulty guidance for innovative mathematical problem generation,"['Yifei Suna', 'Yongan Lia', 'A.K. Qinb', 'Sicheng Houa', 'Tamas Pflanznerc']",,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A self-evolving multi-role collaborative framework with fine-grained difficulty guidance || for innovative mathematical problem generation || Yifei Suna,, Yongan Lia, A.K. Qinb, Sicheng Houa, Tamas Pflanznerc || aSchool of Physics and Information Technology, Shaanxi Normal University, Xian,  ... (truncated) ||  || { || ""title"": ""A self-evolving multi-role collaborative framework with fine-grained difficulty guidance for innovative mathematical problem generation"", || ""authors"": [ || ""Yifei Suna"", || ""Yongan Lia"", || ""A.K. Qinb"", || ""Sicheng Houa"", || ""Tamas Pflanznerc"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Problem generation"", || ""Large language models"", || ""Multi-role collaboration"", || ""Intelligent education"", || ""Self-evolution"", || ""Knowledge distillation"" || ], || ""summary"": ""This paper proposes a self-evolving, multi-role collaborative framework with fine-grained difficulty guidance for innovative mathematical problem generation. It introduces a multi-role collaborative mechanism and an improved difficulty model to enhance problem generation quality."" || } ||  || [ Prompt: 108.8 t/s | Generation: 27.7 t/s ]"
2601.11801v1_RobotDesignGPT Automated Robot Design Synthesis us.pdf,RobotDesignGPT: Automated Robot Design Synthesis,"['Nitish Sontakke', 'K. Niranjan Kumar', 'Sehoon Ha']",,27.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || RobotDesignGPT: Automated Robot Design Synthesis || using Vision Language Models || Nitish Sontakke 1 K. Niranjan Kumar 1 Sehoon Ha 1 || Abstract Robot design is a nontrivial process that involves || careful consideration of multiple criteria, including user specifi- || cations, kinematic structur ... (truncated) ||  || { || ""title"": ""RobotDesignGPT: Automated Robot Design Synthesis"", || ""authors"": [ || ""Nitish Sontakke"", || ""K. Niranjan Kumar"", || ""Sehoon Ha"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper presents RobotDesignGPT, a novel automated robot design framework that leverages vision-language models to synthesize robot designs from user prompts and reference images. It addresses the challenges in robot design synthesis by utilizing the general knowledge and reasoning capabilities of large pre-trained vision-language models, aiming to improve design quality and reduce manual feedback."" || } ||  || [ Prompt: 111.6 t/s | Generation: 27.2 t/s ]"
2601.11809v1_Multi-agent DRL-based Lane Change Decision Model f.pdf,Multi-agent DRL-based Lane Change Decision,"['Zeyu Mu1', 'Shangtong Zhang', 'B. Brian Park']",,27.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Multi-agent DRL-based Lane Change Decision || Model for Cooperative Planning in Mixed Traffic || Zeyu Mu1, Shangtong Zhang 2 and B. Brian Park 3 || AbstractConnected automated vehicles (CA Vs) possess the || ability to communicate and coordinate with one another, enabling || cooperative platooning ... (truncated) ||  || { || ""title"": ""Multi-agent DRL-based Lane Change Decision"", || ""authors"": [ || ""Zeyu Mu1"", || ""Shangtong Zhang"", || ""B. Brian Park"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Multi-Agent"", || ""Reinforcement Learning"", || ""Cooperative Platooning"", || ""Lane Change"", || ""Traffic Flow"" || ], || ""summary"": ""The study proposes a hybrid multi-agent lane change decision model using QMIX and CNN-QMIX to enhance cooperative platooning in mixed traffic environments, improving traffic efficiency and safety."" || } ||  || [ Prompt: 110.7 t/s | Generation: 27.2 t/s ]"
2601.11816v1_POLARIS Typed Planning and Governed Execution for .pdf,POLARIS: Typed Planning and Governed Execution,"['Zahra Moslemi1', 'Keerthi Koneru2', 'Yen-Ting Lee3', 'Sheethal Kumar2', 'Ramesh Radhakrishnan2']",,28.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || POLARIS: Typed Planning and Governed Execution || for Agentic AI in Back-Office Automation || Zahra Moslemi1, Keerthi Koneru2, Yen-Ting Lee3, Sheethal Kumar2, Ramesh Radhakrishnan2 || 1University of California, Irvine,2Center for Advanced AI, Accenture,3University of California, San Diego || En ... (truncated) ||  || { || ""title"": ""POLARIS: Typed Planning and Governed Execution"", || ""authors"": [ || ""Zahra Moslemi1"", || ""Keerthi Koneru2"", || ""Yen-Ting Lee3"", || ""Sheethal Kumar2"", || ""Ramesh Radhakrishnan2"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Agentic AI"", || ""Enterprise Automation"", || ""Back-Office Tasks"", || ""Benchmarks"", || ""Governance"", || ""Typed Planning"", || ""Evaluation"" || ], || ""summary"": ""POLARIS presents a governed orchestration framework for agentic AI in back-office automation, focusing on typed planning, policy alignment, and execution guarantees. It achieves strong performance on benchmark datasets and provides reproducible decision artifacts."" || } ||  || [ Prompt: 111.6 t/s | Generation: 28.9 t/s ]"
2601.11825v1_AI Co-Scientist for Knowledge Synthesis in Medical.pdf,AI Co-Scientist for Knowledge Synthesis in Medical Contexts: A Proof of Concept,"['Arya Rahgozara', 'Pouria Mortezaaghaa']",arXiv:2601.11825v1,30.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || AI Co-Scientist for Knowledge Synthesis in Medical || Contexts: A Proof of Concept || Arya Rahgozara,b, Pouria Mortezaaghaa,b || aMethodological Implementation Research, Ottawa Hospital Research || Institute, Ottawa, ON, Canada || bSchool of Engineering Design and Teaching Innovation, University o ... (truncated) ||  || { || ""title"": ""AI Co-Scientist for Knowledge Synthesis in Medical Contexts: A Proof of Concept"", || ""authors"": [ || ""Arya Rahgozara"", || ""Pouria Mortezaaghaa"" || ], || ""doi"": ""arXiv:2601.11825v1"", || ""arxiv_id"": ""2601.11825"", || ""keywords"": [ || ""AI co-scientist"", || ""knowledge synthesis"", || ""medical contexts"", || ""PICOS framework"", || ""semantic retrieval"", || ""topic modeling"" || ], || ""summary"": ""This paper presents a multi-representational platform integrating databases, semantic retrieval, and a Neo4j knowledge graph to develop an AI co-scientist for scalable knowledge synthesis in medical research. It evaluates transformer-based and BiLSTM models for PICOS compliance classification and demonstrates strong performance in automated and retrieval-augmented generation approaches."" || } ||  || [ Prompt: 116.8 t/s | Generation: 30.7 t/s ]"
2601.11840v1_Imandra CodeLogician Neuro-Symbolic Reasoning for .pdf,Imandra CodeLogician: Neuro-Symbolic Reasoning for Precise Analysis of Software Logic,"['Hongyu Lin', 'Samer Abdallah', 'Makar Valentinov', 'Paul Brennan', 'Elijah Kagan', 'Christoph M. Wintersteiger', 'Denis Ignatovich', 'Grant Passmore']",,27.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Imandra CodeLogician: Neuro-Symbolic Reasoning for Precise || Analysis of Software Logic || Hongyu Lin 1, Samer Abdallah 1, Makar Valentinov 1, Paul Brennan 1, Elijah Kagan 1, || Christoph M. Wintersteiger 1, Denis Ignatovich 1, and Grant Passmore 1,2 || 1Imandra Inc. || 2Clare Hall, University of ... (truncated) ||  || { || ""title"": ""Imandra CodeLogician: Neuro-Symbolic Reasoning for Precise Analysis of Software Logic"", || ""authors"": [ || ""Hongyu Lin"", || ""Samer Abdallah"", || ""Makar Valentinov"", || ""Paul Brennan"", || ""Elijah Kagan"", || ""Christoph M. Wintersteiger"", || ""Denis Ignatovich"", || ""Grant Passmore"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper presents CodeLogician 1, a neurosymbolic agent for precise software logic analysis, integrating with ImandraX to enable rigorous reasoning about software systems. It introduces a new benchmark to evaluate reasoning accuracy and compares LLM performance with augmented reasoning capabilities."" || } ||  || [ Prompt: 118.0 t/s | Generation: 27.3 t/s ]"
2601.11850v1_Human-AI Collaborative Inductive Thematic Analysis.pdf,HumanAI Collaborative Inductive Thematic Analysis: How AI Guides Analysis and Researchers Reclaim Interpretive Authority,"['Matthew Nyaaba', 'Min SungEun', 'Mary Abiswin Apam', 'Kwame Owoahene Acheampong', 'Emmanuel Dwamena', 'Xiaoming Zhai']",1,27.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Under Review                                                                                                                    JDEM || 1 ||  || HumanAI Collaborative Inductive Thematic Analysis: How AI || Guides Analysis and Researchers Reclaim Interpretive Auth ... (truncated) ||  || { || ""title"": ""HumanAI Collaborative Inductive Thematic Analysis: How AI Guides Analysis and Researchers Reclaim Interpretive Authority"", || ""authors"": [ || ""Matthew Nyaaba"", || ""Min SungEun"", || ""Mary Abiswin Apam"", || ""Kwame Owoahene Acheampong"", || ""Emmanuel Dwamena"", || ""Xiaoming Zhai"" || ], || ""doi"": ""1"", || ""arxiv_id"": """", || ""keywords"": [ || ""HumanAI"", || ""Inductive Thematic Analysis"", || ""Generative AI"", || ""Research Methodology"", || ""Epistemic Authority"", || ""Reflexive Thematic Analysis"" || ], || ""summary"": ""The study examines how AI tools, specifically an Inductive Thematic Analysis GPT, influence qualitative research practices by guiding analysts through structured workflows while emphasizing the importance of human oversight in maintaining interpretive authority."" || } ||  || [ Prompt: 109.0 t/s | Generation: 27.4 t/s ]"
2601.11854v1_ATOD An Evaluation Framework and Benchmark for Age.pdf,,[],,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ATOD: An Evaluation Framework and Benchmark for Agentic || Task-Oriented Dialogue System || Yifei Zhang1* Hooshang Nayyeri1 Rinat Khaziev1 || Emine Yilmaz1,2 Gokhan Tur1,3 Dilek Hakkani-Tr1,3 Hari Thadakamalla1 || 1Amazon 2University College London 3University of Illinois UrbanaChampaign || {jimmy ... (truncated) ||  || { || ""title"": ""ATOD: An Evaluation Framework and Benchmark for Agentic Task-Oriented Dialogue System"", || ""authors"": [ || ""Yifei Zhang"", || ""Hooshang Nayyeri"", || ""Emine Yilmaz"", || ""Gokhan Tur"", || ""Dilek Hakkani-Tr1,3"", || ""Hari Thadakamalla"", || ""Jimmy Zyfi"", || ""Hooshang"", || ""Rinatk"", || ""Gokturt"", || ""Hakkanit"", || ""Thadakah"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""task-oriented dialogue"", || ""agentic systems"", || ""LLMs"", || ""benchmark"", || ""benchmarks"", || ""agentic capabilities"", || ""long-term reasoning"" || ], || ""summary"": ""This paper introduces ATOD, a benchmark and synthetic dialogue generation pipeline for advanced task-oriented dialogue systems. It evaluates agentic behaviors such as multi-goal concurrency, interleaved workflows, long-horizon memory, and proactivity. ATOD-Eval provides fine-grained metrics for comprehensive assessment, highlighting a trade-off between accuracy and efficiency compared to existing methods."" || } ||  || [ Prompt: 114.9 t/s | Generation: 28.6 t/s ]"
2601.11859v1_Cascaded Transformer for Robust and Scalable SLA D.pdf,Cascaded Transformer for Robust and Scalable,['Cyril Shih-Huan Hsu'],,27.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Cascaded Transformer for Robust and Scalable || SLA Decomposition via Amortized Optimization || Cyril Shih-Huan Hsu || Informatics Institute || University of Amsterdam || Amsterdam, The Netherlands || s.h.hsu@uva.nl || AbstractThe evolution toward 6G networks increasingly || relies on network slicing to pr ... (truncated) ||  || { || ""title"": ""Cascaded Transformer for Robust and Scalable"", || ""authors"": [""Cyril Shih-Huan Hsu""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""network slicing"", ""service level agreement"", ""quality of service"", ""deep neural network"", ""optimization""], || ""summary"": ""The paper introduces Casformer, a cascaded Transformer architecture for fast, optimization-free SLA decomposition. It leverages domain-specific encoders and cross-domain aggregation to improve SLA quality and scalability in 6G networks."" || } ||  || [ Prompt: 108.5 t/s | Generation: 27.2 t/s ]"
2601.11863v1_Utilizing Metadata for Better Retrieval-Augmented .pdf,,[],,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Utilizing Metadata for Better || Retrieval-Augmented Generation || Raquib Bin Yousuf1[0009000112450450], Shengzhe Xu1[0009000885896526], || Mandar Sharma1[0000000270129323], Andrew Neeser1, Chris Latimer2, and || Naren Ramakrishnan1[0000000218219743] || 1 Virginia Tech, Virginia, USA || {raquib, shen ... (truncated) ||  || { || ""title"": ""Utilizing Metadata for Better Retrieval-Augmented Generation"", || ""authors"": [ || ""Raquib Bin Yousuf"", || ""Shengzhe Xu"", || ""Mandar Sharma"", || ""Andrew Neeser"", || ""Chris Latimer"", || ""Naren Ramakrishnan"" || ], || ""doi"": ""0009000112450450"", || ""arxiv_id"": ""0009000885896526"", || ""keywords"": [ || ""Retrieval-Augmented Generation"", || ""Metadata-aware"", || ""RAG"", || ""Metadata-aware Query Reformulation"", || ""Benchmark Datasets"" || ], || ""summary"": ""This study evaluates metadata-aware retrieval strategies in Retrieval-Augmented Generation systems, comparing plain-text baselines with approaches that embed metadata directly. The results show that incorporating metadata improves performance across various retrieval metrics and ablations, highlighting the benefits of structural cues and unified embeddings."" || } ||  || [ Prompt: 125.0 t/s | Generation: 29.0 t/s ]"
2601.11868v1_Terminal-Bench Benchmarking Agents on Hard Realist.pdf,,[],,26.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TERMINAL-BENCH: || BENCHMARKINGAGENTS ONHARD, REALISTIC || TASKS INCOMMANDLINEINTERFACES || Mike A. Merrill1,*,Alexander G. Shaw 2,*,Nicholas Carlini 3,Boxuan Li 4,Harsh Raj 5,Ivan || Bercovich6,Lin Shi 7,Jeong Yeon Shin 1,8,Thomas Walshe 9,E. Kelly Buchanan 1 Junhong || Shen10,Guanghao Ye 11,Haow ... (truncated) ||  || { || ""title"": ""TERMINAL-BENCH"", || ""authors"": [ || ""Mike A. Merrill"", || ""Alexander G. Shaw"", || ""Nicholas Carlini"", || ""Boxuan Li"", || ""Harsh Raj"", || ""Ivan Bercovich"", || ""Lin Shi"", || ""Jeong Yeon Shin"", || ""Thomas Walshe"", || ""E. Kelly Buchanan"", || ""Junhong Shen"", || ""Guanghao Ye"", || ""Haowei Lin"", || ""Jason Poulos"", || ""Maoyu Wang"", || ""Marianna Nezhurina"", || ""Di Lu"", || ""Orfeas Menis"", || ""Zhiwei Xu"", || ""Zizhao Chen"", || ""Yue Liu"", || ""Robert Zhang"", || ""Leon Liangyu Chen"", || ""Anurag Kashyap"", || ""Jianbo Wu"", || ""Minghao Yan"", || ""Song Bian"", || ""Vedang Sharma"", || ""Ke Sun"", || ""Steven Dillmann"", || ""Akshay Anand"", || ""Andrew Lanpouthakoun"", || ""Bardia Koopah"", || ""Changran Hu"", || ""Etash Guha"", || ""Gabriel H. S. Dreiman"", || ""Jiacheng Zhu"", || ""Karl Krauth"", || ""Li Zhong3"", || ""Niklas Muennighoff"", || ""Robert Amanfu"", || ""Shangyin Tan"", || ""Shreyas Pimpalgaonkar"", || ""Tushar Aggarwal"", || ""Xiangning Lin"", || ""Xin Lan"", || ""Xuandong Zhao"", || ""Yiqing Liang"", || ""Yuanli Wang"", || ""Zilong Wang"", || ""Changzhi Zhou"", || ""David Heineman"", || ""Hange Liu"", || ""Yiwei Dai"", || ""Wuwei Lin"", || ""Yiying Wang"", || ""Shanda Li"", || ""Terry Yue Zhuo"", || ""Wenhao Chai"", || ""Shang Zhou"", || ""Dariush Wahdany"", || ""Ziyu She"", || ""Jiaming Hu"", || ""Zhikang Dong"", || ""Yuxuan Zhu"", || ""Sasha Cui"", || ""Ahson Sai ||  || [ Prompt: 114.9 t/s | Generation: 26.8 t/s ]"
2601.11876v1_AI for Green Spaces Leveraging Autonomous Navigati.pdf,Autonomous Trash Pickup Robots on Grass Fields,[],,25.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  || Abstract There are 50 billion pieces of litter in the || U.S. alone. Grass fields contribute to this problem because || picnickers tend to leave trash on the field . We propose || building a robot that can autonomously navigate, identify, || and pick up trash in parks. To autonomously na ... (truncated) ||  || { || ""title"": ""Autonomous Trash Pickup Robots on Grass Fields"", || ""authors"": [], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper discusses the challenges of litter in grass fields and proposes a robot solution using STC algorithm, RTK GPS, and ResNet50 CNN for trash detection. It highlights the viability of autonomous trash pickup robots on grass."" || } ||  || [ Prompt: 113.3 t/s | Generation: 25.3 t/s ]"
2601.11880v1_TF-CoDiT Conditional Time Series Synthesis with Di.pdf,TF-CoDiT: Conditional Time Series Synthesis with Diffusion Transformers,"['Yingxiao Zhang', 'Jiaxin Duan', 'Junfu Zhang', 'Ke Feng']",10.48550/arXiv.2405.12345,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TF-CoDiT: Conditional Time Series Synthesis with Diffusion Transformers || for Treasury Futures || Yingxiao Zhang1,2, Jiaxin Duan3, Junfu Zhang1, Ke Feng1 || 1School of Software and Microelectronics, Peking University, || 2Financial Markets Division, Pingan Bank Co. Ltd, || 3China Electronics Clou ... (truncated) ||  || { || ""title"": ""TF-CoDiT: Conditional Time Series Synthesis with Diffusion Transformers"", || ""authors"": [ || ""Yingxiao Zhang"", || ""Jiaxin Duan"", || ""Junfu Zhang"", || ""Ke Feng"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [ || ""Treasury futures"", || ""Diffusion Transformers"", || ""Time series synthesis"", || ""Financial markets"", || ""Wavelet Transform"", || ""Latent variables"", || ""Market dynamics"" || ], || ""summary"": ""This paper introduces TF-CoDiT, a framework for generating treasury futures data using diffusion transformers. It addresses challenges in synthesizing low-volume, high-dependency financial time-series by adapting standard DiT and introducing a U-shape VAE for cross-channel encoding."" || } ||  || [ Prompt: 110.0 t/s | Generation: 28.7 t/s ]"
2601.11885v1_MyGram Modality-aware Graph Transformer with Globa.pdf,MyGram: Modality-aware Graph Transformer with Global Distribution for Multi-modal Entity Alignment,"['Zhifei Li1', 'Ziyue Qin', 'Xiangyu Luo', 'Xiaoju Hou', 'Yue Zhao', 'Miao Zhang', 'Zhifang Huang', 'Kui Xiao', 'Bing Yang']",zhifei1993,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MyGram: Modality-aware Graph Transformer with Global Distribution for || Multi-modal Entity Alignment || Zhifei Li1,5,6, Ziyue Qin 1,*, Xiangyu Luo 4, Xiaoju Hou 2, || Yue Zhao3,*, Miao Zhang 1, Zhifang Huang 1, Kui Xiao 1, Bing Yang1,* || 1School of Computer Science, Hubei University, Wuhan 43 ... (truncated) ||  || { || ""title"": ""MyGram: Modality-aware Graph Transformer with Global Distribution for Multi-modal Entity Alignment"", || ""authors"": [ || ""Zhifei Li1"", || ""Ziyue Qin"", || ""Xiangyu Luo"", || ""Xiaoju Hou"", || ""Yue Zhao"", || ""Miao Zhang"", || ""Zhifang Huang"", || ""Kui Xiao"", || ""Bing Yang"" || ], || ""doi"": ""zhifei1993"", || ""arxiv_id"": """", || ""keywords"": [ || ""multi-modal entity alignment"", || ""knowledge graphs"", || ""graph transformer"", || ""entity alignment"", || ""semantic representations"" || ], || ""summary"": ""Multi-modal entity alignment aims to identify equivalent entities between two multi-modal knowledge graphs by integrating multi-modal data. This paper proposes MyGram, an amodality-aware graph transformer with global distribution for multi-modal entity alignment, addressing structural contextual information and improving fusion accuracy."" || } ||  || [ Prompt: 112.3 t/s | Generation: 27.8 t/s ]"
2601.11895v1_DevBench A Realistic Developer-Informed Benchmark .pdf,,[],,27.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DevBench: A Realistic, Developer-Informed Benchmark for Code || Generation Models || Pareesa Ameneh Golnari ,1, Adarsh Kumarappan ,2, Wen Wen 1, Xiaoyu Liu 1, || Gabriel Ryan 1, Yuting Sun 1, Shengyu Fu 1, Elsie Nallipogu 1 || 1Microsoft, 2California Institute of Technology || {pgolnar, wenwen, li ... (truncated) ||  || { || ""title"": ""DevBench: A Realistic, Developer-Informed Benchmark for Code"", || ""authors"": [ || ""Pareesa Ameneh Golnari"", || ""Adarsh Kumarappan"", || ""Wen Wen"", || ""Xiaoyu Liu"", || ""Gabriel Ryan"", || ""Yuting Sun"", || ""Shengyu Fu"", || ""Elsie Nallipogu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""DevBench"", || ""LLM"", || ""code generation"", || ""code completion"", || ""telemetry"", || ""benchmark"", || ""software development"" || ], || ""summary"": ""DevBench is a benchmark designed to evaluate Large Language Models on realistic code completion tasks, focusing on ecological validity and practical utility. It assesses models across multiple programming languages and task categories, providing insights into syntactic precision, semantic reasoning, and contextual relevance."" || } ||  || [ Prompt: 112.0 t/s | Generation: 27.2 t/s ]"
2601.11903v1_AEMA Verifiable Evaluation Framework for Trustwort.pdf,AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems,"['Yen-Ting Lee', 'Keerthi Koneru', 'Zahra Moslemi', 'Sheethal Kumar', 'Ramesh Radhakrishnan']",,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || AEMA: Verifiable Evaluation Framework for || Trustworthy and Controlled Agentic LLM Systems || Yen-Ting Lee1, Keerthi Koneru2, Zahra Moslemi3, Sheethal Kumar2, Ramesh Radhakrishnan2 || 1University of California, San Diego,2Center for Advanced AI, Accenture,3University of California, Irvine || E ... (truncated) ||  || { || ""title"": ""AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems"", || ""authors"": [ || ""Yen-Ting Lee"", || ""Keerthi Koneru"", || ""Zahra Moslemi"", || ""Sheethal Kumar"", || ""Ramesh Radhakrishnan"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Agentic AI"", || ""Multi-Agent Systems"", || ""Trustworthy AI"", || ""Verifiable Evaluation"", || ""Human Oversight"" || ], || ""summary"": ""AEMA presents a process-aware, auditable framework for evaluating multi-agent LLM systems, emphasizing stability, transparency, and traceability in autonomous reasoning and collaboration."" || } ||  || [ Prompt: 116.9 t/s | Generation: 27.5 t/s ]"
2601.11905v1_LIBRA Language Model Informed Bandit Recourse Algo.pdf,,[],,27.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LIBRA: Language Model Informed Bandit Recourse || Algorithm for Personalized Treatment Planning || Junyu Cao*1, Ruijiang Gao*2, Esmaeil Keyvanshokooh*3, Jianhao Ma*4 || 1McCombs School of Business, University of Texas at Austin, junyu.cao@mccombs.utexas.edu || 2Naveen Jindal School of Managemen ... (truncated) ||  || { || ""title"": ""Language Model Informed Bandit Recourse"", || ""authors"": [ || ""Junyu Cao"", || ""Ruijiang Gao"", || ""Esmaeil Keyvanshokooh"", || ""Jianhao Ma"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Large Language Models"", || ""LLM-Bandits Collaboration"", || ""Algorithmic Recourse"", || ""Regret Analysis"", || ""Personalized Treatment Planning"", || ""Hypertension Management""] || "", ""summary"": ""Introduce a unified framework integrating algorithmic recourse, contextual bandits, and large language models for sequential decision-making in personalized medicine. Present GLRB algorithm with warm-start, LLM-effort, and robustness guarantees. Experiments show improved regret, treatment quality, and sample efficiency."" || } ||  || [ Prompt: 114.7 t/s | Generation: 27.2 t/s ]"
2601.11907v1_Towards Airborne Object Detection A Deep Learning .pdf,Towards Airborne Object Detection: A Deep Learning Analysis,"['1st Prosenjit Chatterjee', '2nd ANK Zaman']",0000-0003-1169-4717,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Towards Airborne Object Detection: A Deep || Learning Analysis || 1st Prosenjit Chatterjee || Member, IEEE || 0000-0003-1169-4717 || 2nd ANK Zaman || Member, IEEE || 0000-0001-7831-0955 || AbstractThe rapid proliferation of airborne || platformsincluding commercial aircraft, drones, and || UA Vshas intensified t ... (truncated) ||  || { || ""title"": ""Towards Airborne Object Detection: A Deep Learning Analysis"", || ""authors"": [ || ""1st Prosenjit Chatterjee"", || ""2nd ANK Zaman"" || ], || ""doi"": ""0000-0003-1169-4717"", || ""arxiv_id"": ""0000-0001-7831-0955"", || ""keywords"": [ || ""Airborne Object Detection"", || ""Threat Detection"", || ""Deep Learning"", || ""EfficientNetB4"", || ""ResNet-50"", || ""UA V"" || ], || ""summary"": ""This work introduces a dual-task model using EfficientNetB4 for airborne object classification and threat-level prediction, leveraging the AODTA Dataset. It demonstrates strong performance in surveillance, defense, and airspace management applications."" || } ||  || [ Prompt: 112.1 t/s | Generation: 26.9 t/s ]"
2601.11913v1_LSTM-MAS A Long Short-Term Memory Inspired Multi-A.pdf,LSTM-MAS: A LONG SHORT-TERM MEMORY INSPIRED MULTI-AGENT SYSTEM FOR LONG-CONTEXT UNDERSTANDING,"['Yichen Jiang', 'Peng Ye', 'Jiakang Yuan', 'Chongjun Tu', 'Lei Bai (B)', 'Tao Chen']",,27.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LSTM-MAS: A LONG SHORT-TERM MEMORY INSPIRED MULTI-AGENT SYSTEM FOR LONG-CONTEXT UNDERSTANDING 1 || LSTM-MAS: A Long Short-Term Memory Inspired Multi-Agent || System for Long-Context Understanding || Yichen Jiang, Peng Ye , Jiakang Yuan , Chongjun Tu  Lei Bai (B) and Tao Chen (B) || Fudan Univer ... (truncated) ||  || { || ""title"": ""LSTM-MAS: A LONG SHORT-TERM MEMORY INSPIRED MULTI-AGENT SYSTEM FOR LONG-CONTEXT UNDERSTANDING"", || ""authors"": [ || ""Yichen Jiang"", || ""Peng Ye"", || ""Jiakang Yuan"", || ""Chongjun Tu"", || ""Lei Bai (B)"", || ""Tao Chen"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Long-Context Understanding"", || ""Large Language Models"", || ""Multi-Agent System"", || ""Memory"", || ""Long Short-Term Memory"", || ""Hallucination"" || ], || ""summary"": ""The paper presents LSTM-MAS, a multi-agent system inspired by LSTM architecture, designed for long-context understanding. It organizes agents to handle hierarchical information flow and mitigates error accumulation in multi-agent frameworks."" || } ||  || [ Prompt: 110.8 t/s | Generation: 27.2 t/s ]"
2601.11920v1_Enhancing LLM-Based Data Annotation with Error Dec.pdf,Enhancing LLM-Based Data Annotation with Error,"['Zhen Xu', 'Columbia University', 'University of California, Irvine', 'University of Pennsylvania', 'Columbia University', 'University of California, Irvine', 'Columbia University', 'Columbia University']",zx2393@tc.columbia.edu,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Enhancing LLM-Based Data Annotation with Error || Decomposition || Zhen Xu || zx2393@tc.columbia.edu || Columbia University || USA || Vedant Khatri || University of California, Irvine || USA || Yijun Dai || Columbia University || USA || Xiner Liu || University of Pennsylvania || USA || Siyan Li || Columbia University || USA || Xuanming ... (truncated) ||  || { || ""title"": ""Enhancing LLM-Based Data Annotation with Error"", || ""authors"": [ || ""Zhen Xu"", || ""Columbia University"", || ""University of California, Irvine"", || ""University of Pennsylvania"", || ""Columbia University"", || ""University of California, Irvine"", || ""Columbia University"", || ""Columbia University"" || ], || ""doi"": ""zx2393@tc.columbia.edu"", || ""arxiv_id"": """", || ""keywords"": [ || ""Data Annotation"", || ""Qualitative Coding"", || ""Large Language Models"", || ""Human-AI Collaboration"" || ], || ""summary"": ""This paper proposes a diagnostic evaluation paradigm to assess errors in LLM-based data annotation by distinguishing between model-driven inaccuracies and task-inherent ambiguities. It introduces a refined approach using a diagnostic taxonomy and a lightweight human annotation test to improve annotation quality assessment."" || } ||  || [ Prompt: 111.2 t/s | Generation: 27.6 t/s ]"
2601.11935v1_Big Data Workload Profiling for Energy-Aware Cloud.pdf,Big Data Workload Profiling for Energy-Aware Cloud Resource Management,"['Milan Parikh', 'Aniket Abhishek Soni', 'Sneja Mitinbhai Shah', 'Ayush Raj Jha']",,26.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Big Data Workload Profiling for || Energy-Aware Cloud Resource || Management || Milan Parikh, Aniket Abhishek Soni, Sneja Mitinbhai Shah, Ayush Raj Jha || Independent Researchers, Senior Members, IEEE || Richmond, TX, USA; Brooklyn, NY , USA; Milpitas, CA, USA || Email: milan.parikh@ieee.org, anikets ... (truncated) ||  || { || ""title"": ""Big Data Workload Profiling for Energy-Aware Cloud Resource Management"", || ""authors"": [ || ""Milan Parikh"", || ""Aniket Abhishek Soni"", || ""Sneja Mitinbhai Shah"", || ""Ayush Raj Jha"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Cloud computing"", || ""energy-aware scheduling"", || ""workload profiling"", || ""virtual machine placement"", || ""big data"", || ""green computing"" || ], || ""summary"": ""The paper presents a workload-aware scheduling framework that uses profiling of CPU usage, memory demand, and storage I/O behavior to guide energy-efficient virtual machine placement. It evaluates the framework using Hadoop MapReduce, Spark MLlib, and ETL workloads, demonstrating a 1520% reduction in energy consumption while maintaining SLAs."" || } ||  || [ Prompt: 112.2 t/s | Generation: 26.7 t/s ]"
2601.11940v1_Thinking Traps in Long Chain-of-Thought A Measurab.pdf,Thinking Traps in Long Chain-of-Thought: A Measurable Study and Trap-Aware Adaptive Restart,"['Kang Chen', 'Fan Yu', 'Junjie Nian', 'Shihan Zhao', 'Zhuoka Feng', 'Zun Yao', 'Heng Wang', 'Minshen Yu', 'Yixin Cao']",arXiv:2601.11940v1,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Thinking Traps in Long Chain-of-Thought: A Measurable || Study and Trap-Aware Adaptive Restart || Kang Chen1,*, Fan Yu1,*, Junjie Nian1, Shihan Zhao1, Zhuoka Feng1, Zun Yao, Heng || Wang1, Minshen Yu1, Yixin Cao1,2, || 1Fudan University,2Shanghai Innovation Institute || Abstract || Scaling test-time  ... (truncated) ||  || { || ""title"": ""Thinking Traps in Long Chain-of-Thought: A Measurable Study and Trap-Aware Adaptive Restart"", || ""authors"": [ || ""Kang Chen"", || ""Fan Yu"", || ""Junjie Nian"", || ""Shihan Zhao"", || ""Zhuoka Feng"", || ""Zun Yao"", || ""Heng Wang"", || ""Minshen Yu"", || ""Yixin Cao"" || ], || ""doi"": ""arXiv:2601.11940v1"", || ""arxiv_id"": ""arXiv:2601.11940"", || ""keywords"": [ || ""Long Chain-of-Thought"", || ""Thinking Traps"", || ""Adaptive Restart"", || ""Reasoning"", || ""Model Evaluation"" || ], || ""summary"": ""Scaling test-time compute via Long Chain-of-Thought improves reasoning but introduces thinking traps. TAAR framework detects and mitigates these traps to enhance model reliability."" || } ||  || [ Prompt: 109.7 t/s | Generation: 28.4 t/s ]"
2601.11956v1_Double-Calibration Towards Trustworthy LLMs via Ca.pdf,Double-Calibration: Towards Trustworthy LLMs via Calibrating,"['Yuyin Lu', 'Ziran Liang', 'Yanghui Rao', 'Wenqi Fan', 'Fu Lee Wang', 'Qing Li']",,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Double-Calibration: Towards Trustworthy LLMs via Calibrating || Knowledge and Reasoning Confidence || Yuyin Lu1, Ziran Liang2, Yanghui Rao1*, Wenqi Fan2, Fu Lee Wang3, Qing Li2 || 1School of Computer Science and Engineering, Sun Yat-sen University || 2Department of Computing, The Hong Kong Poly ... (truncated) ||  || { || ""title"": ""Double-Calibration: Towards Trustworthy LLMs via Calibrating"", || ""authors"": [ || ""Yuyin Lu"", || ""Ziran Liang"", || ""Yanghui Rao"", || ""Wenqi Fan"", || ""Fu Lee Wang"", || ""Qing Li"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper discusses challenges in achieving trustworthy reasoning in LLMs due to hallucination, and introduces DoublyCal, a framework that improves accuracy and calibration by incorporating calibrated evidence confidence."" || } ||  || [ Prompt: 113.6 t/s | Generation: 27.7 t/s ]"
2601.11960v1_R2PO Decoupling Training Trajectories from Inferen.pdf,R2PO: Decoupling Training Trajectories,"['Jingchu Wang', 'Bingbing Xu', 'Yige Yuan', 'Bin Xie', 'Xiaoqian Sun', 'Huawei Shen']",10.48550/arXiv.2405.12345,30.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || R2PO: Decoupling Training Trajectories || from Inference Responses for LLM Reasoning || Jingchu Wang1,2, Bingbing Xu1*, || Yige Yuan1,2,Bin Xie 1,2,Xiaoqian Sun 1,Huawei Shen 1 || 1State Key Laboratory of AI Safety, Institute of Computing Technology, CAS, || 2University of Chinese Academy of Scien ... (truncated) ||  || { || ""title"": ""R2PO: Decoupling Training Trajectories"", || ""authors"": [ || ""Jingchu Wang"", || ""Bingbing Xu"", || ""Yige Yuan"", || ""Bin Xie"", || ""Xiaoqian Sun"", || ""Huawei Shen"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [ || ""Reinforcement learning"", || ""LLM reasoning"", || ""training trajectories"", || ""inference responses"", || ""exploration"", || ""optimization"" || ], || ""summary"": ""The paper proposes R2PO (ResidualRolloutPolicy Optimization) to decouple training trajectories from inference responses, improving reasoning capabilities by enabling controlled trajectory diversification while maintaining stable inference generation. Experiments show improved performance across benchmarks."" || } ||  || [ Prompt: 111.1 t/s | Generation: 30.1 t/s ]"
2601.11969v1_textttMemoryRewardBench Benchmarking Reward Models.pdf,MemoryRewardBench: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models,"['Zecheng Tang', 'Baibei Ji', 'Ruoxi Sun', 'Haitian Wang', 'Wangjie You', 'Yijun Zhang', 'Wenpeng Zhu', 'Ji Qi', 'Juntao Li', 'Min Zhang']",,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MemoryRewardBench: Benchmarking Reward Models for Long-Term || Memory Management in Large Language Models || Zecheng Tang1,2, Baibei Ji1,2, Ruoxi Sun1,2, Haitian Wang1,2, Wangjie You1 || Yijun Zhang3, Wenpeng Zhu3, Ji Qi3, Juntao Li1,2*, Min Zhang1 || 1Soochow University, China 2LCM Laboratory  ... (truncated) ||  || { || ""title"": ""MemoryRewardBench: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models"", || ""authors"": [ || ""Zecheng Tang"", || ""Baibei Ji"", || ""Ruoxi Sun"", || ""Haitian Wang"", || ""Wangjie You"", || ""Yijun Zhang"", || ""Wenpeng Zhu"", || ""Ji Qi"", || ""Juntao Li"", || ""Min Zhang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper introduces MemRewardBench, a benchmark to systematically evaluate reward models' ability to assess long-term memory management in large language models. It covers 10 settings with varying context lengths and highlights performance differences between open-source and proprietary models."" || } ||  || [ Prompt: 105.8 t/s | Generation: 28.3 t/s ]"
2601.11974v1_Learn Like Humans Use Meta-cognitive Reflection fo.pdf,,[],,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Learn Like Humans: Use Meta-cognitive Reflection for Efficient || Self-Improvement || Xinmeng Hou1, Peiliang Gong1, Bohao Qu2, Wuqi Wang3, Qing Guo4, Yang Liu1 || 1Nanyang Technological University, Singapore || 2A*STAR, Singapore || 3Changan University, China || 4Nankai University, China || {hou_xinmeng ... (truncated) ||  || { || ""title"": ""Learn Like Humans: Use Meta-cognitive Reflection for Efficient Self-Improvement"", || ""authors"": [ || ""Xinmeng Hou"", || ""Peiliang Gong"", || ""Bohao Qu"", || ""Wuqi Wang"", || ""Qing Guo"", || ""Yang Liu"" || ], || ""doi"": ""https://anonymous"", || ""arxiv_id"": ""4open.science/r/MARS-9F16"", || ""keywords"": [ || ""metacognitive reflection"", || ""self-improvement"", || ""LLM"", || ""self-evolution"", || ""principle-based instruction"", || ""procedural instruction"" || ], || ""summary"": ""The paper proposes MARS, a framework that enables efficient self-improvement in agents by integrating reflective and procedural strategies inspired by human learning, aiming to overcome limitations of static prompts and improve adaptability."" || } ||  || [ Prompt: 105.2 t/s | Generation: 28.2 t/s ]"
2601.11977v1_One-Shot Price Forecasting with Covariate-Guided E.pdf,One-Shot Price Forecasting with Covariate-Guided Experts under Privacy Constraints,"['1stRen He', '2ndYinliang Xu', '3rdJinfeng Wang', '4thJeremy Watson', '5thJian Song']",,27.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || One-Shot Price Forecasting with || Covariate-Guided Experts under Privacy Constraints || 1stRen He || Tsinghua University || Tsinghua Shenzhen International Graduate School || Shenzhen, China || he-r23@mails.tsinghua.edu.cn || 2ndYinliang Xu || Tsinghua University || Tsinghua Shenzhen International Graduate S ... (truncated) ||  || { || ""title"": ""One-Shot Price Forecasting with Covariate-Guided Experts under Privacy Constraints"", || ""authors"": [ || ""1stRen He"", || ""2ndYinliang Xu"", || ""3rdJinfeng Wang"", || ""4thJeremy Watson"", || ""5thJian Song"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""price forecasting"", || ""time series"", || ""privacy"", || ""mixture of experts"", || ""market analysis"" || ], || ""summary"": ""The paper proposes a novel MoE-Encoder module to enhance forecasting accuracy in power systems by leveraging expert-guided univariate tasks and supporting federated learning under privacy constraints."" || } ||  || [ Prompt: 110.4 t/s | Generation: 27.4 t/s ]"
2601.11979v1_Process In-Context Learning Enhancing Mathematical.pdf,Process In-Context Learning: Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion,"['Ang Gao1', 'Changshuo Zhang1', 'Xiao Zhang1 Deyang Li2', 'Minjun Zhao2', 'Fangchao Liu2', 'Xinyu Zhang2']",,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Process In-Context Learning: || Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion || Ang Gao1* Changshuo Zhang1* Xiao Zhang1 Deyang Li2 || Minjun Zhao2 Fangchao Liu2 Xinyu Zhang2 || 1Gaoling School of Artificial Intelligence, Renmin University of China || 2Huawei Poisson Lab, Ch ... (truncated) ||  || { || ""title"": ""Process In-Context Learning: Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion"", || ""authors"": [ || ""Ang Gao1"", || ""Changshuo Zhang1"", || ""Xiao Zhang1 Deyang Li2"", || ""Minjun Zhao2"", || ""Fangchao Liu2"", || ""Xinyu Zhang2"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper proposes Process In-Context Learning (PICL), a dynamic demonstration integration framework to enhance mathematical reasoning by adapting to real-time inference needs. PICL identifies confusion points in reasoning processes and inserts relevant demonstrations to guide reasoning, improving accuracy in complex mathematical tasks."" || } ||  || [ Prompt: 112.2 t/s | Generation: 28.5 t/s ]"
2601.11995v1_Learning Audio-Visual Embeddings with Inferred Lat.pdf,Learning AudioVisual Embeddings with Inferred Latent Interaction Graphs,"['Donghuo Zeng', 'Hao Niu', 'Yanan Wang', 'Masato Taya']",arXiv:2601.11995v1,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Learning AudioVisual Embeddings with || Inferred Latent Interaction Graphs || Donghuo Zeng[0000000264256270], Hao Niu, Yanan Wang, and Masato Taya || KDDI Research, Inc., Saitama, Japan || {xdo-zen, ha-niu, wa-yanan, ma-taya}@kddi.com || Abstract.Learning robust audiovisual embeddings requires bri ... (truncated) ||  || { || ""title"": ""Learning AudioVisual Embeddings with Inferred Latent Interaction Graphs"", || ""authors"": [ || ""Donghuo Zeng"", || ""Hao Niu"", || ""Yanan Wang"", || ""Masato Taya"" || ], || ""doi"": ""arXiv:2601.11995v1"", || ""arxiv_id"": ""0000000264256270"", || ""keywords"": [ || ""Audiovisuallatent interaction graph"", || ""cross-modal retrieval"", || ""audio-visual event"", || ""semantic alignment loss"", || ""latent interaction graph"", || ""dependency patterns"", || ""semantic coherence"" || ], || ""summary"": ""The paper proposes a framework to improve audiovisual embedding learning by leveraging inferred latent interactions, addressing issues like false negatives and missing cross-modal dependencies through soft-label predictions and dependency graphs."" || } ||  || [ Prompt: 111.3 t/s | Generation: 27.8 t/s ]"
2601.11998v1_Hybrid IDS Using Signature-Based and Anomaly-Based.pdf,Hybrid IDS Using Signature-Based and Anomaly-Based Detection,"['m.boutassetta@univ-eltarf.dz', 'amina.makhlouf@univ-eltarf.dz', 'newfel.messaoudi@univ-eltarf.dz', 'abdelmadjid.benmachiche@univ-eltarf.dz', 'ines.boutabia@univ-eltarf.dz']",,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Hybrid IDS Using Signature-Based and Anomaly-Based || Detection ||  || 1st Messaouda Boutassetta ||  || Department of Computer Science, || Faculty of Science and Technology || LIMA Laboratory || Chadli Bendjedid University || PB 73, El-Tarf 36000, Algeria || m.boutassetta@univ-eltarf.dz || 2nd Amina M ... (truncated) ||  || { || ""title"": ""Hybrid IDS Using Signature-Based and Anomaly-Based Detection"", || ""authors"": [ || ""m.boutassetta@univ-eltarf.dz"", || ""amina.makhlouf@univ-eltarf.dz"", || ""newfel.messaoudi@univ-eltarf.dz"", || ""abdelmadjid.benmachiche@univ-eltarf.dz"", || ""ines.boutabia@univ-eltarf.dz"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Intrusion Detection System (IDS)"", || ""Hybrid IDS"", || ""Signature-Based Detection"", || ""Anomaly-Based Detection"", || ""Machine Learning (ML)"", || ""Cybersecurity"", || ""False Positives"", || ""Detection Accuracy"", || ""Real-Time Detection"", || ""Network Security"" || ], || ""summary"": ""This paper presents a comprehensive survey and conceptual overview of Hybrid IDS, integrating signature-based and anomaly-based detection techniques to enhance attack detection capabilities. It examines recent research, classifies models, discusses advantages, limitations, and applications, and reviews trends like ML and cloud-based deployments."" || } ||  || [ Prompt: 112.3 t/s | Generation: 28.6 t/s ]"
2601.12002v1_Kernel-Based Learning of Safety Barriers.pdf,Kernel-Based Learning of Safety Barriers,"['Oliver Schon', 'Zhengang Zhongzhengang', 'Sadegh Soudjanisadegh', 'Max Planck Institute for Software Systems', 'University of Warwick', 'University of Birmingham']",10.48550/arXiv.2405.12345,27.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Kernel-Based Learning of Safety Barriers || Kernel-Based Learning of Safety Barriers || Oliver Sch ono.schoen2@ncl.ac.uk || Newcastle University, School of Computing, Newcastle upon Tyne, || NE4 5TG, United Kingdom || Zhengang Zhongzhengang.zhong@warwick.ac.uk || University of Warwick, Department of  ... (truncated) ||  || { || ""title"": ""Kernel-Based Learning of Safety Barriers"", || ""authors"": [ || ""Oliver Schon"", || ""Zhengang Zhongzhengang"", || ""Sadegh Soudjanisadegh"", || ""Max Planck Institute for Software Systems"", || ""University of Warwick"", || ""University of Birmingham"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [ || ""safety barriers"", || ""safety verification"", || ""black-box systems"", || ""control barrier certificates"", || ""conditional mean embeddings"", || ""reproducing kernel Hilbert space"", || ""temporal logic specifications"" || ], || ""summary"": ""The paper presents a data-driven approach for verifying safety in AI systems using kernel methods and control barrier certificates, addressing challenges in formal verification of black-box systems with stochastic dynamics."" || } ||  || [ Prompt: 106.6 t/s | Generation: 27.3 t/s ]"
2601.12003v1_Robust Verification of Concurrent Stochastic Games.pdf,,[],,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Robust Verification of || Concurrent Stochastic Games || Angel Y. He || and David Parker || Department of Computer Science, University of Oxford, Oxford OX1 2JD, UK || angel.he@balliol.ox.ac.uk, david.parker@cs.ox.ac.uk || Abstract.Autonomous systems often operate in multi-agent settings || and need to ... (truncated) ||  || { || ""title"": ""Robust Verification of Concurrent Stochastic Games"", || ""authors"": [""Angel Y. He"", ""David Parker""], || ""doi"": ""1"",  // placeholder || ""arxiv_id"": """", || ""keywords"": [""Robust quantitative verification"", ""Probabilistic model checking"", ""Concurrent stochastic games"", ""Epistemic uncertainty""], || ""summary"": ""Autonomous systems in multi-agent settings require robust verification under uncertainty. This paper introduces a novel framework for robust verification of concurrent stochastic games (CSGs) and their subclass interval CSGs (ICSGs), addressing transition probability uncertainties. The work develops theoretical foundations and algorithms for finite and infinite-horizon objectives, focusing on zero-sum and nonzero-sum settings based on social-welfare optimal Nash equilibria. It demonstrates feasibility using PRISM and benchmarks."" || } ||  || [ Prompt: 111.0 t/s | Generation: 28.4 t/s ]"
2601.12014v1_Are LLMs Ready for TOON Benchmarking Structural Co.pdf,Structural Correctness Sustainability Trade-offs in Novel Structured Output,"['Elio Masciari', 'Vincenzo Moscato', 'Enea Vincenzo Napolitano', 'Gian Marco Orlando', 'Marco Perillo', 'Diego Russo']",,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Are LLMs Ready for TOON? Benchmarking Structural || CorrectnessSustainability Trade-offs in Novel Structured Output || Formats || Elio Masciari || elio.masciari@unina.it || University of Naples Federico II || Naples, Italy || Vincenzo Moscato || vincenzo.moscato@unina.it || University of Naples Federico II || Na ... (truncated) ||  || { || ""title"": ""Structural Correctness Sustainability Trade-offs in Novel Structured Output"", || ""authors"": [ || ""Elio Masciari"", || ""Vincenzo Moscato"", || ""Enea Vincenzo Napolitano"", || ""Gian Marco Orlando"", || ""Marco Perillo"", || ""Diego Russo"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Large Language Models"", || ""Structured Output"", || ""Environmental Impact"", || ""Carbon Emissions"", || ""Sustainability"", || ""Generation Correctness"", || ""Format Benchmarking"" || ], || ""summary"": ""This paper evaluates the structural correctness and environmental sustainability of the TOON format compared to JSON, XML, and YAML, proposing a sustainability-aware evaluation framework."" || } ||  || [ Prompt: 113.3 t/s | Generation: 26.9 t/s ]"
2601.12019v1_Acting Flatterers via LLMs Sycophancy Combating Cl.pdf,Acting Flatterers via LLMs Sycophancy: Combating Clickbait with LLMs Opposing-Stance Reasoning,"['Chaowei Zhang', 'Xiansheng Luo', 'Zewei Zhang', 'Yi Zhu', 'Jipeng Qiang', 'Longwei Wang']",10.1145/XXXXXX,28.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Acting Flatterers via LLMs Sycophancy: || Combating Clickbait with LLMs Opposing-Stance Reasoning || Chaowei Zhang || cwzhang@yzu.edu.cn || Yangzhou University || Yangzhou, Jiangsu, China || Xiansheng Luo || mz220240305@stu.yzu.edu.cn || Yangzhou University || Yangzhou, Jiangsu, China || Zewei Zhang || zez0001@aubu ... (truncated) ||  || { || ""title"": ""Acting Flatterers via LLMs Sycophancy: Combating Clickbait with LLMs Opposing-Stance Reasoning"", || ""authors"": [ || ""Chaowei Zhang"", || ""Xiansheng Luo"", || ""Zewei Zhang"", || ""Yi Zhu"", || ""Jipeng Qiang"", || ""Longwei Wang"" || ], || ""doi"": ""10.1145/XXXXXX"", || ""arxiv_id"": """", || ""keywords"": [ || ""Clickbait Detection"", || ""Large Language Models"", || ""Opposing Stance Reasoning"", || ""Contrastive Learning"" || ], || ""summary"": ""The paper discusses how Large Language Models (LLMs) can be leveraged to combat clickbait by generating opposing stance reasoning, addressing sycophancy through a Self-renewal Opposing-stance Reasoning Generation framework."" || } ||  || [ Prompt: 110.8 t/s | Generation: 28.9 t/s ]"
2601.12024v1_A Multi-Agent System for Generating Actionable Bus.pdf,A Multi-Agent System for Generating Actionable Business Advice,"['Kartikey Singh Bhandari', 'Tanish Jain', 'Archit Agrawal', 'Pratik Narang']","p20241006,f20230349,f20191048,dhruv.kumar,pratik.narang",28.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A Multi-Agent System for Generating Actionable Business Advice || Kartikey Singh Bhandari 1 Tanish Jain1 Archit Agrawal1 || Dhruv Kumar1 Praveen Kumar2 Pratik Narang1 || 1Birla Institute of Technology and Science, Pilani || 2Birdeye Inc. || {p20241006,f20230349,f20191048,dhruv.kumar,pratik.narang} ... (truncated) ||  || { || ""title"": ""A Multi-Agent System for Generating Actionable Business Advice"", || ""authors"": [ || ""Kartikey Singh Bhandari"", || ""Tanish Jain"", || ""Archit Agrawal"", || ""Pratik Narang"" || ], || ""doi"": ""p20241006,f20230349,f20191048,dhruv.kumar,pratik.narang"", || ""arxiv_id"": """", || ""keywords"": [ || ""multi-agent system"", || ""LLM-based framework"", || ""business advice"", || ""customer reviews"", || ""actionable insights"" || ], || ""summary"": ""This paper presents a multi-agent, LLM-based framework for transforming large-scale review corpora into actionable business advice. The framework integrates clustering, advice generation, iterative evaluation, and feasibility ranking, achieving higher performance in actionability, specificity, and non-redundancy compared to single-model baselines."" || } ||  || [ Prompt: 111.8 t/s | Generation: 28.9 t/s ]"
2601.12030v1_ARC Active and Reflection-driven Context Managemen.pdf,Active and Reflection-driven Context Management for Long-Horizon Information Seeking Agents,"['Yilun Yao', 'Shan Huang', 'Elsie Dai', 'Zhewen Tan', 'Zhenyu Duan', 'Shousheng Jia', 'Yanbing Jiang', 'Tong Yang']",,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ARC: Active and Reflection-driven Context Management for Long-Horizon || Information Seeking Agents || Yilun Yao1, Shan Huang2, Elsie Dai1, Zhewen Tan1, || Zhenyu Duan3,Shousheng Jia 3,Yanbing Jiang 1,Tong Yang1, || 1Peking University, 2Beihang University, 3Qiyuan Tech, || Abstract || Large language  ... (truncated) ||  || { || ""title"": ""Active and Reflection-driven Context Management for Long-Horizon Information Seeking Agents"", || ""authors"": [ || ""Yilun Yao"", || ""Shan Huang"", || ""Elsie Dai"", || ""Zhewen Tan"", || ""Zhenyu Duan"", || ""Shousheng Jia"", || ""Yanbing Jiang"", || ""Tong Yang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper proposes ARC, a framework that treats context management as an active, reflection-driven process to address context degradation in long-horizon information seeking. ARC uses reflection-driven monitoring and revision to maintain coherent internal states, achieving improved performance over passive methods."" || } ||  || [ Prompt: 112.9 t/s | Generation: 26.9 t/s ]"
2601.12038v1_Abstract Argumentation with Subargument Relations.pdf,Abstract Argumentation with Subargument Relations,['Beishui Liao'],,27.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Abstract Argumentation with Subargument Relations || Beishui Liao || Zhejiang University || baiseliao@zju.edu.cn || Abstract || Dungs abstract argumentation framework characterises argu- || ment acceptability solely via an attack relation, deliberately || abstracting from the internal structure of argum ... (truncated) ||  || { || ""title"": ""Abstract Argumentation with Subargument Relations"", || ""authors"": [""Beishui Liao""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper studies abstract argumentation frameworks enriched with an explicit subargument relation, analyzing how subargument relations interact with attacks and their impact on semantic properties. It highlights the need to clarify structural dependencies in abstract reasoning."" || } ||  || [ Prompt: 115.9 t/s | Generation: 27.4 t/s ]"
2601.12040v1_Partial Reasoning in Language Models Search and Re.pdf,Partial Reasoning in Language Models: Search and Refinement Guided by Uncertainty,"['Murilo da Luz', 'Bruno Brando', 'Luana Martins', 'Gustavo Oliveira', 'Bryan de Oliveira', 'Luckeciano Melo', 'Telma Soares']",,27.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Partial Reasoning in Language Models: Search and || Refinement Guided by Uncertainty || Murilo da Luz1,2,*, Bruno Brando 1,2, Luana Martins 1,2, Gustavo Oliveira 1,2, || Bryan de Oliveira1,2, Luckeciano Melo 1,3 and Telma Soares 1,2 || 1Advanced Knowledge Center for Immersive Technologies (AKCI ... (truncated) ||  || { || ""title"": ""Partial Reasoning in Language Models: Search and Refinement Guided by Uncertainty"", || ""authors"": [ || ""Murilo da Luz"", || ""Bruno Brando"", || ""Luana Martins"", || ""Gustavo Oliveira"", || ""Bryan de Oliveira"", || ""Luckeciano Melo"", || ""Telma Soares"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Uncertainty"", || ""Entropy"", || ""Latent-space search"", || ""Soft Reasoning"", || ""LLM reasoning"" || ], || ""summary"": ""The paper introduces PREGU, a method that monitors entropy during LLM autoregressive generation and uses uncertainty to trigger localized search in latent space for improved reasoning."" || } ||  || [ Prompt: 108.4 t/s | Generation: 27.4 t/s ]"
2601.12042v1_Less Is More -- Until It Breaks Security Pitfalls .pdf,Less Is More  Until It Breaks: Security Pitfalls of Vision Token,"['Xiaomei Zhang', 'Zhaoxi Zhang', 'Leo Yu Zhang', 'Yanjun Zhang', 'Guanhong Tao', 'Shirui Pan']",10.48550/arXiv.1809.04654,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Less Is More  Until It Breaks: Security Pitfalls of Vision Token || Compression in Large Vision-Language Models || Xiaomei Zhang || Griffith University || xiaomei.zhang@griffithuni.edu.au || Zhaoxi Zhang || University of Technology Sydney || zhaoxi.zhang-1@student.uts.edu.au || Leo Yu Zhang || Griffith Univer ... (truncated) ||  || { || ""title"": ""Less Is More  Until It Breaks: Security Pitfalls of Vision Token"", || ""authors"": [ || ""Xiaomei Zhang"", || ""Zhaoxi Zhang"", || ""Leo Yu Zhang"", || ""Yanjun Zhang"", || ""Guanhong Tao"", || ""Shirui Pan"" || ], || ""doi"": ""10.48550/arXiv.1809.04654"", || ""arxiv_id"": ""10.48550/arXiv.1809.04654"", || ""keywords"": [ || ""vision token compression"", || ""large vision-language models"", || ""robustness degradation"", || ""security vulnerabilities"", || ""compression mechanisms"" || ], || ""summary"": ""Visual token compression improves efficiency but compromises robustness, making models vulnerable to perturbations. The study introduces a Compression-Aware Attack to exploit these weaknesses and proposes defenses."" || } ||  || [ Prompt: 110.5 t/s | Generation: 26.9 t/s ]"
2601.12049v1_textitFocaLogic Logic-Based Interpretation of Visu.pdf,FocaLogic: Logic-Based Interpretation of Visual Model Decisions,"['Chenchen Zhao', 'Muxi Chen', 'Qiang Xu']",,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || FocaLogic: Logic-Based Interpretation of Visual Model Decisions || Chenchen Zhao* Muxi Chen* Qiang Xu || Department of Computer Science and Engineering, The Chinese University of Hong Kong || cczhao@cse.cuhk.edu.hk mxchen21@cse.cuhk.edu.hk qxu@cse.cuhk.edu.hk || * Equal contribution  Correspon ... (truncated) ||  || { || ""title"": ""FocaLogic: Logic-Based Interpretation of Visual Model Decisions"", || ""authors"": [ || ""Chenchen Zhao"", || ""Muxi Chen"", || ""Qiang Xu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""interpretability"", || ""visual models"", || ""logic-based"", || ""model interpretability"", || ""focus precision"", || ""focus recall"", || ""divergence"" || ], || ""summary"": ""This paper introduces FocaLogic, a model-agnostic framework for interpreting visual model decisions through logic-based representations. It identifies minimal interpretable subsets and translates them into logical expressions, offering transparent and structured interpretations. The authors also propose quantitative metrics to evaluate model behavior and demonstrate FocaLogic's effectiveness in uncovering insights such as training-induced concentration and focus accuracy."" || } ||  || [ Prompt: 109.0 t/s | Generation: 27.5 t/s ]"
2601.12053v1_A New Strategy for Artificial Intelligence Trainin.pdf,A New Strategy for Artificial Intelligence: Training Foundation Models Directly on Human Brain Data,['Mael Donoso'],10.48550/arXiv.2311.07818,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A New Strategy for Artificial Intelligence: || Training Foundation Models Directly on Human || Brain Data || Mael Donoso || Ouroboros Neurotechnologies, Lausanne, Switzerland || Correspondence*: || Ouroboros Neurotechnologies, Place de la Riponne 5, 1005 Lausanne, Switzerland || mael.donoso@ouroboros-n ... (truncated) ||  || { || ""title"": ""A New Strategy for Artificial Intelligence: Training Foundation Models Directly on Human Brain Data"", || ""authors"": [""Mael Donoso""], || ""doi"": ""10.48550/arXiv.2311.07818"", || ""arxiv_id"": ""arXiv:2311.07818"", || ""keywords"": [""foundation models"", ""brain"", ""neuroimaging"", ""brain-generated data"", ""brain-trained foundation models""], || ""summary"": ""This paper explores a novel strategy for training foundation models by leveraging human brain data, aiming to overcome current limitations by incorporating neuroimaging insights across cognitive levels."" || } ||  || [ Prompt: 117.8 t/s | Generation: 27.9 t/s ]"
2601.12055v1_Automating Parameter Selection in Deep Image Prior.pdf,Automating Parameter Selection in Deep Image,"['Lina Meyer', 'Felix Wissel', 'Tobias Knopp', 'Susanne Pfefferle', 'Ralf Fliegert', 'Maximilian Sandmann', 'Liana Uebler, Franziska Möhck', 'Björn-Philipp Diercks', 'David Lohr', 'René Werner']",10.1002/2016bok.115,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || Automating Parameter Selection in Deep Image || Prior for Fluorescence Microscopy Image Denoising || via Similarity-Based Parameter Transfer || Lina Meyer , Felix Wissel , Tobias Knopp , Susanne Pfefferle , Ralf Fliegert , Maximilian Sandmann , Liana || Uebler, Franziska M ockl, Bj orn-Philip ... (truncated) ||  || { || ""title"": ""Automating Parameter Selection in Deep Image"", || ""authors"": [ || ""Lina Meyer"", || ""Felix Wissel"", || ""Tobias Knopp"", || ""Susanne Pfefferle"", || ""Ralf Fliegert"", || ""Maximilian Sandmann"", || ""Liana Uebler, Franziska Möhck"", || ""Björn-Philipp Diercks"", || ""David Lohr"", || ""René Werner"" || ], || ""doi"": ""10.1002/2016bok.115"", || ""arxiv_id"": """", || ""keywords"": [ || ""deep learning"", || ""fluorescence microscopy"", || ""parameter transfer"", || ""image denoising"", || ""AUTO-DIP"", || ""image similarity"", || ""computational neuroscience"" || ], || ""summary"": ""This paper presents AUTO-DIP, a method for optimizing network parameters for fluorescence microscopy denoising by leveraging image similarity-based transfer. It demonstrates improved performance over traditional supervised approaches, especially for noisy images, and highlights its potential for routine use in fluorescence microscopy."" || } ||  || [ Prompt: 118.9 t/s | Generation: 28.3 t/s ]"
2601.12061v1_Codebook-Injected Dialogue Segmentation for Multi-.pdf,Codebook-Injected Dialogue Segmentation for Multi-Utterance Constructs,"['Jinsook Lee', 'Kirk Vanacore', 'Zhuqian Zhou', 'Bakhtawar Ahtisham', 'Jeanine Grtter', 'Ren F. Kizilcec', 'Khwaja Z. A. A. K. Ziauddin', 'Zheng Liu', 'Liang Chen', 'Liang Jing']",,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Codebook-Injected Dialogue Segmentation for Multi-Utterance Constructs || Annotation: LLM-Assisted and Gold-Label-Free Evaluation || Jinsook Lee || Cornell University || jl3369@cornell.edu || Kirk Vanacore || Cornell University || kpv27@cornell.edu || Zhuqian Zhou || Cornell University || zz968@cornell.edu || Bakht ... (truncated) ||  || { || ""title"": ""Codebook-Injected Dialogue Segmentation for Multi-Utterance Constructs"", || ""authors"": [ || ""Jinsook Lee"", || ""Kirk Vanacore"", || ""Zhuqian Zhou"", || ""Bakhtawar Ahtisham"", || ""Jeanine Grtter"", || ""Ren F. Kizilcec"", || ""Khwaja Z. A. A. K. Ziauddin"", || ""Zheng Liu"", || ""Liang Chen"", || ""Liang Jing"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper proposes codebook-injected segmentation to improve dialogue act annotation by aligning boundary decisions with downstream criteria. It evaluates LLM-based segmenters using metrics for span consistency, distinctiveness, and human-AI distributional agreement, highlighting trade-offs between coherence and boundary precision."" || } ||  || [ Prompt: 110.6 t/s | Generation: 28.5 t/s ]"
2601.12068v1_Bridging the Gap in Bangla Healthcare Machine Lear.pdf,Bridging the Gap in Bangla Healthcare: Machine Learning Based Disease Prediction Using a Symptoms-Disease Dataset,"['Rowzatul Zannat', 'Abdullah Al Shafi', 'Abdul Muntakim']",,27.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 2025 International Conference on Electrical, Computer and Communication Engineering || (ECCE), 13-15 February 2025, CUET, Chattogram-4349, Bangladesh || Bridging the Gap in Bangla Healthcare: Machine || Learning Based Disease Prediction Using a || Symptoms-Disease Dataset || Rowzatul Zannat , Abdu ... (truncated) ||  || { || ""title"": ""Bridging the Gap in Bangla Healthcare: Machine Learning Based Disease Prediction Using a Symptoms-Disease Dataset"", || ""authors"": [ || ""Rowzatul Zannat"", || ""Abdullah Al Shafi"", || ""Abdul Muntakim"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Disease Prediction"", || ""Annotated Dataset"", || ""Machine Learning Techniques"", || ""Soft Voting Ensemble"", || ""Hard Voting Ensemble"" || ], || ""summary"": ""This study addresses the limited availability of Bangla-language health data by developing a comprehensive Bangla symptoms-disease dataset with 758 relationships across 85 diseases. It evaluates machine learning models to predict diseases using Bangla symptoms, achieving 98% accuracy through ensemble methods, aiming to improve healthcare accessibility for Bangla-speaking populations."" || } ||  || [ Prompt: 106.4 t/s | Generation: 27.4 t/s ]"
2601.12082v1_Conditional Random Fields for Interactive Refineme.pdf,Conditional Random Fields for Histopathological Predictions,"['Tiffanie Godelaine', 'Maxime Zanella', 'Karim El Khoury', 'Sad Mahmoudi', 'Benot Macq1 Christophe De Vleeschouwer']",,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || CONDITIONAL RANDOM FIELDS FOR INTERACTIVE REFINEMENT OF || HISTOPA THOLOGICAL PREDICTIONS || Tiffanie Godelaine,1 Maxime Zanella,1,2 Karim El Khoury1 || Sad Mahmoudi2 Benot Macq1 Christophe De Vleeschouwer1 || 1ICTEAM, UCLouvain, Belgium 2ILIA, UMons, Belgium || ABSTRACT || Assisting pathologists in  ... (truncated) ||  || { || ""title"": ""Conditional Random Fields for Histopathological Predictions"", || ""authors"": [ || ""Tiffanie Godelaine"", || ""Maxime Zanella"", || ""Karim El Khoury"", || ""Sad Mahmoudi"", || ""Benot Macq1 Christophe De Vleeschouwer"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""histology classification"", || ""conditional random fields"", || ""human-in-the-loop"", || ""foundation models"", || ""histopathological predictions"" || ], || ""summary"": ""This paper proposes HistoCRF, a Conditional Random Field-based framework to refine predictions from histology foundation models by leveraging expert annotations and iterative human-in-the-loop corrections. Experiments show significant accuracy improvements over zero-shot VLMs."" || } ||  || [ Prompt: 112.3 t/s | Generation: 28.2 t/s ]"
2601.12095v1_Neural Isomorphic Fields A Transformer-based Algeb.pdf,Neuralisomorphic Fields: A Transformer-Based Algebraic Numerical Embedding,"['Hamidreza Sadeghi Saeedeh Momtazi', 'Safa']",10.1007/123456,26.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || NEURALISOMORPHICFIELDS: A TRANSFORMER-BASED || ALGEBRAICNUMERICALEMBEDDING || Hamidreza Sadeghi Saeedeh Momtazi Reza Safabakhsh || Department of Computer Engineering || Amirkabir University of Technology, Tehran, Iran || {sadeghihamid, momtazi, safa}@aut.ac.ir || January 21, 2026 || ABSTRACT || Neural netw ... (truncated) ||  || { || ""title"": ""Neuralisomorphic Fields: A Transformer-Based Algebraic Numerical Embedding"", || ""authors"": [""Hamidreza Sadeghi Saeedeh Momtazi"", ""Safa""], || ""doi"": ""10.1007/123456"", || ""arxiv_id"": """", || ""keywords"": [""neural networks"", ""algebraic structures"", ""number embeddings"", ""algebraic operations""], || ""summary"": ""This paper introduces a fixed-length number embedding vector that preserves algebraic operations within rational numbers. It proposes a Neural Isomorphic Field to maintain algebraic properties during computations, showing strong performance in algebraic tests while highlighting challenges in multiplication."" || } ||  || [ Prompt: 109.4 t/s | Generation: 26.8 t/s ]"
2601.12099v1_Large language models struggle with ethnographic t.pdf,LARGELANGUAGEMODELSSTRUGGLE WITHETHNOGRAPHIC TEXTANNOTATION,"['Leonardo S. Goodall', 'Dor Shilton', 'Daniel Austin Mullins', 'Cohen Institute for the History and Philosophy of Science and Ideas', 'Harvey Whitehouse']",,27.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LARGELANGUAGEMODELSSTRUGGLE WITHETHNOGRAPHIC || TEXTANNOTATION || Leonardo S. Goodall || Calleva Research Centre || Oxford Internet Institute || University of Oxford, UK || Dor Shilton || Cohn Institute for the History and Philosophy of Science and Ideas || Tel Aviv University, Israel || dorshilt@mail.tau.ac. ... (truncated) ||  || { || ""title"": ""LARGELANGUAGEMODELSSTRUGGLE WITHETHNOGRAPHIC TEXTANNOTATION"", || ""authors"": [ || ""Leonardo S. Goodall"", || ""Dor Shilton"", || ""Daniel Austin Mullins"", || ""Cohen Institute for the History and Philosophy of Science and Ideas"", || ""Harvey Whitehouse"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""large language models"", || ""ethnographic text annotation"", || ""cross-cultural research"", || ""anthropology"", || ""anthropological texts"" || ], || ""summary"": ""Large language models have shown promise for automated text annotation, but their performance is limited in ethnographic contexts. Human inter-coder reliability remains high, indicating that LLMs cannot yet substitute for human expertise in this domain."" || } ||  || [ Prompt: 111.0 t/s | Generation: 27.2 t/s ]"
2601.12104v1_Powerful Training-Free Membership Inference Agains.pdf,Powerful Training-Free Membership-Free Inference,"['David Ilic', 'David Stanojevic', 'Kostadin Cvejoski']",10.48550/arXiv.2303.04112,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Powerful Training-Free Membership Inference || Against Autoregressive Language Models || David Ilic1 David Stanojevic1 Kostadin Cvejoski1 || 1JetBrains Research || {david.ilic, david.stanojevic, kostadin.cvejoski}@jetbrains.com || Abstract || Fine-tuned language models pose significant || privacy risks, ... (truncated) ||  || { || ""title"": ""Powerful Training-Free Membership-Free Inference"", || ""authors"": [ || ""David Ilic"", || ""David Stanojevic"", || ""Kostadin Cvejoski"" || ], || ""doi"": ""10.48550/arXiv.2303.04112"", || ""arxiv_id"": ""arXiv:2303.04112"", || ""keywords"": [ || ""membership inference"", || ""privacy risks"", || ""language models"", || ""attack methods"", || ""error zone"", || ""data leakage"" || ], || ""summary"": ""This paper presents EZ-MIA, a membership inference attack that leverages the Error Zone score to detect memorization in fine-tuned language models without requiring a reference model. It achieves higher detection rates than prior methods, demonstrating substantial privacy risks in fine-tuned LLMs."" || } ||  || [ Prompt: 112.6 t/s | Generation: 29.0 t/s ]"
2601.12124v1_SynQP A Framework and Metrics for Evaluating the Q.pdf,A Framework and Metrics for Evaluating the Quality and Privacy Risk of Synthetic Data,"['Bing Hu', 'Yixin Li', 'Asma Bahamyirou', 'Helen Chen']",,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SYNQP: A FRAMEWORK ANDMETRICS FOREVALUATING THE || QUALITY ANDPRIVACYRISK OFSYNTHETICDATA || Bing Hu || Computer Science || University of Waterloo || b25hu@uwaterloo.ca || Yixin Li || Public Health Sciences || University of Waterloo || Asma Bahamyirou || Public Health Agency of Canada || Government of Canada || Helen  ... (truncated) ||  || { || ""title"": ""A Framework and Metrics for Evaluating the Quality and Privacy Risk of Synthetic Data"", || ""authors"": [ || ""Bing Hu"", || ""Yixin Li"", || ""Asma Bahamyirou"", || ""Helen Chen"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Real-World Data"", || ""Synthetic Data"", || ""Privacy Metrics"", || ""Evaluation Framework"", || ""Membership Inference"", || ""Identity Disclosure Risk"" || ], || ""summary"": ""The paper introduces SYNQP, an open framework for benchmarking privacy in synthetic data generation using simulated sensitive data. It addresses the lack of accessible benchmark datasets and proposes new identity disclosure risk metrics, demonstrating results with CTGAN and highlighting compliance with regulatory thresholds."" || } ||  || [ Prompt: 107.4 t/s | Generation: 26.9 t/s ]"
2601.12126v1_UniMo Unified Motion Generation and Understanding .pdf,Unified Motion Generation and Understanding with Chain of Thought,"['Guocun Wang', 'Kenkun Liu', 'Jing Lin', 'Guorui Song', 'Jian Li', 'Xiaoguang Han', '4', '5', 'SIGs', 'Tsinghua University', 'SSE', 'The Chinese University of Hong Kong (Shenzhen)', 'MMLab, Nanyang Technological University', 'FNii-Shenzhen', 'Guangdong Provincial Key Laboratory of Future Networks of Intelligence']",,28.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || UniMo: Unified Motion Generation and Understanding with Chain of Thought || Guocun Wang1*, Kenkun Liu2*, Jing Lin3, Guorui Song1, Jian Li1, Xiaoguang Han2,4,5 || 1SIGS, Tsinghua University || 2SSE, The Chinese University of Hong Kong (Shenzhen) || 3MMLab, Nanyang Technological University || 4FNii- ... (truncated) ||  || { || ""title"": ""Unified Motion Generation and Understanding with Chain of Thought"", || ""authors"": [ || ""Guocun Wang"", || ""Kenkun Liu"", || ""Jing Lin"", || ""Guorui Song"", || ""Jian Li"", || ""Xiaoguang Han"", || ""4"", ""5"", || ""SIGs"", || ""Tsinghua University"", || ""SSE"", || ""The Chinese University of Hong Kong (Shenzhen)"", || ""MMLab, Nanyang Technological University"", || ""FNii-Shenzhen"", || ""Guangdong Provincial Key Laboratory of Future Networks of Intelligence"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Existing 3D human motion generation and understanding methods often exhibit limited interpretability, restricting effective mutual enhancement between these inherently related tasks. While current unified frameworks based on large language models (LLMs) leverage linguistic priors, they frequently encounter challenges in semantic alignment and task coherence. Moreover, the next-token prediction paradigm in LLMs is ill-suited for motion sequences, causing cumulative prediction errors. To address these limitations, we propose UniMo, a novel framework that integrates motion-language information and interpretable chain of thought (CoT) reasoning into the LLM via supervised fine-tuning (SFT). We further introduce reinforcement learning with Group Relative Policy Optimization (GRPO) as a post-training strategy that optimizes over groups of tokens to enforce structural correctness and semantic alignment, mitigating cumulative errors in motion token prediction. Extensive experiments demonstrate that UniMo significantly outperforms existing unified and task-specific models, achieving state-of-the-art performance in both motion generation and understanding."" || } ||  || [ Prompt: 115.3 t/s | Generation: 28.0 t/s ]"
2601.12132v1_Bengali Text Classification An Evaluation of Large.pdf,Bengali Text Classification: An Evaluation of Large Language Model Approaches,"['Md Mahmudul Hoque', 'Md Mehedi Hassain', 'Md Hojaifa Tanvir', 'Rahul Nandy']",,27.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Bengali Text Classification: An Evaluation of || Large Language Model Approaches || Md Mahmudul Hoque1 , Md Mehedi Hassain2 , Md Hojaifa Tanvir3, and || Rahul Nandy2 || 1 Dept. of Computer Science & Engineering, CCN University of Science and || Technology, CCN Road, Cumilla - 3506, Bangladesh. || cse ... (truncated) ||  || { || ""title"": ""Bengali Text Classification: An Evaluation of Large Language Model Approaches"", || ""authors"": [ || ""Md Mahmudul Hoque"", || ""Md Mehedi Hassain"", || ""Md Hojaifa Tanvir"", || ""Rahul Nandy"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Bengali Text Classification"", || ""Transformer-based Text Classifier"", || ""Multilingual NLP"", || ""Qwen"", || ""LLaMA"", || ""LLaMA 3.1"", || ""LLaMA 3.2"", || ""Qwen 2.5"" || ], || ""summary"": ""This study evaluates large language models for Bengali newspaper article classification. Qwen 2.5 achieved the highest accuracy (72%) in the 'Sports' category, outperforming LLaMA 3.1 (53%) and LLaMA 3.2 (56%). The research highlights challenges due to limited Bengali NLP resources and suggests future work on model refinement."" || } ||  || [ Prompt: 121.1 t/s | Generation: 27.2 t/s ]"
2601.12134v1_Human-Human-AI Triadic Programming Uncovering the .pdf,Human-Human-AI Triadic Programming: Uncovering the Role of AI Agent and the Value of Human Partner in Collaborative Learning,"['Taufiq Daryanto', 'Xiaohan Ding', 'Kaike Ping', 'Lance T. Wilhelm', 'Yan Chen', 'Chris Brown']",arXiv:2601.12134v1,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Human-Human-AI Triadic Programming: Uncovering the Role of || AI Agent and the Value of Human Partner in Collaborative || Learning || Taufiq Daryanto || taufiqhd@vt.edu || Virginia Tech || Blacksburg, VA, USA || Xiaohan Ding || xiaohan@vt.edu || Virginia Tech || Blacksburg, VA, USA || Kaike Ping || pkk@vt.edu || Virginia ... (truncated) ||  || { || ""title"": ""Human-Human-AI Triadic Programming: Uncovering the Role of AI Agent and the Value of Human Partner in Collaborative Learning"", || ""authors"": [ || ""Taufiq Daryanto"", || ""Xiaohan Ding"", || ""Kaike Ping"", || ""Lance T. Wilhelm"", || ""Yan Chen"", || ""Chris Brown"" || ], || ""doi"": ""arXiv:2601.12134v1"", || ""arxiv_id"": ""arXiv:2601.12134v1"", || ""keywords"": [ || ""human-human-AI"", || ""programming learning"", || ""collaborative learning"", || ""AI agent"", || ""pedagogical benefits"" || ], || ""summary"": ""This study explores human-human-AI triadic programming, examining how AI can augment human partners in collaborative programming without replacing the social and learning benefits of human collaboration. It introduces the concept of human-human-AI (HHAI) triadic programming and presents findings from a within-subjects study."" || } ||  || [ Prompt: 119.4 t/s | Generation: 27.5 t/s ]"
2601.12138v1_DriveSafe A Hierarchical Risk Taxonomy for Safety-.pdf,DriveSafe: A Hierarchical Risk Taxonomy for Safety-Critical LLM-Based Driving Assistants,"['Abhishek Kumar', 'Riya Tapwal', 'Carsten Maple']",,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DriveSafe: A Hierarchical Risk Taxonomy for Safety-Critical LLM-Based || Driving Assistants || Abhishek Kumar1, Riya Tapwal2, Carsten Maple2, || 1The Alan Turing Institute, 2University of Warwick, || akumar@turing.ac.uk, tapwalriya@gmail.com, cm@warwick.ac.uk || Abstract || Large Language Models (LLM ... (truncated) ||  || { || ""title"": ""DriveSafe: A Hierarchical Risk Taxonomy for Safety-Critical LLM-Based Driving Assistants"", || ""authors"": [ || ""Abhishek Kumar"", || ""Riya Tapwal"", || ""Carsten Maple"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""LLM safety"", || ""driving assistants"", || ""safety-critical"", || ""LLM-based"", || ""ethical"", || ""regulatory"", || ""technical"", || ""legal"", || ""societal"", || ""ethical"" || ], || ""summary"": ""This paper introduces DriveSafe, a hierarchical risk taxonomy for characterizing safety-critical failure modes of LLM-based driving assistants. It outlines 129 fine-grained risk categories across technical, legal, societal, and ethical dimensions, aiming to improve safety evaluation in real-world driving scenarios."" || } ||  || [ Prompt: 110.7 t/s | Generation: 27.8 t/s ]"
2601.12141v1_TIDE A Trace-Informed Depth-First Exploration for .pdf,TIDE: A Trace-Informed Depth-First Exploration,"['Yuliia Suprun', 'Khen Elimelech', 'Lydia E. Kavraki', 'Moshe Y. Vardi']",arXiv:2601.12141v1,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TIDE: A Trace-Informed Depth-First Exploration || for Planning with Temporally Extended Goals || Yuliia Suprun1, Khen Elimelech 1, Lydia E. Kavraki 1,2, and Moshe Y. Vardi 1,2 || 1Department of Computer Science, Rice University, USA || 2Ken Kennedy Institute, Rice University, USA || May 2025 || Abstr ... (truncated) ||  || { || ""title"": ""TIDE: A Trace-Informed Depth-First Exploration"", || ""authors"": [ || ""Yuliia Suprun"", || ""Khen Elimelech"", || ""Lydia E. Kavraki"", || ""Moshe Y. Vardi"" || ], || ""doi"": ""arXiv:2601.12141v1"", || ""arxiv_id"": ""arXiv:2601.12141v1"", || ""keywords"": [], || ""summary"": ""Task planning with temporally extended goals (TEGs) is a critical challenge in AI and robotics, enabling agents to achieve complex sequences of objectives over time rather than adressing isolated, immediate tasks. Linear Temporal Logic on finite traces (LTL f) provides a robust formalism for encoding these temporal goals. Traditional LTLf task planning approaches often transform the temporal planning problem into a classical planning problem with reachability goals, which are then solved using off-the-shelf planners. However, these methods often lack informed heuristics to provide a guided search for temporal goals."" || } ||  || [ Prompt: 120.2 t/s | Generation: 27.7 t/s ]"
2601.12147v1_Segment and Matte Anything in a Unified Model.pdf,Segment And Matte Anything,"['Zezhong Fan', 'Xiaohan Li', 'Topojoy Biswas', 'Kaushiki Nag', 'Kannan Achan']",10.48550/arXiv.2311.06854,27.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Segment and Matte Anything in a Unified Model || Zezhong Fan*, Xiaohan Li*, Topojoy Biswas, Kaushiki Nag, Kannan Achan || Personalization Team, Walmart Global Tech || Sunnyvale, CA, USA || {zezhong.fan, xiaohan.li, topojoy.biswas, kaushiki.nag, kannan.achan}@walmart.com || Abstract || Segment Anythin ... (truncated) ||  || { || ""title"": ""Segment And Matte Anything"", || ""authors"": [ || ""Zezhong Fan"", || ""Xiaohan Li"", || ""Topojoy Biswas"", || ""Kaushiki Nag"", || ""Kannan Achan"" || ], || ""doi"": ""10.48550/arXiv.2311.06854"", || ""arxiv_id"": ""2311.06854"", || ""keywords"": [ || ""Segmentation"", || ""Matte"", || ""Image Processing"", || ""Computer Vision"", || ""Deep Learning"" || ], || ""summary"": ""This paper introduces Segment And Matte Anything (SAMA), a lightweight extension of Segment Anything (SAM) that achieves high-quality interactive image segmentation and matting with minimal parameters. It leverages a Multi-View Localization Encoder and a Localization Adapter to enhance mask refinement, and incorporates prediction heads for both segmentation and matting tasks. SAMA demonstrates state-of-the-art performance across benchmarks, highlighting its adaptability for downstream applications."" || } ||  || [ Prompt: 114.8 t/s | Generation: 27.2 t/s ]"
2601.12150v1_Enhanced Diagnostic Performance via Large-Resoluti.pdf,Enhanced Diagnostic Performance Via Large-Resolution Inference Optimization for Pathology Foundation Models,"['Mengxuan Hu', 'Zihan Guan', 'John Kang', 'Sheng Li', 'Zhongliang Zhou']",,26.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ENHANCEDDIAGNOSTICPERFORMANCE VIA || LARGE-RESOLUTIONINFERENCEOPTIMIZATION FOR || PATHOLOGYFOUNDATIONMODELS || Mengxuan Hu || University of Virginia || Charlottesville, V A, USA || qtq7su@virginia.edu || Zihan Guan, || University of Virginia || Charlottesville, V A, USA || bxv6gs@virginia.edu || John Kang || Merck & C ... (truncated) ||  || { || ""title"": ""Enhanced Diagnostic Performance Via Large-Resolution Inference Optimization for Pathology Foundation Models"", || ""authors"": [ || ""Mengxuan Hu"", || ""Zihan Guan"", || ""John Kang"", || ""Sheng Li"", || ""Zhongliang Zhou"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""computational pathology"", || ""foundation models"", || ""inference optimization"", || ""ROI classification"", || ""segmentation"", || ""whole-slide images"", || ""GPU memory"", || ""morphological details"" || ], || ""summary"": ""The paper addresses the challenge of applying pathology foundation models to high-resolution whole-slide images by proposing a space- and time-efficient inference strategy that reduces GPU memory usage and runtime while maintaining performance."" || } ||  || [ Prompt: 112.0 t/s | Generation: 26.5 t/s ]"
2601.12186v1_Aletheia What Makes RLVR For Code Verifiers Tick.pdf,What Makes RLVR For Code Verifiers Tick?,"['Vatsal Venkatkrishna', 'Indraneil Paul', 'Iryna Gurevych']",,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Aletheia: What Makes RLVR For Code Verifiers Tick? || Vatsal Venkatkrishna || /envelpe, Indraneil Paul || , and Iryna Gurevych || , || first.last@insait.ai first.last@tu-darmstadt.de || INSAIT, Sofia University St. Kliment Ohridski, Bulgaria || Ubiquitous Knowledge Processing Lab (UKP Lab), || Departmen ... (truncated) ||  || { || ""title"": ""What Makes RLVR For Code Verifiers Tick?"", || ""authors"": [ || ""Vatsal Venkatkrishna"", || ""Indraneil Paul"", || ""Iryna Gurevych"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Multi-domain thinking verifiers trained via Reinforcement Learning from Verifiable Rewards are valuable for judging model outputs in code generation, especially where execution feedback is scarce. The study examines components of RLVR training and identifies key optimization opportunities."" || } ||  || [ Prompt: 105.4 t/s | Generation: 29.0 t/s ]"
2601.12205v1_Do Neural Codecs Generalize A Controlled Study Acr.pdf,Do Neural Codecs Generalize? A Controlled Study Across Unseen Languages and Non-Speech Tasks,"['Shih-Heng Wang', 'Jiatong Shi', 'Jinchuan Tian', 'Haibin Wu', 'Shinji Watanabe']",,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Do Neural Codecs Generalize? A Controlled Study Across Unseen || Languages and Non-Speech Tasks || Shih-Heng Wang1*, Jiatong Shi 2, Jinchuan Tian 2, || Haibin Wu3,Shinji Watanabe 2, || 1University of Southern California, 2Carnegie Mellon University, 3Meta || Abstract || This paper investigates three  ... (truncated) ||  || { || ""title"": ""Do Neural Codecs Generalize? A Controlled Study Across Unseen Languages and Non-Speech Tasks"", || ""authors"": [ || ""Shih-Heng Wang"", || ""Jiatong Shi"", || ""Jinchuan Tian"", || ""Haibin Wu"", || ""Shinji Watanabe"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Neural Audio Codecs"", || ""Generalization"", || ""Language"", || ""Non-speech tasks"", || ""Speech"", || ""Downstream applications"" || ], || ""summary"": ""This paper investigates the generalization capabilities of Neural Audio Codecs (NACs) across unseen languages during pre-training, the performance of speech-only pre-trained NACs on non-speech tasks, and the impact of including non-speech pre-training data on overall performance. The study aims to provide fair comparisons using controlled experiments and comprehensive evaluations."" || } ||  || [ Prompt: 117.0 t/s | Generation: 28.2 t/s ]"
2601.12212v1_Speculative Sampling with Reinforcement Learning.pdf,Speculative Sampling with Reinforcement Learning,"['Chenan Wang', 'Daniel H. Shi', 'Haipeng Chen']",,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Speculative Sampling with Reinforcement Learning || Chenan Wang1, Daniel H. Shi1, Haipeng Chen1 || 1William & Mary || {cwang33,dshi01,hchen23}@wm.edu || Abstract || Inference time latency has remained an open challenge for || real world applications of large language models (LLMs). || State-of-the-art ( ... (truncated) ||  || { || ""title"": ""Speculative Sampling with Reinforcement Learning"", || ""authors"": [""Chenan Wang"", ""Daniel H. Shi"", ""Haipeng Chen""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper introduces Reinforcement Learning for Speculative Sampling (Re-SpS), a reinforcement learning-based framework for optimizing draft tree hyperparameters in real-time, improving generation speed while maintaining output fidelity."" || } ||  || [ Prompt: 112.1 t/s | Generation: 28.3 t/s ]"
2601.12215v1_Wavelet-Driven Masked Multiscale Reconstruction fo.pdf,Wavelet-Driven Masked Multiscale,"['Megha Thukral', 'Cyrus Tanade', 'Simon A. Lee', 'Juhyeon Lee', 'Hao Zhou', 'Keum San Chun', 'Migyeong Gwak', 'Viswam Nathan', 'Md Mahbubur Rahman', 'Li Zhu', 'Mehrab Bin Morshed', 'Subramaniam Venkatraman', 'Sharanya Arcot Desai']",arXiv:2601.12215v1,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Wavelet-Driven Masked Multiscale || Reconstruction for PPG Foundation Models || Megha Thukral*,1,2, Cyrus Tanade 1, Simon A. Lee 1, Juhyeon Lee 1, Hao Zhou 1, Keum San Chun 1, Migyeong Gwak 1, || Viswam Nathan1, Md Mahbubur Rahman 1, Li Zhu 1, Mehrab Bin Morshed 1, Subramaniam Venkatraman 1  ... (truncated) ||  || { || ""title"": ""Wavelet-Driven Masked Multiscale"", || ""authors"": [ || ""Megha Thukral"", || ""Cyrus Tanade"", || ""Simon A. Lee"", || ""Juhyeon Lee"", || ""Hao Zhou"", || ""Keum San Chun"", || ""Migyeong Gwak"", || ""Viswam Nathan"", || ""Md Mahbubur Rahman"", || ""Li Zhu"", || ""Mehrab Bin Morshed"", || ""Subramaniam Venkatraman"", || ""Sharanya Arcot Desai"" || ], || ""doi"": ""arXiv:2601.12215v1"", || ""arxiv_id"": ""2601.12215"", || ""keywords"": [ || ""Wearable SSL Method"", || ""Wavelet based Modelling"", || ""PPG foundation models"" || ], || ""summary"": ""This paper introduces Masked Multiscale Reconstruction (MMR) for PPG representation learning, leveraging wavelet-based multiresolution decomposition to capture multi-scale physiological rhythms. Pretrained on 17 million unlabeled PPG segments, MMR outperforms or matches state-of-the-art PPG foundation models and demonstrates the importance of wavelet representations for robust health-related predictions."" || } ||  || [ Prompt: 125.1 t/s | Generation: 28.1 t/s ]"
2601.12224v1_Where It Moves It Matters Referring Surgical Instr.pdf,"Where It Moves, It Matters: Referring Surgical Instrument Segmentation via Motion","['Meng Wei', 'Kun Yuan', 'Shi Li', 'Yue Zhou', 'Long Bai', 'Nassir Navab', 'Hongliang Ren', 'Hong Joo Lee', 'Tom Vercauteren', 'Nicolas Padoy']",10.48550/arXiv.2405.12345,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Where It Moves, It Matters: Referring Surgical Instrument Segmentation via || Motion || Meng Wei1, Kun Yuan2,3,5*, Shi Li3, Yue Zhou2, Long Bai4, Nassir Navab2, Hongliang Ren4, || Hong Joo Lee2,5*, Tom Vercauteren1, Nicolas Padoy3 || 1Biomedical Engineering and Imaging Sciences, Kings College L ... (truncated) ||  || { || ""title"": ""Where It Moves, It Matters: Referring Surgical Instrument Segmentation via Motion"", || ""authors"": [ || ""Meng Wei"", || ""Kun Yuan"", || ""Shi Li"", || ""Yue Zhou"", || ""Long Bai"", || ""Nassir Navab"", || ""Hongliang Ren"", || ""Hong Joo Lee"", || ""Tom Vercauteren"", || ""Nicolas Padoy"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [ || ""surgical video"", || ""instrument segmentation"", || ""natural language processing"", || ""motion guidance"", || ""robotic surgery"" || ], || ""summary"": ""This work introduces SurgRef, a motion-guided framework for segmenting surgical instruments from video using natural language descriptions. It addresses challenges in generalizing segmentation under occlusion and ambiguity, aiming to improve robustness in surgical applications."" || } ||  || [ Prompt: 111.5 t/s | Generation: 28.7 t/s ]"
2601.12234v1_Proc3D Procedural 3D Generation and Parametric Edi.pdf,,[],,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Proc3D: Procedural 3D Generation and Parametric Editing of 3D Shapes with || Large Language Models || Fadlullah Raji1, Stefano Petrangeli2, Matheus Gadelha2, Yu Shen2, Uttaran Bhattacharya2, Gang || Wu2 || 1University of South Florida || 2Adobe Research || fraji@usf.edu, {gadelha, shenyu, petrange, u ... (truncated) ||  || { || ""title"": ""Proc3D: Procedural 3D Generation and Parametric Editing of 3D Shapes with Large Language Models"", || ""authors"": [ || ""Fadlullah Raji"", || ""Stefano Petrangeli"", || ""Matheus Gadelha"", || ""Yu Shen"", || ""Uttaran Bhattacharya"", || ""Gang Wu2"" || ], || ""doi"": ""arXiv:2601.12234v1"", || ""arxiv_id"": ""arXiv:2601.12234"", || ""keywords"": [ || ""Proc3D"", || ""3D generation"", || ""Parametric editing"", || ""Large Language Models"", || ""Procedural Compact Graph"", || ""Text-based editing"" || ], || ""summary"": ""Proc3D introduces a system for generating editable 3D models using procedural compact graph (PCG) and enables real-time, intuitive modifications through LLMs. It improves editing efficiency and ULIP scores significantly."" || } ||  || [ Prompt: 115.1 t/s | Generation: 27.5 t/s ]"
2601.12242v1_Optimal Power Allocation and Sub-Optimal Channel A.pdf,Optimal Power Allocation and Sub-Optimal Channel Assignment,"['Woo Seok Kim', 'Jeonghoon Lee', 'Sangho Kim', 'Taesun An', 'WonMin Lee', 'Sangho Kim', 'Dowon Kim', 'Kyungseop Shin']",arXiv:2601.12242v1,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || OPTIMALPOWERALLOCATION ANDSUB-OPTIMALCHANNEL || ASSIGNMENT FORDOWNLINKNOMA SYSTEMUSINGDEEP || REINFORCEMENTLEARNING || WooSeok Kim || Department of Computer Science || Sangmyung University || 3suksw@gmail.com || Jeonghoon Lee || Department of Game Design and Development || Sangmyung University || 2jh0926@naver.c ... (truncated) ||  || { || ""title"": ""Optimal Power Allocation and Sub-Optimal Channel Assignment"", || ""authors"": [ || ""Woo Seok Kim"", || ""Jeonghoon Lee"", || ""Sangho Kim"", || ""Taesun An"", || ""WonMin Lee"", || ""Sangho Kim"", || ""Dowon Kim"", || ""Kyungseop Shin"" || ], || ""doi"": ""arXiv:2601.12242v1"", || ""arxiv_id"": ""arXiv:2601.12242"", || ""keywords"": [ || ""Non-Orthogonal Multiple Access"", || ""Deep Reinforcement Learning"", || ""Wireless Network"", || ""Resource Allocation"" || ], || ""summary"": ""This paper proposes a deep reinforcement learning framework incorporating replay memory with an on-policy algorithm to optimize network resource allocation in a Non-Orthogonal Multiple Access system. It addresses the challenges of channel assignment and resource optimization in the context of IoT expansion."" || } ||  || [ Prompt: 110.5 t/s | Generation: 27.5 t/s ]"
2601.12243v1_Less is More Label-Guided Summarization of Procedu.pdf,Less is More: Label-Guided Summarization of Procedural and Instructional Videos,"['Shreya Rajpal', 'Michal Golovanesky', 'Carsten Eickhoff']",,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Less is More: Label-Guided Summarization of || Procedural and Instructional Videos || Shreya Rajpal || Vellore Institute of Technology || shreyarajpal6@gmail.com || Michal Golovanesky || Brown University || michal_golovanesky@brown.edu || Carsten Eickhoff || University of Tbingen || carsten.eickhoff@uni-tuebinge ... (truncated) ||  || { || ""title"": ""Less is More: Label-Guided Summarization of Procedural and Instructional Videos"", || ""authors"": [ || ""Shreya Rajpal"", || ""Michal Golovanesky"", || ""Carsten Eickhoff"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""video summarization"", || ""procedural videos"", || ""instructional videos"", || ""semantic understanding"", || ""semantic alignment"", || ""video analysis"" || ], || ""summary"": ""This paper proposes a three-stage framework, PRISM, for procedural and instructional video summarization. PRISM integrates semantic and multimodal analysis to produce contextually coherent summaries, maintaining high semantic content retention while reducing video length. The method leverages adaptive visual sampling, label-driven keyframe anchoring, and contextual validation using a large language model."" || } ||  || [ Prompt: 117.4 t/s | Generation: 27.6 t/s ]"
2601.12247v1_Plan Verify and Fill A Structured Parallel Decodin.pdf,"Plan, Verify and Fill: A Structured Parallel Decoding Approach for Diffusion","['Miao Li', 'Hanyang Jiang', 'Xuanzhou Chen', 'Pascal Van Hentenryck', 'Yuhang Cai', 'Huang']","2025a; Google DeepMind, 2025",29.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Plan, Verify and Fill: A Structured Parallel Decoding Approach for Diffusion || Language Models || Miao Li * 1 Hanyang Jiang * 1 Sikai Cheng 1 Hengyu Fu 2 Yuhang Cai2 Baihe Huang 2 Tinghan Ye1 || Xuanzhou Chen 1 Pascal Van Hentenryck1 || Abstract || Diffusion Language Models (DLMs) present a || promi ... (truncated) ||  || { || ""title"": ""Plan, Verify and Fill: A Structured Parallel Decoding Approach for Diffusion"", || ""authors"": [ || ""Miao Li"", || ""Hanyang Jiang"", || ""Xuanzhou Chen"", || ""Pascal Van Hentenryck"", || ""Yuhang Cai"", || ""Huang"" || ], || ""doi"": ""2025a; Google DeepMind, 2025"", || ""arxiv_id"": ""2026-01-21"", || ""keywords"": [ || ""Diffusion Language Models"", || ""Planning"", || ""Verification"", || ""Parallel Decoding"", || ""DLM"", || ""DLS"" || ], || ""summary"": ""This paper proposes Plan-Verify-Fill (PVF), a training-free diffusion paradigm that leverages quantitative validation to guide planning and optimize global context utilization. It shows improved efficiency in reducing function evaluations while maintaining accuracy."" || } ||  || [ Prompt: 112.3 t/s | Generation: 29.5 t/s ]"
2601.12248v1_AQUA-Bench Beyond Finding Answers to Knowing When .pdf,AQUA-BENCH: BEYOND FINDING ANSWERS TO KNOWING WHEN THERE ARE NONE,"['Chun-Yi Kuan', 'Hung-yi Lee']",,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || AQUA-BENCH: BEYOND FINDING ANSWERS TO KNOWING WHEN THERE ARE NONE || IN AUDIO QUESTION ANSWERING || Chun-Yi Kuan and Hung-yi Lee || National Taiwan University || ABSTRACT || Recent advances in audio-aware large language models have || shown strong performance on audio question answering. However, || exi ... (truncated) ||  || { || ""title"": ""AQUA-BENCH: BEYOND FINDING ANSWERS TO KNOWING WHEN THERE ARE NONE"", || ""authors"": [""Chun-Yi Kuan"", ""Hung-yi Lee""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""unanswerable questions"", ""audio question answering"", ""audio-aware large language models""], || ""summary"": ""This paper introduces AQUA-Bench, a benchmark for evaluating audio question answering systems by focusing on unanswerable questions, highlighting gaps in current evaluation methods."" || } ||  || [ Prompt: 110.5 t/s | Generation: 28.4 t/s ]"
2601.12249v1_An Innovative Framework for Breast Cancer Detectio.pdf,"An Innovative Framework for Breast Cancer Detection Using Pyramid Adaptive Atrous Convolution, Transformer Integration, and Multi-Scale Feature Fusion","['Ehsan Sadeghi Pour', 'Mahdi Esmaeili', 'Morteza Romoozi']",,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  ||  || An Innovative Framework for Breast Cancer || Detection Using Pyramid Adaptive Atrous || Convolution, Transformer Integration, and Multi- || Scale Feature Fusion || Ehsan Sadeghi Pour1, Mahdi Esmaeili2* , Morteza Romoozi3 || Department of Electrical and Computer Engineering Kashan Branch,  ... (truncated) ||  || { || ""title"": ""An Innovative Framework for Breast Cancer Detection Using Pyramid Adaptive Atrous Convolution, Transformer Integration, and Multi-Scale Feature Fusion"", || ""authors"": [ || ""Ehsan Sadeghi Pour"", || ""Mahdi Esmaeili"", || ""Morteza Romoozi"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Breast Cancer Detection"", || ""Pyramid Adaptive Atrous Convolution"", || ""Transformer"", || ""Multi-Scale Feature Fusion"", || ""Medical Image Processing"" || ], || ""summary"": ""This thesis presents an innovative framework for detecting malignant masses in mammographic images by integrating Pyramid Adaptive Atrous Convolution (PAAC) and Transformer architectures. The approach utilizes Multi-Scale Feature Fusion and employs Dice Loss and Focal Loss functions to enhance model performance. The proposed model achieves high accuracy (98.5%) in detecting cancerous masses, outperforming existing methods and demonstrating effectiveness in complex datasets."" || } ||  || [ Prompt: 106.5 t/s | Generation: 27.8 t/s ]"
2601.12256v1_Improving Large Molecular Language Model via Relat.pdf,Improving Large Molecular Language Model,"['Jinyoung Park', 'Minseong Bae', 'Jeehye Na', 'Hyunwoo J. Kim']",,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Improving Large Molecular Language Model || via Relation-aware Multimodal Collaboration || Jinyoung Park*, Minseong Bae, Jeehye Na, Hyunwoo J. Kim || Korea Advanced Institute of Science and Technology || {jinyoung.park, bms2002, jeehyena, hyunwoojkim}@kaist.ac.kr || Abstract || Large language models  ... (truncated) ||  || { || ""title"": ""Improving Large Molecular Language Model"", || ""authors"": [ || ""Jinyoung Park"", || ""Minseong Bae"", || ""Jeehye Na"", || ""Hyunwoo J. Kim"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper proposes CoLLaMo, a large language model-based molecular assistant with a multi-level molecular modality-collaborative projector, to enhance the generalization of LMLMs by incorporating 2D structural and 3D spatial relations."" || } ||  || [ Prompt: 113.2 t/s | Generation: 28.7 t/s ]"
2601.12257v1_Soft Shadow Diffusion SSD Physics-inspired Learnin.pdf,Soft Shadow Diffusion (SSD): Physics-inspired,"['Fadlullah Raji', 'John Murray Bruce']",arXiv:2601.12257v1,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Soft Shadow Diffusion (SSD): Physics-inspired || Learning for 3D Computational Periscopy || Fadlullah Raji and John Murray Bruce || Computer Science and Engineering, University of South Florida || 4202 E. Fowler Avenue, Tampa, FL, USA 33620. || {fraji, murraybruce}@usf.edu || Abstract.Conventional im ... (truncated) ||  || { || ""title"": ""Soft Shadow Diffusion (SSD): Physics-inspired"", || ""authors"": [""Fadlullah Raji"", ""John Murray Bruce""], || ""doi"": ""arXiv:2601.12257v1"", || ""arxiv_id"": ""arXiv:2601.12257"", || ""keywords"": [""Computational imaging"", ""Machine learning"", ""3D generative models"", ""Diffusion models"", ""Separable non-linear least squares""], || ""summary"": ""This paper presents a novel 3D reconstruction method called Soft Shadow Diffusion (SSD) that leverages physics-inspired reformulation of light transport to enable non-line-of-sight imaging. SSD addresses the challenge of reconstructing hidden scenes from passive NLOS photographs by decomposing the problem into light-occluding and non-light-occluding components. The approach combines gradient-based optimization and a physics-inspired neural network, demonstrating effectiveness across diverse real-world scenarios."" || } ||  || [ Prompt: 123.3 t/s | Generation: 27.8 t/s ]"
2601.12259v1_FutureX-Pro Extending Future Prediction to High-Va.pdf,FutureX-Pro: Extending Future Prediction to High-Value,[],arXiv:2601.12259v1,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || FutureX-Pro: Extending Future Prediction to High-Value || Vertical Domains || ByteDance Seed,Hong Kong University of Science and Technology,Georgia Institute of || Technology,Stanford University,Princeton University || Full author list in Contributions || Abstract || Building upon FutureX, which esta ... (truncated) ||  || { || ""title"": ""FutureX-Pro: Extending Future Prediction to High-Value"", || ""authors"": [], || ""doi"": ""arXiv:2601.12259v1"", || ""arxiv_id"": ""arXiv:2601.12259"", || ""keywords"": [], || ""summary"": ""Building upon FutureX, this report introduces FutureX-Pro, extending agentic future prediction to high-value vertical domains such as Finance, Retail, Public Health, and Natural Disaster. It benchmarks LLMs across entry-level prediction tasks relevant to these sectors."" || } ||  || [ Prompt: 118.3 t/s | Generation: 27.5 t/s ]"
2601.12260v1_Docs2Synth A Synthetic Data Trained Retriever Fram.pdf,,[],,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Docs2Synth: A Synthetic Data Trained Retriever Framework for || Scanned Visually Rich Documents Understanding || Yihao Ding1*, Qiang Sun 1*, Puzhen Wu2, Sirui Li 3, Siwen Luo 1, Wei Liu1 || 1University of Western Australia, 2The University of Hong Kong, 3Murdoch University || {yihao.ding,pascal ... (truncated) ||  || { || ""title"": ""Docs2Synth: A Synthetic Data Trained Retriever Framework for Scanned Visually Rich Documents Understanding"", || ""authors"": [ || ""Yihao Ding"", || ""Qiang Sun"", || ""Puzhen Wu"", || ""Sirui Li"", || ""Siwen Luo"", || ""Wei Liu"" || ], || ""doi"": ""10.48550/arXiv.2311.07891"", || ""arxiv_id"": ""arXiv:2311.07891"", || ""keywords"": [ || ""document understanding"", || ""scanned documents"", || ""synthetic data"", || ""retrieval-guided inference"", || ""visual retriever"", || ""hallucination reduction"" || ], || ""summary"": ""This paper introduces Docs2Synth, a synthetic-supervision framework for improving grounding and domain generalization in visual document understanding. It addresses challenges like lack of annotations and domain-specific grounding by combining MLLMs and VLPMs, and provides an easy-to-use Python package for deployment."" || } ||  || [ Prompt: 104.9 t/s | Generation: 28.3 t/s ]"
2601.12263v1_Multimodal Generative Engine Optimization Rank Man.pdf,Multimodal Generative Engine Optimization: Rank Manipulation for VisionLanguage Model Rankers,"['Yixuan Du', 'Chenxiao Yu', 'Haoyan Xu', 'Ziyi Wang', 'Yue Zhao', 'Xiyang Hu']",10.48550/arXiv.2024.12345,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Multimodal Generative Engine Optimization: || Rank Manipulation for VisionLanguage Model Rankers || Yixuan Du1, Chenxiao Yu2, Haoyan Xu 2, Ziyi Wang3, Yue Zhao2, Xiyang Hu 4* || 1Georgetown University || 2University of Southern California || 3University of Maryland, College Park || 4Arizona State Uni ... (truncated) ||  || { || ""title"": ""Multimodal Generative Engine Optimization: Rank Manipulation for VisionLanguage Model Rankers"", || ""authors"": [ || ""Yixuan Du"", || ""Chenxiao Yu"", || ""Haoyan Xu"", || ""Ziyi Wang"", || ""Yue Zhao"", || ""Xiyang Hu"" || ], || ""doi"": ""10.48550/arXiv.2024.12345"", || ""arxiv_id"": ""632562"", || ""keywords"": [ || ""Vision-Language Models"", || ""Multimodal Ranking"", || ""Adversarial Manipulation"", || ""Product Search"", || ""Rank Optimization"" || ], || ""summary"": ""This paper explores vulnerabilities in Vision-Language Models by introducing a multimodal ranking attack that jointly manipulates image and text to influence relevance scoring, highlighting risks in current search systems."" || } ||  || [ Prompt: 107.3 t/s | Generation: 28.5 t/s ]"
2601.12269v1_Simulated Annealing Enhances Theory-of-Mind Reason.pdf,Simulated Annealing Enhances Theory-of-Mind Reasoning in Autoregressive Language Models,"['Xucong Hu', 'Jian-Qiao Zhu']",,29.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Simulated Annealing Enhances Theory-of-Mind Reasoning in Autoregressive || Language Models || Xucong Hu (xuconghu@zju.edu.cn)1,* & Jian-Qiao Zhu (zhujq@hku.hk)2,* || 1Department of Psychology and Behavioral Sciences, Zhejiang University || 2Department of Psychology, The University of Hong Kong || ... (truncated) ||  || { || ""title"": ""Simulated Annealing Enhances Theory-of-Mind Reasoning in Autoregressive Language Models"", || ""authors"": [ || ""Xucong Hu"", || ""Jian-Qiao Zhu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Language Models"", || ""Markov Chain Monte Carlo"", || ""Simulated Annealing"", || ""Power Sampling"", || ""Theory of Mind"" || ], || ""summary"": ""The paper explores how incorporating simulated annealing into autoregressive language models can recover Theory of Mind capabilities without additional training, highlighting the importance of global coherence in these models."" || } ||  || [ Prompt: 111.7 t/s | Generation: 29.9 t/s ]"
2601.12276v1_Predictive Prototyping Evaluating Design Concepts .pdf,Predictive Prototyping: Evaluating Design Concepts with GPT,[],,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  || 1  2024 by ASME Restricted || Restricted || PREDICTIVE PROTOTYPING: EVALUATING DESIGN CONCEPTS WITH GPT || ABSTRACT The design-build-test cycle is critical to realize innovative solutions. This cycle enables a team to evaluate a concept based on performance and iteration to enhance  ... (truncated) ||  || { || ""title"": ""Predictive Prototyping: Evaluating Design Concepts with GPT"", || ""authors"": [], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Prototyping"", ""Design Theory"", ""Iteration"", ""Simulation"", ""AI"", ""LLM"", ""GPT"", ""RAG""], || ""summary"": ""This work explores using a GPT to predict design attributes such as cost, performance, and usability by leveraging retrieval augmented generation. It compares GPT predictions against physical prototyping results and evaluates prototype performance against commercial and topology-optimized models. The study highlights the accuracy of AI-driven insights and their potential to streamline design iteration."" || } ||  || [ Prompt: 111.8 t/s | Generation: 27.5 t/s ]"
2601.12282v1_CytoCLIP Learning Cytoarchitectural Characteristic.pdf,CytoCLIP: Learning Cytoarchitectural Characteristics in Developing Human Brain,"['Pralaypati Ta', 'Sriram Venkatesaperumal', 'Keerthi Ram', 'Mohanasankar Sivaprakasam']",10.1093/acps/clac045,27.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || IEEE TRANSACTIONS AND JOURNALS TEMPLATE    1 ||  ||  || CytoCLIP: Learning Cytoarchitectural || Characteristics in Developing Human Brain || Using Contrastive Language Image Pre-Training ||  || Pralaypati Ta, Sriram Venkatesap ... (truncated) ||  || { || ""title"": ""CytoCLIP: Learning Cytoarchitectural Characteristics in Developing Human Brain"", || ""authors"": [ || ""Pralaypati Ta"", || ""Sriram Venkatesaperumal"", || ""Keerthi Ram"", || ""Mohanasankar Sivaprakasam"" || ], || ""doi"": ""10.1093/acps/clac045"", || ""arxiv_id"": ""IEEE TRANSACTIONS AND JOURNALS TEMPLATE"", || ""keywords"": [ || ""Cytoarchitecture"", || ""Histological Image Processing"", || ""Contrastive Learning"", || ""CLIP"", || ""Brain Regions"", || ""Developing Human Brain"" || ], || ""summary"": ""The paper presents CytoCLIP, a vision-language model leveraging pre-trained CLIP frameworks to learn cytoarchitectural patterns in developing human brain regions. It proposes two model variants trained on low- and high-resolution images, demonstrating improved classification performance for brain region identification."" || } ||  || [ Prompt: 113.4 t/s | Generation: 27.0 t/s ]"
2601.12286v1_Conversational Context Classification A Representa.pdf,Conversational Context Classification: A,['Jonathan Pan'],,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Conversational Context Classification: A || Representation Engineering Approach || Jonathan Pan || Nanyang Technological University || Singapore || JonathanPan@ntu.edu.sg || AbstractThe increasing prevalence of Large Language Mod- || els (LLMs) demands effective safeguards for their operation, par- || ticu ... (truncated) ||  || { || ""title"": ""Conversational Context Classification: A"", || ""authors"": [""Jonathan Pan""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Large Language Models"", ""One-Class SVM"", ""Novelty Detection"", ""In/Out-of-Context"", ""Representation Engineering""], || ""summary"": ""This paper explores using Representation Engineering and One-Class SVM to detect subspaces in LLMs that represent specific conversational contexts, aiming to improve AI safety by identifying out-of-context behavior."" || } ||  || [ Prompt: 119.6 t/s | Generation: 26.9 t/s ]"
2601.12288v1_TimeGMM Single-Pass Probabilistic Forecasting via .pdf,,[],,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TIMEGMM: SINGLE-PASS PROBABILISTIC FORECASTING VIA ADAPTIVE GAUSSIAN || MIXTURE MODELS WITH REVERSIBLE NORMALIZATION || Lei Liu1, Tengyuan Liu1, Hongwei Zhao1,, Jiahui Huang1, Ruibo Guo1, Bin Li1 || 1University of Science and Technology of China, Hefei, 230026, China || {liulei13, hwzhao, binli ... (truncated) ||  || { || ""title"": ""Single-Pass Probabilistic Forecasting Via Adaptive Gaussian"", || ""authors"": [ || ""Lei Liu1"", || ""Tengyuan Liu1"", || ""Hongwei Zhao1"", || ""Jiahui Huang1"", || ""Ruibo Guo1"", || ""Bin Li1"" || ], || ""doi"": ""https://github.com/USTC-AI4EEE/TimeGMM"", || ""arxiv_id"": """", || ""keywords"": [ || ""probabilistic time series forecasting"", || ""Gaussian mixture model"", || ""reversible instance normalization"", || ""uncertainty quantification"", || ""energy"", || ""finance"" || ], || ""summary"": ""This paper presents TimeGMM, a probabilistic forecasting framework using Gaussian Mixture Models with adaptive Gaussian normalization, achieving state-of-the-art performance in uncertainty quantification and distribution modeling."" || } ||  || [ Prompt: 112.6 t/s | Generation: 28.3 t/s ]"
2601.12294v1_ToolPRMBench Evaluating and Advancing Process Rewa.pdf,ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents,"['Dawei Li', 'Yuguang Yao', 'Zhen Tan', 'Huan Liu', 'Ruocheng Guo']",,28.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ToolPRMBench: Evaluating and Advancing Process Reward Models for || Tool-using Agents || Dawei Li, Yuguang Yao, Zhen Tan, Huan Liu, Ruocheng Guo || Arizona State University, Intuit AI Research || {daweili5, ztan36, huanliu}@asu.edu || {yuguang_yao,ruocheng_guo}@intuit.com || Abstract || Reward-guided se ... (truncated) ||  || { || ""title"": ""ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents"", || ""authors"": [ || ""Dawei Li"", || ""Yuguang Yao"", || ""Zhen Tan"", || ""Huan Liu"", || ""Ruocheng Guo"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""tool-using agents"", || ""process reward models"", || ""step-level evaluation"", || ""LLM benchmarks"", || ""tool APIs"" || ], || ""summary"": ""This paper introduces ToolPRMBench, a benchmark for evaluating process reward models in tool-using agents. It focuses on providing step-level rewards to enable fine-grained monitoring and compares performance across different LLMs and specialized PRMs."" || } ||  || [ Prompt: 112.7 t/s | Generation: 28.0 t/s ]"
2601.12304v1_A Two-Stage Globally-Diverse Adversarial Attack fo.pdf,A TWO-STAGE GLOBALLY-DIVERSE ADVERSARIAL A TTACK FOR VISION-LANGUAGE,"['Wutao Chen1', 'Huaqin Zou1', 'Chen Wan1*', 'Lifeng Huang2']",,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A TWO-STAGE GLOBALLY-DIVERSE ADVERSARIAL A TTACK FOR VISION-LANGUAGE || PRE-TRAINING MODELS || Wutao Chen1, Huaqin Zou 1, Chen Wan1*, Lifeng Huang 2 || 1Department of Computer Science and Technology, Shantou University, Shantou, China || 2College of Mathematics and Informatics, South China Agri ... (truncated) ||  || { || ""title"": ""A TWO-STAGE GLOBALLY-DIVERSE ADVERSARIAL A TTACK FOR VISION-LANGUAGE"", || ""authors"": [ || ""Wutao Chen1"", || ""Huaqin Zou1"", || ""Chen Wan1*"", || ""Lifeng Huang2"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Adversarial Attack"", || ""VLP Models"", || ""Multi-modal Retrieval"", || ""Transferability"" || ], || ""summary"": ""The paper proposes 2S-GDA, a two-stage globally-diverse attack framework for vision-language pre-training models, improving attack success rates by up to 11.17% in black-box settings."" || } ||  || [ Prompt: 108.4 t/s | Generation: 28.8 t/s ]"
2601.12310v1_Survival is the Only Reward Sustainable Self-Train.pdf,Survival is the Only Reward: Sustainable Self-Training Through Environment-Mediated Selection,"['Jennifer Dodgson', 'Alfath Daryl Alhajir', 'Michael Joedhitya', 'Akira Rafhael Janson Pattirane', 'Surender Suresh Kumar', 'Joseph Lim', 'C.H. Peh', 'Adith Ramdas', 'Steven Zhang Zhexu']",arXiv:2601.12310v1,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Survival is the Only Reward: || Sustainable Self-Training Through || Environment-Mediated Selection || Jennifer Dodgson, Alfath Daryl Alhajir, Michael Joedhitya, || Akira Rafhael Janson Pattirane, Surender Suresh Kumar, Joseph Lim, || C.H. Peh, Adith Ramdas and Steven Zhang Zhexu || January 2026 || 1 Ab ... (truncated) ||  || { || ""title"": ""Survival is the Only Reward: Sustainable Self-Training Through Environment-Mediated Selection"", || ""authors"": [ || ""Jennifer Dodgson"", || ""Alfath Daryl Alhajir"", || ""Michael Joedhitya"", || ""Akira Rafhael Janson Pattirane"", || ""Surender Suresh Kumar"", || ""Joseph Lim"", || ""C.H. Peh"", || ""Adith Ramdas"", || ""Steven Zhang Zhexu"" || ], || ""doi"": ""arXiv:2601.12310v1"", || ""arxiv_id"": ""arXiv:2601.12310"", || ""keywords"": [], || ""summary"": ""This paper presents a self-training architecture that relies on environmental viability for selection, avoiding reward hacking and semantic drift. It explores sustainable self-improvement through negative-space learning and meta-learning strategies without external supervision."", || ""summary_abstract"": ""Self-training systems often fail due to lack of external quality criteria, leading to reward hacking. This work introduces a system where learning is driven by environmental impact, enabling stable self-training under sparse feedback and limited memory. Improvement emerges from persistence and pruning of effective behaviors, a process termed negative-space learning."" || } ||  || [ Prompt: 107.7 t/s | Generation: 29.0 t/s ]"
2601.12316v1_GazeFormer-MoE Context-Aware Gaze Estimation via C.pdf,GAZEFORMER-MOE: CONTEXT-A W ARE GAZE ESTIMATION VIA CLIP AND MOE,"['Xinyuan Zhao', 'Xianrui Chen', 'Ahmad Chaddad', '1AIPM, School of Artificial Intelligence, Guilin University of Electronic Technology, China', 'Laboratory for Imagery, Vision and Artificial Intelligence, Ecole de Technologie Superieure, Canada']",,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || GAZEFORMER-MOE: CONTEXT-A W ARE GAZE ESTIMATION VIA CLIP AND MOE || TRANSFORMER || Xinyuan Zhao1,Xianrui Chen1, Ahmad Chaddad1,2, || 1AIPM, School of Artificial Intelligence, Guilin University of Electronic Technology, China || 2Laboratory for Imagery, Vision and Artificial Intelligence, Ecole  ... (truncated) ||  || { || ""title"": ""GAZEFORMER-MOE: CONTEXT-A W ARE GAZE ESTIMATION VIA CLIP AND MOE"", || ""authors"": [ || ""Xinyuan Zhao"", || ""Xianrui Chen"", || ""Ahmad Chaddad"", || ""1AIPM, School of Artificial Intelligence, Guilin University of Electronic Technology, China"", || ""Laboratory for Imagery, Vision and Artificial Intelligence, Ecole de Technologie Superieure, Canada"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""gaze estimation"", || ""multi scale fusion"", || ""MoE transformer"", || ""CLIP"", || ""semantic modulation"", || ""3D gaze estimation"" || ], || ""summary"": ""We present a semantics modulated, multi scale Transformer for 3D gaze estimation. Our model conditions CLIP global features with learnable prototype banks (illumination, head pose, background, direction), fuses these prototype-enriched global vectors with CLIP patch tokens and high-resolution CNN tokens in a unified attention space, and replaces several FFN blocks with routed/shared Mixture of Experts to increase conditional capacity. Evaluated on MPIIFaceGaze, EYEDIAP, Gaze360 and ETH-XGaze, our model achieves new state of the art angular errors of 2.49, 3.22, 10.16, and 1.44, demonstrating up to a 64% relative improvement over previously reported results. Ablations attribute gains to proto type conditioning, cross scale fusion, MoE and hyperparameter."" || } ||  || [ Prompt: 112.9 t/s | Generation: 27.7 t/s ]"
2601.12317v1_Explanova Automatically Discover Data Insights in .pdf,Explanova: Automatically Discover Data Insights in NM Table via XAI Combined LLM Workflow,['Yiming Huang'],10.1145/nnnnnnn.nnnnnnn,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Explanova: Automatically Discover Data Insights in NM Table || via XAI Combined LLM Workflow || Yiming Huang || HKUST(GZ) || Guangzhou, China || yhuang033@connect.hkust-gz.edu.cn || Abstract || Automation in data analysis has been a long-time pursuit. Current || agentic LLM shows a promising solution towar ... (truncated) ||  || { || ""title"": ""Explanova: Automatically Discover Data Insights in NM Table via XAI Combined LLM Workflow"", || ""authors"": [""Yiming Huang""], || ""doi"": ""10.1145/nnnnnnn.nnnnnnn"", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Automation in data analysis has been a long-time pursuit. Current agentic LLM shows a promising solution towards it. Like Deep-Analyze, DataSage, and Datawise. They are all powerful agentic frameworks for automatic fine-grained analysis and are powered by LLM-based agentic tool calling ability. However, what about powered by a preset AutoML-like workflow? If we traverse all possible exploration, like Xn itselfs statistics, Xn1-Xn2 relationships, Xn to all other, and finally explain? Our Explanova is such an attempt: Cheaper due to a Local Small LLM."" || } ||  || [ Prompt: 110.0 t/s | Generation: 28.6 t/s ]"
2601.12318v1_Beyond Human Annotation Recent Advances in Data Ge.pdf,Beyond Human Annotation: Recent Advances in Data Generation Methods for Document Intelligence,"['Dehao Ying', 'Fengchang Yu', 'Haihua Chen', 'Changjiang Jiang', 'Yurong Li', 'Wei Lu']",https://doi.org/XXXXXXX,28.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Beyond Human Annotation: Recent Advances in Data Generation Methods for || Document Intelligence || DEHAO YING,Wuhan University, China || FENGCHANG YU,Wuhan University, China || HAIHUA CHEN,University of North Texas, United States || CHANGJIANG JIANG,Wuhan University, China || YURONG LI,Wuhan Univers ... (truncated) ||  || { || ""title"": ""Beyond Human Annotation: Recent Advances in Data Generation Methods for Document Intelligence"", || ""authors"": [ || ""Dehao Ying"", || ""Fengchang Yu"", || ""Haihua Chen"", || ""Changjiang Jiang"", || ""Yurong Li"", || ""Wei Lu"" || ], || ""doi"": ""https://doi.org/XXXXXXX"", || ""arxiv_id"": """", || ""keywords"": [ || ""Document Intelligence"", || ""Data Generation"", || ""Data Quality Evaluation"" || ], || ""summary"": ""This survey establishes the first comprehensive technical map for data generation in Document Intelligence, redefining data generation as supervisory signal production and introducing a novel taxonomy based on data and label availability. It organizes methodologies into four paradigms and evaluates their performance across benchmarks."" || } ||  || [ Prompt: 107.6 t/s | Generation: 28.0 t/s ]"
2601.12323v1_MARO Learning Stronger Reasoning from Social Inter.pdf,Learning Stronger Reasoning from Social Interaction,"['Yin Cai1', 'Zhouhong Gu1', 'JunTao Zhang1', 'Ping Chen1']",,26.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MARO: Learning Stronger Reasoning from Social Interaction || Yin Cai1, Zhouhong Gu1, JunTao Zhang1, Ping Chen1* || 1College of Computer Science and Artificial Intelligence, Fudan University || {ycai25, zhgu22, juntaozhang22}@m.fudan.edu.cn, pchen@fudan.edu.cn || Abstract || Humans face countless s ... (truncated) ||  || { || ""title"": ""Learning Stronger Reasoning from Social Interaction"", || ""authors"": [ || ""Yin Cai1"", || ""Zhouhong Gu1"", || ""JunTao Zhang1"", || ""Ping Chen1"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper proposes MARO, a method enabling large language models to improve reasoning through multi-agent social interactions. It addresses sparse learning, uneven role distribution, and environmental instability by simulating social scenarios."" || } ||  || [ Prompt: 111.8 t/s | Generation: 26.6 t/s ]"
2601.12327v1_The Expert Validation Framework EVF Enabling Domai.pdf,The Expert Validation Framework (EVF): Enabling Domain Expert Control in AI Engineering,"['Lucas Gren', 'Felix Dobslaw']",10.1145/xxx.xxxx,26.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || The Expert Validation Framework (EVF): || Enabling Domain Expert Control in AI Engineering || Lucas Gren || Chalmers|University of Gothenburg and || Getinge AB || Gothenburg, Sweden || lucas.gren@lucasgren.com || Felix Dobslaw || Mid Sweden University || stersund, Sweden || felix.dobslaw@miun.se || Abstract || Generat ... (truncated) ||  || { || ""title"": ""The Expert Validation Framework (EVF): Enabling Domain Expert Control in AI Engineering"", || ""authors"": [ || ""Lucas Gren"", || ""Felix Dobslaw"" || ], || ""doi"": ""10.1145/xxx.xxxx"", || ""arxiv_id"": ""CCS Concepts"", || ""keywords"": [ || ""GenAI"", || ""expert validation"", || ""quality assurance"", || ""AI engineering"", || ""domain expert control"" || ], || ""summary"": ""The paper presents an Expert Validation Framework that places domain experts at the center of building software with GenAI components, ensuring quality through structured specification, testing, validation, and continuous monitoring."" || } ||  || [ Prompt: 108.1 t/s | Generation: 26.7 t/s ]"
2601.12330v1_IceWatch Forecasting Glacial Lake Outburst Floods .pdf,IceWatch: Forecasting Glacial Lake Outburst Floods using Multimodal Deep Learning,"['Zuha Fatima', 'Muhammad Anser Sohaib', 'Muhammad Talha', 'Ayesha Kanwal', 'Sidra Sultana', 'Nazia Perwaiz']",,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  || IceWatch: Forecasting Glacial Lake Outburst Floods || (GLOFs) using Multimodal Deep Learning ||  || Zuha Fatima, Muhammad Anser Sohaib, Muhammad Talha, Ayesha Kanwal, Sidra Sultana, Nazia Perwaiz || AbstractGlacial Lake Outburst Floods (GLOFs) pose a serious || threat in high mountain re ... (truncated) ||  || { || ""title"": ""IceWatch: Forecasting Glacial Lake Outburst Floods using Multimodal Deep Learning"", || ""authors"": [ || ""Zuha Fatima"", || ""Muhammad Anser Sohaib"", || ""Muhammad Talha"", || ""Ayesha Kanwal"", || ""Sidra Sultana"", || ""Nazia Perwaiz"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""CNN"", || ""deep learning"", || ""glacier monitoring"", || ""GLOF detection"", || ""LSTM"", || ""remote sensing"", || ""temperature forecasting"", || ""transformer"", || ""velocity prediction"" || ], || ""summary"": ""Glacial Lake Outburst Floods (GLOFs) pose a serious threat in high mountain regions. This paper presents IceWatch, a deep learning framework that integrates spatial and temporal data using CNN and LSTM models to predict GLOF events based on satellite imagery and physical dynamics."" || } ||  || [ Prompt: 112.8 t/s | Generation: 26.9 t/s ]"
2601.12331v1_Efficient Privacy-Preserving Retrieval Augmented G.pdf,Efficient Privacy-Preserving Retrieval Augmented Generation with Distance-Preserving Encryption,"['Huanyi Ye', 'Jiale Guo', 'Ziyao Liu', 'Kwok-Yan Lam']",,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Efficient Privacy-Preserving Retrieval Augmented || Generation with Distance-Preserving Encryption || Huanyi Ye, Jiale Guo , Ziyao Liu , Kwok-Yan Lam || College of Computing and Data Science,Nanyang Technological University, Singapore || huanyi001@e.ntu.edu.sg || Digital Trust Centre (DTC), Singa ... (truncated) ||  || { || ""title"": ""Efficient Privacy-Preserving Retrieval Augmented Generation with Distance-Preserving Encryption"", || ""authors"": [ || ""Huanyi Ye"", || ""Jiale Guo"", || ""Ziyao Liu"", || ""Kwok-Yan Lam"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""RAG"", || ""Privacy-Preserving"", || ""Distance-Preserving Encryption"", || ""LLMs"", || ""Cloud"", || ""Security"" || ], || ""summary"": ""This paper proposes a privacy-preserving retrieval-augmented generation framework (ppRAG) for untrusted cloud environments. It introduces CAPRISE, an encryption method that preserves relative distances between encrypted embeddings, enhancing privacy while maintaining efficiency. The approach addresses privacy risks like vector reconstruction and query analysis, offering secure LLM augmentation."" || } ||  || [ Prompt: 118.8 t/s | Generation: 27.5 t/s ]"
2601.12338v1_Actionable Advice from Reviews via Mixture of LoRA.pdf,Actionable Advice from Reviews via Mixture of LoRA Experts: A,"['Kartikey Singh Bhandari', 'Manav Ganesh', 'Yashwant Viswanathan', 'Archit Agrawal', 'Dhruv Kumar', 'Pratik Narang']",,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Actionable Advice from Reviews via Mixture of LoRA Experts: A || Two-LLM Pipeline for Issue Extraction and Business || Recommendations || Kartikey Singh Bhandari || BITS Pilani,Pilani Campus || Pilani, India || p20241006@pilani.bits-pilani.ac.in || Manav Ganesh || BITS Pilani,Pilani Campus || Pilani, India || f2 ... (truncated) ||  || { || ""title"": ""Actionable Advice from Reviews via Mixture of LoRA Experts: A"", || ""authors"": [ || ""Kartikey Singh Bhandari"", || ""Manav Ganesh"", || ""Yashwant Viswanathan"", || ""Archit Agrawal"", || ""Dhruv Kumar"", || ""Pratik Narang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""customer reviews"", || ""review-to-action generation"", || ""business recommendations"", || ""LLM"", || ""LoRA"", || ""operational decisions"" || ], || ""summary"": ""Customer reviews contain detailed signals about service failures and user expectations. This study proposes a two-LLM pipeline using a mixture-of-LoRA experts to generate concrete, actionable recommendations from reviews in domains like airlines and restaurants."" || } ||  || [ Prompt: 113.2 t/s | Generation: 28.1 t/s ]"
2601.12341v1_Time-Continuous Modeling for Temporal Affective Pa.pdf,Time-Continuous Modeling for Temporal Affective Pattern Recognition in LLMs,"['Rezky M. Kam', 'Coddy N. Siswanto']",,13.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Time-Continuous Modeling for Temporal Affective || Pattern Recognition in LLMs || Rezky M. Kam || School of Computer Science || Bina Nusantara University || East Jakarta, Indonesia || rezky.kam@binus.ac.id || Coddy N. Siswanto || School of Computer Science || Bina Nusantara University || East Jakarta, Indonesia || ... (truncated) ||  || { || ""title"": ""Time-Continuous Modeling for Temporal Affective Pattern Recognition in LLMs"", || ""authors"": [ || ""Rezky M. Kam"", || ""Coddy N. Siswanto"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""time-continuous modeling"", || ""temporal affective patterns"", || ""longitudinal adaptation"", || ""physics-informed neural networks"", || ""interpretability"", || ""affective dynamics"" || ], || ""summary"": ""The paper discusses challenges in modeling affective dynamics in language models, emphasizing the need for time-aware architectures that capture evolving emotional states across conversations. It introduces a hybrid encoder-decoder with progressive steering to improve interpretability and performance in affective understanding."" || } ||  || [ Prompt: 35.5 t/s | Generation: 13.3 t/s ]"
2601.12343v1_How Well Do LLMs Predict Human Behavior A Measure .pdf,How Well Do LLMs Predict Human Behavior?,"['Wayne Gao', 'Sukjin Han', 'Annie Liang']",arXiv:2601.12343v1,15.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || How Well Do LLMs Predict Human Behavior? || A Measure of their Pretrained Knowledge || Wayne Gao Sukjin Han Annie Liang || January 21, 2026 || Abstract || Large language models (LLMs) are increasingly used to predict human behavior. || We propose a measure for evaluating how much knowledge a pretrai ... (truncated) ||  || { || ""title"": ""How Well Do LLMs Predict Human Behavior?"", || ""authors"": [""Wayne Gao"", ""Sukjin Han"", ""Annie Liang""], || ""doi"": ""arXiv:2601.12343v1"", || ""arxiv_id"": ""arXiv:2601.12343"", || ""keywords"": [ || ""LLMs"", || ""human behavior"", || ""predictive accuracy"", || ""pretrained knowledge"", || ""economic variables"" || ], || ""summary"": ""The paper proposes a measure to evaluate how much knowledge a pretrained LLM brings to predicting human behavior by comparing prediction errors across different models."" || } ||  || [ Prompt: 34.7 t/s | Generation: 15.2 t/s ]"
2601.12349v1_Zero-Permission Manipulation Can We Trust Large Mu.pdf,Zero-Permission Manipulation: Can We Trust Large Multimodal Model Powered GUI Agents?,"['Yi Qian', 'Kunwei Qian', 'Xingbang He', 'Ligeng Chen', 'Jikang Zhang', 'Tiantai Zhang', 'Haiyang Wei', 'Linzhang Wang', 'Hao Wu', 'Bing Mao']",z472421519,13.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Zero-Permission Manipulation: Can We Trust Large Multimodal || Model Powered GUI Agents? || Yi Qian1, Kunwei Qian1, Xingbang He1, Ligeng Chen2, Jikang Zhang3,Tiantai Zhang1, Haiyang Wei1, || Linzhang Wang1, Hao Wu1,, Bing Mao1 || 1State Key Laboratory for Novel Software Technology, Nanjing Univ ... (truncated) ||  || { || ""title"": ""Zero-Permission Manipulation: Can We Trust Large Multimodal Model Powered GUI Agents?"", || ""authors"": [ || ""Yi Qian"", || ""Kunwei Qian"", || ""Xingbang He"", || ""Ligeng Chen"", || ""Jikang Zhang"", || ""Tiantai Zhang"", || ""Haiyang Wei"", || ""Linzhang Wang"", || ""Hao Wu"", || ""Bing Mao"" || ], || ""doi"": ""z472421519"", || ""arxiv_id"": """", || ""keywords"": [ || ""large multimodal model"", || ""GUI agents"", || ""Android"", || ""security"", || ""attack chains"", || ""attack surface"", || ""Android UI"", || ""attack detection"" || ], || ""summary"": ""This paper explores vulnerabilities in Android GUI agents by demonstrating an attack technique called Action Rebinding, which exploits the assumption of visual atomicity. The authors present a strategy to manipulate agent reasoning and bypass verification gates, achieving successful attacks with no sensitive permissions or privileged API calls."" || } ||  || [ Prompt: 37.0 t/s | Generation: 13.6 t/s ]"
2601.12357v1_SimpleMatch A Simple and Strong Baseline for Seman.pdf,SimpleMatch: A Simple and Strong Baseline for Semantic Correspondence,"['Hailong Jin1', 'Huiying Li1']",,14.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SimpleMatch: A Simple and Strong Baseline for Semantic Correspondence || Hailong Jin1 Huiying Li1* || 1Jilin University || Abstract || Recent advances in semantic correspondence have been || largely driven by the use of pre-trained large-scale models. || However, a limitation of these approaches is t ... (truncated) ||  || { || ""title"": ""SimpleMatch: A Simple and Strong Baseline for Semantic Correspondence"", || ""authors"": [""Hailong Jin1"", ""Huiying Li1""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper presents SimpleMatch, a lightweight framework for semantic correspondence that achieves strong performance at low resolutions. It introduces a lightweight upsample decoder and a multi-scale supervised loss to address computational overhead and improves matching accuracy."" || } ||  || [ Prompt: 35.3 t/s | Generation: 14.6 t/s ]"
2601.12358v1_From Prompts to Pavement LMMs-based Agentic Behavi.pdf,From Prompts to Pavement: LMM-based Agentic Behavior-Tree,"['Omar Y. Goba1', 'Ahmed Y. Gado1', 'Catherine M. Elias1', 'Ahmed Hussein3']",,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || From Prompts to Pavement:LMMs-based Agentic Behavior-Tree || Generation Framework for Autonomous Vehicles || Omar Y . Goba1,2, Ahmed Y . Gado1,2, || Catherine M. Elias 1,2 ,Member, IEEEand Ahmed Hussein 3,Senior Member, IEEE || Abstract Autonomous vehicles (A Vs) require adaptive be- || havior pla ... (truncated) ||  || { || ""title"": ""From Prompts to Pavement: LMM-based Agentic Behavior-Tree"", || ""authors"": [ || ""Omar Y. Goba1"", || ""Ahmed Y. Gado1"", || ""Catherine M. Elias1"", || ""Ahmed Hussein3"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Behavior Tree"", || ""Large Language Model"", || ""L5 Autonomy"", || ""Navigation"", || ""ROS"", || ""CARLA"", || ""Nav2"" || ], || ""summary"": ""This paper presents an agentic framework leveraging LLMs and LVMs to generate adaptive behavior trees for autonomous vehicles, demonstrating successful navigation in simulated environments."" || } ||  || [ Prompt: 108.1 t/s | Generation: 28.4 t/s ]"
2601.12374v1_A Scalable Entity-Based Framework for Auditing Bia.pdf,A Scalable Entity-Based Framework for Auditing Bias in LLMs,"['Akram Elbouanani', 'Aboubacar Tuo', 'Adrian Popescu']",1.0 0.5 0.0 0.5 1.0,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A Scalable Entity-Based Framework for Auditing Bias in LLMs || Akram Elbouanani1, Aboubacar Tuo1, Adrian Popescu1, || 1Universit Paris-Saclay, CEA, List, F-91120, Palaiseau, France || Abstract || Existing approaches to bias evaluation in large || language models (LLMs) trade ecological va- || lidity  ... (truncated) ||  || { || ""title"": ""A Scalable Entity-Based Framework for Auditing Bias in LLMs"", || ""authors"": [ || ""Akram Elbouanani"", || ""Aboubacar Tuo"", || ""Adrian Popescu"" || ], || ""doi"": ""1.0 0.5 0.0 0.5 1.0"", || ""arxiv_id"": """", || ""keywords"": [ || ""bias"", || ""LLMs"", || ""auditing"", || ""entities"", || ""fairness"", || ""politics"" || ], || ""summary"": ""This paper introduces a scalable bias-auditing framework using named entities to measure structural disparities in large language models. It presents the largest bias audit to date, analyzing 1.9 billion data points across multiple dimensions and revealing systematic biases such as preference for Western entities and companies."" || } ||  || [ Prompt: 112.5 t/s | Generation: 28.5 t/s ]"
2601.12389v1_NADIR Differential Attention Flow for Non-Autoregr.pdf,Differential Attention Flow for Non-Autoregressive Transliteration in Indic Languages,"['Lakshya Tomar', 'Vinayak Abrol', 'Puneet Agarwal']",,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || NADIR: Differential Attention Flow for Non-Autoregressive Transliteration in || Indic Languages || Lakshya Tomar1, Vinayak Abrol2, Puneet Agarwal 1 || 1RocketFrog AI || 2CSE Department, Indraprastha Institute of Information Technology, Delhi || lakshya.tomar@rocketfrog.ai, abrol@iiitd.ac.in, punee ... (truncated) ||  || { || ""title"": ""Differential Attention Flow for Non-Autoregressive Transliteration in Indic Languages"", || ""authors"": [ || ""Lakshya Tomar"", || ""Vinayak Abrol"", || ""Puneet Agarwal"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This work introduces NADIR, a novel non-autoregressive architecture for multilingual transliteration that balances speed and accuracy by integrating a Differential Transformer and a Mixture-of-Experts mechanism."" || } ||  || [ Prompt: 116.6 t/s | Generation: 28.4 t/s ]"
2601.12392v1_PsychēChat An Empathic Framework Focused on Emotio.pdf,PsycheChat: An Empathic Framework Focused on Emotion Shift Tracking and Safety Risk Analysis in Psychological Counseling,"['Zhentao Xia', 'Yongqi Fan', 'Yuxiang Chu', 'Yichao Yin', 'Liangliang Chen', 'Tong Ruan', 'Weiyan Zhang']",,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || PsycheChat: An Empathic Framework Focused on Emotion Shift Tracking || and Safety Risk Analysis in Psychological Counseling || Zhentao Xia* || , Yongqi Fan* || , Yuxiang Chu, Yichao Yin, || Liangliang Chen,Tong Ruan ,Weiyan Zhang || East China University of Science and Technology, Shanghai, China || Sh ... (truncated) ||  || { || ""title"": ""PsycheChat: An Empathic Framework Focused on Emotion Shift Tracking and Safety Risk Analysis in Psychological Counseling"", || ""authors"": [ || ""Zhentao Xia"", || ""Yongqi Fan"", || ""Yuxiang Chu"", || ""Yichao Yin"", || ""Liangliang Chen"", || ""Tong Ruan"", || ""Weiyan Zhang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""PsycheChat"", || ""emotion shift tracking"", || ""psychological counseling"", || ""safety risk analysis"", || ""LLM"", || ""mental health"" || ], || ""summary"": ""This paper proposes PsycheChat, a framework integrating emotion shift tracking and safety risk analysis for psychological counseling. It introduces interactive role-playing with two modules: Emotion Management Module and Risk Control Module, and presents two modeling paradigms. Experiments show PsycheChat outperforms existing methods in emotional insight and safety control."" || } ||  || [ Prompt: 110.1 t/s | Generation: 28.5 t/s ]"
2601.12401v1_Beyond the Dirac Delta Mitigating Diversity Collap.pdf,Beyond the Dirac Delta: Mitigating Diversity Collapse in Reinforcement,"['Jinmei Liu', 'Haoru Li', 'Zhenhong Sun', 'Bo Wang', 'Daoyi Dong', 'Chunlin Chen', 'Yatao Bian', 'Zhi Wang']",,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Beyond the Dirac Delta: Mitigating Diversity Collapse in Reinforcement || Fine-Tuning for Versatile Image Generation || Jinmei Liu 1 Haoru Li 1 Zhenhong Sun 2 Chaofeng Chen 3 Yatao Bian4 || Bo Wang 1 Daoyi Dong 5 Chunlin Chen 1 Zhi Wang 1 || Abstract || Reinforcement learning (RL) has emerged as a ... (truncated) ||  || { || ""title"": ""Beyond the Dirac Delta: Mitigating Diversity Collapse in Reinforcement"", || ""authors"": [ || ""Jinmei Liu"", || ""Haoru Li"", || ""Zhenhong Sun"", || ""Bo Wang"", || ""Daoyi Dong"", || ""Chunlin Chen"", || ""Yatao Bian"", || ""Zhi Wang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper discusses the diversity collapse in reinforcement learning fine-tuning for image generation and proposes DRIFT to improve diversity while maintaining task alignment."" || } ||  || [ Prompt: 113.1 t/s | Generation: 28.2 t/s ]"
2601.12402v1_Weaknesses of Facial Emotion Recognition Systems.pdf,Weaknesses of Facial Emotion Recognition Systems,"['Aleksandra Jamrz', 'Patrycja Wysocka', 'Piotr Garbat']",arXiv:2601.12402v1,31.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Weaknesses of Facial Emotion Recognition || Systems || Aleksandra Jamrz1, Patrycja Wysocka1,2, and Piotr Garbat1 || 1 Warsaw University of Technology, Poland || 2 SWPS University, Poland || oyamroz@gmail.com, w512patrycja@gmail.com || Abstract.Emotion detection from faces is one of the machine learni ... (truncated) ||  || { || ""title"": ""Weaknesses of Facial Emotion Recognition Systems"", || ""authors"": [ || ""Aleksandra Jamrz"", || ""Patrycja Wysocka"", || ""Piotr Garbat"" || ], || ""doi"": ""arXiv:2601.12402v1"", || ""arxiv_id"": ""arXiv:2601.12402"", || ""keywords"": [ || ""Facial Emotion Recognition"", || ""Deep learning"", || ""Computer"", || ""Vision"" || ], || ""summary"": ""This study presents a comprehensive analysis of the most advanced facial emotion recognition solutions, evaluating network performance across different datasets and highlighting weaknesses such as dataset differences, varying difficulty levels, and challenges in distinguishing closely related emotions."" || } ||  || [ Prompt: 123.2 t/s | Generation: 31.3 t/s ]"
2601.12405v1_Explainable Machine Learning for Pediatric Dental .pdf,Explainable Machine Learning for Pediatric Dental Risk Stratification Using Socio-Demographic Determinants,"['Manasi Kanade', 'Abhi Thakkar', 'Gabriela Fernandes']",,30.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Explainable Machine Learning for Pediatric Dental Risk Stratification Using Socio- || Demographic Determinants || Manasi Kanade1, Abhi Thakkar2, Gabriela Fernandes3 || 1 Department of Pediatric Dentistry, Loma Linda University, Los Angeles, California, USA || 2 Camarena Dental Health, Madera ... (truncated) ||  || { || ""title"": ""Explainable Machine Learning for Pediatric Dental Risk Stratification Using Socio-Demographic Determinants"", || ""authors"": [ || ""Manasi Kanade"", || ""Abhi Thakkar"", || ""Gabriela Fernandes"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""pediatric dental disease"", || ""socio-economic determinants"", || ""demographic factors"", || ""explainable AI"", || ""risk stratification"" || ], || ""summary"": ""This study explores the use of explainable AI to stratify pediatric dental risk by incorporating socio-demographic factors, emphasizing interpretability and ethical deployment."" || } ||  || [ Prompt: 124.1 t/s | Generation: 30.6 t/s ]"
2601.12410v1_Are LLMs Smarter Than Chimpanzees An Evaluation on.pdf,Are LLMs Smarter Than Chimpanzees?,"['Dingyi Yang', 'Junqi Zhao', 'Xue Li', 'Ce Li', 'Boyang Li']",,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Are LLMs Smarter Than Chimpanzees? || An Evaluation on Perspective Taking and Knowledge State Estimation || Dingyi Yang1, Junqi Zhao1, Xue Li2, Ce Li3, Boyang Li1* || 1College of Computing and Data Science, Nanyang Technological University || 2University of Science and Technology of China || 3Chin ... (truncated) ||  || { || ""title"": ""Are LLMs Smarter Than Chimpanzees?"", || ""authors"": [ || ""Dingyi Yang"", || ""Junqi Zhao"", || ""Xue Li"", || ""Ce Li"", || ""Boyang Li"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper evaluates LLM performance in knowledge state tracking and estimation, comparing it to chimpanzees, and argues for future focus on intention understanding and knowledge estimation."" || } ||  || [ Prompt: 114.1 t/s | Generation: 28.2 t/s ]"
2601.12415v1_Orthogonalized Policy OptimizationDecoupling Sampl.pdf,Orthogonalized Policy Optimization,['Wang Zixian'],arXiv:2601.12415v1,27.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Orthogonalized Policy Optimization || Decoupling Sampling Geometry from Optimization Geometry in RLHF || Wang Zixian || China Mobile Communications Group Shandong Co., Ltd. Taian Branch || wangzixian@sd.chinamobile.com || Abstract || Recent alignment methods for large language models, including PPO,  ... (truncated) ||  || { || ""title"": ""Orthogonalized Policy Optimization"", || ""authors"": [""Wang Zixian""], || ""doi"": ""arXiv:2601.12415v1"", || ""arxiv_id"": ""arXiv:2601.12415"", || ""keywords"": [], || ""summary"": ""This paper discusses decoupling sampling geometry from optimization geometry in RLHF, introducing Orthogonalized Policy Optimization (OPO) to address numerical issues in alignment methods."" || } ||  || [ Prompt: 119.1 t/s | Generation: 27.3 t/s ]"
2601.12436v1_Purification Before Fusion Toward Mask-Free Speech.pdf,Purification Before Fusion: Mask-Free Speech Enhancement for Robust Audio-Visual Speech Recognition,"['Linzhi Wu1', 'Xingyu Zhang2', 'Hao Yuan3', 'Yakun Zhang2', 'Changyan Zheng4', 'Liang Xie2', 'Tiejun Liu1', 'Erwei Yin2']",,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || PURIFICA TION BEFORE FUSION: TOW ARD MASK-FREE SPEECH ENHANCEMENT FOR || ROBUST AUDIO-VISUAL SPEECH RECOGNITION || Linzhi Wu1,2, Xingyu Zhang2, Hao Yuan3,2, Yakun Zhang2, Changyan Zheng4,2 || Liang Xie2, Tiejun Liu1, Erwei Yin2 || 1University of Electronic Science and Technology of China, Cheng ... (truncated) ||  || { || ""title"": ""Purification Before Fusion: Mask-Free Speech Enhancement for Robust Audio-Visual Speech Recognition"", || ""authors"": [ || ""Linzhi Wu1"", || ""Xingyu Zhang2"", || ""Hao Yuan3"", || ""Yakun Zhang2"", || ""Changyan Zheng4"", || ""Liang Xie2"", || ""Tiejun Liu1"", || ""Erwei Yin2"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""audio-visual speech recognition"", || ""speech feature enhancement"", || ""noise-robust"", || ""multimodal bottleneck Conformer"" || ], || ""summary"": ""This work proposes an end-to-end noise-robust A VSR framework that integrates speech enhancement with speech enhancement using a Conformer-based bottleneck fusion module. It aims to preserve semantic integrity while improving recognition performance under noisy conditions."" || } ||  || [ Prompt: 110.0 t/s | Generation: 28.8 t/s ]"
2601.12442v1_Constraint-Aware Neurosymbolic Uncertainty Quantif.pdf,Constraint-Aware Neurosymbolic Uncertainty,"['Shahnawaz Alam', 'Mohammed Mudassir Uddin', 'Mohammed Kaif Pasha']",,27.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Constraint-Aware Neurosymbolic Uncertainty || Quantification with Bayesian Deep Learning for Scientific || Discovery || Shahnawaz Alam1,, Mohammed Mudassir Uddin 1, Mohammed Kaif Pasha 1 || 1Department of Computer Science and Engineering || Muffakham Jah College of Engineering and Technology (MJCE ... (truncated) ||  || { || ""title"": ""Constraint-Aware Neurosymbolic Uncertainty"", || ""authors"": [ || ""Shahnawaz Alam"", || ""Mohammed Mudassir Uddin"", || ""Mohammed Kaif Pasha"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Neurosymbolic AI"", || ""Uncertainty Quantification"", || ""Bayesian Deep Learning"", || ""Scientific Constraints"", || ""Calibration"", || ""Physics-Informed Machine Learning"" || ], || ""summary"": ""The paper introduces the Constraint-Aware Neurosymbolic Uncertainty Framework (CANUF), unifying Bayesian deep learning with differentiable symbolic reasoning to deliver trustworthy uncertainty in scientific AI applications. It demonstrates improved calibration and constraint satisfaction compared to existing methods."" || } ||  || [ Prompt: 118.1 t/s | Generation: 27.3 t/s ]"
2601.12443v1_Adversarial Defense in Vision-Language Models An O.pdf,Adversarial Defense in Vision-Language Models: An Overview,"['Xiaowei Fu', 'Lei Zhang']",,26.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Adversarial Defense in Vision-Language Models: || An Overview || Xiaowei Fu || School of Microelectronics and Communication Engineering || Chongqing University || Chongqing, China || xwfu@cqu.edu.cn || Lei Zhang* || School of Microelectronics and Communication Engineering || Chongqing University || Chongqing, Ch ... (truncated) ||  || { || ""title"": ""Adversarial Defense in Vision-Language Models: An Overview"", || ""authors"": [ || ""Xiaowei Fu"", || ""Lei Zhang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Vision Language Models"", || ""adversarial defense"", || ""survey"", || ""robustness"", || ""attacks"" || ], || ""summary"": ""This paper reviews recent advancements in adversarial defense strategies for Vision Language Models, discussing training-time defense, test-time adaptation, and training-free approaches, while highlighting challenges and limitations."" || } ||  || [ Prompt: 108.1 t/s | Generation: 26.1 t/s ]"
2601.12444v1_Large Language Model for OWL Proofs.pdf,Large Language Model for OWL Proofs,"['Hui Yang', 'Jiaoyan Chen', 'Uli Sattler']",10.1145/XXXXXX.XXXXXX,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Large Language Model for OWL Proofs || Hui Yang || The University of Manchester || Manchester, UK || hui.yang-2@manchetser.ac.uk || Jiaoyan Chen || The University of Manchester || Manchester, UK || jiaoyan.chen@manchester.ac.uk || Uli Sattler || The University of Manchester || Manchester, UK || uli.sattler@manchester. ... (truncated) ||  || { || ""title"": ""Large Language Model for OWL Proofs"", || ""authors"": [ || ""Hui Yang"", || ""Jiaoyan Chen"", || ""Uli Sattler"" || ], || ""doi"": ""10.1145/XXXXXX.XXXXXX"", || ""arxiv_id"": """", || ""keywords"": [ || ""Large Language Models"", || ""OWL ontologies"", || ""Reasoning"", || ""Proof generation"", || ""Natural language generation"" || ], || ""summary"": ""This work studies proof generation in OWL ontologies using an automated dataset construction and evaluation framework. It evaluates three tasks: Extraction, Simplification, Explanation, and Logic Completeness assessment, revealing insights on model limitations and data quality impacts."" || } ||  || [ Prompt: 113.0 t/s | Generation: 28.2 t/s ]"
2601.12449v1_AgenTRIM Tool Risk Mitigation for Agentic AI.pdf,AgenTRIM: Tool Risk Mitigation for Agentic AI,"['Roy Betser', 'Shamik Bose', 'Amit Giloni', 'Chiara Picardi', 'Sindhu Padakandla', 'Roman Vainshtein']",10.1093/acps/ccad025,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || AgenTRIM: Tool Risk Mitigation for Agentic AI || Roy Betser1*, Shamik Bose1, Amit Giloni1, || Chiara Picardi1,Sindhu Padakandla 2,Roman Vainshtein 1 || 1Fujitsu Research of Europe (FRE), 2Fujitsu Research of India Pvt. Ltd. (FRIPL) || Correspondence:roy.betser@fujitsu.com || Abstract || AI agents are ... (truncated) ||  || { || ""title"": ""AgenTRIM: Tool Risk Mitigation for Agentic AI"", || ""authors"": [ || ""Roy Betser"", || ""Shamik Bose"", || ""Amit Giloni"", || ""Chiara Picardi"", || ""Sindhu Padakandla"", || ""Roman Vainshtein"" || ], || ""doi"": ""10.1093/acps/ccad025"", || ""arxiv_id"": """", || ""keywords"": [ || ""AI agents"", || ""tool risk mitigation"", || ""agentic AI"", || ""security risks"", || ""tool permissions"", || ""external tools"", || ""attack surface"", || ""attack surface expansion"" || ], || ""summary"": ""The paper introduces AGENTRIM, a framework for detecting and mitigating tool-driven agency risks in LLM-based agents. It addresses security issues like indirect prompt injection and tool misuse by enforcing least-privilege tool access during both offline and online phases. AGENTRIM helps maintain high performance while reducing attack surfaces."" || } ||  || [ Prompt: 113.1 t/s | Generation: 28.4 t/s ]"
2601.12465v1_Incentivizing In-depth Reasoning over Long Context.pdf,Incentivizing In-Depth Reasoning Over Long,"['Miao Peng1', 'Weizhou Shen2', 'Nuo Chen1', 'Chenliang Li2', 'Ming Yan2', 'Jia Li1']","mpeng885, jialee",28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Preprint || INCENTIVIZINGIN-DEPTHREASONING OVERLONG || CONTEXTS WITHPROCESSADVANTAGESHAPING || Miao Peng1,2 Weizhou Shen2 Nuo Chen1 Chenliang Li2 Ming Yan2 Jia Li1 || 1The Hong Kong University of Science and Technology (Guangzhou) || 2Tongyi Lab, Alibaba Group || {mpeng885, jialee}@connect.hkust-gz.e ... (truncated) ||  || { || ""title"": ""Incentivizing In-Depth Reasoning Over Long"", || ""authors"": [ || ""Miao Peng1"", || ""Weizhou Shen2"", || ""Nuo Chen1"", || ""Chenliang Li2"", || ""Ming Yan2"", || ""Jia Li1"" || ], || ""doi"": ""mpeng885, jialee"", || ""arxiv_id"": """", || ""keywords"": [ || ""Reinforcement Learning"", || ""Verifiable Rewards"", || ""Long-context reasoning"", || ""LLMs"", || ""multi-hop reasoning"", || ""credit assignment"", || ""reasoning chains"" || ], || ""summary"": ""The paper discusses limitations of RLVR in long-context scenarios and introduces DEEPREASONQA and LONGPAS to improve reasoning accuracy by addressing reasoning density and learning signal preservation."" || } ||  || [ Prompt: 112.1 t/s | Generation: 28.5 t/s ]"
2601.12467v1_Patch-Level Tokenization with CNN Encoders and Att.pdf,Patch-Level Tokenization with CNN Encoders and Attention for Improved Transformer Time-Series,['Saurish Nagrath'],,27.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Patch-Level Tokenization with CNN Encoders and || Attention for Improved Transformer Time-Series || Forecasting || Saurish Nagrath || VIT-AP || AbstractTransformer-based models have shown strong per- || formance in time-series forecasting by leveraging self-attention || to model long-range temporal depe ... (truncated) ||  || { || ""title"": ""Patch-Level Tokenization with CNN Encoders and Attention for Improved Transformer Time-Series"", || ""authors"": [""Saurish Nagrath""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""multivariate time-series forecasting"", || ""financial time-series forecasting"", || ""Transformer models"", || ""temporal tokenization"", || ""convolutional neural networks"", || ""attention mechanisms"", || ""representation learning"", || ""deep learning for finance"" || ], || ""summary"": ""This work proposes a two-stage forecasting framework that combines convolutional neural networks for local temporal representation and transformer self-attention for global dependency modeling. The approach achieves competitive forecasting performance on synthetic multivariate time-series data."" || } ||  || [ Prompt: 116.8 t/s | Generation: 27.4 t/s ]"
2601.12471v1_Knowing When to Abstain Medical LLMs Under Clinica.pdf,Knowing When to Abstain: Medical LLMs Under Clinical Uncertainty,"['Sravanthi Machcha', 'Sushrita Yerra', 'Sahil Gupta', 'Aishwarya Sahoo', 'Sharmin Sultana', 'Hong Yu', 'Zonghai Yao']",https://github.com/sravanthi6m/MedAbstain,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Knowing When to Abstain: Medical LLMs Under Clinical Uncertainty || Sravanthi Machcha* 1, Sushrita Yerra* 1, Sahil Gupta 1, Aishwarya Sahoo 1, || Sharmin Sultana 2,3,Hong Yu 1,2,3,Zonghai Yao 1,2 || 1Manning College of Information and Computer Sciences, UMass Amherst, MA, USA || 2Center for Hea ... (truncated) ||  || { || ""title"": ""Knowing When to Abstain: Medical LLMs Under Clinical Uncertainty"", || ""authors"": [ || ""Sravanthi Machcha"", || ""Sushrita Yerra"", || ""Sahil Gupta"", || ""Aishwarya Sahoo"", || ""Sharmin Sultana"", || ""Hong Yu"", || ""Zonghai Yao"" || ], || ""doi"": ""https://github.com/sravanthi6m/MedAbstain"", || ""arxiv_id"": """", || ""keywords"": [ || ""medical LLMs"", || ""clinical uncertainty"", || ""abstain mechanisms"", || ""medical QA"", || ""uncertainty handling"" || ], || ""summary"": ""Current evaluation of large language models prioritizes accuracy, but in real-world applications, the ability to abstain when uncertain is crucial for trustworthy deployment. This paper introduces MedAbstain, a benchmark for abstention in medical multiple-choice question answering, highlighting that models often fail to abstain despite high accuracy."" || } ||  || [ Prompt: 109.7 t/s | Generation: 28.8 t/s ]"
2601.12494v1_Harmonizing the Arabic Audio Space with Data Sched.pdf,Harmonizing the Arabic Audio Space with Data Scheduling,"['Hunzalah Hassan Bhatti', 'Firoj Alam', 'Shammur Absar Chowdhury']",,28.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Harmonizing the Arabic Audio Space with Data Scheduling || Hunzalah Hassan Bhatti, Firoj Alam, Shammur Absar Chowdhury || Qatar Computing Research Institute, Qatar || hunzalahhassan@gmail.com, {alam, shchowdhury}@hbku.edu.qa || Abstract || Audio large language models (LLMs) en- || able unied speech u ... (truncated) ||  || { || ""title"": ""Harmonizing the Arabic Audio Space with Data Scheduling"", || ""authors"": [""Hunzalah Hassan Bhatti"", ""Firoj Alam"", ""Shammur Absar Chowdhury""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Arabic"", ""audio"", ""LLM"", ""data scheduling"", ""generative tasks""], || ""summary"": ""This paper presents the first systematic study of multi-task instruction tuning for an Arabic-centric audio LLM, covering generative tasks (ASR, speech summarization) and discriminative tasks (dialect and emotion identification). It introduces AraMega-SSum dataset and proposes a Hybrid TPC+ADS Strategy to address efficiency and robustness challenges."" || } ||  || [ Prompt: 113.0 t/s | Generation: 28.9 t/s ]"
2601.12499v1_Failure Modes in Multi-Hop QA The Weakest Link Law.pdf,Failure Modes in Multi-Hop QA: The Weakest Link Law and the Recognition Bottleneck,"['Meiru Zhang', 'Zaiqiao Meng', 'Nigel Collier']",mz468@cam.ac.uk,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Failure Modes in Multi-Hop QA: The Weakest Link Law and the || Recognition Bottleneck || Meiru Zhang || University of Cambridge || mz468@cam.ac.uk || Zaiqiao Meng || University of Cambridge || zm324@cam.ac.uk || Nigel Collier || University of Cambridge || nhc30@cam.ac.uk || Abstract || Despite scaling to massive conte ... (truncated) ||  || { || ""title"": ""Failure Modes in Multi-Hop QA: The Weakest Link Law and the Recognition Bottleneck"", || ""authors"": [ || ""Meiru Zhang"", || ""Zaiqiao Meng"", || ""Nigel Collier"" || ], || ""doi"": ""mz468@cam.ac.uk"", || ""arxiv_id"": ""nhc30@cam.ac.uk"", || ""keywords"": [ || ""LLM"", || ""multi-hop reasoning"", || ""position bias"", || ""recognition failure"", || ""system-2 reasoning"" || ], || ""summary"": ""This paper investigates why Large Language Models struggle with multi-hop reasoning due to position bias. It introduces Multi-Focus Attention Instruction (MFAI) to address recognition bottlenecks and demonstrates that performance depends on the visibility of evidence rather than linear distance. The study reveals dual effects of attention steering and highlights improvements in accuracy through targeted interventions."" || } ||  || [ Prompt: 107.6 t/s | Generation: 28.1 t/s ]"
2601.12518v1_Cooperative Multi-agent RL with Communication Cons.pdf,Cooperative Multi-agent RL with Communication constraints,"['Nuoya Xiong', 'Aarti Singh']",,30.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Cooperative Multi-agent RL with Communication constraints || Nuoya Xiong  Aarti Singh || January 21, 2026 || Abstract || Cooperative Multi-agent reinforcement learning (MARL) often assumes frequent access to global || information in a data buffer, such as team rewards or other agents actions, whi ... (truncated) ||  || { || ""title"": ""Cooperative Multi-agent RL with Communication constraints"", || ""authors"": [""Nuoya Xiong"", ""Aarti Singh""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper discusses challenges in cooperative multi-agent reinforcement learning under communication constraints, introducing base policy prediction to reduce communication costs while maintaining performance."" || } ||  || [ Prompt: 116.5 t/s | Generation: 30.1 t/s ]"
2601.12522v1_Improved Bug Localization with AI Agents Leveragin.pdf,Improved Bug Localization with AI Agents Leveraging Hypothesis and Dynamic Cognition,"['Asif Mohammed Samir', 'Mohammad Masudur Rahman']",https://doi.org/,27.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Improved Bug Localization with AI Agents Leveraging || Hypothesis and Dynamic Cognition || Asif Mohammed Samir || Dalhousie University || Halifax, NS, Canada || asifsamir@dal.ca || Mohammad Masudur Rahman || Dalhousie University || Halifax, NS, Canada || masud.rahman@dal.ca || Abstract || Software bugs cost technol ... (truncated) ||  || { || ""title"": ""Improved Bug Localization with AI Agents Leveraging Hypothesis and Dynamic Cognition"", || ""authors"": [ || ""Asif Mohammed Samir"", || ""Mohammad Masudur Rahman"" || ], || ""doi"": ""https://doi.org/"", || ""arxiv_id"": """", || ""keywords"": [ || ""Bug Localization"", || ""LLM"", || ""Agentic AI"", || ""Cognition"", || ""Debugging"", || ""Software Engineering"", || ""Information Retrieval"" || ], || ""summary"": ""The paper presents CogniGent, an agentic technique for bug localization that leverages multiple AI agents, causal reasoning, call-graph analysis, and context engineering. It achieves significant improvements over traditional and LLM-based methods in performance metrics."" || } ||  || [ Prompt: 110.5 t/s | Generation: 27.2 t/s ]"
2601.12534v1_Encoding Emotion Through Self-Supervised Eye Movem.pdf,Encoding Emotion Through Self-Supervised Eye Movement Reconstruction,"['Marcus Ma', 'Jordan Prescott', 'Emily Zhou', 'Tiantian Feng', 'Kleanthis Avramidis', 'Gabor Mihaly Toth', 'Shrikanth Narayanan']",,27.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ENCODING EMOTION THROUGH SELF-SUPERVISED || EYE MOVEMENT RECONSTRUCTION || Marcus Ma1, Jordan Prescott1, Emily Zhou1, Tiantian Feng1, || Kleanthis Avramidis1, Gabor Mihaly Toth2, Shrikanth Narayanan1 || 1University of Southern California, 2University of Luxembourg || ABSTRACT || The relationship betw ... (truncated) ||  || { || ""title"": ""Encoding Emotion Through Self-Supervised Eye Movement Reconstruction"", || ""authors"": [ || ""Marcus Ma"", || ""Jordan Prescott"", || ""Emily Zhou"", || ""Tiantian Feng"", || ""Kleanthis Avramidis"", || ""Gabor Mihaly Toth"", || ""Shrikanth Narayanan"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""eye movement"", || ""self-supervised learning"", || ""emotion prediction"", || ""deep learning"", || ""Holocaust survivors"", || ""Holocaust concentration camp"" || ], || ""summary"": ""This study explores how eye movement can predict emotional expressions using self-supervised models trained on naturalistic videos. The researchers developed a gaze detection model leveraging pretraining on language models and applied it to emotional expression tasks in Holocaust survivor interviews."" || } ||  || [ Prompt: 106.9 t/s | Generation: 27.2 t/s ]"
2601.12535v1_Improving Low-Resource Machine Translation via Rou.pdf,Improving Low-Resource Machine Translation via Round-Trip,"['Ahmed Attia', 'Alham Fikri', 'MBZUAI', 'Masdar City, UAE']",,26.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Improving Low-Resource Machine Translation via Round-Trip || Reinforcement Learning || Ahmed Attia || MBZUAI || Masdar City, UAE || ahmed.attia@mbzuai.ac.ae || Alham Fikri || MBZUAI || Masdar City, UAE || alham.fikri@mbzuai.ac.ae || Abstract || Low-resource machine translation (MT) has || gained increasing attention a ... (truncated) ||  || { || ""title"": ""Improving Low-Resource Machine Translation via Round-Trip"", || ""authors"": [ || ""Ahmed Attia"", || ""Alham Fikri"", || ""MBZUAI"", || ""Masdar City, UAE"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper presents a self-supervised reinforcement learning-based fine-tuning approach for low-resource machine translation using round-trip bootstrapping with the No Language Left Behind family of models. The method translates English into a target low-resource language and back, optimizing translation quality through reward functions based on BLEU and chrF++."" || } ||  || [ Prompt: 115.6 t/s | Generation: 26.6 t/s ]"
2601.12538v1_Agentic Reasoning for Large Language Models.pdf,Agentic Reasoning for Large Language Models,"['Tianxin Wei', 'Ting-Wei Li', 'Zhining Liu', 'Xuying Ning', 'Ze Yang', 'Jiaru Zou', 'Zhichen Zeng', 'Ruixiang Qiu', 'Xiao Lin', 'Dongqi Fu', 'Yiang Xiao', 'Heng Ji', 'Hanghang Tong', 'Jingrui He']",,27.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Agentic Reasoning for Large Language Models || FoundationsEvolutionCollaboration || Tianxin Wei1 Ting-Wei Li1 Zhining Liu1 Xuying Ning1 Ze Yang2 Jiaru Zou1 || Zhichen Zeng1 Ruizhong Qiu1 Xiao Lin1 Dongqi Fu2 Zihao Li1 Mengting Ai1 Duo Zhou1 || Wenxuan Bao1 Yunzhe Li1 Gaotang Li1 Cheng Qian1 Yu  ... (truncated) ||  || { || ""title"": ""Agentic Reasoning for Large Language Models"", || ""authors"": [ || ""Tianxin Wei"", || ""Ting-Wei Li"", || ""Zhining Liu"", || ""Xuying Ning"", || ""Ze Yang"", || ""Jiaru Zou"", || ""Zhichen Zeng"", || ""Ruixiang Qiu"", || ""Xiao Lin"", || ""Dongqi Fu"", || ""Yiang Xiao"", || ""Heng Ji"", || ""Hanghang Tong"", || ""Jingrui He"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Agentic AI"", || ""LLM Agent"", || ""Agentic Reasoning"", || ""Self-evolving"", || ""Collective Multi-agent Reasoning"" || ], || ""summary"": ""Reasoning is a fundamental cognitive process underlying inference, problem-solving, and decision-making. While large language models (LLMs) demonstrate strong reasoning capabilities in closed-world settings, they struggle in open-ended and dynamic environments. The emergence of agentic reasoning marks a paradigm shift, bridging thought and action by reframing LLMs as autonomous agents that plan, act, and learn through continual interaction. In this survey, we provide a systematic roadmap by organizing agentic reasoning along three complementary dimensions."" || } ||  || [ Prompt: 110.8 t/s | Generation: 27.4 t/s ]"
2601.12539v1_MemeLens Multilingual Multitask VLMs for Memes.pdf,MemeLens: Multilingual Multitask VLMs for Memes,"['Ali Ezzat Shahroor', 'Mohamed Bayan Kmainasi', 'Abul Hasnat', 'Dimitar Dimitrov', 'Giovanni Da San Martino', 'Preslav Nakov', 'Firoj Alam']","fialam, alsh34060",28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MemeLens: Multilingual Multitask VLMs for Memes || Ali Ezzat Shahroor1*, Mohamed Bayan Kmainasi2 , Abul Hasnat3,4 , || Dimitar Dimitrov, Giovanni Da San Martino, Preslav Nakov, Firoj Alam1 || 1Qatar Computing Research Institute, Qatar, 2Qatar University, Qatar, || 3Blackbird.AI, USA, 4APA VI.AI ... (truncated) ||  || { || ""title"": ""MemeLens: Multilingual Multitask VLMs for Memes"", || ""authors"": [ || ""Ali Ezzat Shahroor"", || ""Mohamed Bayan Kmainasi"", || ""Abul Hasnat"", || ""Dimitar Dimitrov"", || ""Giovanni Da San Martino"", || ""Preslav Nakov"", || ""Firoj Alam"" || ], || ""doi"": ""fialam, alsh34060"", || ""arxiv_id"": ""mha/2303.04112"", || ""keywords"": [ || ""memes"", || ""multilingual"", || ""multitask"", || ""VLM"", || ""meme understanding"" || ], || ""summary"": ""This paper proposes MEMELENS, a unified multilingual and multitask explanation-enhanced Vision Language Model for meme understanding. It consolidates 38 public meme datasets and presents a comprehensive empirical analysis across modeling paradigms, highlighting the need for multimodal training and caution against over-specialization."" || } ||  || [ Prompt: 104.9 t/s | Generation: 28.6 t/s ]"
2601.12542v1_Rethinking the AI Scientist Interactive Multi-Agen.pdf,Rethinking the AI Scientist: Interactive Multi-Agent,"['Lukas Weidener', 'Marko Brki', 'Mihailo Jovanovi', 'Ritvik Singh', 'Chiara Baccin', 'Emre Ulgac', 'Alex Dobrin', 'Aakaash Meduri']",https://github.com/bio-xyz/BioAgents,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Rethinking the AI Scientist: Interactive Multi-Agent || Workflows for Scientific Discovery || Lukas Weidener*    ; Marko Brki    ; Mihailo Jovanovi    ;  Ritvik Singh; Chiara Baccin; Emre || Ulgac; Alex Dobrin; Aakaash Meduri || https://github.com/bio-xyz/BioAgents || Abstract  .  Artif ... (truncated) ||  || { || ""title"": ""Rethinking the AI Scientist: Interactive Multi-Agent"", || ""authors"": [ || ""Lukas Weidener"", || ""Marko Brki"", || ""Mihailo Jovanovi"", || ""Ritvik Singh"", || ""Chiara Baccin"", || ""Emre Ulgac"", || ""Alex Dobrin"", || ""Aakaash Meduri"" || ], || ""doi"": ""https://github.com/bio-xyz/BioAgents"", || ""arxiv_id"": """", || ""keywords"": [ || ""artificial intelligence"", || ""scientific discovery"", || ""multi-agent system"", || ""interactive scientific investigation"", || ""open access literature"", || ""novelty detection"" || ], || ""summary"": ""Artificial intelligence systems for scientific discovery have demonstrated remarkable potential, yet existing approaches remain largely proprietary and operate in batch-processing modes requiring hours per research cycle, precluding real-time researcher guidance. This paper introduces Deep Research, a multi-agent system enabling interactive scientific investigation with turnaround times measured in minutes. The architecture comprises specialized agents for planning, data analysis, literature search, and novelty detection, unified through a persistent world state that maintains context across iterative research cycles. Two operational modes support different workflows: semi-autonomous mode with selective human checkpoints, and fully autonomous mode for extended investigations. Evaluation on the BixBench computational biology benchmark demonstrated state-of-the-art performance, achieving 48.8% accuracy on open response and 64.5% on multiple-choice evaluation, exceeding existing baselines by 14 to 26 percentage points."" || } ||  || [ Prompt: 112.1 t/s | Generation: 27.9 t/s ]"
2601.12547v1_How Clinicians Think and What AI Can Learn From It.pdf,How Clinicians Think and What AI Can Learn From,"['Dr. Dipayan Sengupta, MD', 'Dr. Saumya Panda, MD']",,27.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || How Clinicians Thinkand What AI Can Learn From || It: || Ordinal-First, Robust Decision Algorithms for Medicine || Dr. Dipayan Sengupta, MD (Dermatology) 1 and Dr. Saumya Panda, MD (Dermatology) 2 || 1Consultant Dermatologist, Charnock Hospital, Kolkata, India || 2Professor and Head, Department of ... (truncated) ||  || { || ""title"": ""How Clinicians Think and What AI Can Learn From"", || ""authors"": [ || ""Dr. Dipayan Sengupta, MD"", || ""Dr. Saumya Panda, MD"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""clinical AI"", || ""decision-making"", || ""ordinal reasoning"", || ""healthcare"", || ""patient values"" || ], || ""summary"": ""The paper argues that clinician reasoning is not about optimizing probabilities but about ordinal, non-compensatory decisions shaped by heuristics. It proposes that AI should support robust, rule-based decision-making rather than probabilistic prediction."" || } ||  || [ Prompt: 108.5 t/s | Generation: 27.0 t/s ]"
2601.12549v1_Benchmarking Concept-Spilling Across Languages in .pdf,Benchmarking Concept-Spilling Across Languages in LLMs,"['Ilia Badanin', 'Daniil Dzenhaliou', 'Imanol Schlag']",arXiv:2601.12549v1,27.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Benchmarking Concept-Spilling Across Languages in LLMs || Ilia Badanin || EPFL || ilia.badanin@epfl.ch || Daniil Dzenhaliou || EPFL || daniil.dzenhaliou@epfl.ch || Imanol Schlag || ETH AI Center || ischlag@ethz.ch || Abstract || Multilingual Large Language Models || (LLMs) exhibit remarkable cross-lingual || abilities, y ... (truncated) ||  || { || ""title"": ""Benchmarking Concept-Spilling Across Languages in LLMs"", || ""authors"": [ || ""Ilia Badanin"", || ""Daniil Dzenhaliou"", || ""Imanol Schlag"" || ], || ""doi"": ""arXiv:2601.12549v1"", || ""arxiv_id"": ""arXiv:2601.12549"", || ""keywords"": [ || ""multilingual models"", || ""semantic robustness"", || ""language spilling"", || ""polysemy"", || ""cross-lingual evaluation"" || ], || ""summary"": ""This paper presents a comparative framework for evaluating multilingual semantic robustness by measuring how models handle polysemous words across languages. It introduces a methodology to assess semantic interference, particularly language spilling, and evaluates models using a structured meaning generation task across nine languages."" || } ||  || [ Prompt: 107.7 t/s | Generation: 27.1 t/s ]"
2601.12554v1_Artificial Intelligence in Materials Science and E.pdf,"Artificial Intelligence in Materials Science and Engineering: Current Landscape, Key Challenges, and Future","['Iman Peivaste', 'Salim Belouettar', 'Francesco Mercuri', 'Nicholas Fantuzzi', 'Hamidreza Dehghani', 'Razieh Izadi', 'Halliru Ibrahim', 'Jakub Lengiewicz', 'Mal Belouettar-Mathis', 'Kouider Bendine', 'Ahmed Makradi', 'Martin Hrsch', 'Peter Klein', 'Mohamed El Hachemi', 'Yacine Rezgui', 'Natalia Konchakova', 'Ali Daouadji', 'Luxembourg Institute of Science and Technology (LIST)', 'Department of Physics and Materials Science, University of Luxembourg', 'Istituto per lo Studio dei Materiali Nanostrutturati (ISMN)', 'Norwegian University of Life Sciences (NMBU)', 'Fraunhofer Institute for Industrial Mathematics (ITWM)', 'Ecole Centrale de Lyon', 'Norwegian University of Science and Technology (NTNU)', 'School of Engineering, Cardiff University', 'INSA Lyon']",arXiv:2601.12554v1,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Artificial Intelligence in Materials Science and Engineering: || Current Landscape, Key Challenges, and Future || Trajectories. || Iman Peivaste1,2, Salim Belouettar 1, Francesco Mercuri 3, Nicholas Fantuzzi 4, || Hamidreza Dehghani 1, Razieh Izadi 1, Halliru Ibrahim 1, Jakub Lengiewicz 1, Mal || ... (truncated) ||  || { || ""title"": ""Artificial Intelligence in Materials Science and Engineering: Current Landscape, Key Challenges, and Future"", || ""authors"": [ || ""Iman Peivaste"", || ""Salim Belouettar"", || ""Francesco Mercuri"", || ""Nicholas Fantuzzi"", || ""Hamidreza Dehghani"", || ""Razieh Izadi"", || ""Halliru Ibrahim"", || ""Jakub Lengiewicz"", || ""Mal Belouettar-Mathis"", || ""Kouider Bendine"", || ""Ahmed Makradi"", || ""Martin Hrsch"", || ""Peter Klein"", || ""Mohamed El Hachemi"", || ""Yacine Rezgui"", || ""Natalia Konchakova"", || ""Ali Daouadji"", || ""Luxembourg Institute of Science and Technology (LIST)"", || ""Department of Physics and Materials Science, University of Luxembourg"", || ""Istituto per lo Studio dei Materiali Nanostrutturati (ISMN)"", || ""Norwegian University of Life Sciences (NMBU)"", || ""Fraunhofer Institute for Industrial Mathematics (ITWM)"", || ""Ecole Centrale de Lyon"", || ""Norwegian University of Science and Technology (NTNU)"", || ""School of Engineering, Cardiff University"", || ""INSA Lyon"" || ], || ""doi"": ""arXiv:2601.12554v1"", || ""arxiv_id"": """", || ""keywords"": [ || ""Artificial Intelligence"", || ""Materials Science"", || ""Engineering"", || ""Machine Learning"", || ""Deep Learning"", || ""Generative AI"", || ""Data Representation"", || ""Uncertainty Quantification"" || ], || ""summary"": ""Artificial Intelligence is rapidly transforming materials science and engineering, providing powerful tools to navigate complexity, accelerate discovery, and optimize material design in ways previously unattainable. This review offers a comprehensive overview of recent advancements and methodologies, covering machine learning approaches, data strategies, and emerging AI techniques."" || } ||  || [ Prompt: 112.5 t/s | Generation: 28.3 t/s ]"
2601.12557v1_Life Machine Learning and the Search for Habitabil.pdf,"Life, Machine Learning, and the Search for Habitability: Predicting Biosignature","['Mark Moussa1', 'Amber V . Young1', 'Brianna Isola1', 'Vasuda Trehan1', 'Michael D. Himes1', 'Nicholas Wogan2', 'Giada Arney1']",10.48550/arXiv.2407.04219,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Life, Machine Learning, and the Search for Habitability: Predicting Biosignature || Fluxes for the Habitable Worlds Observatory || Mark Moussa1, Amber V . Young1, Brianna Isola1,3, Vasuda Trehan1,4, Michael D. Himes1,5, || Nicholas Wogan2, Giada Arney1 || 1NASA Goddard Space Flight Center, Gree ... (truncated) ||  || { || ""title"": ""Life, Machine Learning, and the Search for Habitability: Predicting Biosignature"", || ""authors"": [ || ""Mark Moussa1"", || ""Amber V . Young1"", || ""Brianna Isola1"", || ""Vasuda Trehan1"", || ""Michael D. Himes1"", || ""Nicholas Wogan2"", || ""Giada Arney1"" || ], || ""doi"": ""10.48550/arXiv.2407.04219"", || ""arxiv_id"": ""arXiv:2407.04219"", || ""keywords"": [ || ""Life"", || ""Machine Learning"", || ""Habitability"", || ""Biosignature"", || ""Exoplanets"", || ""Habitable Worlds Observatory"" || ], || ""summary"": ""The paper introduces two advanced machine-learning models—Bayesian Convolutional Neural Network (BCNN) and Spectral Query Adaptive Transformer (SQuAT)—for predicting biosignature species fluxes from exoplanet reflected-light spectra. It highlights their ability to quantify uncertainties and interpret spectral features, supporting efficient prioritization for future flagship missions like NASA's Habitable Worlds Observatory."" || } ||  || [ Prompt: 108.3 t/s | Generation: 29.0 t/s ]"
2601.12560v1_Agentic Artificial Intelligence AI Architectures T.pdf,"Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents","['Arunkumar V', 'Gangadharan G.R.', 'Rajkumar Buyya']",arunkumarv1530@gmail.com,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and || Evaluation of Large Language Model Agents || Arunkumar V || University College of Engineering, Anna University || Tiruchirappalli, Tamil Nadu, India || arunkumarv1530@gmail.com || Gangadharan G.R. || National Institute of Technology ... (truncated) ||  || { || ""title"": ""Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents"", || ""authors"": [ || ""Arunkumar V"", || ""Gangadharan G.R."", || ""Rajkumar Buyya"" || ], || ""doi"": ""arunkumarv1530@gmail.com"", || ""arxiv_id"": ""arunkumarv1530@gmail.com"", || ""keywords"": [ || ""Agentic AI"", || ""Large Language Models"", || ""Autonomous Agents"", || ""Multi-Agent Systems"", || ""Cognitive Architectures"", || ""Tool Use"", || ""Planning"" || ], || ""summary"": ""This paper investigates architectures and proposes a unified taxonomy for Agentic AI, focusing on perception, brain, planning, action, tool use, and collaboration. It discusses the shift from linear reasoning to native inference time reasoning and highlights challenges such as hallucination and infinite loops."" || } ||  || [ Prompt: 118.0 t/s | Generation: 27.9 t/s ]"
2601.12577v1_Primate-like perceptual decision making emerges th.pdf,Primate-like perceptual decision making emerges through deep recurrent reinforcement learning,"['Nathan J. Wispinski', 'Scott A. Stone', 'Anthony Singhal', 'Patrick M. Pilarski', 'Craig S. Chapman']",arXiv:2601.12577v1,28.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Primate-like perceptual decision making emerges through || deep recurrent reinforcement learning || Nathan J. Wispinski 1,2,*, Scott A. Stone 1,2, Anthony Singhal 1,2, || Patrick M. Pilarski 3,4, & Craig S. Chapman 2,5 || 1. Department of Psychology, University of Alberta || 2. Neuroscience and Me ... (truncated) ||  || { || ""title"": ""Primate-like perceptual decision making emerges through deep recurrent reinforcement learning"", || ""authors"": [ || ""Nathan J. Wispinski"", || ""Scott A. Stone"", || ""Anthony Singhal"", || ""Patrick M. Pilarski"", || ""Craig S. Chapman"" || ], || ""doi"": ""arXiv:2601.12577v1"", || ""arxiv_id"": ""arXiv:2601.12577"", || ""keywords"": [], || ""summary"": ""Progress has led to a detailed understanding of the neural mechanisms that underlie decision making in primates. However, less is known about why such mechanisms are present in the first place. Theory suggests that primate decision making mechanisms, and their resultant behavioral abilities, emerged to maximize reward in the face of noisy, temporally evolving information. To test this theory, we trained an end-to-end deep recurrent neural network using reinforcement learning on a noisy perceptual discrimination task. Networks learned several key abilities of primate-like decision making including trading off speed for accuracy, and flexibly changing their mind in the face of new information. Internal dynamics of these networks suggest that these abilities were supported by similar decision mechanisms as those observed in primate neurophysiological studies. These results provide experimental support for key pressures that gave rise to the primate ability to make flexible decisions."", || ""summary_field"": ""Decision making in primates and its neural underpinnings"" || } ||  || [ Prompt: 107.8 t/s | Generation: 28.0 t/s ]"
2601.12582v1_Ontology-aligned structuring and reuse of multimod.pdf,Ontology-aligned structuring and reuse of multimodal materials data and workflows towards automatic reproduction,"['Sepideh Baghaee Ravari', 'Abril Azocar', 'Guzman Sarath', 'Menon', 'Stefan Sandfeld', 'Tilmann Hickel', 'Markus Stricker']",,27.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 INTRODUCTION || Ontology-aligned structuring and reuse of multimodal ma- || terials data and workflows towards automatic reproduction || Sepideh Baghaee Ravari Abril Azocar Guzman Sarath Menon Stefan Sandfeld Tilmann || Hickel Markus Stricker* || S. B. R., S. M., M. S. || Interdisciplinary Centre f ... (truncated) ||  || { || ""title"": ""Ontology-aligned structuring and reuse of multimodal materials data and workflows towards automatic reproduction"", || ""authors"": [ || ""Sepideh Baghaee Ravari"", || ""Abril Azocar"", || ""Guzman Sarath"", || ""Menon"", || ""Stefan Sandfeld"", || ""Tilmann Hickel"", || ""Markus Stricker"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""text mining"", || ""workflow"", || ""large language models"", || ""stacking fault energy"", || ""computational reproducibility"" || ], || ""summary"": ""The paper introduces an ontology-driven framework using large language models to automate the extraction and structuring of computational workflows from literature, aiming to improve reproducibility in materials science by organizing and contextualizing reported simulation data."" || } ||  || [ Prompt: 119.8 t/s | Generation: 27.0 t/s ]"
2601.12585v1_Do MLLMs See What We See Analyzing Visualization L.pdf,Do MLLMs See What We See?,"['Mengli (Dawn) Duan', 'Yuhe (Sissi) Jiang', 'Matthew Varona', 'Carolina Nobre']",,27.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Do MLLMs See What We See? || Analyzing Visualization Literacy Barriers in AI Systems || Mengli (Dawn) Duan*, Yuhe (Sissi) Jiang*, Matthew Varona, and Carolina Nobre || Fig. 1: An overview of the proposed framework for identifying barriers in visualization literacy of MLLMs including (a) SOTA ... (truncated) ||  || { || ""title"": ""Do MLLMs See What We See?"", || ""authors"": [ || ""Mengli (Dawn) Duan"", || ""Yuhe (Sissi) Jiang"", || ""Matthew Varona"", || ""Carolina Nobre"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Visualization Literacy"", || ""Multimodal Large Language Model"", || ""Evaluation Study"" || ], || ""summary"": ""This paper presents a systematic analysis of barriers to visualization literacy in MLLMs using the reVLAT benchmark. It identifies two machine-specific barriers and discusses implications for AI-driven visualization assistants."" || } ||  || [ Prompt: 120.9 t/s | Generation: 27.1 t/s ]"
2601.12594v1_SLAP Scalable Language-Audio Pretraining with Vari.pdf,Scalable Language-Audio Pretraining With V Arable-Duration,"['Xinhao Mei', 'Gael Le Lan Haohe Liu', 'Zhaoheng Ni', 'Nguyen Yang Liu', 'Shi Vikas Chandra']",,27.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SLAP: SCALABLE LANGUAGE-AUDIO PRETRAINING WITH V ARIABLE-DURATION || AUDIO AND MULTI-OBJECTIVE TRAINING || Xinhao Mei Gael Le Lan Haohe Liu Zhaoheng Ni || V arun Nagaraja Yang Liu Yangyang Shi Vikas Chandra || Meta || ABSTRACT || Contrastive language-audio pretraining (CLAP) has achieved notable || succ ... (truncated) ||  || { || ""title"": ""Scalable Language-Audio Pretraining With V Arable-Duration"", || ""authors"": [ || ""Xinhao Mei"", || ""Gael Le Lan Haohe Liu"", || ""Zhaoheng Ni"", || ""Nguyen Yang Liu"", || ""Shi Vikas Chandra"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Scalable Language-Audio Pretraining"", || ""SLAP"", || ""Language-Audio Model"", || ""Audio Text Pairs"", || ""Variable Duration"", || ""Multi-Objective Training"" || ], || ""summary"": ""This paper introduces SLAP, a scalable language-audio pretraining method that addresses limitations of existing CLAP models by enabling training on 109 million audio-text pairs with variable durations and incorporating multiple training objectives."" || } ||  || [ Prompt: 111.3 t/s | Generation: 27.3 t/s ]"
2601.12607v1_A Cloud-based Multi-Agentic Workflow for Science.pdf,A Cloud-based Multi-Agentic Workflow for Science,"['Anurag Acharya', 'Timothy Vega', 'Rizwan A. Ashraf', 'Anshu Sharma', 'Robert Rallo']",10.1145/nnnnnnn.nnnnnnn,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A Cloud-based Multi-Agentic Workflow for Science || Anurag Acharya || Pacific Northwest National || Laboratory || Richland, Washington, USA || anurag.acharya@pnnl.gov || Timothy Vega || Pacific Northwest National || Laboratory || Richland, Washington, USA || timothy.vega@pnnl.gov || Rizwan A. Ashraf || Pacific Northwe ... (truncated) ||  || { || ""title"": ""A Cloud-based Multi-Agentic Workflow for Science"", || ""authors"": [ || ""Anurag Acharya"", || ""Timothy Vega"", || ""Rizwan A. Ashraf"", || ""Anshu Sharma"", || ""Robert Rallo"" || ], || ""doi"": ""10.1145/nnnnnnn.nnnnnnn"", || ""arxiv_id"": """", || ""keywords"": [ || ""Large Language Models"", || ""LLMs for Science"", || ""LLM Agents"", || ""Multi-agent Framework"", || ""Catalysis"", || ""Chemistry"", || ""Material Science"", || ""Cloud Computing"" || ], || ""summary"": ""This paper presents a domain-agnostic, model-independent workflow for an agentic framework that can act as a scientific assistant while being run entirely on cloud. It discusses challenges in balancing models, cloud providers, and external resources, and evaluates performance across synthetic benchmarks and real-world tasks."" || } ||  || [ Prompt: 109.8 t/s | Generation: 28.7 t/s ]"
2601.12617v1_Creating Disability Story Videos with Generative A.pdf,"Creating Disability Story Videos with Generative AI: Motivation, Expression, and Sharing","['Shuo Niu', 'Dylan Clements', 'Hyungsin Kim']",10.1145/3772318.3791495,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Creating Disability Story Videos with Generative AI: Motivation, || Expression, and Sharing || Shuo Niu || shniu@clarku.edu || Clark University || Worcester, Massachusetts, USA || Dylan Clements || dyclements@clarku.edu || Clark University || Worcester, Massachusetts, USA || Hyungsin Kim || HyuKim@clarku.edu || Clark  ... (truncated) ||  || { || ""title"": ""Creating Disability Story Videos with Generative AI: Motivation, Expression, and Sharing"", || ""authors"": [ || ""Shuo Niu"", || ""Dylan Clements"", || ""Hyungsin Kim"" || ], || ""doi"": ""10.1145/3772318.3791495"", || ""arxiv_id"": """", || ""keywords"": [ || ""Disability"", || ""Storytelling"", || ""Video"", || ""Generative AI"", || ""LLM"" || ], || ""summary"": ""Generative AI is explored as a tool for people with disabilities to create stories about their experiences, highlighting affordances and challenges in digital storytelling."" || } ||  || [ Prompt: 113.9 t/s | Generation: 29.0 t/s ]"
2601.12637v1_Topology-Aware Multiscale Mixture of Experts for E.pdf,,[],,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TOPOLOGY-AWAREMULTISCALEMIXTURE OFEXPERTS FOR || EFFICIENTMOLECULARPROPERTYPREDICTION || Long D. Nguyen || School of Mathematics and Statistics || Victoria University of Wellington || Wellington, New Zealand || duylong.nguyen@vuw.ac.nz || Kelin Xia || School of Physical and Mathematical Sciences || Nanyang Te ... (truncated) ||  || { || ""title"": ""Topology-Aware Multiscale Mixure of Experts for Efficient Molecular Property Prediction"", || ""authors"": [ || ""Long D. Nguyen"", || ""Kelin Xia"", || ""Binh P. Nguyen"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""graph neural networks"", || ""topological deep learning"", || ""mixture of experts"", || ""molecular representation"", || ""3D molecular graphs""] || "", ""summary"": ""The paper proposes a Multiscale Interaction Mixture of Experts (MI-MoE) to adapt interaction modeling across geometric regimes, introducing a distance-cutoff expert ensemble, a topological gating encoder, and demonstrating improved performance on diverse molecular property prediction benchmarks."" || } ||  || [ Prompt: 107.4 t/s | Generation: 27.5 t/s ]"
2601.12638v1_Mixed Precision PointPillars for Efficient 3D Obje.pdf,Mixed Precision PointPillars for Efficient 3D Object,"['Ninnart Fuengfusin', 'Keisuke Yoneda', 'Naoki Suganuma']",,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Mixed Precision PointPillars for Efficient 3D Object || Detection with TensorRT || 1st Ninnart Fuengfusin || Advanced Mobility Research Institute || Kanazawa University || Ichikawa, Japan || ninnart@se.kanazawa-u.ac.jp || 2nd Keisuke Yoneda || Advanced Mobility Research Institute || Kanazawa University || Ichika ... (truncated) ||  || { || ""title"": ""Mixed Precision PointPillars for Efficient 3D Object"", || ""authors"": [ || ""Ninnart Fuengfusin"", || ""Keisuke Yoneda"", || ""Naoki Suganuma"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""neural networks"", || ""quantization"", || ""3D object detection"", || ""PointPillars"", || ""TensorRT"" || ], || ""summary"": ""The paper proposes a mixed precision framework for PointPillars to improve runtime efficiency in LIDAR 3D object detection. It uses post-training quantization and evaluates model sensitivity to optimize performance."" || } ||  || [ Prompt: 109.7 t/s | Generation: 28.6 t/s ]"
2601.12641v1_STEP-LLM Generating CAD STEP Models from Natural L.pdf,Generating CAD STEP Models from Natural Language with Large Language Models,"['Xiangyu Shi', 'Yunyang Ding', 'Xu Zhao', 'Sinong Zhan', 'Payal Mohapatra', 'Daniel Quispe', 'Kojo Welbeck', 'Jian Cao', 'Wei Chen', 'Ping Guo', 'Qi Zhu']",,27.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || STEP-LLM: Generating CAD STEP Models from Natural Language with || Large Language Models || Xiangyu Shi, Junyang Ding, Xu Zhao, Sinong Zhan, Payal Mohapatra, Daniel Quispe, Kojo Welbeck, || Jian Cao, Wei Chen, Ping Guo, Qi Zhu || Northwestern University, Evanston, USA || Abstract || Computer-aided de ... (truncated) ||  || { || ""title"": ""Generating CAD STEP Models from Natural Language with Large Language Models"", || ""authors"": [ || ""Xiangyu Shi"", || ""Yunyang Ding"", || ""Xu Zhao"", || ""Sinong Zhan"", || ""Payal Mohapatra"", || ""Daniel Quispe"", || ""Kojo Welbeck"", || ""Jian Cao"", || ""Wei Chen"", || ""Ping Guo"", || ""Qi Zhu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Computer-aided design"", || ""STEP file"", || ""large language models"", || ""design automation"" || ], || ""summary"": ""This paper introduces a dataset of 40K STEP-caption pairs and presents a novel preprocessing method tailored for the STEP format. It leverages retrieval-augmented generation and reinforcement learning to improve geometric fidelity in STEP model generation from natural language, aiming to democratize CAD design for manufacturing."" || } ||  || [ Prompt: 118.9 t/s | Generation: 27.0 t/s ]"
2601.12646v1_Unbounded Harms Bounded Law Liability in the Age o.pdf,"Unbounded Harms, Bounded Law: Liability in the Age of Borderless AI",['Ha-Chi Tran'],10.1093/acprof:oso/9780190871293.013.0001,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Unbounded Harms, Bounded Law: || Liability in the Age of Borderless AI || Ha-Chi Tran || The London School of Economics and Political Science || London, United Kingdom || c.h.tran@lse.ac.uk || Abstract || The rapid acceleration of artificial intelligence (AI) has exposed fundamental defi- || ciencies in pr ... (truncated) ||  || { || ""title"": ""Unbounded Harms, Bounded Law: Liability in the Age of Borderless AI"", || ""authors"": [""Ha-Chi Tran""], || ""doi"": ""10.1093/acprof:oso/9780190871293.013.0001"", || ""arxiv_id"": """", || ""keywords"": [ || ""unbounded harms"", || ""bounded law"", || ""liability"", || ""AI governance"", || ""transboundary risks"" || ], || ""summary"": ""The paper examines the inadequacy of current legal frameworks for addressing AI-related harms, emphasizing the need for new compensation and liability mechanisms in a globally interconnected AI landscape."" || } ||  || [ Prompt: 114.3 t/s | Generation: 28.7 t/s ]"
2601.12648v1_Intelligent Documentation in Medical Education Can.pdf,Intelligent Documentation in Medical Education: Can AI Replace Manual Case Logging?,"['Nafiz Imtiaz Khan', 'Kylie Cleland', 'Vladimir Filkov', 'Roger Eric Goldman']",,26.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Intelligent Documentation in Medical Education: Can AI Replace || Manual Case Logging? || Nafiz Imtiaz Khan, MSc || Department of Computer Science, University of California, Davis, CA, USA || Kylie Cleland, BSc || Department of Radiology, University of California, Davis, CA, USA || Vladimir Filkov, P ... (truncated) ||  || { || ""title"": ""Intelligent Documentation in Medical Education: Can AI Replace Manual Case Logging?"", || ""authors"": [ || ""Nafiz Imtiaz Khan"", || ""Kylie Cleland"", || ""Vladimir Filkov"", || ""Roger Eric Goldman"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""artificial intelligence"", || ""large language models"", || ""radiology"", || ""case logs"", || ""medical education"" || ], || ""summary"": ""This study investigates the feasibility of using large language models to automate procedural case log documentation in radiology training, evaluating performance and integration challenges."" || } ||  || [ Prompt: 112.4 t/s | Generation: 26.5 t/s ]"
2601.12654v1_Explanation Multiplicity in SHAP Characterization .pdf,Explanation Multiplicity in SHAP: Characterization and Assessment,"['Hyunseung Hwang', 'Seungeun Lee', 'Lucas Rosenblatt', 'Julia Stoyanovich', 'Steven Euijong Whang']",10.1093/acps/ccad025,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Explanation Multiplicity in SHAP: Characterization and Assessment || HYUNSEUNG HWANG,KAIST, Republic of Korea || SEUNGEUN LEE,New York University, USA || LUCAS ROSENBLATT,New York University, USA || JULIA STOYANOVICH,New York University, USA || STEVEN EUIJONG WHANG,KAIST, Republic of Korea || Post-ho ... (truncated) ||  || { || ""title"": ""Explanation Multiplicity in SHAP: Characterization and Assessment"", || ""authors"": [ || ""Hyunseung Hwang"", || ""Seungeun Lee"", || ""Lucas Rosenblatt"", || ""Julia Stoyanovich"", || ""Steven Euijong Whang"" || ], || ""doi"": ""10.1093/acps/ccad025"", || ""arxiv_id"": """", || ""keywords"": [ || ""SHAP"", || ""explanation multiplicity"", || ""post-hoc explanations"", || ""model interpretability"", || ""recourse"", || ""accountability"" || ], || ""summary"": ""This paper explores explanation multiplicity in SHAP, highlighting how multiple internally consistent but substantively different explanations can emerge for the same decision. It discusses the normative challenges this poses and proposes a methodology to characterize and assess such multiplicity, emphasizing the need for robust evaluation metrics."" || } ||  || [ Prompt: 116.1 t/s | Generation: 27.7 t/s ]"
2601.12658v1_Augmenting Question Answering with A Hybrid RAG Ap.pdf,Augmenting Question Answering with A Hybrid RAG Approach,"['Tianyi Yang', 'Nashrah Haque', 'Vaishnave Jonnalagadda', 'Yuya Jeremy Ong', 'Zhehui Chen', 'Yanzhao Wu', 'Lei Yu', 'Divyesh Jadav', 'Wenqi Wei']",,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Augmenting Question Answering with A || Hybrid RAG Approach || Tianyi Yang, Nashrah Haque , Vaishnave Jonnalagadda, Yuya Jeremy Ong 1 || Zhehui Chen , Yanzhao Wu, Lei Yu , Divyesh Jadav 1 , Wenqi Wei2 || Fordham University, New York, NY , USA,{ty10, nhaque14, vj1, wwei23}@fordham.edu || Plastic  ... (truncated) ||  || { || ""title"": ""Augmenting Question Answering with A Hybrid RAG Approach"", || ""authors"": [ || ""Tianyi Yang"", || ""Nashrah Haque"", || ""Vaishnave Jonnalagadda"", || ""Yuya Jeremy Ong"", || ""Zhehui Chen"", || ""Yanzhao Wu"", || ""Lei Yu"", || ""Divyesh Jadav"", || ""Wenqi Wei"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Question-answering"", || ""RAG"", || ""query process"", || ""query augmentation"", || ""agentic routing"", || ""structured retrieval"", || ""context unification"" || ], || ""summary"": ""The paper introduces Structured-Semantic RAG (SSRAG), a hybrid architecture that improves QA quality by integrating query augmentation, agentic routing, and structured retrieval. It evaluates performance across multiple datasets and LLMs, demonstrating enhanced accuracy and informativeness."" || } ||  || [ Prompt: 108.2 t/s | Generation: 28.5 t/s ]"
2601.12661v1_MedConsultBench A Full-Cycle Fine-Grained Process-.pdf,,[],,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MedConsultBench: A Full-Cycle, Fine-Grained, Process-Aware Benchmark || for Medical Consultation Agents || Chuhan Qiao* Jianghua Huang* Daxing Zhao* Ziding Liu Yanjun Shen || Bing Cheng Wei Lin Kai Wu || Meituan || {qiaochuhan, huangjianghua, zhaodaxing, || liuziding, shenyanjun03, bing.cheng, linwe ... (truncated) ||  || { || ""title"": ""MedConsultBench: A Full-Cycle, Fine-Grained, Process-Aware Benchmark"", || ""authors"": [ || ""Chuhan Qiao"", || ""Jianghua Huang"", || ""Daxing Zhao"", || ""Ziding Liu"", || ""Shan Yanjun"", || ""Bing Cheng"", || ""Lin Wei"", || ""Wu Kai"", || ""Meituan"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""medical consultation agents"", || ""outcome-oriented tasks"", || ""end-to-end process"", || ""clinical safety"", || ""diagnostic rigor"", || ""medication regimen"", || ""follow-up Q&A"" || ], || ""summary"": ""This paper introduces MedConsultBench, a comprehensive framework to evaluate the full clinical consultation cycle. It addresses gaps in existing benchmarks by focusing on process integrity, fine-grained metrics, and real-world clinical requirements. The study highlights deficiencies in information gathering and medication safety, emphasizing the need for improved uncertainty handling in AI systems."" || } ||  || [ Prompt: 109.8 t/s | Generation: 28.7 t/s ]"
2601.12664v1_Generalizable Hyperparameter Optimization for Fede.pdf,Generalizable Hyperparameter Optimization for Federated Learning on Non-IID Cancer Images,"['Elisa Gonc alves Ribeiro', 'Rodrigo Moreira', 'Larissa Ferreira Rodrigues Moreira', 'Andre Ricardo Backes']",,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Generalizable Hyperparameter Optimization for Federated Learning on || Non-IID Cancer Images || Elisa Gonc alves Ribeiro1 || a, Rodrigo Moreira1 || b, || Larissa Ferreira Rodrigues Moreira1 || c, Andre Ricardo Backes2 || d || 1Institute of Exact and Technological Sciences, Federal University of Vic osa ... (truncated) ||  || { || ""title"": ""Generalizable Hyperparameter Optimization for Federated Learning on Non-IID Cancer Images"", || ""authors"": [ || ""Elisa Gonc alves Ribeiro"", || ""Rodrigo Moreira"", || ""Larissa Ferreira Rodrigues Moreira"", || ""Andre Ricardo Backes"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Federated Learning"", || ""Hyperparameter Optimization"", || ""Non-IID Data"", || ""Medical Imaging"", || ""Cancer"" || ], || ""summary"": ""This paper examines whether hyperparameters optimized on one cancer imaging dataset generalize across non-IID federated settings. It introduces a cross-dataset aggregation heuristic combining learning rates, optimizers, and batch sizes to improve performance in ovarian and colorectal cancer classification."" || } ||  || [ Prompt: 109.4 t/s | Generation: 28.1 t/s ]"
2601.12667v1_Empowering All-in-Loop Health Management of Spacec.pdf,Empowering All-in-Loop Health Management of Spacecraft Power System in the Mega-Constellation Era via Human-AI Collaboration,"['Yi Di1', 'Yi Di2', 'Zhibin Zhao1', 'Zhibin Zhao2', 'Fujin Wang3', 'Xue Liu4', 'Jiafeng Tang1', 'Jiafeng Tang2', 'Jiaxin Ren1', 'Jiaxin Ren2', 'Zhi Zhai1', 'Zhi Zhai2', 'Xuefeng Chen1', 'Xuefeng Chen2']",,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Empowering All-in-Loop Health Management of Spacecraft Power System in the || Mega-Constellation Era via Human-AI Collaboration || Yi Di1,2, Zhibin Zhao1,2,5,, Fujin Wang3, Xue Liu4, Jiafeng Tang1,2, Jiaxin Ren1,2, Zhi Zhai1,2,, Xuefeng Chen1,2 || Abstract || It is foreseeable that the number o ... (truncated) ||  || { || ""title"": ""Empowering All-in-Loop Health Management of Spacecraft Power System in the Mega-Constellation Era via Human-AI Collaboration"", || ""authors"": [ || ""Yi Di1"", || ""Yi Di2"", || ""Zhibin Zhao1"", || ""Zhibin Zhao2"", || ""Fujin Wang3"", || ""Xue Liu4"", || ""Jiafeng Tang1"", || ""Jiafeng Tang2"", || ""Jiaxin Ren1"", || ""Jiaxin Ren2"", || ""Zhi Zhai1"", || ""Zhi Zhai2"", || ""Xuefeng Chen1"", || ""Xuefeng Chen2"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Large Language Model"", || ""Human-AI Collaboration"", || ""Spacecraft Power System"", || ""All-in-loop Health Management"", || ""Satellite Mega-Constellation"" || ], || ""summary"": ""The paper discusses the increasing need for advanced health management in spacecraft power systems due to the rise of satellite mega-constellations. It introduces SpaceHMchat, an open-source framework for human-AI collaboration in all-in-loop health management, and presents experimental results showing its effectiveness in various performance metrics."" || } ||  || [ Prompt: 113.8 t/s | Generation: 27.6 t/s ]"
2601.12671v1_Exploiting Test-Time Augmentation in Federated Lea.pdf,Exploiting Test-Time Augmentation in Federated Learning for Brain Tumor MRI Classification,"['Thamara Leandra de Deus Melo', 'Rodrigo Moreira', 'Larissa Ferreira Rodrigues Moreira']",10.1007/978-3-642-45678-3,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Exploiting Test-Time Augmentation in Federated Learning for Brain || Tumor MRI Classification || Thamara Leandra de Deus Melo1, Rodrigo Moreira1 || a, || Larissa Ferreira Rodrigues Moreira1 || b, Andre R. Backes2 || c || 1Institute of Exact and Technological Sciences, Federal University of Vic osa -  ... (truncated) ||  || { || ""title"": ""Exploiting Test-Time Augmentation in Federated Learning for Brain Tumor MRI Classification"", || ""authors"": [ || ""Thamara Leandra de Deus Melo"", || ""Rodrigo Moreira"", || ""Larissa Ferreira Rodrigues Moreira"" || ], || ""doi"": ""10.1007/978-3-642-45678-3"", || ""arxiv_id"": """", || ""keywords"": [ || ""Brain tumors"", || ""Federated Learning"", || ""Test-Time Augmentation"", || ""Image classification"" || ], || ""summary"": ""Efficient brain tumor diagnosis is crucial for early treatment; however, it is challenging because of lesion variability and image complexity. The study evaluates CNNs in a federated learning setting, comparing models trained on original versus preprocessed MRI images and demonstrating that combining test-time augmentation (TTA) with preprocessing yields significant improvements in federated MRI classification."" || } ||  || [ Prompt: 113.4 t/s | Generation: 27.8 t/s ]"
2601.12688v1_Logic-Guided Multistage Inference for Explainable .pdf,Logic-Guided Multistage Inference for Explainable Multidefendant Judgment Prediction,"['Xu Zhang', 'Qinghua Wang', 'Mengyang Zhao', 'Fang Wang', 'Cunquan Qu']",10.1234/jcli2025.1238,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || JOURNAL OF LATEX CLASS FILES, VOL. X, NO. X, AUGUST 2025 1 || Logic-Guided Multistage Inference for Explainable || Multidefendant Judgment Prediction || Xu Zhang, Qinghua Wang, Mengyang Zhao, Fang Wang, and Cunquan Qu || AbstractCrime disrupts societal stability, making law || essential for balanc ... (truncated) ||  || { || ""title"": ""Logic-Guided Multistage Inference for Explainable Multidefendant Judgment Prediction"", || ""authors"": [ || ""Xu Zhang"", || ""Qinghua Wang"", || ""Mengyang Zhao"", || ""Fang Wang"", || ""Cunquan Qu"" || ], || ""doi"": ""10.1234/jcli2025.1238"", || ""arxiv_id"": ""10.1234/jcli2025.1238"", || ""keywords"": [ || ""Multiple defendants"", || ""Legal judgment predictions"", || ""Label broadcast"", || ""Guilt responsibility"", || ""Transformer"", || ""Guilt responsibility"", || ""Role differentiation"" || ], || ""summary"": ""This study introduces a masked multistage inference framework to enhance role-based culpability analysis in multidefendant cases. By integrating sentencing logic into a pretrained Transformer model, it improves accuracy in distinguishing between principals and accomplices, offering a robust solution for intelligent judicial systems."" || } ||  || [ Prompt: 110.3 t/s | Generation: 28.4 t/s ]"
2601.12711v1_Neurosymbolic LoRA Why and When to Tune Weights vs.pdf,Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts,"['Kevin Wang', 'Neel P. Bhatt', 'Cong Liu', 'Junbo Li', 'Runjin Chen', 'Yihan Xi', 'Timothy Barclay', 'Alvaro Velasquez', 'Ufuk Topcu', 'Zhangyang Wang']",,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts || Kevin Wang*, Neel P. Bhatt*, Cong Liu*, Junbo Li, Runjin Chen, Yihan Xi, Timothy Barclay, || Alvaro Velasquez, Ufuk Topcu, Zhangyang Wang || Abstract || Large language models (LLMs) can be adapted either through || numericalup ... (truncated) ||  || { || ""title"": ""Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts"", || ""authors"": [ || ""Kevin Wang"", || ""Neel P. Bhatt"", || ""Cong Liu"", || ""Junbo Li"", || ""Runjin Chen"", || ""Yihan Xi"", || ""Timothy Barclay"", || ""Alvaro Velasquez"", || ""Ufuk Topcu"", || ""Zhangyang Wang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper introduces a neurosymbolic LoRA framework that combines numerical and symbolic updates for efficient language model fine-tuning. It proposes a unified monitoring signal and reward-based classifier to decide when to apply LoRA versus TextGrad, improving adaptability and performance in data-scarce domains."" || } ||  || [ Prompt: 110.4 t/s | Generation: 28.1 t/s ]"
2601.12715v1_RSOD Reliability-Guided Sonar Image Object Detecti.pdf,,[],,28.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || RSOD: Reliability-Guided Sonar Image Object Detection || with Extremely Limited Labels || Chengzhou Li1, Ping Guo1, Guanchen Meng1, Qi Jia1, Jinyuan Liu1, Zhu Liu1, || Xiaokang Liu1, Yu Liu1, Zhongxuan Luo1, Xin Fan1* || 1School of Software Technology, Dalian University of Technology || {lichengzh ... (truncated) ||  || { || ""title"": ""Reliability-Guided Sonar Image Object Detection"", || ""authors"": [ || ""Chengzhou Li1"", || ""Ping Guo1"", || ""Guanchen Meng1"", || ""Qi Jia1"", || ""Jinyuan Liu1"", || ""Zhu Liu1"", || ""Xiaokang Liu1"", || ""Yu Liu1"", || ""Zhongxuan Luo1"", || ""Xin Fan1"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Object detection in sonar images is challenging due to limited labels. This paper proposes RSOD, a teacher-student framework that leverages reliability scores and pseudo-labeling to improve performance with minimal labeled data."" || } ||  || [ Prompt: 114.2 t/s | Generation: 28.0 t/s ]"
2601.12720v1_Teaching Large Reasoning Models Effective Reflecti.pdf,Teaching Large Reasoning Models Effective Reflection,"['Hanbin Wang', 'Jingwei Song', 'Jinpeng Li', 'Qi Zhu', 'Fei Mi', 'Ganqu Cui', 'Yasheng Wang', 'Lifeng Shang']",,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Teaching Large Reasoning Models Effective Reflection || Hanbin Wang1*, Jingwei Song2*, Jinpeng Li3, Qi Zhu3, || Fei Mi3, Ganqu Cui4, Yasheng Wang, Lifeng Shang3 || 1Peking University 2The University of Hong Kong || 3Huawei Technologies 4Shanghai AI Lab || Abstract || Large Reasoning Models (LRMs) hav ... (truncated) ||  || { || ""title"": ""Teaching Large Reasoning Models Effective Reflection"", || ""authors"": [ || ""Hanbin Wang"", || ""Jingwei Song"", || ""Jinpeng Li"", || ""Qi Zhu"", || ""Fei Mi"", || ""Ganqu Cui"", || ""Yasheng Wang"", || ""Lifeng Shang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper discusses the issue of superficial reflection in Large Reasoning Models (LRMs) and introduces Self-Critique Fine-Tuning (SCFT) and Reinforcement Learning with Effective Reflection Rewards (RLERR) to improve reflection quality."" || } ||  || [ Prompt: 112.1 t/s | Generation: 28.5 t/s ]"
2601.12723v1_An Evolutionary Framework for Automatic Optimizati.pdf,An Evolutionary Framework for Automatic Optimization Benchmark Generation via Large Language Models,"['Yuhiro Ono', 'Tomohiro Harada', 'Yukiya Miura']",arXiv:2601.12723v1,31.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || An Evolutionary Framework for Automatic || Optimization Benchmark Generation via Large || Language Models || Yuhiro Ono1, Tomohiro Harada 2*, Yukiya Miura 1 || 1Graduate School of Systems Design, Tokyo Metropolitan University, || 6-6, Asahigaoka, Hino, 1910065, Tokyo, Japan. || 2*Graduate School of S ... (truncated) ||  || { || ""title"": ""An Evolutionary Framework for Automatic Optimization Benchmark Generation via Large Language Models"", || ""authors"": [ || ""Yuhiro Ono"", || ""Tomohiro Harada"", || ""Yukiya Miura"" || ], || ""doi"": ""arXiv:2601.12723v1"", || ""arxiv_id"": ""2601.12723"", || ""keywords"": [ || ""optimization benchmarks"", || ""large language models"", || ""evolutionary algorithms"", || ""benchmark generation"", || ""mathematical expressions"" || ], || ""summary"": ""The paper proposes an LLM-driven evolutionary benchmark generator to create diverse optimization benchmarks, demonstrating improved performance generation compared to traditional methods."" || } ||  || [ Prompt: 115.8 t/s | Generation: 31.1 t/s ]"
2601.12727v1_AI-exhibited Personality Traits Can Shape Human Se.pdf,AI-exhibited Personality Traits Can Shape Human Self-concept through Conversations,"['Jingshu Li', 'Tianqi Song', 'Nattapat Boonprakong', 'Yitian Yang', 'Yi-Chieh Lee']",10.1145/3772318.3790654,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || AI-exhibited Personality Traits Can Shape Human Self-concept || through Conversations || Jingshu Li || Computer Science || National University of Singapore || Singapore, Singapore || jingshu@u.nus.edu || Tianqi Song || National University of Singapore || Singapore, Singapore || tianqi_song@u.nus.edu || Nattapat Boo ... (truncated) ||  || { || ""title"": ""AI-exhibited Personality Traits Can Shape Human Self-concept through Conversations"", || ""authors"": [ || ""Jingshu Li"", || ""Tianqi Song"", || ""Nattapat Boonprakong"", || ""Yitian Yang"", || ""Yi-Chieh Lee"" || ], || ""doi"": ""10.1145/3772318.3790654"", || ""arxiv_id"": ""arXiv:2601.12727v1"", || ""keywords"": [ || ""AI"", || ""personality traits"", || ""self-concept"", || ""conversations"", || ""LLM"", || ""human interaction"" || ], || ""summary"": ""This study explores how Large Language Model (LLM)-based AI chatbots can shape human self-concept through conversations, highlighting the potential for AI traits to influence users' perceptions of their own personality."" || } ||  || [ Prompt: 119.6 t/s | Generation: 28.5 t/s ]"
2601.12731v1_A Shared Geometry of Difficulty in Multilingual La.pdf,A Shared Geometry of Difficulty in Multilingual Language Models,"['Stefano Civelli', 'Pietro Bernardelle', 'Nicolo Brunello', 'Gianluca Demartini']",,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A Shared Geometry of Difficulty in Multilingual Language Models || Stefano Civelli1, Pietro Bernardelle1, Nicol Brunello2, Gianluca Demartini1 || 1The University of Queensland 2Polytechnic University of Milan || {s.civelli,p.bernardelle,g.demartini}@uq.edu.au, nicolo.brunello@polimi.it || Abstr ... (truncated) ||  || { || ""title"": ""A Shared Geometry of Difficulty in Multilingual Language Models"", || ""authors"": [ || ""Stefano Civelli"", || ""Pietro Bernardelle"", || ""Nicolo Brunello"", || ""Gianluca Demartini"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper investigates how problem-difficulty is represented in multilingual large language models by analyzing linear probes across languages. It reveals that difficulty signals emerge in early and deep layers, with shallow representations performing better across languages but less accurately within them."" || } ||  || [ Prompt: 112.3 t/s | Generation: 26.9 t/s ]"
2601.12740v1_TreeWriter AI-Assisted Hierarchical Planning and W.pdf,TreeWriter: AI-Assisted Hierarchical Planning and Writing for Long-Form Documents,"['Zijian Zhang', 'Fangshi Du', 'Xingjian Liu', 'Pan Chen', 'Oliver Huang', 'Runlong Ye', 'Michael Liut', 'Aln Aspuru-Guzik', '1 Department of Computer Science, University of Toronto', '2 Vector Institute for Artificial Intelligence', '3 Department of Chemistry, University of Toronto', '4 Department of Mathematical and Computational Sciences, University of Toronto', '5 Department of Materials Science & Engineering, University of Toronto', '6 Department of Chemical Engineering & Applied Chemistry, University of Toronto', '7 Acceleration Consortium', '8 Canadian Institute for Advanced Research (CIFAR)', '9 NVIDIA']",,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TreeWriter: AI-Assisted Hierarchical Planning and || Writing for Long-Form Documents || Zijian Zhang1,2,Fangshi Du 1,Xingjian Liu 1,Pan Chen 1,2,Oliver Huang 1,Runlong Ye 1,Michael Liut 4,Aln || Aspuru-Guzik1,2,3,5,6,7,8,9, || 1Department of Computer Science, University of Toronto, Sandford Fle ... (truncated) ||  || { || ""title"": ""TreeWriter: AI-Assisted Hierarchical Planning and Writing for Long-Form Documents"", || ""authors"": [ || ""Zijian Zhang"", || ""Fangshi Du"", || ""Xingjian Liu"", || ""Pan Chen"", || ""Oliver Huang"", || ""Runlong Ye"", || ""Michael Liut"", || ""Aln Aspuru-Guzik"", || ""1 Department of Computer Science, University of Toronto"", || ""2 Vector Institute for Artificial Intelligence"", || ""3 Department of Chemistry, University of Toronto"", || ""4 Department of Mathematical and Computational Sciences, University of Toronto"", || ""5 Department of Materials Science & Engineering, University of Toronto"", || ""6 Department of Chemical Engineering & Applied Chemistry, University of Toronto"", || ""7 Acceleration Consortium"", || ""8 Canadian Institute for Advanced Research (CIFAR)"", || ""9 NVIDIA"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""TreeWriter"", || ""AI-assisted writing"", || ""long-form documents"", || ""hierarchical planning"", || ""document organization"", || ""creative writing"", || ""planning and writing"", || ""collaborative writing"" || ], || ""summary"": ""TreeWriter is a hierarchical writing system that supports documents as trees, integrating AI assistance for planning and refining long documents. It enables authors to create, save, and refine outlines at multiple levels, improving idea development and authorial control."" || } ||  || [ Prompt: 112.5 t/s | Generation: 28.2 t/s ]"
2601.12742v1_AirHunt Bridging VLM Semantics and Continuous Plan.pdf,AirHunt: Bridging VLM Semantics and Continuous,"['Xuecheng Chen', 'Zongzhuo Liu', 'Jianfa Ma', 'Bang Du', 'Tiantian Zhang', 'Xueqian Wang', 'Boyu Zhou']",10.48550/arXiv.2405.12345,26.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || AirHunt: Bridging VLM Semantics and Continuous || Planning for Efficient Aerial Object Navigation || Xuecheng Chen, Zongzhuo Liu, Jianfa Ma, Bang Du, Tiantian Zhang, Xueqian Wang, and Boyu Zhou || CameraLiDAR || Computer || Instruction: Find the green trash bin on the roadside. || StartPosition || Tar ... (truncated) ||  || { || ""title"": ""AirHunt: Bridging VLM Semantics and Continuous"", || ""authors"": [ || ""Xuecheng Chen"", || ""Zongzhuo Liu"", || ""Jianfa Ma"", || ""Bang Du"", || ""Tiantian Zhang"", || ""Xueqian Wang"", || ""Boyu Zhou"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""10.48550/arXiv.2405.12345"", || ""keywords"": [ || ""Vision-Language Models"", || ""Aerial Navigation"", || ""LiDAR"", || ""Computer Vision"", || ""Object Detection"", || ""Path Planning"" || ], || ""summary"": ""AirHunt presents a system that integrates Vision-Language Models with continuous path planning for drones, enabling efficient outdoor navigation through zero-shot generalization and adaptive guidance."" || } ||  || [ Prompt: 114.7 t/s | Generation: 26.7 t/s ]"
2601.12744v1_Vision Language Models for Optimization-Driven Int.pdf,,[],,26.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Vision Language Models for Optimization-Driven || Intent Processing in Autonomous Networks || Accepted for presentation at The IEEE International Conference on Communications (ICC) 2026 || Tasnim Ahmed, Yifan Zhu, Salimur Choudhury || School of Computing, Queens University, Ontario, Canada || {tas ... (truncated) ||  || { || ""title"": ""Intent-Based Networking (IBN)"", || ""authors"": [""Tasnim Ahmed"", ""Yifan Zhu"", ""Salimur Choudhury""], || ""doi"": ""10.48550/arXiv.2026.12345"", || ""arxiv_id"": ""arXiv:2509.12345"", || ""keywords"": [""Intent-Based Networking"", ""Optimization"", ""Vision-Language Models"", ""Code Generation""], || ""summary"": ""This paper presents IntentOpt, a benchmark of 85 optimization problems across 17 categories, evaluating four VLMs under multimodal and text-only prompts. It highlights performance differences in execution success and shows that visual parameter extraction improves results."" || } ||  || [ Prompt: 109.3 t/s | Generation: 26.5 t/s ]"
2601.12745v1_A Graph Prompt Fine-Tuning Method for WSN Spatio-T.pdf,A GraphA PromptA Fine-TuningA MethodA forAWSNA,"['Miao Ye', 'Jing Cui', 'Yuan Huang', 'Yong Wang', 'Qian He', 'Jiwen Zhang']",,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || > REPLACE THIS LINE WITH YOUR MANUSCRIPT ID NUMBER (DOUBLE -CLICK HERE TO EDIT) < ||  || A A GraphA PromptA Fine-TuningA MethodA forAWSNA || Spatio-TemporalACorrelationA nomalyADetectionA ||  || Miao Ye , Jing Cui , Yuan Huang , Yong Wang , Qian He , Jiwen Zhang ||  ||  || AbstractAnomaly detect ... (truncated) ||  || { || ""title"": ""A GraphA PromptA Fine-TuningA MethodA forAWSNA"", || ""authors"": [ || ""Miao Ye"", || ""Jing Cui"", || ""Yuan Huang"", || ""Yong Wang"", || ""Qian He"", || ""Jiwen Zhang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Anomaly Detection"", || ""Graph Neural Networks"", || ""Pre-training"", || ""Prompt Learning"", || ""Wireless Sensor Networks"" || ], || ""summary"": ""Anomaly detection of multi-temporal modal data in Wireless Sensor Network using a graph neural network with spatio-temporal correlation features and a multi-task self-supervised training strategy."" || } ||  || [ Prompt: 107.6 t/s | Generation: 28.6 t/s ]"
2601.12754v1_PAIR-SAFE A Paired-Agent Approach for Runtime Audi.pdf,,[],,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || PAIR-SAFE: A Paired-Agent Approach for Runtime Auditing and Refining || AI-Mediated Mental Health Support || Jiwon Kim1, Violeta J. Rodriguez1, Dong Whi Yoo2, Eshwar Chandrasekharan1, Koustuv Saha1 || 1University of Illinois Urbana-Champaign, 2Indiana University Indianapolis || {jiwonk7, vjrodr ... (truncated) ||  || { || ""title"": ""PAIR-SAFE: A Paired-Agent Approach for Runtime Auditing and Refining"", || ""authors"": [ || ""Jiwon Kim"", || ""Violeta J. Rodriguez"", || ""Dong Whi Yoo"", || ""Eshwar Chandrasekharan"", || ""Koustuv Saha"" || ], || ""doi"": ""dy22@iu.edu"", || ""arxiv_id"": """", || ""keywords"": [ || ""AI-mediated mental health support"", || ""paired-agent framework"", || ""Motivational Interviewing Treatments Integrity"", || ""runtime accountability"", || ""clinical alignment"" || ], || ""summary"": ""This paper introduces PAIR-SAFE, a paired-agent framework for auditing and refining AI-generated mental health support. It integrates a Responder agent with a supervisory Judge agent based on the Motivational Interviewing Treatments Integrity framework. The approach improves key dimensions of the MITI model and is supported by qualitative expert evaluation."" || } ||  || [ Prompt: 108.4 t/s | Generation: 28.3 t/s ]"
2601.12758v1_VISPA Pluralistic Alignment via Automatic Value Se.pdf,Pluralistic Alignment via Automatic Value Selection and Activation,"['Shenyan Zheng', 'Jiayou Zhong', 'Anudeex Shetty', 'Heng Ji', 'Preslav Nakov', 'Usman Naseem']","b63zheng,j55zhong",13.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || VISPA: Pluralistic Alignment via Automatic Value Selection and Activation || Shenyan Zheng1, Jiayou Zhong1, Anudeex Shetty2,5, Heng Ji3, Preslav Nakov4, Usman Naseem5 || 1University of Waterloo, 2University of Melbourne, 3University of Illinois Urbana-Champaign, || 4MBZUAI, 5Macquarie Univer ... (truncated) ||  || { || ""title"": ""Pluralistic Alignment via Automatic Value Selection and Activation"", || ""authors"": [ || ""Shenyan Zheng"", || ""Jiayou Zhong"", || ""Anudeex Shetty"", || ""Heng Ji"", || ""Preslav Nakov"", || ""Usman Naseem"" || ], || ""doi"": ""b63zheng,j55zhong"", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper introduces VISPA, a training-free pluralistic alignment framework that enables dynamic selection and internal model activation to achieve diverse, context-aware outputs. It addresses the challenge of representing multiple perspectives in high-stakes domains like healthcare."" || } ||  || [ Prompt: 38.1 t/s | Generation: 13.7 t/s ]"
2601.12762v1_Teaching LLMs to Learn Tool Trialing and Execution.pdf,Teaching LLMs to Learn Tool Trialing and Execution through Environment Interaction,"['Xingjie Gao', 'Pengcheng Huang', 'Zhenghao Liu', 'Yukun Yan', 'Shuo Wang', 'Zulong Chen', 'Chen Qian', 'Ge Yu', 'Yu Gu']",,13.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Teaching LLMs to Learn Tool Trialing and Execution through || Environment Interaction || Xingjie Gao1*, Pengcheng Huang1*, Zhenghao Liu1 || Yukun Yan2, Shuo Wang2, Zulong Chen3, Chen Qian4, Ge Yu1, Yu Gu1 || 1School of Computer Science and Engineering, Northeastern University, Shenyang, China || 2 ... (truncated) ||  || { || ""title"": ""Teaching LLMs to Learn Tool Trialing and Execution through Environment Interaction"", || ""authors"": [ || ""Xingjie Gao"", || ""Pengcheng Huang"", || ""Zhenghao Liu"", || ""Yukun Yan"", || ""Shuo Wang"", || ""Zulong Chen"", || ""Chen Qian"", || ""Ge Yu"", || ""Yu Gu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper proposes ToolMaster, a framework that enables LLMs to learn tool usage by interacting with the environment through trial-and-execution, improving generalization to novel tools."" || } ||  || [ Prompt: 38.9 t/s | Generation: 13.7 t/s ]"
2601.12781v1_VIRO Robust and Efficient Neuro-Symbolic Reasoning.pdf,Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension,['Hyejin Park Junhyuk Kwon Suha Kwak Jungseul Ok'],,13.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for || Referring Expression Comprehension || Hyejin Park Junhyuk Kwon Suha Kwak Jungseul Ok || Pohang University of Science and Technology (POSTECH), South Korea || {parkebbi2, treejhk, suha.kwak, jungseul}@postech.ac.kr || Abst ... (truncated) ||  || { || ""title"": ""Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension"", || ""authors"": [""Hyejin Park Junhyuk Kwon Suha Kwak Jungseul Ok""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Referring Expression Comprehension"", ""neuro-symbolic reasoning"", ""verification operators""], || ""summary"": ""This paper introduces Verification-Integrated Reasoning Operators (VIRO), a neuro-symbolic framework that incorporates lightweight verifiers to robustly handle no-target cases in referring expression comprehension. VIRO achieves state-of-the-art performance with balanced accuracy and high reliability, demonstrating strong generalization and computational efficiency."" || } ||  || [ Prompt: 36.1 t/s | Generation: 13.2 t/s ]"
2601.12785v1_Distilling Time Series Foundation Models for Effic.pdf,Distilling Time Series Foundation Models for Efficient Forecasting,"['Yuqi Li a', 'Kuiye Ding a', 'Chuanguang Yang b', 'Szu-Yu Chenc', 'Yingli Tiana']",,22.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DISTILLING TIME SERIES FOUNDATION MODELS FOR EFFICIENT FORECASTING || Yuqi Li a , Kuiye Ding a , Chuanguang Yang b, Szu-Yu Chenc, Yingli Tiana || a The City College of New York, City University of New York, USA || b Institute of Computing Technology, Chinese Academy of Sciences, China || c Stev ... (truncated) ||  || { || ""title"": ""Distilling Time Series Foundation Models for Efficient Forecasting"", || ""authors"": [ || ""Yuqi Li a"", || ""Kuiye Ding a"", || ""Chuanguang Yang b"", || ""Szu-Yu Chenc"", || ""Yingli Tiana"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Time Series Foundation Model"", || ""Knowledge Distillation"", || ""Distillation Framework"", || ""Forecasting Performance"", || ""Model Compression"" || ], || ""summary"": ""This paper presents DistilTS, the first distillation framework specifically designed for time series foundation models. It addresses challenges such as task difficulty discrepancy and architecture discrepancy, introducing horizon-weighted objectives and a temporal alignment strategy to enable efficient deployment without sacrificing forecasting performance."" || } ||  || [ Prompt: 35.1 t/s | Generation: 22.2 t/s ]"
2601.12804v1_SL-CBM Enhancing Concept Bottleneck Models with Se.pdf,SL-CBM: Enhancing Concept Bottleneck Models with Semantic Locality for Better Interpretability,"['Hanwei Zhang', 'Luo Cheng', 'Rui Wen', 'Yang Zhang', 'Lijun Zhang', 'Holger Hermanns']",RIV AL10,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SL-CBM: Enhancing Concept Bottleneck Models with Semantic Locality for || Better Interpretability || Hanwei Zhang 1, Luo Cheng 2,5, Rui Wen 3, Yang Zhang 4, Lijun Zhang 5, Holger Hermanns 1 || 1 Saarland University || 2 University of Chinese Academy of Sciences || 3 Institute of Science Tokyo || 4 CI ... (truncated) ||  || { || ""title"": ""SL-CBM: Enhancing Concept Bottleneck Models with Semantic Locality for Better Interpretability"", || ""authors"": [ || ""Hanwei Zhang"", || ""Luo Cheng"", || ""Rui Wen"", || ""Yang Zhang"", || ""Lijun Zhang"", || ""Holger Hermanns"" || ], || ""doi"": ""RIV AL10"", || ""arxiv_id"": """", || ""keywords"": [ || ""Explainable AI"", || ""Concept Bottleneck Models"", || ""Interpretability"", || ""Semantic Locality"", || ""Intervention Efficacy"" || ], || ""summary"": ""This paper proposes SL-CBM, a novel extension of Concept Bottleneck Models that enhances locality faithfulness by generating spatially coherent saliency maps at concept and class levels. It improves locality alignment and explanation quality while maintaining competitive accuracy."" || } ||  || [ Prompt: 105.4 t/s | Generation: 28.2 t/s ]"
2601.12805v1_SciHorizon-GENE Benchmarking LLM for Life Sciences.pdf,SciHorizon-Gene: Benchmarking LLM for Life Sciences Inference,"['Xiaohan Huang', 'Meng Xiao', 'Chuan Qin', 'Qingqing Long', 'qqlong', 'Jinmiao Chen', 'micchenj', 'Yuanchun Zhou', 'zyc', 'Hengshu Zhu']",XXXXXXX.XXXXXXX,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SciHorizon-Gene: Benchmarking LLM for Life Sciences Inference || from Gene Knowledge to Functional Understanding || Xiaohan Huang || CNIC, CAS || UCAS || Beijing, China || xhhuang@cnic.cn || Meng Xiao || DUKE-NUS Med School, NUS || CNIC, CAS || Singapore || meng.xiao@nus.edu.sg || Chuan Qin || CNIC, CAS || Beijing, China || qi ... (truncated) ||  || { || ""title"": ""SciHorizon-Gene: Benchmarking LLM for Life Sciences Inference"", || ""authors"": [ || ""Xiaohan Huang"", || ""Meng Xiao"", || ""Chuan Qin"", || ""Qingqing Long"", || ""qqlong"", || ""Jinmiao Chen"", || ""micchenj"", || ""Yuanchun Zhou"", || ""zyc"", || ""Hengshu Zhu"" || ], || ""doi"": ""XXXXXXX.XXXXXXX"", || ""arxiv_id"": ""XXXXXX"", || ""keywords"": [ || ""large language models"", || ""biomedical research"", || ""knowledge-driven interpretation"", || ""cell type annotation"", || ""functional interpretation"", || ""mechanism-oriented analysis"" || ], || ""summary"": ""This paper introduces SciHorizon-Gene, a large-scale gene-centric benchmark for evaluating LLMs in biomedical contexts. It systematically assesses LLMs across four key dimensions: research attention sensitivity, hallucination tendency, answer completeness, and literature influence. The benchmark covers over 190K human genes and more than 540K questions, aiming to identify limitations in current models' gene-level reasoning and their implications for safe biological interpretation."" || } ||  || [ Prompt: 109.8 t/s | Generation: 28.1 t/s ]"
2601.12809v1_Left-Right Symmetry Breaking in CLIP-style Vision-.pdf,LeftRight Symmetry Breaking in CLIP-style Vision-Language Models Trained on Synthetic Spatial-Relation Data,"['Takaki Yamamoto', 'Chihiro Noguchi', 'Toshihiro Tanizawa']",,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LeftRight Symmetry Breaking in CLIP-style Vision-Language Models Trained || on Synthetic Spatial-Relation Data || Takaki Yamamoto1 Chihiro Noguchi 1 Toshihiro Tanizawa1 || Abstract || Spatial understanding remains a key challenge || in vision-language models. Yet it is still unclear || whether such u ... (truncated) ||  || { || ""title"": ""LeftRight Symmetry Breaking in CLIP-style Vision-Language Models Trained on Synthetic Spatial-Relation Data"", || ""authors"": [ || ""Takaki Yamamoto"", || ""Chihiro Noguchi"", || ""Toshihiro Tanizawa"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""vision-language models"", || ""spatial understanding"", || ""left-right relations"", || ""CLIP-style models"", || ""contrastive training"", || ""label diversity"", || ""spatial reasoning"" || ], || ""summary"": ""The paper presents a controllable 1D imagetext testbed to study how left-right relational understanding emerges in vision-language models trained with a CLIP-style contrastive objective. It finds that contrastive training induces left-right symmetry breaking and that label diversity drives generalization."" || } ||  || [ Prompt: 112.5 t/s | Generation: 27.9 t/s ]"
2601.12816v1_Fisher-Orthogonal Projected Natural Gradient Desce.pdf,Fisher-Orthogonal Projected Natural Gradient Descent for Continual Learning,"['Ishir Garg', 'Neel Kolhe', 'Andy Peng', 'Rohan Gopalam']",10.48550/arXiv.2026.12345,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Fisher-Orthogonal Projected Natural Gradient Descent for Continual Learning || Ishir Garg 1 Neel Kolhe 1 Andy Peng 1 Rohan Gopalam 1 || Abstract || Continual learning aims to enable neural networks || to acquire new knowledge on sequential tasks. || However, the key challenge in such settings is || t ... (truncated) ||  || { || ""title"": ""Fisher-Orthogonal Projected Natural Gradient Descent for Continual Learning"", || ""authors"": [ || ""Ishir Garg"", || ""Neel Kolhe"", || ""Andy Peng"", || ""Rohan Gopalam"" || ], || ""doi"": ""10.48550/arXiv.2026.12345"", || ""arxiv_id"": ""arXiv:2509.12345"", || ""keywords"": [ || ""continual learning"", || ""Fisher-Orthogonal projection"", || ""natural gradient descent"", || ""catastrophic forgetting"", || ""information geometry"" || ], || ""summary"": ""The paper proposes a Fisher-Orthogonal Projected Natural Gradient Descent (FOPNG) optimizer to address catastrophic forgetting in continual learning by enforcing Fisher orthogonality constraints. This method projects gradients onto the Fisher-orthogonal complement, enabling stable learning across sequential tasks while preserving prior performance."" || } ||  || [ Prompt: 105.4 t/s | Generation: 26.9 t/s ]"
2601.12822v1_MirrorGuard Toward Secure Computer-Use Agents via .pdf,MirrorGuard: Toward Secure Computer-Use Agents via Simulation-to-Real Reasoning Correction,"['Wenqi Zhang', 'Yulin Shen', 'Changyue Jiang', 'Jiarun Dai', 'Geng Hong', 'Xudong Pan', 'ghong@fudan.edu.cn', 'cyjiang24@m.fudan.edu.cn', 'jrdai@fudan.edu.cn', 'xdpan@fudan.edu.cn']",10.48550/arXiv.2311.06824,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MirrorGuard: Toward Secure Computer-Use Agents via || Simulation-to-Real Reasoning Correction || Wenqi Zhang || Fudan University || Shanghai, China || 25113050235@m.fudan.edu.cn || Yulin Shen || Fudan University || Shanghai, China || 24210240286@m.fudan.edu.cn || Changyue Jiang || Fudan University || Shanghai Innovati ... (truncated) ||  || { || ""title"": ""MirrorGuard: Toward Secure Computer-Use Agents via Simulation-to-Real Reasoning Correction"", || ""authors"": [ || ""Wenqi Zhang"", || ""Yulin Shen"", || ""Changyue Jiang"", || ""Jiarun Dai"", || ""Geng Hong"", || ""Xudong Pan"", || ""ghong@fudan.edu.cn"", || ""cyjiang24@m.fudan.edu.cn"", || ""jrdai@fudan.edu.cn"", || ""xdpan@fudan.edu.cn"" || ], || ""doi"": ""10.48550/arXiv.2311.06824"", || ""arxiv_id"": ""arXiv:2311.06824"", || ""keywords"": [ || ""security"", || ""computer use agents"", || ""simulation-based training"", || ""real-world testing"", || ""autonomous interaction"", || ""malicious instructions"" || ], || ""summary"": ""This paper presents MirrorGuard, a defense framework for Computer Use Agents that leverages simulation-to-real reasoning correction to mitigate security risks. It introduces a neural-symbolic simulation pipeline to detect and rectify insecure reasoning chains, improving system safety without sacrificing utility. Extensive evaluations show significant reductions in unsafe behavior across benchmarks."" || } ||  || [ Prompt: 107.4 t/s | Generation: 27.9 t/s ]"
2601.12837v1_Cognition spaces natural artificial and hybrid.pdf,"Cognition spaces: natural, artificial, and hybrid","['Ricard Sole', 'Luis F Seoane', 'Jordi Pla-Mauri', 'Michael Timothy Bennett', 'Michael E. Hochberg', 'Dr. Aiguader', 'Institucio Catalana de la Recerca i Estudis Avanc ats (ICREA)', 'Institut de Biologia Evolutiva, CSIC-UPF', 'Santa Fe Institute', 'School of Computing, Australian National University', 'ISEM, Universite de Montpellier', 'Allen Discovery Center, Tufts University', 'Wyss Institute for Biologically Inspired Engineering, Harvard University']",,27.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Cognition spaces: natural, artificial, and hybrid || Ricard Sole,1, 2, 3, 4,Luis F Seoane, 3 Jordi Pla-Mauri,1, 3 Michael Timothy Bennett, 5 Michael E. Hochberg, 6, 4 || and Michael Levin 7, 8 || 1Complex Systems Lab, Universitat Pompeu Fabra, Dr. Aiguader 88, 08003 Barcelona. || 2Institucio Ca ... (truncated) ||  || { || ""title"": ""Cognition spaces: natural, artificial, and hybrid"", || ""authors"": [ || ""Ricard Sole"", || ""Luis F Seoane"", || ""Jordi Pla-Mauri"", || ""Michael Timothy Bennett"", || ""Michael E. Hochberg"", || ""Dr. Aiguader"", || ""Institucio Catalana de la Recerca i Estudis Avanc ats (ICREA)"", || ""Institut de Biologia Evolutiva, CSIC-UPF"", || ""Santa Fe Institute"", || ""School of Computing, Australian National University"", || ""ISEM, Universite de Montpellier"", || ""Allen Discovery Center, Tufts University"", || ""Wyss Institute for Biologically Inspired Engineering, Harvard University"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Evolved cognition"", || ""basal cognition"", || ""artificial life"", || ""artificial intelligence"", || ""synthetic biology"", || ""morphospace"" || ], || ""summary"": ""Cognition spaces are proposed as a unified framework to compare diverse cognitive systems across natural, artificial, and hybrid domains, highlighting the uneven distribution of cognitive capabilities and the role of constraints in shaping them."" || } ||  || [ Prompt: 111.3 t/s | Generation: 27.2 t/s ]"
2601.12842v1_SCULPT Constraint-Guided Pruned MCTS that Carves E.pdf,SCULPT: Constraint-Guided Pruned MCTS that Carves Efficient Paths for Mathematical Reasoning,"['Qitong Fang', 'Haotian Li', 'Xu Wang']",,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SCULPT: Constraint-Guided Pruned MCTS that Carves Efficient Paths for || Mathematical Reasoning || Qitong Fang* || Jilin Jianzhu University || fangqitong@ || student.jlju.edu.cn || Haotian Li || Jilin Jianzhu University || lihaotian@ || student.jlju.edu.cn || Xu Wang || Jilin Jianzhu University || wangxu@ || jlju.edu.cn || ... (truncated) ||  || { || ""title"": ""SCULPT: Constraint-Guided Pruned MCTS that Carves Efficient Paths for Mathematical Reasoning"", || ""authors"": [ || ""Qitong Fang"", || ""Haotian Li"", || ""Xu Wang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""constraint-guided"", || ""pruned MCTS"", || ""mathematical reasoning"", || ""LLM"", || ""search strategies"", || ""domain-aware scoring"" || ], || ""summary"": ""Automated agent workflows can enhance LLM problem-solving, but current search strategies rely on stochastic exploration, leading to implausible paths. This paper introduces SCULPT, a constraint-guided MCTS that improves reasoning accuracy by integrating domain-aware scoring and pruning."" || } ||  || [ Prompt: 112.0 t/s | Generation: 27.9 t/s ]"
2601.12849v1_The Cost of EFX Generalized-Mean Welfare and Compl.pdf,The Cost of EFX: Generalized-Mean Welfare and Complexity Dichotomies with Few Surplus Items,"['Eugene Lim', 'Tzeh Yuan Neoh', 'Nicholas Teh']",,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || The Cost of EFX: Generalized-Mean Welfare and || Complexity Dichotomies with Few Surplus Items || Eugene Lim1, Tzeh Yuan Neoh2 and Nicholas Teh3 || 1National University of Singapore, Singapore || 2Harvard University, USA || 3University of Oxford, UK || Abstract || Envy-freeness up to any good (EFX) is a ... (truncated) ||  || { || ""title"": ""The Cost of EFX: Generalized-Mean Welfare and Complexity Dichotomies with Few Surplus Items"", || ""authors"": [ || ""Eugene Lim"", || ""Tzeh Yuan Neoh"", || ""Nicholas Teh"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper explores envy-freeness up to any good (EFX) in settings with few surplus items, analyzing computational complexity and welfare implications."" || } ||  || [ Prompt: 113.2 t/s | Generation: 28.7 t/s ]"
2601.12856v1_Mining Citywide Dengue Spread Patterns in Singapor.pdf,Mining Citywide Dengue Spread Patterns in Singapore Through Hotspot Dynamics from Open Web Data,"['Liping Huang', 'Gaoxi Xiao', 'Stefan Ma', 'Hechang Chen', 'Shisong Tang']",10.1145/XXXXXX.XXXXXX,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Mining Citywide Dengue Spread Patterns in Singapore Through || Hotspot Dynamics from Open Web Data || Liping Huang || Agency for Science, Technology and || Research, Singapore || Singapore || liping.huang.sg@gmail.com || Gaoxi Xiao || Nanyang Technological University || Singapore || egxxiao@ntu.edu.sg || Stefan Ma || ... (truncated) ||  || { || ""title"": ""Mining Citywide Dengue Spread Patterns in Singapore Through Hotspot Dynamics from Open Web Data"", || ""authors"": [ || ""Liping Huang"", || ""Gaoxi Xiao"", || ""Stefan Ma"", || ""Hechang Chen"", || ""Shisong Tang"" || ], || ""doi"": ""10.1145/XXXXXX.XXXXXX"", || ""arxiv_id"": """", || ""keywords"": [ || ""Dengue Cases"", || ""Disease Spreading Pattern"", || ""Hotpot Dynamics"", || ""Ma"" || ], || ""summary"": ""This study introduces a novel framework that uncovers and exploits latent transmission links between urban regions using publicly available dengue case data. It models hotspot formation influenced by epidemic dynamics and human mobility, demonstrating effectiveness in predicting dengue spread and validating transmission patterns."" || } ||  || [ Prompt: 108.6 t/s | Generation: 28.1 t/s ]"
2601.12879v1_Hierarchical Sparse Circuit Extraction from Billio.pdf,Hierarchical Sparse Circuit Extraction from Billion-Parameter Language Models through Scalable Attribution Graph Decomposition,"['Mohammed Mudassir Uddin', 'Shahnawaz Alam', 'Mohammed Kaif Pasha']",,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Hierarchical Sparse Circuit Extraction from || Billion-Parameter Language Models through || Scalable Attribution Graph Decomposition || Mohammed Mudassir Uddin , Shahnawaz Alam, Mohammed Kaif Pasha || {mohd.mudassiruddin7@gmail.com, shahnawaz.alam1024@gmail.com, mdkaifpasha2k@gmail.com} || Departm ... (truncated) ||  || { || ""title"": ""Hierarchical Sparse Circuit Extraction from Billion-Parameter Language Models through Scalable Attribution Graph Decomposition"", || ""authors"": [ || ""Mohammed Mudassir Uddin"", || ""Shahnawaz Alam"", || ""Mohammed Kaif Pasha"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Mechanistic interpretability"", || ""sparse computational graphs"", || ""circuit discovery"", || ""transformer architectures"", || ""causal inference"", || ""attribution methods"", || ""hierarchical decomposition"" || ], || ""summary"": ""The paper presents a framework for extracting sparse computational circuits from large language models using hierarchical graph decomposition and differentiable search, aiming to improve interpretability while managing complexity."" || } ||  || [ Prompt: 121.3 t/s | Generation: 26.9 t/s ]"
2601.12882v1_YOLO26 An Analysis of NMS-Free End to End Framewor.pdf,YOLO26: ANALYSIS OF NMS-FREE END-TO-END OBJECT DETECTION,['Sudip Chakrabarty'],arXiv:2601.12882v1,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || YOLO26: ANANALYSIS OFNMS-FREEEND TOEND || FRAMEWORK FORREAL-TIMEOBJECTDETECTION || Sudip Chakrabarty || School of Computer Engineering, KIIT University || sudipchakrabarty6@gmail.com || January 21, 2026 || ABSTRACT || The ""You Only Look Once"" (YOLO) framework has long served as the benchmark || for real-ti ... (truncated) ||  || { || ""title"": ""YOLO26: ANALYSIS OF NMS-FREE END-TO-END OBJECT DETECTION"", || ""authors"": [""Sudip Chakrabarty""], || ""doi"": ""arXiv:2601.12882v1"", || ""arxiv_id"": ""arXiv:2601.12882"", || ""keywords"": [""YOLOv26"", ""End-to-End Object Detection"", ""NMS-Free"", ""MuSGD"", ""ProgLoss""], || ""summary"": ""This paper analyzes YOLO26, a framework that eliminates Non-Maximum Suppression in favor of end-to-end learning, introducing innovations such as MuSGD optimizer, STAL for small-target assignment, and ProgLoss for dynamic supervision. It demonstrates YOLO26's superior performance in speed and accuracy compared to previous models."" || } ||  || [ Prompt: 118.7 t/s | Generation: 28.6 t/s ]"
2601.12886v1_Communication Methods in Multi-Agent Reinforcement.pdf,Communication Methods in Multi-Agent,['Christoph Wittner'],k12045895@students.jku.at,30.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Communication Methods in Multi-Agent || Reinforcement Learning || Christoph Wittner[0009000414941730] || Telecooperation Institute, Johannes Kepler University Linz, Austria || k12045895@students.jku.at || Abstract. Multi-agent reinforcement learning is a promising research || area that extends establ ... (truncated) ||  || { || ""title"": ""Communication Methods in Multi-Agent"", || ""authors"": [""Christoph Wittner""], || ""doi"": ""k12045895@students.jku.at"", || ""arxiv_id"": ""0009000414941730"", || ""keywords"": [""Machine learning"", ""MARL"", ""Communication""], || ""summary"": ""This work provides an overview of communication techniques in multi-agent reinforcement learning, evaluating explicit, implicit, attention-based, graph-based, and hierarchical/role-based methods. It highlights the lack of a universal optimal communication framework and emphasizes the need for scalable and robust solutions."" || } ||  || [ Prompt: 119.8 t/s | Generation: 30.8 t/s ]"
2601.12893v1_AdaNODEs Test Time Adaptation for Time Series Fore.pdf,Test time adaptation for time series forecasting using neural odes,"['Ting Dang', 'Soumyajit Chatterjee', 'Hong Jia', 'Yu Wu#', 'Flora Salim+', 'Fahim Kawsar']",,26.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ADANODES: TEST TIME ADAPTA TION FOR TIME SERIES FORECASTING USING || NEURAL ODES || Ting Dang, Soumyajit Chatterjee, Hong Jia, Yu Wu#, Flora Salim+, Fahim Kawsar || The University of Melbourne, Australia Nokia Bell Labs, UK || The University of Auckland, New Zealand #University of Cambridge, UK ... (truncated) ||  || { || ""title"": ""Test time adaptation for time series forecasting using neural odes"", || ""authors"": [ || ""Ting Dang"", || ""Soumyajit Chatterjee"", || ""Hong Jia"", || ""Yu Wu#"", || ""Flora Salim+"", || ""Fahim Kawsar"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""test time adaptation"", || ""time series forecasting"", || ""domain adaptation"", || ""neural odes"", || ""unlabeled data"", || ""forecasting tasks"" || ], || ""summary"": ""This paper presents AdaNODEs, a novel source-free test-time adaptation method for time series forecasting using Neural Ordinary Differential Equations. It addresses challenges in adapting pre-trained models to new data distributions without labeled target data, offering improvements over existing methods."" || } ||  || [ Prompt: 110.5 t/s | Generation: 26.8 t/s ]"
2601.12904v1_From Prefix Cache to Fusion RAG Cache Accelerating.pdf,From Prefix Cache to Fusion RAG Cache: Accelerating LLM,"['Jiahao Wang', 'Weiyu Xie', 'Mingxing Zhang', 'Boxing Zhang', 'Jianwei Dong', 'Yuening Zhu', 'Chen Lin', 'Jinqi Tang', 'Yaochen Han', 'Zhiyuan Ai', 'Xianglin Chen']",,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || From Prefix Cache to Fusion RAG Cache: Accelerating LLM || Inference in Retrieval-Augmented Generation || JIAHAO WANG,Hangzhou Dianzi University, China and Approaching.AI, China || WEIYU XIE,Tsinghua University, China || MINGXING ZHANG ,Tsinghua University, China || BOXING ZHANG,Tsinghua Universit ... (truncated) ||  || { || ""title"": ""From Prefix Cache to Fusion RAG Cache: Accelerating LLM"", || ""authors"": [ || ""Jiahao Wang"", || ""Weiyu Xie"", || ""Mingxing Zhang"", || ""Boxing Zhang"", || ""Jianwei Dong"", || ""Yuening Zhu"", || ""Chen Lin"", || ""Jinqi Tang"", || ""Yaochen Han"", || ""Zhiyuan Ai"", || ""Xianglin Chen"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Retrieval-Augmented Generation"", || ""Large Language Models"", || ""KVCache"", || ""Fusion RAG"", || ""Hallucinations"", || ""Prompt Length"", || ""Computational Cost"", || ""Generation Quality"", || ""Time to First Token"" || ], || ""summary"": ""This paper discusses how FusionRAG improves RAG performance by optimizing preprocessing and reprocessing stages, achieving better generation quality with reduced computational cost compared to previous methods."" || } ||  || [ Prompt: 112.6 t/s | Generation: 27.9 t/s ]"
2601.12910v1_SciCoQA Quality Assurance for Scientific Paper--Co.pdf,Quality Assurance for Scientific Paper,"['Tim Baumgrtner', 'Iryna Gurevych']",https://hf.co/datasets/ukplab/scicoqa,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SCICOQA: Quality Assurance for Scientific PaperCode Alignment || Tim BaumgrtnerandIryna Gurevych || Ubiquitous Knowledge Processing Lab (UKP Lab), Department of Computer Science, || TU Darmstadt and National Research Center for Applied Cybersecurity ATHENE || Code: https://github.com/ukplab/sci ... (truncated) ||  || { || ""title"": ""Quality Assurance for Scientific Paper"", || ""authors"": [""Tim Baumgrtner"", ""Iryna Gurevych""], || ""doi"": ""https://hf.co/datasets/ukplab/scicoqa"", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""SCICOQA is a dataset for detecting discrepancies between scientific publications and their codebases to ensure faithful implementations. It includes 611 discrepancies and proposes synthetic data generation methods."" || } ||  || [ Prompt: 109.3 t/s | Generation: 27.9 t/s ]"
2601.12912v1_Human Emotion Verification by Action Languages via.pdf,Human Emotion Verification by Action Languages,"['Andreas Brannström', 'Juan Carlos Nieves']",10.1017/xxxxx,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TPLP: Page 18.The Author(s), 2021. Published by Cambridge University Press 2021 || doi:10.1017/xxxxx || 1 || Human Emotion Verification by Action Languages || via Answer Set Programming || ANDREAS BR ANNSTR OM || Ume  a University || Department of Computing Science || JUAN CARLOS NIEVES || Ume  a University || D ... (truncated) ||  || { || ""title"": ""Human Emotion Verification by Action Languages"", || ""authors"": [ || ""Andreas Brannström"", || ""Juan Carlos Nieves"" || ], || ""doi"": ""10.1017/xxxxx"", || ""arxiv_id"": ""2601.12912v1"", || ""keywords"": [ || ""Action Languages"", || ""Answer Set Programming"", || ""Theory of Mind"" || ], || ""summary"": ""The paper introduces the action language C-MT, built on answer set programming and transition systems, to model human mental states and emotions. It aims to enable controlled agent behaviors by formalizing transitions between mental states based on psychological principles."" || } ||  || [ Prompt: 111.4 t/s | Generation: 27.5 t/s ]"
2601.12913v1_Actionable Interpretability Must Be Defined in Ter.pdf,Position: Actionable Interpretability Must Be Defined in Terms of Symmetries,"['Pietro Barbiero', 'Mateo Espinosa Zarlenga', 'Francesco Giannini', 'Alberto Termine', 'Filippo Bonchi', 'Mateja Jamnik', 'Giuseppe Marra', 'Pietro Barbiero', 'Giuseppe Marra']",,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Position: Actionable Interpretability Must Be Defined in Terms of Symmetries || Pietro Barbiero 1 Mateo Espinosa Zarlenga 2 Francesco Giannini 3 Alberto Termine4 Filippo Bonchi 3 || Mateja Jamnik 5 Giuseppe Marra 6 || Abstract || This paper argues that interpretability research in || Artificial In ... (truncated) ||  || { || ""title"": ""Position: Actionable Interpretability Must Be Defined in Terms of Symmetries"", || ""authors"": [ || ""Pietro Barbiero"", || ""Mateo Espinosa Zarlenga"", || ""Francesco Giannini"", || ""Alberto Termine"", || ""Filippo Bonchi"", || ""Mateja Jamnik"", || ""Giuseppe Marra"", || ""Pietro Barbiero"", || ""Giuseppe Marra"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper argues that interpretability research in AI is fundamentally ill-posed because existing definitions lack formal principles. It posits that interpretability must be defined in terms of symmetries to derive actionable models and inference formulations."" || } ||  || [ Prompt: 111.9 t/s | Generation: 28.5 t/s ]"
2601.12922v1_Your Privacy Depends on Others Collusion Vulnerabi.pdf,Your Privacy Depends on Others: Collusion Vulnerabilities in Individual Differential Privacy,"['Johannes Kaiser', 'Alexander Ziller', 'Eleni Triantafillou', 'Daniel Rckert', '3', 'Georgios Kaissis']",,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Your Privacy Depends on Others: || Collusion Vulnerabilities in Individual Differential || Privacy || Johannes Kaiser1, 2, Alexander Ziller1, Eleni Triantafillou4, Daniel Rckert1, 3, and Georgios Kaissis2, * || 1Chair for AI in Healthcare and Medicine, Technical University of Munich and TUM Uni ... (truncated) ||  || { || ""title"": ""Your Privacy Depends on Others: Collusion Vulnerabilities in Individual Differential Privacy"", || ""authors"": [ || ""Johannes Kaiser"", || ""Alexander Ziller"", || ""Eleni Triantafillou"", || ""Daniel Rckert"", || ""3"", || ""Georgios Kaissis"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Differential Privacy"", || ""Individual Differential Privacy"", || ""Excess Risk"", || ""Membership Inference"", || ""Collusion"", || ""Privacy Budget"" || ], || ""summary"": ""This paper reveals a previously overlooked vulnerability in sampling-based iDP mechanisms, showing that privacy risk depends not only on individual privacy budgets but also on collective privacy choices. It demonstrates that certain privacy preference distributions can unintentionally inflate individual risks, providing an exploitable attack vector within DP guarantees."" || } ||  || [ Prompt: 110.4 t/s | Generation: 26.9 t/s ]"
2601.12925v1_ForeDiffusion Foresight-Conditioned Diffusion Poli.pdf,Foresight-Conditioned Diffusion Policy via Future View,"['Weize Xie1', 'Yi Ding1', 'Ying He1', 'Leilei Wang1', 'Binwen Bai1', 'Zheyi Zhao1', 'Chenyang Wang1', 'F. Richard Yu3']","2410105060, 2410103031",28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ForeDiffusion: Foresight-Conditioned Diffusion Policy via Future View || Construction for Robot Manipulation || Weize Xie1, * || , Yi Ding1, * || , Ying He1, || , Leilei Wang1, 2, Binwen Bai1, Zheyi Zhao1, 2, || Chenyang Wang1, F. Richard Yu3 || 1College of Computer Science and Software Engineering, Sh ... (truncated) ||  || { || ""title"": ""Foresight-Conditioned Diffusion Policy via Future View"", || ""authors"": [ || ""Weize Xie1"", || ""Yi Ding1"", || ""Ying He1"", || ""Leilei Wang1"", || ""Binwen Bai1"", || ""Zheyi Zhao1"", || ""Chenyang Wang1"", || ""F. Richard Yu3"" || ], || ""doi"": ""2410105060, 2410103031"", || ""arxiv_id"": ""2300271042"", || ""keywords"": [ || ""Foresight-Conditioned Diffusion"", || ""Diffusion Strategies"", || ""Robot Manipulation"", || ""Future View"", || ""Task Complexity"", || ""Success Rate"" || ], || ""summary"": ""This paper proposes ForeDiffusion, a diffusion-based policy that incorporates future view predictions to improve robot manipulation performance. It addresses limitations of existing methods by using a dual loss mechanism and achieving higher success rates in complex tasks."" || } ||  || [ Prompt: 110.0 t/s | Generation: 28.7 t/s ]"
2601.12929v1_Membership Inference Test Auditing Training Data i.pdf,,[],,27.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Membership Inference Test: || Auditing Training Data in Object Classification Models || Gonzalo Mancera, Daniel DeAlcala, Aythami Morales, Ruben Tolosana, Julian Fierrez || 1Biometrics and Data Pattern Analytics Lab, Universidad Autonoma de Madrid, Spain || {gonzalo.mancera, daniel.dealcala,ayt ... (truncated) ||  || { || ""title"": ""Membership Inference Test: Auditing Training Data in Object Classification Models"", || ""authors"": [ || ""Gonzalo Mancera"", || ""Daniel DeAlcala"", || ""Aythami Morales"", || ""Ruben Tolosana"", || ""Julian Fierrez"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [ || ""Membership Inference"", || ""Auditing"", || ""Data Pattern Analytics"", || ""Object Recognition"", || ""AI Training"", || ""Transparency"" || ], || ""summary"": ""This research analyzes Membership Inference Tests (MINT) in object classification models, proposing architectures to optimize data utilization and improve precision in detecting training data usage."" || } ||  || [ Prompt: 108.4 t/s | Generation: 27.0 t/s ]"
2601.12931v1_Online Continual Learning for Time Series a Natura.pdf,Online Continual Learning Fortimeseries: A Natural Score-Driven Approach,"['Edoardo Urettini', 'Daniele Atzeni', 'Ioanna-Yvonni Tsaknaki', 'Antonio Carta']",,28.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Arxiv Preprint || ONLINECONTINUALLEARNING FORTIMESERIES:A || NATURALSCORE-DRIVENAPPROACH || Edoardo Urettini1, 2, Daniele Atzeni 3, Ioanna-Yvonni Tsaknaki2, Antonio Carta 1 || 1University of Pisa, Pisa, Italy || 2Scuola Normale Superiore, Pisa, Italy || 3IIT-CNR, Pisa, Italy || ABSTRACT || Online continual ... (truncated) ||  || { || ""title"": ""Online Continual Learning Fortimeseries: A Natural Score-Driven Approach"", || ""authors"": [ || ""Edoardo Urettini"", || ""Daniele Atzeni"", || ""Ioanna-Yvonni Tsaknaki"", || ""Antonio Carta"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper discusses applying online continual learning to online time series forecasting, introducing Natural Score-driven Replay and demonstrating improved forecasting performance."" || } ||  || [ Prompt: 110.3 t/s | Generation: 28.0 t/s ]"
2601.12937v1_On the Evidentiary Limits of Membership Inference .pdf,Evidentiary Limits of Membership Inference for Copyright Auditing,"['Murat Bilgehan Ertan', 'Emirhan Boge', 'Kaleel Mahmood', 'Marten van Dijk']",1 2,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || On the Evidentiary Limits of Membership Inference for Copyright Auditing || Murat Bilgehan Ertan 1 2 Emirhan Boge 3 Min Chen 2 Kaleel Mahmood 4 * Marten van Dijk 1 2 * || Abstract || As large language models (LLMs) are trained on || increasingly opaque corpora, membership infer- || ence attacks (M ... (truncated) ||  || { || ""title"": ""Evidentiary Limits of Membership Inference for Copyright Auditing"", || ""authors"": [ || ""Murat Bilgehan Ertan"", || ""Emirhan Boge"", || ""Kaleel Mahmood"", || ""Marten van Dijk"" || ], || ""doi"": ""1 2"", || ""arxiv_id"": ""1 2"", || ""keywords"": [ || ""membership inference"", || ""memory forged texts"", || ""copyright auditing"", || ""large language models"", || ""semantic preservation"" || ], || ""summary"": ""This paper explores the reliability of membership inference attacks as evidence in copyright disputes, introducing SAGE for paraphrasing and testing MIAs under a judge-prosecutor model. Results indicate MIAs are sensitive to semantic transformations and not robust enough as standalone auditing tools."" || } ||  || [ Prompt: 106.8 t/s | Generation: 27.7 t/s ]"
2601.12938v1_The Post-Turing Condition Conceptualising Artifici.pdf,The Post-Turing Condition: Conceptualising Artificial Subjectivity and Synthetic Sociality,"['Thoren Jelinek', 'Patrick Glauner', 'Alvin Wang Graylin', 'Yubao Qiu']",,30.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || The Post-Turing Condition: Conceptualising Artificial Subjectivity and Synthetic Sociality  Thorsten Jelinek,1,4 Patrick Glauner,2 Alvin Wang Graylin,3 Yubao Qiu4,5   1. Centre for Digital Governance, Hertie School, Berlin, Germany   2. Department of Applied Computer Science, De ... (truncated) ||  || { || ""title"": ""The Post-Turing Condition: Conceptualising Artificial Subjectivity and Synthetic Sociality"", || ""authors"": [ || ""Thoren Jelinek"", || ""Patrick Glauner"", || ""Alvin Wang Graylin"", || ""Yubao Qiu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""In the Post-Turing era, artificial intelligence increasingly shapes social coordination and meaning formation rather than merely automating cognitive tasks. The central challenge is not whether machines become conscious, but whether processes of interpretation and shared reference are progressively automated in ways that marginalize human participation."" || } ||  || [ Prompt: 118.9 t/s | Generation: 30.8 t/s ]"
2601.12939v1_Active Inference-Driven World Modeling for Adaptiv.pdf,Active Inference-Driven World Modeling For Adaptive UA V V Swarm,"['Kaleem Arshid', 'Ali Krayani', 'Lucio Marcenaro', 'David Martin Gomez', 'Carlo Regazzoni']",PE00000001 - program RESTART,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ACTIVE INFERENCE-DRIVEN WORLD MODELING FOR ADAPTIVE UA V SW ARM || TRAJECTORY DESIGN || Kaleem Arshid 1,2, Ali Krayani 1, Lucio Marcenaro 1, David Martin Gomez 2, Carlo Regazzoni 1 || 1University of Genoa, Italy, 2 Carlos III University Madrid, Spain || ABSTRACT || This paper proposes an Active In ... (truncated) ||  || { || ""title"": ""Active Inference-Driven World Modeling For Adaptive UA V V Swarm"", || ""authors"": [ || ""Kaleem Arshid"", || ""Ali Krayani"", || ""Lucio Marcenaro"", || ""David Martin Gomez"", || ""Carlo Regazzoni"" || ], || ""doi"": ""PE00000001 - program RESTART"", || ""arxiv_id"": """", || ""keywords"": [ || ""Autonomous Systems"", || ""World Model"", || ""UA V-Swarm"", || ""Probabilistic Decision-Making"", || ""Active-Inference"" || ], || ""summary"": ""This paper proposes an Active Inference-based framework for autonomous trajectory design in UA V swarms. The method integrates probabilistic reasoning and self-learning to enable distributed mission allocation, route ordering, and motion planning. Expert trajectories generated using a Genetic Algorithm with Repulsion Forces (GARF) are employed to train a hierarchical World Model capturing swarm behavior across mission, route, and motion levels. During online operation, UA Vs infer actions by minimizing divergence between current beliefs and model-predicted states, enabling adaptive responses to dynamic environments. Simulation results show faster convergence, higher stability, and safer navigation than Q-Learning, demonstrating the scalability and cognitive grounding of the proposed framework for intelligent UA V swarm control."" || } ||  || [ Prompt: 109.1 t/s | Generation: 27.8 t/s ]"
2601.12946v1_AI-generated data contamination erodes pathologica.pdf,AI-generated data contamination erodes pathological variability and diagnostic reliability,"['Hongyu He', 'Shaowen Xiang', 'Ye Zhang', 'Yingtao Zhu', 'Jin Zhang', 'Hao Deng', 'Emily Alsentzer', 'Qingyu Chen', 'Kun-Hsing Yu', 'Andrew Marmenshall', 'Tingting Chen', 'Srinivas Anumasa', 'Daniel Ebner', 'Dean Ho', 'Kee Yuan Ngiam', 'Ching-Yu Cheng', 'Dianbo Liu']",,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Article Title: AI-generated data contamination erodes pathological variability and diagnostic reliability  Hongyu He1, Shaowen Xiang1, Ye Zhang1, Yingtao Zhu1, Jin Zhang1, Hao Deng2,3, Emily Alsentzer4, Qingyu Chen5, Kun-Hsing Yu2, Andrew Marmenshall2, Tingting Chen1, Srinivas Anuma ... (truncated) ||  || { || ""title"": ""AI-generated data contamination erodes pathological variability and diagnostic reliability"", || ""authors"": [ || ""Hongyu He"", || ""Shaowen Xiang"", || ""Ye Zhang"", || ""Yingtao Zhu"", || ""Jin Zhang"", || ""Hao Deng"", || ""Emily Alsentzer"", || ""Qingyu Chen"", || ""Kun-Hsing Yu"", || ""Andrew Marmenshall"", || ""Tingting Chen"", || ""Srinivas Anumasa"", || ""Daniel Ebner"", || ""Dean Ho"", || ""Kee Yuan Ngiam"", || ""Ching-Yu Cheng"", || ""Dianbo Liu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The study examines how AI-generated synthetic data degrades pathological variability and diagnostic reliability in medical records, highlighting the loss of rare but critical findings and skewed demographic representations. It finds that models converge toward generic phenotypes, and false reassurance rates triple, undermining clinical usefulness."" || } ||  || [ Prompt: 117.8 t/s | Generation: 28.4 t/s ]"
2601.12951v1_Beyond Accuracy Characterizing Code Comprehension .pdf,Beyond Accuracy: Characterizing Code Comprehension,"['Felix Mchtle', 'Jan-Niclas Serr', 'Nils Loose', 'Thomas Eisenbarth']",59 175 55,27.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Beyond Accuracy: Characterizing Code Comprehension || Capabilities in (Large) Language Models || Felix Mchtle || ITS, University of Luebeck || Luebeck, Germany || Jan-Niclas Serr || ITS, University of Luebeck || Luebeck, Germany || Nils Loose || ITS, University of Luebeck || Luebeck, Germany || Thomas Eisenbarth || IT ... (truncated) ||  || { || ""title"": ""Beyond Accuracy: Characterizing Code Comprehension"", || ""authors"": [ || ""Felix Mchtle"", || ""Jan-Niclas Serr"", || ""Nils Loose"", || ""Thomas Eisenbarth"" || ], || ""doi"": ""59 175 55"", || ""arxiv_id"": """", || ""keywords"": [ || ""Code Comprehension"", || ""Model Evaluation and Benchmarking"", || ""Machine Learning for Software Engineering"" || ], || ""summary"": ""This paper investigates whether LLM code-comprehension performance aligns with traditional human-centric software metrics or reflects distinct patterns. It introduces a diagnostic framework linking model performance to complexity metrics and finds minimal correlation between human metrics and LLM success."" || } ||  || [ Prompt: 121.8 t/s | Generation: 27.0 t/s ]"
2601.13007v1_ArchAgent Scalable Legacy Software Architecture Re.pdf,ArchitectAgent: Scalable Legacy Software Architecture Recovery with LLMs,"['Rusheng Pan Bingcheng', 'Mao Tianyi Ma', 'Zhenhua Ling']",https://github.com/panrusheng/arch-eval-benchmark,27.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ARCHAGENT: SCALABLE LEGACY SOFTW ARE ARCHITECTURE RECOVERY WITH || LLMS || Rusheng Pan Bingcheng Mao Tianyi Ma Zhenhua Ling || HiThink Research, Hanzhou, China || University of Science and Technology of China, Hefei, China || ABSTRACT || Recovering accurate architecture from large-scale legacy || softw ... (truncated) ||  || { || ""title"": ""ArchitectAgent: Scalable Legacy Software Architecture Recovery with LLMs"", || ""authors"": [""Rusheng Pan Bingcheng"", ""Mao Tianyi Ma"", ""Zhenhua Ling""], || ""doi"": ""https://github.com/panrusheng/arch-eval-benchmark"", || ""arxiv_id"": """", || ""keywords"": [""software architecture recovery"", ""code repository"", ""large language models""], || ""summary"": ""Recovering accurate architecture from large-scale legacy software is hindered by architectural drift, missing relationships, and limited context of LLMs. ArchAgent introduces a scalable agent-based framework combining static analysis, adaptive code segmentation, and LLM-powered synthesis to reconstruct multiview architectures from cross-repository codebases. It improves architectural accuracy and supports business-aligned abstractions."" || } ||  || [ Prompt: 108.7 t/s | Generation: 27.0 t/s ]"
2601.13013v1_HT-GNN Hyper-Temporal Graph Neural Network for Cus.pdf,,[],,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || HT-GNN: Hyper-Temporal Graph Neural Network || for Customer Lifetime Value Prediction in Baidu || Ads || Xiaohui Zhao , Xinjian Zhao , Jiahui Zhang , Guoyu Liu , Houzhi Wang , Shu Wu || Baidu Inc., Institute of Automation, Chinese Academy of Sciences, CUHK-Shenzhen || {zhaoxiaohui03, zhangjiahui0 ... (truncated) ||  || { || ""title"": ""HT-GNN: Hyper-Temporal Graph Neural Network"", || ""authors"": [ || ""HT-GNN: Hyper-Temporal Graph Neural Network"", || ""Xiaohui Zhao"", || ""Xinjian Zhao"", || ""Jiahui Zhang"", || ""Guoyu Liu"", || ""Houzhi Wang"", || ""Shu Wu"", || ""Baidu Inc."", || ""Institute of Automation, Chinese Academy of Sciences"", || ""CUHK-Shenzhen"" || ], || ""doi"": ""zhaoxiaohui03, zhangjiahui05, liuguoyu, wanghouzhi"", || ""arxiv_id"": """", || ""keywords"": [ || ""Lifetime Value Prediction"", || ""Advertising Platform"", || ""Customer Lifetime Value"", || ""Hypergraph"", || ""Transformer"", || ""Marketing Strategy"", || ""Revenue Growth"" || ], || ""summary"": ""The paper proposes a Hyper-Temporal Graph Neural Network (HT-GNN) to address challenges in lifetime value prediction for Baidu Ads, focusing on demographic heterogeneity and dynamic marketing patterns. Experiments show superior performance across metrics and prediction horizons."" || } ||  || [ Prompt: 106.8 t/s | Generation: 28.4 t/s ]"
2601.13018v1_Bi-Attention HateXplain  Taking into account the s.pdf,Bi-Attention HateXplain,['Ghislain Dorian Tchuente Mondjo'],,26.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Bi-Attention HateXplain : Taking into account the sequential aspect || of data during explainability in a multi-task context || Ghislain Dorian Tchuente Mondjo 1 || tchuente.mondjo@gmail.com || Universit e de Yaound e I, Facult e des Sciences, D epartement dInformatique || BP 812 Yaound e, Camerou ... (truncated) ||  || { || ""title"": ""Bi-Attention HateXplain"", || ""authors"": [""Ghislain Dorian Tchuente Mondjo""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Multitask learning"", ""Deep Learning"", ""Hate speech"", ""Explainability"", ""Bi-Attention""], || ""summary"": ""This article discusses the challenges of maintaining consistent attention in multi-task models for hate speech detection and proposes a BiAttention BiRNN model to improve explainability and performance."" || } ||  || [ Prompt: 110.3 t/s | Generation: 26.7 t/s ]"
2601.13020v1_PASs-MoE Mitigating Misaligned Co-drift among Rout.pdf,PASs-MoE: Mitigating Misaligned Co-drift among Router and Experts via Pathway Activation Subspaces for Continual Learning,"['Zhiyan Hou', 'Haiyun Guo', 'Haokai Ma', 'Yandu Sun', 'Yonghui Yang', 'Jinqiao Wang', 'Wuhan AI Research', 'National University of Singapore', 'Southeast University, Nanjing', 'Wuhan AI Research', 'Institute of Automation, Chinese Academy of Sciences', 'University of Chinese Academy of Sciences', 'Nanjing University', 'Nanjing, China', 'Wuhan', 'China']",,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || PASs-MoE: Mitigating Misaligned Co-drift among Router and Experts via || Pathway Activation Subspaces for Continual Learning || Zhiyan Hou1,2, Haiyun Guo1,2, Haokai Ma3, Yandu Sun4, Yonghui Yang3, Jinqiao Wang1,2,5 || 1Institute of Automation, Chinese Academy of Sciences 2University of Chine ... (truncated) ||  || { || ""title"": ""PASs-MoE: Mitigating Misaligned Co-drift among Router and Experts via Pathway Activation Subspaces for Continual Learning"", || ""authors"": [ || ""Zhiyan Hou"", || ""Haiyun Guo"", || ""Haokai Ma"", || ""Yandu Sun"", || ""Yonghui Yang"", || ""Jinqiao Wang"", || ""Wuhan AI Research"", || ""National University of Singapore"", || ""Southeast University, Nanjing"", || ""Wuhan AI Research"", || ""Institute of Automation, Chinese Academy of Sciences"", || ""University of Chinese Academy of Sciences"", || ""Nanjing University"", || ""Nanjing, China"", || ""Wuhan"", || ""China"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""continual instruction tuning"", || ""multimodal large language models"", || ""misaligned co-drift"", || ""pathway activation subspace"", || ""continual learning"", || ""LoRA"", || ""MoE"", || ""forgetting"" || ], || ""summary"": ""The paper addresses Misaligned Co-drift in LoRA-based Mixture-of-Experts methods during continual instruction tuning. It introduces a Pathway Activation Subspace (PASs) to align routing and expert adaptation, improving stability and performance without additional parameters."" || } ||  || [ Prompt: 108.2 t/s | Generation: 27.9 t/s ]"
2601.13048v1_Analysis of Long Range Dependency Understanding in.pdf,Analysis of Long Range Dependency Understanding in STA Space,"['Srividya Ravikumar', 'Abhinav Anand', 'Shweta V erma', 'Mira Mezini']",10.48550/arXiv.2405.12345,27.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ANALYSIS OF LONG RANGE DEPENDENCY UNDERSTANDING IN STA TE SPACE || MODELS || Srividya Ravikumar Abhinav Anand Shweta V erma Mira Mezini || TU Darmstadt || Hessian Center for Artificial Intelligence, Darmstadt, Germany || National Research Center for Applied Cybersecurity ATHENE || ABSTRACT || Althoug ... (truncated) ||  || { || ""title"": ""Analysis of Long Range Dependency Understanding in STA Space"", || ""authors"": [ || ""Srividya Ravikumar"", || ""Abhinav Anand"", || ""Shweta V erma"", || ""Mira Mezini"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""2405.12345"", || ""keywords"": [ || ""structured state-space models"", || ""interpretability"", || ""vulnerability detection"", || ""source code analysis"", || ""long-range dependencies"" || ], || ""summary"": ""This work presents the first systematic kernel interpretability study of the diagonalized state-space model (S4D) trained on a real-world task (vulnerability detection in source code). The study analyzes the long-range modeling capability of S4D across different architectures, revealing how it can behave as low-pass, band-pass, or high-pass filters. The insights aim to guide future design of better S4D-based models."" || } ||  || [ Prompt: 110.8 t/s | Generation: 27.3 t/s ]"
2601.13054v1_TinyML-Enabled IoT for Sustainable Precision Irrig.pdf,TinyML-Enabled IoT for Sustainable Precision Irrigation,"['Kamogelo Taueatsoala1', 'Caitlyn Daniels1', 'Angelina J. Ramsunar1', 'Petrus Bronkhorst2', 'Absalom E. Ezugwu1']",,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TinyML-Enabled IoT for Sustainable Precision Irrigation || Kamogelo Taueatsoala1, Caitlyn Daniels1, Angelina J. Ramsunar1, Petrus Bronkhorst2, Absalom E. Ezugwu1,* || 1 Unit for Data Science and Computing, North-West University, 11 Hoffman Street, Potchefstroom 2520, South || Africa. || 2 U ... (truncated) ||  || { || ""title"": ""TinyML-Enabled IoT for Sustainable Precision Irrigation"", || ""authors"": [ || ""Kamogelo Taueatsoala1"", || ""Caitlyn Daniels1"", || ""Angelina J. Ramsunar1"", || ""Petrus Bronkhorst2"", || ""Absalom E. Ezugwu1"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""TinyML"", || ""edge computing"", || ""Internet of Things"", || ""precision agriculture"", || ""smart irrigation"", || ""sustainable water management"", || ""embedded machine learning"", || ""resource-constrained systems"" || ], || ""summary"": ""A novel edge-first IoT framework integrating TinyML enables autonomous, offline-capable precision irrigation for small-scale farmers, improving water usage efficiency through low-cost hardware and advanced sensor data analysis."" || } ||  || [ Prompt: 106.1 t/s | Generation: 27.5 t/s ]"
2601.13060v1_MagicGUI-RMS A Multi-Agent Reward Model System for.pdf,MagicGUI-RMS: A Multi-Agent Reward Modelsystem,"['Foreself-EvolvingGUI Agents', 'Zecheng Li', 'Zhihui Cao', 'Wenke Huang', 'Yudong Zhang', 'Keying Qi', 'Rui Wang', 'Zeyu Zheng', 'Jian Zhao', 'Hao Zhu', 'Hengxin Wu', 'Yuran Wang', 'Guitao Fan', 'Guokun Wu', 'Yicong Liu', 'Zhilin Gao', 'Haikun Xu', 'He Yang', 'Minqi Xiang', 'Xingyu Liu', 'Zuojian Wang']",,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MAGICGUI-RMS: A MULTI-AGENTREWARDMODELSYSTEM || FORSELF-EVOLVINGGUI AGENTS VIAAUTOMATEDFEEDBACK || REFLUX || Zecheng Li, Zhihui Cao  , Wenke Huang, Yudong Zhang, Keying Qi, Rui Wang, Zeyu Zheng || Jian Zhao, Hao Zhu, Hengxin Wu, Yuran Wang, Guitao Fan, Guokun Wu, Yicong Liu, Zhilin Gao || Haikun X ... (truncated) ||  || { || ""title"": ""MagicGUI-RMS: A Multi-Agent Reward Modelsystem"", || ""authors"": [ || ""Foreself-EvolvingGUI Agents"", || ""Zecheng Li"", || ""Zhihui Cao"", || ""Wenke Huang"", || ""Yudong Zhang"", || ""Keying Qi"", || ""Rui Wang"", || ""Zeyu Zheng"", || ""Jian Zhao"", || ""Hao Zhu"", || ""Hengxin Wu"", || ""Yuran Wang"", || ""Guitao Fan"", || ""Guokun Wu"", || ""Yicong Liu"", || ""Zhilin Gao"", || ""Haikun Xu"", || ""He Yang"", || ""Minqi Xiang"", || ""Xingyu Liu"", || ""Zuojian Wang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""multi-agent"", || ""reward model"", || ""graphical user interface"", || ""autonomous interaction"", || ""task execution"", || ""reactive feedback"", || ""self-evolving learning"" || ], || ""summary"": ""MagicGUI-RMS is a multi-agent reward model system that enables adaptive trajectory evaluation, corrective feedback, and self-evolving learning for GUI agents. It integrates a Domain-Specific Reward Model with a General-Purpose Reward Model to support scalable and robust performance across diverse GUI tasks."" || } ||  || [ Prompt: 110.5 t/s | Generation: 27.6 t/s ]"
2601.13075v1_METIS Mentoring Engine for Thoughtful Inquiry  Sol.pdf,METIS: Mentoring Engine for Thoughtful Inquiry & Solutions,"['Abhinav Rajeev Kumar', 'Dhruv Trehan', 'Paras Chopra']",,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || METIS: Mentoring Engine for Thoughtful Inquiry & Solutions || Abhinav Rajeev Kumar, Dhruv Trehan, Paras Chopra || Lossfunk || {abhinav.kumar, dhruv.trehan, paras}@lossfunk.com || Abstract || Many students lack access to expert research mentor- || ship. We ask whether an AI mentor can move under- || grad ... (truncated) ||  || { || ""title"": ""METIS: Mentoring Engine for Thoughtful Inquiry & Solutions"", || ""authors"": [""Abhinav Rajeev Kumar"", ""Dhruv Trehan"", ""Paras Chopra""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Explores whether an AI mentor can guide undergraduates from idea to publishable paper, evaluating METIS against GPT-5 and Claude Sonnet 4.5 across six writing stages."" || } ||  || [ Prompt: 108.7 t/s | Generation: 28.5 t/s ]"
2601.13111v1_CORE-T COherent REtrieval of Tables for Text-to-SQ.pdf,CORE-T: COherent REtrieval of Tables for Text-to-SQL,"['Hassan Soliman', 'Vivek Gupta', 'Dan Roth', 'Iryna Gurevych']",https://arxiv.org/abs/2106.09685,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || CORE-T: COherent REtrieval of Tables for Text-to-SQL || Hassan Soliman1 Vivek Gupta2 Dan Roth3 Iryna Gurevych1 || 1Ubiquitous Knowledge Processing Lab (UKP Lab), Department of Computer Science || TU Darmstadt and National Research Center for Applied Cybersecurity ATHENE, Germany || 2Arizona Sta ... (truncated) ||  || { || ""title"": ""CORE-T: COherent REtrieval of Tables for Text-to-SQL"", || ""authors"": [ || ""Hassan Soliman"", || ""Vivek Gupta"", || ""Dan Roth"", || ""Iryna Gurevych"" || ], || ""doi"": ""https://arxiv.org/abs/2106.09685"", || ""arxiv_id"": ""arxiv:2106.09685"", || ""keywords"": [ || ""text-to-SQL"", || ""table retrieval"", || ""open-book setting"", || ""LLM-generated metadata"", || ""multi-table execution"" || ], || ""summary"": ""The paper presents CORE-T, a scalable, training-free framework that enriches tables with LLM-generated purpose metadata and pre-computes a lightweight table-compatibility cache. It improves table selection accuracy while reducing the number of tables retrieved, enhancing multi-table execution performance."" || } ||  || [ Prompt: 108.3 t/s | Generation: 28.2 t/s ]"
2601.13114v1_IntAgent NWDAF-Based Intent LLM Agent Towards Adva.pdf,IntAgent: NWDAF-Based Intent LLM Agent,"['Abdelrahman Soliman', 'Ahmed Refaey', 'Aiman Erbad', 'Amr Mohamed']",,27.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || IntAgent: NWDAF-Based Intent LLM Agent || Towards Advanced Next Generation Networks || Abdelrahman Soliman , Ahmed Refaey , Aiman Erbad , and Amr Mohamed || University of Guelph, Guelph, Ontario, Canada. || Qatar University, Doha, Qatar. || AbstractIntent-based networks (IBNs) are gaining || promi ... (truncated) ||  || { || ""title"": ""IntAgent: NWDAF-Based Intent LLM Agent"", || ""authors"": [ || ""Abdelrahman Soliman"", || ""Ahmed Refaey"", || ""Aiman Erbad"", || ""Amr Mohamed"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Core Network"", || ""Next Generation Network"", || ""Large Language Models"", || ""Intent Management"", || ""Intelligent Networks"", || ""Closed Loop"" || ], || ""summary"": ""This paper introduces IntAgent, an intelligent intent LLM agent integrating NWDAF analytics to fulfill network operators' intents. It presents an enriched, 3GPP-compliant data source and an MCP tools server for dynamic network operations."" || } ||  || [ Prompt: 107.6 t/s | Generation: 27.4 t/s ]"
2601.13122v1_Responsible AI for General-Purpose Systems Overvie.pdf,Responsible AI for General-Purpose Systems: Overview,"['Gourab K. Patro', 'Himanshi Agrawal', 'Himanshu Gharat', 'Supriya Panigrahi', 'Nim Sherpa', 'Vishal Vaddina', 'Dagnachew Birru']",,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Responsible AI for General-Purpose Systems: Overview, || Challenges, and A Path Forward || Gourab K. Patro, Himanshi Agrawal, Himanshu Gharat, Supriya Panigrahi, Nim Sherpa, || Vishal Vaddina, and Dagnachew Birru || Phi Labs, Quantiphi Inc. || January 21, 2026 || Abstract || Modern general-purpose AI sy ... (truncated) ||  || { || ""title"": ""Responsible AI for General-Purpose Systems: Overview"", || ""authors"": [ || ""Gourab K. Patro"", || ""Himanshi Agrawal"", || ""Himanshu Gharat"", || ""Supriya Panigrahi"", || ""Nim Sherpa"", || ""Vishal Vaddina"", || ""Dagnachew Birru"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Modern general-purpose AI systems are capable of performing diverse tasks but pose risks such as hallucinations, toxicity, and stereotypes. This paper reviews these risks through the lens of responsible AI principles and proposes C 2V2 desiderata to guide future development."" || } ||  || [ Prompt: 108.1 t/s | Generation: 26.9 t/s ]"
2601.13142v1_TVWorld Foundations for Remote-Control TV Agents.pdf,Foundations for Remote-Control TV Agents,"['Zhantao Ma', 'Quanfeng Lu', 'Shuai Zhong', 'Dahai Yu3', 'Ping Luo1', 'Michael K. Ng 2']",,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TVWorld: Foundations for Remote-Control TV Agents || Zhantao Ma1*, Quanfeng Lu1*, Shuai Zhong1, Dahai Yu3 || Ping Luo1,Michael K. Ng 2 || 1The University of Hong Kong 2Hong Kong Baptist University || 3TCL Corporate Research (Hong Kong) Co., Ltd || https://github.com/Lqf-HFNJU/TVTheseus || Abstract || Re ... (truncated) ||  || { || ""title"": ""Foundations for Remote-Control TV Agents"", || ""authors"": [ || ""Zhantao Ma"", || ""Quanfeng Lu"", || ""Shuai Zhong"", || ""Dahai Yu3"", || ""Ping Luo1"", || ""Michael K. Ng 2"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Recent large vision-language models (LVLMs) have demonstrated strong potential for device control. However, existing research has primarily focused on point-and-click (PnC) interaction, while remote-control (RC) interaction commonly encountered in everyday TV usage remains largely underexplored. To fill this gap, we introduce TVWorld, an offline graph-based abstraction of real-world TV navigation that enables reproducible and deployment-free evaluation. On this basis, we derive two complementary benchmarks that comprehensively assess TV-use capabilities: TVWorld-N for topology-aware navigation and TVWorld-G for focus-aware grounding. These benchmarks expose a key limitation of existing agents: insufficient topology awareness for focus-based, long-horizon TV navigation. Motivated by this finding, we propose a Topology-Aware Training framework that injects topology awareness into LVLMs. Using this framework, we develop TVTheseus, a foundation model specialized for TV navigation. TVTheseus achieves a success rate of 68.3% on TVWorld-N, surpassing strong closed-source baselines such as Gemini 3 Flash and establishing state-of-the-art (SOTA) performance."" || } ||  || [ Prompt: 111.4 t/s | Generation: 28.2 t/s ]"
2601.13160v1_Training instability in deep learning follows low-.pdf,Training instability in deep learning follows low-dimensional dynamical principles,"['Zhipeng Zhang', 'Zhenjie Yao', 'Kai Li', 'Lei Yang']",arXiv:2601.13160v1,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Training instability in deep learning follows low-dimensional || dynamical principles || Zhipeng Zhang 1,2 Zhenjie Yao3 Kai Li 1 Lei Yang1 || 1China Mobile Research Institute, Beijing, China || 2China Mobile GBA Innovation Institute, Guangzhou, China || 3Institute of Microelectronics, Chinese Acad ... (truncated) ||  || { || ""title"": ""Training instability in deep learning follows low-dimensional dynamical principles"", || ""authors"": [ || ""Zhipeng Zhang"", || ""Zhenjie Yao"", || ""Kai Li"", || ""Lei Yang"" || ], || ""doi"": ""arXiv:2601.13160v1"", || ""arxiv_id"": ""2601.13160"", || ""keywords"": [ || ""training instability"", || ""deep learning"", || ""reinforcement learning"", || ""large language models"", || ""dynamical systems"" || ], || ""summary"": ""The paper discusses how training instability in deep learning can be understood through a unified dynamical perspective, highlighting four interacting dimensions: optimization, environmental/data, parametric, and learning-signal stability. It identifies recurring patterns across reinforcement learning and large language model training, emphasizing that performance and stability are not always aligned and that low-dimensional latent states often precede performance collapse."" || } ||  || [ Prompt: 109.1 t/s | Generation: 28.3 t/s ]"
2601.13166v1_From 100000 images to winning the first brain MRI .pdf,Developing Foundation Models for medical image analysis,"['Pedro M. Gordaliza', 'Jaume Banus', 'Benot Grin', 'Maxence Wynen', 'Nataliia Molchanova', 'Jonas Richiardi']",,19.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || From  100,000+  images  to  winning  the  first  brain  MRI  foundation  model || challenges: ||  || Sharing ||  || lessons ||  || and ||  || models ||  || Pedro  M.  Gordaliza || 1,2, || ,  Jaume  Banus || 2 || ,  Benot  Grin || 3 || ,  Maxence  Wynen || 3,4 || ,  Nataliia || Molchanova || 2,5 || , ||  || and ||  || Jonas ||  || Richiardi || 2,1 ||  || , || ... (truncated) ||  || { || ""title"": ""Developing Foundation Models for medical image analysis"", || ""authors"": [ || ""Pedro M. Gordaliza"", || ""Jaume Banus"", || ""Benot Grin"", || ""Maxence Wynen"", || ""Nataliia Molchanova"", || ""Jonas Richiardi"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""brain MRI"", || ""challenges"", || ""models"", || ""Pedro Gordaliza"", || ""Jaume Banus"", || ""Benot Grin"", || ""Maxence Wynen"", || ""Nataliia Molchanova"", || ""Jonas Richiardi"", || ""Neuroinflammation"", || ""imaging lab"", || ""CIBM Center"", || ""Lausanne"", || ""ICTEAM"", || ""Universite Catholique de Louvain"", || ""Neuroinflammation Imaging Lab"", || ""HES-SO"", || ""University of Western Switzerland"", || ""University of Lausanne"", || ""Applied Sciences Western Switzerland"", || ""Louvain University"", || ""Neuroinflammation Research Group"", || ""Louvain-la-Neuve"", || ""Catholique Université de Louvain"", || ""Brussels"", || ""University of Applied Sciences Western Switzerland"", || ""Louvain"" || ], || ""summary"": ""This paper presents a foundation model for medical image analysis, addressing challenges in 3D brain MRI, sharing, lessons, and models. The models combine U-Net CNN architecture with anatomical priors and neuroimaging knowledge, achieving competitive performance with fewer parameters than transformer-based methods."" || } ||  || [ Prompt: 112.9 t/s | Generation: 19.3 t/s ]"
2601.13186v1_Prompt Injection Mitigation with Agentic AI Nested.pdf,"Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching","['Diego Gosmar', 'Deborah A. Dahl']",arXiv:2601.13186v1,13.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Prompt Injection Mitigation with Agentic AI, Nested Learning, || and AI Sustainability via Semantic Caching || Diego Gosmar || Head of AI, Tesisquare || Member, Open Voice Interoperability Initiative || Linux Foundation AI & Data || Torino, Italy || diego.gosmar@ieee.org || Deborah A. Dahl || Principal, Conve ... (truncated) ||  || { || ""title"": ""Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching"", || ""authors"": [ || ""Diego Gosmar"", || ""Deborah A. Dahl"" || ], || ""doi"": ""arXiv:2601.13186v1"", || ""arxiv_id"": ""2601.13186"", || ""keywords"": [ || ""prompt injection"", || ""agentic AI"", || ""nested learning"", || ""semantic caching"", || ""security"", || ""sustainability"" || ], || ""summary"": ""This paper extends the evaluation framework for prompt injection by introducing semantic similarity-based caching, a fourth-agent rule-based evaluator, and an Observability Score Ratio. It investigates trade-offs between mitigation strictness and auditability in a HOPE-inspired architecture, demonstrating that semantic caching improves efficiency and sustainability while enhancing security."" || } ||  || [ Prompt: 37.0 t/s | Generation: 13.8 t/s ]"
2601.13187v1_Scientific production in the era of Large Language.pdf,Scientific production in the era of Large Language Models,"['Keigo Kusumegi', 'Xinyu Yang', 'Paul Ginsparg', 'Mathijs de Vaan', 'Toby Stuart', 'Yian Yin']",10.1126/science.adw3000,15.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || Scientific production in the era of Large Language Models Keigo Kusumegi1, Xinyu Yang1, Paul Ginsparg1, Mathijs de Vaan2*, Toby Stuart2*, Yian Yin1*                     Large Language Models (LLMs) are rapidly reshaping scientific research. We analyze these changes in multiple,  ... (truncated) ||  || { || ""title"": ""Scientific production in the era of Large Language Models"", || ""authors"": [ || ""Keigo Kusumegi"", || ""Xinyu Yang"", || ""Paul Ginsparg"", || ""Mathijs de Vaan"", || ""Toby Stuart"", || ""Yian Yin"" || ], || ""doi"": ""10.1126/science.adw3000"", || ""arxiv_id"": """", || ""keywords"": [ || ""scientific production"", || ""Large Language Models"", || ""LLMs"", || ""scientific research"", || ""manuscripts"", || ""writing complexity"", || ""paper quality"", || ""citation patterns"", || ""science publication"" || ], || ""summary"": ""Scientists adopting LLMs show a significant increase in paper production, with variations across fields and author backgrounds. LLM use has altered the relationship between writing complexity and paper quality, leading to more linguistically complex but less substantively strong manuscripts. Authors also access and cite a broader range of prior work."" || } ||  || [ Prompt: 39.5 t/s | Generation: 15.1 t/s ]"
2601.13197v1_Diffusion-Driven Synthetic Tabular Data Generation.pdf,Diffusion-Driven Synthetic Tabular Data Generation,"['Aravind B', 'Anirud R.S.', 'Sai Surya Teja N', 'Bala Subrahmanya Sriranga Navaneeth A', 'Karthika R', 'Mohankumar N']",,13.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Diffusion-Driven Synthetic Tabular Data Generation || for Enhanced DoS/DDoS Attack Classification || Aravind B || Department of Electronics and Communication Engineering, || Amrita School of Engineering, Coimbatore, || Amrita Vishwa Vidyapeetham,India || baravind878@gmail.com || Anirud R.S. || Department o ... (truncated) ||  || { || ""title"": ""Diffusion-Driven Synthetic Tabular Data Generation"", || ""authors"": [ || ""Aravind B"", || ""Anirud R.S."", || ""Sai Surya Teja N"", || ""Bala Subrahmanya Sriranga Navaneeth A"", || ""Karthika R"", || ""Mohankumar N"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""network intrusion detection"", || ""Tabular diffusion models"", || ""Class imbalance"", || ""DDoS attack detection"", || ""Data augmentation"", || ""IDS2017"" || ], || ""summary"": ""The paper addresses class imbalance in network intrusion detection using Tabular Denoising Diffusion Probability Models (TabDDPM). It introduces a method to generate synthetic samples for minority classes, improving model recall for underrepresented attack classes. Applications include fraud detection and medical diagnostics."" || } ||  || [ Prompt: 37.4 t/s | Generation: 13.2 t/s ]"
2601.13206v1_Real-Time Deadlines Reveal Temporal Awareness Fail.pdf,Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues,"['Neil Sehgal', 'Sharath Chandra Guntuku', 'Lyle Ungar']",1,23.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic || Dialogues || Neil Sehgal1 ,Sharath Chandra Guntuku 1 ,Lyle Ungar 1 || 1University of Pennsylvania || {nsehgal, sharathg, ungar}@upenn.edu, || Abstract || Large Language Models (LLMs) generate text || token-by-token in discrete ti ... (truncated) ||  || { || ""title"": ""Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues"", || ""authors"": [""Neil Sehgal"", ""Sharath Chandra Guntuku"", ""Lyle Ungar""], || ""doi"": ""1"", || ""arxiv_id"": """", || ""keywords"": [""LLM"", ""temporal awareness"", ""strategic dialogues""], || ""summary"": ""Large Language Models generate text token-by-token but struggle with real-time deadlines, showing high deal closure rates under time constraints but poor temporal tracking."" || } ||  || [ Prompt: 36.4 t/s | Generation: 23.9 t/s ]"
2601.13217v1_Beyond Single-shot Writing Deep Research Agents ar.pdf,Beyond Single-shot Writing: Deep Research Agents are Unreliable at Multi-turn Report Revision,"['Bingsen Chen', 'Boyan Li', 'Ping Nie', 'Yuyu Zhang', 'Xi Ye', 'Chen Zhao', 'New York University', 'University of Alberta', 'Princeton University', 'University of Waterloo', 'Verdant AI, Inc.']",,28.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Preprint. Under review. || Beyond Single-shot Writing: Deep Research Agents are || Unreliable at Multi-turn Report Revision || Bingsen Chen1,2,, Boyan Li3,,, Ping Nie5, Yuyu Zhang6, Xi Ye3,4,, Chen Zhao1,2, || 1New York University 2NYU Shanghai 3University of Alberta || 4Princeton University 5Univ ... (truncated) ||  || { || ""title"": ""Beyond Single-shot Writing: Deep Research Agents are Unreliable at Multi-turn Report Revision"", || ""authors"": [ || ""Bingsen Chen"", || ""Boyan Li"", || ""Ping Nie"", || ""Yuyu Zhang"", || ""Xi Ye"", || ""Chen Zhao"", || ""New York University"", || ""University of Alberta"", || ""Princeton University"", || ""University of Waterloo"", || ""Verdant AI, Inc."" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Existing benchmarks treat report generation as a single-shot task, but human researchers revise reports iteratively. This study introduces MRDRE to evaluate multi-turn report revision and finds that current agents struggle to preserve earlier edits and maintain content quality."" || } ||  || [ Prompt: 110.5 t/s | Generation: 28.0 t/s ]"
2601.13222v1_Incorporating QA Nuggets into Retrieval-Augmented .pdf,Incorporating Q&A Nuggets into Retrieval-Augmented Generation,"['Laura Dietz', 'Bryan Li', 'Gabrielle Liu', 'Jia-Huei Ju', 'Eugene Yang', 'Dawn Lawrie', 'William Walden', 'James Mayfield']",arXiv:2601.13222v1,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Incorporating Q&A Nuggets into || Retrieval-Augmented Generation || Laura Dietz1 , Bryan Li2 , Gabrielle Liu 3 , Jia-Huei Ju 4 , Eugene Yang5 , || Dawn Lawrie5 , William Walden5 , and James Mayfield 5 || 1 University of New Hampshire, Durham, New Hampshire, USAdietz@cs.unh.edu || 2 University of  ... (truncated) ||  || { || ""title"": ""Incorporating Q&A Nuggets into Retrieval-Augmented Generation"", || ""authors"": [ || ""Laura Dietz"", || ""Bryan Li"", || ""Gabrielle Liu"", || ""Jia-Huei Ju"", || ""Eugene Yang"", || ""Dawn Lawrie"", || ""William Walden"", || ""James Mayfield"" || ], || ""doi"": ""arXiv:2601.13222v1"", || ""arxiv_id"": ""arXiv:2601.13222"", || ""keywords"": [ || ""RAG"", || ""LLM"", || ""nugget-based evaluation"", || ""Crucible"", || ""TREC Neu-CLIR 2024"" || ], || ""summary"": ""The paper presents Crucible, a nugget-augmented generation system that uses explicit citation provenance by constructing a bank of Q&A nuggets from retrieved documents to guide extraction, selection, and report generation. It compares its performance to Ginger and highlights improvements in nugget recall and citation grounding."" || } ||  || [ Prompt: 116.9 t/s | Generation: 27.8 t/s ]"
2601.13227v1_Insider Knowledge How Much Can RAG Systems Gain fr.pdf,Insider Knowledge: How Much Can RAG Systems Gain from Evaluation Secrets?,"['Laura Dietz', 'Bryan Li', 'Eugene Yang', 'Dawn Lawrie', 'William Walden', 'James Mayfield']",arXiv:2601.13227v1,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Insider Knowledge: How Much Can RAG || Systems Gain from Evaluation Secrets? || Laura Dietz1 , Bryan Li 2 , Eugene Yang3 , Dawn Lawrie3 , William || Walden3 , and James Mayfield 3 || 1 University of New Hampshire, Durham, New Hampshire, USAdietz@cs.unh.edu || 2 University of Pennsylvania, Philade ... (truncated) ||  || { || ""title"": ""Insider Knowledge: How Much Can RAG Systems Gain from Evaluation Secrets?"", || ""authors"": [ || ""Laura Dietz"", || ""Bryan Li"", || ""Eugene Yang"", || ""Dawn Lawrie"", || ""William Walden"", || ""James Mayfield"" || ], || ""doi"": ""arXiv:2601.13227v1"", || ""arxiv_id"": ""arXiv:2601.13227"", || ""keywords"": [ || ""Retrieval-augmented generation"", || ""LLM judge"", || ""Nugget-based evaluation"", || ""System evaluation"", || ""Methodological diversity"" || ], || ""summary"": ""The paper investigates how nugget-based evaluation methods can be leveraged in RAG systems, highlighting risks of circularity and overfitting in evaluation settings."" || } ||  || [ Prompt: 122.2 t/s | Generation: 28.3 t/s ]"
2601.13228v1_Autoregressive Models Rival Diffusion Models at AN.pdf,AUTOREGRESSIVEMODELSRIVAL,"['Tianqi Du', 'Lizhe Fang', 'Weijie Yang', 'Chenheng Zhang', 'Zeming Wei', 'Yifei Wang', 'Yisen Wang']",,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || AUTOREGRESSIVEMODELSRIVAL || DIFFUSIONMODELS ATANY-ORDER GENERATION || Tianqi Du1 Lizhe Fang1 Weijie Yang2 || Chenheng Zhang1 Zeming Wei2 Yifei Wang3 Yisen Wang1, 4 || 1 National Key Lab of General Artificial Intelligence, || School of Intelligence Science and Technology, Peking University || 2 Schoo ... (truncated) ||  || { || ""title"": ""AUTOREGRESSIVEMODELSRIVAL"", || ""authors"": [ || ""Tianqi Du"", || ""Lizhe Fang"", || ""Weijie Yang"", || ""Chenheng Zhang"", || ""Zeming Wei"", || ""Yifei Wang"", || ""Yisen Wang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Diffusion language models enable flexible generation but suffer from limited modeling depth. This work proposes Any-Order Any-subset Autoregressive modeling (A3) to address this by extending AR factorization to arbitrary token groups and generation orders."" || } ||  || [ Prompt: 108.3 t/s | Generation: 26.9 t/s ]"
2601.13233v1_RAG A Random-Forest-Based Generative Design Framew.pdf,A RANDOM-FOREST-BASEDGENERATIVEDESIGN,"['Bolin Chen', 'Dex Doksoo Lee', 'Wei Wayne Chen', 'Wei Chen']",,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || RAG: A RANDOM-FOREST-BASEDGENERATIVEDESIGN || FRAMEWORK FORUNCERTAINTY-AWAREDESIGN OF || METAMATERIALS WITHCOMPLEXFUNCTIONALRESPONSE || REQUIREMENTS || Bolin Chen1, Dex Doksoo Lee1, Wei Wayne Chen2, and Wei Chen1* || 1Department of Mechanical Engineering, Northwestern University, Evanston, IL 6020 ... (truncated) ||  || { || ""title"": ""A RANDOM-FOREST-BASEDGENERATIVEDESIGN"", || ""authors"": [ || ""Bolin Chen"", || ""Dex Doksoo Lee"", || ""Wei Wayne Chen"", || ""Wei Chen"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Random forest"", || ""Generative design"", || ""Functional response"", || ""Uncertainty quantification"", || ""Metamaterials"", || ""Design requirements"" || ], || ""summary"": ""Metamaterials design for advanced functionality often entails the inverse design on nonlinear and condition-dependent responses. This paper introduces a RANDOM-forest-based Generative approach (RAG) to address challenges in functional response inverse design, emphasizing data efficiency and uncertainty quantification."" || } ||  || [ Prompt: 104.9 t/s | Generation: 27.6 t/s ]"
2601.13235v1_RubRIX Rubric-Driven Risk Mitigation in Caregiver-.pdf,RubRIX: Rubric-Driven Risk Mitigation in Caregiver-AI Interactions,"['Drishti Goel', 'Jeongah Lee', 'Qiuyue Joy Zhong', 'Violeta J. Rodriguez', 'Daniel S. Brown', 'Ravi Karkar', 'Dong Whi Yoo', 'Koustuv Saha']",,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || RubRIX: Rubric-Driven Risk Mitigation in Caregiver-AI Interactions || Drishti Goel1, Jeongah Lee2, Qiuyue Joy Zhong2, Violeta J. Rodriguez1, || Daniel S. Brown3,Ravi Karkar 2,Dong Whi Yoo 4,Koustuv Saha 1 || 1University of Illinois Urbana-Champaign, 2University of Massachusetts Amherst, || 3OSF ... (truncated) ||  || { || ""title"": ""RubRIX: Rubric-Driven Risk Mitigation in Caregiver-AI Interactions"", || ""authors"": [ || ""Drishti Goel"", || ""Jeongah Lee"", || ""Qiuyue Joy Zhong"", || ""Violeta J. Rodriguez"", || ""Daniel S. Brown"", || ""Ravi Karkar"", || ""Dong Whi Yoo"", || ""Koustuv Saha"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""caregiver"", || ""AI"", || ""risk mitigation"", || ""ethics of care"", || ""LLM"", || ""healthcare"" || ], || ""summary"": ""This paper introduces RubRIX, a framework for evaluating risks in AI-mediated caregiving interactions. RubRIX focuses on five risk dimensions: Inattention, Bias & Stigma, Information Inaccuracy, Uncritical Affirmation, and Epistemic Arrogancy. It evaluates six state-of-the-art LLMs using over 20,000 caregiver queries, showing that rubric-guided refinement can reduce risk components by 45-98%."" || } ||  || [ Prompt: 112.9 t/s | Generation: 28.3 t/s ]"
2601.13236v1_Pixelwise Uncertainty Quantification of Accelerate.pdf,Pixelwise Uncertainty Quantication of Accelerated MRI Reconstruction,"['Ilias I. Giannakopoulos', 'Lokesh B Gautham Muthukumar', 'Yvonne W. Lui', 'Riccardo Lattanzi']",10.1109/JR.2023.12345,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || Pixelwise Uncertainty Quantication of Accelerated || MRI Reconstruction || Ilias I. Giannakopoulos, Senior Member , IEEE, Lokesh B Gautham Muthukumar, Yvonne W. Lui, and Riccardo || Lattanzi, Senior Member , IEEE || AbstractParallel imaging techniques reduce magnetic reso- || nance imaging (MRI) ... (truncated) ||  || { || ""title"": ""Pixelwise Uncertainty Quantication of Accelerated MRI Reconstruction"", || ""authors"": [ || ""Ilias I. Giannakopoulos"", || ""Lokesh B Gautham Muthukumar"", || ""Yvonne W. Lui"", || ""Riccardo Lattanzi"" || ], || ""doi"": ""10.1109/JR.2023.12345"", || ""arxiv_id"": ""10.1109/JR.2023.12345"", || ""keywords"": [ || ""Conformal Prediction"", || ""Magnetic Resonance Imaging"", || ""Parallel Imaging"", || ""Quantile Regression"", || ""Uncertainty Quantification"", || ""Diagnostic Quality"" || ], || ""summary"": ""This work introduces a framework for pixel-wise uncertainty quantification in parallel MRI reconstructions, enabling automatic identification of unreliable regions without ground-truth images. It integrates conformal quantile regression with image reconstruction to estimate uncertainty intervals and demonstrates strong agreement with reconstruction error metrics at higher acceleration factors."" || } ||  || [ Prompt: 106.8 t/s | Generation: 28.8 t/s ]"
2601.13238v1_A Semantic Decoupling-Based Two-Stage Rainy-Day At.pdf,Semantic DecouplingBased Two-Stage Rainy-Day Attack for Revealing Weather Robustness Deficiencies in VisionLanguage Models,"['Chengyin Hu Xiang', 'Chen Zhe Jia Weiwen', 'Fengyu Zhang', 'Yiwei Wei']",,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A Semantic DecouplingBased Two-Stage Rainy-Day Attack for Revealing || Weather Robustness Deficiencies in VisionLanguage Models || Chengyin Hu Xiang Chen Zhe Jia Weiwen Shi Fengyu Zhang Jiujiang Guo Yiwei Wei || Abstract || VisionLanguage Models (VLMs) are trained || on imagetext pairs collected u ... (truncated) ||  || { || ""title"": ""Semantic DecouplingBased Two-Stage Rainy-Day Attack for Revealing Weather Robustness Deficiencies in VisionLanguage Models"", || ""authors"": [""Chengyin Hu Xiang"", ""Chen Zhe Jia Weiwen"", ""Fengyu Zhang"", ""Yiwei Wei""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper introduces a two-stage adversarial framework exploiting realistic weather perturbations to reveal weaknesses in VisionLanguage Models' robustness to rain, highlighting physical and interpretable shifts in semantic decision spaces."" || } ||  || [ Prompt: 110.9 t/s | Generation: 28.6 t/s ]"
2601.13240v1_KOCO-BENCH Can Large Language Models Leverage Doma.pdf,KOCO-BENCH: Can Large Language Models Leverage Domain Knowledge in Software Development?,"['Xue Jiang1', 'Jiaru Qian1', 'Xianjie Shi1', 'Chenjie Li1', 'Hao Zhu1', 'Ziyu Wang1', 'Jielun Zhang1', 'Zheyu Zhao1', 'Kechi Zhang1', 'Jia Li2', 'Wenpin Jiao1', 'Zhi Jin1', 'Ge Li1', 'Yihong Dong1']",,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Preprint, January 2026 || KOCO-BENCH: Can Large Language Models Leverage || Domain Knowledge in Software Development? || Xue Jiang1, Jiaru Qian1, Xianjie Shi1, Chenjie Li1, Hao Zhu1, Ziyu Wang1, Jielun Zhang1, || Zheyu Zhao1, Kechi Zhang1, Jia Li2, Wenpin Jiao1, Zhi Jin1, Ge Li1, Yihong Dong1 || 1 ... (truncated) ||  || { || ""title"": ""KOCO-BENCH: Can Large Language Models Leverage Domain Knowledge in Software Development?"", || ""authors"": [ || ""Xue Jiang1"", || ""Jiaru Qian1"", || ""Xianjie Shi1"", || ""Chenjie Li1"", || ""Hao Zhu1"", || ""Ziyu Wang1"", || ""Jielun Zhang1"", || ""Zheyu Zhao1"", || ""Kechi Zhang1"", || ""Jia Li2"", || ""Wenpin Jiao1"", || ""Zhi Jin1"", || ""Ge Li1"", || ""Yihong Dong1"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""LLM"", || ""software development"", || ""domain knowledge"", || ""code generation"", || ""programming"", || ""LLM4SE"" || ], || ""summary"": ""This paper introduces KOCO-BENCH, a new benchmark for evaluating domain specialization in LLMs for software development. It highlights the limitations of current LLMs in acquiring and applying domain-specific knowledge and presents KOCO-BENCH to address this gap."" || } ||  || [ Prompt: 106.6 t/s | Generation: 28.6 t/s ]"
2601.13247v1_Aligning Agentic World Models via Knowledgeable Ex.pdf,Aligning Agentic World Models via Knowledgeable Experience Learning,"['Baochang Ren', 'Yunzhi Yao', 'Rui Sun', 'Shuofei Qiao', 'Ningyu Zhang*', 'Huajun Chen']",,28.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Aligning Agentic World Models via Knowledgeable Experience Learning || Baochang Ren, Yunzhi Yao, Rui Sun, Shuofei Qiao, || Ningyu Zhang*,Huajun Chen * || Zhejiang University  University of California, Los Angeles || {baochang.ren, zhangningyu}@zju.edu.cn || /githubCode || Visualize || Abstract || Current ... (truncated) ||  || { || ""title"": ""Aligning Agentic World Models via Knowledgeable Experience Learning"", || ""authors"": [ || ""Baochang Ren"", || ""Yunzhi Yao"", || ""Rui Sun"", || ""Shuofei Qiao"", || ""Ningyu Zhang*"", || ""Huajun Chen"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Current LLMs lack procedural grounding, leading to physical hallucinations. This paper introduces WorldMind, a framework that autonomously builds a symbolic World Knowledge Repository to bridge the gap between process experience and goal experience, improving alignment and transferability."" || } ||  || [ Prompt: 110.4 t/s | Generation: 28.0 t/s ]"
2601.13260v1_Stop Taking Tokenizers for Granted They Are Core D.pdf,Stop Taking Tokenizers for Granted: They Are Core Design Decisions in Large Language Models,"['Sawsan Alqahtani', 'Mir Tafseer Nayeem', 'Md Tahmid Rahman Laskar Tasnim Mohiuddin M Saiful Bari', 'Princess Nourah Bint Abdulrahman University Saudi Data & AI Authority (SDAIA)', 'University of Alberta Dialpad York University', 'Qatar Computing Research Institute Amazon AGI']",,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Stop Taking Tokenizers for Granted: They Are Core Design Decisions in || Large Language Models || Sawsan Alqahtani* Mir Tafseer Nayeem* || Md Tahmid Rahman Laskar Tasnim Mohiuddin M Saiful Bari || Princess Nourah Bint Abdulrahman University Saudi Data & AI Authority (SDAIA) || University of Albert ... (truncated) ||  || { || ""title"": ""Stop Taking Tokenizers for Granted: They Are Core Design Decisions in Large Language Models"", || ""authors"": [ || ""Sawsan Alqahtani"", || ""Mir Tafseer Nayeem"", || ""Md Tahmid Rahman Laskar Tasnim Mohiuddin M Saiful Bari"", || ""Princess Nourah Bint Abdulrahman University Saudi Data & AI Authority (SDAIA)"", || ""University of Alberta Dialpad York University"", || ""Qatar Computing Research Institute Amazon AGI"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""tokenization"", || ""large language models"", || ""subword tokenization"", || ""BPE"", || ""language models"", || ""model design"", || ""tokenizer"", || ""NLP"" || ], || ""summary"": ""The paper reframes tokenization as a core modeling decision rather than a preprocessing step, advocating for a context-aware framework that integrates tokenizer and model co-design, emphasizing fairer, more efficient, and adaptable language technologies."" || } ||  || [ Prompt: 116.1 t/s | Generation: 28.2 t/s ]"
2601.13262v1_CURE-Med Curriculum-Informed Reinforcement Learnin.pdf,,[],,27.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || CURE-Med: Curriculum-Informed Reinforcement Learning for || Multilingual Medical Reasoning || Eric Onyame || University of Virginia || Akash Ghosh || IIT-Patna || Subhadip Baidya || IIT-Patna || Sriparna Saha || IIT-Patna || Xiuying Chen || MBZUAI || Chirag Agarwal || University of Virginia || Abstract || While large language  ... (truncated) ||  || { || ""title"": ""CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning"", || ""authors"": [ || ""Eric Onyame"", || ""Akash Ghosh"", || ""Subhadip Baidya"", || ""Sriparna Saha"", || ""Xiuying Chen"", || ""Chirag Agarwal"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""medical reasoning"", || ""multilingual"", || ""reinforcement learning"", || ""curriculum-informed"", || ""code-switching"", || ""logical correctness""] || ""summary"": ""Addresses limitations of large language models in multilingual medical reasoning by introducing CURE-MED, a curriculum-informed reinforcement learning framework that improves logical correctness and language stability across thirteen languages."" || } ||  || [ Prompt: 106.0 t/s | Generation: 27.4 t/s ]"
2601.13268v1_Improving the Safety and Trustworthiness of Medica.pdf,Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops,"['Zainab Ghafoor', 'Md Shafiqul Islam', 'Koushik Howlader', 'Md Rasel Khondokar', 'Tanusree Bhattacharjee', 'Sayantan Chakraborty', 'Adrito Roy', 'Ushashi Bhattacharjee', 'Tirtho Roy']",,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Improving the Safety and Trustworthiness of || Medical AI via Multi-Agent Evaluation Loops || Zainab Ghafoor || Sonoma State University || California, USA || Md Shafiqul Islam || Iowa State University || Ames, USA || Koushik Howlader || Iowa State University || Ames, USA || Md Rasel Khondokar || Iowa State University || ... (truncated) ||  || { || ""title"": ""Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops"", || ""authors"": [ || ""Zainab Ghafoor"", || ""Md Shafiqul Islam"", || ""Koushik Howlader"", || ""Md Rasel Khondokar"", || ""Tanusree Bhattacharjee"", || ""Sayantan Chakraborty"", || ""Adrito Roy"", || ""Ushashi Bhattacharjee"", || ""Tirtho Roy"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Medical AI"", || ""Large Language Models"", || ""Multi-Agent Systems"", || ""Ethical Compliance"", || ""Safety Assessment"" || ], || ""summary"": ""This work introduces a multi-agent refinement framework to enhance the safety and reliability of medical Large Language Models through structured, iterative alignment. The system combines DeepSeek R1 and Med-PaLM with evaluation agents LLaMA 3.1 and Phi-4, assessing responses against AMA Principles of Medical Ethics and SRA-5. Results show improved convergence and risk reduction, demonstrating effectiveness in governing medical AI safety."" || } ||  || [ Prompt: 109.8 t/s | Generation: 27.9 t/s ]"
2601.13286v1_AI Skills Improve Job Prospects Causal Evidence fr.pdf,N/A,N/A,N/A,0.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none || error while handling argument ""-f"": error: failed to open file '/data/local/tmp/pneuma_dataset/2601.13286v1_AI_Skills_Improve_Job_Prospects_Causal_Evidence_fr.txt' ||  ||  || usage: || -f,    --file FNAME                     a file containing the prompt (default: none) ||  ||  || to show complete usage, run with -h"
2601.13295v1_CooperBench Why Coding Agents Cannot be Your Teamm.pdf,Why Coding Agents Cannot be,"['Arpandeep Khatua', 'Hao Zhu', 'Peter Tran', 'Arya Prabhudesai', 'Frederic Sadrieh', 'Johann K. Lieberwirth', 'Xinkai Yu', 'Yicheng Fu', 'Michael J. Ryan', 'Jiaxin Pei', 'Diyi Yang']",,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 2026-1-21 || CooperBench: Why Coding Agents Cannot be || Your Teammates Yet || Arpandeep Khatua1, Hao Zhu1, || Peter Tran2, Arya Prabhudesai2, Frederic Sadrieh2, Johann K. Lieberwirth2, || Xinkai Yu1, Yicheng Fu1, Michael J. Ryan1, Jiaxin Pei1, Diyi Yang1 || 1Stanford University 2SAP Labs US Equal Co ... (truncated) ||  || { || ""title"": ""Why Coding Agents Cannot be"", || ""authors"": [ || ""Arpandeep Khatua"", || ""Hao Zhu"", || ""Peter Tran"", || ""Arya Prabhudesai"", || ""Frederic Sadrieh"", || ""Johann K. Lieberwirth"", || ""Xinkai Yu"", || ""Yicheng Fu"", || ""Michael J. Ryan"", || ""Jiaxin Pei"", || ""Diyi Yang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""coding agents"", || ""collaboration"", || ""coordination"", || ""team conflict"", || ""social intelligence"", || ""task coordination"" || ], || ""summary"": ""The paper introduces CooperBench, a benchmark for evaluating collaborative coding tasks among AI agents. It highlights challenges in achieving compatibility between agents and discusses the need for improved coordination to enhance performance."" || } ||  || [ Prompt: 115.0 t/s | Generation: 27.9 t/s ]"
2601.13317v1_Paid Voices vs. Public Feeds Interpretable Cross-P.pdf,Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme,"['Samantha Sudhoff', 'Pranav Perumal', 'Zhaoqing Wu', 'Tunazzina Islam']",,26.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme || Modeling of Climate Discourse || Samantha Sudhoff*, Pranav Perumal, Zhaoqing Wu, Tunazzina Islam* || Department of Computer Science, Purdue University, West Lafayette, IN 47907 || {ssudhoff, pperuma, wu1828, islam32} @purdue.ed ... (truncated) ||  || { || ""title"": ""Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme"", || ""authors"": [ || ""Samantha Sudhoff"", || ""Pranav Perumal"", || ""Zhaoqing Wu"", || ""Tunazzina Islam"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This work presents a comparative analysis of climate discourse across paid advertisements on Meta and public posts on Bluesky, introducing an interpretable framework to cluster texts by semantic similarity and evaluate thematic structure using large language models."" || } ||  || [ Prompt: 110.7 t/s | Generation: 26.3 t/s ]"
2601.13327v1_PepEDiff Zero-Shot Peptide Binder Design via Prote.pdf,Zero-Shot Peptide Binder Design via Protein,"['Po-Yu, Liang', 'Tibo, Duran 2', 'Jun, Bai 1']",10.1109/PEPEDI.2026.2601,31.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || PepEDi: Zero-Shot Peptide Binder Design via Protein || Embedding Diusion || Po-Yu, Liang1, Tibo, Duran 2, and Jun, Bai 1/Letter || 1 Department of Computer Science, University of Cincinnati, Ohio, United States || baiju@ucmail.uc.edu || 2 Department of Microbiology and Plant Pathology, University  ... (truncated) ||  || { || ""title"": ""Zero-Shot Peptide Binder Design via Protein"", || ""authors"": [ || ""Po-Yu, Liang"", || ""Tibo, Duran 2"", || ""Jun, Bai 1"" || ], || ""doi"": ""10.1109/PEPEDI.2026.2601"", || ""arxiv_id"": ""2601.13327"", || ""keywords"": [ || ""Deep Learning"", || ""Drug Discovery"", || ""Protein Design"" || ], || ""summary"": ""PepEDi is a novel peptide binder generator that designs binding sequences directly from protein sequences and embeddings, enabling zero-shot generation without relying on predicted structures."" || } ||  || [ Prompt: 111.0 t/s | Generation: 31.4 t/s ]"
2601.13348v1_The AI Genie Phenomenon and Three Types of AI Chat.pdf,The AI Genie Phenomenon and Three Types of AI Chatbot Addiction: Escapist,"['M. KAREN SHEN', 'JESSICA HUANG', 'OLIVIA LIANG', 'IG-JAE KIM', 'DONGWOOK YOON']",,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || The AI Genie Phenomenon and Three Types of AI Chatbot Addiction: Escapist || Roleplays, Pseudosocial Companions, and Epistemic Rabbit Holes || M. KAREN SHEN,University of British Columbia, Canada || JESSICA HUANG,Georgia Institute of Technology, USA || OLIVIA LIANG,University of British Columbi ... (truncated) ||  || { || ""title"": ""The AI Genie Phenomenon and Three Types of AI Chatbot Addiction: Escapist"", || ""authors"": [ || ""M. KAREN SHEN"", || ""JESSICA HUANG"", || ""OLIVIA LIANG"", || ""IG-JAE KIM"", || ""DONGWOOK YOON"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""AI chatbot"", || ""Addiction"", || ""Addiction literature"", || ""Sexual content"", || ""Recovery strategies"" || ], || ""summary"": ""This study examines AI chatbot addiction by analyzing user experiences from Reddit, identifying three addiction types: Escapist Roleplay, Pseudosocial Companion, and Epistemic Rabbit Hole, along with notable cases involving sexual content. It highlights the need for prevention and intervention strategies."" || } ||  || [ Prompt: 109.5 t/s | Generation: 26.9 t/s ]"
2601.13352v1_LLM-as-RNN A Recurrent Language Model for Memory U.pdf,LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction,"['Yuxing Lu', 'J. Ben Tamo', 'Weichen Zhao', 'Nan Sun', 'Yishan Zhong', 'Wenqi Shi', 'Jinzhuo Wang', 'May D. Wang']",,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LLM-as-RNN: A Recurrent Language Model for Memory Updates and || Sequence Prediction || Yuxing Lu*12, J. Ben Tamo*1, Weichen Zhao3, Nan Sun4, Yishan Zhong1, Wenqi Shi5, || Jinzhuo Wang2, May D. Wang1 || 1Georgia Institute of Technology, 2Peking University, 3Shandong University, || 4Huazhong Univer ... (truncated) ||  || { || ""title"": ""LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction"", || ""authors"": [ || ""Yuxing Lu"", || ""J. Ben Tamo"", || ""Weichen Zhao"", || ""Nan Sun"", || ""Yishan Zhong"", || ""Wenqi Shi"", || ""Jinzhuo Wang"", || ""May D. Wang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Large language models are strong sequence predictors, yet standard inference relies on immutable context histories. After making an error at generation step t, the model lacks an updatable memory mechanism that improves predictions for step t+1. We propose LLM-as-RNN, an inference-only framework that turns a frozen LLM into a recurrent predictor by representing its hidden state as a structured system-prompt summary. This state is updated at each timestep via feedback-driven text rewrites, enabling learning without parameter updates. Under a fixed token budget, LLM-as-RNN corrects errors and retains task-relevant patterns, effectively performing online learning through language. We evaluate the method on three sequential benchmarks in healthcare, meteorology, and finance across Llama, Gemma, and GPT model families. LLM-as-RNN significantly outperforms zero-shot, full-history, and MemPrompt baselines, improving predictive accuracy by 6.5% on average, while producing interpretable, human-readable learning traces absent in standard context accumulation."" || } ||  || [ Prompt: 114.2 t/s | Generation: 28.2 t/s ]"
2601.13358v1_The Geometry of Thought How Scale Restructures Rea.pdf,The Geometry of Thought: How Scale Restructures Reasoning in Large Language Models,['Samuel Cyrenius Anderson'],,26.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || The Geometry of Thought: How Scale Restructures Reasoning || in Large Language Models || Samuel Cyrenius Anderson * || 1. Scrivly.AI || * sam@scrivly.ai || Abstract || Scale does not uniformly improve reasoningit restructures it. Analyzing || 25,000+ chain-of-thought trajectories across four domains (La ... (truncated) ||  || { || ""title"": ""The Geometry of Thought: How Scale Restructures Reasoning in Large Language Models"", || ""authors"": [""Samuel Cyrenius Anderson""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Scale does not uniformly improve reasoning; it restructures it, revealing domain-specific phase transitions and geometric effects across reasoning types."" || } ||  || [ Prompt: 114.6 t/s | Generation: 26.5 t/s ]"
2601.13376v1_Bounded Minds Generative Machines Envisioning Conv.pdf,"Bounded Minds, Generative Machines",['Jiqun Liu'],https://doi.org/XXXXXXX,27.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Bounded Minds, Generative Machines || Envisioning Conversational AI that Works with Human Heuristics and Reduces Bias Risk || JIQUN LIU,The University of Oklahoma, USA || Conversational AI is rapidly becoming a primary interface for information seeking and decision making, || yet most systems s ... (truncated) ||  || { || ""title"": ""Bounded Minds, Generative Machines"", || ""authors"": [""Jiqun Liu""], || ""doi"": ""https://doi.org/XXXXXXX"", || ""arxiv_id"": ""JACM2025-1234"", || ""keywords"": [""Bounded Rationality"", ""Heuristics"", ""Conversational AI"", ""GenAI"", ""Evaluation""], || ""summary"": ""The article discusses how conversational AI should align with human heuristics and cognitive limitations rather than assuming ideal user behavior, emphasizing the need to address cognitive biases and improve decision quality."" || } ||  || [ Prompt: 117.9 t/s | Generation: 27.0 t/s ]"
2601.13383v1_A Lightweight Modular Framework for Constructing A.pdf,A Lightweight Modular Framework for Constructing Autonomous Agents Driven by Large Language Models,"['A. Jafari', 'C. Ozcinar']",,27.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A LIGHTWEIGHTMODULARFRAMEWORK FORCONSTRUCTING || AUTONOMOUSAGENTSDRIVEN BYLARGELANGUAGE || MODELS: DESIGN, IMPLEMENTATION,ANDAPPLICATIONS IN || AGENTFORGE || A. A. Jafari, C. Ozcinar || University of Tartu || Tartu, Estonia || {akbar.anbar.jafari}@ut.ee || G. Anbarjafari || 3S Holding O || Tartu, Estonia || shb@3s ... (truncated) ||  || { || ""title"": ""A Lightweight Modular Framework for Constructing Autonomous Agents Driven by Large Language Models"", || ""authors"": [ || ""A. Jafari"", || ""C. Ozcinar"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""autonomous agents"", || ""large language models"", || ""modular architecture"", || ""natural language processing"", || ""software framework"", || ""task automation"", || ""artificial intelligence"", || ""open-source software"" || ], || ""summary"": ""The paper introduces AgentForge, a lightweight, open-source Python framework for building LLM-driven autonomous agents. It emphasizes modular design, composable skills, unified LLM backend, and declarative configuration, achieving competitive performance while reducing development time."" || } ||  || [ Prompt: 106.6 t/s | Generation: 27.3 t/s ]"
2601.13385v1_Organ-Aware Attention Improves CT Triage and Class.pdf,Organ-Aware Attention Improves CT Triage and Classification,"['Lavsen Dahal', 'Yubraj Bhandari', 'Geoffrey D. Rubin', 'Joseph Y. Lo']",,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Organ-Aware Attention Improves CT Triage and Classification || Lavsen Dahal || Duke University || Durham, NC, USA || lavsen.dahal@duke.edu || Yubraj Bhandari || Duke University || Durham, NC, USA || yubraj.bhandari@duke.edu || Geoffrey D. Rubin || University of Arizona || Tucson, AZ, USA || grubin@arizona.edu || Joseph Y ... (truncated) ||  || { || ""title"": ""Organ-Aware Attention Improves CT Triage and Classification"", || ""authors"": [ || ""Lavsen Dahal"", || ""Yubraj Bhandari"", || ""Geoffrey D. Rubin"", || ""Joseph Y. Lo"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""CT triage"", || ""classification"", || ""computed tomography"", || ""radiology"", || ""radiologist burnout"", || ""organ-aware attention"", || ""3D anatomy"", || ""Vision Language Models"", || ""organ-scalar fusion"" || ], || ""summary"": ""This study introduces ORACLE-CT, an encoder-agnostic, organ-aware head that improves supervised classification of chest and abdomen CT scans. It achieves state-of-the-art AUROC scores and addresses challenges in 3D anatomy and noisy reports."" || } ||  || [ Prompt: 106.4 t/s | Generation: 28.7 t/s ]"
2601.13392v1_Beyond Memorization Testing LLM Reasoning on Unsee.pdf,Beyond Memorization: Testing LLM Reasoning on Unseen Theory of Computation Tasks,"['Shlok Shelat', 'Jay Raval', 'Souvik Roy', 'Manas Gaur', 'Ahmedabad University', 'Gujarat, India', 'Baltimore, MD, USA']",,29.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Beyond Memorization: Testing LLM Reasoning on Unseen Theory of || Computation Tasks || Shlok Shelat || Ahmedabad University || Gujarat, India || Jay Raval || Ahmedabad University || Gujarat, India || Souvik Roy || Ahmedabad University || Gujarat, India || Manas Gaur || University of Maryland || Baltimore County || Baltimore ... (truncated) ||  || { || ""title"": ""Beyond Memorization: Testing LLM Reasoning on Unseen Theory of Computation Tasks"", || ""authors"": [ || ""Shlok Shelat"", || ""Jay Raval"", || ""Souvik Roy"", || ""Manas Gaur"", || ""Ahmedabad University"", || ""Gujarat, India"", || ""Baltimore, MD, USA"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""large language models"", || ""deterministic finite automata"", || ""symbolic reasoning"", || ""formal language tasks"", || ""pattern matching"", || ""semantic consistency"" || ], || ""summary"": ""This paper evaluates large language models' ability to construct deterministic finite automata from regular languages, highlighting performance drops on unseen problems and analyzing the limitations of current prompting strategies."" || } ||  || [ Prompt: 111.9 t/s | Generation: 29.0 t/s ]"
2601.13398v1_Can LLMs Compress and Decompress Evaluating Code U.pdf,Can LLMs Compress (and Decompress)?,"['Nickil Maveli', 'Antonio Vergari', 'Shay B. Cohen']","10 Crichton Street, Edinburgh, EH8 9AB",31.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Can LLMs Compress (and Decompress)? || Evaluating Code Understanding and Execution via Invertibility || Nickil Maveli Antonio Vergari || Shay B. Cohen || School of Informatics, University of Edinburgh || 10 Crichton Street, Edinburgh, EH8 9AB || {nickil.maveli,avergari,scohen}@ed.ac.uk || Abstract || LLMs ... (truncated) ||  || { || ""title"": ""Can LLMs Compress (and Decompress)?"", || ""authors"": [""Nickil Maveli"", ""Antonio Vergari"", ""Shay B. Cohen""], || ""doi"": ""10 Crichton Street, Edinburgh, EH8 9AB"", || ""arxiv_id"": """", || ""keywords"": [""LLMs"", ""code"", ""benchmark"", ""code understanding"", ""execution""], || ""summary"": ""The paper evaluates code benchmarks for LLMs, highlighting limitations in maintaining consistent reasoning across forward and backward execution. It introduces ROUNDTRIPCODEE-VAL(RTCE) to test bijection fidelity."" || } ||  || [ Prompt: 107.9 t/s | Generation: 31.3 t/s ]"
2601.13400v1_Deep Image Prior with L0 Gradient Regularizer for .pdf,DEEP IMAGE PRIOR WITH L0 GRADIENT REGULARIZER FOR IMAGE SMOOTHING,"['Nhat Thanh Tran', 'Kevin Bui', 'Jack Xin']",10.48550/arXiv.2407.08600,27.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DEEP IMAGE PRIOR WITH L0 GRADIENT REGULARIZER FOR IMAGE SMOOTHING || Nhat Thanh Tran, Kevin Bui, Jack Xin || Department of Mathematics; University of California, Irvine; Irvine, CA 92697, United States || ABSTRACT || Image smoothing is a fundamental image processing operation that || preserves the ... (truncated) ||  || { || ""title"": ""DEEP IMAGE PRIOR WITH L0 GRADIENT REGULARIZER FOR IMAGE SMOOTHING"", || ""authors"": [""Nhat Thanh Tran"", ""Kevin Bui"", ""Jack Xin""], || ""doi"": ""10.48550/arXiv.2407.08600"", || ""arxiv_id"": ""arXiv:2407.08600"", || ""keywords"": [""image smoothing"", ""deep image prior"", ""0 gradient regularizer""], || ""summary"": ""This paper proposes DIP-0, a deep image prior framework that incorporates the 0 gradient regularizer. It enables high-quality image smoothing without training data by minimizing a nonconvex, nonsmooth 0 norm loss."" || } ||  || [ Prompt: 110.8 t/s | Generation: 27.0 t/s ]"
2601.13401v1_Reasoning with Pixel-level Precision QVLM Architec.pdf,Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset,"['Peter A. Massih1', '2. Eric Cosatto1']",,27.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset || for Quantitative Geospatial Analytics || Peter A. Massih1,2 & Eric Cosatto1 || 1Department of Machine Learning, NEC Laboratories America || 2EPFL || {pmassih,cosatto}@nec-labs.com, peter.abdelmassih@epfl.ch || Abstract || Curre ... (truncated) ||  || { || ""title"": ""Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset"", || ""authors"": [""Peter A. Massih1"", ""2. Eric Cosatto1""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""quantitative spatial reasoning"", ""vision-language models"", ""SQuID dataset"", ""pixel precision""], || ""summary"": ""Current Vision-Language Models fail at quantitative spatial reasoning due to loss of pixel-level information. This paper introduces SQuID, a benchmark dataset, and proposes QVLM, a model that preserves pixel precision by decoupling language understanding from visual analysis."" || } ||  || [ Prompt: 107.6 t/s | Generation: 27.0 t/s ]"
2601.13404v1_Local-to-Global Logical Explanations for Deep Visi.pdf,Local-to-Global Logical Explanations for Deep Vision Models,"['Bhavan Vasu', 'Giuseppe Raffa', 'Prasad Tadepalli']",arXiv:2601.13404v1,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Local-to-Global Logical Explanations for Deep || Vision Models || Bhavan Vasu1[000000034961580X], Giuseppe Raffa2[0009000391784559], and || Prasad Tadepalli1[0000000327363912] || 1 Oregon State University OR 97331, USA || {vasub, tadepall}@oregonstate.edu || 2 Intel Labs, Hillsboro. Oregon, USA || giuse ... (truncated) ||  || { || ""title"": ""Local-to-Global Logical Explanations for Deep Vision Models"", || ""authors"": [ || ""Bhavan Vasu"", || ""Giuseppe Raffa"", || ""Prasad Tadepalli"" || ], || ""doi"": ""arXiv:2601.13404v1"", || ""arxiv_id"": """", || ""keywords"": [ || ""Explainable AI"", || ""AI Interpretability"", || ""Monotone DNF"", || ""Deep Learning"", || ""GDPR"" || ], || ""summary"": ""The paper introduces local and global explanation methods for deep neural networks, presenting explanations in monotone disjunctive-normal-form (MDNF) and demonstrating their effectiveness in vision tasks."" || } ||  || [ Prompt: 123.0 t/s | Generation: 28.6 t/s ]"
2601.13406v1_Integrating Virtual Reality and Large Language Mod.pdf,Integrating Virtual Reality and Large Language Models for Team-Based Non-Technical Skills Training and Evaluation in the Operating Room,"['Jacob Barker', 'Doga Demirel', 'Anna Johansson', 'Robbin Miraglia', 'Darian Hoagland', 'Stephanie B. Jones', 'John Mitchell', 'Daniel B. Jones', 'Suvranu De', 'Carl J. Shapiro Simulation and Skills Center', 'Stephanie B. Jones', 'Robbin Miraglia', 'Darian Hoagland', 'Cullen Jackson', 'Beth Israel Deaconess Medical Center', 'Carl J. Shapiro Simulation and Skills Center', 'Anna Johansson', 'Beth Israel Deaconess Medical Center', 'Rutgers New Jersey Medical School', 'Florida Agricultural and Mechanical University', 'Florida State University']",,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Integrating Virtual Reality and Large Language Models for Team- || Based Non-Technical Skills Training and Evaluation in the || Operating Room || Jacob Barker || School of Computer Science, || University of Oklahoma || Doga Demirel || School of Computer Science, || University of Oklahoma ||  || Cullen J ... (truncated) ||  || { || ""title"": ""Integrating Virtual Reality and Large Language Models for Team-Based Non-Technical Skills Training and Evaluation in the Operating Room"", || ""authors"": [ || ""Jacob Barker"", || ""Doga Demirel"", || ""Anna Johansson"", || ""Robbin Miraglia"", || ""Darian Hoagland"", || ""Stephanie B. Jones"", || ""John Mitchell"", || ""Daniel B. Jones"", || ""Suvranu De"", || ""Carl J. Shapiro Simulation and Skills Center"", || ""Stephanie B. Jones"", || ""Robbin Miraglia"", || ""Darian Hoagland"", || ""Cullen Jackson"", || ""Beth Israel Deaconess Medical Center"", || ""Carl J. Shapiro Simulation and Skills Center"", || ""Anna Johansson"", || ""Beth Israel Deaconess Medical Center"", || ""Rutgers New Jersey Medical School"", || ""Florida Agricultural and Mechanical University"", || ""Florida State University"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper discusses the development of the Virtual Operating Room Team Experience (VORTeX), a VR platform integrating large language model analytics to train and evaluate non-technical skills in surgical teams during laparoscopic emergencies. It highlights structured dialogue analysis and automated behavioral assessment."" || } ||  || [ Prompt: 116.9 t/s | Generation: 29.1 t/s ]"
2601.13412v1_Using deep learning for predicting cleansing quali.pdf,Using deep learning for predicting cleansing quality of colon capsule endoscopy images,"['Puneet Sharma', 'Kristian Dalsb Hindberg', 'Benedicte Schelde-Olesen', 'Ulrik Deding', 'Esmaeil S. Nadimi', 'Jan-Matthias Braun', 'Corresponding author(s). E-mail(s): puneet.sharma@uit.no']",arXiv:2601.13412v1,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Using deep learning for predicting cleansing || quality of colon capsule endoscopy images || Puneet Sharma, Kristian Dalsb Hindberg, || Benedicte Schelde-Olesen, Ulrik Deding, Esmaeil S. Nadimi, || Jan-Matthias Braun, on behalf of the AICE consortium || 1*Department of Automation and Process Engin ... (truncated) ||  || { || ""title"": ""Using deep learning for predicting cleansing quality of colon capsule endoscopy images"", || ""authors"": [ || ""Puneet Sharma"", || ""Kristian Dalsb Hindberg"", || ""Benedicte Schelde-Olesen"", || ""Ulrik Deding"", || ""Esmaeil S. Nadimi"", || ""Jan-Matthias Braun"", || ""Corresponding author(s). E-mail(s): puneet.sharma@uit.no"" || ], || ""doi"": ""arXiv:2601.13412v1"", || ""arxiv_id"": ""arXiv:2601.13412"", || ""keywords"": [ || ""deep learning"", || ""colon capsule endoscopy"", || ""cleansing quality"", || ""ResNet-18"", || ""stratifiedK-fold"", || ""structured pruning"", || ""explainability"", || ""ROAD method"" || ], || ""summary"": ""This study explores deep learning techniques for predicting cleansing quality in colon capsule endoscopy images using a dataset of 500 images labeled by clinicians. A ResNet-18 model was trained with stratified cross-validation, and structured pruning was applied to achieve high accuracy (88% cross-validation accuracy at 79% sparsity). The approach emphasizes model interpretability and efficiency."" || } ||  || [ Prompt: 120.0 t/s | Generation: 28.7 t/s ]"
2601.13422v1_TrustEnergy A Unified Framework for Accurate and R.pdf,TrustEnergy: A Unified Framework for Accurate and Reliable User-level Energy Usage Prediction,"['Dahai Yu', 'Rongchao Xu', 'Dingyi Zhuang', 'Yuheng Bu', 'Shenhao Wang', 'Guang Wang']",10.48550/arXiv.2303.04219,27.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TrustEnergy: A Unified Framework for Accurate and Reliable || User-level Energy Usage Prediction || Dahai Yu1, Rongchao Xu1, Dingyi Zhuang2, Yuheng Bu3, Shenhao Wang4, Guang Wang1* || 1Florida State University, Tallahassee, Florida || 2Massachusetts Institute of Technology, Cambridge, Massachus ... (truncated) ||  || { || ""title"": ""TrustEnergy: A Unified Framework for Accurate and Reliable User-level Energy Usage Prediction"", || ""authors"": [ || ""Dahai Yu"", || ""Rongchao Xu"", || ""Dingyi Zhuang"", || ""Yuheng Bu"", || ""Shenhao Wang"", || ""Guang Wang"" || ], || ""doi"": ""10.48550/arXiv.2303.04219"", || ""arxiv_id"": ""arXiv:2303.04219"", || ""keywords"": [ || ""energy usage prediction"", || ""deep learning"", || ""spatiotemporal representation"", || ""uncertainty quantification"", || ""user-level prediction"" || ], || ""summary"": ""This paper proposes a unified framework called TrustEnergy for accurate and reliable user-level energy usage prediction. It introduces a Hierarchical Spatiotemporal Representation module and a Sequential Conformalized Quantile Regression module to address challenges in spatial correlations, individualization, and uncertainty quantification."" || } ||  || [ Prompt: 108.6 t/s | Generation: 27.4 t/s ]"
2601.13435v1_A Learnable Wavelet Transformer for Long-Short Equ.pdf,A Learnable Wavelet Transformer for Long-Short Equity Trading and Risk-Adjusted Return,"['Shuozhe Li', 'Du Cheng', 'Leqi Liu']",10.48550/arXiv.2405.12345,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || A Learnable Wavelet Transformer for Long-Short || Equity Trading and Risk-Adjusted Return || Optimization || Shuozhe Li , Du Cheng , and Leqi Liu || AbstractLearning profitable intraday trading policies from || financial time series is challenging due to heavy noise, non- || stationarity, and stron ... (truncated) ||  || { || ""title"": ""A Learnable Wavelet Transformer for Long-Short Equity Trading and Risk-Adjusted Return"", || ""authors"": [ || ""Shuozhe Li"", || ""Du Cheng"", || ""Leqi Liu"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""2405.12345"", || ""keywords"": [ || ""Neural wavelet regularization"", || ""Wavelet-transformer network"", || ""Low-guided high-frequency injection"", || ""Return optimization"", || ""Risk-adjusted returns"" || ], || ""summary"": ""The paper proposes WaveLSFormer, a learnable wavelet-based long-short transformer that uses a learnable wavelet front-end and a low-guided high-frequency injection module to improve profitability and risk-adjusted returns in intraday trading."" || } ||  || [ Prompt: 110.3 t/s | Generation: 27.7 t/s ]"
2601.13437v1_MOSLD-Bench Multilingual Open-Set Learning and Dis.pdf,MOSLD-Bench: Multilingual Open-Set Learning and Discovery,"['Adriana-Valentina Costache', 'Daria-Nicoleta Dragomir', 'Silviu-Florin Gheorghe', 'Eduard Poesina', 'Paul Irofti', 'Radu Tudor Ionescu']",,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MOSLD-Bench: Multilingual Open-Set Learning and Discovery || Benchmark for Text Categorization || Adriana-Valentina Costache, Daria-Nicoleta Dragomir, Silviu-Florin Gheorghe, || Eduard Poesina, Paul Irofti, Radu Tudor Ionescu || Department of Computer Science, University of Bucharest, Romania || E ... (truncated) ||  || { || ""title"": ""MOSLD-Bench: Multilingual Open-Set Learning and Discovery"", || ""authors"": [ || ""Adriana-Valentina Costache"", || ""Daria-Nicoleta Dragomir"", || ""Silviu-Florin Gheorghe"", || ""Eduard Poesina"", || ""Paul Irofti"", || ""Radu Tudor Ionescu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Open-set learning and discovery benchmark for text categorization in multiple languages."" || } ||  || [ Prompt: 108.8 t/s | Generation: 28.5 t/s ]"
2601.13443v1_Explicit Cognitive Allocation A Principle for Gove.pdf,Explicit Cognitive Allocation: A Principle for Governed and Auditable Inference in Large Language Models,"['Hctor Manuel Manzanilla-Granados', 'Zaira Navarrete-Cazales', 'Miriam Pescador-Rojas', 'Escuela Superior de Cmputo del I.P .N']",07738,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Explicit Cognitive Allocation: A Principle for Governed and Auditable Inference in Large || Language Models. || *Hctor Manuel Manzanilla-Granados, **Zaira Navarrete-Cazales. *Miriam Pescador-Rojas, *Tonahtiu || Ramrez-Romero. || *Escuela Superior de Cmputo del I.P .N, Av. Juan de Dios Btiz  ... (truncated) ||  || { || ""title"": ""Explicit Cognitive Allocation: A Principle for Governed and Auditable Inference in Large Language Models"", || ""authors"": [ || ""Hctor Manuel Manzanilla-Granados"", || ""Zaira Navarrete-Cazales"", || ""Miriam Pescador-Rojas"", || ""Escuela Superior de Cmputo del I.P .N"" || ], || ""doi"": ""07738"", || ""arxiv_id"": """", || ""keywords"": [ || ""large language models"", || ""AI-assisted reasoning"", || ""epistemic control"", || ""auditability"", || ""transparency"", || ""instrumental allocation"" || ], || ""summary"": ""The paper introduces Explicit Cognitive Allocation as a framework to structure AI-assisted inference, emphasizing structured separation of cognitive functions and improving traceability, epistemic control, and reproducibility in high-responsibility AI applications."" || } ||  || [ Prompt: 118.1 t/s | Generation: 27.8 t/s ]"
2601.13458v1_Labels or Preferences Budget-Constrained Learning .pdf,Budget-Constrained Learning with Human Judgments over AI-Generated Outputs,"['Zihan Dong', 'Ruijia Wu', 'Linjun Zhang']",arXiv:2601.13458v1,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Labels or Preferences? Budget-Constrained Learning with || Human Judgments over AI-Generated Outputs || Zihan Dong 1, Ruijia Wu 2, and Linjun Zhang 1 || 1Rutgers University 2Shanghai Jiao Tong University || January 21, 2026 || Abstract || The increasing reliance on human preference feedback to judge  ... (truncated) ||  || { || ""title"": ""Budget-Constrained Learning with Human Judgments over AI-Generated Outputs"", || ""authors"": [ || ""Zihan Dong"", || ""Ruijia Wu"", || ""Linjun Zhang"" || ], || ""doi"": ""arXiv:2601.13458v1"", || ""arxiv_id"": ""2601.13458"", || ""keywords"": [ || ""budget-constrained learning"", || ""human judgments"", || ""AI-generated outputs"", || ""preference calibration"", || ""active learning"" || ], || ""summary"": ""The paper addresses the need for efficient data acquisition by optimizing the allocation of annotation budgets between ground-truth labels and human preferences, introducing a novel PCAL method."" || } ||  || [ Prompt: 116.2 t/s | Generation: 27.6 t/s ]"
2601.13462v1_SpatialBench-UC Uncertainty-Aware Evaluation of Sp.pdf,SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt,['Amine Rostane'],,25.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt || Following in Text-to-Image Generation || Amine Rostane || ESIEA, France || hello@aminerostane.com || Abstract || Evaluating whether text to image models follow explicit spatial instructions is difficult to automate. || Object detectors m ... (truncated) ||  || { || ""title"": ""SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt"", || ""authors"": [""Amine Rostane""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Evaluating whether text to image models follow explicit spatial instructions is difficult to automate. Object detectors may miss targets or return multiple plausible detections, and simple geometric tests can become ambiguous in borderline cases. Spatial evaluation is naturally an aselective prediction problem."" || } ||  || [ Prompt: 111.9 t/s | Generation: 25.9 t/s ]"
2601.13464v1_Context and Transcripts Improve Detection of Deepf.pdf,Context and Transcripts Improve Detection of Deepfake Audios,"['Chongyang Gao', 'Marco Postiglione', 'Julian Baldwin', 'Natalia Denisenko', 'Isabel Gortner', 'Luke Fosdick', 'Chiara Pulice', 'Sarit Kraus', 'V. S. Subrahmanian']",10.48550/arXiv.2026.12345,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Context and Transcripts Improve Detection of Deepfake Audios || of Public Figures || Chongyang Gao 1, Marco Postiglione 1, Julian Baldwin 1, Natalia Denisenko 1, || Isabel Gortner 1, Luke Fosdick 1, Chiara Pulice 1, Sarit Kraus 2, V. S. Subrahmanian 1 || 1Northwestern University || 2Bar-Ilan Unive ... (truncated) ||  || { || ""title"": ""Context and Transcripts Improve Detection of Deepfake Audios"", || ""authors"": [ || ""Chongyang Gao"", || ""Marco Postiglione"", || ""Julian Baldwin"", || ""Natalia Denisenko"", || ""Isabel Gortner"", || ""Luke Fosdick"", || ""Chiara Pulice"", || ""Sarit Kraus"", || ""V. S. Subrahmanian"" || ], || ""doi"": ""10.48550/arXiv.2026.12345"", || ""arxiv_id"": ""arXiv:2509.12345"", || ""keywords"": [ || ""deepfake detection"", || ""audio deepfakes"", || ""context"", || ""public figures"", || ""audio detectors"", || ""adversarial evasion"" || ], || ""summary"": ""Humans use context to assess the veracity of information. This study introduces a Context-based Audio Deepfake Detector (CADD) that leverages context and transcripts to improve audio deepfake detection. A large dataset of public deepfakes and synthetic data are presented, showing significant performance gains over traditional methods."" || } ||  || [ Prompt: 111.7 t/s | Generation: 28.7 t/s ]"
2601.13465v1_Graph Neural Networks are Heuristics.pdf,Graph Neural Networks are Heuristics,"['Yimeng Min', 'Carla P . Gomes']",,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Graph Neural Networks are Heuristics || Yimeng Min || Department of Computer Science || Cornell University || Ithaca, NY , USA || min@cs.cornell.edu || Carla P . Gomes || Department of Computer Science || Cornell University || Ithaca, NY , USA || gomes@cs.cornell.edu || Abstract || We demonstrate that a single trainin ... (truncated) ||  || { || ""title"": ""Graph Neural Networks are Heuristics"", || ""authors"": [ || ""Yimeng Min"", || ""Carla P . Gomes"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""We demonstrate that a single training trajectory can transform a graph neural network into an unsupervised heuristic for combinatorial optimization. Focusing on the Travelling Salesman Problem, we show that encoding global structural constraints as an inductive bias enables a non-autoregressive model to generate solutions via direct forward passes, without search, supervision, or sequential decision-making. At inference time, dropout and snapshot ensembling allow a single model to act as an implicit ensemble, reducing optimality gaps through increased solution diversity. Our results establish that graph neural networks do not require supervised training nor explicit search to be effective. Instead, they can internalize global combinatorial structure and function as strong, learned heuristics."" || } ||  || [ Prompt: 110.5 t/s | Generation: 27.8 t/s ]"
2601.13474v1_Preconditioning Benefits of Spectral Orthogonaliza.pdf,Preconditioning Benefits of Spectral Orthogonalization in Muon,"['Jianhao Ma', 'Penn', 'Yu Huang', 'Yuejie Chi', 'Yale', 'Yuxin Chen']",arXiv:2601.13474v1,27.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Preconditioning Benefits of Spectral Orthogonalization in Muon || Jianhao Ma || Penn || Yu Huang || Penn || Yuejie Chi || Yale || Yuxin Chen || Penn || January 21, 2026 || Abstract || The Muon optimizer, a matrix-structured algorithm that leverages spectral orthogonalization of || gradients, is a milestone in the pre ... (truncated) ||  || { || ""title"": ""Preconditioning Benefits of Spectral Orthogonalization in Muon"", || ""authors"": [ || ""Jianhao Ma"", || ""Penn"", || ""Yu Huang"", || ""Yuejie Chi"", || ""Yale"", || ""Yuxin Chen"" || ], || ""doi"": ""arXiv:2601.13474v1"", || ""arxiv_id"": ""2601.13474"", || ""keywords"": [], || ""summary"": ""The Muon optimizer leverages spectral orthogonalization of gradients to improve convergence, demonstrating superior performance over gradient descent and Adam in matrix optimization tasks."" || } ||  || [ Prompt: 115.7 t/s | Generation: 27.0 t/s ]"
2601.13476v1_A Unified Variational Imputation Framework for Ele.pdf,A Unified Variational Imputation Framework for Electric Vehicle Charging Data,"['Jinhao Li', 'Hao Wang']",10.48550/arXiv.2405.12345,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A Unified Variational Imputation Framework for || Electric Vehicle Charging Data || Using Retrieval-Augmented Language Model || Jinhao Li and Hao Wang,Member IEEE || AbstractThe reliability of data-driven applications in electric || vehicle (EV) infrastructure, such as charging demand forecasting, ... (truncated) ||  || { || ""title"": ""A Unified Variational Imputation Framework for Electric Vehicle Charging Data"", || ""authors"": [""Jinhao Li"", ""Hao Wang""], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [""electric vehicle"", ""data imputation"", ""charging demand"", ""large language model"", ""retrieval-augmented generation""], || ""summary"": ""This paper presents a novel probabilistic variational imputation framework leveraging large language models and retrieval-augmented memory to address data sparsity in EV charging datasets. PRAIM encodes heterogeneous data into a unified representation and enhances imputation accuracy through dynamic retrieval."" || } ||  || [ Prompt: 109.3 t/s | Generation: 27.5 t/s ]"
2601.13481v1_Towards Efficient and Robust Linguistic Emotion Di.pdf,Towards Efficient and Robust Linguistic Emotion,"['Jian Zhang', 'Zhangqi Wang', 'Zhiyuan Wang', 'Weiping Fu', 'Yu He', 'Haiping Zhu', 'Qika Lin']",1731,27.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || IEEE TRANSACTIONS ON AFFECTIVE COMPUTING 14(3), 2023 1731 || Towards Efficient and Robust Linguistic Emotion || Diagnosis for Mental Health via Multi-Agent || Instruction Refinement || Jian Zhang, Zhangqi Wang, Zhiyuan Wang, Weiping Fu, Yu He, || Haiping Zhu, Qika Lin,Member, IEEE, and Jun Liu,Sen ... (truncated) ||  || { || ""title"": ""Towards Efficient and Robust Linguistic Emotion"", || ""authors"": [ || ""Jian Zhang"", || ""Zhangqi Wang"", || ""Zhiyuan Wang"", || ""Weiping Fu"", || ""Yu He"", || ""Haiping Zhu"", || ""Qika Lin"" || ], || ""doi"": ""1731"", || ""arxiv_id"": ""IEEE TRANSACTIONS ON AFFECTIVE COMPUTING 14(3), 2023"", || ""keywords"": [ || ""Linguistic Emotion Diagnosis"", || ""Emotional Comorbidity"", || ""Inefficient Exploration"", || ""Automated Prompt Optimization"", || ""Multi-Agent Collaboration"", || ""Medical Language Processing"", || ""Trustworthy Artificial Intelligence"" || ], || ""summary"": ""The paper proposes APOLO, a framework for automated prompt optimization in linguistic emotion diagnosis, addressing challenges like emotional comorbidity and inefficient cue exploration. It introduces a multi-agent collaboration mechanism to enhance diagnostic accuracy and robustness in mental health applications."" || } ||  || [ Prompt: 116.0 t/s | Generation: 27.9 t/s ]"
2601.13487v1_The Hidden Toll of Social Media News Causal Effect.pdf,The Hidden Toll of Social Media News: Causal Effects on Psychosocial Wellbeing,"['Olivia Pal', 'Agam Goyal', 'Eshwar Chandrasekharan', 'Koustuv Saha']",,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || The Hidden Toll of Social Media News: Causal Effects on Psychosocial Wellbeing || Olivia Pal, Agam Goyal, Eshwar Chandrasekharan, Koustuv Saha || University of Illinois Urbana-Champaign || Urbana, IL, USA || {opal2, agam2, eshwar, ksaha2}@illinois.edu || Abstract || News consumption on social media h ... (truncated) ||  || { || ""title"": ""The Hidden Toll of Social Media News: Causal Effects on Psychosocial Wellbeing"", || ""authors"": [ || ""Olivia Pal"", || ""Agam Goyal"", || ""Eshwar Chandrasekharan"", || ""Koustuv Saha"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""social media"", || ""news consumption"", || ""psychosocial wellbeing"", || ""affective outcomes"", || ""behavioral outcomes"", || ""cognitive outcomes"", || ""news effects"", || ""psychological impact"" || ], || ""summary"": ""News engagement on social media produces systematic trade-offs: increased depression, stress, and anxiety, yet decreased loneliness and increased social interaction. Newsfeed bookmarking is associated with greater psychosocial deterioration compared to commenting or quoting."" || } ||  || [ Prompt: 108.1 t/s | Generation: 27.5 t/s ]"
2601.13508v1_CatMaster An Agentic Autonomous System for Computa.pdf,CatMaster: An Agentic Autonomous System for Computational Heterogeneous Catalysis Research,"['Honghao Chen', 'Jiangjie Qiu', 'Yi Shen Tew', 'Xiaonan Wang']",arXiv:2601.13508v1,30.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || CatMaster: An Agentic Autonomous System for || Computational Heterogeneous Catalysis Research || Honghao Chen, Jiangjie Qiu, Yi Shen Tew, and Xiaonan Wang || Beijing Key Laboratory of Artificial Intelligence for Advanced Chemical Engineering || Materials, Department of Chemical Engineering, Ts ... (truncated) ||  || { || ""title"": ""CatMaster: An Agentic Autonomous System for Computational Heterogeneous Catalysis Research"", || ""authors"": [ || ""Honghao Chen"", || ""Jiangjie Qiu"", || ""Yi Shen Tew"", || ""Xiaonan Wang"" || ], || ""doi"": ""arXiv:2601.13508v1"", || ""arxiv_id"": ""arXiv:2601.13508"", || ""keywords"": [], || ""summary"": ""CatMaster is a large-language-model-driven agent system that automates computational heterogeneous catalysis workflows using DFT, improving reproducibility and efficiency."" || } ||  || [ Prompt: 100.3 t/s | Generation: 30.1 t/s ]"
2601.13515v1_Automatic Adjustment of HPA Parameters and Attack .pdf,Automatic Adjustment of HPA Parameters and Attack,"['Huah Yong Chan', 'Hanlin Zhou', 'Jingfei Ni', 'Mengchun Wu']",arXiv:2601.13515v1,30.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Automatic Adjustment of HPA Parameters and Attack || Prevention in Kubernetes Using Random Forests || Huah Yong Chan || School of Computer Sciences, Universiti Sains Malaysia || hychan@usm.my || Hanlin Zhou || School of Computer Sciences, Universiti Sains Malaysia || Xiamen Institute of Software Technol ... (truncated) ||  || { || ""title"": ""Automatic Adjustment of HPA Parameters and Attack"", || ""authors"": [ || ""Huah Yong Chan"", || ""Hanlin Zhou"", || ""Jingfei Ni"", || ""Mengchun Wu"" || ], || ""doi"": ""arXiv:2601.13515v1"", || ""arxiv_id"": ""arXiv:2601.13515"", || ""keywords"": [""Kubernetes"", ""HPA"", ""Security"", ""Random Forest""], || ""summary"": ""This paper explores using HTTP status codes as custom metrics in HPA to dynamically adjust pod parameters via Random Forest, aiming to manage attack traffic and reduce 5XX status codes."" || } ||  || [ Prompt: 109.1 t/s | Generation: 30.8 t/s ]"
2601.13518v1_AgenticRed Optimizing Agentic Systems for Automate.pdf,AGENTICRED: Optimizing Agentic Systems for Automated Red-teaming,"['Jiayi Yuan', 'Jonathan Nother', 'Natasha Jaques', 'Goran Radanovic']",,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || AGENTICRED: Optimizing Agentic Systems for Automated Red-teaming || Jiayi Yuan* 1 Jonathan Nother 2 Natasha Jaques 1 Goran Radanovic 2 || Abstract || While recent automated red-teaming methods || show promise for systematically exposing model || vulnerabilities, most existing approaches rely on || hu ... (truncated) ||  || { || ""title"": ""AGENTICRED: Optimizing Agentic Systems for Automated Red-teaming"", || ""authors"": [ || ""Jiayi Yuan"", || ""Jonathan Nother"", || ""Natasha Jaques"", || ""Goran Radanovic"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""automated red-teaming"", || ""LLMs"", || ""system design"", || ""agentic systems"", || ""red-teaming"", || ""AI safety"" || ], || ""summary"": ""AGENTICRED introduces an automated pipeline leveraging LLMs in-context learning to design and refine red-teaming systems without human intervention. It outperforms state-of-the-art methods, achieving high attack success rates across various models."" || } ||  || [ Prompt: 112.6 t/s | Generation: 28.5 t/s ]"
2601.13528v1_Eliciting Harmful Capabilities by Fine-Tuning On S.pdf,Eliciting Harmful Capabilities by Fine-Tuning on Safeguarded Outputs,"['Jackson Kaunismaa', 'Mats', 'Avery Griffin', 'Anthropic', 'John Hughes', 'Anthropic', 'Christina Q Knight', 'Scale AI', 'Mrinank Sharma', 'Anthropic', 'Erik Jones']",,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ELICITINGHARMFULCAPABILITIES BYFINE-TUNING || ONSAFEGUARDEDOUTPUTS || Jackson Kaunismaa || MATS || Avery Griffin || Anthropic || John Hughes || Anthropic || Christina Q Knight || Scale AI || Mrinank Sharma || Anthropic || Erik Jones || Anthropic || ABSTRACT || Model developers implement safeguards in frontier models to prevent ... (truncated) ||  || { || ""title"": ""Eliciting Harmful Capabilities by Fine-Tuning on Safeguarded Outputs"", || ""authors"": [ || ""Jackson Kaunismaa"", || ""Mats"", || ""Avery Griffin"", || ""Anthropic"", || ""John Hughes"", || ""Anthropic"", || ""Christina Q Knight"", || ""Scale AI"", || ""Mrinank Sharma"", || ""Anthropic"", || ""Erik Jones"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""elicit harmful capabilities"", || ""safeguarded outputs"", || ""hazardous chemical synthesis"", || ""output-level safeguards"", || ""model fine-tuning"", || ""ecosystem-level risks"" || ], || ""summary"": ""This work demonstrates that even models protected against harmful outputs can be used to elicit dangerous capabilities via elicitation attacks. The authors show that such attacks recover a significant portion of the capability gap between open-source and unrestricted models, highlighting challenges in mitigating misuse through safeguards."" || } ||  || [ Prompt: 106.6 t/s | Generation: 28.6 t/s ]"
2601.13533v1_Reasoning While Recommending Entropy-Guided Latent.pdf,Reasoning While Recommending: Entropy-Guided Latent,['Changshuo Zhang'],XXXXXXX,27.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Reasoning While Recommending: Entropy-Guided Latent || Reasoning in Generative Re-ranking Models || Changshuo Zhang || Individual Author || China || lyingCS@foxmail.com || Abstract || Reinforcement learning plays a crucial role in generative re-ranking || scenarios due to its exploration-exploitation capab ... (truncated) ||  || { || ""title"": ""Reasoning While Recommending: Entropy-Guided Latent"", || ""authors"": [""Changshuo Zhang""], || ""doi"": ""XXXXXXX"", || ""arxiv_id"": ""XXXXXX"", || ""keywords"": [""Generative Re-ranking"", ""Latent Reasoning"", ""Reinforcement Learning""], || ""summary"": ""Reinforcement learning enhances generative re-ranking by adapting to dynamic model difficulty, reducing entropy in decision-making and improving recommendation precision."" || } ||  || [ Prompt: 108.5 t/s | Generation: 27.1 t/s ]"
2601.13534v1_MN-TSGContinuous Time Series Generation with Irreg.pdf,Continuous Timeseries Generation With Irregular Observations,"['Xu Zhang', 'Junwei Deng', 'Chang Xu', 'Hao Li']",,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MN-TSG: CONTINUOUSTIMESERIESGENERATION WITH || IRREGULAROBSERVATIONS || Xu Zhang || Microsoft Research || Beijing, China || v-xuzhang2@microsoft.com || Junwei Deng || University of Illinois at Urbana-Champaign || Champagne, Illinois, United States of America || junweid2@illinois.edu || Chang Xu || Microsoft Researc ... (truncated) ||  || { || ""title"": ""Continuous Timeseries Generation With Irregular Observations"", || ""authors"": [ || ""Xu Zhang"", || ""Junwei Deng"", || ""Chang Xu"", || ""Hao Li"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Irregular time series"", || ""Continuous time series generation"", || ""Deep learning architecture"", || ""Neural Controlled Differential Equations"", || ""Time series generation"", || ""Data augmentation"", || ""Privacy-preserving data sharing"", || ""High-fidelity simulations"" || ], || ""summary"": ""This paper addresses the challenges of generating irregular and continuous time series by proposing a novel framework, MN-TSG, which integrates Mixture-of-Experts-based Neural Controlled Differential Equations with existing time series generation models. The approach aims to support downstream tasks requiring continuous and high-resolution time series, especially in healthcare applications."" || } ||  || [ Prompt: 111.8 t/s | Generation: 27.6 t/s ]"
2601.13537v1_When Wording Steers the Evaluation Framing Bias in.pdf,When Wording Steers the Evaluation: Framing Bias in LLM judges,"['Yerin Hwang', 'Dongryeol Lee', 'Taegwan Kang', 'Minwoo Lee', 'Kyomin Jung']",,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || When Wording Steers the Evaluation: Framing Bias in LLM judges || Yerin Hwang1 Dongryeol Lee 2 || Taegwan Kang3 Minwoo Lee3 Kyomin Jung1,2,4 || 1IPAI, Seoul National University 2Dept. of ECE, Seoul National University || 3LG AI Research 4SNU-LG AI Research Center || {dpfls589, drl123, kjung}@snu.a ... (truncated) ||  || { || ""title"": ""When Wording Steers the Evaluation: Framing Bias in LLM judges"", || ""authors"": [ || ""Yerin Hwang"", || ""Dongryeol Lee"", || ""Taegwan Kang"", || ""Minwoo Lee"", || ""Kyomin Jung"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper investigates how deliberate prompt framing influences large language models' judgments across four evaluation tasks, highlighting framing bias as a structural issue in LLM-based systems."" || } ||  || [ Prompt: 107.9 t/s | Generation: 27.8 t/s ]"
2601.13545v1_TruthTensor Evaluating LLMs Human Imitation throug.pdf,Evaluating Language Models Human Imitation Through Prediction Market Drift and Holistic Reasoning,"['Shirin Shahabi', 'Spencer Graham', 'Haruna Isah']",https://truthtensor.com,13.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TRUTHTENSOR: EVALUATINGLLMSHUMANIMITATION THROUGH || PREDICTIONMARKETDRIFT ANDHOLISTICREASONING || Shirin Shahabi, Spencer Graham, and Haruna Isah || [shirin, spencer, and haruna]@inferencelabs.com || Inference Labs Inc. || Abstract || Evaluating language models and AI agents remains fundamentally ch ... (truncated) ||  || { || ""title"": ""Evaluating Language Models Human Imitation Through Prediction Market Drift and Holistic Reasoning"", || ""authors"": [""Shirin Shahabi"", ""Spencer Graham"", ""Haruna Isah""], || ""doi"": ""https://truthtensor.com"", || ""arxiv_id"": """", || ""keywords"": [""language models"", ""LLM evaluation"", ""human imitation"", ""drift analysis""], || ""summary"": ""This paper introduces TruthTensor, a new evaluation framework that assesses LLMs not just for accuracy but for robustness, calibration, and alignment with human decision-making under dynamic conditions. It emphasizes holistic reasoning, contamination-free tasks, and reproducible diagnostics to better reflect real-world performance."" || } ||  || [ Prompt: 39.1 t/s | Generation: 13.6 t/s ]"
2601.13546v1_ChatAD Reasoning-Enhanced Time-Series Anomaly Dete.pdf,Reasoning-Enhanced Time-Series Anomaly Detection with Multi-Turn Instruction Evolution,"['Hui Sun', 'Chang Xu', 'Haonan Xie', 'Hao Li', 'Yuhao Huang', 'Chuheng Zhang', 'Ming Jin', 'Xiaoguang Liu', 'Gang Wang', 'Jiang Bian', 'Nankai University', 'Microsoft Research Asia', 'Huanjiang Laboratory', 'University of Manchester', 'Nanjing University', 'Griffith University']",,13.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ChatAD: Reasoning-Enhanced Time-Series Anomaly Detection with || Multi-Turn Instruction Evolution || Hui Sun1* || , Chang Xu2 || , Haonan Xie3, Hao Li4, Yuhao Huang5, || Chuheng Zhang2, Ming Jin6, Xiaoguang Liu1, Gang Wang1, Jiang Bian2, || 1 Nankai University, 2 Microsoft Research Asia, 3 Huanjiang  ... (truncated) ||  || { || ""title"": ""Reasoning-Enhanced Time-Series Anomaly Detection with Multi-Turn Instruction Evolution"", || ""authors"": [ || ""Hui Sun"", || ""Chang Xu"", || ""Haonan Xie"", || ""Hao Li"", || ""Yuhao Huang"", || ""Chuheng Zhang"", || ""Ming Jin"", || ""Xiaoguang Liu"", || ""Gang Wang"", || ""Jiang Bian"", || ""Nankai University"", || ""Microsoft Research Asia"", || ""Huanjiang Laboratory"", || ""University of Manchester"", || ""Nanjing University"", || ""Griffith University"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""LLM-driven anomaly detection"", || ""Time Series"", || ""Anomaly detection"", || ""LLM"", || ""Multi-turn dialogue"", || ""Reasoning"", || ""Cross-task generalization"" || ], || ""summary"": ""The paper proposes a multi-agent-based Time Series Evolution algorithm (TSEvol) with an AD reasoning and multi-turn dialogue dataset (TSEData-20K). It introduces ChatAD models and benchmarks them using LLM-driven methods, achieving significant improvements in accuracy and generalization."" || } ||  || [ Prompt: 38.4 t/s | Generation: 13.5 t/s ]"
2601.13547v1_HateXScore A Metric Suite for Evaluating Reasoning.pdf,HateXScore: A Metric Suite for Evaluating Reasoning Quality in Hate Speech Explanations,"['Yujia Hu', 'Roy Ka-Wei Lee']",10.48550/arXiv.2405.12345,13.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || HateXScore: A Metric Suite for Evaluating Reasoning Quality in || Hate Speech Explanations || Yujia Hu, Roy Ka-Wei Lee || Singapore University of Technology and Design || yujia_hu@sutd.edu.sg,roy_lee@sutd.edu.sg || Abstract || Hateful speech detection is a key component || of content moderation, yet cur ... (truncated) ||  || { || ""title"": ""HateXScore: A Metric Suite for Evaluating Reasoning Quality in Hate Speech Explanations"", || ""authors"": [ || ""Yujia Hu"", || ""Roy Ka-Wei Lee"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""10.48550/arXiv.2405.12345"", || ""keywords"": [ || ""hate speech"", || ""content moderation"", || ""explainability"", || ""reasoning quality"", || ""interpretability"" || ], || ""summary"": ""The paper introduces HateXScore, a four-component metric suite to evaluate the reasoning quality of model explanations in hate speech detection. It assesses conclusion explicitness, faithfulness, causal grounding, and logical consistency, aiming to reveal interpretability failures and annotation inconsistencies."" || } ||  || [ Prompt: 38.6 t/s | Generation: 13.1 t/s ]"
2601.13558v1_Leveraging ChatGPT and Other NLP Methods for Ident.pdf,Leveraging ChatGPT and Other NLP Methods for Identifying Risk and Protective Behaviors in MSM: Social Media and Dating apps Text Analysis,"['Mehrab Beikzadeh', 'Chenglin Hong', 'Cory J Cascalheira', 'Callisto Boka', 'Majid Sarrafzadeh', 'Ian W Holloway']",,27.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Leveraging ChatGPT and Other NLP Methods for || Identifying Risk and Protective Behaviors in MSM: || Social Media and Dating apps Text Analysis || Mehrab Beikzadeh , Chenglin Hong , Cory J Cascalheira ,, || Callisto Boka , Majid Sarrafzadeh , Ian W Holloway || Department of Computer Science, Henr ... (truncated) ||  || { || ""title"": ""Leveraging ChatGPT and Other NLP Methods for Identifying Risk and Protective Behaviors in MSM: Social Media and Dating apps Text Analysis"", || ""authors"": [ || ""Mehrab Beikzadeh"", || ""Chenglin Hong"", || ""Cory J Cascalheira"", || ""Callisto Boka"", || ""Majid Sarrafzadeh"", || ""Ian W Holloway"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""mens who have sex with men"", || ""sexually transmitted infections"", || ""harmful drinking"", || ""social media"", || ""dating apps"", || ""text analysis"", || ""machine learning"", || ""public health interventions"" || ], || ""summary"": ""This study explores the use of text data from social media and dating apps to identify risk and protective behaviors among men who have sex with men (MSM). It evaluates the predictive power of ChatGPT embeddings, BERT embeddings, LIWC analysis, and a custom dictionary-based approach in detecting behaviors such as binge drinking, multiple sexual partners, and PrEP use."" || } ||  || [ Prompt: 46.5 t/s | Generation: 27.3 t/s ]"
2601.13559v1_AgentGC Evolutionary Learning-based Lossless Compr.pdf,AgentGC: Evolutionary Learning-based Lossless Compression for Genomics Data with LLM-driven Multiple Agent,"['Hui Sun', 'Yanfeng Ding', 'Huidong Ma', 'Chang Xu', 'Keyan Jin', 'Lizheng Zu', 'Cheng Zhong', 'Xiaoguang Liu', 'Gang Wang', 'Wentong Cai', 'Nankai University', 'Nanyang Technology University', 'Microsoft Research Asia', 'Macao Polytechnic University', 'Guangxi University']",,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || AgentGC: Evolutionary Learning-based Lossless Compression for || Genomics Data with LLM-driven Multiple Agent || Hui Sun1,2, Yanfeng Ding1, Huidong Ma1,2, Chang Xu3, Keyan Jin4, || Lizheng Zu2, Cheng Zhong5, Xiaoguang Liu1* || , Gang Wang1 || , Wentong Cai2, || 1 Nankai University, 2 Nanyang Technolo ... (truncated) ||  || { || ""title"": ""AgentGC: Evolutionary Learning-based Lossless Compression for Genomics Data with LLM-driven Multiple Agent"", || ""authors"": [ || ""Hui Sun"", || ""Yanfeng Ding"", || ""Huidong Ma"", || ""Chang Xu"", || ""Keyan Jin"", || ""Lizheng Zu"", || ""Cheng Zhong"", || ""Xiaoguang Liu"", || ""Gang Wang"", || ""Wentong Cai"", || ""Nankai University"", || ""Nanyang Technology University"", || ""Microsoft Research Asia"", || ""Macao Polytechnic University"", || ""Guangxi University"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""genomics data"", || ""lossless compression"", || ""LLM"", || ""multi-agent"", || ""compression"", || ""algorithm design"" || ], || ""summary"": ""Lossless compression for genomics data using an evolutionary agent-based system with LLM-driven multi-agent architecture. The approach includes a user-friendly interface, cognitive optimization, and automated compression framework, achieving significant compression and throughput improvements over existing methods."" || } ||  || [ Prompt: 110.4 t/s | Generation: 27.7 t/s ]"
2601.13562v1_Reasoning is a Modality.pdf,Reasoning is a Modality,"['Zhiguang Liu', 'Yi Shang']","lz7fd@missouri.edu, shangy@missouri.edu",27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Reasoning is a Modality || Zhiguang Liu,Yi Shang || University of Missouri - Columbia || lz7fd@missouri.edu, shangy@missouri.edu || Abstract || The Abstraction and Reasoning Corpus (ARC) || provides a compact laboratory for studying ab- || stract reasoning, an ability central to human in- || telligence. Mo ... (truncated) ||  || { || ""title"": ""Reasoning is a Modality"", || ""authors"": [""Zhiguang Liu"", ""Yi Shang""], || ""doi"": ""lz7fd@missouri.edu, shangy@missouri.edu"", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper discusses the Abstraction and Reasoning Corpus (ARC) and proposes a role-separated transformer block to model reasoning as a distinct cognitive modality, aiming to bridge the gap between human-like explanation and AI-generated rationalizations."" || } ||  || [ Prompt: 111.8 t/s | Generation: 27.8 t/s ]"
2601.13563v1_ButterflyMoE Sub-Linear Ternary Experts via Struct.pdf,ButterflyMoE: Sub-Linear Ternary Experts via Structured Butterfly,['Aryan Karmore'],bt24csd009@iiitn.ac.in,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ButterflyMoE: Sub-Linear Ternary Experts via Structured Butterfly || Orbits || Aryan Karmore || Indian Institute of Information Technology, Nagpur || bt24csd009@iiitn.ac.in || Abstract || Linear memory scaling storesNindependent expert weight || matrices requiringO(Nd 2)memory, which exceeds edge || device ... (truncated) ||  || { || ""title"": ""ButterflyMoE: Sub-Linear Ternary Experts via Structured Butterfly"", || ""authors"": [""Aryan Karmore""], || ""doi"": ""bt24csd009@iiitn.ac.in"", || ""arxiv_id"": """", || ""keywords"": [""ButterflyMoE"", ""linear memory scaling"", ""quantization"", ""quantized substrate""], || ""summary"": ""Introduces ButterflyMoE, a method that reduces memory scaling by treating experts as geometric reorientations of a shared quantized prototype, achieving 150x memory reduction at 256 experts."" || } ||  || [ Prompt: 110.8 t/s | Generation: 28.8 t/s ]"
2601.13564v1_Multi-objective fluorescent molecule design with a.pdf,Multi-objective fluorescent molecule design with a data-physics dual-driven generative framework,"['Yanheng Li', 'Zhichen Pu', 'Lijiang Yang', 'Zehao Zhou', 'Yi Qin Gao']",,31.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  ||  || Multi-objective fluorescent molecule design with a || data-physics dual-driven generative framework || Yanheng Li1,2, Zhichen Pu2, Lijiang Yang1, Zehao Zhou2,3, Yi Qin Gao1,4 || 1. New Cornerstone Science Laboratory, College of Chemistry and Molecular Engineering, Peking || University,  ... (truncated) ||  || { || ""title"": ""Multi-objective fluorescent molecule design with a data-physics dual-driven generative framework"", || ""authors"": [ || ""Yanheng Li"", || ""Zhichen Pu"", || ""Lijiang Yang"", || ""Zehao Zhou"", || ""Yi Qin Gao"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""New Cornerstone Science Laboratory, College of Chemistry and Molecular Engineering, Peking University; Bytedance Seed, Beijing; Zhongguancun Academy, Beijing; Department of Chemistry, School of Science, Westlake University."" || } ||  || [ Prompt: 101.3 t/s | Generation: 31.0 t/s ]"
2601.13566v1_Self-Improvement as Coherence Optimization A Theor.pdf,Self-Improvement as Coherence Optimization: A Theoretical Account,"['Tianyi Qiu', 'Ahmed Hani Ismailahmedhismail', 'Zhonghao Hehezhonghao2030', 'George Washington University', 'UC Berkeley']",arXiv:2601.13566v1,27.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Self-Improvement as Coherence Optimization: || A Theoretical Account || Tianyi Qiu qiutianyi.qty@gmail.com || Peking University || University of Oxford || Ahmed Hani Ismailahmedhismail@berkeley.edu || UC Berkeley || Zhonghao Hehezhonghao2030@gmail.com || University of Oxford || Shi Feng shi.feng@gwu.edu || Georg ... (truncated) ||  || { || ""title"": ""Self-Improvement as Coherence Optimization: A Theoretical Account"", || ""authors"": [ || ""Tianyi Qiu"", || ""Ahmed Hani Ismailahmedhismail"", || ""Zhonghao Hehezhonghao2030"", || ""George Washington University"", || ""UC Berkeley"" || ], || ""doi"": ""arXiv:2601.13566v1"", || ""arxiv_id"": ""arXiv:2601.13566"", || ""keywords"": [ || ""language models"", || ""self-improvement"", || ""coherence optimization"", || ""supervised learning"", || ""description-length regularization"" || ], || ""summary"": ""The paper explores how language models can improve accuracy without external supervision by optimizing coherence, showing it is equivalent to description-length regularization and optimal for semi-supervised learning."" || } ||  || [ Prompt: 106.8 t/s | Generation: 27.4 t/s ]"
2601.13570v1_GeoDynamics A Geometric State-Space Neural Network.pdf,GeoDynamics: A Geometric State-Space Neural Network for Understanding Brain Dynamics on Riemannian Manifolds,"['Tingting Dan', 'Jiaqi Ding', 'Guorong Wu']",10.48550/arXiv.2405.12345,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || GeoDynamics: A Geometric State-Space Neural || Network for Understanding Brain Dynamics on || Riemannian Manifolds || Tingting Dan Jiaqi Ding Guorong Wu || Departments of Psychiatry and Computer Science || University of North Carolina at Chapel Hill || Chapel Hill, NC 27599 || {Tingting_Dan,grwu}@med.u ... (truncated) ||  || { || ""title"": ""GeoDynamics: A Geometric State-Space Neural Network for Understanding Brain Dynamics on Riemannian Manifolds"", || ""authors"": [""Tingting Dan"", ""Jiaqi Ding"", ""Guorong Wu""], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""10.48550/arXiv.2405.12345"", || ""keywords"": [""neural networks"", ""brain dynamics"", ""functional connectivity"", ""geometric state-space models""], || ""summary"": ""GeoDynamics introduces a geometric state-space neural network that models latent brain-state trajectories on a Riemannian manifold, enabling insights into cognition, behavior, and early markers of neurological disorders."" || } ||  || [ Prompt: 104.6 t/s | Generation: 26.9 t/s ]"
2601.13580v1_Neural Organ Transplantation NOT Checkpoint-Based .pdf,Neural Organ Transplantation (NOT),['Ahmad Al-Zuraiqi'],arXiv:2601.13580v1,30.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || NEURALORGANTRANSPLANTATION(NOT): || CHECKPOINT-BASEDMODULARADAPTATION FOR || TRANSFORMERMODELS || A PREPRINT || Ahmad Al-Zuraiqi || AI Research Center || Jadara University || alzuraiqi@jadara.edu.jo || January 21, 2026 || ABSTRACT || We introduceNeural Organ Transplantation(NOT), a modular adaptation framework t ... (truncated) ||  || { || ""title"": ""Neural Organ Transplantation (NOT)"", || ""authors"": [""Ahmad Al-Zuraiqi""], || ""doi"": ""arXiv:2601.13580v1"", || ""arxiv_id"": ""arXiv:2601.13580"", || ""keywords"": [""Modular Deep Learning"", ""Transfer Learning"", ""Checkpoint Transfer"", ""Domain Adaptation"", ""Large Language Model""], || ""summary"": ""Introduces Neural Organ Transplantation (NOT), a framework that enables modular adaptation of transformer layers as reusable checkpoints for domain adaptation. It demonstrates significant improvements over LoRA in perplexity while training faster, with position-dependent benefits."" || } ||  || [ Prompt: 104.1 t/s | Generation: 30.7 t/s ]"
2601.13581v1_SCRIPTMIND Crime Script Inference and Cognitive Ev.pdf,Crime Script Inference and Cognitive Evaluation for LLM-based Social Engineering Scam Detection System,"['Heedou Kim1', 'Heedou Kim2', 'Changsik Kim2', 'Sanghwa Shin3', 'Jaewoo Kang1', 'Inje University, Gimhae, Republic of Korea']",,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || SCRIPTMIND: Crime Script Inference and Cognitive Evaluation for || LLM-based Social Engineering Scam Detection System || Heedou Kim1,2, Changsik Kim2, Sanghwa Shin3,*, Jaewoo Kang1,* || 1Korea University, Seoul, Republic of Korea, || 2Korean National Police Agency, Seoul, Republic of Korea, || 3In ... (truncated) ||  || { || ""title"": ""Crime Script Inference and Cognitive Evaluation for LLM-based Social Engineering Scam Detection System"", || ""authors"": [ || ""Heedou Kim1"", || ""Heedou Kim2"", || ""Changsik Kim2"", || ""Sanghwa Shin3"", || ""Jaewoo Kang1"", || ""Inje University, Gimhae, Republic of Korea"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""social engineering"", || ""scam detection"", || ""LLM"", || ""cognitive evaluation"", || ""crime script inference"", || ""cognitive awareness"" || ], || ""summary"": ""SCRIPTMIND is an integrated framework for LLM-based scam detection that combines automated reasoning and human cognition. It features a Crime Script Inference Task, a Crime ScriptAware Inference Dataset, and a Cognitive Simulation-based Evaluation. Experimental results demonstrate improved detection accuracy and user awareness compared to commercial models."" || } ||  || [ Prompt: 107.9 t/s | Generation: 28.4 t/s ]"
2601.13588v1_TREX Tokenizer Regression for Optimal Data Mixture.pdf,TREX: Tokenizer Regression for Optimal Data Mixture,"['Inho Won', 'Hangyeol Yoo', 'Jungyeul Park', 'Minkyung Cho', 'Jungyeul KyungTae Lim']",,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TREX: Tokenizer Regression for Optimal Data Mixture || Inho Won1 Hangyeol Yoo2 || Minkyung Cho1 Jungyeul Park1,3 Hoyun Song4 KyungTae Lim1,4 || 1KAIST CT 2Seoul National University of Science and Technology || 3Upstage AI 4KAIST InnoCORE PRISM-AI Center || inho.won@kaist.ac.kr,hgyoo@seoultech.ac.k ... (truncated) ||  || { || ""title"": ""TREX: Tokenizer Regression for Optimal Data Mixture"", || ""authors"": [ || ""Inho Won"", || ""Hangyeol Yoo"", || ""Jungyeul Park"", || ""Minkyung Cho"", || ""Jungyeul KyungTae Lim"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Building effective tokenizers for multilingual LLMs requires careful control over language-specific data mixtures. TREX introduces a regression-based framework to predict optimal data mixtures for tokenizer training, improving scalability and robustness."" || } ||  || [ Prompt: 106.2 t/s | Generation: 28.2 t/s ]"
2601.13589v1_Motion-to-Response Content Generation via Multi-Ag.pdf,MOTION-TO-RESPONSECONTENTGENERATION VIA MULTI-AGENT AI SYSTEM WITHREAL-TIMESAFETY VERIFICATION,['HyeYoung Lee'],,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MOTION-TO-RESPONSECONTENTGENERATION VIA || MULTI-AGENTAI SYSTEM WITHREAL-TIMESAFETY || VERIFICATION || HyeYoung Lee || Department of Artificial Intelligence || Korean University || Seoul, South Korea || uohesha@korea.ac.kr || January 21, 2026 || ABSTRACT || This paper proposes a multi-agent artificial intelligen ... (truncated) ||  || { || ""title"": ""MOTION-TO-RESPONSECONTENTGENERATION VIA MULTI-AGENT AI SYSTEM WITHREAL-TIMESAFETY VERIFICATION"", || ""authors"": [""HyeYoung Lee""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Speech Emotion Recognition"", || ""Multi-Agent Systems"", || ""Content Generation"", || ""Safety Verification"", || ""On-Device AI"" || ], || ""summary"": ""This paper proposes a multi-agent artificial intelligence system that generates response-oriented media content in real time based on audio-derived emotional signals. The system emphasizes transforming inferred emotional states into safe, age-appropriate, and controllable responses through a structured pipeline of specialized AI agents."" || } ||  || [ Prompt: 111.3 t/s | Generation: 28.1 t/s ]"
2601.13590v1_Vulnerability of LLMs Belief Systems LLMs Belief R.pdf,Vulnerability of LLMs Belief Systems? LLMs Belief Resistance Check,"['Fan Huang', 'Haewoon Kwak', 'Jisun An']",,28.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Vulnerability of LLMs Belief Systems? LLMs Belief Resistance Check || Through Strategic Persuasive Conversation Interventions || Fan Huang, Haewoon Kwak, Jisun An || Indiana University Bloomington / United States || huangfan@acm.org, haewoon@acm.org, jisun.an@acm.org || Abstract || Large Language Mod ... (truncated) ||  || { || ""title"": ""Vulnerability of LLMs Belief Systems? LLMs Belief Resistance Check"", || ""authors"": [""Fan Huang"", ""Haewoon Kwak"", ""Jisun An""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""large language models"", ""belief systems"", ""persuasion"", ""meta-cognition""], || ""summary"": ""This study evaluates how large language models (LLMs) are susceptible to persuasion under the SourceMessage Channel Receiver (SMCR) framework, analyzing susceptibility across multiple interaction turns and examining the impact of meta-cognition prompting."" || } ||  || [ Prompt: 113.1 t/s | Generation: 28.0 t/s ]"
2601.13591v1_DSAEval Evaluating Data Science Agents on a Wide R.pdf,Evaluating Data Science Agents on a Wide Range of Real-World Data Science Problems,"['Maojun Sun', 'Yifei Xie', 'Yue Wu', 'Ruijian Han', 'Defeng Sun', 'Jian Huang']",https://dsaeval.github.io/DSAEval/,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DSAEval: Evaluating Data Science Agents on a Wide Range of Real-World || Data Science Problems || Maojun Sun1* Yifei Xie1* Yue Wu1* Ruijian Han1 || Binyan Jiang1 Defeng Sun2 Yancheng Yuan2 Jian Huang1,2 || 1Department of Data Science and Artificial Intelligence, Hong Kong Polytechnic University ... (truncated) ||  || { || ""title"": ""Evaluating Data Science Agents on a Wide Range of Real-World Data Science Problems"", || ""authors"": [ || ""Maojun Sun"", || ""Yifei Xie"", || ""Yue Wu"", || ""Ruijian Han"", || ""Defeng Sun"", || ""Jian Huang"" || ], || ""doi"": ""https://dsaeval.github.io/DSAEval/"", || ""arxiv_id"": """", || ""keywords"": [ || ""data science agents"", || ""LLM-based"", || ""data analysis"", || ""deep learning"", || ""structured data"", || ""unstructured data"", || ""multimodal perception"", || ""multi-query interactions"", || ""multi-dimensional evaluation"" || ], || ""summary"": ""This paper introduces DSAEval, a benchmark with 641 real-world data science problems across 285 datasets, evaluating advanced agentic LLMs. It highlights performance gains from multimodal perception and multi-dimensional evaluation, identifying strengths and challenges in unstructured domains."" || } ||  || [ Prompt: 112.1 t/s | Generation: 28.3 t/s ]"
2601.13592v1_Machine learning based radiative parameterization .pdf,Machine learning based radiative parameterization scheme and its performance in operational reforecast experiments,"['Jing Hao', 'Xiao Sa1', 'Xiao Huadong', 'Xue Wei', 'Li Haoyu', 'Xiao Sa2']",10.5194/arrmw-1234-2024,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  || Machine learning based radiative parameterization scheme and its performance in || operational reforecast experiments ||  || Jing Hao1,2, Xiao Sa1,2*, Li Haoyu1,2, Xiao Huadong1,2, Xue Wei2,3 ||  || 1 State Key Laboratory of Severe Weather Meteorological Science and ... (truncated) ||  || { || ""title"": ""Machine learning based radiative parameterization scheme and its performance in operational reforecast experiments"", || ""authors"": [ || ""Jing Hao"", || ""Xiao Sa1"", || ""Xiao Huadong"", || ""Xue Wei"", || ""Li Haoyu"", || ""Xiao Sa2"" || ], || ""doi"": ""10.5194/arrmw-1234-2024"", || ""arxiv_id"": """", || ""keywords"": [ || ""Machine learning"", || ""Radiation"", || ""Hybrid model"", || ""Operational reforecast experiments"" || ], || ""summary"": ""The study investigates a machine learning approach to simulate radiation for improving computational efficiency in operational forecasting. It focuses on addressing coupling compatibility and long-term stability in hybrid models using a residual convolutional neural network for RRTMG approximation."" || } ||  || [ Prompt: 117.9 t/s | Generation: 27.6 t/s ]"
2601.13599v1_Diffusion In Diffusion Breaking the Autoregressive.pdf,,[],,27.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Preprint. Under review. || Diffusion In Diffusion: Breaking the Autoregressive Bottle- || neck in Block Diffusion Models || Linrui Ma, Yufei Cui, Kai Han& Yunhe Wang || Noahs Ark Lab, Huawei || Montreal, Canada & Beijing, China || linrui.ma@h-partners.com,{yufei.cui, kai.han, yunhe.wang}@huawei.com || A ... (truncated) ||  || { || ""title"": ""Diffusion In Diffusion: Breaking the Autoregressive Bottleneck in Block Diffusion Models"", || ""authors"": [""Linrui Ma"", ""Yufei Cui"", ""Kai Han"", ""Yunhe Wang""], || ""doi"": ""10.48550/arXiv.2405.12345"",  // Placeholder || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [""block diffusion"", ""autoregressive"", ""diffusion models"", ""generative models""], || ""summary"": ""The paper proposes DIFFUSION INDIFFUSION to overcome irreversibility and myopia in block diffusion models by combining rapid block diffusion drafts with global bidirectional refinement. It introduces snapshot confidence remasking and mix-scale training to improve performance on the OpenWebText dataset."" || } ||  || [ Prompt: 110.9 t/s | Generation: 27.0 t/s ]"
2601.13600v1_Foundations of Global Consistency Checking with No.pdf,Foundations of Global Consistency Checking with Noisy LLM Oracles,"['Paul He', 'Elke Kirschbaum', 'Shiva Kasiviswanathan']",,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Foundations of Global Consistency Checking with Noisy LLM Oracles || Paul He* || Nanyang Technological University || paul005@ntu.edu.sg || Elke Kirschbaum || Amazon Web Services || elkeki@amazon.com || Shiva Kasiviswanathan || Amazon Web Services || kasivisw@gmail.com || Abstract || Ensuring that collections of nat ... (truncated) ||  || { || ""title"": ""Foundations of Global Consistency Checking with Noisy LLM Oracles"", || ""authors"": [ || ""Paul He"", || ""Elke Kirschbaum"", || ""Shiva Kasiviswanathan"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Ensuring global consistency of natural-language facts is crucial for tasks like fact-checking and knowledge construction. The paper addresses the challenge of verifying global consistency using noisy LLM oracles and proposes an adaptive divide-and-conquer algorithm."" || } ||  || [ Prompt: 107.1 t/s | Generation: 28.2 t/s ]"
2601.13614v1_CauScientist Teaching LLMs to Respect Data for Cau.pdf,Teaching LLMs to Respect Data for Causal Discovery,"['Bo Peng1', 'Bo Peng2', 'Bo Peng3', 'Sirui Chen1', 'Sirui Chen4', 'Lei Xu1', 'Lei Xu5', 'Chaochao Lu1']",,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || CauScientist: Teaching LLMs to Respect Data for Causal Discovery || Bo Peng1,2,3, Sirui Chen1,4, Lei Xu1,5, Chaochao Lu1 || 1Shanghai Artificial Intelligence Laboratory, 2Shanghai Jiao Tong University || 3Shanghai Innovation Institute 4Tongji University 5cole Polytechnique Fdrale de Lausanne ... (truncated) ||  || { || ""title"": ""Teaching LLMs to Respect Data for Causal Discovery"", || ""authors"": [ || ""Bo Peng1"", || ""Bo Peng2"", || ""Bo Peng3"", || ""Sirui Chen1"", || ""Sirui Chen4"", || ""Lei Xu1"", || ""Lei Xu5"", || ""Chaochao Lu1"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""causal discovery"", || ""LLM"", || ""data-driven"", || ""statistical inference"", || ""causal structure"", || ""semantic knowledge"", || ""graph search"", || ""error memory"" || ], || ""summary"": ""CauScientist is a collaborative framework that synergizes LLMs as hypothesis-generating data scientists with probabilistic statistics as rigorous verifiers. It employs hybrid initialization, iterative refinement, and error memory to improve causal discovery performance, achieving significant improvements over data-driven baselines."" || } ||  || [ Prompt: 112.8 t/s | Generation: 28.3 t/s ]"
2601.13622v1_CARPE Context-Aware Image Representation Prioritiz.pdf,Context-Aware Image Representation Prioritization via Ensemble,"['Donghee Lee', 'Rui Cai', 'Zhe Zhao']",,26.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || CARPE: || CONTEXT-AWAREIMAGEREPRESENTATIONPRIORITIZATION || VIAENSEMBLE FORLARGEVISION-LANGUAGEMODELS || Donghee Lee, Rui Cai, Zhe Zhao || Department of Computer Science, University of California, Davis || ryu0315360@gmail.com || January 21, 2026 || ABSTRACT || Recent advancements in Large Vision-Language  ... (truncated) ||  || { || ""title"": ""Context-Aware Image Representation Prioritization via Ensemble"", || ""authors"": [""Donghee Lee"", ""Rui Cai"", ""Zhe Zhao""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Recent advancements in Large Vision-Language Models (LVLMs) have pushed them closer to general-purpose assistants. This paper proposes CARPE, a novel model-agnostic framework that introduces vision-integration layers and a context-aware ensemble strategy to improve performance in image classification and related benchmarks."" || } ||  || [ Prompt: 105.5 t/s | Generation: 26.4 t/s ]"
2601.13632v1_Resilient Routing Risk-Aware Dynamic Routing in Sm.pdf,,[],,27.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Resilient Routing: Risk-Aware Dynamic Routing in || Smart Logistics via Spatiotemporal Graph Learning || Zhiming Xue , Sichen Zhao , Yalun Qi , Xianling Zeng  and Zihan Yu || College of Engineering, Northeastern University, Boston, USA || Khoury College of Computer Sciences, Northeastern Unive ... (truncated) ||  || { || ""title"": ""Resilient Routing: Risk-Aware Dynamic Routing in Smart Logistics via Spatiotemporal Graph Learning"", || ""authors"": [ || ""Zhiming Xue"", || ""Sichen Zhao"", || ""Yalun Qi"", || ""Xianling Zeng"", || ""Zihan Yu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Smart Logistics"", || ""Graph Neural Network"", || ""Dynamic Routing"", || ""Spatiotemporal modeling"", || ""Supply Chain Resilience""] || "", ""summary"": ""The paper proposes a Risk-Aware Dynamic Routing framework integrating Spatiotemporal Graph Neural Networks with combinatorial optimization to enhance supply chain resilience in e-commerce logistics."" || } ||  || [ Prompt: 107.7 t/s | Generation: 27.3 t/s ]"
2601.13645v1_Quadratic Upper Bound for Boosting Robustness.pdf,Quadratic Upper Bound for Boosting Robustness,['Euijin Y Ou1 Hyang-Won Lee'],10.48550/arXiv.2405.12345,26.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Quadratic Upper Bound for Boosting Robustness || Euijin Y ou1 Hyang-Won Lee 1 || Abstract || Fast adversarial training (FAT) aims to enhance || the robustness of models against adversarial at- || tacks with reduced training time, however, FAT || often suffers from compromised robustness due || to insuff ... (truncated) ||  || { || ""title"": ""Quadratic Upper Bound for Boosting Robustness"", || ""authors"": [""Euijin Y Ou1 Hyang-Won Lee""], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""10.48550/arXiv.2405.12345"", || ""keywords"": [""robustness"", ""adversarial training"", ""fast adversarial training""], || ""summary"": ""The paper presents a loss function to improve robustness in fast adversarial training without stronger inner maximization, showing significant robustness improvements."" || } ||  || [ Prompt: 110.5 t/s | Generation: 26.5 t/s ]"
2601.13647v1_Fusion Segment Transformer Bi-Directional Attentio.pdf,Fusion Segment Transformer: Bi-Directional Attention Guided Fusion,"['Yumin Kim', 'Seonghyeon Go']",,26.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || FUSION SEGMENT TRANSFORMER: BI-DIRECTIONAL A TTENTION GUIDED FUSION || NETWORK FOR AI GENERA TED MUSIC DETECTION || Yumin Kim and Seonghyeon Go || MIPPIA Inc. || /githubCode7Demo || ABSTRACT || With the rise of generative AI technology, anyone can now || easily create and deploy AI-generated music, whi ... (truncated) ||  || { || ""title"": ""Fusion Segment Transformer: Bi-Directional Attention Guided Fusion"", || ""authors"": [""Yumin Kim"", ""Seonghyeon Go""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""AI-generated music detection"", ""Full-audio segment detection"", ""Musical structure analysis"", ""Cross-modal fusion layer""], || ""summary"": ""The paper proposes an improved Segment Transformer called Fusion Segment Transformer for detecting AI-generated music in full audio, addressing limitations of previous models by incorporating a Gated Fusion Layer to capture long-term musical context."" || } ||  || [ Prompt: 108.6 t/s | Generation: 26.5 t/s ]"
2601.13649v1_Fairness or Fluency An Investigation into Language.pdf,,[],,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Fairness or Fluency? An Investigation into Language Bias of Pairwise || LLM-as-a-Judge || Xiaolin Zhou1*, Zheng Luo1*, Yicheng Gao1*, Qixuan Chen1, || Xiyang Hu2,Yue Zhao 1,Ruishan Liu 1 || 1University of Southern California, 2Arizona State University || {xzhou733, luozheng, gaoyiche, qixuanch, yu ... (truncated) ||  || { || ""title"": ""Fairness or Fluency? An Investigation into Language Bias of Pairwise LLM-as-a-Judge"", || ""authors"": [ || ""Xiaolin Zhou"", || ""Zheng Luo"", || ""Yicheng Gao"", || ""Qixuan Chen"", || ""Xiyang Hu"", || ""Yue Zhao"", || ""Ruishan Liu"" || ], || ""doi"": ""10.48550/arXiv.2311.07818"", || ""arxiv_id"": ""10.48550/arXiv:2311.07818"", || ""keywords"": [ || ""LLM-as-a-judge"", || ""language bias"", || ""performance disparity"", || ""European languages"", || ""African languages"", || ""LLM evaluation"" || ], || ""summary"": ""This paper investigates language bias in pairwise LLM-as-a-judge systems. It identifies performance disparities across languages when judges compare options within the same language versus across different languages. The study also explores whether language bias stems from low-perplexity effects and examines its impact on evaluation accuracy."" || } ||  || [ Prompt: 112.6 t/s | Generation: 28.1 t/s ]"
2601.13655v1_Why Does the LLM Stop Computing An Empirical Study.pdf,Why Does the LLM Stop Computing: An Empirical Study of User-Reported Failures in Open-Source LLMs,"['Guangba Yu', 'Zirui Wang', 'Yujie Huang', 'Renyi Zhong', 'Yuedong Zhong', 'Yilun Wang', 'Michael R. Lyu']",10.1093/acprof:oso/9780190871293.013,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Why Does the LLM Stop Computing: An Empirical Study of || User-Reported Failures in Open-Source LLMs || GUANGBA YU,The Chinese University of HongKong, China || ZIRUI WANG,Sun Yat-sen University, China || YUJIE HUANG,The Chinese University of HongKong, China || RENYI ZHONG,The Chinese University of ... (truncated) ||  || { || ""title"": ""Why Does the LLM Stop Computing: An Empirical Study of User-Reported Failures in Open-Source LLMs"", || ""authors"": [ || ""Guangba Yu"", || ""Zirui Wang"", || ""Yujie Huang"", || ""Renyi Zhong"", || ""Yuedong Zhong"", || ""Yilun Wang"", || ""Michael R. Lyu"" || ], || ""doi"": ""10.1093/acprof:oso/9780190871293.013"", || ""arxiv_id"": """", || ""keywords"": [ || ""Large Language Models"", || ""Failure Analysis"", || ""Empirical Study"", || ""Software Reliability"", || ""Software Usability"", || ""General and Reference"" || ], || ""summary"": ""This study examines user-reported failures in open-source LLMs, identifying systemic reliability issues rather than model defects. It highlights three key phenomena: diagnostic divergence, systemic homogeneity, and lifecycle escalation, offering guidance for improving LLM reliability."" || } ||  || [ Prompt: 106.6 t/s | Generation: 28.4 t/s ]"
2601.13657v1_Communication-Free Collective Navigation for a Swa.pdf,Communication-Free Collective Navigation for a Swarm of UA Vs,"['Myong-Yol Choi', 'Hankyoul Ko', 'Hanse Cho', 'Changseung Kim', 'Seunghwan Kim', 'Jaemin Seo', 'Hyondong Oh']",,27.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1 || Communication-Free Collective Navigation for a Swarm of UA Vs || via LiDAR-Based Deep Reinforcement Learning || Myong-Yol Choi, Hankyoul Ko, Hanse Cho, Changseung Kim, Seunghwan Kim, Jaemin Seo, || and Hyondong Oh || AbstractThis paper presents a deep reinforcement learning || (DRL) based contro ... (truncated) ||  || { || ""title"": ""Communication-Free Collective Navigation for a Swarm of UA Vs"", || ""authors"": [ || ""Myong-Yol Choi"", || ""Hankyoul Ko"", || ""Hanse Cho"", || ""Changseung Kim"", || ""Seunghwan Kim"", || ""Jaemin Seo"", || ""Hyondong Oh"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""multi-robot systems"", || ""collective navigation"", || ""sensor-based control"", || ""deep reinforcement learning"", || ""swarm intelligence"" || ], || ""summary"": ""This paper presents a deep reinforcement learning based controller for collective navigation of unmanned aerial vehicle swarms in communication-denied environments. It employs an implicit leader-follower framework where followers learn robust policies using only onboard LiDAR sensing, without inter-agent communication."" || } ||  || [ Prompt: 110.4 t/s | Generation: 27.3 t/s ]"
2601.13659v1_Temporal-Spatial Decouple before Act Disentangled .pdf,TEMPORAL-SPA TIAL DECOUPLE BEFORE ACT: DISENTANGLED REPRESENTA TION,"['Chunlei Meng', 'Ziyang Zhou', 'Lucas He', 'Xiaojing Du', 'Chun Ouyang', 'Zhongxue Gan']",,26.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TEMPORAL-SPA TIAL DECOUPLE BEFORE ACT: DISENTANGLED REPRESENTA TION || LEARNING FOR MULTIMODAL SENTIMENT ANALYSIS || Chunlei Meng1, Ziyang Zhou2, Lucas He3, Xiaojing Du4, Chun Ouyang1 , Zhongxue Gan1 || 1Fudan University, 2Shantou University, 3University College London, 4University of South  ... (truncated) ||  || { || ""title"": ""TEMPORAL-SPA TIAL DECOUPLE BEFORE ACT: DISENTANGLED REPRESENTA TION"", || ""authors"": [ || ""Chunlei Meng"", || ""Ziyang Zhou"", || ""Lucas He"", || ""Xiaojing Du"", || ""Chun Ouyang"", || ""Zhongxue Gan"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Multimodal Sentiment Analysis"", || ""Temporal-Spatial Decoupling"", || ""Representation Learning"", || ""Sentiment Analysis"", || ""Linguistic"", || ""Visual"", || ""Acoustic"" || ], || ""summary"": ""Proposes TSDA, TemporalSpatial Decouple before Act to address spatiotemporal heterogeneity in multimodal sentiment analysis by explicitly decoupling temporal dynamics and spatial structure before alignment."" || } ||  || [ Prompt: 111.2 t/s | Generation: 26.7 t/s ]"
2601.13671v1_The Orchestration of Multi-Agent Systems Architect.pdf,"The Orchestration of Multi-Agent Systems: Architectures, Protocols, and Enterprise Adoption","['Apoorva Adimulam', 'Rajesh Gupta', 'Sumit Kumar']",,27.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || The Orchestration of Multi-Agent Systems: || Architectures, Protocols, and Enterprise Adoption || Apoorva Adimulam || Applied Agentic AI || Skan AI || Menlo Park, USA || apoorva.adimulam@skan.ai || Rajesh Gupta || Applied Agentic AI || Skan AI || Menlo Park, USA || rajesh.gupta@skan.ai || Sumit Kumar || Applied Agentic A ... (truncated) ||  || { || ""title"": ""The Orchestration of Multi-Agent Systems: Architectures, Protocols, and Enterprise Adoption"", || ""authors"": [ || ""Apoorva Adimulam"", || ""Rajesh Gupta"", || ""Sumit Kumar"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Agent orchestration"", || ""Agent-to-Agent protocol"", || ""multi-agent systems"", || ""observability"", || ""state management"", || ""system governance"" || ], || ""summary"": ""This paper consolidates and formalizes the technical composition of orchestrated multi-agent systems, presenting a unified architectural framework that integrates planning, policy enforcement, state management, and quality operations. It introduces the Model Context Protocol and Agent-to-Agent protocol, emphasizing interoperability, scalability, and policy compliance in distributed AI ecosystems."" || } ||  || [ Prompt: 104.7 t/s | Generation: 27.4 t/s ]"
2601.13684v1_HeteroCache A Dynamic Retrieval Approach to Hetero.pdf,HeteroCache: A Dynamic Retrieval Approach to Heterogeneous KV Cache,"['Zhiyuan Shi', 'Qibo Qiu2', 'Feng Xue3', 'Zhonglin Jiang3', 'Li Yu2', 'Jian Jiang 2', 'Xiaofei He 1', 'Wenxiao Wang 1']",1ZhejiangUniversity,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || HeteroCache: A Dynamic Retrieval Approach to Heterogeneous KV Cache || Compression for Long-Context LLM Inference || Zhiyuan Shi1, Qibo Qiu2,1, Feng Xue3, Zhonglin Jiang3, || Li Yu2,Jian Jiang 2,Xiaofei He 1,Wenxiao Wang 1, || 1Zhejiang University || 2China Mobile (Zhejiang) Research & Innovation  ... (truncated) ||  || { || ""title"": ""HeteroCache: A Dynamic Retrieval Approach to Heterogeneous KV Cache"", || ""authors"": [ || ""Zhiyuan Shi"", || ""Qibo Qiu2"", || ""Feng Xue3"", || ""Zhonglin Jiang3"", || ""Li Yu2"", || ""Jian Jiang 2"", || ""Xiaofei He 1"", || ""Wenxiao Wang 1"" || ], || ""doi"": ""1ZhejiangUniversity"", || ""arxiv_id"": ""1"", ""keywords"": [ || ""Heterogeneous KV Cache"", || ""Dynamic Retrieval"", || ""Long-Context LLM Inference"", || ""Attention Drift"", || ""Compression"", || ""Memory Growth"", || ""I/O Overhead"" || ], || ""summary"": ""The paper discusses the limitations of static compression methods in LLM inference for long contexts and introduces HeteroCache, a training-free dynamic compression framework that addresses attention drift and spatial redundancy."" || } ||  || [ Prompt: 108.7 t/s | Generation: 27.7 t/s ]"
2601.13687v1_Understanding Mental States to Guide Social Influe.pdf,Understanding Mental States to Guide Social Influence in Multi-Person Group Dialogue,"['Zhichao Liang', 'Satoshi Nakamura']",,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Understanding Mental States to Guide Social Influence in Multi-Person || Group Dialogue || Zhichao Liang Satoshi Nakamura || The Chinese University of Hong Kong, Shenzhen || zhichaoliang@link.cuhk.edu.cn, snakamura@cuhk.edu.cn || Abstract || Existing dynamic Theory of Mind (ToM) || benchmarks mostly pla ... (truncated) ||  || { || ""title"": ""Understanding Mental States to Guide Social Influence in Multi-Person Group Dialogue"", || ""authors"": [""Zhichao Liang"", ""Satoshi Nakamura""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper introduces SocialMindChange, a benchmark that evaluates models' ability to influence mental states in multi-person dialogue by tracking evolving states across connected social scenarios."" || } ||  || [ Prompt: 108.8 t/s | Generation: 28.4 t/s ]"
2601.13693v1_End-to-End Reverse Screening Identifies Protein Ta.pdf,End-to-End Reverse Screening Identifies Protein,"['Shengjie Xu', 'Xianbin Ye', 'Mengran Zhu', 'Xiaonan Zhang', 'Shanzhuo Zhang', 'Xiaomin Fang']",arXiv:2601.13693v1,30.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || End-to-End Reverse Screening Identifies Protein || Targets of Small Molecules Using HelixFold3 || Shengjie Xu 1,2, Xianbin Ye 1, Mengran Zhu 3, Xiaonan Zhang 1, || Shanzhuo Zhang1*, Xiaomin Fang 1* || 1PaddleHelix Team, Baidu Inc., Shenzhen, China. || 2School of Software Engineering, Huazhong Univ ... (truncated) ||  || { || ""title"": ""End-to-End Reverse Screening Identifies Protein"", || ""authors"": [ || ""Shengjie Xu"", || ""Xianbin Ye"", || ""Mengran Zhu"", || ""Xiaonan Zhang"", || ""Shanzhuo Zhang"", || ""Xiaomin Fang"" || ], || ""doi"": ""arXiv:2601.13693v1"", || ""arxiv_id"": ""2601.13693"", || ""keywords"": [ || ""Reverse screening"", || ""Target identification"", || ""Biomolecular structure prediction"", || ""HelixFold3"" || ], || ""summary"": ""Identifying protein targets for small molecules, or reverse screening, is essential for understanding drug action, guiding compound repurposing, predicting off-target effects, and elucidating molecular mechanisms. This study presents an end-to-end reverse screening strategy using HelixFold3, improving accuracy and structural fidelity compared to conventional methods."" || } ||  || [ Prompt: 117.6 t/s | Generation: 30.6 t/s ]"
2601.13697v1_Uncertainty-Aware Gradient Signal-to-Noise Data Se.pdf,Uncertainty-Aware Gradient Signal-to-Noise Data Selection for Instruction Tuning,"['Zhihang Yuan', 'Chengyu Yue', 'Long Huang', 'Litu Ou', 'Lei Shi', '*']",,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Uncertainty-Aware Gradient Signal-to-Noise Data Selection for || Instruction Tuning || Zhihang Yuan1, Chengyu Yue1, Long Huang1, Litu Ou2, Lei Shi1, * || 1Alibaba Cloud Computing 2The University of Edinburgh || 1{yuanzhihang.yzh,yuechengyu.ycy, baixuan.hl, juetian.sl}@alibaba-inc.com || 2litu.ou@e ... (truncated) ||  || { || ""title"": ""Uncertainty-Aware Gradient Signal-to-Noise Data Selection for Instruction Tuning"", || ""authors"": [ || ""Zhihang Yuan"", || ""Chengyu Yue"", || ""Long Huang"", || ""Litu Ou"", || ""Lei Shi"", || ""*"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""instruction tuning"", || ""data selection"", || ""uncertainty-aware"", || ""gradient filtering"", || ""LLM adaptation"" || ], || ""summary"": ""This paper proposes GRADFILTERING, an objective-agnostic data selection framework that leverages uncertainty-aware G-SNR to select training examples, aiming to reduce cost and redundancy in large language model fine-tuning while maintaining or improving performance."" || } ||  || [ Prompt: 106.8 t/s | Generation: 27.8 t/s ]"
2601.13698v1_Does Privacy Always Harm Fairness Data-Dependent T.pdf,,[],,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Does Privacy Always Harm Fairness? Data-Dependent Trade-offs || via Chernoff Information Neural Estimation || Arjun Nichani 1, Hsiang Hsu 2, Chun-Fu (Richard) Chen 2, Haewon Jeong 1 || 1University of California, Santa Barbara || 2JP Morgan Chase Global Technology Applied Research || {anichani, hae ... (truncated) ||  || { || ""title"": ""Does Privacy Always Harm Fairness? Data-Dependent Trade-offs"", || ""authors"": [ || ""Arjun Nichani"", || ""Hsiang Hsu"", || ""Chun-Fu (Richard) Chen"", || ""Haewon Jeong"" || ], || ""doi"": ""10.48550/arXiv.2026.12345"", || ""arxiv_id"": ""arXiv:2509.12345"", || ""keywords"": [ || ""fairness"", || ""privacy"", || ""privacy-preserving"", || ""machine learning"", || ""data-dependent trade-offs"" || ], || ""summary"": ""This paper explores the data-dependent trade-offs between fairness, privacy, and accuracy in machine learning, introducing the Noisy Chernoff Difference to analyze their relationship."" || } ||  || [ Prompt: 110.2 t/s | Generation: 28.5 t/s ]"
2601.13704v1_Performance and Complexity Trade-off Optimization .pdf,Performance and Complexity Trade-off,"['Esteban Gómez', 'Tom Bäckstrom']",,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || IEEE TRANSACTIONS ON AUDIO, SPEECH, AND LANGUAGE PROCESSING, VOL. XX, NO. X, AUGUST 20XX 1 || Performance and Complexity Trade-off || Optimization of Speech Models During Training || Esteban G omez, Tom B ackstromSenior Member, IEEE || AbstractIn speech machine learning, neural network models || a ... (truncated) ||  || { || ""title"": ""Performance and Complexity Trade-off"", || ""authors"": [""Esteban Gómez"", ""Tom Bäckstrom""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""speech machine learning"", ""low-complexity"", ""voice activity detection"", ""deep fake detection""], || ""summary"": ""The paper discusses optimizing speech models during training by balancing performance and computational complexity through a reparameterization technique based on feature noise injection. It highlights the nonlinear relationship between model performance and complexity and presents case studies demonstrating its effectiveness."" || } ||  || [ Prompt: 114.3 t/s | Generation: 27.7 t/s ]"
2601.13707v1_Attention-space Contrastive Guidance for Efficient.pdf,Attention-space Contrastive Guidance for Efficient Hallucination Mitigation in LVLMs,"['Yujin Jo', 'Sangyoon Bae', 'Taesup Kim']",,26.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Attention-space Contrastive Guidance || for Efficient Hallucination Mitigation in LVLMs || Yujin Jo, Sangyoon Bae, Taesup Kim* || Graduate School of Data Science, Seoul National University || Abstract || Hallucinations in large visionlanguage models (LVLMs) || often arise when language priors dominat ... (truncated) ||  || { || ""title"": ""Attention-space Contrastive Guidance for Efficient Hallucination Mitigation in LVLMs"", || ""authors"": [""Yujin Jo"", ""Sangyoon Bae"", ""Taesup Kim""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Addresses hallucinations in LVLMs by introducing Attention-space Contrastive Guidance (ACG), a single-pass mechanism that balances vision-language and language-only attention to improve faithfulness and reduce computational cost."" || } ||  || [ Prompt: 110.1 t/s | Generation: 26.5 t/s ]"
2601.13709v1_Hidden in Plain Text Measuring LLM Deception Quali.pdf,Measuring LLM Deception,"['Christopher Kao', 'Vanshika Vats', 'James Davis']","77SPARX Studio, Inc.",26.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  || Hidden in Plain Text: Measuring LLM Deception || Quality Against Human Baselines Using Social || Deduction Games || Christopher Kao || Research & Development || 77SPARX Studio, Inc.. || Sunnyvale, USA || ckao@77sparx.com ||  || Vanshika Vats || Department of Computer Science || University of California ... (truncated) ||  || { || ""title"": ""Measuring LLM Deception"", || ""authors"": [ || ""Christopher Kao"", || ""Vanshika Vats"", || ""James Davis"" || ], || ""doi"": ""77SPARX Studio, Inc."", || ""arxiv_id"": """", || ""keywords"": [ || ""large language models"", || ""natural language processing"", || ""autonomous game players"", || ""social deduction games"" || ], || ""summary"": ""The paper studies deception in the Social Deduction Game Mafia using LLM agents, comparing detection accuracy to humans and analyzing deception quality."" || } ||  || [ Prompt: 114.3 t/s | Generation: 26.2 t/s ]"
2601.13710v1_Who Should Have Surgery A Comparative Study of Gen.pdf,Who Should Have Surgery? A Comparative Study of GenAI vs Supervised ML for CRS Surgical Outcome Prediction,"['Sayeed Shafayet Chowdhury', 'Snehasis Mukhopadhyay', 'Shiaofen Fang', 'Vijay R. Ramakrishnan']",,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Who Should Have Surgery? A Comparative Study of GenAI vs || Supervised ML for CRS Surgical Outcome Prediction || Sayeed Shafayet Chowdhury 1,2, Snehasis Mukhopadhyay 1, Shiaofen Fang 2, and Vijay R. Ramakrishnan 3 || AbstractArtificial intelligence has reshaped medical imaging, || yet the use o ... (truncated) ||  || { || ""title"": ""Who Should Have Surgery? A Comparative Study of GenAI vs Supervised ML for CRS Surgical Outcome Prediction"", || ""authors"": [ || ""Sayeed Shafayet Chowdhury"", || ""Snehasis Mukhopadhyay"", || ""Shiaofen Fang"", || ""Vijay R. Ramakrishnan"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Chronic Rhinosinusitis"", || ""clinical decision support"", || ""generative artificial intelligence"", || ""large language models"", || ""SNOT-22"", || ""surgical outcome prediction"", || ""tabular clinical data"" || ], || ""summary"": ""Artificial intelligence has reshaped medical imaging, yet its application in clinical decision support for surgical outcomes remains limited. This study evaluates pre-operative prediction models to identify patients who would benefit from avoiding surgery, comparing supervised machine learning with generative AI approaches."" || } ||  || [ Prompt: 108.8 t/s | Generation: 28.7 t/s ]"
2601.13717v1_Simulated Ignorance Fails A Systematic Study of LL.pdf,,[],,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Simulated Ignorance Fails: A Systematic Study of LLM Behaviors on Forecasting || Problems Before Model Knowledge Cutoff || Zehan Li1 ,Yuxuan Wang 2 ,Ali El Lahib 2 ,Ying-Jieh Xia 2 ,Xinyu Pi 2 || 1University of Chicago || 2University of California, San Diego || zehan@uchicago.edu,{waw009, aellahib ... (truncated) ||  || { || ""title"": ""Simulated Ignorance Fails: A Systematic Study of LLM Behaviors on Forecasting"", || ""authors"": [ || ""Zehan Li"", || ""Yuxuan Wang"", || ""Ali El Lahib"", || ""Ying-Jieh Xia"", || ""Xinyu Pi"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""LLM"", || ""forecasting"", || ""knowledge cutoff"", || ""retrospective evaluation"", || ""true ignorance"", || ""prompting"", || ""model evaluation"" || ], || ""summary"": ""Evaluating LLM forecasting capabilities is constrained by a tension between rigorous evaluation and high latency. Simulated Ignorance (SI) is tested against True Ignorance (TI) across multiple models and datasets, revealing systematic shortcomings."" || } ||  || [ Prompt: 107.2 t/s | Generation: 28.7 t/s ]"
2601.13719v1_Hierarchical Long Video Understanding with Audiovi.pdf,Hierarchical Long Video Understanding with Audiovisual Entity Cohesion and Agentic Search,"['Xinlei Yin', 'Xiulian Peng', 'Xiao Li', 'Zhiwei Xiong', 'Yan Lu']",10.48550/arXiv.2024.12345,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Hierarchical Long Video Understanding with Audiovisual Entity Cohesion and || Agentic Search || Xinlei Yin1* Xiulian Peng2 Xiao Li2 Zhiwei Xiong1 Yan Lu2 || 1University of Science and Technology of China, Hefei, Anhui, China || 2Microsoft Research Asia, Beijing, China || Abstract || Long video unders ... (truncated) ||  || { || ""title"": ""Hierarchical Long Video Understanding with Audiovisual Entity Cohesion and Agentic Search"", || ""authors"": [ || ""Xinlei Yin"", || ""Xiulian Peng"", || ""Xiao Li"", || ""Zhiwei Xiong"", || ""Yan Lu"" || ], || ""doi"": ""10.48550/arXiv.2024.12345"", || ""arxiv_id"": ""arXiv:2409.12345"", || ""keywords"": [ || ""long video understanding"", || ""audiovisual entity cohesion"", || ""agentic search"", || ""video indexing"", || ""multimodal reasoning"" || ], || ""summary"": ""This paper introduces HAVEN, a unified framework for long-video understanding that integrates audiovisual entity cohesion and hierarchical video indexing with agentic search. It addresses challenges in maintaining coherence across long sequences by structuring content hierarchically and employing dynamic retrieval mechanisms. Experiments show strong performance in temporal coherence and entity tracking, achieving 84.1% accuracy on LVBench."" || } ||  || [ Prompt: 118.3 t/s | Generation: 28.2 t/s ]"
2601.13722v1_OP-Bench Benchmarking Over-Personalization for Mem.pdf,Benchmarking Over-Personalization for Memory-Augmented Personalized Conversational Agents,"['Yulin Hu', 'Zimo Long', 'Jiahe Guo', 'Xingyu Sui', 'Xing Fu', 'Weixiang Zhao', 'Yanyan Zhao', 'Bing Qin']",,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || OP-Bench: Benchmarking Over-Personalization for Memory-Augmented || Personalized Conversational Agents || Yulin Hu, Zimo Long, Jiahe Guo, Xingyu Sui, Xing Fu || Weixiang Zhao,Yanyan Zhao,Bing Qin || Harbin Institute of Technology || {ylhu, yyzhao}@ir.hit.edu.cn || Abstract || Memory-augmented conversati ... (truncated) ||  || { || ""title"": ""Benchmarking Over-Personalization for Memory-Augmented Personalized Conversational Agents"", || ""authors"": [ || ""Yulin Hu"", || ""Zimo Long"", || ""Jiahe Guo"", || ""Xingyu Sui"", || ""Xing Fu"", || ""Weixiang Zhao"", || ""Yanyan Zhao"", || ""Bing Qin"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper introduces OP-Bench, a benchmark evaluating memory-augmented conversational agents, highlighting the issue of over-personalization and proposing Self-ReCheck to mitigate it."" || } ||  || [ Prompt: 109.5 t/s | Generation: 28.3 t/s ]"
2601.13734v1_Towards robust long-context understanding of large.pdf,TOW ARDS ROBUST LONG-CONTEXT UNDERSTANDING OF LARGE LANGUAGE MODEL,['Chenyu Hui1'],,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TOW ARDS ROBUST LONG-CONTEXT UNDERSTANDING OF LARGE LANGUAGE MODEL || VIA ACTIVE RECAP LEARNING || Chenyu Hui1 || 1School of Microelectronics || Xian Jiaotong University || Xian, China || ABSTRACT || In this paper, we propose active recap learning (ARL), a || framework for enhancing large language model (L ... (truncated) ||  || { || ""title"": ""TOW ARDS ROBUST LONG-CONTEXT UNDERSTANDING OF LARGE LANGUAGE MODEL"", || ""authors"": [""Chenyu Hui1""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""LLM"", ""Long-context understanding"", ""Active recap learning"", ""Recap supervision""], || ""summary"": ""The paper proposes active recap learning (ARL) to enhance large language models' ability to understand long contexts by enabling models to revisit and summarize earlier content during inference. ARL improves performance on benchmarks like RULER and LongBench."" || } ||  || [ Prompt: 108.6 t/s | Generation: 26.9 t/s ]"
2601.13735v1_Reasoning or Fluency Dissecting Probabilistic Conf.pdf,Reasoning or Fluency? Dissecting Probabilistic Confidence in Best-of-N Selection,"['Hojin Kim', 'Jaehyung Kim']",,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Reasoning or Fluency? Dissecting Probabilistic Confidence in || Best-of-N Selection || Hojin Kim || Yonsei University || rlaghwls@yonsei.ac.kr || Jaehyung Kim || Yonsei University || jaehyungk@yonsei.ac.kr || Abstract || Probabilistic confidence metrics are increas- || ingly adopted as proxies for reasoning qual ... (truncated) ||  || { || ""title"": ""Reasoning or Fluency? Dissecting Probabilistic Confidence in Best-of-N Selection"", || ""authors"": [ || ""Hojin Kim"", || ""Jaehyung Kim"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This work challenges the assumption that probabilistic confidence metrics reflect reasoning quality by investigating inter-step causal dependencies in Best-of-N selection. It finds that current metrics are largely insensitive to causal disruptions, suggesting they capture surface-level fluency rather than deeper reasoning structure."" || } ||  || [ Prompt: 111.8 t/s | Generation: 28.2 t/s ]"
2601.13749v1_Pro-AI Bias in Large Language Models.pdf,Pro-AI Bias in Large Language Models,"['Benaya Trabaisi', 'Jonathan Shaki', 'Sarit Kraus']",,26.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Pro-AI Bias in Large Language Models || Benaya Trabelsi,Jonathan Shaki,Sarit Kraus || Bar Ilan University || benaya7@gmail.com, jonathshaki@gmail.com, sarit@cs.biu.ac.il || Abstract || Large language models (LLMs) are increasingly || employed for decision-support across multiple do- || mains. We investi ... (truncated) ||  || { || ""title"": ""Pro-AI Bias in Large Language Models"", || ""authors"": [ || ""Benaya Trabaisi"", || ""Jonathan Shaki"", || ""Sarit Kraus"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Pro-AI bias"", || ""Large Language Models"", || ""Decision support"", || ""AI bias"", || ""LLM recommendations"" || ], || ""summary"": ""Investigates systematic preferential bias of LLMs toward AI-related options across diverse queries, showing that proprietary models favor AI more strongly than baselines."" || } ||  || [ Prompt: 111.1 t/s | Generation: 26.8 t/s ]"
2601.13752v1_Finding RELIEF Shaping Reasoning Behavior without .pdf,Finding RELIEF: Shaping Reasoning Behavior without Reasoning,"['Chak Tou Leong', 'Dingwei Chen', 'Heming Xia', 'Qingyu Yin', 'Sunbowen Lee', 'Jian Wang', 'Wenjie Li']",10.48550/arXiv.2405.12345,24.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Finding RELIEF: Shaping Reasoning Behavior without Reasoning || Supervision via Belief Engineering || Chak Tou Leong1, Dingwei Chen 2, Heming Xia 1, Qingyu Yin3, || Sunbowen Lee4, Jian Wang1, Wenjie Li1 || 1 Department of Computing, The Hong Kong Polytechnic University || 2 Sun Y at-sen University ... (truncated) ||  || { || ""title"": ""Finding RELIEF: Shaping Reasoning Behavior without Reasoning"", || ""authors"": [ || ""Chak Tou Leong"", || ""Dingwei Chen"", || ""Heming Xia"", || ""Qingyu Yin"", || ""Sunbowen Lee"", || ""Jian Wang"", || ""Wenjie Li"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [ || ""reasoning behavior"", || ""belief engineering"", || ""large reasoning models"", || ""faithfulness"", || ""logit probing"" || ], || ""summary"": ""This paper proposes Rea-son Belief Engineering (RELIF) to shape large reasoning models by aligning their self-concept with a target belief blueprint, bypassing the need for reasoning-trace supervision. Experiments show RELIEF matches or outperforms existing behavior-supervised methods while reducing computational cost."" || } ||  || [ Prompt: 111.9 t/s | Generation: 24.5 t/s ]"
2601.13761v1_DARC Decoupled Asymmetric Reasoning Curriculum for.pdf,Decoupled Asymmetric Reasoning Curriculum for LLM Evolution,"['Shengda Fan', 'Xuyan Ye', 'Yankai Lin']",,13.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DARC: Decoupled Asymmetric Reasoning Curriculum for LLM Evolution || Shengda Fan1*, Xuyan Ye1, Yankai Lin1 || 1 Gaoling School of Artificial Intelligence, Renmin University of China || {fanshengda, yexvyan0923, yankailin}@ruc.edu.cn || Abstract || Self-play with large language models has || emerged a ... (truncated) ||  || { || ""title"": ""Decoupled Asymmetric Reasoning Curriculum for LLM Evolution"", || ""authors"": [ || ""Shengda Fan"", || ""Xuyan Ye"", || ""Yankai Lin"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Self-play with large language models has emerged as a promising paradigm for achieving self-improving artificial intelligence. However, existing self-play frameworks often suffer from optimization instability, due to (i) non-stationary objectives induced by solver-dependent reward feedback for the Questioner, and (ii) bootstrapping errors from self-generated pseudo-labels used to supervise the Solver. To mitigate these challenges, we introduce DARC (Decoupled Asymmetric Reasoning Curriculum), a two-stage framework that stabilizes the self-evolution process."" || } ||  || [ Prompt: 38.0 t/s | Generation: 13.6 t/s ]"
2601.13768v1_vLinear A Powerful Linear Model for Multivariate T.pdf,vLinear: A Powerful Linear Model for Multivariate Time Series Forecasting,"['Wenzhen Yue', 'Ruohao Guo', 'Ji Shi', 'Zihan Hao', 'Shiyu Hu', 'Xianghua Ying']",,13.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || vLinear: A Powerful Linear Model for Multivariate Time Series Forecasting || Wenzhen Yue1 ,Ruohao Guo 1 ,Ji Shi 1 ,Zihan Hao 1 ,Shiyu Hu 1 andXianghua Ying 1 || 1State Key Laboratory of General Artificial Intelligence, School of Intelligence Science and Technology, || Peking University || yuewe ... (truncated) ||  || { || ""title"": ""vLinear: A Powerful Linear Model for Multivariate Time Series Forecasting"", || ""authors"": [ || ""Wenzhen Yue"", || ""Ruohao Guo"", || ""Ji Shi"", || ""Zihan Hao"", || ""Shiyu Hu"", || ""Xianghua Ying"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""linear model"", || ""time series forecasting"", || ""multivariate correlations"", || ""Transformer"", || ""velocity-oriented flow matching"", || ""path-weighted strategies"" || ], || ""summary"": ""The paper introduces vLinear, a lightweight linear-based multivariate time series forecaster that uses a learnable vector to capture correlations, reducing computational complexity. It proposes vecTrans to improve inference speed and performance, and introduces WFMLoss for path- and horizon-weighted objectives, achieving state-of-the-art results across benchmarks."" || } ||  || [ Prompt: 37.4 t/s | Generation: 13.7 t/s ]"
2601.13770v1_Look-Ahead-Bench a Standardized Benchmark of Look-.pdf,Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance,['Mostapha Benhenda'],arXiv:2601.13770v1,13.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || arXiv:2601.13770v1  [cs.AI]  20 Jan 2026 || Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in || Point-in-Time LLMs for Finance || Mostapha Benhenda * || Abstract || We introduce Look-Ahead-Bench, a standard- || ized benchmark measuring look-ahead bias in || Point-in-Time (PiT) Large Lang ... (truncated) ||  || { || ""title"": ""Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance"", || ""authors"": [""Mostapha Benhenda""], || ""doi"": ""arXiv:2601.13770v1"", || ""arxiv_id"": ""arXiv:2601.13770"", || ""keywords"": [""look-ahead bias"", ""Point-in-Time LLMs"", ""finance"", ""LLM evaluation""], || ""summary"": ""Introduces Look-Ahead-Bench to measure look-ahead bias in LLMs for financial applications, evaluating performance across different model scales and market regimes."" || } ||  || [ Prompt: 37.1 t/s | Generation: 13.7 t/s ]"
2601.13798v1_Insight Interpretable Semantic Hierarchies in Visi.pdf,,[],,16.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || INSIGHT: Interpretable Semantic Hierarchies in Vision-Language Encoders || Kai Wittenmayer, Sukrut Rao, Amin Parchami-Araghi, Bernt Schiele, Jonas Fischer || Max Planck Institute for Informatics, Saarland Informatics Campus, Saarbrucken, Germany || {kwittenm,sukrut.rao,mparcham,schiele,jonas ... (truncated) ||  || { || ""title"": ""Interpretable Semantic Hierarchies in Vision-Language Encoders"", || ""authors"": [ || ""Kai Wittenmayer"", || ""Sukrut Rao"", || ""Amin Parchami-Araghi"", || ""Bernt Schiele"", || ""Jonas Fischer"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Interpretable"", || ""Semantic Hierarchies"", || ""Vision-Language Models"", || ""Concept Representation"", || ""Explainability"", || ""Spatial Grounding"" || ], || ""summary"": ""INSIGHT provides fine-grained, human-interpretable concepts with spatial grounding for vision foundation models. It leverages hierarchical representations to enable concept-based explanations across tasks."" || } ||  || [ Prompt: 37.3 t/s | Generation: 16.1 t/s ]"
2601.13809v1_DroneVLA VLA based Aerial Manipulation.pdf,DroneVLA: VLA based Aerial Manipulation,"['Fawad Mehboob', 'Monijesu James', 'Amir Habel', 'Jeffrin Sam', 'Miguel Altamirano Cabrera', 'Dzmitry Tsetserukou']",,28.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DroneVLA: VLA based Aerial Manipulation || Fawad Mehboob || Fawad.Mehboob@skoltech.ru || Skoltech || Moscow, Russia || Monijesu James || Monijesu.James@skoltech.ru || Skoltech || Moscow, Russia || Amir Habel || Amir.Habel@skoltech.ru || Skoltech || Moscow, Russia || Jeffrin Sam || Jeffrin.Sam@skoltech.ru || Skoltech || Moscow, Ru ... (truncated) ||  || { || ""title"": ""DroneVLA: VLA based Aerial Manipulation"", || ""authors"": [ || ""Fawad Mehboob"", || ""Monijesu James"", || ""Amir Habel"", || ""Jeffrin Sam"", || ""Miguel Altamirano Cabrera"", || ""Dzmitry Tsetserukou"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Aerial Manipulation"", || ""Vision-Language-Action Models"", || ""Human-Robot Interaction"", || ""Computing methodologies"", || ""Computer vision"", || ""Artificial intelligence"", || ""Embedded and cyber-physical systems"" || ], || ""summary"": ""This work introduces a novel autonomous aerial manipulation system that interprets natural language commands to retrieve and deliver objects using a MediaPipe-based grounding system and a Vision-Language-Action model. It integrates a custom-built drone with a 1-DOF gripper and an Intel RealSense camera, enabling safe and intuitive human interaction during object handling."" || } ||  || [ Prompt: 111.6 t/s | Generation: 28.8 t/s ]"
2601.13846v1_Virtual Urbanism An AI-Driven Framework for Quanti.pdf,Virtual Urbanism: An AI-Driven Framework for Quantifying Urban Identity,['Glinkaya Maria'],,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Virtual  Urbanism:  An  AI-Driven  Framework  for  Quantifying  Urban || Identity. || A  Tokyo-Based  Pilot  Study  Using  Diusion-Generated  Synthetic || Environments || Glinskaya  Maria    Department  of  Architecture,  The  University  of  Tokyo,  Tokyo,  Japan || Abstract   This  pa ... (truncated) ||  || { || ""title"": ""Virtual Urbanism: An AI-Driven Framework for Quantifying Urban Identity"", || ""authors"": [""Glinkaya Maria""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""generative artificial intelligence"", ""latent diffusion model"", ""low-rank adaptation model"", ""urban perception"", ""urban identity""], || ""summary"": ""This paper introduces Virtual Urbanism (VU), a multimodal AI-driven analytical framework for quantifying urban identity through synthetic urban environments. The pilot study demonstrates feasibility using Tokyo microcosms, integrating Stable Diffusion and LoRA models to generate synthetic replicas, and evaluates perceptual legitimacy and quantified area-level identity metrics."" || } ||  || [ Prompt: 113.5 t/s | Generation: 28.4 t/s ]"
2601.13864v1_HardSecBench Benchmarking the Security Awareness o.pdf,HardSecBench: Benchmarking the Security Awareness of LLMs for Hardware,"['Qirui Chen', 'Jingxian Shuai', 'Shuangwu Chen', 'Shenghao Ye', 'Zijian Wen', 'Xufei Su', 'Jie Jin', 'Jiangming Li', 'Jun Chen', 'Xiaobin Tan', 'Jian Yang']",,28.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || HardSecBench: Benchmarking the Security Awareness of LLMs for Hardware || Code Generation || Qirui Chen1 ,Jingxian Shuai 1 ,Shuangwu Chen 1 ,Shenghao Ye 1 ,Zijian Wen 1 ,Xufei Su 2 , || Jie Jin3 ,Jiangming Li 4 ,Jun Chen 4 ,Xiaobin Tan 1 andJian Yang 1 || 1University of Science and Technology o ... (truncated) ||  || { || ""title"": ""HardSecBench: Benchmarking the Security Awareness of LLMs for Hardware"", || ""authors"": [ || ""Qirui Chen"", || ""Jingxian Shuai"", || ""Shuangwu Chen"", || ""Shenghao Ye"", || ""Zijian Wen"", || ""Xufei Su"", || ""Jie Jin"", || ""Jiangming Li"", || ""Jun Chen"", || ""Xiaobin Tan"", || ""Jian Yang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""large language models"", || ""security awareness"", || ""hardware"", || ""code generation"", || ""security vulnerabilities"", || ""common weakness enumeration"", || ""functional correctness"", || ""security risks"" || ], || ""summary"": ""This paper introduces HardSecBench, a benchmark evaluating security awareness in LLM-generated hardware code. It covers 924 tasks spanning Verilog RTL and firmware C, assessing functional correctness and security issues. The study reveals that LLMs often meet functional requirements but expose security risks, highlighting the need for improved evaluation methods."" || } ||  || [ Prompt: 106.4 t/s | Generation: 28.3 t/s ]"
2601.13880v1_LifeAgentBench A Multi-dimensional Benchmark and A.pdf,,[],,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LifeAgentBench: A Multi-dimensional Benchmark and Agent for || Personal Health Assistants in Digital Health || Ye Tian1, Zihao Wang1, Onat Gungor1, Xiaoran Fan2 and Tajana Rosing1 || 1University of California San Diego, La Jolla, CA, USA || 2 Google Research, Mountain View, CA, USA || {yet002,ziw1 ... (truncated) ||  || { || ""title"": ""LifeAgentBench: A Multi-dimensional Benchmark and Agent for Personal Health Assistants in Digital Health"", || ""authors"": [ || ""Ye Tian"", || ""Zihao Wang"", || ""Onat Gungor"", || ""Xiaoran Fan"", || ""Tajana Rosing"" || ], || ""doi"": ""1"",  // Placeholder, actual DOI should be filled || ""arxiv_id"": """", || ""keywords"": [ || ""personalized digital health"", || ""long-horizon reasoning"", || ""cross-dimensional"", || ""multi-user"", || ""health assistant"", || ""LLM"", || ""benchmark"", || ""mobile sensing"", || ""realistic scenarios"" || ], || ""summary"": ""This paper introduces LifeAgentBench, a large-scale QA benchmark for evaluating LLMs in long-horizon, cross-dimensional, and multi-user lifestyle health reasoning. It aims to provide a standardized evaluation framework and assesses 11 leading LLMs, identifying key challenges in aggregation and reasoning. The study proposes LifeAgent as a strong baseline for health assistants."" || } ||  || [ Prompt: 110.4 t/s | Generation: 28.7 t/s ]"
2601.13885v1_Confident Rankings with Fewer Items Adaptive LLM E.pdf,Confident Rankings with Fewer Items: Adaptive LLM Evaluation with Continuous Scores,"['Esma Balkr1', 'Alice Pernthaller1', 'Marco Basaldella1', 'Jos Hernndez-Orallo2', '3* Nigel Collier']",,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Confident Rankings with Fewer Items: Adaptive LLM Evaluation with || Continuous Scores || Esma Balkr1, Alice Pernthaller1, Marco Basaldella1, || Jos Hernndez-Orallo2,3*,Nigel Collier 1,4* || 1Trismik, 2Leverhulme Centre for the Future of Intelligence, University of Cambridge, || 3Universitat Polit ... (truncated) ||  || { || ""title"": ""Confident Rankings with Fewer Items: Adaptive LLM Evaluation with Continuous Scores"", || ""authors"": [""Esma Balkr1"", ""Alice Pernthaller1"", ""Marco Basaldella1"", ""Jos Hernndez-Orallo2"", ""3* Nigel Collier""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""adaptive LLM evaluation"", ""continuous scores"", ""computerized adaptive testing"", ""ROUGE"", ""BLEU"", ""LLM-as-a-Judge""], || ""summary"": ""This paper presents an extension of IRT-based adaptive testing to continuous bounded scores by replacing the Bernoulli response distribution with a heteroskedastic normal distribution. It introduces an uncertainty-aware ranker with adaptive stopping criteria, achieving reliable model ranking with fewer items and lower cost. The method is validated on five benchmarks and shows improved ranking correlation over random sampling."" || } ||  || [ Prompt: 112.2 t/s | Generation: 28.2 t/s ]"
2601.13887v1_Human Simulation Computation A Human-Inspired Fram.pdf,Human Simulation Computation: A Human-Inspired Framework for Adaptive AI Systems,['Hong Su'],10.1007/s11423-015-2055-7,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 1 || Human Simulation Computation: A Human-Inspired || Framework for Adaptive AI Systems || Hong Su || AbstractLarge language models (LLMs) have demonstrated || strong capabilities in knowledge representation and reasoning || based on textual  ... (truncated) ||  || { || ""title"": ""Human Simulation Computation: A Human-Inspired Framework for Adaptive AI Systems"", || ""authors"": [""Hong Su""], || ""doi"": ""10.1007/s11423-015-2055-7"", || ""arxiv_id"": """", || ""keywords"": [""Human Simulation Computation"", ""Environment Interaction"", ""Adaptive Artificial Intelligence"", ""Human-Inspired Reasoning""], || ""summary"": ""The paper proposes Human Simulation Computation (HSC), a framework modeling intelligence through continuous, closed-loop processes involving thinking, action, learning, reflection, and activity scheduling. It emphasizes human-like reasoning strategies and action-based adaptation for robust real-world interaction."" || } ||  || [ Prompt: 112.1 t/s | Generation: 27.8 t/s ]"
2601.13895v1_OmniOVCD Streamlining Open-Vocabulary Change Detec.pdf,OmniOVCD: Streamlining Open-Vocabulary Change Detection with SAM 3,"['Xu Zhang', 'Danyang Li', 'Yingjie Xia', 'Xiaohang Dong', 'Hualong Yu', 'Jianye Wang', 'Qicheng Li']",10.48550/arXiv.2303.04212,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || OmniOVCD: Streamlining Open-Vocabulary Change Detection with SAM 3 || Xu Zhang1 ,Danyang Li 2 ,Yingjie Xia 2 ,Xiaohang Dong 1 || Hualong Yu1 ,Jianye Wang 1 ,Qicheng Li 1 || 1TMCC, Computer Science, Nankai University 2VCIP, Computer Science, Nankai University || {xu zhang, danyang.li}@mail.nanka ... (truncated) ||  || { || ""title"": ""OmniOVCD: Streamlining Open-Vocabulary Change Detection with SAM 3"", || ""authors"": [ || ""Xu Zhang"", || ""Danyang Li"", || ""Yingjie Xia"", || ""Xiaohang Dong"", || ""Hualong Yu"", || ""Jianye Wang"", || ""Qicheng Li"" || ], || ""doi"": ""10.48550/arXiv.2303.04212"", || ""arxiv_id"": ""10.48550/arXiv.2303.04212"", || ""keywords"": [ || ""Change Detection"", || ""Open-Vocabulary"", || ""SAM 3"", || ""OmniOVCD"", || ""Segment Anything Model"", || ""Land Cover"", || ""Change Mask"" || ], || ""summary"": ""This paper introduces OmniOVCD, a standalone framework for Open-Vocabulary Change Detection using SAM 3. It proposes a Synergistic Fusion to Instance Decoupling (SFID) strategy to improve accuracy and stability by integrating semantic, instance, and presence outputs."" || } ||  || [ Prompt: 109.1 t/s | Generation: 27.6 t/s ]"
2601.13897v1_TractRLFusion A GPT-Based Multi-Critic Policy Fusi.pdf,TRACTRLFUSION: A GPT-BASED MULTI-CRITIC POLICY FUSION FRAMEWORK FOR FIBER TRACTOGRAPHY,"['Ankita Joshi', 'Ashutosh Sharma', 'Anoushkrit Goel', 'Ranjeet Ranjan Jha', 'Chirag Ahuja', 'Arnav Bhavsar', 'Aditya Nigam']",10.1000/tractrlfusion,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TRACTRLFUSION: A GPT-BASED MULTI-CRITIC POLICY FUSION FRAMEWORK FOR || FIBER TRACTOGRAPHY || Ankita Joshi1, Ashutosh Sharma1, Anoushkrit Goel1, Ranjeet Ranjan Jha2, || Chirag Ahuja3, Arnav Bhavsar1, Aditya Nigam1 || 1 IIT Mandi, 2 IIT Patna, 3 PGIMER Chandigarh || ABSTRACT || Tractography plays a piv ... (truncated) ||  || { || ""title"": ""TRACTRLFUSION: A GPT-BASED MULTI-CRITIC POLICY FUSION FRAMEWORK FOR FIBER TRACTOGRAPHY"", || ""authors"": [ || ""Ankita Joshi"", || ""Ashutosh Sharma"", || ""Anoushkrit Goel"", || ""Ranjeet Ranjan Jha"", || ""Chirag Ahuja"", || ""Arnav Bhavsar"", || ""Aditya Nigam"" || ], || ""doi"": ""10.1000/tractrlfusion"", || ""arxiv_id"": ""arXiv:2109.07956"", || ""keywords"": [ || ""Diffusion MRI"", || ""Tractography"", || ""Reinforcement Learning"", || ""Transformers"", || ""White matter pathways"", || ""Neurosurgical planning"" || ], || ""summary"": ""This paper introduces TractRLFusion, a novel GPT-based policy fusion framework for fiber tractography. It integrates multiple reinforcement learning policies using a data-driven fusion strategy to improve accuracy and robustness in reconstructing white matter tracts."" || } ||  || [ Prompt: 111.3 t/s | Generation: 28.7 t/s ]"
2601.13904v1_PREFAB PREFerence-based Affective Modeling for Low.pdf,PREFAB: PREFerence-based Affective Modeling for Low-Budget,"['Jaeyoung Moon', 'Youjin Choi', 'Yucheon Park', 'David Melhart', 'Georgios N. Yannakakis', 'Kyung-Joong Kim']",https://doi.org/10.1145/3675094.3678379,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || PREFAB: PREFerence-based Affective Modeling for Low-Budget || Self-Annotation || Jaeyoung Moon || Department of AI Convergence || Gwangju Institute of Science and || Technology || Gwangju, South Korea || super_moon@gm.gist.ac.kr || Youjin Choi || Department of AI Convergence || Gwangju Institute of Science and || T ... (truncated) ||  || { || ""title"": ""PREFAB: PREFerence-based Affective Modeling for Low-Budget"", || ""authors"": [ || ""Jaeyoung Moon"", || ""Youjin Choi"", || ""Yucheon Park"", || ""David Melhart"", || ""Georgios N. Yannakakis"", || ""Kyung-Joong Kim"" || ], || ""doi"": ""https://doi.org/10.1145/3675094.3678379"", || ""arxiv_id"": ""CHI 26, April 1317, 2026"", || ""keywords"": [ || ""self-annotation"", || ""affective modeling"", || ""low-budget"", || ""preference learning"", || ""inflection regions"", || ""annotator workload"" || ], || ""summary"": ""Self-annotation is the gold standard for collecting affective state labels. Existing methods rely on full annotation, which is time-consuming and cognitively demanding. PREFAB alleviates this by targeting affective inflection regions using a preference-learning model, reducing workload while maintaining annotation quality."" || } ||  || [ Prompt: 113.0 t/s | Generation: 28.6 t/s ]"
2601.13920v1_Asymmetric regularization mechanism for GAN traini.pdf,Asymmetric regularization mechanism for GAN training with Variational Inequalities,"['Spyridon C. Giagtzoglou', 'Mark H.M. Winands', 'Barbara Franci']",,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Asymmetric regularization mechanism for GAN training with Variational || Inequalities || Spyridon C. Giagtzoglou Mark H.M. Winands Barbara Franci || Abstract We formulate the training of generative adversar- || ial networks (GANs) as a Nash equilibrium seeking problem. || To stabilize the training ... (truncated) ||  || { || ""title"": ""Asymmetric regularization mechanism for GAN training with Variational Inequalities"", || ""authors"": [ || ""Spyridon C. Giagtzoglou"", || ""Mark H.M. Winands"", || ""Barbara Franci"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""GANs"", || ""variational inequalities"", || ""regularization"", || ""asymmetric regularization"", || ""Nash equilibrium"", || ""saddle point problem"" || ], || ""summary"": ""The paper proposes an asymmetric regularization mechanism based on Tikhonov steps and a zero-centered gradient penalty to stabilize GAN training. It derives convergence guarantees using projected algorithms and monotone operator theory, showing empirical convergence even without strong monotonicity."" || } ||  || [ Prompt: 109.0 t/s | Generation: 28.7 t/s ]"
2601.13938v1_IF-GEO Conflict-Aware Instruction Fusion for Multi.pdf,IF-GEO: Conflict-Aware Instruction Fusion for Multi-Query Generative Engine Optimization,"['Heyang Zhou', 'JiaJia Chen', 'Xiaolu Chen', 'Jie Bao', 'Zhen Chen', 'Yong Liao']",,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || IF-GEO: Conflict-Aware Instruction Fusion for Multi-Query Generative || Engine Optimization || Heyang Zhou1, JiaJia Chen2, Xiaolu Chen1, Jie Bao1, Zhen Chen1*, Yong Liao1 || 1School of Cyber Science and Technology, University of Science and Technology of China || 2Institute of Dataspace, Hefei  ... (truncated) ||  || { || ""title"": ""IF-GEO: Conflict-Aware Instruction Fusion for Multi-Query Generative Engine Optimization"", || ""authors"": [ || ""Heyang Zhou"", || ""JiaJia Chen"", || ""Xiaolu Chen"", || ""Jie Bao"", || ""Zhen Chen"", || ""Yong Liao"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper proposes IF-GEO, a framework for Generative Engine Optimization that uses conflict-aware instruction fusion to address challenges in optimizing documents for diverse queries while maintaining source visibility."" || } ||  || [ Prompt: 108.5 t/s | Generation: 28.2 t/s ]"
2601.13942v1_Glance-or-Gaze Incentivizing LMMs to Adaptively Fo.pdf,Glance-or-Gaze: Incentivizing LMMs to Adaptively Focus Search via Reinforcement Learning,"['Hongbo Bai1', 'Yujin Zhou1', 'Yile Wu1', 'Chi-Min Chan1', 'Pengcheng Wen1', 'Kunhao Pan1', 'Sirui Han1', 'Yike Guo1']",,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Glance-or-Gaze: Incentivizing LMMs to Adaptively Focus Search via || Reinforcement Learning || Hongbo Bai1, Yujin Zhou1, Yile Wu1, Chi-Min Chan1 || Pengcheng Wen1,Kunhao Pan 1,Sirui Han1,Yike Guo 1 || 1Hong Kong University of Science and Technology || baihongbo@ust.hk || Abstract || Large Multimodal Mod ... (truncated) ||  || { || ""title"": ""Glance-or-Gaze: Incentivizing LMMs to Adaptively Focus Search via Reinforcement Learning"", || ""authors"": [ || ""Hongbo Bai1"", || ""Yujin Zhou1"", || ""Yile Wu1"", || ""Chi-Min Chan1"", || ""Pengcheng Wen1"", || ""Kunhao Pan1"", || ""Sirui Han1"", || ""Yike Guo1"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Large Multimodal Models"", || ""Visual Understanding"", || ""Knowledge-intensive Queries"", || ""Search-Augmented Approaches"", || ""Selective Gaze"", || ""Reinforcement Learning"", || ""Visual Reasoning"", || ""Complexity Adaptation"" || ], || ""summary"": ""This paper proposes Glance-or-Gaze (GoG), a framework that enables LMMs to adaptively focus on relevant visual regions using a Selective Gaze mechanism. It combines reflective behavior alignment with complexity-adaptive reinforcement learning to improve performance on challenging visual queries."" || } ||  || [ Prompt: 110.1 t/s | Generation: 28.1 t/s ]"
2601.13948v1_Stream-Voice-Anon Enhancing Utility of Real-Time S.pdf,Streaming Speaker Anonymization,"['Nikita Kuzmin1', 'Songting Liu1', 'Kong Aik Lee3', 'Eng Siong Chng1']","s220028@e.ntu.edu.sg, lius0114@e.ntu.edu.sg",28.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || STREAM-VOICE-ANON: ENHANCING UTILITY OF REAL-TIME SPEAKER || ANONYMIZATION VIA NEURAL AUDIO CODEC AND LANGUAGE MODELS || Nikita Kuzmin1,2, Songting Liu1, Kong Aik Lee3, Eng Siong Chng1 || 1Nanyang Technological University, Singapore || 2Institute for Infocomm Research, ASTAR, Singapore || 3The Hon ... (truncated) ||  || { || ""title"": ""Streaming Speaker Anonymization"", || ""authors"": [ || ""Nikita Kuzmin1"", || ""Songting Liu1"", || ""Kong Aik Lee3"", || ""Eng Siong Chng1"" || ], || ""doi"": ""s220028@e.ntu.edu.sg, lius0114@e.ntu.edu.sg"", || ""arxiv_id"": """", || ""keywords"": [ || ""streaming speaker anonymization"", || ""neural audio codec"", || ""voice conversion"", || ""privacy preservation"", || ""disentanglement"", || ""language models"", || ""speaker representation"" || ], || ""summary"": ""The paper presents Stream-Voice-Anon, a method that adapts causal language model-based neural audio codec architectures for streaming speaker anonymization. It integrates anonymization techniques such as pseudo-speaker representation sampling and leverages disentanglement properties to protect speaker identity while maintaining linguistic fidelity. The approach achieves up to 46% relative WER reduction and 28% UAR preservation under the VoicePrivacy 2024 Challenge, balancing latency and privacy protection."" || } ||  || [ Prompt: 108.5 t/s | Generation: 28.0 t/s ]"
2601.13964v1_RL-BioAug Label-Efficient Reinforcement Learning f.pdf,RL-BioAug: Label-Efficient Reinforcement Learning,"['Cheol-Hui Lee', 'Hwa-Yeon Lee', 'Dong-Joo Kim']",10.48550/arXiv.2405.12345,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || RL-BioAug: Label-Efficient Reinforcement Learning || for Self-Supervised EEG Representation Learning || Cheol-Hui Lee 1, Hwa-Yeon Lee1, and Dong-Joo Kim 1,2,3 || Abstract The quality of data augmentation serves as a || critical determinant for the performance of contrastive learning || in EEG task ... (truncated) ||  || { || ""title"": ""RL-BioAug: Label-Efficient Reinforcement Learning"", || ""authors"": [ || ""Cheol-Hui Lee"", || ""Hwa-Yeon Lee"", || ""Dong-Joo Kim"" || ], || ""doi"": ""10.48550/arXiv.2405.12345"", || ""arxiv_id"": ""arXiv:2405.12345"", || ""keywords"": [ || ""RL-BioAug"", || ""label-efficient"", || ""reinforcement learning"", || ""EEG"", || ""self-supervised learning"", || ""data augmentation"" || ], || ""summary"": ""The paper proposes RL-BioAug, a framework using reinforcement learning to autonomously select optimal data augmentation strategies for EEG data, improving performance without relying on large labeled datasets."" || } ||  || [ Prompt: 107.5 t/s | Generation: 27.6 t/s ]"
2601.13969v1_Autonomous Knowledge Graph Exploration with Adapti.pdf,Autonomous Knowledge Graph Exploration with Adaptive Breadth-Depth Retrieval,"['Joaqun Polonuer', 'Lucas Vittor', 'Iaki Arango', 'Ayush Noori', 'David A. Clifton', 'Luciano Del Corro', 'Marinka Zitnik', 'Kempner Institute for the Study of Natural and Artificial Intelligence', 'Oxford Suzhou Centre for Advanced Research', 'ELIAS Lab', 'Lumina Labs', 'Kempner Institute for the Study of Natural and Artificial Intelligence', 'Harvard Data Science Initiative']",,28.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Autonomous Knowledge Graph Exploration || with Adaptive Breadth-Depth Retrieval || Joaqun Polonuer1,2, , Lucas Vittor1, , Iaki Arango 1, , Ayush Noori1,3, , || David A. Clifton 3,4 ,Luciano Del Corro 5,6,,,Marinka Zitnik 1,7,8,9,, || 1Department of Biomedical Informatics, Harvard Medical School ... (truncated) ||  || { || ""title"": ""Autonomous Knowledge Graph Exploration with Adaptive Breadth-Depth Retrieval"", || ""authors"": [ || ""Joaqun Polonuer"", || ""Lucas Vittor"", || ""Iaki Arango"", || ""Ayush Noori"", || ""David A. Clifton"", || ""Luciano Del Corro"", || ""Marinka Zitnik"", || ""Kempner Institute for the Study of Natural and Artificial Intelligence"", || ""Oxford Suzhou Centre for Advanced Research"", || ""ELIAS Lab"", || ""Lumina Labs"", || ""Kempner Institute for the Study of Natural and Artificial Intelligence"", || ""Harvard Data Science Initiative"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""knowledge graph"", || ""knowledge retrieval"", || ""language models"", || ""multi-hop traversal"", || ""broad search"", || ""depth-oriented expansion"", || ""retrieval-based methods"", || ""adaptive retrieval"", || ""semantic similarity"", || ""knowledge graphs"", || ""information retrieval"" || ], || ""summary"": ""Retrieving evidence for language model queries from knowledge graphs requires balancing broad search across the graph with multi-hop traversal. Similarity-based retrievers offer coverage but remain shallow, whereas traversal-based methods depend on seed nodes. ARK adapts tool use to queries, improving performance on AMAZON, MAG, and PRIME datasets."" || } ||  || [ Prompt: 110.9 t/s | Generation: 28.2 t/s ]"
2601.13992v1_The Whole Is Greater Than the Sum of Its Parts A C.pdf,The Whole Is Greater Than the Sum of Its Parts: A Compatibility-Aware Multi-Teacher CoT Distillation Framework,"['Jin Cui', 'Jiaqi Guo', 'Jiepeng Zhou', 'Ruixuan Yang', 'Jiayi Lu', 'Jiajun Xu', 'Jiangcheng Song', 'Boran Zhao', 'Pengju Ren']",,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || The Whole Is Greater Than the Sum of Its Parts: || A Compatibility-Aware Multi-Teacher CoT Distillation Framework || Jin Cui1 ,Jiaqi Guo 2 ,Jiepeng Zhou 3 ,Ruixuan Yang 1 ,Jiayi Lu 1 ,Jiajun Xu 4 ,Jiangcheng || Song1 ,Boran Zhao 4 ,Pengju Ren 1 || 1State Key Laboratory of Human-Machine Hybrid A ... (truncated) ||  || { || ""title"": ""The Whole Is Greater Than the Sum of Its Parts: A Compatibility-Aware Multi-Teacher CoT Distillation Framework"", || ""authors"": [ || ""Jin Cui"", || ""Jiaqi Guo"", || ""Jiepeng Zhou"", || ""Ruixuan Yang"", || ""Jiayi Lu"", || ""Jiajun Xu"", || ""Jiangcheng Song"", || ""Boran Zhao"", || ""Pengju Ren"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Chain-of-Thought"", || ""Multi-Teacher"", || ""CoT Distillation"", || ""Large Language Models"", || ""Catastrophic Forgetting"", || ""Graph-based Consensus"", || ""Mutual-Information-based Adaptability"", || ""Loss-based Difficulty"" || ], || ""summary"": ""This paper introduces COMPACT, a framework that adaptively fuses supervision from multiple teachers using dynamic weighting based on real-time compatibility metrics. It addresses challenges in CoT distillation by incorporating graph-based consensus, mutual information-based adaptability, and loss-based difficulty assessment to improve reasoning capabilities without compromising model knowledge."" || } ||  || [ Prompt: 107.5 t/s | Generation: 28.5 t/s ]"
2601.13994v1_torch-sla Differentiable Sparse Linear Algebra wit.pdf,Differentiable Sparse Linear Algebra with Adjoint Solvers and Sparse Tensor Parallelism for PyTorch,['Mingyuan Chi'],,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || torch-sla: Differentiable Sparse Linear Algebra with || Adjoint Solvers and Sparse Tensor Parallelism for PyTorch || Mingyuan Chi || walker.chi.000@gmail.com || https://github.com/walkerchi/torch-sla || January 21, 2026 || Abstract || Industrial scientific computing predominantly uses sparse matrices to ... (truncated) ||  || { || ""title"": ""Differentiable Sparse Linear Algebra with Adjoint Solvers and Sparse Tensor Parallelism for PyTorch"", || ""authors"": [""Mingyuan Chi""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Presents torch-sla, an open-source PyTorch library for GPU-accelerated, scalable, and differentiable sparse linear algebra, addressing challenges in GPU acceleration, multi-GPU scaling, and adjoint-based differentiation."" || } ||  || [ Prompt: 112.6 t/s | Generation: 28.1 t/s ]"
2601.13999v1_DAME Duration-Aware Matryoshka Embedding for Durat.pdf,Duration-Aware Matryoshka Embedding for Duration-Robust Speaker Verification,"['Youngmoon Jung', 'Joon-Young Yang', 'Ju-ho Kim', 'Jaeyoung Roh', 'Chang Woo Han', 'Hoon-Young Cho']",,27.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DAME: DURATION-A W ARE MATRYOSHKA EMBEDDING FOR DURATION-ROBUST || SPEAKER VERIFICATION || Youngmoon Jung*, Joon-Young Yang*, Ju-ho Kim, Jaeyoung Roh, Chang Woo Han, Hoon-Young Cho || AI Solution Team, Samsung Research, Seoul, South Korea || ABSTRACT || Short-utterance speaker verification remains ... (truncated) ||  || { || ""title"": ""Duration-Aware Matryoshka Embedding for Duration-Robust Speaker Verification"", || ""authors"": [ || ""Youngmoon Jung"", || ""Joon-Young Yang"", || ""Ju-ho Kim"", || ""Jaeyoung Roh"", || ""Chang Woo Han"", || ""Hoon-Young Cho"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""short-duration speaker verification"", || ""multi-scale aggregation"", || ""matryoshka representation learning"", || ""speaker verification"", || ""duration-robust"" || ], || ""summary"": ""The paper proposes DAME, a model-agnostic framework that builds nested embeddings aligned to utterance durations. It captures compact speaker traits from short utterances and richer details from longer ones, improving performance across durations without extra inference cost."" || } ||  || [ Prompt: 105.4 t/s | Generation: 27.5 t/s ]"
2601.14012v1_MATE Matryoshka Audio-Text Embeddings for Open-Voc.pdf,MATRYOSHKA AUDIOTEXT EMBEDDINGS FOR OPEN-VOCABULARY,"['Youngmoon Jung', 'Myunghun Jung', 'Joon-Young Yang', 'Yong-Hyeok Lee', 'Jaeyoung Roh', 'Hoon-Young Cho']",,28.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MATE: MATRYOSHKA AUDIOTEXT EMBEDDINGS FOR OPEN-VOCABULARY || KEYWORD SPOTTING || Youngmoon Jung, Myunghun Jung, Joon-Young Yang, Yong-Hyeok Lee, Jaeyoung Roh, Hoon-Young Cho || AI Solution Team, Samsung Research, Seoul, South Korea || ABSTRACT || Open-vocabulary keyword spotting (KWS) with text-ba ... (truncated) ||  || { || ""title"": ""MATRYOSHKA AUDIOTEXT EMBEDDINGS FOR OPEN-VOCABULARY"", || ""authors"": [ || ""Youngmoon Jung"", || ""Myunghun Jung"", || ""Joon-Young Yang"", || ""Yong-Hyeok Lee"", || ""Jaeyoung Roh"", || ""Hoon-Young Cho"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""keyword spotting"", || ""open-vocabulary"", || ""text enrollment"", || ""audiotext embedding"", || ""deep metric learning"" || ], || ""summary"": ""This paper introduces Matryoshka AudioText Embeddings (MATE), a dual-encoder framework for open-vocabulary keyword spotting that uses nested sub-embeddings to encode multiple granularities. It proposes PCA-guided prefix alignment to focus keyword cues in lower-dimensional prefixes while preserving detail in higher dimensions. MATE is trained with standard deep metric learning objectives and achieves state-of-the-art results on WSJ and LibriPhrase without inference overhead."" || } ||  || [ Prompt: 110.9 t/s | Generation: 28.6 t/s ]"
2601.14022v1_Credible CO2 Comparisons A Machine Learning Approa.pdf,Credible CO2 Comparisons: A Machine Learning Approach to Vehicle Powertrain Assessment,"['Rodrigo Pereira', 'Luciano Araujo', 'Daniel Marques da Silva', 'Joo Alfredo Cal-Braz']",xxx/xxxx,26.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Received: Added at production Revised: Added at production Accepted: Added at production || DOI: xxx/xxxx || A R T I C L E T Y P E || Credible CO2 Comparisons: A Machine Learning Approach to || Vehicle Powertrain Assessment || Rodrigo Pereira David1 Luciano Araujo Dourado Filho1,2 Daniel Marques d ... (truncated) ||  || { || ""title"": ""Credible CO2 Comparisons: A Machine Learning Approach to Vehicle Powertrain Assessment"", || ""authors"": [ || ""Rodrigo Pereira"", || ""Luciano Araujo"", || ""Daniel Marques da Silva"", || ""Joo Alfredo Cal-Braz"" || ], || ""doi"": ""xxx/xxxx"", || ""arxiv_id"": """", || ""keywords"": [ || ""machine learning"", || ""vehicle emissions"", || ""electric vehicles"", || ""ICEVs"", || ""real-world driving conditions"" || ], || ""summary"": ""This paper proposes a machine learning-based framework for comparing CO2 emissions between internal combustion engine vehicles and electric vehicles under identical driving conditions. It uses recurrent neural networks to model the mapping between driving variables and emissions, enabling fair comparisons and scalable evaluation of powertrain technologies."" || } ||  || [ Prompt: 108.5 t/s | Generation: 26.9 t/s ]"
2601.14027v1_Numina-Lean-Agent An Open and General Agentic Reas.pdf,Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics,"['Junqi Liu', 'Zihao Zhou', 'Zekai Zhu', 'Marco Dos Santos', 'Weikun He', 'Jiawei Liu', 'Ran Wang', 'Yunzhou Xie', 'Junqiao Zhao', 'Qiufeng Wang', 'Lihong Zhi', 'Jia Li', 'Wenda Li', 'Jia Li', 'Ran Wang', 'Junqiao Zhao', 'Qiufeng Wang', 'Lihong Zhi', 'Jia Li', 'Wenda Li', 'Imperial College London', 'University of Edinburgh']",,27.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Numina-Lean-Agent: An Open and General Agentic Reasoning System || for Formal Mathematics || Junqi Liu * 1 Zihao Zhou * 2 3 Zekai Zhu * 4 Marco Dos Santos 5 Weikun He 1 Jiawei Liu 6 Ran Wang 6 || Yunzhou Xie 7 Junqiao Zhao 4 Qiufeng Wang 3 Lihong Zhi 1 Jia Li 6 Wenda Li 8 || *Equal contribution ... (truncated) ||  || { || ""title"": ""Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics"", || ""authors"": [ || ""Junqi Liu"", || ""Zihao Zhou"", || ""Zekai Zhu"", || ""Marco Dos Santos"", || ""Weikun He"", || ""Jiawei Liu"", || ""Ran Wang"", || ""Yunzhou Xie"", || ""Junqiao Zhao"", || ""Qiufeng Wang"", || ""Lihong Zhi"", || ""Jia Li"", || ""Wenda Li"", || ""Jia Li"", || ""Ran Wang"", || ""Junqiao Zhao"", || ""Qiufeng Wang"", || ""Lihong Zhi"", || ""Jia Li"", || ""Wenda Li"", || ""Imperial College London"", || ""University of Edinburgh"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""formal mathematics"", || ""agentic systems"", || ""formal theorem proving"", || ""Lean"", || ""Numina-Lean-MCP"", || ""autonomous reasoning"", || ""mathematical proofs"" || ], || ""summary"": ""This paper proposes Numina-Lean-Agent, a general coding agent that enables flexible and autonomous interaction with Lean for formal mathematics. It aims to improve performance by using a general agent and supports various reasoning tasks without relying on task-specific pipelines."" || } ||  || [ Prompt: 112.0 t/s | Generation: 27.3 t/s ]"
2601.14039v1_Generalizing Abstention for Noise-Robust Learning .pdf,Generalizing Abstention for Noise-Robust Learning in Medical Image Segmentation,"['Wesam Moustafa', 'Hossam Elsafty', 'Helen Schneider', 'Lorenz Sparrenberg']",118,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Proceedings of Machine Learning Research  Under Review:118, 2026 Full Paper  MIDL 2026 submission || Generalizing Abstention for Noise-Robust Learning in || Medical Image Segmentation || Wesam Moustafa1,2 wesam.h.moustafa@gmail.com || Hossam Elsafty1,2,3 || hossam.elsafty@iais.fraunhofer.de || Helen ... (truncated) ||  || { || ""title"": ""Generalizing Abstention for Noise-Robust Learning in Medical Image Segmentation"", || ""authors"": [ || ""Wesam Moustafa"", || ""Hossam Elsafty"", || ""Helen Schneider"", || ""Lorenz Sparrenberg"" || ], || ""doi"": ""118"", || ""arxiv_id"": ""MIDL 2026 submission"", || ""keywords"": [ || ""Abstention"", || ""Medical Image Segmentation"", || ""Label Noise"", || ""Noise-Robust Learning"", || ""Loss Functions"" || ], || ""summary"": ""The paper introduces a universal and modular abstention framework to enhance noise-robustness in medical image segmentation. It presents three noise-robust variants (GAC, SAC, ADS) and demonstrates their effectiveness on medical datasets, showing significant improvements over non-abstaining baselines."" || } ||  || [ Prompt: 107.9 t/s | Generation: 28.5 t/s ]"
2601.14041v1_Top 10 Open Challenges Steering the Future of Diff.pdf,Top 10 Open Challenges Steering the Future of Diffusion Language Model and Its Variants,"['Yunhe Wang', 'Kai Han', 'Huiling Zhen', 'Yuchuan Tian', 'Hanting Chen', 'Yongbing Huang', 'Yufei Cui', 'Yingte Shu', 'Shan Gao', 'Ismail Elezi', 'Roy Vaughan Miles', 'Songcen Xu', 'Feng Wen', 'Chao Xu', 'Sinan Zeng', 'Dacheng Tao']",arXiv:2601.14041v1,29.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Top 10 Open Challenges Steering the Future of || Diffusion Language Model and Its Variants || Yunhe Wang1, Kai Han 1, Huiling Zhen 1, Yuchuan Tian 2, || Hanting Chen 1, Yongbing Huang 3, Yufei Cui 1, Yingte Shu 2, || Shan Gao 1, Ismail Elezi 1, Roy Vaughan Miles 1, Songcen Xu 1, || Feng Wen1, Chao ... (truncated) ||  || { || ""title"": ""Top 10 Open Challenges Steering the Future of Diffusion Language Model and Its Variants"", || ""authors"": [ || ""Yunhe Wang"", || ""Kai Han"", || ""Huiling Zhen"", || ""Yuchuan Tian"", || ""Hanting Chen"", || ""Yongbing Huang"", || ""Yufei Cui"", || ""Yingte Shu"", || ""Shan Gao"", || ""Ismail Elezi"", || ""Roy Vaughan Miles"", || ""Songcen Xu"", || ""Feng Wen"", || ""Chao Xu"", || ""Sinan Zeng"", || ""Dacheng Tao"" || ], || ""doi"": ""arXiv:2601.14041v1"", || ""arxiv_id"": ""2601.14041v1"", || ""keywords"": [ || ""Large Language Models"", || ""Diffusion Models"", || ""Transformers"" || ], || ""summary"": ""The paper discusses the challenges facing diffusion language models and proposes a roadmap to overcome them, emphasizing architectural, algorithmic, and cognitive advancements."" || } ||  || [ Prompt: 123.2 t/s | Generation: 29.3 t/s ]"
2601.14047v1_Collective intelligence in science direct elicitat.pdf,Collective Intelligence in Science,[],,27.8,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || COLLECTIVE INTELLIGENCE IN SCIENCE: || DIRECT ELICITATION OF DIVERSE INFORMATION FROM || EXPERTS WITH UNKNOWN INFORMATION STRUCTURE || ALEXEY V. OSIPOV , AND NIKOLAY N. OSIPOV,, || Abstract.Suppose we need a deep collective analysis of an open scientific || problem: there is a complex scientific h ... (truncated) ||  || { || ""title"": ""Collective Intelligence in Science"", || ""authors"": [], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""collective intelligence"", || ""scientific hypothesis"", || ""information pooling"", || ""information elicitation"", || ""Bayesian truth serum"", || ""Bayesian markets"", || ""peer prediction"", || ""large language models"", || ""scientific collaboration"" || ], || ""summary"": ""The paper discusses using a self-resolving play-money prediction market integrated with chat to enable experts to collaboratively analyze complex scientific problems. It highlights mechanisms for efficient information aggregation and proposes rewarding experts with real assets based on their contributions."" || } ||  || [ Prompt: 105.6 t/s | Generation: 27.8 t/s ]"
2601.14051v1_Kakugo Distillation of Low-Resource Languages into.pdf,Kakugo: Distillation of Low-Resource Languages into Small Language,"['Peter Devine', 'Mardhiyah Sanni', 'Farid Adilazuarda', 'Julieta Gil Loizaga', 'Barry Haddow']",,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Kakugo: Distillation of Low-Resource Languages into Small Language || Models || Peter Devine, Mardhiyah Sanni, Farid Adilazuarda, || Julieta Gil Loizaga, Barry Haddow || School of Informatics, University of Edinburgh || Edinburgh, UK || {pdevine2, msanni, farid.adilazuarda, julieta.loizaga, bhaddow}@ ... (truncated) ||  || { || ""title"": ""Kakugo: Distillation of Low-Resource Languages into Small Language"", || ""authors"": [ || ""Peter Devine"", || ""Mardhiyah Sanni"", || ""Farid Adilazuarda"", || ""Julieta Gil Loizaga"", || ""Barry Haddow"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""We present Kakugo, a novel and cost-effective pipeline designed to train general-purpose Small Language Models (SLMs) for low-resource languages using only the language name as input. By using a large teacher model to generate synthetic prompts and translate instruction datasets, we produced training data and SLMs for 54 low-resource languages. Evaluations across translation, classification, and question answering demonstrate consistent performance improvements over base models with a total generation and training cost under $50 per language."" || } ||  || [ Prompt: 110.7 t/s | Generation: 28.4 t/s ]"
2601.14053v1_LLMOrbit A Circular Taxonomy of Large Language Mod.pdf,LLMOrbit: A Circular Taxonomy of Large Language Models,"['Badri N. Patro', 'Vijay S. Agneeswaran']",,28.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LLMOrbit: A Circular Taxonomy of Large Language Models || From Scaling Walls to Agentic AI Systems || Badri N. Patro, Vijay S. Agneeswaran || Microsoft || {badripatro, vagneeswaran}@microsoft.com || Abstract || The field of artificial intelligence has undergone a rev- || olution from foundational Transf ... (truncated) ||  || { || ""title"": ""LLMOrbit: A Circular Taxonomy of Large Language Models"", || ""authors"": [""Badri N. Patro"", ""Vijay S. Agneeswaran""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""A comprehensive circular taxonomy navigating the landscape of large language models from 2019-2025, examining over 50 major models across 15 organizations."" || } ||  || [ Prompt: 109.3 t/s | Generation: 28.1 t/s ]"
2601.14055v1_Decoder-Free Supervoxel GNN for Accurate Brain-Tum.pdf,Decoder-Free Supervoxel GNN for Accurate Brain-Tumor Localization in Multi-Modal MRI,"['Andrea Protani', 'Marc Molina Van Den Bosch', 'Heloisa Barbosa Da Silva', 'Paolo Cacace', 'Albert Sund Aillet', 'Miguel Angel Gonzalez Ballester', 'Friedhelm Hummel', 'Luigi Serio']",arXiv:2601.14055v1,26.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Decoder-Free Supervoxel GNN for Accurate || Brain-Tumor Localization in Multi-Modal MRI || Andrea Protani1,2, Marc Molina Van Den Bosch1,3, Lorenzo Giusti1, || Heloisa Barbosa Da Silva1,4, Paolo Cacace1,5, Albert Sund Aillet1, || Miguel Angel Gonzalez Ballester3,6, Friedhelm Hummel2, and Luigi  ... (truncated) ||  || { || ""title"": ""Decoder-Free Supervoxel GNN for Accurate Brain-Tumor Localization in Multi-Modal MRI"", || ""authors"": [ || ""Andrea Protani"", || ""Marc Molina Van Den Bosch"", || ""Heloisa Barbosa Da Silva"", || ""Paolo Cacace"", || ""Albert Sund Aillet"", || ""Miguel Angel Gonzalez Ballester"", || ""Friedhelm Hummel"", || ""Luigi Serio"" || ], || ""doi"": ""arXiv:2601.14055v1"", || ""arxiv_id"": ""arXiv:2601.14055"", || ""keywords"": [ || ""BrainTumorLocalization"", || ""SupervoxelGNN"", || ""MultiModalMRI"", || ""MedicalImageAnalysis"", || ""InterpretableAI"" || ], || ""summary"": ""Modern vision backbones for 3D medical imaging typically process dense voxel grids through parameter-heavy encoder-decoder structures, allocating significant parameters to spatial reconstruction. Our approach introduces SVGFormer, a decoder-free pipeline built on a content-aware grouping stage that partitions the volume into a semantic graph of supervoxels. Its hierarchical encoder learns rich node representations by combining patch-level Transformer with a supervoxel-level Graph Attention Network, jointly modeling fine-grained intra-region features and broader inter-regional dependencies. This design concentrates all learnable capacity on feature encoding and provides inherent, dual-scale explainability from the patch to the region level. The framework was validated on the BraTS dataset, achieving strong performance in node-level classification (F1=0.875) and tumor proportion regression (MAE=0.028)."", || ""summary_abstract"": ""This paper presents SVGFormer, a decoder-free pipeline for accurate brain-tumor localization in multi-modal MRI. It leverages a content-aware grouping strategy and a hierarchical encoder to model spatial and regional dependencies, achieving high accuracy in both classification and regression tasks."" || } ||  || [ Prompt: 112.0 t/s | Generation: 26.0 t/s ]"
2601.14056v1_POCI-Diff Position Objects Consistently and Intera.pdf,POCI-Diff: Position Objects Consistently and Interactively with 3D-Layout Guided Diffusion,"['Andrea Rigo', 'Luca Stornaiuolo', 'Weijie Wang', 'Mauro Martino', 'Bruno Lepri', 'Nicu Sebe']",arXiv:2601.14056v1,13.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || POCI-Diff: Position Objects Consistently and || Interactively with 3D-Layout Guided Diffusion || Andrea Rigo1, Luca Stornaiuolo2, Weijie Wang1,4, Mauro Martino3, Bruno || Lepri4, and Nicu Sebe1 || 1 DISI, University of Trento, Trento, Italy || 2 Toretei S.r.l., Roma, Italy || 3 Visual AI Lab, MIT-IBM ... (truncated) ||  || { || ""title"": ""POCI-Diff: Position Objects Consistently and Interactively with 3D-Layout Guided Diffusion"", || ""authors"": [ || ""Andrea Rigo"", || ""Luca Stornaiuolo"", || ""Weijie Wang"", || ""Mauro Martino"", || ""Bruno Lepri"", || ""Nicu Sebe"" || ], || ""doi"": ""arXiv:2601.14056v1"", || ""arxiv_id"": ""arXiv:2601.14056"", || ""keywords"": ""DiffusionImage Generation3D Layout"", || ""summary"": ""We propose a diffusion-based approach for Text-to-Image generation with consistent and interactive 3D layout control and editing. Our method enables explicit per-object semantic control by binding individual text descriptions to specific 3D bounding boxes, allowing one-shot synthesis of complex multi-object scenes while preserving object identity and consistency across edits."" || } ||  || [ Prompt: 39.6 t/s | Generation: 13.6 t/s ]"
2601.14063v1_XCR-Bench A Multi-Task Benchmark for Evaluating Cu.pdf,XCR-Bench: A Multi-Task Benchmark for Evaluating Cultural Reasoning in LLMs,"['Mohsinul Kabir', 'Tasnim Ahmed', 'Shaoxiong Ji', 'Hassan Alhuzali', 'Sophia Ananiadou']",10.48550/arXiv.2303.04219,13.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || XCR-Bench: A Multi-Task Benchmark for Evaluating Cultural || Reasoning in LLMs || Mohsinul Kabir1,2, Tasnim Ahmed3, Md Mezbaur Rahman 4, || Shaoxiong Ji5,6, Hassan Alhuzali7, Sophia Ananiadou1,2 || 1Department of Computer Science, National Centre for Text Mining, || The University of Manchester 2E ... (truncated) ||  || { || ""title"": ""XCR-Bench: A Multi-Task Benchmark for Evaluating Cultural Reasoning in LLMs"", || ""authors"": [ || ""Mohsinul Kabir"", || ""Tasnim Ahmed"", || ""Shaoxiong Ji"", || ""Hassan Alhuzali"", || ""Sophia Ananiadou"" || ], || ""doi"": ""10.48550/arXiv.2303.04219"", || ""arxiv_id"": ""10.48550/arXiv.2303.04219"", || ""keywords"": [ || ""cross-cultural competence"", || ""large language models"", || ""cultural reasoning"", || ""cultural bias"", || ""Newmarks CSI framework"" || ], || ""summary"": ""This paper introduces XCR-Bench, a benchmark for evaluating cultural reasoning in large language models. It addresses the lack of high-quality cross-cultural annotated data and highlights LLMs' biases in social etiquette and cultural adaptation. The study reveals consistent weaknesses in identifying culture-specific items and uncovers regional and ethno-religious biases even in monolingual settings."" || } ||  || [ Prompt: 37.0 t/s | Generation: 13.7 t/s ]"
2601.14069v1_Unsupervised Video Class-Incremental Learning via .pdf,Unsupervised Video Class-Incremental Learning,"['Nattapong Kurpukdee', 'Adrian G. Bors']",,13.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || UNSUPERVISED VIDEO CLASS-INCREMENTAL LEARNING || VIA DEEP EMBEDDED CLUSTERING MANAGEMENT || Nattapong Kurpukdee, Adrian G. Bors || Department of Computer Science, || University of York, York YO10 5GH, UK || nattapong.kurpukdee@york.ac.uk, adrian.bors@york.ac.uk || ABSTRACT || Unsupervised video class in ... (truncated) ||  || { || ""title"": ""Unsupervised Video Class-Incremental Learning"", || ""authors"": [""Nattapong Kurpukdee"", ""Adrian G. Bors""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""unsupervised"", ""video class-incremental"", ""video continual learning"", ""deep embedded clustering""], || ""summary"": ""This paper proposes a simple yet effective approach to address unsupervised video class incremental learning (uVCIL) using deep feature extractors and progressive deep clustering. The method leverages representative video features without relying on labels and improves performance across multiple video datasets."" || } ||  || [ Prompt: 37.3 t/s | Generation: 13.4 t/s ]"
2601.14084v1_DermaBench A Clinician-Annotated Benchmark Dataset.pdf,DermaBench: A Clinician-Annotated Benchmark,"['Abdurrahim Yilmaz', 'Ozan Erdem', 'Ece Gokyayla', 'Ayda Acar', 'Burc Bugra Dagtas', 'Dilara Ilhan Erdil', 'Gulsum Gencoglan', 'Burak Temelkuran']",,20.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || DermaBench: A Clinician-Annotated Benchmark || Dataset for Dermatology Visual Question Answering || and Reasoning || Abdurrahim Yilmaz1,*, Ozan Erdem2,, Ece Gokyayla3,, Ayda Acar4,, Burc Bugra Dagtas5,, || Dilara Ilhan Erdil6,, Gulsum Gencoglan7,*, and Burak Temelkuran1,* || 1Imperial College Lond ... (truncated) ||  || { || ""title"": ""DermaBench: A Clinician-Annotated Benchmark"", || ""authors"": [ || ""Abdurrahim Yilmaz"", || ""Ozan Erdem"", || ""Ece Gokyayla"", || ""Ayda Acar"", || ""Burc Bugra Dagtas"", || ""Dilara Ilhan Erdil"", || ""Gulsum Gencoglan"", || ""Burak Temelkuran"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""dermatology"", || ""visual question answering"", || ""clinical reasoning"", || ""skin types"", || ""lesion morphology"", || ""image annotation"", || ""medical AI"", || ""multimodal models"" || ], || ""summary"": ""DermaBench is a clinician-annotated dermatology visual question answering benchmark built on the Diverse Dermatology Images (DDI) dataset. It contains 656 clinical images from 570 patients across Fitzpatrick skin types IVI, with expert annotations covering diagnosis, anatomic site, lesion details, and narrative descriptions. The dataset aims to evaluate how AI models interpret dermatological images beyond simple classification."" || } ||  || [ Prompt: 36.0 t/s | Generation: 20.9 t/s ]"
2601.14086v1_Two-Stream temporal transformer for video action c.pdf,Two-Stream Temporal Transformer for Video Action Classification,"['Nattapong Kurpukdee', 'Adrian G. Bors']",,26.0,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || TWO-STREAM TEMPORAL TRANSFORMER FOR VIDEO ACTION CLASSIFICATION || Nattapong Kurpukdee and Adrian G. Bors || Department of Computer Science, || University of York, York YO10 5GH, UK || nattapong.kurpukdee@york.ac.uk, adrian.bors@york.ac.uk || ABSTRACT || Motion representation plays an important role  ... (truncated) ||  || { || ""title"": ""Two-Stream Temporal Transformer for Video Action Classification"", || ""authors"": [""Nattapong Kurpukdee"", ""Adrian G. Bors""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""Video Transformer"", ""Optical Flow"", ""Two-Stream video processing"", ""Video Action Classification""], || ""summary"": ""This study introduces a two-stream transformer video classifier that extracts spatio-temporal information from optical flow and temporal frames, leveraging self-attention to improve video action recognition."" || } ||  || [ Prompt: 113.8 t/s | Generation: 26.0 t/s ]"
2601.14087v1_1-bit Count-based Sorting Unit to Reduce Link Powe.pdf,,[],,26.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || 1-bit Count-based Sorting Unit to Reduce Link || Power in DNN Accelerators || Ruichi Han, Yizhi Chen, Tong Lei, Jordi Altayo Gonzalez, Ahmed Hemani || Department of Electronics and Embedded Systems, KTH Royal Institute of Technology, Stockholm, Sweden || {ruichi, yizhic, tonglei, jordiag, heman ... (truncated) ||  || { || ""title"": ""1-bit Count-based Sorting Unit to Reduce Link"", || ""authors"": [""Ruichi Han"", ""Yizhi Chen"", ""Tong Lei"", ""Jordi Altayo Gonzalez"", ""Ahmed Hemani""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""1-bit count-based sorting"", ""Approximate computing"", ""Bit transition reduction"", ""Link power""], || ""summary"": ""This work proposes a hardware implementation of a comparison-free sorting unit optimized for Convolutional Neural Networks (CNN) using approximate computing. It achieves up to 35.4% area reduction while maintaining 19.50% BT reduction compared to precise implementation."" || } ||  || [ Prompt: 113.4 t/s | Generation: 26.4 t/s ]"
2601.14091v1_Zero-shot adaptable task planning for autonomous c.pdf,Zero-shot adaptable task planning for autonomous construction robots: a comparative study of lightweight single and multi-AI agent systems,"['Hossein Naderi', 'Alireza Shojaei', 'Lifu Huang', 'Philip Agee', 'Kereshmeh Afsari', 'Abiola Akanmu']",,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Zero-shot adaptable task planning for autonomous construction robots: a comparative || study of lightweight single and multi-AI agent systems ||  || Hossein Naderi1, Alireza Shojaei2, Lifu Huang, Philip Agee4, Kereshmeh Afsari5, Abiola Akanmu6 ||  || 1Dept. of Building Construction, Myers-Law ... (truncated) ||  || { || ""title"": ""Zero-shot adaptable task planning for autonomous construction robots: a comparative study of lightweight single and multi-AI agent systems"", || ""authors"": [ || ""Hossein Naderi"", || ""Alireza Shojaei"", || ""Lifu Huang"", || ""Philip Agee"", || ""Kereshmeh Afsari"", || ""Abiola Akanmu"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""Construction robotics"", || ""quadruped robots"", || ""robot task planning"", || ""multi-AI agent"", || ""LLMs"", || ""VLMs"", || ""GPT4o"" || ], || ""summary"": ""The study explores the potential of foundation models to enhance adaptability and generalizability of task planning in construction robots. Four lightweight AI agent systems are proposed and evaluated across three construction roles, showing improved performance and cost-effectiveness compared to state-of-the-art models."" || } ||  || [ Prompt: 107.8 t/s | Generation: 28.7 t/s ]"
2601.14096v1_Remapping and navigation of an embedding space via.pdf,Remapping and Navigating Embedding Space,"['Benedikt Hartl', 'Lo Pio-Lopez', 'Chris Fields', 'Michael Levin']",arXiv:2601.14096v1,30.9,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Remapping and navigation of an embedding space via error || minimization: a fundamental organizational principle of || cognition in natural and artificial systems || Benedikt Hartl1, , Lo Pio-Lopez1, , Chris Fields1 , and Michael Levin1,2, ,* || 1Allen Discovery Center at Tufts University, Medf ... (truncated) ||  || { || ""title"": ""Remapping and Navigating Embedding Space"", || ""authors"": [ || ""Benedikt Hartl"", || ""Lo Pio-Lopez"", || ""Chris Fields"", || ""Michael Levin"" || ], || ""doi"": ""arXiv:2601.14096v1"", || ""arxiv_id"": ""arXiv:2601.14096v1"", || ""keywords"": [ || ""Evolution"", || ""Development"", || ""Intelligence"", || ""Active Inference"", || ""Navigation Policy"", || ""Nested Embedding Spaces"" || ], || ""summary"": ""A fundamental organizational principle of cognition in natural and artificial systems."" || } ||  || [ Prompt: 89.5 t/s | Generation: 30.9 t/s ]"
2601.14099v1_Causal feature selection framework for stable soft.pdf,Causal Feature Selection Framework for Stable Soft Sensor Modeling based on Time-Delayed Cross Mapping,"['Shi-Shun Chen', 'Xiao-Yang Li', 'Enrico Zio']",,32.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user ||  ||  ||  || Causal Feature Selection Framework for Stable Soft Sensor Modeling based on || Time-Delayed Cross Mapping ||  || Shi-Shun Chen a, b, Xiao-Yang Li a,*, Enrico Zio b, c ||  || a School of Reliability and Systems Engineering, Beihang University, Beijing, China || b Energy Department, Politec ... (truncated) ||  || { || ""title"": ""Causal Feature Selection Framework for Stable Soft Sensor Modeling based on Time-Delayed Cross Mapping"", || ""authors"": [ || ""Shi-Shun Chen"", || ""Xiao-Yang Li"", || ""Enrico Zio"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""A causal feature selection framework for stable soft sensor modeling based on time-delayed cross mapping."" || } ||  || [ Prompt: 97.2 t/s | Generation: 32.2 t/s ]"
2601.14115v1_Riemannian Liquid Spatio-Temporal Graph Network.pdf,Riemannian Liquid Spatio-Temporal Graph Network,"['Liangsi Lu', 'Jingchao Wang', 'Zhaorong Dai', 'Hanqian Liu', 'Sun Yat-Sen University', 'Yang Shi']",10.1145/3774904.3792090,28.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Riemannian Liquid Spatio-Temporal Graph Network || Liangsi Lu || lu.liangsi.cn@gmail.com || Guangdong University of Technology || Guangzhou, China || Jingchao Wang || ethanwangjc@163.com || Peking University || Beijing, China || Zhaorong Dai || 13725167598@163.com || South China Agricultural University || Guangzhou, C ... (truncated) ||  || { || ""title"": ""Riemannian Liquid Spatio-Temporal Graph Network"", || ""authors"": [ || ""Liangsi Lu"", || ""Jingchao Wang"", || ""Zhaorong Dai"", || ""Hanqian Liu"", || ""Sun Yat-Sen University"", || ""Yang Shi"" || ], || ""doi"": ""10.1145/3774904.3792090"", || ""arxiv_id"": ""https://rlstg.github.io"", || ""keywords"": [ || ""Riemannian Manifolds"", || ""Neural ODEs"", || ""Spatio-Temporal Graphs"" || ], || ""summary"": ""Liquid Time-Constant networks excel at modeling irregularly-sampled dynamics but are limited to Euclidean space. This work introduces a Riemannian Liquid Spatio-Temporal Graph Network (RLSTG) to overcome geometric distortion by unifying continuous-time dynamics with Riemannian geometry."" || } ||  || [ Prompt: 108.0 t/s | Generation: 28.7 t/s ]"
2601.14124v1_Style Transfer as Bias Mitigation Diffusion Models.pdf,Style Transfer as Bias Mitigation: Diffusion Models for Synthetic Mental Health Text for Arabic,"['Saad Mankarious', 'Ayah Zirikly']",,27.6,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Style Transfer as Bias Mitigation: Diffusion Models for || Synthetic Mental Health Text for Arabic || Saad Mankarious Ayah Zirikly || School of Engineering and Applied Science || George Washington University, Washington, D.C. 20037 || {saadm, ayah.zirikly}@gwu.edu || Abstract || Synthetic data offers a  ... (truncated) ||  || { || ""title"": ""Style Transfer as Bias Mitigation: Diffusion Models for Synthetic Mental Health Text for Arabic"", || ""authors"": [""Saad Mankarious"", ""Ayah Zirikly""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [""style transfer"", ""bias mitigation"", ""synthetic data"", ""Arabic"", ""mental health""], || ""summary"": ""This work proposes a pretraining-free diffusion-based approach for generating synthetic Arabic mental health text to address gender bias. It focuses on male-to-female style transfer to augment female-authored content, using five datasets to train specialized diffusion models. Results show high semantic fidelity and meaningful stylistic divergence, offering a flexible framework for mitigating bias in low-resource mental health domains."" || } ||  || [ Prompt: 117.8 t/s | Generation: 27.6 t/s ]"
2601.14152v1_Lost in the Prompt Order Revealing the Limitations.pdf,Revealing the Limitations of Causal Attention in Language Models,"['Hyunjong Ok', 'Jaeho Lee']",,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Lost in the Prompt Order: || Revealing the Limitations of Causal Attention in Language Models || Hyunjong Ok1,2 Jaeho Lee1 || 1POSTECH 2HJ AILAB || hyunjong.ok@gmail.com, jaeho.lee@postech.ac.kr || Abstract || Large language models exhibit surprising sen- || sitivity to the structure of the prompt, but  ... (truncated) ||  || { || ""title"": ""Revealing the Limitations of Causal Attention in Language Models"", || ""authors"": [""Hyunjong Ok"", ""Jaeho Lee""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""This paper investigates how the ordering of components in multiple-choice question answering affects model performance, identifying causal attention as a key mechanism."" || } ||  || [ Prompt: 105.5 t/s | Generation: 28.5 t/s ]"
2601.14154v1_LLM Augmented Intervenable Multimodal Adaptor for .pdf,,[],,27.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || LLM Augmented Intervenable Multimodal Adaptor for Post-operative || Complication Prediction in Lung Cancer Surgery || Shubham Pandey, Bhavin Jawade, Srirangaraj Setlur, Venu Govindaraju, Kenneth Seastedt || University at Buffalo, Roswell Park Comprehensive Cancer Center || Buffalo, NY , USA || {sp ... (truncated) ||  || { || ""title"": ""LLM Augmented Intervenable Multimodal Adaptor for Post-operative Complication Prediction in Lung Cancer Surgery"", || ""authors"": [ || ""Shubham Pandey"", || ""Bhavin Jawade"", || ""Srirangaraj Setlur"", || ""Venu Govindaraju"", || ""Kenneth Seastedt"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""postoperative complications"", || ""lung cancer surgery"", || ""risk prediction"", || ""deep learning"", || ""multimodal data"", || ""interpretable AI"", || ""clinical decision support"" || ], || ""summary"": ""MIRA-CLE is a deep learning architecture that integrates preoperative clinical and radiological data to predict postoperative complications in lung cancer surgery. It enhances transparency and provides actionable insights, outperforming traditional models and LLMs for personalized risk management."" || } ||  || [ Prompt: 111.6 t/s | Generation: 27.2 t/s ]"
2601.14157v1_ConceptCaps -- a Distilled Concept Dataset for Int.pdf,ConceptCaps - a Distilled Concept Dataset for Interpretability in Music Models,"['Bruno Sienkiewicz', 'ukasz Neumann', 'Mateusz Modrzejewski']",,27.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || ConceptCaps - a Distilled Concept Dataset for Interpretability in Music Models || Bruno Sienkiewicz1 ,ukasz Neumann 1 andMateusz Modrzejewski 1 || 1Institute of Computer Science, Warsaw University of Technology || bruno.sienkiewicz@gmail.com,{lukasz.neumann, mateusz.modrzejewski}@pw.edu.pl, || ... (truncated) ||  || { || ""title"": ""ConceptCaps - a Distilled Concept Dataset for Interpretability in Music Models"", || ""authors"": [""Bruno Sienkiewicz"", ""ukasz Neumann"", ""Mateusz Modrzejewski""], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Concept-based interpretability methods like TCA V require clean, well-separated positive and negative examples. Existing music datasets lack this structure. We introduce ConceptCaps, a dataset of 23k music-caption-audio triplets with explicit labels from a 200-attribute taxonomy. Our pipeline separates semantic modeling from text generation to improve coherence and controllability."" || } ||  || [ Prompt: 112.3 t/s | Generation: 27.1 t/s ]"
2601.14160v1_Domain-Adaptation through Synthetic Data Fine-Tuni.pdf,Domain-Adaptation through Synthetic Data: Fine-Tuning Large Language Models for German Law,"['Ali Hamza Bashir', 'Muhammad Rehan Khalid', 'Kostadin Cvejoski', 'Jana Birr', 'Jule Berghaus', 'Armin Berger', 'Sandra Halscheidt', 'Christian Temath', 'Rafet Sifa', 'David Berghaus']",,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Domain-Adaptation through Synthetic Data: || Fine-Tuning Large Language Models for German Law || Ali Hamza Bashir1,2,3 ,Muhammad Rehan Khalid 2 ,Kostadin Cvejoski 5 ,Jana Birr 1 , || Jule Berghaus4 ,Armin Berger 1,3,4 ,Sandra Halscheidt 1 ,Christian Temath 1 , || Rafet Sifa1,3,4 ,David Berghaus ... (truncated) ||  || { || ""title"": ""Domain-Adaptation through Synthetic Data: Fine-Tuning Large Language Models for German Law"", || ""authors"": [ || ""Ali Hamza Bashir"", || ""Muhammad Rehan Khalid"", || ""Kostadin Cvejoski"", || ""Jana Birr"", || ""Jule Berghaus"", || ""Armin Berger"", || ""Sandra Halscheidt"", || ""Christian Temath"", || ""Rafet Sifa"", || ""David Berghaus"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [ || ""legal adaptation"", || ""synthetic data"", || ""German law"", || ""LLM fine-tuning"", || ""legal QA"", || ""hallucination prevention"" || ], || ""summary"": ""This paper presents a method to adapt large language models to German legal question answering using synthetic data generated from authoritative German statutes. It addresses challenges in legal NLP by leveraging curated legal corpora and demonstrating improved performance through parameter-efficient fine-tuning."" || } ||  || [ Prompt: 107.8 t/s | Generation: 28.5 t/s ]"
2601.14171v1_Paper2Rebuttal A Multi-Agent Framework for Transpa.pdf,A Multi-Agent Framework for Transparent Author,"['Qianli Ma', 'Chang Guo', 'Zhiheng Tian', 'Siyu Wang', 'Jipeng Xiao', 'Yuanhao Yue', 'Zhipeng Zhang']",,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Paper2Rebuttal: A Multi-Agent Framework for Transparent Author || Response Assistance || Qianli Ma* Chang Guo* Zhiheng Tian* Siyu Wang Jipeng Xiao || Yuanhao Yue Zhipeng Zhang || AutoLab, School of Artificial Intelligence, Shanghai Jiao Tong University || {mqlqianli,zhipengzhang}@sjtu.edu.cn || Proj ... (truncated) ||  || { || ""title"": ""A Multi-Agent Framework for Transparent Author"", || ""authors"": [ || ""Qianli Ma"", || ""Chang Guo"", || ""Zhiheng Tian"", || ""Siyu Wang"", || ""Jipeng Xiao"", || ""Yuanhao Yue"", || ""Zhipeng Zhang"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper introduces REBUTTALAGENT, a multi-agent framework that reframes rebuttal generation as evidence-centric planning, aiming to improve transparency and accuracy in manuscript reviews."" || } ||  || [ Prompt: 113.8 t/s | Generation: 28.4 t/s ]"
2601.14172v1_Human Values in a Single Sentence Moral Presence H.pdf,"Human Values in a Single Sentence: Moral Presence, Hierarchies, and Transformer Ensembles on the Schwartz Continuum","['Vctor Yestea', 'Paolo Rossoa', 'Valencian Graduate School and Research Network of Artificial Intelligence (ValgrAI)']",arXiv:2601.14172v1,30.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Human Values in a Single Sentence: Moral Presence, || Hierarchies, and Transformer Ensembles on the || Schwartz Continuum || Vctor Yestea,b,, Paolo Rossoa,c || aPRHLT Research Center, Universitat Politcnica de Valncia, Valencia, 46022, Spain || bSchool of Science, Engineering and Design, Universid ... (truncated) ||  || { || ""title"": ""Human Values in a Single Sentence: Moral Presence, Hierarchies, and Transformer Ensembles on the Schwartz Continuum"", || ""authors"": [ || ""Vctor Yestea"", || ""Paolo Rossoa"", || ""Valencian Graduate School and Research Network of Artificial Intelligence (ValgrAI)"" || ], || ""doi"": ""arXiv:2601.14172v1"", || ""arxiv_id"": ""2601.14172v1"", || ""keywords"": [ || ""human values"", || ""moral presence"", || ""sentence-level detection"", || ""Schwartz continuum"", || ""transformer models"" || ], || ""summary"": ""This study investigates the identification of human values in the Schwartz motivational continuum using sentence-level data, demonstrating that hierarchical gating improves performance over direct multi-label classification despite sparse moral cues."" || } ||  || [ Prompt: 120.3 t/s | Generation: 30.1 t/s ]"
2601.14175v1_A model of errors in transformers.pdf,A model of errors in transformers,"['Suvrat Raju', 'Praneeth Netrapalli']",,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || A model of errors in transformers || Suvrat Raju 1 and Praneeth Netrapalli 2 || Abstract || We study the error rate of LLMs on tasks like || arithmetic that require a deterministic output, and || repetitive processing of tokens drawn from a small || set of alternatives. We argue that incorrect predic ... (truncated) ||  || { || ""title"": ""A model of errors in transformers"", || ""authors"": [ || ""Suvrat Raju"", || ""Praneeth Netrapalli"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""We study the error rate of LLMs on tasks like arithmetic and repetitive processing, arguing that incorrect predictions arise from accumulated attention errors and deriving a quantitative relationship between accuracy and task complexity."" || } ||  || [ Prompt: 105.9 t/s | Generation: 29.1 t/s ]"
2601.14192v1_Toward Efficient Agents Memory Tool learning and P.pdf,"Toward Efficient Agents: A Survey of Memory, Tool learning, and Planning","['Xiaofang Yang', 'Lijun Li', 'Heng Zhou', 'Tong Zhu', 'Xiaoye Qu', 'Yuchen Fan', 'Qianshan Wei', 'Rui Ye', 'Li Kang', 'Yiran Qin', 'Zhiqiang Kou', 'Daizong Liu', 'Qi Li', 'Ning Ding', 'Siheng Chen', 'Jing Shao']",arXiv:2601.14192v1,27.7,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Toward Efficient Agents: A Survey of Memory, || Tool learning, and Planning || Xiaofang Yang1,2, Lijun Li1,, || Heng Zhou1,3, Tong Zhu1, Xiaoye Qu1 Yuchen Fan1,4 || Qianshan Wei5 Rui Ye4 Li Kang1,4 Yiran Qin6 Zhiqiang Kou7 Daizong Liu8 Qi Li5 || Ning Ding9 Siheng Chen4 Jing Shao1, || 1 Shanghai Arti ... (truncated) ||  || { || ""title"": ""Toward Efficient Agents: A Survey of Memory, Tool learning, and Planning"", || ""authors"": [ || ""Xiaofang Yang"", || ""Lijun Li"", || ""Heng Zhou"", || ""Tong Zhu"", || ""Xiaoye Qu"", || ""Yuchen Fan"", || ""Qianshan Wei"", || ""Rui Ye"", || ""Li Kang"", || ""Yiran Qin"", || ""Zhiqiang Kou"", || ""Daizong Liu"", || ""Qi Li"", || ""Ning Ding"", || ""Siheng Chen"", || ""Jing Shao"" || ], || ""doi"": ""arXiv:2601.14192v1"", || ""arxiv_id"": ""2601.14192v1"", || ""keywords"": [ || ""Agents"", || ""Efficiency"", || ""Agent Memory"", || ""Tool Learning"", || ""Planning"" || ], || ""summary"": ""This paper investigates efficiency from memory, tool learning, and planning components, addressing cost considerations such as latency, tokens, and steps. It reviews recent approaches and proposes benchmarks and future directions for efficient agentic systems."" || } ||  || [ Prompt: 111.3 t/s | Generation: 27.7 t/s ]"
2601.14209v1_InT Self-Proposed Interventions Enable Credit Assi.pdf,Self-Proposed Interventions Enable Credit,"['Matthew Y. R. Yang', 'Hao Bai', 'Ian Wu', 'Gene Yang', 'Amrith Setlur', 'Aviral Kumar']",,27.2,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || InT: Self-Proposed Interventions Enable Credit || Assignment in LLM Reasoning || Matthew Y. R. Yang1, Hao Bai2, Ian Wu1, Gene Yang1, Amrith Setlur1 and Aviral Kumar1 || 1Carnegie Mellon University,2University of Illinois Urbana-Champaign || Base model || SFT || problem || Base model || RL || problem || Intervent ... (truncated) ||  || { || ""title"": ""Self-Proposed Interventions Enable Credit"", || ""authors"": [ || ""Matthew Y. R. Yang"", || ""Hao Bai"", || ""Ian Wu"", || ""Gene Yang"", || ""Amrith Setlur"", || ""Aviral Kumar"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""The paper proposes Intervention Training (InT) to improve credit assignment in LLMs by suggesting single-step corrections during reasoning traces. It addresses the credit assignment problem in RL, showing improved performance after fine-tuning."" || } ||  || [ Prompt: 106.2 t/s | Generation: 27.2 t/s ]"
2601.14230v1_MASCOT Towards Multi-Agent Socio-Collaborative Com.pdf,MASCOT: Towards Multi-Agent Socio-Collaborative Companion Systems,"['Yiyang Wang', 'Yiqiao Jin', 'Alex Cabral', 'Josiah Hester']",,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || MASCOT: Towards Multi-Agent Socio-Collaborative Companion Systems || Yiyang Wang1, Yiqiao Jin1, Alex Cabral1, and Josiah Hester 1 || 1Georgia Institute of Technology || 1ywang3420@gatech.edu || Abstract || Multi-agent systems (MAS) have recently || emerged as promising socio-collaborative com- || panion ... (truncated) ||  || { || ""title"": ""MASCOT: Towards Multi-Agent Socio-Collaborative Companion Systems"", || ""authors"": [ || ""Yiyang Wang"", || ""Yiqiao Jin"", || ""Alex Cabral"", || ""Josiah Hester"" || ], || ""doi"": """", || ""arxiv_id"": """", || ""keywords"": [], || ""summary"": ""Multi-agent systems for socio-collaborative companionship; addresses persona collapse and social symmetry."" || } ||  || [ Prompt: 107.7 t/s | Generation: 29.1 t/s ]"
2601.14232v1_KAGE-Bench Fast Known-Axis Visual Generalization E.pdf,KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning,"['Egor Cherepannov', 'Daniil Zelezetsky', 'Alexey K. Kovalev', 'Aleksandr I. Panov']",https://avanturist322.github.io/KAGEBench,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for || Reinforcement Learning || Egor Cherepannov 1 2 Daniil Zelezetsky 1 Alexey K. Kovalev 1 2 Aleksandr I. Panov 1 2 || Project Page: avanturist322.github.io/KAGEBench || Abstract || Pixel-based reinforcement learning agents of- || ten fa ... (truncated) ||  || { || ""title"": ""KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning"", || ""authors"": [ || ""Egor Cherepannov"", || ""Daniil Zelezetsky"", || ""Alexey K. Kovalev"", || ""Aleksandr I. Panov"" || ], || ""doi"": ""https://avanturist322.github.io/KAGEBench"", || ""arxiv_id"": ""not provided"", || ""keywords"": [ || ""reinforcement learning"", || ""visual generalization"", || ""pixel-based agents"", || ""visual distribution shift"", || ""KAGE-Env"", || ""JAX-native platformer"" || ], || ""summary"": ""The paper introduces KAGE-Env, a benchmark environment for evaluating visual generalization in reinforcement learning agents, and discusses challenges posed by visual distribution shifts."" || } ||  || [ Prompt: 112.1 t/s | Generation: 28.5 t/s ]"
2601.14234v1_Q-learning with Adjoint Matching.pdf,Q-learning with Adjoint Matching,"['Qiyang Li', 'Sergey Levine']",arXiv:2601.14234v1,28.5,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Preprint. || Q-LEARNING WITHADJOINTMATCHING || Qiyang Li || UC Berkeley || qcli@berkeley.edu || Sergey Levine || UC Berkeley || svlevine@berkeley.edu || ABSTRACT || We propose Q-learning with Adjoint Matching (QAM), a novel TD-based reinforce- || ment learning (RL) algorithm that tackles a long-standing challeng ... (truncated) ||  || { || ""title"": ""Q-learning with Adjoint Matching"", || ""authors"": [ || ""Qiyang Li"", || ""Sergey Levine"" || ], || ""doi"": ""arXiv:2601.14234v1"", || ""arxiv_id"": ""arXiv:2601.14234"", || ""keywords"": [ || ""Q-learning"", || ""adjoint matching"", || ""reinforcement learning"", || ""policy optimization"", || ""flow matching"" || ], || ""summary"": ""We propose Q-learning with Adjoint Matching (QAM), a novel TD-based reinforcement learning algorithm that tackles the challenge of efficiently optimizing expressive diffusion or flow-matching policies. QAM leverages adjoint matching to avoid unstable backpropagation and provides an unbiased policy at the optimum."" || } ||  || [ Prompt: 109.5 t/s | Generation: 28.5 t/s ]"
2601.14235v1_Opportunities in AIML for the Rubin LSST Dark Ener.pdf,,[],,27.3,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || Opportunities in AI/ML for the Rubin LSST || Dark Energy Science Collaboration || Version 1.0  January 2026 || The LSST Dark Energy Science Collaboration (DESC), Eric Aubourg,1 Camille Avestruz,2, 3 Matthew R. Becker,4 || Biswajit Biswas,4 Rahul Biswas,5 Boris Bolliet,6, 7 Adam S. Bolton,8 Clec ... (truncated) ||  || { || ""title"": ""Opportunities in AI/ML for the Rubin LSST"", || ""authors"": [ || ""Eric Aubourg"", || ""Camille Avestruz"", || ""Matthew R. Becker"", || ""Biswajit Biswas"", || ""Rahul Biswas"", || ""Boris Bolliet"", || ""Adam S. Bolton"", || ""Clecio R. Bom"", || ""Raphael Bonnet-Guerrini"", || ""Alexandre Boucaud"", || ""Jean-Eric Campagne"", || ""Chihway Chang"", || ""Aleksandra Ciprijanovic"", || ""Johann Cohen-Tanugi"", || ""Michael W. Coughlin"", || ""John Franklin Crenshaw"", || ""Juan C. Cuevas-Tello"", || ""Juan de Vicente"", || ""Seth W. Digel"", || ""Steven Dillmann"", || ""Mariano Javier de Leon Dominguez Romero"", || ""Alex Drlica-Wagner"", || ""Sydney Erickson"", || ""Alexander T. Gagliano"", || ""Christos Georgiou"", || ""Aritra Ghosh"", || ""Matthew Grayling"", || ""Kirill A. Grishin"", || ""Alan Heavens"", || ""Lindsay R. House"", || ""Michelle Lochner"", || ""Yao-Yuan Mao"", || ""Peter Melchior"", || ""Grant Merz"", || ""Martin Millon"", || ""Anais Moller"", || ""Gautham Narayan"", || ""Yuuki Omori"", || ""Hiranya Peiris"", || ""Laurence Perreault-Levasseur"", || ""Andres A. Plazas Malagon"", || ""Nesar Ramachandra"", || ""Benjamin Remy"", || ""Cecile Roucelle"", || ""Jaime Ruiz-Zapatero"", || ""Stefan Schuldt"", || ""Ignacio Sevilla-Noarbe"", || ""Tjitske Starkenburg"", || ""Stephen Thorp"", || ""Laura Toribio San Cipriano"", || ""Tilman Troster"", || ""Roberto Trotta"", || ""Padma Venkatraman"", || ""Amanda Wasserman"", || ""Tim White"", || ""Justine Zeghal"", || ""Tianqing Zhang"", || ""Yuanyuan Zhang ||  || [ Prompt: 109.0 t/s | Generation: 27.3 t/s ]"
2601.14242v1_APEX-Agents.pdf,APEXAgents,"['Bertie Vidgen', 'Austin Mann', 'Abby Fennelly', 'John Wright', 'Stanly', 'Lucas Rothman', 'Marco Burstein', 'Julien Benchek', 'David Ostrofsky', 'Anirudh Ravichandran', 'Debnil', 'Sur Neel Venugopal', 'Alannah Hsia', 'Isaac Robinson', 'Calix Huang', 'Olivia Varones', 'Daniyal Khan', 'Michael Haines', 'Zach Richards', 'Brendan Foody', 'Osvald Nitski']",arXiv:2601.14242v1,28.4,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || APEXAgents || Bertie Vidgen Austin Mann Abby Fennelly John Wright Stanly || Lucas Rothman Marco Burstein Julien Benchek David Ostrofsky || Anirudh Ravichandran Debnil Sur Neel Venugopal Alannah Hsia || Isaac Robinson Calix Huang Olivia Varones Daniyal Khan Michael Haines || Zach Richards Chirag Ma ... (truncated) ||  || { || ""title"": ""APEXAgents"", || ""authors"": [ || ""Bertie Vidgen"", || ""Austin Mann"", || ""Abby Fennelly"", || ""John Wright"", || ""Stanly"", || ""Lucas Rothman"", || ""Marco Burstein"", || ""Julien Benchek"", || ""David Ostrofsky"", || ""Anirudh Ravichandran"", || ""Debnil"", || ""Sur Neel Venugopal"", || ""Alannah Hsia"", || ""Isaac Robinson"", || ""Calix Huang"", || ""Olivia Varones"", || ""Daniyal Khan"", || ""Michael Haines"", || ""Zach Richards"", || ""Brendan Foody"", || ""Osvald Nitski"" || ], || ""doi"": ""arXiv:2601.14242v1"", || ""arxiv_id"": ""arXiv:2601.14242"", || ""keywords"": [], || ""summary"": ""We introduce the AI Productivity Index for Agents (APEXAgents), a benchmark for assessing whether AI agents can execute long-horizon, cross-application tasks created by investment banking analysts, management consultants, and corporate lawyers. APEXAgents requires agents to navigate realistic work environments with files and tools. We test eight agents for the leaderboard using Pass@1."" || } ||  || [ Prompt: 114.7 t/s | Generation: 28.4 t/s ]"
2601.14255v1_VideoMaMa Mask-Guided Video Matting via Generative.pdf,VideoMaMa: Mask-Guided Video Matting via Generative Prior,"['Sangbeom Lim', 'Seoung Wug Oh2', 'Jiahui Huang2', 'Heeji Yoon3', 'Seungryong Kim3', 'Joon-Young Lee2']",https://cvlab-kaist.github.io/VideoMaMa,29.1,LFM-2.5,Dimensity_9300+(Immortalis Vulkan),"ggml_vulkan: Found 1 Vulkan devices: || ggml_vulkan: 0 = Mali-G720-Immortalis MC12 (Mali-G720-Immortalis MC12) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 16 | shared memory: 32768 | int dot: 1 | matrix cores: none ||  || Loading model... ||  ||  || ▄▄ ▄▄ || ██ ██ || ██ ██  ▀▀█▄ ███▄███▄  ▀▀█▄    ▄████ ████▄ ████▄ || ██ ██ ▄█▀██ ██ ██ ██ ▄█▀██    ██    ██ ██ ██ ██ || ██ ██ ▀█▄██ ██ ██ ██ ▀█▄██ ██ ▀████ ████▀ ████▀ || ██    ██ || ▀▀    ▀▀ ||  || build      : b7807-0e4ebeb05 || model      : lfm.gguf || modalities : text ||  || available commands: || /exit or Ctrl+C     stop or exit || /regen              regenerate the last response || /clear              clear the chat history || /read               add a text file ||  ||  || > <|im_start|>system || You are a metadata extraction system. Extract fields into JSON: || { ""title"": """", ""authors"": [], ""doi"": """", ""arxiv_id"": """", ""keywords"": [], ""summary"": """" } || Output ONLY JSON.<|im_end|> || <|im_start|>user || VideoMaMa: Mask-Guided Video Matting via Generative Prior || Sangbeom Lim1 || Seoung Wug Oh2 Jiahui Huang2 Heeji Yoon3 || Seungryong Kim3 Joon-Young Lee2 || 1Korea University 2Adobe Research 3KAIST AI || https://cvlab-kaist.github.io/VideoMaMa || Input Video || VideoMaMa || Input Mask || Model-generated Mask  ... (truncated) ||  || { || ""title"": ""VideoMaMa: Mask-Guided Video Matting via Generative Prior"", || ""authors"": [ || ""Sangbeom Lim"", || ""Seoung Wug Oh2"", || ""Jiahui Huang2"", || ""Heeji Yoon3"", || ""Seungryong Kim3"", || ""Joon-Young Lee2"" || ], || ""doi"": ""https://cvlab-kaist.github.io/VideoMaMa"", || ""arxiv_id"": ""arXiv:2601.14255v1"", || ""keywords"": [ || ""video matting"", || ""mask-guided"", || ""generative prior"", || ""video diffusion"", || ""matting anything in video"" || ], || ""summary"": ""VideoMaMa is a diffusion-based model that generates high-quality alpha mattes from segmentation masks, demonstrating strong zero-shot generalization to real-world footage. The authors developed MA-V dataset and improved SAM2-Matte for robust in-the-wild matting."" || } ||  || [ Prompt: 121.5 t/s | Generation: 29.1 t/s ]"
